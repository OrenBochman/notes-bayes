---
date: 2024-11-05
title: "Graded Assignment: Bayesian analysis of an EEG dataset using an AR(p) -  M2L5"
subtitle: Time Series Analysis
description: "The AR(P) process, its state-space representation, the characteristic polynomial, and the forecast function"
categories: 
  - Coursera 
  - notes
  - Bayesian Statistics
  - Autoregressive Models
  - Time Series
keywords: 
  - time series
  - stability
  - order of an AR process 
  - characteristic lag polynomial
  - autocorrelation function
  - ACF
  - partial autocorrelation function
  - PACF
  - smoothing
  - State Space Model
  - ARMA process
  - ARIMA
  - moving average
  - AR(p) process  
  - R code
---

::::: {.content-visible unless-profile="HC"}

::: {.callout-caution}
Section omitted to comply with the Honor Code
:::

:::::

::::: {.content-hidden unless-profile="HC"}



The dataset below corresponds to a portion of an electroencephalogram (EEG) recorded in a particular location on the scalp of an individual. The original EEG dataset was originally recorded at 256Hz but was then subsampled every sixth observations, so the resulting sampling rate is about 42.7 observations per second. The dataset below has 400 observations corresponding approximately to 9.36 seconds.

You will use an AR(8) to model this dataset and obtain maximum likelihood estimation and Bayesian inference for the parameters of the model. For this you will need to do the following:

1.  Download the dataset, and plot it in R. Upload a picture of your graph displaying the data and comment on the features of the data. Does it present any trends or quasi-periodic behavior?

2.  Modify the code below to obtain the maximum likelihood estimators (MLEs) for the AR coefficients under the conditional likelihood. For this you will assume an autoregressive model of order p=8. The parameters of the model are $\phi=(\phi_1, \ldots \phi_8)'$ snf $v$. You will compute the MLE of $\phi$ denoted as $\hat\phi$. â€‹

3.  Obtain an unbiased estimator for the observational variance of the AR(8). You will compute the unbiased estimator for $v$ denoted as $s^2$.

4.  Modify the code below to obtain 500 samples from the posterior distribution of the parameters $\phi=(\phi_1, \ldots \phi_8)'$ and $v$ under the conditional likelihood and the reference prior. You will assume an autoregressive model of order v. Once you obtain samples from the posterior distribution you will compute the posterior means of $\phi$ and $v$, denoted as $\hat\phi$. and $\hat v$, respectively.

Modify the code below to use the function `polyroot` and obtain the moduli and periods of the reciprocal roots of the AR polynomial evaluated at the posterior mean $\hat\phi$.

```{r}
#| label: ar-simulation

set.seed(2021)
r=0.95
lambda=12 
phi=numeric(2) 
phi[1]=2*r*cos(2*pi/lambda) 
phi[2]=-r^2
sd=1 # innovation standard deviation
T=300 # number of time points
# generate stationary AR(2) process
yt=arima.sim(n = T, model = list(ar = phi), sd = sd) 
par(mfrow=c(1,1), mar = c(3, 4, 2, 1) )
plot(yt)

## Case 1: Conditional likelihood
p=2
y=rev(yt[(p+1):T]) # response
X=t(matrix(yt[rev(rep((1:p),T-p)+rep((0:(T-p-1)),rep(p,T-p)))],p,T-p));
XtX=t(X)%*%X
XtX_inv=solve(XtX)
phi_MLE=XtX_inv%*%t(X)%*%y # MLE for phi
s2=sum((y - X%*%phi_MLE)^2)/(length(y) - p) #unbiased estimate for v

cat("\n MLE of conditional likelihood for phi: ", phi_MLE, "\n",
    "Estimate for v: ", s2, "\n")
    
#####################################################################################
##  AR(2) case 
### Posterior inference, conditional likelihood + reference prior via 
### direct sampling                 
#####################################################################################

n_sample=1000 # posterior sample size
library(MASS)

## step 1: sample v from inverse gamma distribution
v_sample=1/rgamma(n_sample, (T-2*p)/2, sum((y-X%*%phi_MLE)^2)/2)

## step 2: sample phi conditional on v from normal distribution
phi_sample=matrix(0, nrow = n_sample, ncol = p)
for(i in 1:n_sample){
  phi_sample[i, ]=mvrnorm(1,phi_MLE,Sigma=v_sample[i]*XtX_inv)
}

## plot histogram of posterior samples of phi and nu
par(mfrow = c(1, 3),  mar = c(3, 4, 2, 1), cex.lab = 1.3)
for(i in 1:2){
  hist(phi_sample[, i], xlab = bquote(phi), 
       main = bquote("Histogram of "~phi[.(i)]))
  abline(v = phi[i], col = 'red')
}

hist(v_sample, xlab = bquote(nu), main = bquote("Histogram of "~v))
abline(v = sd, col = 'red')

```

:::::