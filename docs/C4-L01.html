<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="dcterms.date" content="2024-10-23">
<meta name="keywords" content="time series, stationarity, strong stationarity, weak stationarity, lag, autocorrelation function (ACF), partial autocorrelation function (PACF), smoothing, trend, seasonality, differencing operator, back shift operator, moving average, AR(1) process, Yule-Walker equations, Durbin-Levinson recursion, R code">
<meta name="description" content="This lesson we will define the AR(1) process, Stationarity, ACF, PACF, differencing, smoothing">

<title>88&nbsp; Introductions to Time Series analysis &amp; the AR(1) process – Bayesian Specialization Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C4-L02.html" rel="next">
<link href="./C4-L00.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-923206e44a13b4518db4dede9f4ebdc9.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-987387ce273b62b48f1747d606bce1d5.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(images/banner_deep.jpg);
background-size: cover;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./C4-L01.html"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Introductions to Time Series analysis &amp; the AR(1) process</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Introductions to Time Series analysis &amp; the AR(1) process</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
            <p class="subtitle lead">Time Series Analysis</p>
                  <div>
        <div class="description">
          This lesson we will define the AR(1) process, Stationarity, ACF, PACF, differencing, smoothing
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">coursera</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">bayesian statistics</div>
                <div class="quarto-category">autoregressive models</div>
                <div class="quarto-category">time series</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 23, 2024</p>
      </div>
    </div>
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>time series, stationarity, strong stationarity, weak stationarity, lag, autocorrelation function (ACF), partial autocorrelation function (PACF), smoothing, trend, seasonality, differencing operator, back shift operator, moving average, AR(1) process, Yule-Walker equations, Durbin-Levinson recursion, R code</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Specialization Notes</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Bayesian Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Paradigms of probability - M1L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayes’ Theorem - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">M1L2HW1 - Conditional Probability and Bayes’ Law</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">M1L2HW2 - Probability and Bayes’ Theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">M1L3 - Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Random Variables - M1L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework on Distributions - M1L3HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">M2L4 - Frequentist Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Frequentist MLE - M2L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bayesian Inference - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Homework on Likelihoods and MLEs - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Homework on Bayesian Inference - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Priors - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Homework Posterior Probabilities - M3L6HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">M3L7 - Binomial Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Homework on Priors - M2L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Poisson Data - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Homework on Poisson Data - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Beta Bernoulli - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">M4L9 - Exponential Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Homework on Exponential Data - M4L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Normally distributed Data - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Homework on Normal Data - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Non-Informative Priors - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Homework Alternative Priors - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Brief Review of Regression - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">M1L1 - Statistical Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">M1L2 - Bayesian Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">M1L3 - Monte Carlo estimation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">M2L4 - Metropolis-Hastings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Homework on the Metropolis-Hastings algorithm</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Gibbs sampling - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Homework Gibbs-Sampling algorithm - M2L22HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Assessing Convergence - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Homework on the Gibbs-Sampling algorithm - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Homework on M-H algorithm M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Linear regression - M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Homework on Linear Regression Model Part 1 - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Homework on Deviance information criterion - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">ANOVA - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Homework on ANOVA - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Homework on Multiple Factor ANOVA - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">M3L9 - Logistic regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Homework on Logistic Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">M4L10 - Poisson regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Homework on Poisson regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Hierarchical modeling - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Homework on Hierarchical Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Homework on Non-Normal Hierarchical Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">M4L12 - Capstone Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Homework Predictive distributions and mixture models - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">M1L1 - Definitions of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex1-Basic-Definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Basic Concepts of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex2-Gaussian-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Mixtures of Gaussians</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex3-Zero-Inflated-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Zero inflated distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex4-Def-mixture-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Definition of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Likelihood functions for Mixture Models - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Homework The Likelihood function - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Homework Identifiability - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Homework The likelihood function M1L2HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">HW - Simulating from a Mixture Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">HW - Simulation of Poisson mixture model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">HW+ - Sim mixture of exponential distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">M2L3 - The EM algorithm for Mixture models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">The EM algorithm for Zero-Inflated Mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">M4L1 - MCMC for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">The MCMC algorithm for Zero-Inflated Mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Markov chain Monte Carlo algorithms for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">M4L5 - Density Estimation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">M4L6 - Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">M4L7 -Classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the EM algorithm</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the MCMC algorithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Bayesian Mixture Models for Classification of Banknotes</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Computational Considerations - M5L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Computational considerations for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Determining the number of components - M5L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">M5HW2 - Bayesian Information Criteria (BIC)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">M5HW2 - Estimating the number of components in Bayesian settings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">M5HW3 - Estimating the partition structure in Bayesian models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">M5HW4 - BIC for zero-inflated mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Week 0: Introductions to time series analysis and the AR(1) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L01.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Introductions to Time Series analysis &amp; the AR(1) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">The AR(p) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">Normal Dynamic Linear Models, Part 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">Normal Dynamic Linear Models, Part 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Final Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Week 0: Feynman Notebook on Bayesian Time Series Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">Appendix: Notation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">Appendix: Discrete Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">96</span>&nbsp; <span class="chapter-title">Appendix: Continuous Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">97</span>&nbsp; <span class="chapter-title">Appendix: Exponents &amp; Logarithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">98</span>&nbsp; <span class="chapter-title">Appendix: The Law of Large Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">99</span>&nbsp; <span class="chapter-title">Appendix: The Central Limit Theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">100</span>&nbsp; <span class="chapter-title">Appendix: Conjugate Priors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">101</span>&nbsp; <span class="chapter-title">Appendix: Link Function</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">102</span>&nbsp; <span class="chapter-title">Bayes by backprop</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">103</span>&nbsp; <span class="chapter-title">Bayesian Books in R &amp; Python</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">About</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">105</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">88.1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#welcome-to-bayesian-statistics-time-series" id="toc-welcome-to-bayesian-statistics-time-series" class="nav-link" data-scroll-target="#welcome-to-bayesian-statistics-time-series"><span class="header-section-number">88.1.1</span> Welcome to Bayesian Statistics: Time Series</a></li>
  <li><a href="#introduction-to-r" id="toc-introduction-to-r" class="nav-link" data-scroll-target="#introduction-to-r"><span class="header-section-number">88.1.2</span> Introduction to R</a></li>
  </ul></li>
  <li><a href="#sec-stationarity-acf-pacf" id="toc-sec-stationarity-acf-pacf" class="nav-link" data-scroll-target="#sec-stationarity-acf-pacf"><span class="header-section-number">88.2</span> Stationarity the ACF and the PACF (Video)</a>
  <ul class="collapse">
  <li><a href="#stationarity-video" id="toc-stationarity-video" class="nav-link" data-scroll-target="#stationarity-video"><span class="header-section-number">88.2.1</span> Stationarity (video)</a></li>
  <li><a href="#sec-acf" id="toc-sec-acf" class="nav-link" data-scroll-target="#sec-acf"><span class="header-section-number">88.2.2</span> The auto-correlation function ACF (video)</a></li>
  <li><a href="#sec-pacf-reading" id="toc-sec-pacf-reading" class="nav-link" data-scroll-target="#sec-pacf-reading"><span class="header-section-number">88.2.3</span> The partial auto-correlation function PACF (Reading)</a></li>
  </ul></li>
  <li><a href="#sec-differencing-and-smoothing" id="toc-sec-differencing-and-smoothing" class="nav-link" data-scroll-target="#sec-differencing-and-smoothing"><span class="header-section-number">88.3</span> Differencing and smoothing (Reading)</a>
  <ul class="collapse">
  <li><a href="#differencing" id="toc-differencing" class="nav-link" data-scroll-target="#differencing"><span class="header-section-number">88.3.1</span> Differencing</a></li>
  <li><a href="#smoothing" id="toc-smoothing" class="nav-link" data-scroll-target="#smoothing"><span class="header-section-number">88.3.2</span> Smoothing</a></li>
  </ul></li>
  <li><a href="#sec-differencing-and-smoothing-examples" id="toc-sec-differencing-and-smoothing-examples" class="nav-link" data-scroll-target="#sec-differencing-and-smoothing-examples"><span class="header-section-number">88.4</span> ACF PACF Differencing and Smoothing Examples (Video)</a></li>
  <li><a href="#sec-differencing-and-smoothing-reading" id="toc-sec-differencing-and-smoothing-reading" class="nav-link" data-scroll-target="#sec-differencing-and-smoothing-reading"><span class="header-section-number">88.5</span> R code for Differencing and filtering via moving averages (reading)</a></li>
  <li><a href="#sec-white-noise-simulation" id="toc-sec-white-noise-simulation" class="nav-link" data-scroll-target="#sec-white-noise-simulation"><span class="header-section-number">88.6</span> R Code: Simulate data from a white noise process (reading)</a>
  <ul class="collapse">
  <li><a href="#quiz-1-stationarity-acf-pacf-differencing-and-smoothing" id="toc-quiz-1-stationarity-acf-pacf-differencing-and-smoothing" class="nav-link" data-scroll-target="#quiz-1-stationarity-acf-pacf-differencing-and-smoothing"><span class="header-section-number">88.6.1</span> Quiz 1: Stationarity, ACF, PACF, Differencing, and Smoothing</a></li>
  </ul></li>
  <li><a href="#the-ar1-process-definition-and-properties" id="toc-the-ar1-process-definition-and-properties" class="nav-link" data-scroll-target="#the-ar1-process-definition-and-properties"><span class="header-section-number">88.7</span> The AR(1) process: Definition and properties</a>
  <ul class="collapse">
  <li><a href="#the-ar1-process-video" id="toc-the-ar1-process-video" class="nav-link" data-scroll-target="#the-ar1-process-video"><span class="header-section-number">88.7.1</span> The AR(1) process (video)</a></li>
  <li><a href="#the-pacf-of-the-ar1-process-reading" id="toc-the-pacf-of-the-ar1-process-reading" class="nav-link" data-scroll-target="#the-pacf-of-the-ar1-process-reading"><span class="header-section-number">88.7.2</span> The PACF of the AR(1) process (reading)</a></li>
  <li><a href="#simulate-data-from-an-ar1-process-video" id="toc-simulate-data-from-an-ar1-process-video" class="nav-link" data-scroll-target="#simulate-data-from-an-ar1-process-video"><span class="header-section-number">88.7.3</span> Simulate data from an AR(1) process (video)</a></li>
  <li><a href="#r-code-sample-data-from-ar1-processes-reading" id="toc-r-code-sample-data-from-ar1-processes-reading" class="nav-link" data-scroll-target="#r-code-sample-data-from-ar1-processes-reading"><span class="header-section-number">88.7.4</span> R code: Sample data from AR(1) processes (Reading)</a></li>
  <li><a href="#quiz-2-the-ar1-definition-and-properties" id="toc-quiz-2-the-ar1-definition-and-properties" class="nav-link" data-scroll-target="#quiz-2-the-ar1-definition-and-properties"><span class="header-section-number">88.7.5</span> Quiz 2: The AR(1) definition and properties</a></li>
  </ul></li>
  <li><a href="#the-ar1-processmaximum-likelihood-estimation-and-bayesian-inference" id="toc-the-ar1-processmaximum-likelihood-estimation-and-bayesian-inference" class="nav-link" data-scroll-target="#the-ar1-processmaximum-likelihood-estimation-and-bayesian-inference"><span class="header-section-number">89</span> The AR(1) process:Maximum likelihood estimation and Bayesian inference</a>
  <ul class="collapse">
  <li><a href="#review-of-maximum-likelihood-and-bayesian-inference-in-regression" id="toc-review-of-maximum-likelihood-and-bayesian-inference-in-regression" class="nav-link" data-scroll-target="#review-of-maximum-likelihood-and-bayesian-inference-in-regression"><span class="header-section-number">89.1</span> Review of maximum likelihood and Bayesian inference in regression</a>
  <ul class="collapse">
  <li><a href="#regression-models-maximum-likelihood-estimation" id="toc-regression-models-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#regression-models-maximum-likelihood-estimation"><span class="header-section-number">89.1.1</span> Regression Models: Maximum Likelihood Estimation</a></li>
  <li><a href="#regression-models-bayesian-inference" id="toc-regression-models-bayesian-inference" class="nav-link" data-scroll-target="#regression-models-bayesian-inference"><span class="header-section-number">89.1.2</span> Regression Models: Bayesian Inference</a></li>
  </ul></li>
  <li><a href="#maximum-likelihood-estimation-in-the-ar1-video" id="toc-maximum-likelihood-estimation-in-the-ar1-video" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-in-the-ar1-video"><span class="header-section-number">89.2</span> Maximum likelihood estimation in the AR(1) (video)</a></li>
  <li><a href="#r-code-mle-for-the-ar1-examples-reading" id="toc-r-code-mle-for-the-ar1-examples-reading" class="nav-link" data-scroll-target="#r-code-mle-for-the-ar1-examples-reading"><span class="header-section-number">89.3</span> R code: MLE for the AR(1), examples (reading)</a></li>
  <li><a href="#bayesian-inference-in-the-ar1" id="toc-bayesian-inference-in-the-ar1" class="nav-link" data-scroll-target="#bayesian-inference-in-the-ar1"><span class="header-section-number">89.4</span> Bayesian inference in the AR(1)</a></li>
  <li><a href="#bayesian-inference-in-the-ar1-conditional-likelihood-example-video" id="toc-bayesian-inference-in-the-ar1-conditional-likelihood-example-video" class="nav-link" data-scroll-target="#bayesian-inference-in-the-ar1-conditional-likelihood-example-video"><span class="header-section-number">89.5</span> Bayesian inference in the AR(1): Conditional likelihood example (video)</a></li>
  <li><a href="#r-code-ar1-bayesian-inference-conditional-likelihood-example-reading" id="toc-r-code-ar1-bayesian-inference-conditional-likelihood-example-reading" class="nav-link" data-scroll-target="#r-code-ar1-bayesian-inference-conditional-likelihood-example-reading"><span class="header-section-number">89.6</span> R Code: AR(1) Bayesian inference, conditional likelihood example (reading)</a></li>
  <li><a href="#quiz---mle-and-bayesian-inference-in-the-ar1" id="toc-quiz---mle-and-bayesian-inference-in-the-ar1" class="nav-link" data-scroll-target="#quiz---mle-and-bayesian-inference-in-the-ar1"><span class="header-section-number">89.7</span> Quiz - MLE and Bayesian inference in the AR(1)</a></li>
  <li><a href="#practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1" id="toc-practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1" class="nav-link" data-scroll-target="#practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1"><span class="header-section-number">89.8</span> Practice Graded Assignment: MLE and Bayesian inference in the AR(1)</a>
  <ul class="collapse">
  <li><a href="#bayesian-inference-in-the-ar1-full-likelihood-example-reading" id="toc-bayesian-inference-in-the-ar1-full-likelihood-example-reading" class="nav-link" data-scroll-target="#bayesian-inference-in-the-ar1-full-likelihood-example-reading"><span class="header-section-number">89.8.1</span> Bayesian Inference in the AR(1), : full likelihood example (reading)</a></li>
  <li><a href="#transformation-of-phi" id="toc-transformation-of-phi" class="nav-link" data-scroll-target="#transformation-of-phi"><span class="header-section-number">89.8.2</span> Transformation of <span class="math inline">\phi</span></a></li>
  <li><a href="#mcmc-algorithm-bayesian-inference-for-ar1-full-likelihood" id="toc-mcmc-algorithm-bayesian-inference-for-ar1-full-likelihood" class="nav-link" data-scroll-target="#mcmc-algorithm-bayesian-inference-for-ar1-full-likelihood"><span class="header-section-number">89.8.3</span> MCMC Algorithm: Bayesian Inference for AR(1), Full Likelihood</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Learning Objectives
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><del>List the goals of the course</del></label></li>
<li><label><input type="checkbox" checked="">identify the basics of the R environment.</label></li>
<li><label><input type="checkbox" checked="">Explain <strong>stationary</strong> time series processes</label></li>
<li><label><input type="checkbox">Define <strong>auto-correlation function</strong> (ACF) and <strong>partial auto-correlation function</strong> (PACF) and use R to plot the sample ACF and sample PACF of a time series</label></li>
<li><label><input type="checkbox" checked="">Explain the concepts of differencing and smoothing via moving averages to remove/highlight trends and seasonal components in a time series</label></li>
<li><label><input type="checkbox">Define the zero-mean autoregressive process of order one or AR(1) and use R to obtain samples from this type of process</label></li>
<li><label><input type="checkbox">Perform maximum likelihood estimation for the full and conditional likelihood in an AR(1)</label></li>
<li><label><input type="checkbox">Perform Bayesian inference for the AR(1) under the conditional likelihood and the reference prior</label></li>
</ul>
</div>
</div>
</div>
<section id="introduction" class="level2" data-number="88.1">
<h2 data-number="88.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">88.1</span> Introduction</h2>
<section id="welcome-to-bayesian-statistics-time-series" class="level3" data-number="88.1.1">
<h3 data-number="88.1.1" class="anchored" data-anchor-id="welcome-to-bayesian-statistics-time-series"><span class="header-section-number">88.1.1</span> Welcome to Bayesian Statistics: Time Series</h3>
<ul>
<li><label><input type="checkbox" checked="">Obligatory introduction to the course and the instructors.</label></li>
<li><a href="">Raquel Prado</a> is a professor of statistics in the <a href="https://engineering.ucsc.edu/">Baskin School of Engineering</a> at the University of California, Santa Cruz. She was the recipient 2022 <a href="https://bayesian.org/project/zellner-medal/">Zellner Medal</a>, see <span class="citation" data-cites="BibEntry2024Sep">Weckerle (<a href="#ref-BibEntry2024Sep" role="doc-biblioref">2022</a>)</span>.</li>
</ul>
</section>
<section id="introduction-to-r" class="level3" data-number="88.1.2">
<h3 data-number="88.1.2" class="anchored" data-anchor-id="introduction-to-r"><span class="header-section-number">88.1.2</span> Introduction to R</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf">Introduction to R</a></label></li>
</ul>
</section>
</section>
<section id="sec-stationarity-acf-pacf" class="level2 page-columns page-full" data-number="88.2">
<h2 data-number="88.2" class="anchored" data-anchor-id="sec-stationarity-acf-pacf"><span class="header-section-number">88.2</span> Stationarity the ACF and the PACF (Video)</h2>
<p>Before diving into the material here is a brief overview of the notations for timer series.</p>
<div id="tip-notation" class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip&nbsp;88.1: Notation
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p><span class="math inline">\{y_t\}</span> - the time series process, where each <span class="math inline">y_t</span> is a univariate random variable and t are the time points that are equally spaced.</p></li>
<li><p><span class="math inline">y_{1:T}</span> or <span class="math inline">y_1, y_2, \ldots, y_T</span> - the observed data.</p></li>
<li><p>You will see the use of ’ to denote the transpose of a matrix,</p></li>
<li><p>and the use of <span class="math inline">\sim</span> to denote a distribution.</p></li>
<li><p>under tildes <span class="math inline">\utilde{y}</span> are used to denote estimates of the true values <span class="math inline">y</span>.</p></li>
<li><p>E matrix of eigenvalues</p></li>
<li><p><span class="math inline">\Lambda = diagonal(\alpha_1, \alpha_2, \ldots , \alpha_p)</span> is a diagonal matrix with the eigenvalues of <span class="math inline">\Sigma</span> on the diagonal.</p></li>
<li><p><span class="math inline">J_p(1)</span> = a p by p <a href="https://en.wikipedia.org/wiki/Jordan_normal_form">Jordan form</a> matrix with 1 on the super-diagonal</p></li>
</ul>
<p>also see <span class="citation" data-cites="prado2023time">(<a href="#ref-prado2023time" role="doc-biblioref">Prado, Ferreira, and West 2023, 2–3</a>)</span></p>
</div>
</div>
<section id="stationarity-video" class="level3 page-columns page-full" data-number="88.2.1">
<h3 data-number="88.2.1" class="anchored" data-anchor-id="stationarity-video"><span class="header-section-number">88.2.1</span> Stationarity (video)</h3>

<div class="no-row-height column-margin column-container"><div id="fig-slide-stationarity-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-slide-stationarity-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/m1_0001.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;88.1: strong and weak stationarity"><img src="images/m1_0001.png" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-slide-stationarity-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;88.1: strong and weak stationarity
</figcaption>
</figure>
</div></div><p>Stationarity c.f. <span class="citation" data-cites="prado2023time">(<a href="#ref-prado2023time" role="doc-biblioref">Prado, Ferreira, and West 2023, sec. 1.2</a>)</span> is a fundamental concept in time series analysis.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>TL;DR – Stationarity
</div>
</div>
<div class="callout-body-container callout-body">
<dl>
<dt>Stationarity</dt>
<dd>

</dd>
<dd>
<p>A time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.</p>
</dd>
</dl>
<ul>
<li>We make this definition more formal in the definitions of strong and weak stationarity below.</li>
</ul>
</div>
</div>
<div class="no-row-height column-margin column-container"><span class="callout-margin-content">Stationarity</span></div><p><mark>Stationarity is a key concept in time series analysis. A time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.</mark></p>
<div id="def-strong-stationarity" class="theorem definition page-columns page-full">
<div class="page-columns page-full"><p><span class="theorem-title"><strong>Definition 88.1 (Strong Stationarity)</strong></span>  Let <span class="math inline">y_t</span> be a time series. We say that <span class="math inline">y_t</span> is <em>stationary</em> if the following conditions hold:</p><div class="no-row-height column-margin column-container"><span class="">Strong Stationarity</span></div></div>
<p>Let <span class="math inline">\{y_t\} \quad \forall n&gt;0</span> be a time series and <span class="math inline">h &gt; 0</span> be a lag. If for any subsequence the distribution of <span class="math inline">y_t, y_{t+1}, \ldots, y_{t+n}</span> is the same as the distribution of <span class="math inline">y_{t+h}, y_{t+h+1}, \ldots, y_{t+h+n}</span> we call the series strongly stationary.</p>
</div>
<p>As it’s difficult to verify strong stationarity in practice, we will often use the following weaker notion of stationarity.</p>
<div id="def-weak-stationarity" class="theorem definition page-columns page-full">
<div class="page-columns page-full"><p><span class="theorem-title"><strong>Definition 88.2 (Weak Stationarity)</strong></span>   The mean, variance, and auto-covariance are constant over time.</p><div class="no-row-height column-margin column-container"><span class="">Weak Stationarity</span><span class="">Second-order Stationarity</span></div></div>
<p><span id="eq-weak-stationarity"><span class="math display">
\begin{aligned}
\mathbb{E}[y_t] &amp;= \mu \quad \forall t \\
\mathbb{V}ar[y_t] &amp;= \nu =\sigma^2 \quad \forall t \\
\mathbb{C}ov[y_t , y_s ] &amp;= γ(t − s)
\end{aligned}
\tag{88.1}</span></span></p>
</div>
<ul>
<li>Strong stationarity <span class="math inline">\implies</span> Weak stationarity, but</li>
<li>The converse is not true.</li>
<li>In this course when we deal with a Gaussian process, our typical use case, they are equivalent!</li>
</ul>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>Check your understanding
</div>
</div>
<div class="callout-body-container callout-body">
<p>Q. Can you explain with an example when a time series is weakly stationary but not strongly stationary?</p>
</div>
</div>
</section>
<section id="sec-acf" class="level3 page-columns page-full" data-number="88.2.2">
<h3 data-number="88.2.2" class="anchored" data-anchor-id="sec-acf"><span class="header-section-number">88.2.2</span> The auto-correlation function ACF (video)</h3>

<div class="no-row-height column-margin column-container"><div id="fig-slide-afc-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-slide-afc-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/m1_0011.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;88.2: The auto-correlation function ACF"><img src="images/m1_0011.png" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-slide-afc-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;88.2: The auto-correlation function ACF
</figcaption>
</figure>
</div></div><p> <mark>The autocorrelation is simply how correlated a time series is with itself at different lags</mark>.</p>
<ul>
<li>Correlation in general is defined in terms of covariance of two variables.</li>
<li>The covariance is a measure of the joint variability of two random variables.</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recall that the Covariance between two random variables <span class="math inline">y_t</span> and <span class="math inline">y_s</span> is defined as:</p>
<p><span id="eq-covariance"><span class="math display">
\begin{aligned}
\mathbb{C}ov[y_t, y_s] &amp;= \mathbb{E}[(y_t-\mathbb{E}[y_t])(y_s-\mathbb{E}[y_s])] \\
              &amp;= \mathbb{E}[(y_t-\mu_t)(y_s-\mu_s)] \\
              &amp;= E[y_t y_s] - \mu_t \times \mu_s
\end{aligned} \qquad
\tag{88.2}</span></span></p>
<p>We get the second line by substituting <span class="math inline">\mu_t = \mathbb{E}(y_t)</span> and <span class="math inline">\mu_s = \mathbb{E}(y_s)</span> using the definition of the mean of a RV. the third line is by multiplying out and using the linearity of the expectation operator.</p>
</div>
</div>
<div id="tip-acf" class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip&nbsp;88.2: AFC notation
</div>
</div>
<div class="callout-body-container callout-body">
<p>We will frequently use the notation <span class="math inline">\gamma(h)</span> to denote the <strong>autocovariance</strong> for a lag <span class="math inline">h</span> i.e.&nbsp;between <span class="math inline">y_t</span> and <span class="math inline">y_{t+h}</span></p>
<p><span id="eq-autocovariance"><span class="math display">
\gamma(h) = \mathbb{C}ov[y_t, y_{t+h}] \qquad
\tag{88.3}</span></span></p>
</div>
</div>
<p>When the time series is stationary, then the covariance only depends on the lag <span class="math inline">h = |t-s|</span> and we can write the covariance as <span class="math inline">\gamma(h)</span>.</p>
<p>Let <span class="math inline">\{y_t\}</span> be a time series. Recall that the covariance between two random variables <span class="math inline">y_t</span> and <span class="math inline">y_s</span> is defined as:</p>
<p><span id="eq-covariance"><span class="math display">
\gamma(t,s)=\mathbb{C}ov[y_t, y_s] = \mathbb{E}[(y_t-\mu_t)(y_s-\mu_s)] \qquad
\tag{88.4}</span></span></p>
<p>where <span class="math inline">\mu_t = \mathbb{E}(y_t)</span> and <span class="math inline">\mu_s = \mathbb{E}(y_s)</span> are the means of <span class="math inline">y_t</span> and <span class="math inline">y_s</span> respectively.</p>
<p><span id="eq-mean"><span class="math display">
\mu_t = \mathbb{E}(y_t) \qquad \mu_s = \mathbb{E}(y_s)
\tag{88.5}</span></span></p>
<p><span class="math display">
\text{Stationarity} \implies \mathbb{E}[y_t] = \mu \quad \forall t \qquad \therefore \quad \gamma(t,s)=\gamma(|t-s|)
</span></p>
<p>If <span class="math inline">h&gt;0 \qquad \gamma(h)=\mathbb{C}ov[y_t,y_{t-h}]</span></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Autocorrelation Function (AFC)
</div>
</div>
<div class="callout-body-container callout-body">
<p></p>
<p><span id="eq-autocorrelation"><span class="math display">
\rho(t,s) = \frac{\gamma(t,s)}{\sqrt{\gamma(t,t)\gamma(s,s)}}
\tag{88.6}</span></span></p>
</div>
</div>
<div class="no-row-height column-margin column-container"><span class="callout-margin-content">auto-correlation AFC</span></div><p><span class="math display">
\text{Stationarity} \implies \rho(h)=\frac{\gamma(h)}{\gamma(o)} \qquad \gamma(0)=Var(y_t)
</span></p>

<div class="no-row-height column-margin column-container"><div id="fig-slide-afc-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-slide-afc-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/m1_0012.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;88.3: sample AFC"><img src="images/m1_0012.png" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-slide-afc-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;88.3: sample AFC
</figcaption>
</figure>
</div></div><p><span id="eq-sub-sequence"><span class="math display">
y_{1:T}
\tag{88.7}</span></span></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>The sample AFC
</div>
</div>
<div class="callout-body-container callout-body">
<p><span id="eq-sample-auto-covariance-function"><span class="math display">
\hat\gamma(h)= \frac{1}{T} \sum_{t=1}^{T-h}(y_{t+h}-\bar y )(y_t-\hat y)
\tag{88.8}</span></span></p>
<p>where <span class="math inline">\bar y</span> is the sample mean of the time series <span class="math inline">y_{1:T}</span>, and <span class="math inline">\hat y</span> is the sample mean of the time series <span class="math inline">y_{1:T-h}</span>.</p>
</div>
</div>
<p><span id="eq-sample-mean"><span class="math display">
\bar y = \frac{1}{T} \sum_{t=1}^{T}y_t
\tag{88.9}</span></span></p>
<p><span id="eq-sample-auto-correlation-function"><span class="math display">
\hat \rho = \frac{\hat\gamma(h)}{\hat\gamma(o)}
\tag{88.10}</span></span></p>
</section>
<section id="sec-pacf-reading" class="level3 page-columns page-full" data-number="88.2.3">
<h3 data-number="88.2.3" class="anchored" data-anchor-id="sec-pacf-reading"><span class="header-section-number">88.2.3</span> The partial auto-correlation function PACF (Reading)</h3>
<div id="def-pacf" class="theorem definition page-columns page-full">
<p><span class="theorem-title"><strong>Definition 88.3 (Partial Auto-correlation Function (PACF))</strong></span> Let <span class="math inline">{y_t}</span> be a zero-mean stationary process, and let</p>
<p><span id="eq-best-linear-predictor"><span class="math display">
\hat{y}_t^{h-1} = \beta_1 y_{t-1} + \beta_2 y_{t-2} + \ldots + \beta_{h-1} y_{t-(h-1)}
\tag{88.11}</span></span></p>
<p>be the best linear predictor of <span class="math inline">y_t</span> based on the previous <span class="math inline">h − 1</span> values <span class="math inline">\{y_{t−1}, \ldots , y_{t−h+1}\}</span>. The best linear predictor of <span class="math inline">y_t</span> based on the previous <span class="math inline">h − 1</span> values of the process is the linear predictor that minimizes</p>
<p><span id="eq-best-linear-predictor-minimization"><span class="math display">
E[(y_t − \hat{y}_y^{h-1})^2]
\tag{88.12}</span></span></p>
<div class="page-columns page-full"><p>The partial autocorrelation of this process at lag h, denoted by <span class="math inline">\phi(h, h)</span> is defined as: </p><div class="no-row-height column-margin column-container"><span class="">partial auto-correlation PAFC</span></div></div>
<p><span id="eq-partial-auto-correlation"><span class="math display">
\phi(h, h) = Corr(y_{t+h} − \hat{y}_{t+h}^{h-1}, y_t − \hat{y}_t^{h-1})
\tag{88.13}</span></span></p>
<p>for <span class="math inline">h \ge 2</span> and <span class="math inline">\phi(1, 1) = Corr(y_{t+1}, y_{t}) = \rho(1)</span>.</p>
</div>
<p>The partial autocorrelation function can also be computed via the Durbin-Levinson recursion for stationary processes as <span class="math inline">\phi(0, 0) = 0</span>,</p>
<p><span id="eq-durbin-levinson"><span class="math display">
\phi(n, n) = \frac{\rho(n) − \sum_{h=1}^{n-1} \phi(n − 1, h)\rho(n − h)}{1- \sum_{h=1}^{n-1}\phi(n − 1, h)\rho(h)}
\tag{88.14}</span></span></p>
<p>for <span class="math inline">n \ge 1</span>, and</p>
<p><span id="eq-durbin-levinson-2"><span class="math display">
\phi(n, h) = \phi(n − 1, h) − \phi(n, n)\phi(n − 1, n − h),
\tag{88.15}</span></span></p>
<p>for <span class="math inline">n \ge 2</span>, and <span class="math inline">h = 1, \ldots , (n − 1)</span>.</p>
<p>Note that the sample PACF can be obtained by substituting the sample autocorrelations and the sample auto-covariances in the Durbin-Levinson recursion.</p>
</section>
</section>
<section id="sec-differencing-and-smoothing" class="level2 page-columns page-full" data-number="88.3">
<h2 data-number="88.3" class="anchored" data-anchor-id="sec-differencing-and-smoothing"><span class="header-section-number">88.3</span> Differencing and smoothing (Reading)</h2>
<p>Differencing and smoothing are techniques used to remove trends and seasonality in time series data. They are covered in the <span class="citation" data-cites="prado2023time">(<a href="#ref-prado2023time" role="doc-biblioref">Prado, Ferreira, and West 2023, sec. 1.4</a>)</span>.</p>
<p>Many synthetic time series models are built under the assumption of stationarity. However, in the real world time series data often present non-stationary features such as <strong>trends</strong> or <strong>seasonality</strong>. These features render such a time series non-stationary, and therefore, not suitable for analysis using the tools and methods we have discussed so far. However practitioners can use techniques for detrending, deseasonalizing and smoothing that when applied to such observed data transforms it into a new time series that is consistent with the stationarity assumption.</p>
<p>We briefly discuss two methods that are commonly used in practice for detrending and smoothing.</p>
<section id="differencing" class="level3 page-columns page-full" data-number="88.3.1">
<h3 data-number="88.3.1" class="anchored" data-anchor-id="differencing"><span class="header-section-number">88.3.1</span> Differencing</h3>
<div class="page-columns page-full"><p><mark>Differencing, is a method which removes the trend from a time series data</mark>. The first difference of a time series is defined in terms of the difference operator, denoted as <span class="math inline">D</span>, that produces the transformation </p><div class="no-row-height column-margin column-container"><span class="">differencing operator <span class="math inline">D</span></span></div></div>
<p><span id="eq-first-difference-operator-definition"><span class="math display">
Dy_t \doteqdot y_t - y_{t-1}.
\tag{88.16}</span></span></p>
<p>Higher order differences are obtained by successively applying the operator <span class="math inline">D</span>. For example,</p>
<p><span id="eq-higher-order-difference-operator-definition"><span class="math display">
D^2y_t = D(Dy_t) = D(y_t - y_{t-1}) = y_t - 2y_{t-1} + y_{t-2}.
\tag{88.17}</span></span></p>
<div class="page-columns page-full"><p>Differencing can also be written in terms of the so called back-shift operator <span class="math inline">B</span>, with </p><div class="no-row-height column-margin column-container"><span class="">back-shift operator <span class="math inline">B</span></span></div></div>
<p><span id="eq-backshift-operator-definition"><span class="math display">
By_t \doteqdot y_{t-1},
\tag{88.18}</span></span></p>
<p>so that</p>
<p><span id="eq-first-difference-operator-via-back-shift-definition"><span class="math display">
Dy_t \doteqdot (1 - B) y_t
\tag{88.19}</span></span></p>
<p>and</p>
<p><span id="eq-higher-order-difference-operator-definition"><span class="math display">
D^dy_t \doteqdot (1 - B)^d y_t.
\tag{88.20}</span></span></p>
<p>this notation lets us write the differences in by referencing items backwards in time, which is often more intuitive and also useful, for example, when we will want to write the differencing operator in terms of a polynomial.</p>
</section>
<section id="smoothing" class="level3 page-columns page-full" data-number="88.3.2">
<h3 data-number="88.3.2" class="anchored" data-anchor-id="smoothing"><span class="header-section-number">88.3.2</span> Smoothing</h3>
<p><mark>Moving averages, which is commonly used to “smooth” a time series by removing certain features (e.g., seasonality) to highlight other features</mark> (e.g., trends).</p>
<div class="page-columns page-full"><p><mark>A moving average is a weighted average of the time series around a particular time</mark> <span class="math inline">t</span>. In general, if we have data <span class="math inline">y_{1:T}</span>, we could obtain a new time series such that </p><div class="no-row-height column-margin column-container"><span class="">moving average</span></div></div>
<p><span id="eq-moving-average"><span class="math display">
z_t = \sum_{j=-q}^{p} w_j y_{t+j} \qquad
\tag{88.21}</span></span></p>
<p>for <span class="math inline">t = (q + 1) : (T − p)</span>, with weights <span class="math inline">w_j \ge 0</span> and <span class="math inline">\sum^p_{j=−q} w_j = 1</span></p>
<p>We will frequently work with <em>moving averages</em> for which</p>
<p><span class="math display">
p = q \qquad \text{(centered)}
</span></p>
<p>and</p>
<p><span class="math display">
w_j = w_{−j} \forall j  \text{(symmetric)}
</span></p>
<p>Assume we have periodic data with period <span class="math inline">d</span>. Then, symmetric and centered moving averages can be used to remove such periodicity as follows:</p>
<ul>
<li>If <span class="math inline">d = 2q</span> :</li>
</ul>
<p><span id="eq-even-seasonal-moving-average"><span class="math display">
z_t =  \frac{1}{d} \left(\frac{1}{2} y_{t−q} + y_{t−q+1} + \ldots + y_{t+q−1} + \frac{1}{2} y_{t+q}\right )
\tag{88.22}</span></span></p>
<ul>
<li>if <span class="math inline">d = 2q + 1</span> :</li>
</ul>
<p><span id="eq-odd-seasonal-moving-average"><span class="math display">
z_t = \frac{1}{d} \left( y_{t−q} + y_{t−q+1} + \ldots + y_{t+q−1} + y_{t+q}\right )
\tag{88.23}</span></span></p>
<div id="exm-seasonal-moving-average" class="theorem example">
<p><span class="theorem-title"><strong>Example 88.1 (Seasonal Moving Average)</strong></span> To remove seasonality in monthly data (i.e., seasonality with a period of d = 12 months), we use a moving average with <span class="math inline">p = q = 6</span>, <span class="math inline">a_6 = a_{−6} = 1/24</span>, and <span class="math inline">a_j = a_{−j} = 1/12</span> for <span class="math inline">j = 0, \ldots , 5</span> , resulting in:</p>
<p><span id="eq-seasonal-moving-average"><span class="math display">
z_t = \frac{1}{24} y_{t−6} + \frac{1}{12}y_{t−5} + \ldots + \frac{1}{12}y_{t+5} + \frac{1}{24}y_{t+6}
\tag{88.24}</span></span></p>
</div>
</section>
</section>
<section id="sec-differencing-and-smoothing-examples" class="level2" data-number="88.4">
<h2 data-number="88.4" class="anchored" data-anchor-id="sec-differencing-and-smoothing-examples"><span class="header-section-number">88.4</span> ACF PACF Differencing and Smoothing Examples (Video)</h2>
<p>This video walks us through the code snippets in <a href="#lst-moving-averages-and-differencing" class="quarto-xref">Listing&nbsp;<span class="quarto-unresolved-ref">lst-moving-averages-and-differencing</span></a> and <a href="#lst-white-noise-simulation" class="quarto-xref">Listing&nbsp;<span class="quarto-unresolved-ref">lst-white-noise-simulation</span></a> below and provides examples of how to compute the ACF and PACF of a time series, how to use differencing to remove trends, and how to use moving averages to remove seasonality.</p>
<ul>
<li>Outline:
<ul>
<li>We begin by simulating data using the code in <a href="#sec-white-noise-simulation" class="quarto-xref"><span class="quarto-unresolved-ref">sec-white-noise-simulation</span></a></li>
<li>We simulates white noise data using the <code>rnorm(1:2000,mean=0,sd=1)</code> function in R</li>
<li>We plot the white noise data which we can see lacks a temporal structure.</li>
<li>We plot the ACF using the <code>acf</code> function in R:
<ul>
<li>we specify the number of lags using the <code>lag.max=20</code></li>
<li>we shows a confidence interval for the ACF values</li>
</ul></li>
<li>We plot the PACF using the <code>pacf</code> function in R</li>
<li>Next we define some time series objects in R using the <code>ts</code> function
<ul>
<li>we define and plot monthly data starting in January 1960</li>
<li>we define and plot yearly data with one observation per year starting in 1960</li>
<li>we define and plot yearly data with four observations per year starting in 1960</li>
</ul></li>
<li>We move on to smoothing and differencing in <a href="#sec-differencing-and-smoothing" class="quarto-xref"><span class="quarto-unresolved-ref">sec-differencing-and-smoothing</span></a></li>
<li>We load the CO2 dataset in R and plot it</li>
<li>we plot the ACF and PACF of the CO2 dataset</li>
<li>we use the <code>filter</code> function in R to remove the seasonal component of the CO2 dataset we plot the resulting time series highlighting the trend.</li>
<li>To remove the trend we use the <code>diff</code> function in R to take the first and second differences of the CO2 dataset
<ul>
<li>the <code>diff</code> function takes a parameter <code>differences</code> which specifies the number of differences to take</li>
</ul></li>
<li>we plot the resulting time series after taking the first and second differences</li>
<li>the ACF and PACF of the resulting time series are plotted, they look different, in that they no longer have the slow decay characteristic of time series with a trend.</li>
</ul></li>
</ul>
<p>The r-code for the examples is provided below.</p>
</section>
<section id="sec-differencing-and-smoothing-reading" class="level2" data-number="88.5">
<h2 data-number="88.5" class="anchored" data-anchor-id="sec-differencing-and-smoothing-reading"><span class="header-section-number">88.5</span> R code for Differencing and filtering via moving averages (reading)</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="lst-moving-averages-and-differencing"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="lst-moving-averages-and-differencing-1"><a href="#lst-moving-averages-and-differencing-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the CO2 dataset in R</span></span>
<span id="lst-moving-averages-and-differencing-2"><a href="#lst-moving-averages-and-differencing-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(co2) </span>
<span id="lst-moving-averages-and-differencing-3"><a href="#lst-moving-averages-and-differencing-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-moving-averages-and-differencing-4"><a href="#lst-moving-averages-and-differencing-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Take first differences to remove the trend </span></span>
<span id="lst-moving-averages-and-differencing-5"><a href="#lst-moving-averages-and-differencing-5" aria-hidden="true" tabindex="-1"></a>co2_1stdiff<span class="ot">=</span><span class="fu">diff</span>(co2,<span class="at">differences=</span><span class="dv">1</span>)</span>
<span id="lst-moving-averages-and-differencing-6"><a href="#lst-moving-averages-and-differencing-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-moving-averages-and-differencing-7"><a href="#lst-moving-averages-and-differencing-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter via moving averages to remove the seasonality </span></span>
<span id="lst-moving-averages-and-differencing-8"><a href="#lst-moving-averages-and-differencing-8" aria-hidden="true" tabindex="-1"></a>co2_ma<span class="ot">=</span><span class="fu">filter</span>(co2,<span class="at">filter=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">24</span>,<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">12</span>,<span class="dv">11</span>),<span class="dv">1</span><span class="sc">/</span><span class="dv">24</span>),<span class="at">sides=</span><span class="dv">2</span>)</span>
<span id="lst-moving-averages-and-differencing-9"><a href="#lst-moving-averages-and-differencing-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-moving-averages-and-differencing-10"><a href="#lst-moving-averages-and-differencing-10" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab=</span><span class="fl">1.2</span>,<span class="at">cex.main=</span><span class="fl">1.2</span>)</span>
<span id="lst-moving-averages-and-differencing-11"><a href="#lst-moving-averages-and-differencing-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(co2) <span class="co"># plot the original data </span></span>
<span id="lst-moving-averages-and-differencing-12"><a href="#lst-moving-averages-and-differencing-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(co2_1stdiff) <span class="co"># plot the first differences (removes trend, highlights seasonality)</span></span>
<span id="lst-moving-averages-and-differencing-13"><a href="#lst-moving-averages-and-differencing-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(co2_ma) <span class="co"># plot the filtered series via moving averages (removes the seasonality, highlights the trend)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-moving-averages-and-differencing" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-moving-averages-and-differencing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C4-L01_files/figure-html/fig-moving-averages-and-differencing-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;88.4: R code: for Differencing and filtering via moving averages"><img src="C4-L01_files/figure-html/fig-moving-averages-and-differencing-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-moving-averages-and-differencing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;88.4: R code: for Differencing and filtering via moving averages
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-white-noise-simulation" class="level2" data-number="88.6">
<h2 data-number="88.6" class="anchored" data-anchor-id="sec-white-noise-simulation"><span class="header-section-number">88.6</span> R Code: Simulate data from a white noise process (reading)</h2>
<div class="cell">
<div id="lst-white-noise-simulation" class="r cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-white-noise-simulation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;88.1: R Code: Simulate data from a white noise process
</figcaption>
<div aria-describedby="lst-white-noise-simulation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data with no temporal structure (white noise)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">200</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>t <span class="ot">=</span><span class="dv">1</span><span class="sc">:</span>T</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>y_white_noise<span class="ot">=</span><span class="fu">rnorm</span>(T, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">1</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a time series object in R: </span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume the data correspond to annual observations starting in January 1960 </span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">ts</span>(y_white_noise, <span class="at">start=</span><span class="fu">c</span>(<span class="dv">1960</span>), <span class="at">frequency=</span><span class="dv">1</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the simulated time series, their sample ACF and their sample PACF</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>, <span class="at">cex.main =</span> <span class="fl">1.3</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">ts</span>(y_white_noise, <span class="at">start=</span><span class="fu">c</span>(<span class="dv">1960</span>), <span class="at">frequency=</span><span class="dv">1</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt, <span class="at">type =</span> <span class="st">'l'</span>, <span class="at">col=</span><span class="st">'red'</span>, <span class="at">xlab =</span> <span class="st">'time (t)'</span>, <span class="at">ylab =</span> <span class="st">"Y(t)"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(yt, <span class="at">lag.max =</span> <span class="dv">20</span>, <span class="at">xlab =</span> <span class="st">"lag"</span>,</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">"Sample ACF"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(yt, <span class="at">lag.max =</span> <span class="dv">20</span>,<span class="at">xlab =</span> <span class="st">"lag"</span>,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Sample PACF"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</figure>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L01_files/figure-html/lst-white-noise-simulation-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="C4-L01_files/figure-html/lst-white-noise-simulation-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<section id="quiz-1-stationarity-acf-pacf-differencing-and-smoothing" class="level3" data-number="88.6.1">
<h3 data-number="88.6.1" class="anchored" data-anchor-id="quiz-1-stationarity-acf-pacf-differencing-and-smoothing"><span class="header-section-number">88.6.1</span> Quiz 1: Stationarity, ACF, PACF, Differencing, and Smoothing</h3>
<p>omitted per coursera requirements</p>
</section>
</section>
<section id="the-ar1-process-definition-and-properties" class="level2 page-columns page-full" data-number="88.7">
<h2 data-number="88.7" class="anchored" data-anchor-id="the-ar1-process-definition-and-properties"><span class="header-section-number">88.7</span> The AR(1) process: Definition and properties</h2>
<p>We will next introduce the autoregressive process of order one, or AR(1) process, which is a fundamental model in time series analysis. We will discuss the definition of the AR(1) process, its properties, and how to simulate data from an AR(1) process.</p>
<section id="the-ar1-process-video" class="level3 page-columns page-full" data-number="88.7.1">
<h3 data-number="88.7.1" class="anchored" data-anchor-id="the-ar1-process-video"><span class="header-section-number">88.7.1</span> The AR(1) process (video)</h3>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/m1_0031.png" class="lightbox" data-gallery="slides" title="AR(1)"><img src="images/m1_0031.png" class="img-fluid figure-img" width="200" alt="AR(1)"></a></p>
<figcaption>AR(1)</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/m1_0032.png" class="lightbox" data-gallery="slides" title="AR(1) properties"><img src="images/m1_0032.png" class="img-fluid figure-img" width="200" alt="AR(1) properties"></a></p>
<figcaption>AR(1) properties</figcaption>
</figure>
</div></div>
</section>
<section id="the-pacf-of-the-ar1-process-reading" class="level3" data-number="88.7.2">
<h3 data-number="88.7.2" class="anchored" data-anchor-id="the-pacf-of-the-ar1-process-reading"><span class="header-section-number">88.7.2</span> The PACF of the AR(1) process (reading)</h3>
<p>It is possible to show that the PACF of an autoregressive process of order one is zero after the first lag. We can use the Durbin-Levinson recursion to show this.</p>
<p>For lag <span class="math inline">n = 0</span> we have <span class="math inline">\phi(0, 0) = 0</span></p>
<p>For lag <span class="math inline">n = 1</span> we have:</p>
<p><span class="math display">
\phi(1, 1) =  \rho(1) = \phi
</span></p>
<p>For lag <span class="math inline">n = 2</span> we compute <span class="math inline">\phi(2, 2)</span> as:</p>
<p><span class="math display">
\phi(2, 2) = \frac{(\rho(2) − \phi(1, 1)\rho(1))}{ (1 − \phi(1, 1)\rho(1))} = \frac{\phi^2-\phi^2}{1- \phi^2}=0
</span></p>
<p>and we also obtain</p>
<p><span class="math display">
\phi(2, 1) = \phi(1, 1) − \phi(2, 2)\phi(1, 1) = \phi.
</span></p>
<p>For lag <span class="math inline">n = 3</span> we compute <span class="math inline">\phi(3, 3)</span> as</p>
<p><span class="math display">
\begin{aligned}
\phi(3, 3) &amp;= \frac{(\rho(3) − \sum_{h=1}^2 \phi(2, h)\rho(3 − h))}{1 − \sum_{h=1}^2 \phi(2, h)\rho(h)} \newline
&amp;= \frac{\phi^3 - \phi(2,1) \rho(2) - \phi(2,2) \rho(1)}{1 - \phi(2,1)\rho(1) - \phi(2,2)\rho(2)} \newline
&amp;= \frac{\phi^3 - \phi^3 - 0}{1 - \phi^2 } \newline
&amp;= 0
\end{aligned}
</span></p>
<p>and we also obtain</p>
<p><span class="math display">
\phi(3, 1) = \phi(2, 1) − \phi(3, 3)\phi(2, 2) = \phi
</span></p>
<p><span class="math display">
\phi(3, 2) = \phi(2, 2) − \phi(3, 3)\phi(2, 1) = 0
</span></p>
<p>We can prove by induction that in the case of an AR(1), for any lag <span class="math inline">n</span>,</p>
<p><span class="math inline">\phi(n, h) = 0, \phi(n, 1) = \phi</span> and <span class="math inline">\phi(n, h) = 0</span> for <span class="math inline">h \ge 2</span> and <span class="math inline">n \ge 2</span>.</p>
<p>Then, the PACF of an AR(1) is zero for any lag above 1 and the PACF coefficient at lag 1 is equal to the AR coefficient <span class="math inline">\phi</span></p>
</section>
<section id="simulate-data-from-an-ar1-process-video" class="level3" data-number="88.7.3">
<h3 data-number="88.7.3" class="anchored" data-anchor-id="simulate-data-from-an-ar1-process-video"><span class="header-section-number">88.7.3</span> Simulate data from an AR(1) process (video)</h3>
<p>This video walks through the code snippet below and provides examples of how to sample data from an AR(1) process and plot the ACF and PACF functions of the resulting time series.</p>
</section>
<section id="r-code-sample-data-from-ar1-processes-reading" class="level3" data-number="88.7.4">
<h3 data-number="88.7.4" class="anchored" data-anchor-id="r-code-sample-data-from-ar1-processes-reading"><span class="header-section-number">88.7.4</span> R code: Sample data from AR(1) processes (Reading)</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data from 2 ar(1) processes and plot their ACF and PACF functions</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data from an ar(1) with ar coefficient phi = 0.9 and variance 1</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="fl">1.0</span> <span class="co"># innovation variance</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co">#innovation stantard deviation</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>phi1<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>yt1<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi1), <span class="at">sd =</span> sd)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data from an ar(1) with ar coefficient phi = -0.9 and variance 1</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>phi2<span class="ot">=</span><span class="sc">-</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>yt2<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi2), <span class="at">sd =</span> sd)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt1,<span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==</span><span class="fl">0.9</span>))</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt2,<span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==-</span><span class="fl">0.9</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L01_files/figure-html/ar(1) sampling-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="C4-L01_files/figure-html/ar(1) sampling-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">2</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>lag.max<span class="ot">=</span><span class="dv">50</span> <span class="co"># max lag</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="do">## plot true ACFs for both processes</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>cov_0<span class="ot">=</span>sd<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>phi1<span class="sc">^</span><span class="dv">2</span>) <span class="co"># compute auto-covariance at h=0</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>cov_h<span class="ot">=</span>phi1<span class="sc">^</span>(<span class="dv">0</span><span class="sc">:</span>lag.max)<span class="sc">*</span>cov_0 <span class="co"># compute auto-covariance at h</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span>lag.max, cov_h<span class="sc">/</span>cov_0, <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">'h'</span>, <span class="at">col =</span> <span class="st">'red'</span>,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"true ACF"</span>, <span class="at">xlab =</span> <span class="st">"Lag"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==</span><span class="fl">0.9</span>))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>cov_0<span class="ot">=</span>sd<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>phi2<span class="sc">^</span><span class="dv">2</span>) <span class="co"># compute auto-covariance at h=0</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>cov_h<span class="ot">=</span>phi2<span class="sc">^</span>(<span class="dv">0</span><span class="sc">:</span>lag.max)<span class="sc">*</span>cov_0 <span class="co"># compute auto-covariance at h</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot autocorrelation function (ACF)</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span>lag.max, cov_h<span class="sc">/</span>cov_0, <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">'h'</span>, <span class="at">col =</span> <span class="st">'red'</span>,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"true ACF"</span>, <span class="at">xlab =</span> <span class="st">"Lag"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==-</span><span class="fl">0.9</span>))</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="do">## plot sample ACFs for both processes</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(yt1, <span class="at">lag.max =</span> lag.max, <span class="at">type =</span> <span class="st">"correlation"</span>, <span class="at">ylab =</span> <span class="st">"sample ACF"</span>,</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">main =</span> <span class="st">" "</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(yt2, <span class="at">lag.max =</span> lag.max, <span class="at">type =</span> <span class="st">"correlation"</span>, <span class="at">ylab =</span> <span class="st">"sample ACF"</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">main =</span> <span class="st">" "</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="do">## plot sample PACFs for both processes</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(yt1, <span class="at">lag.ma =</span> lag.max, <span class="at">ylab =</span> <span class="st">"sample PACF"</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(yt2, <span class="at">lag.ma =</span> lag.max, <span class="at">ylab =</span> <span class="st">"sample PACF"</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L01_files/figure-html/ar(1) sampling-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="C4-L01_files/figure-html/ar(1) sampling-2.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="quiz-2-the-ar1-definition-and-properties" class="level3" data-number="88.7.5">
<h3 data-number="88.7.5" class="anchored" data-anchor-id="quiz-2-the-ar1-definition-and-properties"><span class="header-section-number">88.7.5</span> Quiz 2: The AR(1) definition and properties</h3>
<p>Omitted per Coursera honor code requirements.</p>
</section>
</section>
<section id="the-ar1-processmaximum-likelihood-estimation-and-bayesian-inference" class="level1 page-columns page-full" data-number="89">
<h1 data-number="89"><span class="header-section-number">89</span> The AR(1) process:Maximum likelihood estimation and Bayesian inference</h1>
<section id="review-of-maximum-likelihood-and-bayesian-inference-in-regression" class="level2" data-number="89.1">
<h2 data-number="89.1" class="anchored" data-anchor-id="review-of-maximum-likelihood-and-bayesian-inference-in-regression"><span class="header-section-number">89.1</span> Review of maximum likelihood and Bayesian inference in regression</h2>
<section id="regression-models-maximum-likelihood-estimation" class="level3" data-number="89.1.1">
<h3 data-number="89.1.1" class="anchored" data-anchor-id="regression-models-maximum-likelihood-estimation"><span class="header-section-number">89.1.1</span> Regression Models: Maximum Likelihood Estimation</h3>
<p>Assume a regression model with the following structure: <span class="math display">
y_i = \beta_1x_{i,1} + \ldots + \beta_kx_{i,k} + \epsilon_i,
</span></p>
<p>for <span class="math inline">i = 1, \ldots, n</span> and <span class="math inline">\epsilon_i</span> independent random variables with <span class="math inline">\epsilon_i \sim N(0, v) \forall i</span>. This model can be written in matrix form as:</p>
<p><span class="math display">
y = X \beta + \epsilon, \epsilon \sim N (0, vI), \qquad
</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">y = (y_1, \ldots, y_n)′</span> is an n-dimensional vector of responses,</li>
<li><span class="math inline">X</span> is an n × k matrix containing the explanatory variables,</li>
<li><span class="math inline">\beta = (\beta_1, \ldots, \beta_k)′</span> is the k-dimensional vector of regression coefficients,</li>
<li><span class="math inline">\epsilon = (\epsilon_1, \ldots, \epsilon_n)′</span> is the n-dimensional vector of errors,</li>
<li><span class="math inline">I</span> is an n × n identity matrix.</li>
</ul>
<p>If <span class="math inline">X</span> is a full rank matrix with rank <span class="math inline">k</span> the maximum likelihood estimator for <span class="math inline">\beta</span>, denoted as <span class="math inline">\hat\beta_{MLE}</span> is given by:</p>
<p><span class="math display">
\hat\beta_{MLE} = (X′X)^{−1}X′y,
</span></p>
<p>and the MLE for v is given by</p>
<p><span class="math display">
\hat v_{MLE} = \frac{1}{n} (y − X \hat\beta_{MLE})′(y − X \hat\beta_{MLE})
</span></p>
<p><span class="math inline">\hat v_{MLE}</span> is not an unbiased estimator of v, therefore, the following unbiased estimator of v is typically used:</p>
<p><span class="math display">
s^2 = \frac{1}{n-k}(y − X \hat\beta_{MLE} )′(y − X \hat\beta_{MLE} )
</span></p>
</section>
<section id="regression-models-bayesian-inference" class="level3" data-number="89.1.2">
<h3 data-number="89.1.2" class="anchored" data-anchor-id="regression-models-bayesian-inference"><span class="header-section-number">89.1.2</span> Regression Models: Bayesian Inference</h3>
<p>Assume once again we have a model with the structure in (1), which results in a likelihood of the form</p>
<p><span class="math display">
\mathbb{P}r(y \mid \beta , v) = \frac{1}{(2\pi v)^{n/2}}\exp \left\{ -\frac{1}{2} (y − X\beta)′(y − X\beta) \right\}
</span></p>
<p>If a prior of the form</p>
<p><span class="math display">
\mathbb{P}r(\beta, v) \propto \frac{1}{v}
</span></p>
<p>is used, we obtain that the posterior distribution is given by</p>
<p><span class="math display">
\mathbb{P}r(\beta,v \mid y) \propto \frac{1}{v^{n/2+1}}\exp \left\{ -\frac{1}{2v} (y − X\beta)′(y − X\beta) \right\}
</span></p>
<p>In addition it can be shown that</p>
<ul>
<li><span class="math inline">(\beta\mid v, y) \sim N (\hat \beta_{MLE} , v(X′X)−1)</span></li>
<li><span class="math inline">(v\mid y) \sim \text{IG}((n − k)/2, d/2)</span> with</li>
</ul>
<p><span class="math display">
d = (y − X \hat \beta_{MLE} )′(y − \hat \beta_{MLE} )
</span></p>
<p>with <span class="math inline">k = dim(\beta)</span>.</p>
<p>Given that <span class="math inline">\mathbb{P}r(\beta, v \mid y) = \mathbb{P}r(\beta \mid v, y)p(v \mid y)</span> the equations above provide a way to directly sample from the posterior distribution of <span class="math inline">\beta</span> and <span class="math inline">v</span> by first sampling v from the inverse-gamma distribution above and then conditioning on this sampled value of v, sampling <span class="math inline">\beta</span> from the normal distribution above.</p>
</section>
</section>
<section id="maximum-likelihood-estimation-in-the-ar1-video" class="level2 page-columns page-full" data-number="89.2">
<h2 data-number="89.2" class="anchored" data-anchor-id="maximum-likelihood-estimation-in-the-ar1-video"><span class="header-section-number">89.2</span> Maximum likelihood estimation in the AR(1) (video)</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/m1_0041.png" class="lightbox" data-gallery="slides" title="slide 1"><img src="images/m1_0041.png" class="img-fluid figure-img" width="200" alt="slide 1"></a></p>
<figcaption>slide 1</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/m1_0042.png" class="lightbox" data-gallery="slides" title="slide 2"><img src="images/m1_0042.png" class="img-fluid figure-img" width="200" alt="slide 2"></a></p>
<figcaption>slide 2</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/m1_0043.png" class="lightbox" data-gallery="slides" title="slide 3"><img src="images/m1_0043.png" class="img-fluid figure-img" width="200" alt="slide 3"></a></p>
<figcaption>slide 3</figcaption>
</figure>
</div></div>

</section>
<section id="r-code-mle-for-the-ar1-examples-reading" class="level2" data-number="89.3">
<h2 data-number="89.3" class="anchored" data-anchor-id="r-code-mle-for-the-ar1-examples-reading"><span class="header-section-number">89.3</span> R code: MLE for the AR(1), examples (reading)</h2>
<p>The following code allows you to compute the MLE of the AR coefficient <span class="math inline">\psi</span>, the unbiased estimator of <span class="math inline">v</span>, <span class="math inline">s^2</span> , and the MLE of v based on a dataset simulated from an AR(1) process and using the conditional likelihood.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Case 1: Conditional likelihood</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">2</span><span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># design matrix</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span><span class="fu">as.numeric</span>((<span class="fu">t</span>(X)<span class="sc">%*%</span>y)<span class="sc">/</span><span class="fu">sum</span>(X<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># MLE for phi</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> phi_MLE<span class="sc">*</span>X)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">1</span>) <span class="co"># Unbiased estimate for v </span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>v_MLE<span class="ot">=</span>s2<span class="sc">*</span>(<span class="fu">length</span>(y)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>(<span class="fu">length</span>(y)) <span class="co"># MLE for v</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of conditional likelihood for phi: "</span>, phi_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MLE for the variance v: "</span>, v_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate s2 for the variance v: "</span>, s2, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
 MLE of conditional likelihood for phi:  0.9261423 
 MLE for the variance v:  1.048 
 Estimate s2 for the variance v:  1.050104 </code></pre>
</div>
</div>
<p>This code allows you to compute estimates of the AR(1) coefficient and the variance using the <code>arima</code> function in R. The first case uses the conditional sum of squares, the second and third cases use the full likelihood with different starting points for the numerical optimization required to compute the MLE with the full likelihood.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtaining parameter estimates using the arima function in R</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Using conditional sum of squares, equivalent to conditional likelihood </span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>arima_CSS<span class="ot">=</span><span class="fu">arima</span>(yt,<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">method=</span><span class="st">"CSS"</span>,<span class="at">n.cond=</span><span class="dv">1</span>,<span class="at">include.mean=</span><span class="cn">FALSE</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AR estimates with conditional sum of squares (CSS) for phi and v:"</span>, arima_CSS<span class="sc">$</span>coef,arima_CSS<span class="sc">$</span>sigma2,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>AR estimates with conditional sum of squares (CSS) for phi and v: 0.9261423 1.048 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Uses ML with full likelihood </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>arima_ML<span class="ot">=</span><span class="fu">arima</span>(yt,<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">method=</span><span class="st">"ML"</span>,<span class="at">include.mean=</span><span class="cn">FALSE</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AR estimates with full likelihood for phi and v:"</span>, arima_ML<span class="sc">$</span>coef,arima_ML<span class="sc">$</span>sigma2,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>AR estimates with full likelihood for phi and v: 0.9265251 1.048434 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Default: uses conditional sum of squares to find the starting point for ML and </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co">#         then uses ML </span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>arima_CSS_ML<span class="ot">=</span><span class="fu">arima</span>(yt,<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">method=</span><span class="st">"CSS-ML"</span>,<span class="at">n.cond=</span><span class="dv">1</span>,<span class="at">include.mean=</span><span class="cn">FALSE</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AR estimates with CSS to find starting point for ML for phi and v:"</span>, </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>arima_CSS_ML<span class="sc">$</span>coef,arima_CSS_ML<span class="sc">$</span>sigma2,<span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>AR estimates with CSS to find starting point for ML for phi and v: 0.9265252 1.048434 </code></pre>
</div>
</div>
<p>This code shows you how to compute the MLE for <span class="math inline">\psi</span> using the full likelihood and the function optimize in R.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="do">## MLE, full likelihood AR(1) with v=1 assumed known </span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># log likelihood function</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="cf">function</span>(phi, yt){</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.5</span><span class="sc">*</span>(<span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>phi<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span> <span class="fu">sum</span>((yt[<span class="dv">2</span><span class="sc">:</span>T] <span class="sc">-</span> phi<span class="sc">*</span>yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)])<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span> yt[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>phi<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a built-in optimization method to obtain maximum likelihood estimates</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span><span class="fu">optimize</span>(log_p, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">tol =</span> <span class="fl">0.0001</span>, <span class="at">maximum =</span> <span class="cn">TRUE</span>, <span class="at">yt =</span> yt)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of full likelihood for phi: "</span>, result<span class="sc">$</span>maximum)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
 MLE of full likelihood for phi:  0.9265928</code></pre>
</div>
</div>
</section>
<section id="bayesian-inference-in-the-ar1" class="level2 page-columns page-full" data-number="89.4">
<h2 data-number="89.4" class="anchored" data-anchor-id="bayesian-inference-in-the-ar1"><span class="header-section-number">89.4</span> Bayesian inference in the AR(1)</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/m1_0051.png" class="lightbox" data-gallery="slides" title="slide 1"><img src="images/m1_0051.png" class="img-fluid figure-img" width="200" alt="slide 1"></a></p>
<figcaption>slide 1</figcaption>
</figure>
</div></div></section>
<section id="bayesian-inference-in-the-ar1-conditional-likelihood-example-video" class="level2" data-number="89.5">
<h2 data-number="89.5" class="anchored" data-anchor-id="bayesian-inference-in-the-ar1-conditional-likelihood-example-video"><span class="header-section-number">89.5</span> Bayesian inference in the AR(1): Conditional likelihood example (video)</h2>
<p>This video walks through the code snippet below and provides examples of how to sample from the posterior distribution of the AR coefficient <span class="math inline">\psi</span> and the variance <span class="math inline">v</span> using the conditional likelihood and a reference prior.</p>
</section>
<section id="r-code-ar1-bayesian-inference-conditional-likelihood-example-reading" class="level2" data-number="89.6">
<h2 data-number="89.6" class="anchored" data-anchor-id="r-code-ar1-bayesian-inference-conditional-likelihood-example-reading"><span class="header-section-number">89.6</span> R Code: AR(1) Bayesian inference, conditional likelihood example (reading)</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="do">#####             MLE for AR(1)               ######</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">200</span> <span class="co"># number of time points</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) <span class="co"># sample stationary AR(1) process</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">2</span><span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># design matrix</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span><span class="fu">as.numeric</span>((<span class="fu">t</span>(X)<span class="sc">%*%</span>y)<span class="sc">/</span><span class="fu">sum</span>(X<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># MLE for phi</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> phi_MLE<span class="sc">*</span>X)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">1</span>) <span class="co"># Unbiased estimate for v</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>v_MLE<span class="ot">=</span>s2<span class="sc">*</span>(<span class="fu">length</span>(y)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>(<span class="fu">length</span>(y)) <span class="co"># MLE for v </span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(phi_MLE,s2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9178472 1.0491054</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="do">######     Posterior inference, AR(1)               </span><span class="al">###</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="do">######     Conditional Likelihood + Reference Prior </span><span class="al">###</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="do">######     Direct sampling                          </span><span class="al">###</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">3000</span>   <span class="co"># posterior sample size</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample posterior distribution of v from inverse gamma distribution</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span>)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((yt[<span class="dv">2</span><span class="sc">:</span>T] <span class="sc">-</span> phi_MLE<span class="sc">*</span>yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)])<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample posterior distribution of phi from normal distribution</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,n_sample)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>phi_sample[i]<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> phi_MLE, <span class="at">sd=</span><span class="fu">sqrt</span>(v_sample[i]<span class="sc">/</span><span class="fu">sum</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">^</span><span class="dv">2</span>)))}</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="do">## plot histogram of posterior samples of phi and v</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(phi_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(phi), </span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>phi),<span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">1.05</span>), <span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> phi, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(v_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(v), <span class="at">col=</span><span class="st">'lightblue'</span>, <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>v))</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> sd, <span class="at">col =</span> <span class="st">'red'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L01_files/figure-html/AR(1) inference, conditional likelihood example-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="C4-L01_files/figure-html/AR(1) inference, conditional likelihood example-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="quiz---mle-and-bayesian-inference-in-the-ar1" class="level2" data-number="89.7">
<h2 data-number="89.7" class="anchored" data-anchor-id="quiz---mle-and-bayesian-inference-in-the-ar1"><span class="header-section-number">89.7</span> Quiz - MLE and Bayesian inference in the AR(1)</h2>
<p>Omitted per Coursera honor code</p>
</section>
<section id="practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1" class="level2" data-number="89.8">
<h2 data-number="89.8" class="anchored" data-anchor-id="practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1"><span class="header-section-number">89.8</span> Practice Graded Assignment: MLE and Bayesian inference in the AR(1)</h2>
<p>This peer-reviewed activity is highly recommended. It does not figure into your grade for this course, but it does provide you with the opportunity to apply what you’ve learned in R and prepare you for your data analysis project in week 5.</p>
<ol type="1">
<li>Consider the R code below: MLE for the AR(1)</li>
</ol>
<div class="cell">
<div id="lst-ar-1-mle" class="r cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-ar-1-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;89.1: R Code: MLE for the AR(1) process, conditional likelihood example
</figcaption>
<div aria-describedby="lst-ar-1-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="do">#####             MLE for AR(1)               ######</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Case 1: Conditional likelihood</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">2</span><span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># design matrix</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span><span class="fu">as.numeric</span>((<span class="fu">t</span>(X)<span class="sc">%*%</span>y)<span class="sc">/</span><span class="fu">sum</span>(X<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># MLE for phi</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> phi_MLE<span class="sc">*</span>X)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">1</span>) <span class="co"># Unbiased estimate for v </span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>v_MLE<span class="ot">=</span>s2<span class="sc">*</span>(<span class="fu">length</span>(y)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>(<span class="fu">length</span>(y)) <span class="co"># MLE for v</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of conditional likelihood for phi: "</span>, phi_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MLE for the variance v: "</span>, v_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate s2 for the variance v: "</span>, s2, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</figure>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 MLE of conditional likelihood for phi:  0.9048951 
 MLE for the variance v:  1.084559 
 Estimate s2 for the variance v:  1.086737 </code></pre>
</div>
</div>
<p>Modify the code above to sample 800 observations from an AR(1) with AR coefficient <span class="math inline">\psi = -0.8</span> and variance <span class="math inline">v = 2</span>. Plot your simulated data. Obtain the MLE for <span class="math inline">\psi</span> based on the conditional likelihood and the unbiased estimate <span class="math inline">s^2</span> for the variance <span class="math inline">v</span>.</p>
<ol start="2" type="1">
<li>Consider the R code below: AR(1) Bayesian inference, conditional likelihood</li>
</ol>
<div class="cell">
<div id="lst-ar-1-inference" class="r cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-ar-1-inference-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;89.2: R Code: AR(1) Bayesian inference, conditional likelihood example
</figcaption>
<div aria-describedby="lst-ar-1-inference-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="do">######     Posterior inference, AR(1)               </span><span class="al">###</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="do">######     Conditional Likelihood + Reference Prior </span><span class="al">###</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="do">######     Direct sampling                          </span><span class="al">###</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">3000</span>   <span class="co"># posterior sample size</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample posterior distribution of v from inverse gamma distribution</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span>)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((yt[<span class="dv">2</span><span class="sc">:</span>T] <span class="sc">-</span> phi_MLE<span class="sc">*</span>yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)])<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample posterior distribution of phi from normal distribution</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,n_sample)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>phi_sample[i]<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> phi_MLE, <span class="at">sd=</span><span class="fu">sqrt</span>(v_sample[i]<span class="sc">/</span><span class="fu">sum</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">^</span><span class="dv">2</span>)))}</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="do">## plot histogram of posterior samples of phi and v</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(phi_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(phi), </span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>phi),<span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">1.05</span>), <span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> phi, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(v_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(v), <span class="at">col=</span><span class="st">'lightblue'</span>, <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>v))</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> sd, <span class="at">col =</span> <span class="st">'red'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</figure>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L01_files/figure-html/lst-ar-1-inference-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="C4-L01_files/figure-html/lst-ar-1-inference-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>Using your simulated data from part 1 modify the code above to summarize your posterior inference for <span class="math inline">\psi</span> and <span class="math inline">v</span> based on 5000 samples from the joint posterior distribution of <span class="math inline">\psi</span> and <span class="math inline">v</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Grading Criteria
</div>
</div>
<div class="callout-body-container callout-body">
<p>The responses should follow the same template as the sample code provided above but you will submit your code lines in plain text. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect that :</p>
<ol type="1">
<li>you generate 800 time points from the AR(1) rather than 500 and plot your simulated data.</li>
<li>your simulated data is from an AR(1) with AR coefficients <span class="math inline">\psi = -0.8</span> and variance <span class="math inline">v = 2</span> rather than AR(1) with AR coefficient <span class="math inline">\psi = 0.9</span> and variance <span class="math inline">v = 1</span> and</li>
<li>you obtain 5000 rather than 3000 samples from the posterior distribution from the new simulated process.</li>
</ol>
</div>
</div>
<section id="bayesian-inference-in-the-ar1-full-likelihood-example-reading" class="level3" data-number="89.8.1">
<h3 data-number="89.8.1" class="anchored" data-anchor-id="bayesian-inference-in-the-ar1-full-likelihood-example-reading"><span class="header-section-number">89.8.1</span> Bayesian Inference in the AR(1), : full likelihood example (reading)</h3>
<p>We consider a prior distribution that assumes that <span class="math inline">\phi</span> and <span class="math inline">v</span> are independent:</p>
<p><span class="math display">
\mathbb{P}r(v) \propto \frac{1}{v},
</span></p>
<p><span class="math display">
\mathbb{P}r(\phi) = \frac{1}{2}, \quad \text{for } \phi \in (-1, 1),
</span></p>
<p>i.e., we assume a Uniform prior for <span class="math inline">\phi \in (-1, 1)</span>. Combining this prior with the full likelihood in the AR(1) case, we obtain the following posterior density:</p>
<p><span class="math display">
\mathbb{P}r(\phi, v \mid y_{1:T}) \propto \frac{(1 - \phi^2)^{1/2} }{v^{T/2 + 1}} \exp\left(-\frac{Q^*(\phi)}{2v}\right), \quad -1 &lt; \phi &lt; 1,
</span></p>
<p>with</p>
<p><span class="math display">
Q^*(\phi) = y_1^2(1 - \phi^2) + \sum_{t=2}^{T} (y_t - \phi y_{t-1})^2.
</span></p>
<p>It is not possible to get a closed-form expression for this posterior or to perform direct simulation. Therefore, we use simulation-based Markov Chain Monte Carlo (MCMC) methods to obtain samples from the posterior distribution.</p>
</section>
<section id="transformation-of-phi" class="level3" data-number="89.8.2">
<h3 data-number="89.8.2" class="anchored" data-anchor-id="transformation-of-phi"><span class="header-section-number">89.8.2</span> Transformation of <span class="math inline">\phi</span></h3>
<p>We first consider the following transformation on <span class="math inline">\phi</span>:</p>
<p><span class="math display">
\eta = \log\left(\frac{1 - \phi}{\phi + 1}\right),
</span></p>
<p>so that <span class="math inline">\eta \in (-\infty, \infty)</span>. The inverse transformation on <span class="math inline">\eta</span> is:</p>
<p><span class="math display">
\phi = \frac{1 - \exp(\eta)}{1 + \exp(\eta)}.
</span></p>
<p>Writing down the posterior density for <span class="math inline">\eta</span> and <span class="math inline">v</span>, we obtain</p>
<p><span class="math display">
\mathbb{P}r(\eta, v \mid y_{1:T}) \propto\frac{ (1 - \phi^2)^{1/2} }{v^{T/2 + 1}} \exp\left(-\frac{Q^*(\phi)}{2v}\right) \cdot \frac{2 \exp(\eta)}{(1 + \exp(\eta))^2},
</span></p>
<p>with <span class="math inline">\phi</span> written as a function of <span class="math inline">\eta</span>. We proceed to obtain samples from this posterior distribution using the MCMC algorithm outlined below. Once we have obtained <span class="math inline">M</span> samples from <span class="math inline">\eta</span> and <span class="math inline">v</span> after convergence, we can use the inverse transformation above to obtain posterior samples for <span class="math inline">\phi</span>.</p>
</section>
<section id="mcmc-algorithm-bayesian-inference-for-ar1-full-likelihood" class="level3" data-number="89.8.3">
<h3 data-number="89.8.3" class="anchored" data-anchor-id="mcmc-algorithm-bayesian-inference-for-ar1-full-likelihood"><span class="header-section-number">89.8.3</span> MCMC Algorithm: Bayesian Inference for AR(1), Full Likelihood</h3>
<p><strong>Algorithm</strong>:</p>
<ol type="1">
<li>Initialize <span class="math inline">\eta^{(0)}</span> and <span class="math inline">\beta^{(0)}</span>.</li>
<li>For <span class="math inline">m</span> in <span class="math inline">1:M</span> do:
<ul>
<li>Sample <span class="math inline">v^{(m)} \sim \text{IG}\left(\frac{T}{2}, \frac{Q^*(\phi^{(m-1)})}{2}\right)</span>.</li>
<li>Sample <span class="math inline">\eta^{(m)}</span> using Metropolis-Hastings:
<ol type="1">
<li>Sample <span class="math inline">\eta^* \sim N(\eta^{(m-1)}, c)</span>, where <span class="math inline">c</span> is a tuning parameter.</li>
<li>Compute the importance ratio:</li>
</ol></li>
</ul></li>
</ol>
<p><span class="math display">
        r = \frac{p(\eta^*, v^{(m)} \mid y_{1:T})}{p(\eta^{(m-1)}, v^{(m)} \mid y_{1:T})}.
</span></p>
<ol start="3" type="1">
<li>Set:</li>
</ol>
<p><span class="math display">
        \eta^{(m)} =
        \begin{cases}
        \eta^* &amp; \text{with probability } \min(r, 1), \\
        \eta^{(m-1)} &amp; \text{otherwise}.
        \end{cases}
</span></p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-prado2023time" class="csl-entry" role="listitem">
Prado, R., M. A. R. Ferreira, and M. West. 2023. <em>Time Series: Modeling, Computation, and Inference</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. CRC Press. <a href="https://books.google.co.il/books?id=pZ6lzgEACAAJ">https://books.google.co.il/books?id=pZ6lzgEACAAJ</a>.
</div>
<div id="ref-BibEntry2024Sep" class="csl-entry" role="listitem">
Weckerle, Melissa. 2022. <span>“<span class="nocase">Statistics professor wins prestigious professional statistics society award <span></span> Baskin School of Engineering</span>.”</span> <a href="https://engineering.ucsc.edu/news/statistics-professor-wins-zellner-medal" class="uri">https://engineering.ucsc.edu/news/statistics-professor-wins-zellner-medal</a>.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C4-L00.html" class="pagination-link" aria-label="Week 0: Introductions to time series analysis and the AR(1) process">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Week 0: Introductions to time series analysis and the AR(1) process</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C4-L02.html" class="pagination-link" aria-label="The AR(p) process">
        <span class="nav-page-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">The AR(p) process</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb20" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2024-10-23</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Introductions to Time Series analysis &amp; the AR(1) process"</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> Time Series Analysis</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "This lesson we will define the AR(1) process, Stationarity, ACF, PACF, differencing, smoothing"</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> </span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - coursera </span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - notes</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - bayesian statistics</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - autoregressive models</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - time series</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> </span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - time series</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - stationarity</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co">  - strong stationarity</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co">  - weak stationarity</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co">  - lag</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co">  - autocorrelation function (ACF)</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co">  - partial autocorrelation function (PACF)</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co">  - smoothing</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co">  - trend</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co">  - seasonality</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="co">  - differencing operator</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="co">  - back shift operator</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="co">  - moving average</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="co">  - AR(1) process</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="co">  - Yule-Walker equations</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="co">  - Durbin-Levinson recursion</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="co">  - R code</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> course-banner.png</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a><span class="an">fig-caption:</span><span class="co"> Notes about ... Bayesian Statistics</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner:</span><span class="co"> images/banner_deep.jpg</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="co">#bibliography: bibliography.bib</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a><span class="co">    html: </span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="co">        code-fold: true</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a><span class="co">        css: styles.css</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## Learning Objectives</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[x]</span> ~~List the goals of the course~~</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[x]</span> identify the basics of the R environment.</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[x]</span> Explain **stationary** time series processes</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[ ]</span> Define **auto-correlation function** (ACF) and **partial auto-correlation function** (PACF) and use R to plot the sample ACF and sample PACF of a time series</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[x]</span> Explain the concepts of differencing and smoothing via moving averages to remove/highlight trends and seasonal components in a time series</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[ ]</span> Define the zero-mean autoregressive process of order one or AR(1) and use R to obtain samples from this type of process</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[ ]</span> Perform maximum likelihood estimation for the full and conditional likelihood in an AR(1)</span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[ ]</span> Perform Bayesian inference for the AR(1) under the conditional likelihood and the reference prior</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### Welcome to Bayesian Statistics: Time Series</span></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[x]</span> Obligatory introduction to the course and the instructors.</span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">Raquel Prado</span><span class="co">]()</span> is a professor of statistics in the <span class="co">[</span><span class="ot">Baskin School of Engineering</span><span class="co">](https://engineering.ucsc.edu/)</span> at the University of California, Santa Cruz. She was the recipient 2022 <span class="co">[</span><span class="ot">Zellner Medal</span><span class="co">](https://bayesian.org/project/zellner-medal/)</span>, see @BibEntry2024Sep.</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a><span class="fu">### Introduction to R</span></span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="va">[x]</span> <span class="co">[</span><span class="ot">Introduction to R</span><span class="co">](https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf)</span></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a><span class="fu">## Stationarity the ACF and the PACF (Video) {#sec-stationarity-acf-pacf}</span></span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>Before diving into the material here is a brief overview of the notations for timer series.</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a>::: {#tip-notation .callout-tip}</span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Notation</span></span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$<span class="sc">\{</span>y_t<span class="sc">\}</span>$ - the time series process, where each $y_t$ is a univariate random variable and t are the time points that are equally spaced. </span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$y_{1:T}$ or $y_1, y_2, \ldots, y_T$ - the observed data.</span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>You will see the use of ' to denote the transpose of a matrix,</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>and the use of $\sim$ to denote a distribution.</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>under tildes $\utilde{y}$ are used to denote estimates of the true values $y$.</span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>E matrix of eigenvalues</span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\Lambda = diagonal(\alpha_1, \alpha_2, \ldots , \alpha_p)$ is a diagonal matrix with the eigenvalues of $\Sigma$ on the diagonal.</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$J_p(1)$ = a p by p <span class="co">[</span><span class="ot">Jordan form</span><span class="co">](https://en.wikipedia.org/wiki/Jordan_normal_form)</span> matrix with 1 on the super-diagonal</span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>also see <span class="co">[</span><span class="ot">@prado2023time pp. 2-3</span><span class="co">]</span></span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stationarity (video)</span></span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a><span class="al">![strong and weak stationarity](images/m1_0001.png)</span>{#fig-slide-stationarity-1 .column-margin  group="slides" width="200px"}</span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a>Stationarity c.f. <span class="co">[</span><span class="ot">@prado2023time §1.2</span><span class="co">]</span> is a fundamental concept in time series analysis. </span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a><span class="fu">## TL;DR -- Stationarity</span></span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-101"><a href="#cb20-101" aria-hidden="true" tabindex="-1"></a>Stationarity</span>
<span id="cb20-102"><a href="#cb20-102" aria-hidden="true" tabindex="-1"></a>:   <span class="co">[</span><span class="ot">Stationarity</span><span class="co">]</span>{.column-margin}</span>
<span id="cb20-103"><a href="#cb20-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-104"><a href="#cb20-104" aria-hidden="true" tabindex="-1"></a>: A time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.</span>
<span id="cb20-105"><a href="#cb20-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-106"><a href="#cb20-106" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We make this definition more formal in the definitions of strong and weak stationarity below.</span>
<span id="cb20-107"><a href="#cb20-107" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-108"><a href="#cb20-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-109"><a href="#cb20-109" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Stationarity is a key concept in time series analysis. A time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.</span><span class="co">]</span>{.mark}</span>
<span id="cb20-110"><a href="#cb20-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-111"><a href="#cb20-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-112"><a href="#cb20-112" aria-hidden="true" tabindex="-1"></a>::: {#def-strong-stationarity}</span>
<span id="cb20-113"><a href="#cb20-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-114"><a href="#cb20-114" aria-hidden="true" tabindex="-1"></a><span class="fu">## Strong Stationarity</span></span>
<span id="cb20-115"><a href="#cb20-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-116"><a href="#cb20-116" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Strong Stationarity</span><span class="co">]</span>{.column-margin} Let $y_t$ be a time series. We say that $y_t$ is *stationary* if the following conditions hold:</span>
<span id="cb20-117"><a href="#cb20-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-118"><a href="#cb20-118" aria-hidden="true" tabindex="-1"></a>Let $<span class="sc">\{</span>y_t<span class="sc">\}</span> \quad \forall n&gt;0$ be a time series and $h &gt; 0$ be a lag. If for any subsequence the distribution of $y_t, y_{t+1}, \ldots, y_{t+n}$ is the same as the distribution of $y_{t+h}, y_{t+h+1}, \ldots, y_{t+h+n}$ we call the series strongly stationary.</span>
<span id="cb20-119"><a href="#cb20-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-120"><a href="#cb20-120" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-121"><a href="#cb20-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-122"><a href="#cb20-122" aria-hidden="true" tabindex="-1"></a>As it's difficult to verify strong stationarity in practice, we will often use the following weaker notion of stationarity.</span>
<span id="cb20-123"><a href="#cb20-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-124"><a href="#cb20-124" aria-hidden="true" tabindex="-1"></a>::: {#def-weak-stationarity}</span>
<span id="cb20-125"><a href="#cb20-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-126"><a href="#cb20-126" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weak Stationarity</span></span>
<span id="cb20-127"><a href="#cb20-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-128"><a href="#cb20-128" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Weak Stationarity</span><span class="co">]</span>{.column-margin} <span class="co">[</span><span class="ot">Second-order Stationarity</span><span class="co">]</span>{.column-margin} The mean, variance, and auto-covariance are constant over time.</span>
<span id="cb20-129"><a href="#cb20-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-130"><a href="#cb20-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-131"><a href="#cb20-131" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb20-132"><a href="#cb20-132" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">y_t</span><span class="co">]</span> &amp;= \mu \quad \forall t <span class="sc">\\</span></span>
<span id="cb20-133"><a href="#cb20-133" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">y_t</span><span class="co">]</span> &amp;= \nu =\sigma^2 \quad \forall t <span class="sc">\\</span></span>
<span id="cb20-134"><a href="#cb20-134" aria-hidden="true" tabindex="-1"></a>\mathbb{C}ov<span class="co">[</span><span class="ot">y_t , y_s </span><span class="co">]</span> &amp;= γ(t − s)</span>
<span id="cb20-135"><a href="#cb20-135" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb20-136"><a href="#cb20-136" aria-hidden="true" tabindex="-1"></a>$$ {#eq-weak-stationarity}</span>
<span id="cb20-137"><a href="#cb20-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-138"><a href="#cb20-138" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-139"><a href="#cb20-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-140"><a href="#cb20-140" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Strong stationarity $\implies$ Weak stationarity, but</span>
<span id="cb20-141"><a href="#cb20-141" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The converse is not true.</span>
<span id="cb20-142"><a href="#cb20-142" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In this course when we deal with a Gaussian process, our typical use case, they are equivalent!</span>
<span id="cb20-143"><a href="#cb20-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-144"><a href="#cb20-144" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution}</span>
<span id="cb20-145"><a href="#cb20-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-146"><a href="#cb20-146" aria-hidden="true" tabindex="-1"></a><span class="fu">## Check your understanding</span></span>
<span id="cb20-147"><a href="#cb20-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-148"><a href="#cb20-148" aria-hidden="true" tabindex="-1"></a>Q. Can you explain with an example when a time series is weakly stationary but not strongly stationary?</span>
<span id="cb20-149"><a href="#cb20-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-150"><a href="#cb20-150" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-151"><a href="#cb20-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-152"><a href="#cb20-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-153"><a href="#cb20-153" aria-hidden="true" tabindex="-1"></a><span class="fu">### The auto-correlation function ACF (video) {#sec-acf}</span></span>
<span id="cb20-154"><a href="#cb20-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-155"><a href="#cb20-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-156"><a href="#cb20-156" aria-hidden="true" tabindex="-1"></a><span class="al">![The auto-correlation function ACF](images/m1_0011.png)</span>{#fig-slide-afc-1 .column-margin  group="slides" width="200px"}</span>
<span id="cb20-157"><a href="#cb20-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-158"><a href="#cb20-158" aria-hidden="true" tabindex="-1"></a>\index{autocorrelation function}</span>
<span id="cb20-159"><a href="#cb20-159" aria-hidden="true" tabindex="-1"></a>\index{ACF|\see{autocorrelation function}}</span>
<span id="cb20-160"><a href="#cb20-160" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">The autocorrelation is simply how correlated a time series is with itself at different lags</span><span class="co">]</span>{.mark}.</span>
<span id="cb20-161"><a href="#cb20-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-162"><a href="#cb20-162" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Correlation in general is defined in terms of covariance of two variables.</span>
<span id="cb20-163"><a href="#cb20-163" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The covariance is a measure of the joint variability of two random variables. </span>
<span id="cb20-164"><a href="#cb20-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-165"><a href="#cb20-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-166"><a href="#cb20-166" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb20-167"><a href="#cb20-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-168"><a href="#cb20-168" aria-hidden="true" tabindex="-1"></a>Recall that the Covariance between two random variables $y_t$ and $y_s$ is defined as:</span>
<span id="cb20-169"><a href="#cb20-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-170"><a href="#cb20-170" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-171"><a href="#cb20-171" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb20-172"><a href="#cb20-172" aria-hidden="true" tabindex="-1"></a>\mathbb{C}ov<span class="co">[</span><span class="ot">y_t, y_s</span><span class="co">]</span> &amp;= \mathbb{E}<span class="co">[</span><span class="ot">(y_t-\mathbb{E}[y_t])(y_s-\mathbb{E}[y_s])</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb20-173"><a href="#cb20-173" aria-hidden="true" tabindex="-1"></a>              &amp;= \mathbb{E}<span class="co">[</span><span class="ot">(y_t-\mu_t)(y_s-\mu_s)</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb20-174"><a href="#cb20-174" aria-hidden="true" tabindex="-1"></a>              &amp;= E<span class="co">[</span><span class="ot">y_t y_s</span><span class="co">]</span> - \mu_t \times \mu_s</span>
<span id="cb20-175"><a href="#cb20-175" aria-hidden="true" tabindex="-1"></a>\end{aligned} \qquad</span>
<span id="cb20-176"><a href="#cb20-176" aria-hidden="true" tabindex="-1"></a>$$ {#eq-covariance}</span>
<span id="cb20-177"><a href="#cb20-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-178"><a href="#cb20-178" aria-hidden="true" tabindex="-1"></a>We get the second line by substituting $\mu_t = \mathbb{E}(y_t)$ and $\mu_s = \mathbb{E}(y_s)$ using the definition of the mean of a RV.</span>
<span id="cb20-179"><a href="#cb20-179" aria-hidden="true" tabindex="-1"></a>the third line is by multiplying out and using the linearity of the expectation operator.</span>
<span id="cb20-180"><a href="#cb20-180" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-181"><a href="#cb20-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-182"><a href="#cb20-182" aria-hidden="true" tabindex="-1"></a>::: {#tip-acf .callout-tip }</span>
<span id="cb20-183"><a href="#cb20-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-184"><a href="#cb20-184" aria-hidden="true" tabindex="-1"></a><span class="fu">### AFC notation {#sec-afc-notation}</span></span>
<span id="cb20-185"><a href="#cb20-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-186"><a href="#cb20-186" aria-hidden="true" tabindex="-1"></a>We will frequently use the notation $\gamma(h)$ to denote the **autocovariance** for a lag $h$ i.e. between $y_t$ and $y_{t+h}$</span>
<span id="cb20-187"><a href="#cb20-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-188"><a href="#cb20-188" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-189"><a href="#cb20-189" aria-hidden="true" tabindex="-1"></a>\gamma(h) = \mathbb{C}ov<span class="co">[</span><span class="ot">y_t, y_{t+h}</span><span class="co">]</span> \qquad</span>
<span id="cb20-190"><a href="#cb20-190" aria-hidden="true" tabindex="-1"></a>$$ {#eq-autocovariance}</span>
<span id="cb20-191"><a href="#cb20-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-192"><a href="#cb20-192" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-193"><a href="#cb20-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-194"><a href="#cb20-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-195"><a href="#cb20-195" aria-hidden="true" tabindex="-1"></a>When the time series is stationary, then the covariance only depends on the lag $h = |t-s|$ and we can write the covariance as $\gamma(h)$.</span>
<span id="cb20-196"><a href="#cb20-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-197"><a href="#cb20-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-198"><a href="#cb20-198" aria-hidden="true" tabindex="-1"></a>Let $<span class="sc">\{</span>y_t<span class="sc">\}</span>$ be a time series. Recall that the covariance between two random variables $y_t$ and $y_s$ is defined as:</span>
<span id="cb20-199"><a href="#cb20-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-200"><a href="#cb20-200" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-201"><a href="#cb20-201" aria-hidden="true" tabindex="-1"></a>\gamma(t,s)=\mathbb{C}ov<span class="co">[</span><span class="ot">y_t, y_s</span><span class="co">]</span> = \mathbb{E}<span class="co">[</span><span class="ot">(y_t-\mu_t)(y_s-\mu_s)</span><span class="co">]</span> \qquad</span>
<span id="cb20-202"><a href="#cb20-202" aria-hidden="true" tabindex="-1"></a>$$ {#eq-covariance}</span>
<span id="cb20-203"><a href="#cb20-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-204"><a href="#cb20-204" aria-hidden="true" tabindex="-1"></a>where $\mu_t = \mathbb{E}(y_t)$ and $\mu_s = \mathbb{E}(y_s)$ are the means of $y_t$ and $y_s$ respectively.</span>
<span id="cb20-205"><a href="#cb20-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-206"><a href="#cb20-206" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-207"><a href="#cb20-207" aria-hidden="true" tabindex="-1"></a>\mu_t = \mathbb{E}(y_t) \qquad \mu_s = \mathbb{E}(y_s)</span>
<span id="cb20-208"><a href="#cb20-208" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mean}</span>
<span id="cb20-209"><a href="#cb20-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-210"><a href="#cb20-210" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-211"><a href="#cb20-211" aria-hidden="true" tabindex="-1"></a>\text{Stationarity} \implies \mathbb{E}<span class="co">[</span><span class="ot">y_t</span><span class="co">]</span> = \mu \quad \forall t \qquad \therefore \quad \gamma(t,s)=\gamma(|t-s|)</span>
<span id="cb20-212"><a href="#cb20-212" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-213"><a href="#cb20-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-214"><a href="#cb20-214" aria-hidden="true" tabindex="-1"></a>If $h&gt;0 \qquad \gamma(h)=\mathbb{C}ov<span class="co">[</span><span class="ot">y_t,y_{t-h}</span><span class="co">]</span>$</span>
<span id="cb20-215"><a href="#cb20-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-216"><a href="#cb20-216" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb20-217"><a href="#cb20-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-218"><a href="#cb20-218" aria-hidden="true" tabindex="-1"></a><span class="fu">###  Autocorrelation Function (AFC) {#sec-autocorrelation-function}</span></span>
<span id="cb20-219"><a href="#cb20-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-220"><a href="#cb20-220" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">auto-correlation AFC</span><span class="co">]</span>{.column-margin}</span>
<span id="cb20-221"><a href="#cb20-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-222"><a href="#cb20-222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-223"><a href="#cb20-223" aria-hidden="true" tabindex="-1"></a>\rho(t,s) = \frac{\gamma(t,s)}{\sqrt{\gamma(t,t)\gamma(s,s)}}</span>
<span id="cb20-224"><a href="#cb20-224" aria-hidden="true" tabindex="-1"></a>$$ {#eq-autocorrelation}</span>
<span id="cb20-225"><a href="#cb20-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-226"><a href="#cb20-226" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-227"><a href="#cb20-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-228"><a href="#cb20-228" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-229"><a href="#cb20-229" aria-hidden="true" tabindex="-1"></a>\text{Stationarity} \implies \rho(h)=\frac{\gamma(h)}{\gamma(o)} \qquad \gamma(0)=Var(y_t)</span>
<span id="cb20-230"><a href="#cb20-230" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-231"><a href="#cb20-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-232"><a href="#cb20-232" aria-hidden="true" tabindex="-1"></a><span class="al">![sample AFC](images/m1_0012.png)</span>{#fig-slide-afc-2 .column-margin group="slides" width="200px"}</span>
<span id="cb20-233"><a href="#cb20-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-234"><a href="#cb20-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-235"><a href="#cb20-235" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-236"><a href="#cb20-236" aria-hidden="true" tabindex="-1"></a>y_{1:T}</span>
<span id="cb20-237"><a href="#cb20-237" aria-hidden="true" tabindex="-1"></a>$$ {#eq-sub-sequence}</span>
<span id="cb20-238"><a href="#cb20-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-239"><a href="#cb20-239" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb20-240"><a href="#cb20-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-241"><a href="#cb20-241" aria-hidden="true" tabindex="-1"></a><span class="fu">### The  sample AFC {#sec-sample-acf}</span></span>
<span id="cb20-242"><a href="#cb20-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-243"><a href="#cb20-243" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-244"><a href="#cb20-244" aria-hidden="true" tabindex="-1"></a>\hat\gamma(h)= \frac{1}{T} \sum_{t=1}^{T-h}(y_{t+h}-\bar y )(y_t-\hat y)</span>
<span id="cb20-245"><a href="#cb20-245" aria-hidden="true" tabindex="-1"></a>$$ {#eq-sample-auto-covariance-function}</span>
<span id="cb20-246"><a href="#cb20-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-247"><a href="#cb20-247" aria-hidden="true" tabindex="-1"></a>where $\bar y$ is the sample mean of the time series $y_{1:T}$, and $\hat y$ is the sample mean of the time series $y_{1:T-h}$.</span>
<span id="cb20-248"><a href="#cb20-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-249"><a href="#cb20-249" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-250"><a href="#cb20-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-251"><a href="#cb20-251" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-252"><a href="#cb20-252" aria-hidden="true" tabindex="-1"></a>\bar y = \frac{1}{T} \sum_{t=1}^{T}y_t</span>
<span id="cb20-253"><a href="#cb20-253" aria-hidden="true" tabindex="-1"></a>$$ {#eq-sample-mean}</span>
<span id="cb20-254"><a href="#cb20-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-255"><a href="#cb20-255" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-256"><a href="#cb20-256" aria-hidden="true" tabindex="-1"></a>\hat \rho = \frac{\hat\gamma(h)}{\hat\gamma(o)}</span>
<span id="cb20-257"><a href="#cb20-257" aria-hidden="true" tabindex="-1"></a>$$ {#eq-sample-auto-correlation-function}</span>
<span id="cb20-258"><a href="#cb20-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-259"><a href="#cb20-259" aria-hidden="true" tabindex="-1"></a><span class="fu">### The partial auto-correlation function PACF (Reading) {#sec-pacf-reading}</span></span>
<span id="cb20-260"><a href="#cb20-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-261"><a href="#cb20-261" aria-hidden="true" tabindex="-1"></a>::: {#def-pacf }</span>
<span id="cb20-262"><a href="#cb20-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-263"><a href="#cb20-263" aria-hidden="true" tabindex="-1"></a><span class="fu">## Partial Auto-correlation Function (PACF)</span></span>
<span id="cb20-264"><a href="#cb20-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-265"><a href="#cb20-265" aria-hidden="true" tabindex="-1"></a>Let ${y_t}$ be a zero-mean stationary process, and let</span>
<span id="cb20-266"><a href="#cb20-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-267"><a href="#cb20-267" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-268"><a href="#cb20-268" aria-hidden="true" tabindex="-1"></a>\hat{y}_t^{h-1} = \beta_1 y_{t-1} + \beta_2 y_{t-2} + \ldots + \beta_{h-1} y_{t-(h-1)}</span>
<span id="cb20-269"><a href="#cb20-269" aria-hidden="true" tabindex="-1"></a>$$ {#eq-best-linear-predictor}</span>
<span id="cb20-270"><a href="#cb20-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-271"><a href="#cb20-271" aria-hidden="true" tabindex="-1"></a>be the best linear predictor of $y_t$ based on the previous $h − 1$ values $<span class="sc">\{</span>y_{t−1}, \ldots , y_{t−h+1}<span class="sc">\}</span>$. The best linear predictor of $y_t$ based on the previous $h − 1$ values of the process is the linear predictor that minimizes</span>
<span id="cb20-272"><a href="#cb20-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-273"><a href="#cb20-273" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-274"><a href="#cb20-274" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">(y_t − \hat{y}_y^{h-1})^2</span><span class="co">]</span></span>
<span id="cb20-275"><a href="#cb20-275" aria-hidden="true" tabindex="-1"></a>$$ {#eq-best-linear-predictor-minimization}</span>
<span id="cb20-276"><a href="#cb20-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-277"><a href="#cb20-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-278"><a href="#cb20-278" aria-hidden="true" tabindex="-1"></a>The partial autocorrelation of this process at lag h, denoted by $\phi(h, h)$ is defined as: <span class="co">[</span><span class="ot">partial auto-correlation PAFC</span><span class="co">]</span>{.column-margin}</span>
<span id="cb20-279"><a href="#cb20-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-280"><a href="#cb20-280" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-281"><a href="#cb20-281" aria-hidden="true" tabindex="-1"></a>\phi(h, h) = Corr(y_{t+h} − \hat{y}_{t+h}^{h-1}, y_t − \hat{y}_t^{h-1})</span>
<span id="cb20-282"><a href="#cb20-282" aria-hidden="true" tabindex="-1"></a>$$ {#eq-partial-auto-correlation}</span>
<span id="cb20-283"><a href="#cb20-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-284"><a href="#cb20-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-285"><a href="#cb20-285" aria-hidden="true" tabindex="-1"></a>for $h \ge 2$ and $\phi(1, 1) = Corr(y_{t+1}, y_{t}) = \rho(1)$.</span>
<span id="cb20-286"><a href="#cb20-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-287"><a href="#cb20-287" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-288"><a href="#cb20-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-289"><a href="#cb20-289" aria-hidden="true" tabindex="-1"></a>The partial autocorrelation function can also be computed via the Durbin-Levinson recursion for stationary processes as $\phi(0, 0) = 0$,</span>
<span id="cb20-290"><a href="#cb20-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-291"><a href="#cb20-291" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-292"><a href="#cb20-292" aria-hidden="true" tabindex="-1"></a>\phi(n, n) = \frac{\rho(n) − \sum_{h=1}^{n-1} \phi(n − 1, h)\rho(n − h)}{1- \sum_{h=1}^{n-1}\phi(n − 1, h)\rho(h)}</span>
<span id="cb20-293"><a href="#cb20-293" aria-hidden="true" tabindex="-1"></a>$$ {#eq-durbin-levinson}</span>
<span id="cb20-294"><a href="#cb20-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-295"><a href="#cb20-295" aria-hidden="true" tabindex="-1"></a>for $n \ge 1$, and</span>
<span id="cb20-296"><a href="#cb20-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-297"><a href="#cb20-297" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-298"><a href="#cb20-298" aria-hidden="true" tabindex="-1"></a>\phi(n, h) = \phi(n − 1, h) − \phi(n, n)\phi(n − 1, n − h),</span>
<span id="cb20-299"><a href="#cb20-299" aria-hidden="true" tabindex="-1"></a>$$ {#eq-durbin-levinson-2}</span>
<span id="cb20-300"><a href="#cb20-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-301"><a href="#cb20-301" aria-hidden="true" tabindex="-1"></a>for $n \ge 2$, and $h = 1, \ldots , (n − 1)$.</span>
<span id="cb20-302"><a href="#cb20-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-303"><a href="#cb20-303" aria-hidden="true" tabindex="-1"></a>Note that the sample PACF can be obtained by substituting the sample autocorrelations and the sample auto-covariances in the Durbin-Levinson recursion.</span>
<span id="cb20-304"><a href="#cb20-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-305"><a href="#cb20-305" aria-hidden="true" tabindex="-1"></a><span class="fu">## Differencing and smoothing (Reading) {#sec-differencing-and-smoothing}</span></span>
<span id="cb20-306"><a href="#cb20-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-307"><a href="#cb20-307" aria-hidden="true" tabindex="-1"></a>Differencing and smoothing are techniques used to remove trends and seasonality in time series data. They are covered in the <span class="co">[</span><span class="ot">@prado2023time §1.4</span><span class="co">]</span>.</span>
<span id="cb20-308"><a href="#cb20-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-309"><a href="#cb20-309" aria-hidden="true" tabindex="-1"></a>Many synthetic time series models are built under the assumption of stationarity. However, in the real world time series data often present non-stationary features such as **trends** or **seasonality**. These features render such a time series non-stationary, and therefore, not suitable for analysis using the tools and methods we have discussed so far. However practitioners can use techniques for detrending, deseasonalizing and smoothing that when applied to such observed data transforms it into a new time series that is consistent with the stationarity assumption.</span>
<span id="cb20-310"><a href="#cb20-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-311"><a href="#cb20-311" aria-hidden="true" tabindex="-1"></a>We briefly discuss two methods that are commonly used in practice for detrending and smoothing.</span>
<span id="cb20-312"><a href="#cb20-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-313"><a href="#cb20-313" aria-hidden="true" tabindex="-1"></a><span class="fu">### Differencing</span></span>
<span id="cb20-314"><a href="#cb20-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-315"><a href="#cb20-315" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Differencing, is a method which removes the trend from a time series data</span><span class="co">]</span>{.mark}. The first difference of a time series is defined in terms of the  difference operator, denoted as $D$, that produces the transformation <span class="co">[</span><span class="ot">differencing operator $D$</span><span class="co">]</span>{.column-margin}</span>
<span id="cb20-316"><a href="#cb20-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-317"><a href="#cb20-317" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-318"><a href="#cb20-318" aria-hidden="true" tabindex="-1"></a>Dy_t \doteqdot y_t - y_{t-1}.</span>
<span id="cb20-319"><a href="#cb20-319" aria-hidden="true" tabindex="-1"></a>$$ {#eq-first-difference-operator-definition}</span>
<span id="cb20-320"><a href="#cb20-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-321"><a href="#cb20-321" aria-hidden="true" tabindex="-1"></a>Higher order differences are obtained by successively applying the operator $D$. For example,</span>
<span id="cb20-322"><a href="#cb20-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-323"><a href="#cb20-323" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-324"><a href="#cb20-324" aria-hidden="true" tabindex="-1"></a>D^2y_t = D(Dy_t) = D(y_t - y_{t-1}) = y_t - 2y_{t-1} + y_{t-2}.</span>
<span id="cb20-325"><a href="#cb20-325" aria-hidden="true" tabindex="-1"></a>$$ {#eq-higher-order-difference-operator-definition}</span>
<span id="cb20-326"><a href="#cb20-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-327"><a href="#cb20-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-328"><a href="#cb20-328" aria-hidden="true" tabindex="-1"></a>Differencing can also be written in terms of the so called back-shift operator $B$, with <span class="co">[</span><span class="ot">back-shift operator $B$</span><span class="co">]</span>{.column-margin}</span>
<span id="cb20-329"><a href="#cb20-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-330"><a href="#cb20-330" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-331"><a href="#cb20-331" aria-hidden="true" tabindex="-1"></a>By_t \doteqdot y_{t-1},</span>
<span id="cb20-332"><a href="#cb20-332" aria-hidden="true" tabindex="-1"></a>$$ {#eq-backshift-operator-definition}</span>
<span id="cb20-333"><a href="#cb20-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-334"><a href="#cb20-334" aria-hidden="true" tabindex="-1"></a>so that </span>
<span id="cb20-335"><a href="#cb20-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-336"><a href="#cb20-336" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-337"><a href="#cb20-337" aria-hidden="true" tabindex="-1"></a>Dy_t \doteqdot (1 - B) y_t</span>
<span id="cb20-338"><a href="#cb20-338" aria-hidden="true" tabindex="-1"></a>$$ {#eq-first-difference-operator-via-back-shift-definition}</span>
<span id="cb20-339"><a href="#cb20-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-340"><a href="#cb20-340" aria-hidden="true" tabindex="-1"></a>and</span>
<span id="cb20-341"><a href="#cb20-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-342"><a href="#cb20-342" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-343"><a href="#cb20-343" aria-hidden="true" tabindex="-1"></a>D^dy_t \doteqdot (1 - B)^d y_t.</span>
<span id="cb20-344"><a href="#cb20-344" aria-hidden="true" tabindex="-1"></a>$$ {#eq-higher-order-difference-operator-definition}</span>
<span id="cb20-345"><a href="#cb20-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-346"><a href="#cb20-346" aria-hidden="true" tabindex="-1"></a>this notation lets us write the differences in by referencing items backwards in time, which is often more intuitive and also useful, for example, when we will want to write the differencing operator in terms of a polynomial.</span>
<span id="cb20-347"><a href="#cb20-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-348"><a href="#cb20-348" aria-hidden="true" tabindex="-1"></a><span class="fu">### Smoothing</span></span>
<span id="cb20-349"><a href="#cb20-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-350"><a href="#cb20-350" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Moving averages, which is commonly used to "smooth" a time series by removing certain features (e.g., seasonality) to highlight other features</span><span class="co">]</span>{.mark} (e.g., trends). </span>
<span id="cb20-351"><a href="#cb20-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-352"><a href="#cb20-352" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">A moving average is a weighted average of the time series around a particular time</span><span class="co">]</span>{.mark} $t$. In general, if we have data $y_{1:T}$, we could obtain a new time series such that <span class="co">[</span><span class="ot">moving average</span><span class="co">]</span>{.column-margin}</span>
<span id="cb20-353"><a href="#cb20-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-354"><a href="#cb20-354" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-355"><a href="#cb20-355" aria-hidden="true" tabindex="-1"></a>z_t = \sum_{j=-q}^{p} w_j y_{t+j} \qquad</span>
<span id="cb20-356"><a href="#cb20-356" aria-hidden="true" tabindex="-1"></a>$$ {#eq-moving-average}</span>
<span id="cb20-357"><a href="#cb20-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-358"><a href="#cb20-358" aria-hidden="true" tabindex="-1"></a>for $t = (q + 1) : (T − p)$, with weights $w_j \ge 0$ and $\sum^p_{j=−q} w_j = 1$</span>
<span id="cb20-359"><a href="#cb20-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-360"><a href="#cb20-360" aria-hidden="true" tabindex="-1"></a>We will frequently work with *moving averages* for which </span>
<span id="cb20-361"><a href="#cb20-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-362"><a href="#cb20-362" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-363"><a href="#cb20-363" aria-hidden="true" tabindex="-1"></a>p = q \qquad \text{(centered)}</span>
<span id="cb20-364"><a href="#cb20-364" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-365"><a href="#cb20-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-366"><a href="#cb20-366" aria-hidden="true" tabindex="-1"></a>and</span>
<span id="cb20-367"><a href="#cb20-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-368"><a href="#cb20-368" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-369"><a href="#cb20-369" aria-hidden="true" tabindex="-1"></a>w_j = w_{−j} \forall j  \text{(symmetric)}</span>
<span id="cb20-370"><a href="#cb20-370" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-371"><a href="#cb20-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-372"><a href="#cb20-372" aria-hidden="true" tabindex="-1"></a>Assume we have periodic data with period $d$. Then, symmetric and centered moving averages can be used to remove such periodicity as follows:</span>
<span id="cb20-373"><a href="#cb20-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-374"><a href="#cb20-374" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If $d = 2q$ :</span>
<span id="cb20-375"><a href="#cb20-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-376"><a href="#cb20-376" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-377"><a href="#cb20-377" aria-hidden="true" tabindex="-1"></a>z_t =  \frac{1}{d} \left(\frac{1}{2} y_{t−q} + y_{t−q+1} + \ldots + y_{t+q−1} + \frac{1}{2} y_{t+q}\right ) </span>
<span id="cb20-378"><a href="#cb20-378" aria-hidden="true" tabindex="-1"></a>$$ {#eq-even-seasonal-moving-average}</span>
<span id="cb20-379"><a href="#cb20-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-380"><a href="#cb20-380" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>if $d = 2q + 1$ :</span>
<span id="cb20-381"><a href="#cb20-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-382"><a href="#cb20-382" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-383"><a href="#cb20-383" aria-hidden="true" tabindex="-1"></a>z_t = \frac{1}{d} \left( y_{t−q} + y_{t−q+1} + \ldots + y_{t+q−1} + y_{t+q}\right ) </span>
<span id="cb20-384"><a href="#cb20-384" aria-hidden="true" tabindex="-1"></a>$$ {#eq-odd-seasonal-moving-average}</span>
<span id="cb20-385"><a href="#cb20-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-386"><a href="#cb20-386" aria-hidden="true" tabindex="-1"></a>::: {#exm-seasonal-moving-average}</span>
<span id="cb20-387"><a href="#cb20-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-388"><a href="#cb20-388" aria-hidden="true" tabindex="-1"></a><span class="fu">### Seasonal Moving Average</span></span>
<span id="cb20-389"><a href="#cb20-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-390"><a href="#cb20-390" aria-hidden="true" tabindex="-1"></a>To remove seasonality in monthly data (i.e., seasonality with a period of d = 12 months), we use a moving average with $p = q = 6$, $a_6 = a_{−6} = 1/24$, and $a_j = a_{−j} = 1/12$ for $j = 0, \ldots , 5$ , resulting in:</span>
<span id="cb20-391"><a href="#cb20-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-392"><a href="#cb20-392" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-393"><a href="#cb20-393" aria-hidden="true" tabindex="-1"></a>z_t = \frac{1}{24} y_{t−6} + \frac{1}{12}y_{t−5} + \ldots + \frac{1}{12}y_{t+5} + \frac{1}{24}y_{t+6}</span>
<span id="cb20-394"><a href="#cb20-394" aria-hidden="true" tabindex="-1"></a>$$ {#eq-seasonal-moving-average}</span>
<span id="cb20-395"><a href="#cb20-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-396"><a href="#cb20-396" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-397"><a href="#cb20-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-398"><a href="#cb20-398" aria-hidden="true" tabindex="-1"></a><span class="fu">## ACF PACF Differencing and Smoothing Examples (Video) {#sec-differencing-and-smoothing-examples}</span></span>
<span id="cb20-399"><a href="#cb20-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-400"><a href="#cb20-400" aria-hidden="true" tabindex="-1"></a>This video walks us through the code snippets in @lst-moving-averages-and-differencing and @lst-white-noise-simulation below and provides examples of how to compute the ACF and PACF of a time series, how to use differencing to remove trends, and how to use moving averages to remove seasonality. </span>
<span id="cb20-401"><a href="#cb20-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-402"><a href="#cb20-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-403"><a href="#cb20-403" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Outline:</span>
<span id="cb20-404"><a href="#cb20-404" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>We begin by simulating data using the code in @sec-white-noise-simulation</span>
<span id="cb20-405"><a href="#cb20-405" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>We simulates white noise data using the <span class="in">`rnorm(1:2000,mean=0,sd=1)`</span> function in R</span>
<span id="cb20-406"><a href="#cb20-406" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>We plot the white noise data which we can see lacks a temporal structure.</span>
<span id="cb20-407"><a href="#cb20-407" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>We plot the ACF using the <span class="in">`acf`</span> function in R:</span>
<span id="cb20-408"><a href="#cb20-408" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we specify the number of lags using the <span class="in">`lag.max=20`</span></span>
<span id="cb20-409"><a href="#cb20-409" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we shows a confidence interval for the ACF values</span>
<span id="cb20-410"><a href="#cb20-410" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>We plot the PACF using the <span class="in">`pacf`</span> function in R</span>
<span id="cb20-411"><a href="#cb20-411" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Next we define some time series objects in R using the <span class="in">`ts`</span> function</span>
<span id="cb20-412"><a href="#cb20-412" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we define and plot monthly data starting in January 1960</span>
<span id="cb20-413"><a href="#cb20-413" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we define and plot yearly data with one observation per year starting in 1960</span>
<span id="cb20-414"><a href="#cb20-414" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we define and plot yearly data with four observations per year starting in 1960</span>
<span id="cb20-415"><a href="#cb20-415" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>We move on to smoothing and differencing  in @sec-differencing-and-smoothing</span>
<span id="cb20-416"><a href="#cb20-416" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>We load the CO2 dataset in R and plot it</span>
<span id="cb20-417"><a href="#cb20-417" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>we plot the ACF and PACF of the CO2 dataset</span>
<span id="cb20-418"><a href="#cb20-418" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>we use the <span class="in">`filter`</span> function in R to remove the seasonal component of the CO2 dataset we plot the resulting time series highlighting the trend.</span>
<span id="cb20-419"><a href="#cb20-419" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>To remove the trend we use the <span class="in">`diff`</span> function in R to take the first and second differences of the CO2 dataset</span>
<span id="cb20-420"><a href="#cb20-420" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>the <span class="in">`diff`</span> function takes a parameter <span class="in">`differences`</span> which specifies the number of differences to take</span>
<span id="cb20-421"><a href="#cb20-421" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>we plot the resulting time series after taking the first and second differences</span>
<span id="cb20-422"><a href="#cb20-422" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>the ACF and PACF of the resulting time series are plotted, they look different, in that they no longer have the slow decay characteristic of time series with a trend.</span>
<span id="cb20-423"><a href="#cb20-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-424"><a href="#cb20-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-425"><a href="#cb20-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-426"><a href="#cb20-426" aria-hidden="true" tabindex="-1"></a>The r-code for the examples is provided below.</span>
<span id="cb20-427"><a href="#cb20-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-428"><a href="#cb20-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-429"><a href="#cb20-429" aria-hidden="true" tabindex="-1"></a><span class="fu">## R code for Differencing and filtering via moving averages (reading) {#sec-differencing-and-smoothing-reading}</span></span>
<span id="cb20-430"><a href="#cb20-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-433"><a href="#cb20-433" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-434"><a href="#cb20-434" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-moving-averages-and-differencing</span></span>
<span id="cb20-435"><a href="#cb20-435" aria-hidden="true" tabindex="-1"></a><span class="co">#| lst-label: lst-moving-averages-and-differencing</span></span>
<span id="cb20-436"><a href="#cb20-436" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "R code: for Differencing and filtering via moving averages"</span></span>
<span id="cb20-437"><a href="#cb20-437" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig.height: 9</span></span>
<span id="cb20-438"><a href="#cb20-438" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig.width: 7</span></span>
<span id="cb20-439"><a href="#cb20-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-440"><a href="#cb20-440" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the CO2 dataset in R</span></span>
<span id="cb20-441"><a href="#cb20-441" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(co2) </span>
<span id="cb20-442"><a href="#cb20-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-443"><a href="#cb20-443" aria-hidden="true" tabindex="-1"></a><span class="co"># Take first differences to remove the trend </span></span>
<span id="cb20-444"><a href="#cb20-444" aria-hidden="true" tabindex="-1"></a>co2_1stdiff<span class="ot">=</span><span class="fu">diff</span>(co2,<span class="at">differences=</span><span class="dv">1</span>)</span>
<span id="cb20-445"><a href="#cb20-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-446"><a href="#cb20-446" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter via moving averages to remove the seasonality </span></span>
<span id="cb20-447"><a href="#cb20-447" aria-hidden="true" tabindex="-1"></a>co2_ma<span class="ot">=</span><span class="fu">filter</span>(co2,<span class="at">filter=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">24</span>,<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">12</span>,<span class="dv">11</span>),<span class="dv">1</span><span class="sc">/</span><span class="dv">24</span>),<span class="at">sides=</span><span class="dv">2</span>)</span>
<span id="cb20-448"><a href="#cb20-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-449"><a href="#cb20-449" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab=</span><span class="fl">1.2</span>,<span class="at">cex.main=</span><span class="fl">1.2</span>)</span>
<span id="cb20-450"><a href="#cb20-450" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(co2) <span class="co"># plot the original data </span></span>
<span id="cb20-451"><a href="#cb20-451" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(co2_1stdiff) <span class="co"># plot the first differences (removes trend, highlights seasonality)</span></span>
<span id="cb20-452"><a href="#cb20-452" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(co2_ma) <span class="co"># plot the filtered series via moving averages (removes the seasonality, highlights the trend)</span></span>
<span id="cb20-453"><a href="#cb20-453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-454"><a href="#cb20-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-455"><a href="#cb20-455" aria-hidden="true" tabindex="-1"></a><span class="fu">## R Code: Simulate data from a white noise process (reading) {#sec-white-noise-simulation}</span></span>
<span id="cb20-456"><a href="#cb20-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-459"><a href="#cb20-459" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-460"><a href="#cb20-460" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lst-white-noise-simulation</span></span>
<span id="cb20-461"><a href="#cb20-461" aria-hidden="true" tabindex="-1"></a><span class="co">#| lst-label: lst-white-noise-simulation</span></span>
<span id="cb20-462"><a href="#cb20-462" aria-hidden="true" tabindex="-1"></a><span class="co">#| lst-cap: "R Code: Simulate data from a white noise process"</span></span>
<span id="cb20-463"><a href="#cb20-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-464"><a href="#cb20-464" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-465"><a href="#cb20-465" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data with no temporal structure (white noise)</span></span>
<span id="cb20-466"><a href="#cb20-466" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-467"><a href="#cb20-467" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb20-468"><a href="#cb20-468" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">200</span></span>
<span id="cb20-469"><a href="#cb20-469" aria-hidden="true" tabindex="-1"></a>t <span class="ot">=</span><span class="dv">1</span><span class="sc">:</span>T</span>
<span id="cb20-470"><a href="#cb20-470" aria-hidden="true" tabindex="-1"></a>y_white_noise<span class="ot">=</span><span class="fu">rnorm</span>(T, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">1</span>)</span>
<span id="cb20-471"><a href="#cb20-471" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-472"><a href="#cb20-472" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a time series object in R: </span></span>
<span id="cb20-473"><a href="#cb20-473" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume the data correspond to annual observations starting in January 1960 </span></span>
<span id="cb20-474"><a href="#cb20-474" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-475"><a href="#cb20-475" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">ts</span>(y_white_noise, <span class="at">start=</span><span class="fu">c</span>(<span class="dv">1960</span>), <span class="at">frequency=</span><span class="dv">1</span>)</span>
<span id="cb20-476"><a href="#cb20-476" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-477"><a href="#cb20-477" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the simulated time series, their sample ACF and their sample PACF</span></span>
<span id="cb20-478"><a href="#cb20-478" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-479"><a href="#cb20-479" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>, <span class="at">cex.main =</span> <span class="fl">1.3</span>)</span>
<span id="cb20-480"><a href="#cb20-480" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">ts</span>(y_white_noise, <span class="at">start=</span><span class="fu">c</span>(<span class="dv">1960</span>), <span class="at">frequency=</span><span class="dv">1</span>)</span>
<span id="cb20-481"><a href="#cb20-481" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt, <span class="at">type =</span> <span class="st">'l'</span>, <span class="at">col=</span><span class="st">'red'</span>, <span class="at">xlab =</span> <span class="st">'time (t)'</span>, <span class="at">ylab =</span> <span class="st">"Y(t)"</span>)</span>
<span id="cb20-482"><a href="#cb20-482" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(yt, <span class="at">lag.max =</span> <span class="dv">20</span>, <span class="at">xlab =</span> <span class="st">"lag"</span>,</span>
<span id="cb20-483"><a href="#cb20-483" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">"Sample ACF"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span>
<span id="cb20-484"><a href="#cb20-484" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(yt, <span class="at">lag.max =</span> <span class="dv">20</span>,<span class="at">xlab =</span> <span class="st">"lag"</span>,</span>
<span id="cb20-485"><a href="#cb20-485" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Sample PACF"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span>
<span id="cb20-486"><a href="#cb20-486" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-487"><a href="#cb20-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-488"><a href="#cb20-488" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quiz 1: Stationarity, ACF, PACF, Differencing, and Smoothing</span></span>
<span id="cb20-489"><a href="#cb20-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-490"><a href="#cb20-490" aria-hidden="true" tabindex="-1"></a>omitted per coursera requirements</span>
<span id="cb20-491"><a href="#cb20-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-492"><a href="#cb20-492" aria-hidden="true" tabindex="-1"></a><span class="fu">## The AR(1) process: Definition and properties</span></span>
<span id="cb20-493"><a href="#cb20-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-494"><a href="#cb20-494" aria-hidden="true" tabindex="-1"></a>We will next introduce the autoregressive process of order one, or AR(1) process, which is a fundamental model in time series analysis. We will discuss the definition of the AR(1) process, its properties, and how to simulate data from an AR(1) process.</span>
<span id="cb20-495"><a href="#cb20-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-496"><a href="#cb20-496" aria-hidden="true" tabindex="-1"></a><span class="fu">### The AR(1) process (video)</span></span>
<span id="cb20-497"><a href="#cb20-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-498"><a href="#cb20-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-499"><a href="#cb20-499" aria-hidden="true" tabindex="-1"></a><span class="al">![AR(1)](images/m1_0031.png)</span>{.column-margin  group="slides" width="200px"}</span>
<span id="cb20-500"><a href="#cb20-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-501"><a href="#cb20-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-502"><a href="#cb20-502" aria-hidden="true" tabindex="-1"></a><span class="al">![AR(1) properties](images/m1_0032.png)</span>{.column-margin  group="slides" width="200px"}</span>
<span id="cb20-503"><a href="#cb20-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-504"><a href="#cb20-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-505"><a href="#cb20-505" aria-hidden="true" tabindex="-1"></a><span class="fu">### The PACF of the AR(1) process (reading)</span></span>
<span id="cb20-506"><a href="#cb20-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-507"><a href="#cb20-507" aria-hidden="true" tabindex="-1"></a>It is possible to show that the PACF of an autoregressive process of order one is zero after the first lag. We can use the Durbin-Levinson recursion to show this.</span>
<span id="cb20-508"><a href="#cb20-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-509"><a href="#cb20-509" aria-hidden="true" tabindex="-1"></a>For lag $n = 0$ we have $\phi(0, 0) = 0$</span>
<span id="cb20-510"><a href="#cb20-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-511"><a href="#cb20-511" aria-hidden="true" tabindex="-1"></a>For lag $n = 1$ we have:</span>
<span id="cb20-512"><a href="#cb20-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-513"><a href="#cb20-513" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-514"><a href="#cb20-514" aria-hidden="true" tabindex="-1"></a>\phi(1, 1) =  \rho(1) = \phi</span>
<span id="cb20-515"><a href="#cb20-515" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-516"><a href="#cb20-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-517"><a href="#cb20-517" aria-hidden="true" tabindex="-1"></a>For lag $n = 2$ we compute $\phi(2, 2)$ as:</span>
<span id="cb20-518"><a href="#cb20-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-519"><a href="#cb20-519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-520"><a href="#cb20-520" aria-hidden="true" tabindex="-1"></a>\phi(2, 2) = \frac{(\rho(2) − \phi(1, 1)\rho(1))}{ (1 − \phi(1, 1)\rho(1))} = \frac{\phi^2-\phi^2}{1- \phi^2}=0</span>
<span id="cb20-521"><a href="#cb20-521" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-522"><a href="#cb20-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-523"><a href="#cb20-523" aria-hidden="true" tabindex="-1"></a>and we also obtain</span>
<span id="cb20-524"><a href="#cb20-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-525"><a href="#cb20-525" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-526"><a href="#cb20-526" aria-hidden="true" tabindex="-1"></a>\phi(2, 1) = \phi(1, 1) − \phi(2, 2)\phi(1, 1) = \phi.</span>
<span id="cb20-527"><a href="#cb20-527" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-528"><a href="#cb20-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-529"><a href="#cb20-529" aria-hidden="true" tabindex="-1"></a>For lag $n = 3$ we compute $\phi(3, 3)$ as</span>
<span id="cb20-530"><a href="#cb20-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-531"><a href="#cb20-531" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-532"><a href="#cb20-532" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb20-533"><a href="#cb20-533" aria-hidden="true" tabindex="-1"></a>\phi(3, 3) &amp;= \frac{(\rho(3) − \sum_{h=1}^2 \phi(2, h)\rho(3 − h))}{1 − \sum_{h=1}^2 \phi(2, h)\rho(h)} \newline</span>
<span id="cb20-534"><a href="#cb20-534" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\phi^3 - \phi(2,1) \rho(2) - \phi(2,2) \rho(1)}{1 - \phi(2,1)\rho(1) - \phi(2,2)\rho(2)} \newline</span>
<span id="cb20-535"><a href="#cb20-535" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\phi^3 - \phi^3 - 0}{1 - \phi^2 } \newline</span>
<span id="cb20-536"><a href="#cb20-536" aria-hidden="true" tabindex="-1"></a>&amp;= 0</span>
<span id="cb20-537"><a href="#cb20-537" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb20-538"><a href="#cb20-538" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-539"><a href="#cb20-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-540"><a href="#cb20-540" aria-hidden="true" tabindex="-1"></a>and we also obtain</span>
<span id="cb20-541"><a href="#cb20-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-542"><a href="#cb20-542" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-543"><a href="#cb20-543" aria-hidden="true" tabindex="-1"></a>\phi(3, 1) = \phi(2, 1) − \phi(3, 3)\phi(2, 2) = \phi</span>
<span id="cb20-544"><a href="#cb20-544" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-545"><a href="#cb20-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-546"><a href="#cb20-546" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-547"><a href="#cb20-547" aria-hidden="true" tabindex="-1"></a>\phi(3, 2) = \phi(2, 2) − \phi(3, 3)\phi(2, 1) = 0</span>
<span id="cb20-548"><a href="#cb20-548" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-549"><a href="#cb20-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-550"><a href="#cb20-550" aria-hidden="true" tabindex="-1"></a>We can prove by induction that in the case of an AR(1), for any lag $n$,</span>
<span id="cb20-551"><a href="#cb20-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-552"><a href="#cb20-552" aria-hidden="true" tabindex="-1"></a>$\phi(n, h) = 0, \phi(n, 1) = \phi$ and $\phi(n, h) = 0$ for $h \ge 2$ and $n \ge 2$.</span>
<span id="cb20-553"><a href="#cb20-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-554"><a href="#cb20-554" aria-hidden="true" tabindex="-1"></a>Then, the PACF of an AR(1) is zero for any lag above 1 and the PACF coefficient at lag 1 is equal to the AR coefficient $\phi$</span>
<span id="cb20-555"><a href="#cb20-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-556"><a href="#cb20-556" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulate data from an AR(1) process (video)</span></span>
<span id="cb20-557"><a href="#cb20-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-558"><a href="#cb20-558" aria-hidden="true" tabindex="-1"></a>This video walks through the code snippet below and provides examples of how to sample data from an AR(1) process and plot the ACF and PACF functions of the resulting time series.</span>
<span id="cb20-559"><a href="#cb20-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-560"><a href="#cb20-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-561"><a href="#cb20-561" aria-hidden="true" tabindex="-1"></a><span class="fu">###  R code: Sample data from AR(1) processes (Reading)</span></span>
<span id="cb20-562"><a href="#cb20-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-565"><a href="#cb20-565" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-566"><a href="#cb20-566" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "ar(1) sampling"</span></span>
<span id="cb20-567"><a href="#cb20-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-568"><a href="#cb20-568" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data from 2 ar(1) processes and plot their ACF and PACF functions</span></span>
<span id="cb20-569"><a href="#cb20-569" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-570"><a href="#cb20-570" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb20-571"><a href="#cb20-571" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb20-572"><a href="#cb20-572" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-573"><a href="#cb20-573" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data from an ar(1) with ar coefficient phi = 0.9 and variance 1</span></span>
<span id="cb20-574"><a href="#cb20-574" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-575"><a href="#cb20-575" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="fl">1.0</span> <span class="co"># innovation variance</span></span>
<span id="cb20-576"><a href="#cb20-576" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co">#innovation stantard deviation</span></span>
<span id="cb20-577"><a href="#cb20-577" aria-hidden="true" tabindex="-1"></a>phi1<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb20-578"><a href="#cb20-578" aria-hidden="true" tabindex="-1"></a>yt1<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi1), <span class="at">sd =</span> sd)</span>
<span id="cb20-579"><a href="#cb20-579" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-580"><a href="#cb20-580" aria-hidden="true" tabindex="-1"></a><span class="co"># sample data from an ar(1) with ar coefficient phi = -0.9 and variance 1</span></span>
<span id="cb20-581"><a href="#cb20-581" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-582"><a href="#cb20-582" aria-hidden="true" tabindex="-1"></a>phi2<span class="ot">=</span><span class="sc">-</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb20-583"><a href="#cb20-583" aria-hidden="true" tabindex="-1"></a>yt2<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi2), <span class="at">sd =</span> sd)</span>
<span id="cb20-584"><a href="#cb20-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-585"><a href="#cb20-585" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb20-586"><a href="#cb20-586" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt1,<span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==</span><span class="fl">0.9</span>))</span>
<span id="cb20-587"><a href="#cb20-587" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt2,<span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==-</span><span class="fl">0.9</span>))</span>
<span id="cb20-588"><a href="#cb20-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-589"><a href="#cb20-589" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">2</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb20-590"><a href="#cb20-590" aria-hidden="true" tabindex="-1"></a>lag.max<span class="ot">=</span><span class="dv">50</span> <span class="co"># max lag</span></span>
<span id="cb20-591"><a href="#cb20-591" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-592"><a href="#cb20-592" aria-hidden="true" tabindex="-1"></a><span class="do">## plot true ACFs for both processes</span></span>
<span id="cb20-593"><a href="#cb20-593" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-594"><a href="#cb20-594" aria-hidden="true" tabindex="-1"></a>cov_0<span class="ot">=</span>sd<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>phi1<span class="sc">^</span><span class="dv">2</span>) <span class="co"># compute auto-covariance at h=0</span></span>
<span id="cb20-595"><a href="#cb20-595" aria-hidden="true" tabindex="-1"></a>cov_h<span class="ot">=</span>phi1<span class="sc">^</span>(<span class="dv">0</span><span class="sc">:</span>lag.max)<span class="sc">*</span>cov_0 <span class="co"># compute auto-covariance at h</span></span>
<span id="cb20-596"><a href="#cb20-596" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span>lag.max, cov_h<span class="sc">/</span>cov_0, <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">'h'</span>, <span class="at">col =</span> <span class="st">'red'</span>,</span>
<span id="cb20-597"><a href="#cb20-597" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"true ACF"</span>, <span class="at">xlab =</span> <span class="st">"Lag"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==</span><span class="fl">0.9</span>))</span>
<span id="cb20-598"><a href="#cb20-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-599"><a href="#cb20-599" aria-hidden="true" tabindex="-1"></a>cov_0<span class="ot">=</span>sd<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>phi2<span class="sc">^</span><span class="dv">2</span>) <span class="co"># compute auto-covariance at h=0</span></span>
<span id="cb20-600"><a href="#cb20-600" aria-hidden="true" tabindex="-1"></a>cov_h<span class="ot">=</span>phi2<span class="sc">^</span>(<span class="dv">0</span><span class="sc">:</span>lag.max)<span class="sc">*</span>cov_0 <span class="co"># compute auto-covariance at h</span></span>
<span id="cb20-601"><a href="#cb20-601" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot autocorrelation function (ACF)</span></span>
<span id="cb20-602"><a href="#cb20-602" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span>lag.max, cov_h<span class="sc">/</span>cov_0, <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">'h'</span>, <span class="at">col =</span> <span class="st">'red'</span>,</span>
<span id="cb20-603"><a href="#cb20-603" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"true ACF"</span>, <span class="at">xlab =</span> <span class="st">"Lag"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="fu">expression</span>(phi<span class="sc">==-</span><span class="fl">0.9</span>))</span>
<span id="cb20-604"><a href="#cb20-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-605"><a href="#cb20-605" aria-hidden="true" tabindex="-1"></a><span class="do">## plot sample ACFs for both processes</span></span>
<span id="cb20-606"><a href="#cb20-606" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-607"><a href="#cb20-607" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(yt1, <span class="at">lag.max =</span> lag.max, <span class="at">type =</span> <span class="st">"correlation"</span>, <span class="at">ylab =</span> <span class="st">"sample ACF"</span>,</span>
<span id="cb20-608"><a href="#cb20-608" aria-hidden="true" tabindex="-1"></a>    <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">main =</span> <span class="st">" "</span>)</span>
<span id="cb20-609"><a href="#cb20-609" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(yt2, <span class="at">lag.max =</span> lag.max, <span class="at">type =</span> <span class="st">"correlation"</span>, <span class="at">ylab =</span> <span class="st">"sample ACF"</span>,</span>
<span id="cb20-610"><a href="#cb20-610" aria-hidden="true" tabindex="-1"></a>    <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">main =</span> <span class="st">" "</span>)</span>
<span id="cb20-611"><a href="#cb20-611" aria-hidden="true" tabindex="-1"></a><span class="do">## plot sample PACFs for both processes</span></span>
<span id="cb20-612"><a href="#cb20-612" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-613"><a href="#cb20-613" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(yt1, <span class="at">lag.ma =</span> lag.max, <span class="at">ylab =</span> <span class="st">"sample PACF"</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span>
<span id="cb20-614"><a href="#cb20-614" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(yt2, <span class="at">lag.ma =</span> lag.max, <span class="at">ylab =</span> <span class="st">"sample PACF"</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">main=</span><span class="st">""</span>)</span>
<span id="cb20-615"><a href="#cb20-615" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-616"><a href="#cb20-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-617"><a href="#cb20-617" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quiz 2: The AR(1) definition and properties</span></span>
<span id="cb20-618"><a href="#cb20-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-619"><a href="#cb20-619" aria-hidden="true" tabindex="-1"></a>Omitted per Coursera honor code requirements.</span>
<span id="cb20-620"><a href="#cb20-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-621"><a href="#cb20-621" aria-hidden="true" tabindex="-1"></a><span class="fu"># The AR(1) process:Maximum likelihood estimation and Bayesian inference</span></span>
<span id="cb20-622"><a href="#cb20-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-623"><a href="#cb20-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-624"><a href="#cb20-624" aria-hidden="true" tabindex="-1"></a><span class="fu">## Review of maximum likelihood and Bayesian inference in regression</span></span>
<span id="cb20-625"><a href="#cb20-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-626"><a href="#cb20-626" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regression Models: Maximum Likelihood Estimation</span></span>
<span id="cb20-627"><a href="#cb20-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-628"><a href="#cb20-628" aria-hidden="true" tabindex="-1"></a>Assume a regression model with the following structure: </span>
<span id="cb20-629"><a href="#cb20-629" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-630"><a href="#cb20-630" aria-hidden="true" tabindex="-1"></a>y_i = \beta_1x_{i,1} + \ldots + \beta_kx_{i,k} + \epsilon_i,</span>
<span id="cb20-631"><a href="#cb20-631" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-632"><a href="#cb20-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-633"><a href="#cb20-633" aria-hidden="true" tabindex="-1"></a>for $i = 1, \ldots, n$ and $\epsilon_i$ independent random variables with $\epsilon_i \sim N(0, v) \forall i$. This model can be written in matrix form as: </span>
<span id="cb20-634"><a href="#cb20-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-635"><a href="#cb20-635" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-636"><a href="#cb20-636" aria-hidden="true" tabindex="-1"></a>y = X \beta + \epsilon, \epsilon \sim N (0, vI), \qquad</span>
<span id="cb20-637"><a href="#cb20-637" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-638"><a href="#cb20-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-639"><a href="#cb20-639" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb20-640"><a href="#cb20-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-641"><a href="#cb20-641" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$y = (y_1, \ldots, y_n)′$ is an n-dimensional vector of responses,</span>
<span id="cb20-642"><a href="#cb20-642" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$X$ is an n × k matrix containing the explanatory variables,</span>
<span id="cb20-643"><a href="#cb20-643" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\beta = (\beta_1, \ldots, \beta_k)′$ is the k-dimensional vector of regression coefficients,</span>
<span id="cb20-644"><a href="#cb20-644" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\epsilon = (\epsilon_1, \ldots, \epsilon_n)′$ is the n-dimensional vector of errors,</span>
<span id="cb20-645"><a href="#cb20-645" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$I$ is an n × n identity matrix.</span>
<span id="cb20-646"><a href="#cb20-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-647"><a href="#cb20-647" aria-hidden="true" tabindex="-1"></a>If $X$ is a full rank matrix with rank $k$ the maximum likelihood estimator for $\beta$, denoted as $\hat\beta_{MLE}$ is given by:</span>
<span id="cb20-648"><a href="#cb20-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-649"><a href="#cb20-649" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-650"><a href="#cb20-650" aria-hidden="true" tabindex="-1"></a>\hat\beta_{MLE} = (X′X)^{−1}X′y,</span>
<span id="cb20-651"><a href="#cb20-651" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-652"><a href="#cb20-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-653"><a href="#cb20-653" aria-hidden="true" tabindex="-1"></a>and the MLE for v is given by</span>
<span id="cb20-654"><a href="#cb20-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-655"><a href="#cb20-655" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-656"><a href="#cb20-656" aria-hidden="true" tabindex="-1"></a>\hat v_{MLE} = \frac{1}{n} (y − X \hat\beta_{MLE})′(y − X \hat\beta_{MLE})</span>
<span id="cb20-657"><a href="#cb20-657" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-658"><a href="#cb20-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-659"><a href="#cb20-659" aria-hidden="true" tabindex="-1"></a>$\hat v_{MLE}$ is not an unbiased estimator of v, therefore, the following unbiased estimator of v is typically used:</span>
<span id="cb20-660"><a href="#cb20-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-661"><a href="#cb20-661" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-662"><a href="#cb20-662" aria-hidden="true" tabindex="-1"></a>s^2 = \frac{1}{n-k}(y − X \hat\beta_{MLE} )′(y − X \hat\beta_{MLE} )</span>
<span id="cb20-663"><a href="#cb20-663" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-664"><a href="#cb20-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-665"><a href="#cb20-665" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regression Models: Bayesian Inference</span></span>
<span id="cb20-666"><a href="#cb20-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-667"><a href="#cb20-667" aria-hidden="true" tabindex="-1"></a>Assume once again we have a model with the structure in (1), which results in a likelihood of the form</span>
<span id="cb20-668"><a href="#cb20-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-669"><a href="#cb20-669" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-670"><a href="#cb20-670" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(y \mid \beta , v) = \frac{1}{(2\pi v)^{n/2}}\exp \left<span class="sc">\{</span> -\frac{1}{2} (y − X\beta)′(y − X\beta) \right<span class="sc">\}</span></span>
<span id="cb20-671"><a href="#cb20-671" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-672"><a href="#cb20-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-673"><a href="#cb20-673" aria-hidden="true" tabindex="-1"></a>If a prior of the form </span>
<span id="cb20-674"><a href="#cb20-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-675"><a href="#cb20-675" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb20-676"><a href="#cb20-676" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(\beta, v) \propto \frac{1}{v}</span>
<span id="cb20-677"><a href="#cb20-677" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-678"><a href="#cb20-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-679"><a href="#cb20-679" aria-hidden="true" tabindex="-1"></a>is used, we obtain that the posterior distribution is given by</span>
<span id="cb20-680"><a href="#cb20-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-681"><a href="#cb20-681" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-682"><a href="#cb20-682" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(\beta,v \mid y) \propto \frac{1}{v^{n/2+1}}\exp \left<span class="sc">\{</span> -\frac{1}{2v} (y − X\beta)′(y − X\beta) \right<span class="sc">\}</span></span>
<span id="cb20-683"><a href="#cb20-683" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-684"><a href="#cb20-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-685"><a href="#cb20-685" aria-hidden="true" tabindex="-1"></a>In addition it can be shown that</span>
<span id="cb20-686"><a href="#cb20-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-687"><a href="#cb20-687" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$(\beta\mid v, y) \sim N (\hat \beta_{MLE} , v(X′X)−1)$</span>
<span id="cb20-688"><a href="#cb20-688" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$(v\mid y) \sim \text{IG}((n − k)/2, d/2)$ with</span>
<span id="cb20-689"><a href="#cb20-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-690"><a href="#cb20-690" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-691"><a href="#cb20-691" aria-hidden="true" tabindex="-1"></a>d = (y − X \hat \beta_{MLE} )′(y − \hat \beta_{MLE} )</span>
<span id="cb20-692"><a href="#cb20-692" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-693"><a href="#cb20-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-694"><a href="#cb20-694" aria-hidden="true" tabindex="-1"></a>with $k = dim(\beta)$.</span>
<span id="cb20-695"><a href="#cb20-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-696"><a href="#cb20-696" aria-hidden="true" tabindex="-1"></a>Given that $\mathbb{P}r(\beta, v \mid y) = \mathbb{P}r(\beta \mid v, y)p(v \mid y)$ the equations above provide a way to directly sample from the posterior distribution of $\beta$ and $v$ by first sampling v from the inverse-gamma distribution above and then conditioning on this sampled value of v, sampling $\beta$ from the normal distribution above.</span>
<span id="cb20-697"><a href="#cb20-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-698"><a href="#cb20-698" aria-hidden="true" tabindex="-1"></a><span class="fu">## Maximum likelihood estimation in the AR(1) (video)</span></span>
<span id="cb20-699"><a href="#cb20-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-700"><a href="#cb20-700" aria-hidden="true" tabindex="-1"></a><span class="al">![slide 1](images/m1_0041.png)</span>{.column-margin  group="slides" width="200px"}</span>
<span id="cb20-701"><a href="#cb20-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-702"><a href="#cb20-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-703"><a href="#cb20-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-704"><a href="#cb20-704" aria-hidden="true" tabindex="-1"></a><span class="al">![slide 2](images/m1_0042.png)</span>{.column-margin  group="slides" width="200px"}</span>
<span id="cb20-705"><a href="#cb20-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-706"><a href="#cb20-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-707"><a href="#cb20-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-708"><a href="#cb20-708" aria-hidden="true" tabindex="-1"></a><span class="al">![slide 3](images/m1_0043.png)</span>{.column-margin  group="slides" width="200px"}</span>
<span id="cb20-709"><a href="#cb20-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-710"><a href="#cb20-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-711"><a href="#cb20-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-712"><a href="#cb20-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-713"><a href="#cb20-713" aria-hidden="true" tabindex="-1"></a><span class="fu">## R code: MLE for the AR(1), examples (reading)</span></span>
<span id="cb20-714"><a href="#cb20-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-715"><a href="#cb20-715" aria-hidden="true" tabindex="-1"></a>The following code allows you to compute the MLE of the AR coefficient $\psi$, the unbiased estimator of $v$, $s^2$ , and the MLE of v based on a dataset simulated from an AR(1) process and using the conditional likelihood.</span>
<span id="cb20-716"><a href="#cb20-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-719"><a href="#cb20-719" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-720"><a href="#cb20-720" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "MLE for AR(1)"</span></span>
<span id="cb20-721"><a href="#cb20-721" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb20-722"><a href="#cb20-722" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb20-723"><a href="#cb20-723" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb20-724"><a href="#cb20-724" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb20-725"><a href="#cb20-725" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb20-726"><a href="#cb20-726" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb20-727"><a href="#cb20-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-728"><a href="#cb20-728" aria-hidden="true" tabindex="-1"></a><span class="do">## Case 1: Conditional likelihood</span></span>
<span id="cb20-729"><a href="#cb20-729" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">2</span><span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb20-730"><a href="#cb20-730" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># design matrix</span></span>
<span id="cb20-731"><a href="#cb20-731" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span><span class="fu">as.numeric</span>((<span class="fu">t</span>(X)<span class="sc">%*%</span>y)<span class="sc">/</span><span class="fu">sum</span>(X<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># MLE for phi</span></span>
<span id="cb20-732"><a href="#cb20-732" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> phi_MLE<span class="sc">*</span>X)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">1</span>) <span class="co"># Unbiased estimate for v </span></span>
<span id="cb20-733"><a href="#cb20-733" aria-hidden="true" tabindex="-1"></a>v_MLE<span class="ot">=</span>s2<span class="sc">*</span>(<span class="fu">length</span>(y)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>(<span class="fu">length</span>(y)) <span class="co"># MLE for v</span></span>
<span id="cb20-734"><a href="#cb20-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-735"><a href="#cb20-735" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of conditional likelihood for phi: "</span>, phi_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb20-736"><a href="#cb20-736" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MLE for the variance v: "</span>, v_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb20-737"><a href="#cb20-737" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate s2 for the variance v: "</span>, s2, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb20-738"><a href="#cb20-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-739"><a href="#cb20-739" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-740"><a href="#cb20-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-741"><a href="#cb20-741" aria-hidden="true" tabindex="-1"></a>This code allows you to compute estimates of the AR(1) coefficient and the variance using the <span class="in">`arima`</span> function in R. The first case uses the conditional sum of squares, the second and third cases use the full likelihood with different starting points for the numerical optimization required to compute the MLE with the full likelihood.</span>
<span id="cb20-742"><a href="#cb20-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-745"><a href="#cb20-745" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-746"><a href="#cb20-746" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "MLE for AR(1) with different methods"</span></span>
<span id="cb20-747"><a href="#cb20-747" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtaining parameter estimates using the arima function in R</span></span>
<span id="cb20-748"><a href="#cb20-748" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb20-749"><a href="#cb20-749" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb20-750"><a href="#cb20-750" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb20-751"><a href="#cb20-751" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb20-752"><a href="#cb20-752" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb20-753"><a href="#cb20-753" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb20-754"><a href="#cb20-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-755"><a href="#cb20-755" aria-hidden="true" tabindex="-1"></a><span class="co">#Using conditional sum of squares, equivalent to conditional likelihood </span></span>
<span id="cb20-756"><a href="#cb20-756" aria-hidden="true" tabindex="-1"></a>arima_CSS<span class="ot">=</span><span class="fu">arima</span>(yt,<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">method=</span><span class="st">"CSS"</span>,<span class="at">n.cond=</span><span class="dv">1</span>,<span class="at">include.mean=</span><span class="cn">FALSE</span>)</span>
<span id="cb20-757"><a href="#cb20-757" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AR estimates with conditional sum of squares (CSS) for phi and v:"</span>, arima_CSS<span class="sc">$</span>coef,arima_CSS<span class="sc">$</span>sigma2,</span>
<span id="cb20-758"><a href="#cb20-758" aria-hidden="true" tabindex="-1"></a><span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb20-759"><a href="#cb20-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-760"><a href="#cb20-760" aria-hidden="true" tabindex="-1"></a><span class="co">#Uses ML with full likelihood </span></span>
<span id="cb20-761"><a href="#cb20-761" aria-hidden="true" tabindex="-1"></a>arima_ML<span class="ot">=</span><span class="fu">arima</span>(yt,<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">method=</span><span class="st">"ML"</span>,<span class="at">include.mean=</span><span class="cn">FALSE</span>)</span>
<span id="cb20-762"><a href="#cb20-762" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AR estimates with full likelihood for phi and v:"</span>, arima_ML<span class="sc">$</span>coef,arima_ML<span class="sc">$</span>sigma2,</span>
<span id="cb20-763"><a href="#cb20-763" aria-hidden="true" tabindex="-1"></a><span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb20-764"><a href="#cb20-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-765"><a href="#cb20-765" aria-hidden="true" tabindex="-1"></a><span class="co">#Default: uses conditional sum of squares to find the starting point for ML and </span></span>
<span id="cb20-766"><a href="#cb20-766" aria-hidden="true" tabindex="-1"></a><span class="co">#         then uses ML </span></span>
<span id="cb20-767"><a href="#cb20-767" aria-hidden="true" tabindex="-1"></a>arima_CSS_ML<span class="ot">=</span><span class="fu">arima</span>(yt,<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">method=</span><span class="st">"CSS-ML"</span>,<span class="at">n.cond=</span><span class="dv">1</span>,<span class="at">include.mean=</span><span class="cn">FALSE</span>)</span>
<span id="cb20-768"><a href="#cb20-768" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AR estimates with CSS to find starting point for ML for phi and v:"</span>, </span>
<span id="cb20-769"><a href="#cb20-769" aria-hidden="true" tabindex="-1"></a>arima_CSS_ML<span class="sc">$</span>coef,arima_CSS_ML<span class="sc">$</span>sigma2,<span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb20-770"><a href="#cb20-770" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-771"><a href="#cb20-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-772"><a href="#cb20-772" aria-hidden="true" tabindex="-1"></a>This code shows you how to compute the MLE for $\psi$ using the full likelihood and the function optimize in R.</span>
<span id="cb20-773"><a href="#cb20-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-776"><a href="#cb20-776" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-777"><a href="#cb20-777" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "MLE for AR(1) with full likelihood"</span></span>
<span id="cb20-778"><a href="#cb20-778" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb20-779"><a href="#cb20-779" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb20-780"><a href="#cb20-780" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb20-781"><a href="#cb20-781" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb20-782"><a href="#cb20-782" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb20-783"><a href="#cb20-783" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb20-784"><a href="#cb20-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-785"><a href="#cb20-785" aria-hidden="true" tabindex="-1"></a><span class="do">## MLE, full likelihood AR(1) with v=1 assumed known </span></span>
<span id="cb20-786"><a href="#cb20-786" aria-hidden="true" tabindex="-1"></a><span class="co"># log likelihood function</span></span>
<span id="cb20-787"><a href="#cb20-787" aria-hidden="true" tabindex="-1"></a>log_p <span class="ot">&lt;-</span> <span class="cf">function</span>(phi, yt){</span>
<span id="cb20-788"><a href="#cb20-788" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.5</span><span class="sc">*</span>(<span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>phi<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span> <span class="fu">sum</span>((yt[<span class="dv">2</span><span class="sc">:</span>T] <span class="sc">-</span> phi<span class="sc">*</span>yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)])<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span> yt[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>phi<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb20-789"><a href="#cb20-789" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-790"><a href="#cb20-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-791"><a href="#cb20-791" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a built-in optimization method to obtain maximum likelihood estimates</span></span>
<span id="cb20-792"><a href="#cb20-792" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span><span class="fu">optimize</span>(log_p, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">tol =</span> <span class="fl">0.0001</span>, <span class="at">maximum =</span> <span class="cn">TRUE</span>, <span class="at">yt =</span> yt)</span>
<span id="cb20-793"><a href="#cb20-793" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of full likelihood for phi: "</span>, result<span class="sc">$</span>maximum)</span>
<span id="cb20-794"><a href="#cb20-794" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-795"><a href="#cb20-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-796"><a href="#cb20-796" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bayesian inference in the AR(1)</span></span>
<span id="cb20-797"><a href="#cb20-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-798"><a href="#cb20-798" aria-hidden="true" tabindex="-1"></a><span class="al">![slide 1](images/m1_0051.png)</span>{.column-margin  group="slides" width="200px"}</span>
<span id="cb20-799"><a href="#cb20-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-800"><a href="#cb20-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-801"><a href="#cb20-801" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bayesian inference in the AR(1): Conditional likelihood example (video)</span></span>
<span id="cb20-802"><a href="#cb20-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-803"><a href="#cb20-803" aria-hidden="true" tabindex="-1"></a>This video walks through the code snippet below and provides examples of how to sample from the posterior distribution of the AR coefficient $\psi$ and the variance $v$ using the conditional likelihood and a reference prior.</span>
<span id="cb20-804"><a href="#cb20-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-805"><a href="#cb20-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-806"><a href="#cb20-806" aria-hidden="true" tabindex="-1"></a><span class="fu">## R Code: AR(1) Bayesian inference, conditional likelihood example (reading)</span></span>
<span id="cb20-807"><a href="#cb20-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-810"><a href="#cb20-810" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-811"><a href="#cb20-811" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "AR(1) inference, conditional likelihood example"</span></span>
<span id="cb20-812"><a href="#cb20-812" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb20-813"><a href="#cb20-813" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb20-814"><a href="#cb20-814" aria-hidden="true" tabindex="-1"></a><span class="do">#####             MLE for AR(1)               ######</span></span>
<span id="cb20-815"><a href="#cb20-815" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb20-816"><a href="#cb20-816" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb20-817"><a href="#cb20-817" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb20-818"><a href="#cb20-818" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb20-819"><a href="#cb20-819" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">200</span> <span class="co"># number of time points</span></span>
<span id="cb20-820"><a href="#cb20-820" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) <span class="co"># sample stationary AR(1) process</span></span>
<span id="cb20-821"><a href="#cb20-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-822"><a href="#cb20-822" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">2</span><span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb20-823"><a href="#cb20-823" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># design matrix</span></span>
<span id="cb20-824"><a href="#cb20-824" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span><span class="fu">as.numeric</span>((<span class="fu">t</span>(X)<span class="sc">%*%</span>y)<span class="sc">/</span><span class="fu">sum</span>(X<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># MLE for phi</span></span>
<span id="cb20-825"><a href="#cb20-825" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> phi_MLE<span class="sc">*</span>X)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">1</span>) <span class="co"># Unbiased estimate for v</span></span>
<span id="cb20-826"><a href="#cb20-826" aria-hidden="true" tabindex="-1"></a>v_MLE<span class="ot">=</span>s2<span class="sc">*</span>(<span class="fu">length</span>(y)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>(<span class="fu">length</span>(y)) <span class="co"># MLE for v </span></span>
<span id="cb20-827"><a href="#cb20-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-828"><a href="#cb20-828" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(phi_MLE,s2))</span>
<span id="cb20-829"><a href="#cb20-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-830"><a href="#cb20-830" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb20-831"><a href="#cb20-831" aria-hidden="true" tabindex="-1"></a><span class="do">######     Posterior inference, AR(1)               </span><span class="al">###</span></span>
<span id="cb20-832"><a href="#cb20-832" aria-hidden="true" tabindex="-1"></a><span class="do">######     Conditional Likelihood + Reference Prior </span><span class="al">###</span></span>
<span id="cb20-833"><a href="#cb20-833" aria-hidden="true" tabindex="-1"></a><span class="do">######     Direct sampling                          </span><span class="al">###</span></span>
<span id="cb20-834"><a href="#cb20-834" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb20-835"><a href="#cb20-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-836"><a href="#cb20-836" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">3000</span>   <span class="co"># posterior sample size</span></span>
<span id="cb20-837"><a href="#cb20-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-838"><a href="#cb20-838" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample posterior distribution of v from inverse gamma distribution</span></span>
<span id="cb20-839"><a href="#cb20-839" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span>)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((yt[<span class="dv">2</span><span class="sc">:</span>T] <span class="sc">-</span> phi_MLE<span class="sc">*</span>yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)])<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb20-840"><a href="#cb20-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-841"><a href="#cb20-841" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample posterior distribution of phi from normal distribution</span></span>
<span id="cb20-842"><a href="#cb20-842" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,n_sample)</span>
<span id="cb20-843"><a href="#cb20-843" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb20-844"><a href="#cb20-844" aria-hidden="true" tabindex="-1"></a>phi_sample[i]<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> phi_MLE, <span class="at">sd=</span><span class="fu">sqrt</span>(v_sample[i]<span class="sc">/</span><span class="fu">sum</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">^</span><span class="dv">2</span>)))}</span>
<span id="cb20-845"><a href="#cb20-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-846"><a href="#cb20-846" aria-hidden="true" tabindex="-1"></a><span class="do">## plot histogram of posterior samples of phi and v</span></span>
<span id="cb20-847"><a href="#cb20-847" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>),<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb20-848"><a href="#cb20-848" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(phi_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(phi), </span>
<span id="cb20-849"><a href="#cb20-849" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>phi),<span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">1.05</span>), <span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb20-850"><a href="#cb20-850" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> phi, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb20-851"><a href="#cb20-851" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(v_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(v), <span class="at">col=</span><span class="st">'lightblue'</span>, <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>v))</span>
<span id="cb20-852"><a href="#cb20-852" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> sd, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb20-853"><a href="#cb20-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-854"><a href="#cb20-854" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-855"><a href="#cb20-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-856"><a href="#cb20-856" aria-hidden="true" tabindex="-1"></a><span class="fu">## Quiz - MLE and Bayesian inference in the AR(1)</span></span>
<span id="cb20-857"><a href="#cb20-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-858"><a href="#cb20-858" aria-hidden="true" tabindex="-1"></a>Omitted per Coursera honor code</span>
<span id="cb20-859"><a href="#cb20-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-860"><a href="#cb20-860" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice Graded Assignment: MLE and Bayesian inference in the AR(1)</span></span>
<span id="cb20-861"><a href="#cb20-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-862"><a href="#cb20-862" aria-hidden="true" tabindex="-1"></a>This peer-reviewed activity is highly recommended. It does not figure into your grade for this course, but it does provide you with the opportunity to apply what you've learned in R and prepare you for your data analysis project in week 5.</span>
<span id="cb20-863"><a href="#cb20-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-864"><a href="#cb20-864" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Consider the R code below: MLE for the AR(1)</span>
<span id="cb20-865"><a href="#cb20-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-868"><a href="#cb20-868" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-869"><a href="#cb20-869" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "lst-ar-1-mle"</span></span>
<span id="cb20-870"><a href="#cb20-870" aria-hidden="true" tabindex="-1"></a><span class="co">#| lst-label: lst-ar-1-mle</span></span>
<span id="cb20-871"><a href="#cb20-871" aria-hidden="true" tabindex="-1"></a><span class="co">#| lst-cap: "R Code: MLE for the AR(1) process, conditional likelihood example"</span></span>
<span id="cb20-872"><a href="#cb20-872" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb20-873"><a href="#cb20-873" aria-hidden="true" tabindex="-1"></a><span class="do">#####             MLE for AR(1)               ######</span></span>
<span id="cb20-874"><a href="#cb20-874" aria-hidden="true" tabindex="-1"></a><span class="do">####################################################</span></span>
<span id="cb20-875"><a href="#cb20-875" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fl">0.9</span> <span class="co"># ar coefficient</span></span>
<span id="cb20-876"><a href="#cb20-876" aria-hidden="true" tabindex="-1"></a>v<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb20-877"><a href="#cb20-877" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="fu">sqrt</span>(v) <span class="co"># innovation standard deviation</span></span>
<span id="cb20-878"><a href="#cb20-878" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">500</span> <span class="co"># number of time points</span></span>
<span id="cb20-879"><a href="#cb20-879" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb20-880"><a href="#cb20-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-881"><a href="#cb20-881" aria-hidden="true" tabindex="-1"></a><span class="do">## Case 1: Conditional likelihood</span></span>
<span id="cb20-882"><a href="#cb20-882" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">2</span><span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb20-883"><a href="#cb20-883" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">as.matrix</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># design matrix</span></span>
<span id="cb20-884"><a href="#cb20-884" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span><span class="fu">as.numeric</span>((<span class="fu">t</span>(X)<span class="sc">%*%</span>y)<span class="sc">/</span><span class="fu">sum</span>(X<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># MLE for phi</span></span>
<span id="cb20-885"><a href="#cb20-885" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> phi_MLE<span class="sc">*</span>X)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">1</span>) <span class="co"># Unbiased estimate for v </span></span>
<span id="cb20-886"><a href="#cb20-886" aria-hidden="true" tabindex="-1"></a>v_MLE<span class="ot">=</span>s2<span class="sc">*</span>(<span class="fu">length</span>(y)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>(<span class="fu">length</span>(y)) <span class="co"># MLE for v</span></span>
<span id="cb20-887"><a href="#cb20-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-888"><a href="#cb20-888" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of conditional likelihood for phi: "</span>, phi_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb20-889"><a href="#cb20-889" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MLE for the variance v: "</span>, v_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb20-890"><a href="#cb20-890" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate s2 for the variance v: "</span>, s2, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb20-891"><a href="#cb20-891" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-892"><a href="#cb20-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-893"><a href="#cb20-893" aria-hidden="true" tabindex="-1"></a>Modify the code above to sample 800 observations from an AR(1) with AR coefficient $\psi = -0.8$ and variance $v = 2$. Plot your simulated data. Obtain the MLE for $\psi$ based on the conditional likelihood and the unbiased estimate $s^2$ for the variance $v$.</span>
<span id="cb20-894"><a href="#cb20-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-895"><a href="#cb20-895" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Consider the R code below: AR(1) Bayesian inference, conditional likelihood</span>
<span id="cb20-896"><a href="#cb20-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-899"><a href="#cb20-899" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb20-900"><a href="#cb20-900" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lst-ar-1-inference</span></span>
<span id="cb20-901"><a href="#cb20-901" aria-hidden="true" tabindex="-1"></a><span class="co">#| lst-label: lst-ar-1-inference</span></span>
<span id="cb20-902"><a href="#cb20-902" aria-hidden="true" tabindex="-1"></a><span class="co">#| lst-cap: "R Code: AR(1) Bayesian inference, conditional likelihood example"</span></span>
<span id="cb20-903"><a href="#cb20-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-904"><a href="#cb20-904" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb20-905"><a href="#cb20-905" aria-hidden="true" tabindex="-1"></a><span class="do">######     Posterior inference, AR(1)               </span><span class="al">###</span></span>
<span id="cb20-906"><a href="#cb20-906" aria-hidden="true" tabindex="-1"></a><span class="do">######     Conditional Likelihood + Reference Prior </span><span class="al">###</span></span>
<span id="cb20-907"><a href="#cb20-907" aria-hidden="true" tabindex="-1"></a><span class="do">######     Direct sampling                          </span><span class="al">###</span></span>
<span id="cb20-908"><a href="#cb20-908" aria-hidden="true" tabindex="-1"></a><span class="do">#######################################################</span></span>
<span id="cb20-909"><a href="#cb20-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-910"><a href="#cb20-910" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">3000</span>   <span class="co"># posterior sample size</span></span>
<span id="cb20-911"><a href="#cb20-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-912"><a href="#cb20-912" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample posterior distribution of v from inverse gamma distribution</span></span>
<span id="cb20-913"><a href="#cb20-913" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span>)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((yt[<span class="dv">2</span><span class="sc">:</span>T] <span class="sc">-</span> phi_MLE<span class="sc">*</span>yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)])<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb20-914"><a href="#cb20-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-915"><a href="#cb20-915" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample posterior distribution of phi from normal distribution</span></span>
<span id="cb20-916"><a href="#cb20-916" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,n_sample)</span>
<span id="cb20-917"><a href="#cb20-917" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb20-918"><a href="#cb20-918" aria-hidden="true" tabindex="-1"></a>phi_sample[i]<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> phi_MLE, <span class="at">sd=</span><span class="fu">sqrt</span>(v_sample[i]<span class="sc">/</span><span class="fu">sum</span>(yt[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">^</span><span class="dv">2</span>)))}</span>
<span id="cb20-919"><a href="#cb20-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-920"><a href="#cb20-920" aria-hidden="true" tabindex="-1"></a><span class="do">## plot histogram of posterior samples of phi and v</span></span>
<span id="cb20-921"><a href="#cb20-921" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb20-922"><a href="#cb20-922" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(phi_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(phi), </span>
<span id="cb20-923"><a href="#cb20-923" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>phi),<span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">1.05</span>), <span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb20-924"><a href="#cb20-924" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> phi, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb20-925"><a href="#cb20-925" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(v_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(v), <span class="at">col=</span><span class="st">'lightblue'</span>, <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Posterior for "</span><span class="sc">~</span>v))</span>
<span id="cb20-926"><a href="#cb20-926" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> sd, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb20-927"><a href="#cb20-927" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb20-928"><a href="#cb20-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-929"><a href="#cb20-929" aria-hidden="true" tabindex="-1"></a>Using your simulated data from part 1 modify the code above to summarize your posterior inference for $\psi$ and $v$ based on 5000 samples from the joint posterior distribution of $\psi$ and $v$.</span>
<span id="cb20-930"><a href="#cb20-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-931"><a href="#cb20-931" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb20-932"><a href="#cb20-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-933"><a href="#cb20-933" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Grading Criteria</span></span>
<span id="cb20-934"><a href="#cb20-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-935"><a href="#cb20-935" aria-hidden="true" tabindex="-1"></a>The responses should follow the same template as the sample code provided above but you will submit your code lines in plain text. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect that :</span>
<span id="cb20-936"><a href="#cb20-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-937"><a href="#cb20-937" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>you generate 800 time points from the AR(1) rather than 500 and plot your simulated data.</span>
<span id="cb20-938"><a href="#cb20-938" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>your simulated data is from an AR(1) with AR coefficients $\psi = -0.8$ and variance $v = 2$ rather than AR(1) with AR coefficient $\psi = 0.9$ and variance $v = 1$ and</span>
<span id="cb20-939"><a href="#cb20-939" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>you obtain 5000 rather than 3000 samples from the posterior distribution from the new simulated process.</span>
<span id="cb20-940"><a href="#cb20-940" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb20-941"><a href="#cb20-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-942"><a href="#cb20-942" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bayesian Inference in the AR(1), : full likelihood example (reading)</span></span>
<span id="cb20-943"><a href="#cb20-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-944"><a href="#cb20-944" aria-hidden="true" tabindex="-1"></a>We consider a prior distribution that assumes that $\phi$ and $v$ are independent:</span>
<span id="cb20-945"><a href="#cb20-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-946"><a href="#cb20-946" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-947"><a href="#cb20-947" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(v) \propto \frac{1}{v},</span>
<span id="cb20-948"><a href="#cb20-948" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-949"><a href="#cb20-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-950"><a href="#cb20-950" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-951"><a href="#cb20-951" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(\phi) = \frac{1}{2}, \quad \text{for } \phi \in (-1, 1),</span>
<span id="cb20-952"><a href="#cb20-952" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-953"><a href="#cb20-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-954"><a href="#cb20-954" aria-hidden="true" tabindex="-1"></a>i.e., we assume a Uniform prior for $\phi \in (-1, 1)$. Combining this prior with the full likelihood in the AR(1) case, we obtain the following posterior density:</span>
<span id="cb20-955"><a href="#cb20-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-956"><a href="#cb20-956" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-957"><a href="#cb20-957" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(\phi, v \mid y_{1:T}) \propto \frac{(1 - \phi^2)^{1/2} }{v^{T/2 + 1}} \exp\left(-\frac{Q^*(\phi)}{2v}\right), \quad -1 &lt; \phi &lt; 1,</span>
<span id="cb20-958"><a href="#cb20-958" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-959"><a href="#cb20-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-960"><a href="#cb20-960" aria-hidden="true" tabindex="-1"></a>with</span>
<span id="cb20-961"><a href="#cb20-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-962"><a href="#cb20-962" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-963"><a href="#cb20-963" aria-hidden="true" tabindex="-1"></a>Q^*(\phi) = y_1^2(1 - \phi^2) + \sum_{t=2}^{T} (y_t - \phi y_{t-1})^2.</span>
<span id="cb20-964"><a href="#cb20-964" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-965"><a href="#cb20-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-966"><a href="#cb20-966" aria-hidden="true" tabindex="-1"></a>It is not possible to get a closed-form expression for this posterior or to perform direct simulation. Therefore, we use simulation-based Markov Chain Monte Carlo (MCMC) methods to obtain samples from the posterior distribution.</span>
<span id="cb20-967"><a href="#cb20-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-968"><a href="#cb20-968" aria-hidden="true" tabindex="-1"></a><span class="fu">### Transformation of $\phi$</span></span>
<span id="cb20-969"><a href="#cb20-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-970"><a href="#cb20-970" aria-hidden="true" tabindex="-1"></a>We first consider the following transformation on $\phi$:</span>
<span id="cb20-971"><a href="#cb20-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-972"><a href="#cb20-972" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-973"><a href="#cb20-973" aria-hidden="true" tabindex="-1"></a>\eta = \log\left(\frac{1 - \phi}{\phi + 1}\right),</span>
<span id="cb20-974"><a href="#cb20-974" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-975"><a href="#cb20-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-976"><a href="#cb20-976" aria-hidden="true" tabindex="-1"></a>so that $\eta \in (-\infty, \infty)$. The inverse transformation on $\eta$ is:</span>
<span id="cb20-977"><a href="#cb20-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-978"><a href="#cb20-978" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-979"><a href="#cb20-979" aria-hidden="true" tabindex="-1"></a>\phi = \frac{1 - \exp(\eta)}{1 + \exp(\eta)}.</span>
<span id="cb20-980"><a href="#cb20-980" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-981"><a href="#cb20-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-982"><a href="#cb20-982" aria-hidden="true" tabindex="-1"></a>Writing down the posterior density for $\eta$ and $v$, we obtain</span>
<span id="cb20-983"><a href="#cb20-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-984"><a href="#cb20-984" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-985"><a href="#cb20-985" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(\eta, v \mid y_{1:T}) \propto\frac{ (1 - \phi^2)^{1/2} }{v^{T/2 + 1}} \exp\left(-\frac{Q^*(\phi)}{2v}\right) \cdot \frac{2 \exp(\eta)}{(1 + \exp(\eta))^2},</span>
<span id="cb20-986"><a href="#cb20-986" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-987"><a href="#cb20-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-988"><a href="#cb20-988" aria-hidden="true" tabindex="-1"></a>with $\phi$ written as a function of $\eta$. We proceed to obtain samples from this posterior distribution using the MCMC algorithm outlined below. Once we have obtained $M$ samples from $\eta$ and $v$ after convergence, we can use the inverse transformation above to obtain posterior samples for $\phi$.</span>
<span id="cb20-989"><a href="#cb20-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-990"><a href="#cb20-990" aria-hidden="true" tabindex="-1"></a><span class="fu">### MCMC Algorithm: Bayesian Inference for AR(1), Full Likelihood</span></span>
<span id="cb20-991"><a href="#cb20-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-992"><a href="#cb20-992" aria-hidden="true" tabindex="-1"></a>**Algorithm**:</span>
<span id="cb20-993"><a href="#cb20-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-994"><a href="#cb20-994" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Initialize $\eta^{(0)}$ and $\beta^{(0)}$.</span>
<span id="cb20-995"><a href="#cb20-995" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>For $m$ in $1:M$ do:</span>
<span id="cb20-996"><a href="#cb20-996" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Sample $v^{(m)} \sim \text{IG}\left(\frac{T}{2}, \frac{Q^*(\phi^{(m-1)})}{2}\right)$.</span>
<span id="cb20-997"><a href="#cb20-997" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Sample $\eta^{(m)}$ using Metropolis-Hastings:</span>
<span id="cb20-998"><a href="#cb20-998" aria-hidden="true" tabindex="-1"></a><span class="ss">        1.  </span>Sample $\eta^* \sim N(\eta^{(m-1)}, c)$, where $c$ is a tuning parameter.</span>
<span id="cb20-999"><a href="#cb20-999" aria-hidden="true" tabindex="-1"></a><span class="ss">        2.  </span>Compute the importance ratio:</span>
<span id="cb20-1000"><a href="#cb20-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-1001"><a href="#cb20-1001" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-1002"><a href="#cb20-1002" aria-hidden="true" tabindex="-1"></a>        r = \frac{p(\eta^*, v^{(m)} \mid y_{1:T})}{p(\eta^{(m-1)}, v^{(m)} \mid y_{1:T})}.</span>
<span id="cb20-1003"><a href="#cb20-1003" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-1004"><a href="#cb20-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-1005"><a href="#cb20-1005" aria-hidden="true" tabindex="-1"></a><span class="ss"> 3. </span>Set: </span>
<span id="cb20-1006"><a href="#cb20-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-1007"><a href="#cb20-1007" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb20-1008"><a href="#cb20-1008" aria-hidden="true" tabindex="-1"></a>        \eta^{(m)} =</span>
<span id="cb20-1009"><a href="#cb20-1009" aria-hidden="true" tabindex="-1"></a>        \begin{cases}</span>
<span id="cb20-1010"><a href="#cb20-1010" aria-hidden="true" tabindex="-1"></a>        \eta^* &amp; \text{with probability } \min(r, 1), <span class="sc">\\</span></span>
<span id="cb20-1011"><a href="#cb20-1011" aria-hidden="true" tabindex="-1"></a>        \eta^{(m-1)} &amp; \text{otherwise}.</span>
<span id="cb20-1012"><a href="#cb20-1012" aria-hidden="true" tabindex="-1"></a>        \end{cases}</span>
<span id="cb20-1013"><a href="#cb20-1013" aria-hidden="true" tabindex="-1"></a>$$</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"bottom","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>