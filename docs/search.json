[
  {
    "objectID": "A03.html",
    "href": "A03.html",
    "title": "96  Appendix: Continuous Distributions",
    "section": "",
    "text": "96.1 The Continuous Uniform\nFollowing a subjective view of distribution, which is more amenable to reinterpretation I use an indicator function to place restrictions on the range of parameter of the PDF.",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-continuous-uniform",
    "href": "A03.html#sec-continuous-uniform",
    "title": "96  Appendix: Continuous Distributions",
    "section": "",
    "text": "96.1.1 Stories\n\n\n\n\n\n\nNoteDiscrete Uniform Finite set Parametrization\n\n\n\n\n\n\n\nX \\sim U[\\alpha,\\beta]\n\\tag{96.1}\n\n\n96.1.2 Moments\n\n\\mathbb{E}[X]=\\frac{(\\alpha+\\beta)}{2}\n\\tag{96.2}\n\n\\mathbb{V}ar[X]=\\frac{(\\beta-\\alpha)^2}{12}\n\\tag{96.3}\n\n\n96.1.3 Probability mass function (PDF)\n\nf(x)= \\frac{1}{\\alpha-\\beta} \\mathbb{I}_{\\{\\alpha \\le x \\le \\beta\\}}(x)\n\\tag{96.4}\n\n\n96.1.4 Cumulative distribution function (CDF)\n\nF(x\\mid \\alpha,\\beta)=\\begin{cases}\n  0,  & \\text{if }x &lt; \\alpha \\\\\n  \\frac{x-\\alpha}{\\beta-\\alpha}, & \\text{if } x\\in [\\alpha,\\beta]\\\\\n  1, & \\text{if } x &gt; \\beta\n  \\end{cases}\n\\tag{96.5}\n\n\n96.1.5 Prior\nSince a number of families have the uniform as a special case we can use them as priors when we want a uniform prior:\nNormal(0,1)= Beta(1,1)",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-beta-distribution",
    "href": "A03.html#sec-the-beta-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.2 The Beta Distribution",
    "text": "96.2 The Beta Distribution\n\n\n96.2.1 Story\nThe Beta distribution is used for random variables which take on values between 0 and 1. For this reason (and other reasons we will see later in the course), the Beta distribution is commonly used to model probabilities.\n\nX \\sim Beta(\\alpha, \\beta)\n\\tag{96.6}\n\n\n96.2.2 PDF & CDF\n\nf(x \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha−1}(1 − x)^{\\beta−1}\\mathbb{I}_{x\\in(0,1)}\\mathbb{I}_{\\alpha\\in\\mathbb{R}^+}\\mathbb{I}_{\\beta\\in\\mathbb{R}^+} \\qquad \\text{(PDF)}\n\\tag{96.7}\n\n\\begin{aligned}\n                 & F(x \\mid \\alpha,\\beta) &= I_x(\\alpha,\\beta) && \\text{(CDF)}\n\\\\ \\text{where } & I_w(u,v) & &&\\text{ is the regularized beta function: }\n\\\\               & I_w(u,v) &= \\frac{B(w; u, v)}{B(u,v)}\n\\\\ \\text{where } & B(w; u,v) &=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t  && \\text{ is the incomplete beta function  }\n\\\\ \\text{and }   & B(u,v)& && \\text{ is the (complete) beta function}\n\\end{aligned}\n\\tag{96.8}\n\n\n96.2.3 Moments\n\n\\mathbb{E}[X] = \\frac{\\alpha}{\\alpha + \\beta} \\qquad (\\text{expectation})\n\\tag{96.9}\n\n\\mathbb{V}ar[X] = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)} \\qquad (\\text{variance})\n\\tag{96.10}\n\n\\mathbb{M}_X(t) = 1+ \\sum^\\infty_{i=1} \\left ( {\\prod^\\infty_{j=0} \\frac{\\alpha+j}{\\alpha + \\beta + j} } \\right ) \\frac{t^i}{i!}\n\\tag{96.11}\nwhere \\Gamma(·) is the Gamma function introduced with the gamma distribution.\nNote also that \\alpha &gt; 0 and \\beta &gt; 0.\n\n\n96.2.4 Relations\n\n\n\nRelations of the Beta distribution\n\n\nThe standard Uniform(0, 1) distribution is a special case of the beta distribution with \\alpha = \\beta = 1.\n\nUniform(0, 1) = Beta(1,1)\n\\tag{96.12}\n\n\n96.2.5 As a prior\nThe Beta distribution is often used as a prior for parameters that are probabilities,since it takes values from 0 and 1.\nDuring prior elicitation the parameters can be set using\n\nthe mean: \\alpha \\over \\alpha +\\beta which I would interpret here as count of successes over trials prior to seeing the data.\nvariance: Equation 96.10 or\nThe effective sample size which is \\alpha+\\beta (see course 1 lesson 7.3 for the derivation).",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-cauchy",
    "href": "A03.html#sec-cauchy",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.3 The Cauchy Distribution",
    "text": "96.3 The Cauchy Distribution\n\n\n96.3.1 PDF\n\n\\text{Cauchy}(y\\mid\\mu,\\sigma) = \\frac{1}{\\pi \\sigma} \\\n\\frac{1}{1 + \\left((y - \\mu)/\\sigma\\right)^2} \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{96.13}\n\n\n96.3.2 CDF\n\nF(x \\mid \\mu, \\sigma) = \\frac{1}{2} + \\frac{1}{\\pi}\\text{arctan}\\left(\\frac{x-\\mu}{\\sigma}\\right) \\qquad \\text{(CDF)}\n\\tag{96.14}\n\n\\mathbb{E}(X) = \\text{ undefined}\n\n\n\\mathbb{V}ar[X] = \\text{ undefined}\n\n\n\n96.3.3 As a prior\nThe Cauchy despite having no mean or variance is recommended as a prior for regression coefficients in Logistic regression. see (Gelman et al. 2008) this is analyzed and discussed in (Ghosh, Li, and Mitra 2018)",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-double-exponential",
    "href": "A03.html#sec-double-exponential",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.4 Double Exponential Distribution (Laplace)",
    "text": "96.4 Double Exponential Distribution (Laplace)\n \n\n\\text{DoubleExponential}(y \\mid \\mu,\\sigma) =\n\\frac{1}{2\\sigma} \\exp \\left( - \\, \\frac{|y - \\mu|}{\\sigma} \\right)\n\\qquad \\text (PDF)\n\\tag{96.15}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-gamma-distribution",
    "href": "A03.html#sec-the-gamma-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.5 The Gamma Distribution",
    "text": "96.5 The Gamma Distribution\n\n\n96.5.1 Story\nIf X_1, X_2, ..., X_n are independent (and identically distributed \\mathrm{Exp}(\\lambda)) waiting times between successive events, then the total waiting time for all n events to occur Y = \\sum X_i will follow a gamma distribution with shape parameter \\alpha = n and rate parameter \\beta = \\lambda:\nWe denote this as:\n\nY =\\sum^N_{i=0} \\mathrm{Exp}_i(\\lambda) \\sim \\mathrm{Gamma}(\\alpha = N, \\beta = \\lambda)\n\\tag{96.16}\n\n\n96.5.2 PDF\n\nf(y \\mid \\alpha , \\beta) = \\frac{\\beta^\\alpha} {\\Gamma(\\alpha)} y^{\\alpha−1} e^{− \\beta y} \\mathbb{I}_{y \\ge \\theta }(y)\n\\tag{96.17}\n\n\n96.5.3 Moments\n\n\\mathbb{E}[Y] = \\frac{\\alpha}{ \\beta}\n\\tag{96.18}\n\n\\mathbb{V}ar[Y] = \\frac{\\alpha}{ \\beta^2}\n\\tag{96.19}\nwhere \\Gamma(·) is the gamma function, a generalization of the factorial function which can accept non-integer arguments. If n is a positive integer, then \\Gamma(n) = (n − 1)!.\nNote also that \\alpha &gt; 0 and $ &gt; 0$.\n\n\n96.5.4 Relations\n\n\n\nRelations of the Gamma Distribution\n\n\nThe exponential distribution is a special case of the Gamma distribution with \\alpha = 1. The gamma distribution commonly appears in statistical problems, as we will see in this course. It is used to model positive-valued, continuous quantities whose distribution is right-skewed. As \\alpha increases, the gamma distribution more closely resembles the normal distribution.",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#inverse-gamma-distribution",
    "href": "A03.html#inverse-gamma-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.6 Inverse Gamma Distribution",
    "text": "96.6 Inverse Gamma Distribution\n\n\n96.6.1 PDF\n\n\\text{InvGamma}(y|\\alpha,\\beta) =\n\\frac{1} {\\Gamma(\\alpha)}\\frac{\\beta^{\\alpha}}{y^{\\alpha + 1}}  e^{- \\frac{ \\beta}{y}}\n   \\ \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{\\beta \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)\n\\tag{96.20}\n\n\n96.6.2 Moments\n\n\\mathbb{E}[X]=\\frac{\\beta}{\\alpha - 1} \\qquad \\text{Expectation}\n\\tag{96.21}\n\n\\mathbb{V}ar[X]=\\frac{\\beta^2}{(\\alpha-1)^2(\\alpha-2)}\\qquad \\text{Variance}\n\\tag{96.22}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#the-z-or-standard-normal-distribution",
    "href": "A03.html#the-z-or-standard-normal-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.7 The Z or Standard normal distribution",
    "text": "96.7 The Z or Standard normal distribution\n· The Standard normal distribution is given by:\n\nZ \\sim \\mathcal{N}[1,0]\n\\tag{96.23}\n\nf(z) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}\n\\tag{96.24}\n\n\\mathcal{L}(\\mu,\\sigma)=\\prod_{i=1}^{n}{1 \\over 2 \\pi \\sigma}e^{−(x_i−\\mu)^2 \\over 2 \\sigma^2}\n\\tag{96.25}\n\n\\begin{aligned}\n\\ell(\\mu, \\sigma) &= \\log \\mathcal{L}(\\mu, \\sigma) \\\\&= -\\frac{n}{2}\\log(2\\pi) - n\\log\\sigma - \\sum_{i=1}^n \\frac{(x_i-\\mu)^2}{2\\sigma^2}\n\\end{aligned}\\sigma^2\n\\tag{96.26}\n\n\\begin{aligned}\n  \\mathbb{E}(Z)&= 0 \\quad \\text{(Expectation)} \\qquad  \\mathbb{V}ar(Z)&= 1 \\quad \\text{(Variance)}\n\\end{aligned}\n\\tag{96.27}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-normal-distribution",
    "href": "A03.html#sec-the-normal-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.8 The Normal Distribution",
    "text": "96.8 The Normal Distribution\n The normal, or Gaussian distribution is one of the most important distributions in statistics.\nIt arises as the limiting distribution of sums (and averages) of random variables. This is due to the Section 99.1. Because of this property, the normal distribution is often used to model the “errors,” or unexplained variations of individual observations in regression models.\nNow consider X = \\sigma Z+\\mu where \\sigma &gt; 0 and \\mu is any real constant. Then \\mathbb{E}[X] = \\mathbb{E}[\\sigma Z+\\mu] = \\sigma E[Z] + \\mu = \\sigma_0 + \\mu = \\mu and \\mathbb{V}ar[X] = Var(\\sigma^2 Z + \\mu) = \\sigma^2 Var(Z) + 0 = \\sigma^2 \\cdot 1 = \\sigma^2\nThen, X follows a normal distribution with mean \\mu and variance \\sigma^2 (standard deviation \\sigma) denoted as\n\nX \\sim N[\\mu,\\sigma^2]\n\\tag{96.28}\n\n96.8.1 PDF\n\nf(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}  e^{-\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}(x-\\mu)^2}\n\\tag{96.29}\n\n\n96.8.2 Moments\n\n\\mathbb{E}(x)= \\mu\n\\tag{96.30}\n\nVar(x)= \\sigma^2\n\\tag{96.31}\n\nThe normal distribution is symmetric about the mean \\mu and is often described as a bell-shaped curve.\nAlthough X can take on any real value (positive or negative), more than 99% of the probability mass is concentrated within three standard deviations of the mean.\n\nThe normal distribution has several desirable properties.\nOne is that if X_1 \\sim N(\\mu_1, \\sigma^2_1) and X_2 ∼ N(\\mu_2, \\sigma^2_2) are independent, then X_1+X_2 \\sim N(\\mu_1+\\mu_2, \\sigma^2_1+\\sigma^2_2).\nConsequently, if we take the average of n Independent and Identically Distributed (IID) Normal random variables we have:\n\n\\bar X = \\frac{1}{n}\\sum_{i=1}^n X_i \\sim N(\\mu, \\frac{\\sigma^2}{n})\n\\tag{96.32}\n\n\nCode\nimport numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = norm.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=0.00, var=1.00, skew=0.00, kurt=0.00\n\n\nCode\nx = np.linspace(norm.ppf(0.01),\n                norm.ppf(0.99), 100)\nax.plot(x, norm.pdf(x),\n       'r-', lw=5, alpha=0.6, label='norm pdf')\n\nrv = norm()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\nr = norm.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n\n(array([0.00378685, 0.01893426, 0.02272111, 0.03029482, 0.07195019,\n       0.14768723, 0.18555576, 0.24235854, 0.33702984, 0.32566929,\n       0.43927485, 0.33324299, 0.39383263, 0.3483904 , 0.30294817,\n       0.22342428, 0.15147409, 0.09845816, 0.06058963, 0.03029482,\n       0.01893426]), array([-2.92293951, -2.65886794, -2.39479637, -2.1307248 , -1.86665323,\n       -1.60258166, -1.33851009, -1.07443852, -0.81036695, -0.54629538,\n       -0.28222381, -0.01815224,  0.24591933,  0.5099909 ,  0.77406247,\n        1.03813404,  1.30220561,  1.56627718,  1.83034875,  2.09442032,\n        2.35849189,  2.62256346]), [&lt;matplotlib.patches.Polygon object at 0x7407b6aaad70&gt;])\n\n\nCode\nax.set_xlim([x[0], x[-1]])\n\n\n(-2.3263478740408408, 2.3263478740408408)\n\n\nCode\nax.legend(loc='best', frameon=False)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-t-distribution",
    "href": "A03.html#sec-the-t-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.9 The t-Distribution",
    "text": "96.9 The t-Distribution\n If we have normal data, we can use (Equation 96.32) to help us estimate the mean \\mu. Reversing the transformation from the previous section, we get:\n\n\\frac {\\hat X - \\mu}{\\sigma / \\sqrt(n)} \\sim N(0, 1)\n\\tag{96.33}\nHowever, we may not know the value of \\sigma. If we estimate it from data, we can replace it with S = \\sqrt{\\sum_i \\frac{(X_i-\\hat X)^2}{n-1}}, the sample standard deviation. This causes the expression (Equation 96.33) to no longer be distributed as a Standard Normal; but as a standard t-distribution with ν = n − 1 degrees of freedom\n\nX \\sim t[\\nu]\n\\tag{96.34}\nf(t\\mid\\nu) = \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\nu\\pi}}\\left (1 + \\frac{t^2}{\\nu}\\right)^{-(\\frac{\\nu+1}{2})}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{96.35}\n\n\\text{where }\\Gamma(w)=\\int_{0}^{\\infty}t^{w-1}e^{-t}\\mathrm{d}t \\text{ is the gamma function}\n\nf(t\\mid\\nu)={\\frac {1}{{\\sqrt {\\nu }}\\,\\mathrm {B} ({\\frac {1}{2}},{\\frac {\\nu }{2}})}}\\left(1+{\\frac {t^{2}}{\\nu }}\\right)^{-(\\nu +1)/2}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{96.36}\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the beta function}\n\n\\begin{aligned} && F(t)&=\\int _{-\\infty }^{t}f(u)\\,du=1-{\\tfrac {1}{2}}I_{x(t)}\\left({\\tfrac {\\nu }{2}},{\\tfrac {1}{2}}\\right) &&\\text{(CDF)}\n\\\\ \\text{where } && I_{x(t)}&= \\frac{B(x; u, v)}{B(u,v)} &&\\text{is the regularized Beta function}\n\\\\ \\text{where } &&B(w; u,v)&=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t &&  \\text{ is the incomplete Beta function }\n\\\\ \\text {and }&& B(u,v)&=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t && \\text{ is the (complete) beta function} \\end{aligned}\n\\tag{96.37}\n\\int _{-\\infty }^{t}f(u)\\,du={\\tfrac {1}{2}}+t{\\frac {\\Gamma \\left({\\tfrac {1}{2}}(\\nu +1)\\right)}{{\\sqrt {\\pi \\nu }}\\,\\Gamma \\left({\\tfrac {\\nu }{2}}\\right)}}\\,{}_{2}F_{1}\\left({\\tfrac {1}{2}},{\\tfrac {1}{2}}(\\nu +1);{\\tfrac {3}{2}};-{\\tfrac {t^{2}}{\\nu }}\\right)\n\n\n\\mathcal{L}(\\mu, \\sigma, \\nu) = \\prod_{i=1}^n \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu\\pi}\\Gamma(\\frac{\\nu}{2})} \\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right)^{-\\frac{\\nu+1}{2}}\n\\tag{96.38}\n\n\\begin{aligned}\n\\ell(\\mu, \\sigma, \\nu) &= \\log \\mathcal{L}(\\mu, \\sigma, \\nu) \\\\&= \\sum_{i=1}^n \\left[\\log\\Gamma\\left(\\frac{\\nu+1}{2}\\right) - \\log\\sqrt{\\nu\\pi} - \\log\\Gamma\\left(\\frac{\\nu}{2}\\right) - \\frac{\\nu+1}{2}\\log\\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right)\\right] \\\\ &= n\\log\\Gamma\\left(\\frac{\\nu+1}{2}\\right) - n\\log\\sqrt{\\nu\\pi} - n\\log\\Gamma\\left(\\frac{\\nu}{2}\\right) - \\frac{\\nu+1}{2}\\sum_{i=1}^n\\log\\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right).\n\\end{aligned}\n\\tag{96.39}\n\n\\mathbb{E}[Y] = 0 \\qquad \\text{ if } \\nu &gt; 1\n\\tag{96.40}\n\n\\mathbb{V}ar[Y] = \\frac{\\nu}{\\nu - 2} \\qquad \\text{ if } \\nu &gt; 2\n\\tag{96.41}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#location-scale-parametrization-t-distribution",
    "href": "A03.html#location-scale-parametrization-t-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.10 Location Scale Parametrization t-distribution",
    "text": "96.10 Location Scale Parametrization t-distribution\n\nX=\\mu+\\sigma T\n\nThe resulting distribution is also called the non-standardized Student’s t-distribution.\nthis is another parameterization of the student-t with:\n\nlocation \\mu \\in \\mathbb{R}^+\nscale \\sigma \\in \\mathbb{R}^+\ndegrees of freedom \\nu \\in \\mathbb{R}^+\n\n\nf(x \\mid \\mu, \\sigma, \\nu) = \\frac{\\left(\\frac{\\nu }{\\nu +\\frac{(x-\\mu )^2}{\\sigma ^2}}\\right)^{\\frac{\\nu+1}{2}}}{\\sqrt{\\nu } \\sigma  B\\left(\\frac{\\nu }{2},\\frac{1}{2} \\right)}\n\\tag{96.42}\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the beta function}\n\n\nF(\\mu, \\sigma, \\nu) =\n\\begin{cases}\n\\frac{1}{2} I_{\\frac{\\nu  \\sigma ^2}{(x-\\mu )^2+\\nu  \\sigma  ^2}}\\left(\\frac{\\nu }{2},\\frac{1}{2}\\right),                & x\\leq \\mu  \n\\\\ \\frac{1}{2} \\left(I_{\\frac{(x-\\mu )^2}{(x-\\mu )^2+\\nu  \\sigma   ^2}}\\left(\\frac{1}{2},\\frac{\\nu }{2}\\right)+1\\right), & \\text{Otherwise}\n\\end{cases}\n\\tag{96.43}\nwhere I_w(u,v) is the regularized incomplete beta function:\n\n\\\\ I_w(u,v) = \\frac{B(w; u, v)}{B(u,v)}\n\nwhere B(w; u,v) is the incomplete beta function:\n\nB(w; u,v) =\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t\n\nAnd B(u,v) is the (complete) beta function\n\n\\mathbb{E}[X] = \\begin{cases}\n  \\mu,               & \\text{if }\\nu &gt; 1\n  \\\\\\text{undefined} & \\text{ otherwise}\n\\end{cases}\n\\tag{96.44}\n\n\\mathbb{V}ar[X] = \\frac{\\nu \\sigma^2}{\\nu-2}\n\\tag{96.45}\nThe t distribution is symmetric and resembles the Normal Distribution but with thicker tails. As the degrees of freedom increase, the t distribution looks more and more like the standard normal distribution.\n\n\n\n\n\n\n\nFigure 96.1: William Sealy Gosset AKA Student\n\n\n\n\n\n\n\n\nTipHistorical Note on The William Sealy Gosset A.K.A Student\n\n\n\n The student-t distribution is due to Gosset, William Sealy (1876-1937) who was an English statistician, chemist and brewer who served as Head Brewer of Guinness and Head Experimental Brewer of Guinness and was a pioneer of modern statistics. He is known for his pioneering work on small sample experimental designs. Gosset published under the pseudonym “Student” and developed most famously Student’s t-distribution – originally called Student’s “z” – and “Student’s test of statistical significance”.\nHe was told to use a Pseudonym and choose ‘Student’ after a predecessor at Guinness published a paper that leaked trade secrets. Gosset was a friend of both Karl Pearson and Ronald Fisher. Fisher suggested a correction to the student-t using the degrees of freedom rather than the sample size. Fisher is also credited with helping to publicize its use.\nfor a full biography see (Pearson et al. 1990)",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-exponential-distribution",
    "href": "A03.html#sec-the-exponential-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.11 The Exponential Distribution",
    "text": "96.11 The Exponential Distribution\n\n\n96.11.1 Story\nThe Exponential distribution models the waiting time between events for events with a rate lambda. Those events, typically, come from a Poisson process\nThe exponential distribution is often used to model the waiting time between random events. Indeed, if the waiting times between successive events are independent then they form an Exp(λ) distribution. Then for any fixed time window of length t, the number of events occurring in that window will follow a Poisson distribution with mean tλ.\n\nX \\sim Exp[\\lambda]\n\\tag{96.46}\n\n\n96.11.2 PDF\n\nf(x \\mid \\lambda) = \\frac{1}{\\lambda} e^{- \\frac{x}{\\lambda}}(x)\\mathbb{I}_{\\lambda\\in\\mathbb{R}^+ } \\mathbb{I}_{x\\in\\mathbb{R}^+_0 } \\quad \\text{(PDF)}\n\\tag{96.47}\n\n\n96.11.3 CDF\n\nF(x \\mid \\lambda) = 1 - e^{-\\lambda x} \\qquad \\text{(CDF)}\n\n\n\\mathcal{L}(\\lambda) = \\prod_{i=1}^n \\lambda e^{-\\lambda x_i}\n\\tag{96.48}\n\n\\begin{aligned} \\ell(\\lambda) &= \\log \\mathcal{L}(\\lambda) \\\\ &= \\sum_{i=1}^n \\log(\\lambda) - \\lambda x_i \\\\\n&= n\\log(\\lambda) - \\lambda\\sum_{i=1}^n x_i \\end{aligned}\n\\tag{96.49}\n\n\n96.11.4 Moments\n\n\\mathbb{E}(x)= \\lambda\n\\tag{96.50}\n\n\\mathbb{V}ar[X]= \\lambda^2\n\\tag{96.51}\n\n\\mathbb{M}_X(t)= \\frac{1}{1-\\lambda t} \\qquad t &lt; \\frac{1}{\\gamma}\n\\tag{96.52}\n\n\n96.11.5 Special cases:\n\nWeibull Y = X^{\\frac{1}{\\gamma}}\nRayleigh Y = \\sqrt{\\frac{2X}{\\lambda}}\nGumbel Y=\\alpha - \\gamma \\log(\\frac{X}{\\lambda})\n\n\n\n96.11.6 Properties:\n\nmemoryless\n\n\n\nCode\nimport numpy as np\nfrom scipy.stats import expon\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = expon.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=1.00, var=1.00, skew=2.00, kurt=6.00\n\n\nCode\nx = np.linspace(expon.ppf(0.01), expon.ppf(0.99), 100)\nax.plot(x, expon.pdf(x), 'r-', lw=5, alpha=0.6, label='expon pdf')\n\nrv = expon()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n\nr = expon.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n\n(array([0.97219479, 0.70907785, 0.53069349, 0.48163779, 0.28095538,\n       0.29879381, 0.24081889, 0.18730358, 0.13378827, 0.09365179,\n       0.10257101, 0.05797492, 0.08473257, 0.05797492, 0.06689414,\n       0.03567687, 0.00891922, 0.02675765, 0.01783844, 0.01337883,\n       0.00445961, 0.01783844, 0.        , 0.00445961, 0.00445961,\n       0.00445961, 0.        , 0.00891922, 0.00891922, 0.00445961]), array([1.27244171e-03, 2.25507339e-01, 4.49742237e-01, 6.73977134e-01,\n       8.98212032e-01, 1.12244693e+00, 1.34668183e+00, 1.57091672e+00,\n       1.79515162e+00, 2.01938652e+00, 2.24362142e+00, 2.46785632e+00,\n       2.69209121e+00, 2.91632611e+00, 3.14056101e+00, 3.36479591e+00,\n       3.58903080e+00, 3.81326570e+00, 4.03750060e+00, 4.26173550e+00,\n       4.48597039e+00, 4.71020529e+00, 4.93444019e+00, 5.15867509e+00,\n       5.38290998e+00, 5.60714488e+00, 5.83137978e+00, 6.05561468e+00,\n       6.27984957e+00, 6.50408447e+00, 6.72831937e+00]), [&lt;matplotlib.patches.Polygon object at 0x7407b4901930&gt;])\n\n\nCode\nax.set_xlim([x[0], x[-1]])\n\n\n(0.010050335853501442, 4.605170185988091)\n\n\nCode\nax.legend(loc='best', frameon=False)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-lognormal-distribution",
    "href": "A03.html#sec-lognormal-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.12 LogNormal Distribution",
    "text": "96.12 LogNormal Distribution\nThe long normal arises when the a log transform is applied to the normal distribution.\n\n\n\\text{LogNormal}(y\\mid\\mu,\\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\ \\sigma} \\, \\frac{1}{y} \\ \\exp \\! \\left( - \\, \\frac{1}{2} \\, \\left( \\frac{\\log y - \\mu}{\\sigma} \\right)^2 \\right) \\ \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)\n\\tag{96.53}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-pareto-distribution",
    "href": "A03.html#sec-pareto-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.13 Pareto Distribution",
    "text": "96.13 Pareto Distribution\n\n\n\\text{Pareto}(y|y_{\\text{min}},\\alpha) = \\frac{\\displaystyle\n\\alpha\\,y_{\\text{min}}^\\alpha}{\\displaystyle y^{\\alpha+1}} \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{y_{min} \\in \\mathbb{R}^+}\\mathbb{I}_{y\\ge y_{min} \\in \\mathbb{R}^+}\n\\qquad \\text (PDF)\n\\tag{96.54}\n\n\\mathrm{Pareto\\_Type\\_2}(y|\\mu,\\lambda,\\alpha) = \\\n\\frac{\\alpha}{\\lambda} \\, \\left( 1+\\frac{y-\\mu}{\\lambda}\n\\right)^{-(\\alpha+1)} \\! \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\lambda \\in \\mathbb{R}^+}\\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{y\\ge \\mu \\in \\mathbb{R}}\n\\qquad \\text (PDF)\n\\tag{96.55}\n\n\\mathbb{E}[X]=\\displaystyle{\\frac{\\alpha y_\\mathrm{min}}{\\alpha - 1}}\\mathbb{I}_{\\alpha&gt;1} \\qquad \\text (expectation)\n\\tag{96.56}\n\n\\mathbb{V}ar[X]=\\displaystyle{\\frac{\\alpha y_\\mathrm{min}^2}{(\\alpha - 1)^2(\\alpha - 2)}}\\mathbb{I}_{\\alpha&gt;2} \\qquad \\text (variance)\n\\tag{96.57}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-weibull-distribution",
    "href": "A03.html#sec-weibull-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.14 Weibull Distribution",
    "text": "96.14 Weibull Distribution\n\n\n96.14.1 PDF\n\n\\text{Weibull}(y|\\alpha,\\sigma) =\n\\frac{\\alpha}{\\sigma} \\, \\left( \\frac{y}{\\sigma} \\right)^{\\alpha - 1} \\, e^{ - \\left( \\frac{y}{\\sigma} \\right)^{\\alpha}} \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-chi-squared-distribution",
    "href": "A03.html#sec-chi-squared-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.15 Chi Squared Distribution",
    "text": "96.15 Chi Squared Distribution\n\nThe chi squared distribution is a special case of the gamma. It is widely used in hypothesis testing and the construction of confidence intervals. It is parameterized using parameter \\nu for the degrees of predom\n\n96.15.1 PDF:\n\n\\text{ChiSquare}(y\\mid\\nu) = \\frac{2^{-\\nu/2}}     {\\Gamma(\\nu / 2)} \\,\ny^{\\nu/2 - 1} \\, \\exp \\! \\left( -\\, \\frac{1}{2} \\, y \\right) \\mathbb{I}_{\\nu \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}} \\qquad \\text (PDF)\n\\tag{96.58}\n\n\n96.15.2 CDF:\n\n{\\frac {1}{\\Gamma (\\nu/2)}}\\;\\gamma \\left({\\frac {\\nu}{2}},\\,{\\frac {x}{2}}\\right) \\qquad \\text (CDF)\n\\tag{96.59}\n\n\n96.15.3 MOMENTS\n\n\\mathbb{E}[X]=\\nu\n\\tag{96.60}\n\n\\mathbb{V}ar[X] = 2\\nu\n\\tag{96.61}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-logistic-distribution",
    "href": "A03.html#sec-logistic-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.16 Logistic Distribution",
    "text": "96.16 Logistic Distribution\n\n\\text{Logistic}(y|\\mu,\\sigma) = \\frac{1}{\\sigma} \\\n\\exp\\!\\left( - \\, \\frac{y - \\mu}{\\sigma} \\right) \\ \\left(1 + \\exp\n\\!\\left( - \\, \\frac{y - \\mu}{\\sigma} \\right) \\right)^{\\!-2} \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}}  \\qquad \\text (PDF)\n\\tag{96.62}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-f-distribution",
    "href": "A03.html#sec-f-distribution",
    "title": "96  Appendix: Continuous Distributions",
    "section": "96.17 F Distribution",
    "text": "96.17 F Distribution\n   The F-distribution or F-ratio, arises frequently as the null distribution of a test statistic, in the analysis of variance (ANOVA) and other F-tests.F DistributionF-ratio\n\n96.17.1 PDF\n\n\\frac {\\sqrt {\\frac {(d_{1}x)^{d_{1}}d_{2}^{d_{2}}}{(d_{1}x+d_{2})^{d_{1}+d_{2}}}}}{x\\,\\mathrm {B} \\!\\left({\\frac {d_{1}}{2}},{\\frac {d_{2}}{2}}\\right)}\n\\tag{96.63}\n\n\n96.17.2 CDF\n\n\\mathbb{I}_{\\frac {d_{1}x}{d_{1}x+d_{2}}}\\left({\\tfrac {d_{1}}{2}},{\\tfrac {d_{2}}{2}}\\right)\n\\tag{96.64}\n\n\n96.17.3 Moments\n\n\\mathbb{E}[X]=\\frac {d_{2}}{d_{2}-2}\n\\tag{96.65}\n\n\\mathbb{V}ar[X] = {\\frac {2\\,d_{2}^{2}\\,(d_{1}+d_{2}-2)}{d_{1}(d_{2}-2)^{2}(d_{2}-4)}}\n\\tag{96.66}\n\n\n\n\n\n\nGelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” The Annals of Applied Statistics 2 (4). https://doi.org/10.1214/08-aoas191.\n\n\nGhosh, Joyee, Yingbo Li, and Robin Mitra. 2018. “On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression.” Bayesian Analysis 13 (2). https://doi.org/10.1214/17-ba1051.\n\n\nPearson, E. S., W. S. Gosset, R. L. Plackett, and G. A. Barnard. 1990. Student: A Statistical Biography of William Sealy Gosset. Clarendon Press. https://books.google.co.il/books?id=LBDvAAAAMAAJ.",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A05.html",
    "href": "A05.html",
    "title": "97  Appendix: Exponents & Logarithms",
    "section": "",
    "text": "97.1 Exponents\nExponents are of the form a^x where:\nRecall that a^0 = 1. Exponents have the following useful properties\nNote: that the first property requires that both terms have the same base a.\nWe cannot simplify a^x ·b^y if a \\ne b.",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A05.html#sec-exponents",
    "href": "A05.html#sec-exponents",
    "title": "97  Appendix: Exponents & Logarithms",
    "section": "",
    "text": "a (called the base) and\nx (called the exponent) is any real number.\n\n\n\na^x· a^y = a^{x+y}\n(a^x)^y = a^{x·y}\n\n\n\n\nOne common base is the number e which is approximately equal to 2.7183.\nThe function e^x is so common in mathematics and has its own symbol e^x = \\exp(x).\nBecause e &gt; 0 we have e^x &gt; 0 for all real numbers x\n\\lim_{x \\to \\infty} x = e^{−x} = 0.",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A05.html#sec-natural-logarithms",
    "href": "A05.html#sec-natural-logarithms",
    "title": "97  Appendix: Exponents & Logarithms",
    "section": "97.2 Natural Logarithms",
    "text": "97.2 Natural Logarithms\nWe will need to manipulate long products of probabilities. Since there often comprise small fractions, their calculation on computers can be problematic due to the underflow of floats. We will therefore prefer to convert these products into sums of logarithms.\n\nDefinition 97.1 (The Logarithm) A log is the inverse of a power. We can use (Equation 97.1).\n\ny = a^x \\implies log_a(y) = x\n\\tag{97.1}\n\n\nDefinition 97.2 (The Natural log) The natural logarithm function has base e and is written without the subscript\n\nlog_e(y) = log(y)\n\\tag{97.2}\n\n\nTheorem 97.1 (Logs take positive values) logs only exist for values greater than 0\n\n\\forall x(e^x &gt; 0) \\implies \\exists \\log(y) \\iff {y &gt; 0}\n\n\nWe can use the properties of exponents from the previous section to obtain some important properties of logarithms:\n\nDefinition 97.3 (Log of a product) we can use Equation 97.3 to convert a log of a product to a sum of logs.\n\n\\log(x·y) = \\log(x) + \\log(y)\n\\tag{97.3}\n\n\nDefinition 97.4 (Log of a quotient) we can use Equation 97.4 to convert a log of a quotient to a difference of logs.\n\n\\log(\\frac{x}{y}) = log(x) − log(y)\n\\tag{97.4}\n\n\nDefinition 97.5 (Log of a power) we can use Equation 97.5 to convert a log of a variable raised to a power into the product.\n\n    \\log(x^b) = b \\cdot log(x)\n\\tag{97.5}\n\n\nDefinition 97.6 (Log of one) we can use (Equation 97.6) to replace a log of 1 with zero since $x(x^0 = 1) $\n\n    \\log(1)=0\n\\tag{97.6}\n\n\n97.2.1 Log of exponent\nwe can use (Equation 97.7) to cancel a log of an exponent since the log is the inverse function of the exponent.\n\nexp(log(y)) = log(exp(y)) = y\n\\tag{97.7}\n\nExample 97.1 (Logarithm) \n    \\begin{aligned}\n    log \\frac{5^2}{10}= 2 log(5) − log(10) ≈ 0.916.\n    \\end{aligned}\n\n\n\nDefinition 97.7 (Change of base for a log) we can use (Equation 97.8) to change the base of a logarithm.\n\n    \\log_b(a)=\\frac{\\log_c(a)}{\\log_c(n)}\n\\tag{97.8}\n\n\nDefinition 97.8 (Derivative of a Log) we can use (Equation 97.9) to differentiate a log.\n\n    \\frac{d}{dx} \\log_(x)=\\frac{1}{x}\n\\tag{97.9}\n\n\nBecause the natural logarithm is a monotonically increasing one-to-one function, finding the x which maximizes any (positive-valued function) f(x) is equivalent to maximizing log(f(x)).\nThis is useful because we often take derivatives to maximize functions.\nIf f(x) has product terms, then log(f(x)) will have summation terms, which are usually simpler when taking derivatives.",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "C2-L04.html",
    "href": "C2-L04.html",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "",
    "text": "34.1 Markov chain Monte Carlo (MCMC)\nMetropolis-Hastings (M-H) is an algorithm that allows us to sample from a generic probability distribution (which we will call the target distribution), even if we do not know the normalizing constant. To do this, we construct and sample from a Markov chain whose stationary distribution is the target distribution. It consists of picking an arbitrary starting value and iteratively accepting or rejecting candidate samples drawn from another distribution, one that is easy to sample.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#sec-m2l4-metropolis-hastings",
    "href": "C2-L04.html#sec-m2l4-metropolis-hastings",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "",
    "text": "ImportantWhy use M-H or MCMC?\n\n\n\nWe will use M-H or other MCMC methods if there is no easy way to simulate independent draws from the target distribution. This can be due to non-conjugate priors, challenges in evaluating the normalizing constant or multiple explanatory variables.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#sec-",
    "href": "C2-L04.html#sec-",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "34.2 The Metropolis-Hastings Algorithm (Video)",
    "text": "34.2 The Metropolis-Hastings Algorithm (Video)\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\n Let’s say we wish to produce samples from a target distribution \\mathbb{P}r(\\theta) \\propto g(\\theta), where we don’t know the normalizing constant (since \\int g(\\theta)d\\theta is hard or impossible to compute), so we only have g(\\theta), the unnormalized joint probability to work with. The Metropolis-Hastings algorithm proceeds as follows.\n\nSelect an initial value \\theta_0.\nFor i=1,\\dots,m repeat the following steps:\n\nDraw a candidate sample \\theta^∗ from a proposal distribution  q(\\theta^* \\mid \\theta_{i−1}) .\nCompute the ratio \\alpha = \\frac{g(\\theta^*) / q(\\theta^* \\mid \\theta_{i-1}) }{g(\\theta_{i-1}) / q(\\theta_{i-1} \\mid \\theta^*)} = \\frac{g(\\theta^*)q(\\theta_{i-1} \\mid \\theta^*)}{g(\\theta_{i-1})q(\\theta^* \\mid \\theta_{i-1})}\n\nIf \\alpha\\ge 1, then accept \\theta^∗ and set \\theta_i=\\theta^∗.\nIf 0&lt;\\alpha&lt;1:\n\naccept \\theta^∗ and set \\theta_i=\\theta^∗ with probability \\alpha,\nreject \\theta^∗ and set \\theta_i=\\theta_{i−1} with probability 1−\\alpha.\n\n\n\n\nproposal distribution q\n\n\n\n\n\nImportantCorrection to the proposal distribution\n\n\n\nSteps 2.b and 2.c act as a correction  since the proposal distribution is not the target distribution. At each step in the chain, we draw a random candidate value of the parameter and decide whether to “move” the chain there or remain where we are. If the proposed move to the candidate is “advantageous,” (\\alpha \\ge 1) we “move” there and if it is not “advantageous,” we still might move there, but only with probability \\alpha. Since our decision to “move” to the candidate only depends on where the chain currently is, this is a Markov chain.\n\n\ncorrection",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#proposal-distribution-q",
    "href": "C2-L04.html#proposal-distribution-q",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "34.3 Proposal distribution q",
    "text": "34.3 Proposal distribution q\nOne careful choice we must make is the candidate generating distribution q(\\theta^∗\\mid\\theta_{i−1}). It may or may not depend on the previous iteration’s value of \\theta.\n\n\n\n\n\n\nImportantIndependent Metropolis-Hastings\n\n\n\nThe simpler case is when the proposal distribution q does not depend on the previous value. We then write it as q(\\theta^∗). This arises if it is always the same distribution. We call this case independent Metropolis-Hastings. If we use independent M-H, q(\\theta) should be as similar as possible to \\mathbb{P}r(\\theta).\n\n\n\n\n\n\n\n\nImportantRandom-Walk Metropolis-Hastings\n\n\n\nIn the more general case, the proposal distribution takes the form q(\\theta^∗\\mid\\theta_{i−1}) with dependence on the previous iteration, is Random-Walk Metropolis-Hastings. Here, the proposal distribution is centered on \\theta_{i−1}.\nFor instance, it might be a Normal distribution with mean \\theta_{i−1}. Because the Normal distribution is symmetric, this example comes with another advantage: q(\\theta^* \\mid \\theta_{i−1})=q(\\theta_{i−1}∣\\theta^*) causing it to cancel out when we calculate \\alpha.\nThus, in Random-Walk M-H where the candidate is drawn from a Normal with mean \\theta_{i−1} and constant variance, the acceptance ratio is simply \\alpha=g(\\theta^∗)/g(\\theta_{i−1}).",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#acceptance-rate-α",
    "href": "C2-L04.html#acceptance-rate-α",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "34.4 Acceptance rate α",
    "text": "34.4 Acceptance rate α\nClearly, not all candidate draws are accepted, so our Markov chain sometimes “stays” where it is, possibly for many iterations. How often you want the chain to accept candidates depends on the type of algorithm you use. If you approximate \\mathbb{P}r(\\theta) with q(\\theta^∗) and always draw candidates from that, accepting candidates often is good; it means q(\\theta^∗) is approximating \\mathbb{P}r(\\theta) well. However, you still may want q to have a larger variance than p and see some rejection of candidates as an assurance that q is covering the space well.\nAs we will see in coming examples, a high acceptance rate for the Random-Walk Metropolis-Hastings sampler is not a good thing. If the random walk is taking too small of steps, it will accept often but will take a very long time to fully explore the posterior. If the random walk is taking too large of steps, many of its proposals will have a low probability and the acceptance rate will be low, wasting many draws. Ideally, a random walk sampler should accept somewhere between 23% and 50% of the candidates proposed.\nIn the next segment, we will see a demonstration of this algorithm used in a discrete case, where we can show mathematically that the Markov chain converges to the target distribution. In the following segment, we will demonstrate coding a Random-Walk Metropolis-Hastings algorithm in R to solve one of the problems from the end of Lesson 2.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#demonstration-of-a-discrete-case",
    "href": "C2-L04.html#demonstration-of-a-discrete-case",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "34.5 Demonstration of a Discrete case",
    "text": "34.5 Demonstration of a Discrete case\n\n\n\n\nMCMC Coin Flip Example\n\nThe following segment is by Herbert Lee, a professor of statistics and applied mathematics at the University of California, Santa Cruz.\nThe following is a demonstration of using Markov chain Monte Carlo, used to estimate posterior probabilities in a simplified case, where we can actually work out the correct answer in closed form. We demonstrate that the Metropolis-Hastings algorithm is indeed working, and giving us the right answer.\nIf you recall from the previous course, the example where your brother or maybe your sister, has a loaded coin that you know will come up heads 70% of the time. But they come to you with some coin, you’re not sure if it’s the loaded coin or a fair coin, and they want to make a bet with you. And you have to figure out which coin this is.\nSuppose you have a prior probability that it’s a 60% probability, that they’ll bring a loaded coin to you. They let you flip it five times, and you get two heads and three tails.\nAnd then you need to figure out, what’s your posterior probability that this is a loaded coin.\nOur unknown parameter \\theta, can either take the values fair or loaded.\n\n\\theta = \\{\\text{fair, loaded} \\}\n\\tag{34.1}\nOur prior for \\theta is the probability of theta equals loaded, is 0.6.\n\n\\mathbb{P}r(\\theta=\\text{loaded})=0.6 \\qquad  \\text{(prior)}\n\\tag{34.2}\nOur likelihood will follow a Binomial distribution, depending upon the value of \\theta.\n\nf(x\\mid \\theta) = {5 \\choose x} \\frac{1}{2}^5\\mathbb{I}_{\\theta=\\text{fair}}+  {5 \\choose x} (.7)^x(.3)^{5-x}\\mathbb{I}_{\\theta=\\text{loaded}}  \\qquad  \\text{(likelihood)}\n\\tag{34.3}\nOur posterior then, we can look at posterior for theta, given that we saw x=2 equals two heads, posterior is the likelihood times the prior, divided by a normalizing constant.\n\n  \\begin{aligned}\n    f(\\theta \\mid X=2) &=\n      \\frac{ \\frac{1}{2}^5(0.4)\\mathbb{I}_{(\\theta=\\text{fair})} + (.7)^2(.3)^{3}(.6)\\mathbb{I}_{(\\theta=\\text{loaded})}}\n           { \\frac{1}{2}^5(0.4) + (.7)^2(.3)^{3}(.6)}  \n  \\\\&=\\frac{ 0.0125 \\mathbb{I}_{(\\theta=\\text{fair})} + 0.00794 \\mathbb{I}_{(\\theta=\\text{loaded})}}\n           { 0.0125 + 0.00794}\n  \\\\&= 0.612 \\mathbb{I}_{(\\theta=\\text{fair})} + 0.388 \\mathbb{I}_{(\\theta=\\text{loaded})}\n  \\qquad  \\text{(posterior) }\n  \\end{aligned}\n\\tag{34.4}\nIn this case, we can work out the binomial and our prior. And we see that we get these expressions at the end. We get posterior probability of \\theta is loaded given that we saw two heads, to be 0.388.\n\n\\therefore \\mathbb{P}r(\\theta=\\text{loaded}\\mid X=2) = 0.388 \\qquad  \\text{(posterior conditional probability ) }\n\\tag{34.5}\nThis is all review from the previous course so far.\nBut suppose we had a more complicated problem, where we couldn’t work this all out in closed form? We’ll know the likelihood and the prior, but we may not be able to get this normalizing constant. Can we instead do this by simulation? And indeed, yes we can.\nWe can do this with Markov chain Monte Carlo. In particular, using the Metropolis-Hastings algorithm. What we’ll do is, we’ll set up a Markov chain whose equilibrium distribution has this posterior distribution. So we’ll consider a Markov chain with two states, theta equals fair and theta equals loaded. And we’ll allow the chain to move between those two states, with certain transition probabilities. We set this up using this using the Metropolis-Hastings algorithm.\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\nSo under the Metropolis-Hastings algorithm, step one is we start at an arbitrary location. And in this case, we can\n\nstart at either \\theta \\ne \\text{fair}, or \\theta \\ne \\text{loaded}.\n\nIt does not really matter where we start, we’ll be moving back and forth and we’re going to look at the long-term running average, the long-term simulations.\nSo the key is we’ll be simulating.\n\nRun m simulations and in each iteration, we’ll propose a candidate and either accept it or reject it.\n\n\nSo the first part is we’re proposing a new candidate. We’ll call this candidate \\theta^*, and we’re going to propose it be the other state compared to where we are now. Where we are now is \\theta_{i-1}, and so we’ll propose to move to \\theta^*.\n\nIf our current state is fair, we’ll propose \\theta^*=\\text{loaded}.\nIf our current state is loaded, we’ll propose \\theta^*=\\text{fair}.\n\n\nwhat’s our acceptance probability alpha?\nThe general form for \\alpha is:\n\n\\begin {aligned}\n\\alpha &= {\n            { g(\\theta^*)     / q(\\theta^*     \\mid  \\theta_{i-1}) }\n      \\over {g(\\theta_{i-1}) / q(\\theta_{i-1} \\mid  \\theta^*)     }\n      }\n\\\\      &= {\n            { f(x=2 \\mid \\theta^*) f(\\theta^*)     / 1 }\n      \\over { f(x=2 \\mid \\theta_{i-1})f(\\theta_{i-1}) / 1    }\n} \\qquad \\text {(sub. g,q)}\n\\end{aligned}\n\\tag{34.6}\nIn this case,\n\ng() is our un-normalized likelihood times prior\nq(), the proposal distribution, is, in this case, since we always accept the opposite state deterministically i.e. \\theta^*=\\neg \\theta{i_1} with P=1\nIf \\theta^* = \\text{loaded} \\implies \\alpha = {0.00794 \\over 0.0125}=0.635\nIf \\theta^* = \\text{fair} \\implies \\alpha = { 0.0125 \\over 0.00794}=1.574\n\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\nGiven these probabilities, we then can do the acceptance or rejection step.\n\n\\begin{cases}\n\\text{ accept } \\theta^* \\text { and set } \\theta_i=\\text{fair} & \\text{If } \\theta^*=\\text{fair,  } \\alpha&gt;1\n\\\\ \\begin {cases}\n   \\text{ accept } \\theta^* \\text{  and set } \\theta_i=\\text{loaded} &  \\text{ With probability } 0.635\n\\\\ \\text{ reject } \\theta^* \\text{ and set } \\theta_i=\\text{fair}     &  \\text{ Otherwise }\n\\end{cases} & \\text{If } \\theta^*=\\text{loaded, } \\alpha=.635\n\\end{cases}\n\nIf the \\theta^*=\\text{loaded} \\implies \\alpha=0.635. So we accept theta star with probability 0.635. And if we accept it. Set \\theta_i=\\text{loaded} Otherwise, set \\theta_i = \\theta_{i- 1}, if we do not accept, it stays in that same old fair state.\nWe can draw this out as a Markov chain with two states, Fair and ‘loaded’. If it’s in the ‘loaded’ state, it will move with probability one to the fair state. If it’s in the fair state, it will move with a probability of 0.635 to the ‘loaded’ state. And with a probability of 0.365 it will stay in the fair state.\n\n\n\n\nstate diagram\n\nAnd so here’s a little diagram for this Markov chain with two states. In which case it will move back and forth with certain probabilities.\nThus, if we wanted to find our posterior probability , f(\\theta=\\text{loaded} \\mid x=2). We can simulate from this Markov chain using these transition probabilities. And observe the fraction of time that it spends in the state theta equals ‘loaded’. And this gives us a good estimate of the posterior probability that it’s the ‘loaded’ coin. In this particular case, we can also show that this gives us the theoretical right answer.\nIf you’ve seen a little bit of the theory of Markov chains. We can say that a Markov chain with transition probability capital P, has stationary distribution \\Pi.\n\n\\pi P = \\pi \\qquad \\text{(def. stationary distribution)}\n\\tag{34.7}\nHere we have a transition probability matrix P, where we can think about ‘fair’ and ‘loaded’. Moving from the ‘fair’ state, remaining in the ‘fair’ state happens with a probability of 0.365 and it moves from ‘fair’ to ‘loaded’, with a probability of 0.635. If it’s in the ‘loaded’ state, we’ll move to the ‘fair’ state with probability one, and it will stay in the ‘loaded’ state with probability 0.\n\nP=\n\\begin{bmatrix}\n   0.365 & 0.635 \\\\\n   1     & 0\n\\end{bmatrix}\n\nIn this case, we want our stationary distribution to be the posterior probabilities.\n\n\\Pi=\n\\begin{bmatrix}\n    0.612 & 0.388 \\\\\n\\end{bmatrix}\n\nWhich you can recall are 0.612 of being ‘fair’ and 0.388 of being ‘loaded’. And so indeed, if you do just the minimal amount of matrix algebra, you can see that 0.612, 0.388 Multiplied by this matrix, 0.365, 0.635, 1, 0, does indeed give you 0.612 and 0.388, at least to within rounding error.\n\n\\begin{aligned}\n  \\Pi P &=\n  \\begin{bmatrix}\n  0.612 & 0.388\n  \\end{bmatrix}\n  \\begin{bmatrix}\n  0.365 & 0.635 \\\\\n      1 & 0\n  \\end{bmatrix}   \\\\\n  &= \\begin{bmatrix}\n  0.612 & 0.388\n  \\end{bmatrix}\n  \\\\&= \\Pi\n\\end{aligned}\n\\tag{34.8}\nThus in this case we can see, that we do get the correct stationary distribution for the Markov chain using the Metropolis–Hastings algorithm. And that when we simulate it, we do get correct estimates then of the posterior probabilities.\nThis is a nice simple example where we can work out the posterior probabilities in closed form. We don’t need to run Markov chain Monte Carlo. But this method is very powerful because all we need is to be able to evaluate the likelihood and the prior, we don’t need to evaluate the full posterior and get that normalizing constant. And so this applies to a much broader range of more complicated problems. Where we can use Markov chain Monte Carlo to simulate, to be able to get these probabilities. We’ll make good use of this in the rest of this course.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#random-walk-with-normal-likelihood-t-prior",
    "href": "C2-L04.html#random-walk-with-normal-likelihood-t-prior",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "34.6 Random walk with Normal likelihood, t prior",
    "text": "34.6 Random walk with Normal likelihood, t prior\nRecall the model from the last segment of Lesson 2 where the data are the percent change in total personnel from last year to this year for n=10 companies. We used a normal likelihood with known variance and t distribution for the prior on the unknown mean. Suppose the values are y=(1.2,1.4,−0.5,0.3,0.9,2.3,1.0,0.1,1.3,1.9). Because this model is not conjugate, the posterior distribution is not in a standard form that we can easily sample. To obtain posterior samples, we will set up a Markov chain whose stationary distribution is this posterior distribution.\nRecall that the posterior distribution is\n\n\\mathbb{P}r(\\mu \\mid y_1, \\ldots, y_n) \\propto \\frac{\\exp[ n ( \\bar{y} \\mu - \\mu^2/2)]}{1 + \\mu^2}\n\nThe posterior distribution on the left is our target distribution and the expression on the right is our g(\\mu).\nThe first thing we can do in R is write a function to evaluate g(\\mu). Because posterior distributions include likelihoods (the product of many numbers that are potentially small), g(\\mu) might evaluate to such a small number that to the computer, it is effectively zero. This will cause a problem when we evaluate the acceptance ratio \\alpha. To avoid this problem, we can work on the log scale, which will be more numerically stable. Thus, we will write a function to evaluate\n\n\\log(g(\\mu)) = n ( \\bar{y} \\mu - \\mu^2/2) - \\log(1 + \\mu^2)\n\nThis function will require three arguments, \\mu, \\bar{y}, and n.\n\n\nCode\nlg = function(mu, n, ybar) {\n  mu2 = mu^2\n  n * (ybar * mu - mu2 / 2.0) - log(1 + mu2)\n}\n\n\nNext, let’s write a function to execute the Random-Walk Metropolis-Hastings sampler with Normal proposals.\n\n\nCode\nmh = function(n, ybar, n_iter, mu_init, cand_sd) {\n  ## Random-Walk Metropolis-Hastings algorithm\n  \n  ## Step 1, initialize\n  mu_out = numeric(n_iter)\n  accpt = 0\n  mu_now = mu_init\n  lg_now = lg(mu=mu_now, n=n, ybar=ybar)\n  \n  ## Step 2, iterate\n  for (i in 1:n_iter) {\n    ## step 2a\n    mu_cand = rnorm(n=1, mean=mu_now, sd=cand_sd) # draw a candidate\n    \n    ## Step 2b\n    lg_cand = lg(mu=mu_cand, n=n, ybar=ybar) # evaluate log of g with the candidate\n    lalpha = lg_cand - lg_now # log of acceptance ratio\n    alpha = exp(lalpha)\n    \n    ## step 2c\n    u = runif(1) # draw a uniform variable which will be less than alpha with probability min(1, alpha)\n    if (u &lt; alpha) { # then accept the candidate\n      mu_now = mu_cand\n      accpt = accpt + 1 # to keep track of acceptance\n      lg_now = lg_cand\n    }\n    \n    ## collect results\n    mu_out[i] = mu_now # save this iteration's value of mu\n  }\n  \n  ## return a list of output\n  list(mu=mu_out, accpt=accpt/n_iter)\n}\n\n\nNow, let’s set up the problem.\n\n\nCode\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nybar = mean(y)\nn = length(y)\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nFinally, we’re ready to run the sampler! Let’s use m=1000 iterations and proposal standard deviation (which controls the proposal step size) 3.0, and initial value at the prior median 0.\n\n\nCode\nset.seed(43) # set the random seed for reproducibility\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=3.0)\nstr(post)\n\n\nList of 2\n $ mu   : num [1:1000] -0.113 1.507 1.507 1.507 1.507 ...\n $ accpt: num 0.122\n\n\n\n\nCode\nlibrary(\"coda\")\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nThis last plot is called a trace plot. It shows the history of the chain and provides basic feedback about whether the chain has reached its stationary distribution.\nIt appears our proposal step size was too large (acceptance rate below 23%). Let’s try another.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.05)\npost$accpt\n\n\n[1] 0.946\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nOops, the acceptance rate is too high (above 50%). Let’s try something in between.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.9)\npost$accpt\n\n\n[1] 0.38\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nWhich looks good. Just for fun, let’s see what happens if we initialize the chain at some far-off value.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=30.0, cand_sd=0.9)\npost$accpt\n\n\n[1] 0.387\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nIt took awhile to find the stationary distribution, but it looks like we succeeded! If we discard the first 100 or so values, it appears like the rest of the samples come from the stationary distribution, our posterior distribution! Let’s plot the posterior density against the prior to see how the data updated our belief about \\mu.\n\n\nCode\npost$mu_keep = post$mu[-c(1:100)] # discard the first 200 samples\nplot(density(post$mu_keep, adjust=2.0), main=\"\", xlim=c(-1.0, 3.0), xlab=expression(mu)) # plot density estimate of the posterior\ncurve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\npoints(ybar, 0, pch=19) # sample mean\n\ncurve(0.017*exp(lg(mu=x, n=n, ybar=ybar)), from=-1.0, to=3.0, add=TRUE, col=\"blue\") # approximation to the true posterior in blue\n\n\n\n\n\n\n\n\n\nThese results are encouraging, but they are preliminary. We still need to investigate more formally whether our Markov chain has converged to the stationary distribution. We will explore this in a future lesson.\nObtaining posterior samples using the Metropolis-Hastings algorithm can be time-consuming and require some fine-tuning, as we’ve just seen. The good news is that we can rely on software to do most of the work for us. In the next couple of videos, we’ll introduce a program that will make posterior sampling easy.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#setup",
    "href": "C2-L04.html#setup",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "35.1 Setup",
    "text": "35.1 Setup\n\n35.1.1 Introduction to JAGS\nThere are several software packages available that will handle the details of MCMC for us. See the supplementary material for a brief overview of options.\nThe package we will use in this course is JAGS (Just Another Gibbs Sampler) by Martyn Plummer. The program is free, and runs on Mac OS, Windows, and Linux. Better yet, the program can be run using R with the rjags and R2jags packages.\nIn JAGS, we can specify models and run MCMC samplers in just a few lines of code; JAGS does the rest for us, so we can focus more on the statistical modeling aspect and less on the implementation. It makes powerful Bayesian machinery available to us as we can fit a wide variety of statistical models with relative ease.\n\n\n35.1.2 Installation and setup\nThe starting place for JAGS users is mcmc-jags.sourceforge.net. At this site, you can find news about the features of the latest release of JAGS, links to program documentation, as well as instructions for installation.\nThe documentation is particularly important. It is available under the files page link in the Manuals folder.\nAlso under the files page, you will find the JAGS folder where you can download and install the latest version of JAGS. Select the version and operating system, and follow the instructions for download and installation.\nOnce JAGS is installed, we can immediately run it from R using the rjags package. The next segment will show how this is done.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#modeling-in-jags",
    "href": "C2-L04.html#modeling-in-jags",
    "title": "34  M2L4 - Metropolis-Hastings",
    "section": "35.2 Modeling in JAGS",
    "text": "35.2 Modeling in JAGS\nThere are four steps to implementing a model in JAGS through R:\n\nSpecify the model.\nSet up the model.\nRun the MCMC sampler.\nPost-processing.\n\nWe will demonstrate these steps with our running example with the data are the percent change in total personnel from last year to this year for n=10 companies. We used a normal likelihood with known variance and t distribution for the prior on the unknown mean.\n\n35.2.1 1. Specify the model\nIn this step, we give JAGS the hierarchical structure of the model, assigning distributions to the data (the likelihood) and parameters (priors). The syntax for this step is very similar to R, but there are some key differences.\n\n\nCode\nlibrary(\"rjags\")\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\nCode\nmod_string = \" model {\n  for (i in 1:n) {\n    y[i] ~ dnorm(mu, 1.0/sig2)\n  }\n  mu ~ dt(0.0, 1.0/1.0, 1.0) # location, inverse scale, degrees of freedom\n  sig2 = 1.0\n} \"\n\n\nOne of the primary differences between the syntax of JAGS and R is how the distributions are parameterized. Note that the normal distribution uses the mean and precision (instead of variance). When specifying distributions in JAGS, it is always a good idea to check the JAGS user manual here in the chapter on Distributions.\n\n\n35.2.2 2. Set up the model\n\n\nCode\nset.seed(50)\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nn = length(y)\n\ndata_jags = list(y=y, n=n)\nparams = c(\"mu\")\n\ninits = function() {\n  inits = list(\"mu\"=0.0)\n} # optional (and fixed)\n\nmod = jags.model(textConnection(mod_string), data=data_jags, inits=inits)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 10\n   Unobserved stochastic nodes: 1\n   Total graph size: 15\n\nInitializing model\n\n\nThere are multiple ways to specify initial values here. They can be explicitly set, as we did here, or they can be random, i.e., list(\"mu\"=rnorm(1)). Also, we can omit the initial values, and JAGS will provide them.\n\n\n35.2.3 3. Run the MCMC sampler\n\n\nCode\nupdate(mod, 500) # burn-in\n\nmod_sim = coda.samples(model=mod, variable.names=params, n.iter=1000)\n\n\nWe will discuss more options to the coda.samples function in coming examples.\n\n\n35.2.4 4. Post-processing\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 1501:2500\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n       0.89277        0.31987        0.01012        0.01239 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n0.2465 0.6798 0.9116 1.1099 1.4982 \n\n\n\n\nCode\nlibrary(\"coda\")\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\nWe will discuss post processing further, including convergence diagnostics, in a coming lesson.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C4-L00.html",
    "href": "C4-L00.html",
    "title": "87  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "",
    "text": "87.1 Course Card\nI decided to migrate some material that is auxiliary to the course:",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#course-card",
    "href": "C4-L00.html#course-card",
    "title": "87  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "",
    "text": "Course: Bayesian Statistics: Time Series\nOffered by: University of California, Santa Cruz\nInstructor: Raquel Prado\nCertificate: Yes\nLevel: Graduate\nCommitment: 4 weeks of study, 3-4 hours/week",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#overview-of-the-course",
    "href": "C4-L00.html#overview-of-the-course",
    "title": "87  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "87.2 Overview of the course",
    "text": "87.2 Overview of the course\nThis course seems very similar to classic basic time series course without the Bayesian part. (AR, MA, ARMA, ARIMA, SARIMA, DLM etc.)\nOne of the questions I had when I started this course was what is the difference between a Bayesian approach to time series analysis and a classical approach. The following is a summary of what I found:\n\n\n\n\n\n\nImportantAre we Being Bayesian ?\n\n\n\nThe Bayesian approach presents primarily in:\n\nSections on Bayesian inference where we do inference on the parameters of the models.\nBayesian prediction unlike an MLE prediction is a distribution of predictions not just a point estimate, and therefore is useful for quantifying uncertainty.\nWe also cover some material on model selection - this again is where the Bayesian approach to optimization presents more powerful tools than the classical approach.\nWhen we want to quantify the uncertainty in our model we have four sources of uncertainty:\n\nUncertainty due to using the correct model (structure).\n\nI consider this is an epistemic uncertainty -\nOne could reduce it by collecting more data, then applying the Bayesian model selection to choose the best model.\n\nUncertainty due to the estimation of the model parameters. This is an epistemic uncertainty - we can reduce it by collecting more data reducing the plausible intervals for these parameters under the bayesian approach.\nUncertainty due to random shocks \\epsilon_t. for the period being predicted. This is an aleatory uncertainty.\nUncertainty in the forecasted values X_{t+h} Items 2-3 can be quantified using a plausible interval in the Bayesian approach and as we predict further into the future the interval will grow.\n\nModel selection is a big part of the Bayesian approach. We can use the DIC, WAIC, and LOO to compare models.\n\n\n\n\nThe book by Professor Prado is very comprehensive and covers plenty of additional models and references lots of recent research. These including VAR, VARMA models, Kalman filters, SMC/Particle filters, etc. These are useful for the continuous control flavours of RL. But you will need to learn it on your own.\nIn the capstone project that is the next course in the specialization the teacher adds another layer of sophistication by introducing mixtures of TS models.\nHowever unlike some courses I took we dive deep enough and get sufficient examples to understand how to put all the bits together into more sophisticated time series models.\n\n\n87.2.1 Mathematical Review\n\nThere is a issues with mathematics most of the results and techniques are so rarely useful that students will soon forget most but a few very useful results. Having a good memory is a great asset in mathematics but is rarely enough. I like to review some mathematical results from my undergraduate days every five years or so. This helps me keep many of the results fresh in my mind and also makes reading new mathematics easier. Fundamentals in mathematics can fo a very long way. This is material from topology, determinants and solving linear equations, numerical methods for decomposing matrices, and so on. Definitions of certain groups.\nOne reason this and other Bayesian courses and books can be challenging and even overwhelming is that they can use lots of mathematics. This can range from high school material like complex numbers and quadratics formulas to intermediate results like finding root of characteristic polynomials, eigenvalues, Topelitz matrices, jordan forms, and advanced topics like the Durbin-Levinson recursion and certain results from functional analysis theory.\n\nNote that I have not even touched on probability and statistics in that list.\nRather than complain I see this as an opportunity to review/learn some mathematics and statistics that can be useful to a data scientist. During my last sting in Data science I often was able to write formulas but more often then not felt that I lacked sufficient mathematical tools to manipulate them to get the kind of results I wanted. Rather then learning lots of mathematics I wanted to find the most practical and useful results for wrangling maths. When I was a physics undergraduate these might be trigonometric identities, completing the square, being familiar with many integrals and Taylor or Maclaurin series approximations and a few useful inequalities occasionally we use l’Hopital’s rule. Familiarity with some ODEs was also greatly beneficial as these come up in many physical models. Later on hermitian and unitary matrices, fourier expansions, spectral theory, and some results from functional analysis were useful.\nFor statistics we have the variants of the law of large numbers and the central limit theorem, convergence theorems, manipulations of the normal distribution, linear properties of expectation can get you along way. But you have to remember lots of definitions and there are lots of results and theorems that seem to be stepping stones to other results rather than any practical use.\nOn the other hand conjugacy of certain distributions as demonstrated by Herbert Lee and other instructors in this specialization are often very challenging. Charts of Convergence of distributions to other distributions under certain conditions are neat but. There is Hoeffding’s inequality and the Markov’s inequality which can be useful but like most results in mathematics I never had a where they might be used. Then there are certain results - convergence of Markov chains, doubly stochastic matrices. De Finetti’s theorem in statistics.\nI have found that the more I learn the more I can understand and appreciate the material.\n\nThe autoregressive process gives rise to Toeplitz matrices which can be solved using the Durbin-Levinson recursion mentioned many times in the course.\nDurbin-Levinson recursion - is an advanced topic not covered in Numerical Analysis courses or Algebra courses I took.\nTo use it with time series we also need to understand the Yule-Walker equations.\nar(p) require some linear algebra concepts like eigenvalues and Eigenvectors, and characteristic polynomials.\nThe AR(p) the Wold decomposition theorem to get to the infinite order moving average representation and this is not a result I recall learning in my functional analysis course. We also use some complex numbers and Fourier analysis and spectral density functions.\n\nSummarize some of the extra curricular material I found useful in the course.\n\nComplex numbers\nEigenvalues, Eigenvectors and characteristic polynomials\nDurbin-Levinson recursion\nYule-Walker equations\nWiener process (Random walk)\nBrownian motion (Continuous Random walk with drift)\nMarkov Chains ()\nMartingales ()\nStopping theorem\nKalman filter\nWold’s theorem\nDe Finetti’s theorem\nCholesky decomposition\n\n\n\n87.2.2 Complex Numbers (Review)\nWhen we wish to find the roots of real valued polynomials we will often encounter complex numbers. In this course such polynomials arise naturally in the characteristic polynomials of AR(p) processes.\nWe will need the polar form of complex numbers to represent some variants of AR(p) process.\nThe numbers in the Complex field z \\in \\mathbb{C} numbers are numbers that can be expressed in the form z = a + bi, where a,b\\in\\mathbb{R} and i is the imaginary unit. The imaginary unit i is defined as the square root of -1. Complex numbers can be added, subtracted, multiplied, and divided just like real numbers.\nThe complex conjugate  of a complex number z = a + bi is denoted by \\bar{z} = a - bi. The magnitude of a complex number z = a + bi is denoted by |z| = \\sqrt{a^2 + b^2}. This is sometimes called the modulus of the complex number in this course. The argument of a complex number z = a + bi is denoted by \\text{arg}(z) = \\tan^{-1}(b/a). The polar form of a complex number is given by z = r e^{i \\theta}, where r = |z| and \\theta = \\text{arg}(z).complex conjugate\nThe polar form of a complex number is given by:\n\n\\begin{aligned}\nz &= \\mid z\\mid e^{i \\theta} \\\\\n  &= r (\\cos(\\theta) + i \\sin(\\theta))\n\\end{aligned}\n\\tag{87.1}\nwhere:\n\n|z| is the magnitude of the complex number, i.e. the distance from the origin to the point in the complex plane.\n\\theta is the angle of the complex number.\n\nI think we will also need the unit roots.\n\n\n87.2.3 Eigenvalues, Eigenvectors the characteristic polynomials and Unit roots\nThe Eigenvalues of a matrix are the roots of the characteristic polynomial of the matrix. The characteristic polynomial of a matrix A is defined as:\n\n\\begin{aligned}\n\\text{det}(A - \\lambda I) = 0\n\\end{aligned}\n\nwhere \\lambda is the Eigenvalue and I is the identity matrix. The eigenvectors of a matrix are the vectors that satisfy the equation:\n\n\\begin{aligned}\nA v = \\lambda v\n\\end{aligned}\n\nwhere v is the eigenvector and \\lambda is the eigenvalue. The eigenvalues and eigenvectors of a matrix are used in many applications in mathematics and physics, including the diagonalization of matrices, the solution of differential equations, and the analysis of dynamical systems.\n\n87.2.3.1 Unit Roots\nA unit root is a root of the characteristic polynomial of an autoregressive model that is equal to 1. The presence of a unit root in an autoregressive model indicates that the model is not stationary. The unit root test is a statistical test that is used to determine whether a time series is stationary or non-stationary. The unit root test is based on the null hypothesis that the time series has a unit root, and the alternative hypothesis that the time series is stationary. The unit root test is used to determine whether a time series is stationary or non-stationary, and is an important tool in time series analysis.\n\n\n\n87.2.4 Spectral analysis (1898)\nThe power spectrum of a signal is the squared absolute value of its Fourier transform. If it is estimated from the discrete Fourier transform it is also called periodogram. Usually estimated using the a fast Fourier transform (FFT) algorithm.\n\n\n87.2.5 Yule-Walker Equations (1932)\n\n\n87.2.6 Durbin-Levinson recursion (Off-Course Reading)\nLike me, you might be curious about the Durbin-Levinson recursion mentioned above. This is not covered in the course, and turned out to be an enigma wrapped in a mystery.\nI present my finding in the note below - much of it is due to (Wikipedia contributors 2024b) and (Wikipedia contributors 2024a)\nIn (Yule 1927) and (Walker 1931), Yule and Walker proposed a method for estimating the parameters of an autoregressive model. The method is based on the Yule-Walker equations which are a set of linear equations that can be used to estimate the parameters of an autoregressive model.\nDue to the autoregressive nature of the model, the equations are take a special form called a Toeplitz matrix. However at the time they probably had to use the numerically unstable Gauss-Jordan elimination to solve these equations which is O(n^3) in time complexity.\nA decade or two later in (Levinson 1946) and (Durbin 1960) the authors came up for with a weakly stable yet more efficient algorithm for solving these autocorrelated system of equations which requires only O(n^2) in time complexity. Later their work was further refined in (Trench 1964) and (Zohar 1969) to just 3\\times n^2 multiplication. A cursory search reveals that Toeplitz matrix inversion is still an area of active research with papers covering parallel algorithms and stability studies. Not surprising as man of the more interesting deep learning models, including LLMs are autoregressive.\nSo the Durbin-Levinson recursion is just an elegant bit of linear algebra for solving the Yule-Walker equations more efficiently.\nHere is what I dug up:\n\n\n87.2.7 Durbin-Levinson and the Yule-Walker equations (Off-Course Reading)\nThe Durbin-Levinson recursion is a method in linear algebra for computing the solution to an equation involving a Toeplitz matrix AKA a diagonal-constant matrix where descending diagonals are constant. The recursion runs in O(n^2) time rather then O(n^3) time required by Gauss-Jordan elimination.\nThe recursion can be used to compute the coefficients of the autoregressive model of a stationary time series. It is based on the Yule-Walker equations and is used to compute the PACF of a time series.\nThe Yule-Walker equations can be stated as follows for an AR(p) process:\n\n\\gamma_m = \\sum_{k=1}^p \\phi_k \\gamma_{m-k} + \\sigma_\\epsilon^2\\delta_{m,0} \\qquad \\text{(Yule-Walker equations)}\n\\tag{87.2}\nwhere:\n\n\\gamma_m is the autocovariance function of the time series,\n\\phi_k are the AR coefficients,\n\\sigma_\\epsilon^2 is the variance of the white noise process, and\n\\delta_{m,0} is the Kronecker delta function.\n\nwhen m=0 the equation simplifies to:\n\n\\gamma_0 = \\sum_{k=1}^p \\phi_k \\gamma_{-k} + \\sigma_\\epsilon^2 \\qquad \\text{(Yule-Walker equations for m=0)}\n\\tag{87.3}\nfor m &gt; 0 the equation simplifies to:\n\n  \\begin{bmatrix}\n    \\gamma_1 \\\\\n    \\gamma_2 \\\\\n    \\gamma_3 \\\\\n    \\vdots   \\\\\n    \\gamma_p\n  \\end{bmatrix} =  \n  \\begin{bmatrix}\n    \\gamma_0     & \\gamma_{-1}  & \\gamma_{-2}  & \\cdots \\\\\n    \\gamma_1     & \\gamma_0     & \\gamma_{-1}  & \\cdots \\\\\n    \\gamma_2     & \\gamma_1     & \\gamma_0     & \\cdots \\\\\n    \\vdots       & \\vdots       & \\vdots       & \\ddots \\\\\n    \\gamma_{p-1} & \\gamma_{p-2} & \\gamma_{p-3} & \\cdots\n\\end{bmatrix}  \n\\begin{bmatrix}\n    \\phi_{1} \\\\\n    \\phi_{2} \\\\\n    \\phi_{3} \\\\\n    \\vdots   \\\\\n    \\phi_{p}\n\\end{bmatrix}\n\n and since this matrix is Toeplitz, we can use Durbin-Levinson recursion to efficiently solve the system for \\phi_k \\forall k.\nOnce \\{\\phi_m \\qquad m=1,2, \\dots ,p \\} are known, we can consider m=0 and solved for \\sigma_\\epsilon^2 by substituting the \\phi_k into Equation 87.3 Yule-Walker equations.\nOf course the Durbin-Levinson recursion is not the last word on solving this system of equations. There are today numerous improvements which are both faster and more numerically stable.\nThe Yule-Walker equations are a set of p linear equations in the p unknowns \\phi_1, \\phi_2, \\ldots, \\phi_p that can be used to estimate the parameters of an autoregressive model of order p. The Yule-Walker equations are derived by setting the sample autocorrelation function equal to the theoretical autocorrelation function of an AR(p) model and then solving for the unknown parameters. The Yule-Walker equations are given by:\n\n\\begin{aligned}\n\\gamma(0) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(2) + \\ldots + \\phi_p \\gamma(p) \\\\\n\\gamma(1) & = \\phi_1 \\gamma(0) + \\phi_2 \\gamma(1) + \\ldots + \\phi_p \\gamma(p-1) \\\\\n\\gamma(2) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(0) + \\ldots + \\phi_p \\gamma(p-2) \\\\\n\\vdots \\\\\n\\gamma(p) & = \\phi_1 \\gamma(p-1) + \\phi_2 \\gamma(p-2) + \\ldots + \\phi_p \\gamma(0) \\\\\n\\end{aligned}\n\nwhere \\gamma(k) is the sample autocorrelation function at lag k. The Yule-Walker equations can be solved using matrix algebra to obtain the estimates of the AR parameters \\phi_1, \\phi_2, \\ldots, \\phi_p.\n\n\n87.2.8 Wold’s theorem - (extra curricular) circa 1939\nIn the 1920 George Udny Yule and Eugen Slutsky were researching time series and they came up with two different ways to represent a time series.\n\nYule’s researches led to the notion of the autoregressive scheme. \n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t}\n\\end{aligned}\n\\tag{87.4}\nSlutsky’s researches led to the notion of a moving average scheme. \n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{87.5}\n\nwe can use the two schemes together and get the ARMA(p,q) model:\n\n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t} + \\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{87.6}\nwhere:\nThe following is extracted from: the wikipedia at https://en.wikipedia.org/wiki/Wold%27s_theorem\nWold’s decomposition AKA called the Wold representation theorem states that:\n\nEvery covariance-stationary time series Y_{t} can be written as the sum of two time series, one deterministic and one stochastic.\n\nFormally:\n\n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{\\infty }  \\underbrace{b_{j}\\epsilon _{t-j}}_{\\text{stochastic}} + \\underbrace{\\eta _{t}}_{\\text{deterministic}} \\\\\n&= \\sum _{j=0}^{\\infty } b_{j}\\epsilon _{t-j} + \\phi_{j} y_{t-j}\n\\end{aligned}\n\nwhere:\n\n{Y_{t}} is the time series being considered,\n{\\epsilon _{t}} is an white noise sequence called innovation process that acts as an input to the linear filter {\\{b_{j}\\}}.\n{b} is the possibly infinite vector of moving average weights (coefficients or parameters)\n{\\eta _{t}} is a “deterministic” time series, in the sense that it is completely determined as a linear combination of its past values It may include “deterministic terms” like sine/cosine waves of {t}, but it is a stochastic process and it is also covariance-stationary, it cannot be an arbitrary deterministic process that violates stationarity.\n\nThe moving average coefficients have these properties:\n\nStable, that is, square summable \\sum _{j=1}^{\\infty } \\mid b_{j}|^{2} &lt; \\infty\nCausal (i.e. there are no terms with j &lt; 0)\nMinimum delay\nConstant (b_j independent of t)\nIt is conventional to define b_0=1\n\nAny stationary process has this seemingly special representation. Not only is the existence of such a simple linear and exact representation remarkable, but even more so is the special nature of the moving average model.\nThis result is used without stating its name in the course when we are show the AR(p) representation in terms of moving averages.",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#kalman-filter-1960",
    "href": "C4-L00.html#kalman-filter-1960",
    "title": "87  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "87.3 Kalman Filter (1960)",
    "text": "87.3 Kalman Filter (1960)\n\n\\begin{aligned}\nx_{t} & = F_{t} x_{t-1} + G_{t} u_{t} + w_{t} && \\text{(transition equation)} \\\\\ny_{t} & = H_{t} x_{t} + v_{t} && \\text{(observation equation)}\n\\end{aligned}\n\\tag{87.7}\nwhere:\n\nx_{t} is the state vector at time t,\nF_{t} is the state transition matrix,\nG_{t} is the control input matrix,\nu_{t} is the control vector,\nw_{t} is the process noise vector,\ny_{t} is the observation vector at time t,\nH_{t} is the observation matrix,\nv_{t} is the observation noise vector.\n\nThe Kalman filter is a recursive algorithm that estimates the state of a linear dynamic system from a series of noisy observations. The Kalman filter is based on a linear dynamical system model that is defined by two equations: the state transition equation and the observation equation. The state transition equation describes how the state of the system evolves over time, while the observation equation describes how the observations are generated from the state of the system. The Kalman filter uses these two equations to estimate the state of the system at each time step, based on the observations received up to that time step. This could be implemented in real time in the 1960s and was used in the Apollo missions.\nThe Extended Kalman Filter (EKF) is an extension of the Kalman filter that can be used to estimate the state of a nonlinear dynamic system. The EKF linearizes the nonlinear system model at each time step and then applies the Kalman filter to the linearized system. The EKF is an approximation to the true nonlinear system, and its accuracy depends on how well the linearized system approximates the true system.\n\n87.3.1 Box Jenkins Method (1970)\nsee Box Jenkins Method\nA five step process for identifying, selecting and assessing ARMA (and similar) models.\n\nThere are three courses on Stochastic Processes on MIT OCW that I found useful:\n\nIntroduction to Stochastic Processes\nDiscrete Stochastic Processes\nhas lecture videos and notes\npoisson processes\nAdvanced Stochastic Processes\nmartingales\nito calculus",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#bayesian-time-series-bibliography",
    "href": "C4-L00.html#bayesian-time-series-bibliography",
    "title": "87  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "87.4 Bayesian Time Series Bibliography",
    "text": "87.4 Bayesian Time Series Bibliography\nWe start with some books from the course, I collected here both the recommended books and some others that I found useful.\n\n87.4.1 Time Series: Modeling, Computation, and Inference\nc.f. (Prado, Ferreira, and West 2023)\n\n\n\n\nTime Series: Modeling, Computation, and Inference\n\n\nTitle:Time Series: Modeling, Computation, and Inference\nISBN:9781032040042, 1032040041\nPage count:452\nPublished:September 2023\nFormat:Paperback\nPublisher:CRC Press\nAuthors: Raquel Prado, Marco A. R. Ferreira, Mike West\n\n(Prado, Ferreira, and West 2023) “Time Series: Modeling, Computation, and Inference” by course instructor Raquel Prado. This book, now in its second edition is a comprehensive introduction to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nWhile learning this course I found some of the material harder to follow than I expected. The books helped to clarify definitions and so on however the book is\nrather comprehensive and mathematically advanced unlike some other books on statistics.\nThe teacher frequently point out that many aspects of Times series and are beyond the scope of the course. Yet this book covers much more ground like unequally spaced time series and vector valued time series.\nFor example we look at EKG data which the authors have been working on for years. However we look at it in this course in terms of a univariate time series while in reality EKG is usually sampled at 12 sites simultaneously yielding a multi-variate time series.\nOnce this course is done I will probably want to dive deeper into the subject and try to devote more time to other models in the book.\n\n\n\n87.4.2 Bayesian Forecasting and Dynamic Models\nc.f. (West and Harrison 2013)\n\n\n\n\nBayesian Forecasting and Dynamic Models\n\n\nTitle:Bayesian Forecasting and Dynamic Models\nISBN:9781475770971, 1475770979\nPage count:682\nPublished:March 17, 2013\nFormat:Paperback\nPublisher:Springer New York\nAuthor:Mike West, Jeff Harrison\n\n(West and Harrison 2013) “Bayesian Forecasting and Dynamic Models” by Mike West and Jeff Harrison. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian forecasting and dynamic models. The following is the description from the publisher:\n\nThe use of dynamic models in the forecasting of time series data has a long history, with the development of autoregressive integrated moving average (ARIMA) models and state space models. However, the use of Bayesian methods in the development of dynamic models is a relatively recent development. This book provides a comprehensive introduction to the use of Bayesian methods in the development of dynamic models for forecasting time series data. The book covers a wide range of topics, including the use of dynamic models in the analysis of time series data, the use of Bayesian methods in the development of dynamic models, and the use of dynamic models in the forecasting of time series data.\n\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n\n\n\n87.4.3 Practical Time Series Analysis\nc.f. (Nielsen 2019)\n\n\n\n\nPractical Times Series Analysis\n\n\nTitle:Practical Time Series Analysis: Prediction with Statistics and Machine Learning\nISBN:1492041602, 9781492041603\nPage count:504\nPublished:2019\nFormat:Paperback\nPublisher:O’Reilly Media, Inc.\n(Nielsen 2019) “Practical Time Series Analysis: Prediction with Statistics and Machine Learning” by Aileen Nielsen. Is a good resource for parctionars getting started with time series analysis. I also recommend any videos by Aileen Nielsen on the subject.\n\n\nPractical Times Series Analysis by Aileen Nielsen is a good book for beginners. It is a practical guide to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for beginners in statistics, computer science, and related fields.\nTime series data analysis is increasingly important due to the massive production of such data through the internet of things, the digitalization of healthcare, and the rise of smart cities. As continuous monitoring and data collection become more common, the need for competent time series analysis with both statistical and machine learning techniques will increase.\nCovering innovations in time series data analysis and use cases from the real world, this practical guide will help you solve the most common data engineering and analysis challenges in time series, using both traditional statistical and modern machine learning techniques. Author Aileen Nielsen offers an accessible, well-rounded introduction to time series in both R and Python that will have data scientists, software engineers, and researchers up and running quickly.\nYou’ll get the guidance you need to confidently:\n\nFind and wrangle time series data\nUndertake exploratory time series data analysis\nStore temporal data\nSimulate time series data\nGenerate and select features for a time series\nMeasure error\nForecast and classify time series with machine or deep learning\nEvaluate accuracy and performance\n\n\n\n\n87.4.3.1 “Machine Learning: A Bayesian and Optimization Perspective” by Sergios Theodoridis.\nc.f. (Theodoridis 2015)\n\n\n\n\nMachine Learning: A Bayesian and Optimization Perspective\n\n\nTitle:Machine Learning: A Bayesian and Optimization Perspective\nISBN:0128015225, 9780128015223\nPage count:1062\nPublished:2015\nFormat:Hardcover\nPublisher:Academic Press\nAuthors: Sergios Theodoridis\n\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks like a good book on machine learning. The following is the description from the publisher:\n\nThis tutorial text gives a unifying perspective on machine learning by covering both probabilistic and deterministic approaches -which are based on optimization techniques - together with the Bayesian inference approach, whose essence lies in the use of a hierarchy of probabilistic models. The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts.\nThe book builds carefully from the basic classical methods to the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models.\n\nAll major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods.\nThe latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling.\nCase studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied.\nMATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code.\n\n\n\n\n\n87.4.3.2 Statistical Analysis in Climate Research\nc.f.(Storch and Zwiers 2002)\n\n\n\n\nStatistical Analysis in Climate Research\n\n\nTitle:Statistical Analysis in Climate Research\nISBN:1139425099, 9781139425094\nPage count:484\nPublished:2002\nFormat:Paperback\nPublisher:Cambridge University Press\nAuthors: Hans von Storch, Francis W. Zwiers\n\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks promising. Here is the description from the publisher:\n\nClimatology is, to a large degree, the study of the statistics of our climate. The powerful tools of mathematical statistics therefore find wide application in climatological research. The purpose of this book is to help the climatologist understand the basic precepts of the statistician’s art and to provide some of the background needed to apply statistical methodology correctly and usefully. The book is self contained: introductory material, standard advanced techniques, and the specialised techniques used specifically by climatologists are all contained within this one source. There are a wealth of real-world examples drawn from the climate literature to demonstrate the need, power and pitfalls of statistical analysis in climate research. Suitable for graduate courses on statistics for climatic, atmospheric and oceanic science, this book will also be valuable as a reference source for researchers in climatology, meteorology, atmospheric science, and oceanography.\n\nHans von Storch is Director of the Institute of Hydrophysics of the GKSS Research Centre in Geesthacht, Germany and a Professor at the Meteorological Institute of the University of Hamburg.\nFrancis W. Zwiers is Chief of the Canadian Centre for Climate Modelling and Analysis, Atmospheric Environment Service, Victoria, Canada, and an Adjunct Professor at the Department of Mathematicw and Statistics of the University of Victoria.\n\n\n\n\n\n\n87.4.4 Bayesian Modeling and Computation in Python\nc.f. (Martin, Kumar, and Lao 2021)\n\n\n\n\nBayesian Modeling and Computation in Python\n\nThis is a great resource for translating what we learned to Python. The book is available at Bayesian Modeling and Computation in Python\nI found the chapter on state space modeling and the Kalman filter particularly useful. The book is a great resource for translating what we learned in the course to Python. The book is suitable for undergraduate students in statistics, computer science, and related fields.\n\n\n\n87.4.5 Bayesian Data Analysis\nc.f. (Gelman et al. 2013)\n\n\n\n\nBayesian Data Analysis\n\n\nTitle:Bayesian Data Analysis\nISBN:1439840954, 9781439840955\nPage count:675\nPublished:2013\nFormat:Hardcover\nPublisher:Chapman and Hall/CRC\nAuthors: Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, Donald B. Rubin\n\n(Gelman et al. 2013) “Bayesian Data Analysis” is probably the most famous book on Bayesian statistics. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian data analysis. Although this is not a time series book, the authors have been intersted in the domain of political election prediction and have used time series data in their research and some of that is covered in the book’s examples.\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nAn electronic version of the third eddition book is available at Bayesian Data Analysis\n\n\n\n\n87.4.6 Introductory Time Series with R c.f. (Cowpertwait and Metcalfe 2009)\n\n\n\n\nIntroductory Time Series with R\n\n(Cowpertwait and Metcalfe 2009) “Introductory Time Series with R” by Cowpertwait and Metcalfe, and the second is\n\nYearly global mean temperature and ocean levels, daily share prices, and the signals transmitted back to Earth by the Voyager space craft are all examples of sequential observations over time known as time series. This book gives you a step-by-step introduction to analysing time series using the open source software R. Each time series model is motivated with practical applications, and is defined in mathematical notation. Once the model has been introduced it is used to generate synthetic data, using R code, and these generated data are then used to estimate its parameters. This sequence enhances understanding of both the time series model and the R function used to fit the model to data. Finally, the model is used to analyse observed data taken from a practical application. By using R, the whole procedure can be reproduced by the reader.\nAll the data sets used in the book are available on the website at datasets\nThe book is written for undergraduate students of mathematics, economics, business and finance, geography, engineering and related disciplines, and postgraduate students who may need to analyse time series as part of their taught programme or their research.\n\nPaul Cowpertwait is an associate professor in mathematical sciences (analytics) at Auckland University of Technology with a substantial research record in both the theory and applications of time series and stochastic models.\nAndrew Metcalfe is an associate professor in the School of Mathematical Sciences at the University of Adelaide, and an author of six statistics text books and numerous research papers. Both authors have extensive experience of teaching time series to students at all levels.\n\n\n\n\n\n87.4.7 Analysis of Integrated and Cointegrated Time Series with R c.f.\n\n\n\n\nAnalysis of Integrated and Cointegrated Time Series with R\n\n(Pfaff 2008) “Analysis of Integrated and Cointegrated Time Series with R” by Bernhard Pfaff. Its been a long time since I read this book and rather than do it an injustice I direct you to the review by Dirk Eddelbuettel in the Journal of Statistical Software is avaoilable at review. Or the book’s website at Analysis of Integrated and Cointegrated Time Series with R.\n\nThe analysis of integrated and co-integrated time series can be considered as the main methodology employed in applied econometrics. This book not only introduces the reader to this topic but enables him to conduct the various unit root tests and co-integration methods on his own by utilizing the free statistical programming environment R. The book encompasses seasonal unit roots, fractional integration, coping with structural breaks, and multivariate time series models. The book is enriched by numerous programming examples to artificial and real data so that it is ideally suited as an accompanying text book to computer lab classes.\nThe second edition adds a discussion of vector auto-regressive, structural vector auto-regressive, and structural vector error-correction models.\n\n\n\n87.4.8 Bayesian Analysis of Time Series by Lyle D. Broemeling\n(Broemeling 2019)\n\ncovers pretty much the material in the course.\nuses winbugs and R\nmodels considered include\n\nwhite noise\nWiener process (random walk)\nAR(p)\nARMA(p,q)\nARIMA\nRegression\nRegression with MA and Seasonal effects\nDLM\nTAR\n\n\n\n\n87.4.9 Bayesian Inference for Stochastic Processes by Lyle D. Broemeling\n\n\n\n\nBayesian Inference for Stochastic Processes by Lyle D. Broemeling\n\n\nThe code for R and WinBUGS is available at code\nIT is based on WinBUGS which is a bit dated but still useful.\nThis books seems a bit dated but it covers a lot of the material in the course.\n\n\n\n87.4.10 Dynamic Time Series Models using R-INLA: An Applied Perspective\n(Ravishanker, Raman, and Soyer 2022) is a new book that covers the use of the R-INLA package for fitting dynamic time series models. The book is available online gitbook\n\n\n\n\nDynamic Time Series Models using R-INLA: An Applied Perspective\n\nThis is a very interesting book which covers a new approach to fitting time series models using the R-INLA package. INLA stands for Integrated Nested Laplace Approximation and is a method for fitting Bayesian models that is faster than MCMC. The book covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n87.4.11 Statistics for Spatio-Temporal Data\n\n\n\n\nStatistics for Spatio-Temporal Data\n\n(Cressie and Wikle 2011) is a book I came across when I tried to understand the NDLM model. NLDMs have a two level hierarcial form and it seems possible to extend this formulation will non-normaly distributed shocks and possibly non linear relation. In this book the authors take an interesting approch of not only looking at NDLM as a heirarchical model but they also extend the time series model into a spatio-temporal model.\nThis book is a comprehensive introduction to the analysis of spatio-temporal data and covers a wide range of topics in spatio-temporal statistics. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#bayesian-analysis-of-stochastic-process-models",
    "href": "C4-L00.html#bayesian-analysis-of-stochastic-process-models",
    "title": "87  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "87.5 Bayesian Analysis of Stochastic Process Models",
    "text": "87.5 Bayesian Analysis of Stochastic Process Models\nc.f. (Rios Insua, Ruggeri, and Wiper 2012)\n\n\n\n\nBayesian Analysis of Stochastic Process Models\n\nDavid Rios Insua, Fabrizio Ruggeri, Michael P. Wiper\nThis book is a comprehensive introduction to the analysis of stochastic process models using Bayesian methods. The book covers a wide range of topics in stochastic process modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nThere are also a number of books on NDLM that I’ve come across:\n\nDynamic linear model tutorial matlab\nForecasting, structural time series and the Kalman filter by Andrew C. Harvey\nDynamic Linear Models with R by Giovanni Petris Sonia Petrone Patrizia Campagnoli\nTime Series Analysis by State Space Methods by J. Durbin and S.J. Koopman\n\n\n\n\n\n\n\nBroemeling, Lyle D. 2019. Bayesian Analysis of Time Series. CRC Press.\n\n\nCowpertwait, P. S. P., and A. V. Metcalfe. 2009. Introductory Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=QFiZGQmvRUQC.\n\n\nCressie, N., and C. K. Wikle. 2011. Statistics for Spatio-Temporal Data. CourseSmart Series. Wiley. https://books.google.co.il/books?id=-kOC6D0DiNYC.\n\n\nDurbin, J. 1960. “The Fitting of Time-Series Models.” Revue de l’Institut International de Statistique / Review of the International Statistical Institute 28 (3): 233–44. http://www.jstor.org/stable/1401322.\n\n\nGelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. Bayesian Data Analysis, Third Edition. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis. https://books.google.co.il/books?id=ZXL6AQAAQBAJ.\n\n\nLevinson, Norman. 1946. “The Wiener (Root Mean Square) Error Criterion in Filter Design and Prediction.” Journal of Mathematics and Physics 25 (1-4): 261–78. https://doi.org/https://doi.org/10.1002/sapm1946251261.\n\n\nMartin, Osvaldo A., Ravin Kumar, and Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. Boca Raton.\n\n\nNielsen, A. 2019. Practical Time Series Analysis: Prediction with Statistics and Machine Learning. O’Reilly Media. https://books.google.co.il/books?id=xNOwDwAAQBAJ.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=ca5MkRbF3fYC.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nRavishanker, N., B. Raman, and R. Soyer. 2022. Dynamic Time Series Models Using r-INLA: An Applied Perspective. CRC Press. https://books.google.co.il/books?id=e6h6EAAAQBAJ.\n\n\nRios Insua, David, Fabrizio Ruggeri, and Michael P Wiper. 2012. Bayesian Analysis of Stochastic Process Models. John Wiley & Sons.\n\n\nStorch, H. von, and F. W. Zwiers. 2002. Statistical Analysis in Climate Research. Cambridge University Press. https://books.google.co.il/books?id=bs8hAwAAQBAJ.\n\n\nTheodoridis, S. 2015. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science. https://books.google.co.il/books?id=hxQRogEACAAJ.\n\n\nTrench, William F. 1964. “An Algorithm for the Inversion of Finite Toeplitz Matrices.” Journal of the Society for Industrial and Applied Mathematics 12 (3): 515–22. http://ramanujan.math.trinity.edu/wtrench/research/papers/TRENCH_RP_6.PDF.\n\n\nWalker, Gilbert Thomas. 1931. “On Periodicity in Series of Related Terms.” Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character 131 (818): 518–32. https://doi.org/10.1098/rspa.1931.0069.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.\n\n\nWikipedia contributors. 2024a. “Autoregressive Model — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Autoregressive_model&oldid=1233171855#Estimation_of_AR_parameters.\n\n\n———. 2024b. “Levinson Recursion — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Levinson_recursion&oldid=1229942891.\n\n\nYule, George Udny. 1927. “VII. On a Method of Investigating Periodicities Disturbed Series, with Special Reference to Wolfer’s Sunspot Numbers.” Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character 226 (636-646): 267–98. https://doi.org/10.1098/rsta.1927.0007.\n\n\nZohar, Shalhav. 1969. “Toeplitz Matrix Inversion: The Algorithm of w. F. Trench.” J. ACM 16: 592–601. https://api.semanticscholar.org/CorpusID:3115290.",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "A12.html",
    "href": "A12.html",
    "title": "103  Bayesian Books in R & Python",
    "section": "",
    "text": "103.1 Introduction to Probability\nThere are many books in R and Python that can help you learn more about these languages and how to use them for data analysis.\nHere are some of the most popular books on R and Python:",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#introduction-to-probability",
    "href": "A12.html#introduction-to-probability",
    "title": "103  Bayesian Books in R & Python",
    "section": "",
    "text": "Introduction to Probability by Dennis L. Sun",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#sec-bayesian-books",
    "href": "A12.html#sec-bayesian-books",
    "title": "103  Bayesian Books in R & Python",
    "section": "103.2 Books in R",
    "text": "103.2 Books in R\n\nR for Data Science by Hadley Wickham & Garrett Grolemund\nAdvanced R by Hadley Wickham\nggplot2: Elegant Graphics for Data Analysis (3e)\nR Graphics Cookbook, 2nd edition\nAn Introduction to Statistical Learning\nEngineering Production-Grade Shiny Apps\nForecasting: Principles and Practice (3rd ed)\nExploratory Data Analysis with R Roger D. Peng\nModern R with the tidyverse by Bruno Rodrigues\nModern Statistics with R by Benjamin S. Baumer, Daniel T. Kaplan, and Nicholas J. Horton\nMastering Shiny by Hadley Wickham, Winston Chang, and Joe Cheng\nLearning Statistics with R by Danielle Navarro\nText Mining with R by Julia Silge and David Robinson",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#books-in-python",
    "href": "A12.html#books-in-python",
    "title": "103  Bayesian Books in R & Python",
    "section": "103.3 Books in Python",
    "text": "103.3 Books in Python\n\nAn Introduction to Statistical Learning with python by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\nPython for Data Analysis by Wes McKinney of Pandas infamy parquet and Apache Arrow\nPython Data Science Handbook by Jake VanderPlas\nThink Stats by Allen B. Downey\nThink Bayes by Allen B. Downey\nProbabilistic Programming & Bayesian Methods for Hackers by Cameron Davidson-Pilon",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#bayesian-time-series-bibliography",
    "href": "A12.html#bayesian-time-series-bibliography",
    "title": "103  Bayesian Books in R & Python",
    "section": "103.4 Bayesian Time Series Bibliography",
    "text": "103.4 Bayesian Time Series Bibliography\nWe start with some books from the course, I collected here both the recommended books and some others that I found useful.\n\n103.4.1 Time Series: Modeling, Computation, and Inference\nc.f. (Prado, Ferreira, and West 2023)\n\n\n\n\nTime Series: Modeling, Computation, and Inference\n\n\nTitle:Time Series: Modeling, Computation, and Inference\nISBN:9781032040042, 1032040041\nPage count:452\nPublished:September 2023\nFormat:Paperback\nPublisher:CRC Press\nAuthors: Raquel Prado, Marco A. R. Ferreira, Mike West\n\n(Prado, Ferreira, and West 2023) “Time Series: Modeling, Computation, and Inference” by course instructor Raquel Prado. This book, now in its second edition is a comprehensive introduction to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nWhile learning this course I found some of the material harder to follow than I expected. The books helped to clarify definitions and so on however the book is\nrather comprehensive and mathematically advanced unlike some other books on statistics.\nThe teacher frequently point out that many aspects of Times series and are beyond the scope of the course. Yet this book covers much more ground like unequally spaced time series and vector valued time series.\nFor example we look at EKG data which the authors have been working on for years. However we look at it in this course in terms of a univariate time series while in reality EKG is usually sampled at 12 sites simultaneously yielding a multi-variate time series.\nOnce this course is done I will probably want to dive deeper into the subject and try to devote more time to other models in the book.\n\n\n\n103.4.2 Bayesian Forecasting and Dynamic Models\nc.f. (West and Harrison 2013)\n\n\n\n\nBayesian Forecasting and Dynamic Models\n\n\nTitle:Bayesian Forecasting and Dynamic Models\nISBN:9781475770971, 1475770979\nPage count:682\nPublished:March 17, 2013\nFormat:Paperback\nPublisher:Springer New York\nAuthor:Mike West, Jeff Harrison\n\n(West and Harrison 2013) “Bayesian Forecasting and Dynamic Models” by Mike West and Jeff Harrison. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian forecasting and dynamic models. The following is the description from the publisher:\n\nThe use of dynamic models in the forecasting of time series data has a long history, with the development of autoregressive integrated moving average (ARIMA) models and state space models. However, the use of Bayesian methods in the development of dynamic models is a relatively recent development. This book provides a comprehensive introduction to the use of Bayesian methods in the development of dynamic models for forecasting time series data. The book covers a wide range of topics, including the use of dynamic models in the analysis of time series data, the use of Bayesian methods in the development of dynamic models, and the use of dynamic models in the forecasting of time series data.\n\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n\n\n\n103.4.3 Practical Time Series Analysis\nc.f. (Nielsen 2019)\n\n\n\n\nPractical Times Series Analysis\n\n\nTitle:Practical Time Series Analysis: Prediction with Statistics and Machine Learning\nISBN:1492041602, 9781492041603\nPage count:504\nPublished:2019\nFormat:Paperback\nPublisher:O’Reilly Media, Inc.\n(Nielsen 2019) “Practical Time Series Analysis: Prediction with Statistics and Machine Learning” by Aileen Nielsen. Is a good resource for parctionars getting started with time series analysis. I also recommend any videos by Aileen Nielsen on the subject.\n\n\nPractical Times Series Analysis by Aileen Nielsen is a good book for beginners. It is a practical guide to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for beginners in statistics, computer science, and related fields.\nTime series data analysis is increasingly important due to the massive production of such data through the internet of things, the digitalization of healthcare, and the rise of smart cities. As continuous monitoring and data collection become more common, the need for competent time series analysis with both statistical and machine learning techniques will increase.\nCovering innovations in time series data analysis and use cases from the real world, this practical guide will help you solve the most common data engineering and analysis challenges in time series, using both traditional statistical and modern machine learning techniques. Author Aileen Nielsen offers an accessible, well-rounded introduction to time series in both R and Python that will have data scientists, software engineers, and researchers up and running quickly.\nYou’ll get the guidance you need to confidently:\n\nFind and wrangle time series data\nUndertake exploratory time series data analysis\nStore temporal data\nSimulate time series data\nGenerate and select features for a time series\nMeasure error\nForecast and classify time series with machine or deep learning\nEvaluate accuracy and performance\n\n\n\n\n103.4.3.1 “Machine Learning: A Bayesian and Optimization Perspective” by Sergios Theodoridis.\nc.f. (Theodoridis 2015)\n\n\n\n\nMachine Learning: A Bayesian and Optimization Perspective\n\n\nTitle:Machine Learning: A Bayesian and Optimization Perspective\nISBN:0128015225, 9780128015223\nPage count:1062\nPublished:2015\nFormat:Hardcover\nPublisher:Academic Press\nAuthors: Sergios Theodoridis\n\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks like a good book on machine learning. The following is the description from the publisher:\n\nThis tutorial text gives a unifying perspective on machine learning by covering both probabilistic and deterministic approaches -which are based on optimization techniques - together with the Bayesian inference approach, whose essence lies in the use of a hierarchy of probabilistic models. The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts.\nThe book builds carefully from the basic classical methods to the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models.\n\nAll major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods.\nThe latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling.\nCase studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied.\nMATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code.\n\n\n\n\n\n103.4.3.2 Statistical Analysis in Climate Research\nc.f.(Storch and Zwiers 2002)\n\n\n\n\nStatistical Analysis in Climate Research\n\n\nTitle:Statistical Analysis in Climate Research\nISBN:1139425099, 9781139425094\nPage count:484\nPublished:2002\nFormat:Paperback\nPublisher:Cambridge University Press\nAuthors: Hans von Storch, Francis W. Zwiers\n\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks promising. Here is the description from the publisher:\n\nClimatology is, to a large degree, the study of the statistics of our climate. The powerful tools of mathematical statistics therefore find wide application in climatological research. The purpose of this book is to help the climatologist understand the basic precepts of the statistician’s art and to provide some of the background needed to apply statistical methodology correctly and usefully. The book is self contained: introductory material, standard advanced techniques, and the specialised techniques used specifically by climatologists are all contained within this one source. There are a wealth of real-world examples drawn from the climate literature to demonstrate the need, power and pitfalls of statistical analysis in climate research. Suitable for graduate courses on statistics for climatic, atmospheric and oceanic science, this book will also be valuable as a reference source for researchers in climatology, meteorology, atmospheric science, and oceanography.\n\nHans von Storch is Director of the Institute of Hydrophysics of the GKSS Research Centre in Geesthacht, Germany and a Professor at the Meteorological Institute of the University of Hamburg.\nFrancis W. Zwiers is Chief of the Canadian Centre for Climate Modelling and Analysis, Atmospheric Environment Service, Victoria, Canada, and an Adjunct Professor at the Department of Mathematicw and Statistics of the University of Victoria.\n\n\n\n\n\n\n103.4.4 Bayesian Modeling and Computation in Python\nc.f. (Martin, Kumar, and Lao 2021)\n\n\n\n\nBayesian Modeling and Computation in Python\n\nThis is a great resource for translating what we learned to Python. The book is available at Bayesian Modeling and Computation in Python\nI found the chapter on state space modeling and the Kalman filter particularly useful. The book is a great resource for translating what we learned in the course to Python. The book is suitable for undergraduate students in statistics, computer science, and related fields.\n\n\n\n103.4.5 Bayesian Data Analysis\nc.f. (Gelman et al. 2013)\n\n\n\n\nBayesian Data Analysis\n\n\nTitle:Bayesian Data Analysis\nISBN:1439840954, 9781439840955\nPage count:675\nPublished:2013\nFormat:Hardcover\nPublisher:Chapman and Hall/CRC\nAuthors: Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, Donald B. Rubin\n\n(Gelman et al. 2013) “Bayesian Data Analysis” is probably the most famous book on Bayesian statistics. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian data analysis. Although this is not a time series book, the authors have been intersted in the domain of political election prediction and have used time series data in their research and some of that is covered in the book’s examples.\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nAn electronic version of the third eddition book is available at Bayesian Data Analysis\n\n\n\n\n103.4.6 Introductory Time Series with R c.f. (Cowpertwait and Metcalfe 2009)\n\n\n\n\nIntroductory Time Series with R\n\n(Cowpertwait and Metcalfe 2009) “Introductory Time Series with R” by Cowpertwait and Metcalfe, and the second is\n\nYearly global mean temperature and ocean levels, daily share prices, and the signals transmitted back to Earth by the Voyager space craft are all examples of sequential observations over time known as time series. This book gives you a step-by-step introduction to analyzing time series using the open source software R. Each time series model is motivated with practical applications, and is defined in mathematical notation. Once the model has been introduced it is used to generate synthetic data, using R code, and these generated data are then used to estimate its parameters. This sequence enhances understanding of both the time series model and the R function used to fit the model to data. Finally, the model is used to analyze observed data taken from a practical application. By using R, the whole procedure can be reproduced by the reader.\nAll the data sets used in the book are available on the website at datasets\nThe book is written for undergraduate students of mathematics, economics, business and finance, geography, engineering and related disciplines, and postgraduate students who may need to analyse time series as part of their taught programme or their research.\n\nPaul Cowpertwait is an associate professor in mathematical sciences (analytics) at Auckland University of Technology with a substantial research record in both the theory and applications of time series and stochastic models.\nAndrew Metcalfe is an associate professor in the School of Mathematical Sciences at the University of Adelaide, and an author of six statistics text books and numerous research papers. Both authors have extensive experience of teaching time series to students at all levels.\n\n\n\n\n\n103.4.7 Analysis of Integrated and Cointegrated Time Series with R c.f.\n\n\n\n\nAnalysis of Integrated and Cointegrated Time Series with R\n\n(Pfaff 2008) “Analysis of Integrated and Cointegrated Time Series with R” by Bernhard Pfaff. Its been a long time since I read this book and rather than do it an injustice I direct you to the review by Dirk Eddelbuettel in the Journal of Statistical Software is avaoilable at review. Or the book’s website at Analysis of Integrated and Cointegrated Time Series with R.\n\nThe analysis of integrated and co-integrated time series can be considered as the main methodology employed in applied econometrics. This book not only introduces the reader to this topic but enables him to conduct the various unit root tests and co-integration methods on his own by utilizing the free statistical programming environment R. The book encompasses seasonal unit roots, fractional integration, coping with structural breaks, and multivariate time series models. The book is enriched by numerous programming examples to artificial and real data so that it is ideally suited as an accompanying text book to computer lab classes.\nThe second edition adds a discussion of vector auto-regressive, structural vector auto-regressive, and structural vector error-correction models.\n\n\n\n103.4.8 Bayesian Analysis of Time Series by Lyle D. Broemeling\n(Broemeling 2019)\n\ncovers pretty much the material in the course.\nuses winbugs and R\nmodels considered include\n\nwhite noise\nWiener process (random walk)\nAR(p)\nARMA(p,q)\nARIMA\nRegression\nRegression with MA and Seasonal effects\nDLM\nTAR\n\n\n\n\n103.4.9 Bayesian Inference for Stochastic Processes by Lyle D. Broemeling\n\n\n\n\nBayesian Inference for Stochastic Processes by Lyle D. Broemeling\n\n\nThe code for R and WinBUGS is available at code\nIT is based on WinBUGS which is a bit dated but still useful.\nThis books seems a bit dated but it covers a lot of the material in the course.\n\n\n\n103.4.10 Dynamic Time Series Models using R-INLA: An Applied Perspective\n(Ravishanker, Raman, and Soyer 2022) is a new book that covers the use of the R-INLA package for fitting dynamic time series models. The book is available online gitbook\n\n\n\n\nDynamic Time Series Models using R-INLA: An Applied Perspective\n\nThis is a very interesting book which covers a new approach to fitting time series models using the R-INLA package. INLA stands for Integrated Nested Laplace Approximation and is a method for fitting Bayesian models that is faster than MCMC. The book covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n103.4.11 Statistics for Spatio-Temporal Data\n\n\n\n\nStatistics for Spatio-Temporal Data\n\n(Cressie and Wikle 2011) is a book I came across when I tried to understand the NDLM model. NDLMs have a two level hierarchical form and it seems possible to extend this formulation will non-normally distributed shocks and possibly non linear relation. In this book the authors take an interesting approach of not only looking at NDLM as a hierarchical model but they also extend the time series model into a spatio-temporal model.\nThis book is a comprehensive introduction to the analysis of spatio-temporal data and covers a wide range of topics in spatio-temporal statistics. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#bayesian-analysis-of-stochastic-process-models",
    "href": "A12.html#bayesian-analysis-of-stochastic-process-models",
    "title": "103  Bayesian Books in R & Python",
    "section": "103.5 Bayesian Analysis of Stochastic Process Models",
    "text": "103.5 Bayesian Analysis of Stochastic Process Models\nc.f. (Rios Insua, Ruggeri, and Wiper 2012)\n\n\n\n\nBayesian Analysis of Stochastic Process Models\n\nDavid Rios Insua, Fabrizio Ruggeri, Michael P. Wiper\nThis book is a comprehensive introduction to the analysis of stochastic process models using Bayesian methods. The book covers a wide range of topics in stochastic process modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nThere are also a number of books on NDLM that I’ve come across:\n\nDynamic linear model tutorial matlab\nForecasting, structural time series and the Kalman filter by Andrew C. Harvey\nDynamic Linear Models with R by Giovanni Petris Sonia Petrone Patrizia Campagnoli\nTime Series Analysis by State Space Methods by J. Durbin and S.J. Koopman\n\n\n\n\n\n\n\nBroemeling, Lyle D. 2019. Bayesian Analysis of Time Series. CRC Press.\n\n\nCowpertwait, P. S. P., and A. V. Metcalfe. 2009. Introductory Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=QFiZGQmvRUQC.\n\n\nCressie, N., and C. K. Wikle. 2011. Statistics for Spatio-Temporal Data. CourseSmart Series. Wiley. https://books.google.co.il/books?id=-kOC6D0DiNYC.\n\n\nGelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. Bayesian Data Analysis, Third Edition. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis. https://books.google.co.il/books?id=ZXL6AQAAQBAJ.\n\n\nMartin, Osvaldo A., Ravin Kumar, and Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. Boca Raton.\n\n\nNielsen, A. 2019. Practical Time Series Analysis: Prediction with Statistics and Machine Learning. O’Reilly Media. https://books.google.co.il/books?id=xNOwDwAAQBAJ.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=ca5MkRbF3fYC.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nRavishanker, N., B. Raman, and R. Soyer. 2022. Dynamic Time Series Models Using r-INLA: An Applied Perspective. CRC Press. https://books.google.co.il/books?id=e6h6EAAAQBAJ.\n\n\nRios Insua, David, Fabrizio Ruggeri, and Michael P Wiper. 2012. Bayesian Analysis of Stochastic Process Models. John Wiley & Sons.\n\n\nStorch, H. von, and F. W. Zwiers. 2002. Statistical Analysis in Climate Research. Cambridge University Press. https://books.google.co.il/books?id=bs8hAwAAQBAJ.\n\n\nTheodoridis, S. 2015. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science. https://books.google.co.il/books?id=hxQRogEACAAJ.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "C2-L06-Ex1.html",
    "href": "C2-L06-Ex1.html",
    "title": "39  Homework on the Gibbs-Sampling algorithm - M2L5HW1",
    "section": "",
    "text": "Caution\n\n\n\nSection omitted to comply with the Honor Code",
    "crumbs": [
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Homework on the Gibbs-Sampling algorithm - M2L5HW1</span>"
    ]
  },
  {
    "objectID": "C2-L05.html",
    "href": "C2-L05.html",
    "title": "36  Gibbs sampling - M2L5",
    "section": "",
    "text": "36.0.1 Multiple parameter sampling and full conditional distributions (Video)\nGibbs sampling is a Gibbs sampling is named after the physicist Josiah Willard Gibbs, in reference to an analogy between the sampling algorithm and statistical physics. The algorithm was described in (Geman and Geman 1984) by brothers Stuart and Donald Geman, and became popularized in the statistics community for calculating marginal probability distribution, especially the posterior distribution. Gibbs sampling is better suited for sampling from models with many variables by sampling them one at a time from a full conditional distribution.\nSo far, we have demonstrated MCMC for a single parameter.\nWhat if we seek the posterior distribution of multiple parameters, and that posterior distribution does not have a standard form?\nOne option is to perform Metropolis-Hastings (M-H) by sampling candidates for all parameters at once, and accepting or rejecting all of those candidates together. While this is possible, it can get complicated.\nAnother (simpler) option is to sample the parameters one at a time.\nAs a simple example, suppose we have a joint posterior distribution for two parameters \\theta and \\phi, written \\mathbb{P}r(\\theta, \\phi \\mid y) \\propto g(\\theta, \\phi). If we knew the value of \\phi, then we would just draw a candidate for \\theta and use g(\\theta, \\phi) to compute our Metropolis-Hastings ratio, and possibly accept the candidate. Before moving on to the next iteration, if we don’t know \\phi, then we can perform a similar update for it. Draw a candidate for \\phi using some proposal distribution and again use g(\\theta, \\phi) to compute our Metropolis-Hastings ratio. Here we pretend we know the value of \\theta by substituting its current iteration from the Markov chain. Once we’ve drawn for both \\theta and \\phi, that completes one iteration and we begin the next iteration by drawing a new \\theta. In other words, we’re just going back and forth, updating the parameters one at a time, plugging the current value of the other parameter into g(\\theta, \\phi).\nThis idea of one-at-a-time updates is used in what we call Gibbs sampling, which also produces a stationary Markov chain (whose stationary distribution is the posterior). If you recall, this is the namesake of JAGS, “just another Gibbs sampler.”",
    "crumbs": [
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>M2L5 - Gibbs sampling</span>"
    ]
  },
  {
    "objectID": "C2-L05.html#sec-conditionally-conjugate-prior-with-normal-likelihood",
    "href": "C2-L05.html#sec-conditionally-conjugate-prior-with-normal-likelihood",
    "title": "36  Gibbs sampling - M2L5",
    "section": "36.1 Conditionally conjugate prior example with Normal likelihood (Video)",
    "text": "36.1 Conditionally conjugate prior example with Normal likelihood (Video)\n\n36.1.1 Normal likelihood, unknown mean and variance\n\n\n\n\nNormal likelihood, unknown mean and variance\n\n\n\n\nNormal likelihood conjugate prior\n\n\nLet’s return to the example at the end of Lesson 2 where we have normal likelihood with unknown mean and unknown variance. The model is:\n\n\\begin{aligned}\ny_i \\mid \\mu, \\sigma^2 &\\overset{\\text{iid}}{\\sim} \\mathcal{N} ( \\mu, \\sigma^2 ), \\quad i=1,\\ldots,n \\\\\n\\mu &\\sim \\mathcal{N}(\\mu_0, \\sigma_0^2) \\\\\n\\sigma^2 &\\sim \\mathcal{IG}(\\nu_0, \\beta_0)  \\, .\n\\end{aligned}\n\nWe chose a normal prior for \\mu because, in the case where \\sigma^2 is known, the normal is the conjugate prior for \\mu. Likewise, in the case where \\mu is known, the inverse-gamma is the conjugate prior for \\sigma^2. This will give us convenient full conditional distributions in a Gibbs sampler.\nLet’s first work out the form of the full posterior distribution. When we begin analyzing data, the JAGS software will complete this step for us. However, it is extremely valuable to see and understand how this works.\n\n\\begin{aligned}\n\\mathbb{P}r( \\mu, \\sigma^2 \\mid y_1, y_2, \\ldots, y_n ) &\\propto\n\\mathbb{P}r(y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma^2) \\mathbb{P}r(\\mu) \\mathbb{P}r(\\sigma^2)\n\\\\ &= \\prod_{i=1}^n \\mathcal{N} ( y_i \\mid \\mu, \\sigma^2 ) \\times \\mathcal{N}( \\mu \\mid \\mu_0, \\sigma_0^2) \\times \\mathcal{IG}(\\sigma^2 \\mid \\nu_0, \\beta_0)\n\\\\ &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp \\left[ -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right]\n\\\\ & \\qquad \\times\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}} \\exp \\left[ -\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right]\n\\\\ & \\qquad \\times \\frac{\\beta_0^{\\nu_0}}{\\Gamma(\\nu_0)}(\\sigma^2)^{-(\\nu_0 + 1)} \\exp \\left[ -\\frac{\\beta_0}{\\sigma^2} \\right] \\mathbb{I}_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\\\ &\\propto (\\sigma^2)^{-n/2} \\exp \\left[ -\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} \\right]\n\\\\ & \\qquad \\times \\exp \\left[ -\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right] (\\sigma^2)^{-(\\nu_0 + 1)}\n\\\\ & \\qquad \\times \\exp \\left[ -\\frac{\\beta_0}{\\sigma^2} \\right] \\mathbb{I}_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\end{aligned}\n\nFrom here, it is easy to continue on to find the two full conditional distributions we need.\nFirst let’s look at \\mu, assuming \\sigma^2 is known (in which case it becomes a constant and is absorbed into the normalizing constant):\n\n\\begin{aligned}\n\\mathbb{P}r(\\mu \\mid \\sigma^2, y_1, \\ldots, y_n) &\\propto \\mathbb{P}r( \\mu, \\sigma^2 \\mid y_1, \\ldots, y_n )\n\\\\ &\\propto \\exp \\left[ -\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} \\right] \\exp \\left[ -\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right]\n\\\\ &\\propto \\exp \\left[ -\\frac{1}{2} \\left( \\frac{ \\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} + \\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right) \\right]\n\\\\ &\\propto \\text{N} \\left( \\mu \\mid \\frac{n\\bar{y}/\\sigma^2 + \\mu_0/\\sigma_0^2}{n/\\sigma^2 + 1/\\sigma_0^2} \\frac{1}{n/\\sigma^2 + 1/\\sigma_0^2} \\right)\n\\end {aligned}\n\\tag{36.1}\nwhich we derived in the supplementary material of the last course. So, given the data and \\sigma^2, \\mu follows this normal distribution.\nNow let’s look at \\sigma^2, assuming \\mu is known:\n\n\\begin{aligned}\n\\mathbb{P}r(\\sigma^2 \\mid \\mu, y_1, \\ldots, y_n) & \\propto \\mathbb{P}r( \\mu, \\sigma^2 \\mid y_1, \\ldots, y_n )\n\\\\ &\\propto (\\sigma^2)^{-n/2} \\exp \\left[ -\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} \\right] (\\sigma^2)^{-(\\nu_0 + 1)} \\exp \\left[ -\\frac{\\beta_0}{\\sigma^2} \\right] I_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\\\ &\\propto (\\sigma^2)^{-(\\nu_0 + n/2 + 1)} \\exp \\left[ -\\frac{1}{\\sigma^2} \\left( \\beta_0 + \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2} \\right) \\right] I_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\\\ &\\propto \\text{IG}\\left( \\sigma^2 \\mid \\nu_0 + \\frac{n}{2}, \\, \\beta_0 + \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2} \\right)\n\\end{aligned}\n\\tag{36.2}\nThese two distributions provide the basis of a Gibbs sampler to simulate from a Markov chain whose stationary distribution is the full posterior of both \\mu and \\sigma^2. We simply alternate draws between these two parameters, using the most recent draw of one parameter to update the other.\nWe will do this in R in the next segment.",
    "crumbs": [
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>M2L5 - Gibbs sampling</span>"
    ]
  },
  {
    "objectID": "C2-L05.html#computing-example-with-normal-likelihood",
    "href": "C2-L05.html#computing-example-with-normal-likelihood",
    "title": "36  Gibbs sampling - M2L5",
    "section": "36.2 Computing example with Normal likelihood",
    "text": "36.2 Computing example with Normal likelihood\nTo implement the Gibbs sampler we just described, let’s return to our running example where the data are the percent change in total personnel from last year to this year for n=10 companies.  We’ll still use a normal likelihood, but now we’ll relax the assumption that we know the variance of growth between companies, \\sigma^2, and estimate that variance. Instead of the t prior from earlier, we will use the conditionally conjugate priors, normal for \\mu and inverse-gamma for \\sigma^2.Company personnel\nThe first step will be to write functions to simulate from the full conditional distributions we derived in the previous segment. The full conditional for \\mu, given \\sigma^2 and data is\n\n36.2.1 Conditionally conjugate priors for the mean (Video)\n\n\\text{N} \\left( \\mu \\mid \\frac{n\\bar{y}/\\sigma^2 + \\mu_0/\\sigma_0^2}{n/\\sigma^2 + 1/\\sigma_0^2}, \\, \\frac{1}{n/\\sigma^2 + 1/\\sigma_0^2} \\right)\n\\tag{36.3}\n\n\nCode\n#' update_mu\n#'\n#' @param n - sample size\n#' @param ybar - sample mean\n#' @param sig2 - current sigma squared\n#' @param mu_0 - mean hyper-parameter\n#' @param sig2_0 - variance  hyper-parameter\n#' \n#' @output - updated  value for mu the mean\n1update_mu = function(n, ybar, sig2, mu_0, sig2_0) {\n2  sig2_1 = 1.0 / (n / sig2 + 1.0 / sig2_0)\n3  mu_1 = sig2_1 * (n * ybar / sig2 + mu_0 / sig2_0)\n4  rnorm(n=1, mean=mu_1, sd=sqrt(sig2_1))\n}\n\n\n\n1\n\nwe don’t need the data y\n\n2\n\nwhere:  sig2_1 is \\sigma^2_1 the right term in Equation 36.3  sig2 is the current \\sigma_2 which we update in update_sigma below using Equation 36.4  sig2_0 is the hyper parameter for \\sigma^2_0\n\n3\n\nmu_1 is \\sigma^2_1 the left term in Equation 36.3 which uses sig2_1 we just computed\n\n4\n\nwe now draw from the a N(\\mu_1,\\sigma_1^2) for update_sig2 and the trace.\n\n\n\n\n\n\n36.2.2 conditionally conjugate priors for the variance\nThe full conditional for \\sigma^2 given \\mu and data is\n\n\\text{IG}\\left( \\sigma^2 \\mid \\nu_0 + \\frac{n}{2}, \\, \\beta_0 + \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2} \\right)\n\\tag{36.4}\n\n\nCode\n#' update_sig2\n#'\n#' @param n - sample size\n#' @param y - the data\n#' @param nu_0 - nu hyper-parameter\n#' @param beta_0 - beta hyper-parameter\n#' \n#' @output - updated  value for sigma2 the variance\n1update_sig2 = function(n, y, mu, nu_0, beta_0) {\n2  nu_1 = nu_0 + n / 2.0\n3  sumsq = sum( (y - mu)^2 )\n4  beta_1 = beta_0 + sumsq / 2.0\n5  out_gamma = rgamma(n=1, shape=nu_1, rate=beta_1)\n6  1.0 / out_gamma\n}\n\n\n\n1\n\nwe need the data to update beta\n\n2\n\nnu_1 the left term in Equation 36.4\n\n3\n\nvectorized\n\n4\n\nbeta_1 the right term in Equation 36.4\n\n5\n\ndraw a gamma sample with updated rate for \\text{Gamma}() is shape for \\text{IG}() inv-gamma\n\n6\n\nsince there is no rinvgamma in R we use the reciprocal of a gamma random variable which is distributed inv-gamma\n\n\n\n\nWith functions for drawing from the full conditionals, we are ready to write a function to perform Gibbs sampling.\n\n\n36.2.3 Gibbs sampler in R\n\n\nCode\ngibbs = function(y, n_iter, init, prior) {\n  ybar = mean(y)\n  n = length(y)\n  \n  ## initialize\n  mu_out = numeric(n_iter)\n  sig2_out = numeric(n_iter)\n  \n  mu_now = init$mu\n  \n  ## Gibbs sampler\n  for (i in 1:n_iter) {\n    sig2_now = update_sig2(n=n, y=y, mu=mu_now, nu_0=prior$nu_0, beta_0=prior$beta_0)\n    mu_now = update_mu(n=n, ybar=ybar, sig2=sig2_now, mu_0=prior$mu_0, sig2_0=prior$sig2_0)\n    \n    sig2_out[i] = sig2_now\n    mu_out[i] = mu_now\n  }\n  \n1  cbind(mu=mu_out, sig2=sig2_out)\n}\n\n\n\n1\n\ncbind for column bind will take a lists of list and convert them into a matrix of collumns.\n\n\n\n\nNow we are ready to set up the problem in R.\n\n\\begin{aligned}\n  y_i \\mid \\mu, \\sigma &\\stackrel {iid} \\sim \\mathcal{N}(\\mu,\\sigma^2), \\quad i=1,\\ldots,n\n  \\\\ \\mu &\\sim \\mathcal{N}(\\mu_0,\\sigma^2_0)\n  \\\\ \\sigma^2 & \\sim \\mathcal{IG}(\\nu,\\beta_0)\n\\end{aligned}\n\\tag{36.5}\nWe also need to create the prior hyperparameters for \\sigma^2, \\nu_0 and \\beta_0. If we chose these hyperperameters carefully, they are interpretable as a prior guess for sigma squared, as well as a prior effective sample size to go with that guess.\nThe prior effective sample size. Which we’ll call n_0, is two times this \\nu_0 parameter. So in other words, the nu parameter will be the prior sample size Divided by 2. We’re also going to create an initial guess for sigma squared, let’s call it s^2_0. The relationship between \\beta_0 and these two numbers is the following: It is the prior sample size times the prior guess divided by 2.\nThis particular parameterization of the Inverse gamma distribution is called the Scaled Inverse Chi Square Distribution, where the two parameters are n_0 and s^2_0.\n\n\nCode\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nybar = mean(y)\nn = length(y)\n\n## prior\nprior = list()\nprior$mu_0 = 0.0\nprior$sig2_0 = 1.0\nprior$n_0 = 2.0 # prior effective sample size for sig2\nprior$s2_0 = 1.0 # prior point estimate for sig2\nprior$nu_0 = prior$n_0 / 2.0 # prior parameter for inverse-gamma\nprior$beta_0 = prior$n_0 * prior$s2_0 / 2.0 # prior parameter for inverse-gamma\n\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dnorm(x=x, mean = prior$mu_0, sd=sqrt(prior$sig2_0)), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nFinally, we can initialize and run the sampler!\n\n\nCode\nset.seed(53)\n\ninit = list()\ninit$mu = 0.0\n\npost = gibbs(y=y, n_iter=1e3, init=init, prior=prior)\n\n\n\n\nCode\nhead(post)\n\n\n            mu      sig2\n[1,] 0.3746992 1.5179144\n[2,] 0.4900277 0.8532821\n[3,] 0.2536817 1.4325174\n[4,] 1.1378504 1.2337821\n[5,] 1.0016641 0.8409815\n[6,] 1.1576873 0.7926196\n\n\n\n\nCode\nlibrary(\"coda\")\nplot(as.mcmc(post))\n\n\n\n\n\n\n\n\n\n\n\nCode\nsummary(as.mcmc(post))\n\n\n\nIterations = 1:1000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n       Mean     SD Naive SE Time-series SE\nmu   0.9051 0.2868  0.00907        0.00907\nsig2 0.9282 0.5177  0.01637        0.01810\n\n2. Quantiles for each variable:\n\n       2.5%    25%    50%   75% 97.5%\nmu   0.3024 0.7244 0.9089 1.090 1.481\nsig2 0.3577 0.6084 0.8188 1.094 2.141\n\n\nAs with the Metropolis-Hastings example, these chains appear to have converged. In the next lesson, we will discuss convergence in more detail.\n\n\n\n\n\n\nGeman, Stuart, and Donald Geman. 1984. “Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images.” IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI-6 (6): 721–41. https://doi.org/10.1109/tpami.1984.4767596.",
    "crumbs": [
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>M2L5 - Gibbs sampling</span>"
    ]
  },
  {
    "objectID": "C2-L06.html",
    "href": "C2-L06.html",
    "title": "38  Assessing Convergence - M2L5",
    "section": "",
    "text": "38.1 Convergence diagnostics\nIn the previous two lessons, we have demonstrated ways you can simulate a Markov chain whose stationary distribution is the target distribution (usually the posterior). Before using the simulated chain to obtain Monte Carlo estimates, we should first ask ourselves: Has our simulated Markov chain converged to its stationary distribution yet? Unfortunately, this is a difficult question to answer, but we can do several things to investigate.",
    "crumbs": [
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>M2L5 - Assessing Convergence</span>"
    ]
  },
  {
    "objectID": "C2-L06.html#sec-convergence-diagnostics",
    "href": "C2-L06.html#sec-convergence-diagnostics",
    "title": "38  Assessing Convergence - M2L5",
    "section": "",
    "text": "38.1.1 Trace plots\nOur first visual tool for assessing chains is the trace plot. A trace plot shows the history of a parameter value across iterations of the chain. It shows you precisely where the chain has been exploring.\nFirst, let’s talk about what a chain should look like. Here is an example of a chain that has most likely converged.\n\n\nCode\nsource('mh.r')\n\n\nList of 2\n $ mu   : num [1:1000] 0 0 0 0 0 0 0 0 0 0 ...\n $ accpt: num 0.139\n\n\nCode\nlibrary(\"coda\")\nset.seed(61)\npost0 = mh(n=n, ybar=ybar, n_iter=10e3, mu_init=0.0, cand_sd=0.9)\ncoda::traceplot(as.mcmc(post0$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf the chain is stationary, it should not be showing any long-term trends. The average value for the chain should be roughly flat. It should not be wandering as in this example:\n\n\nCode\nset.seed(61)\npost1 = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post1$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf this is the case, you need to run the chain many more iterations, as seen here:\n\n\nCode\nset.seed(61)\npost2 = mh(n=n, ybar=ybar, n_iter=100e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\nThe chain appears to have converged at this much larger time scale.\n\n\n38.1.2 Monte Carlo effective sample size\nOne major difference between the two chains we’ve looked at is the level of autocorrelation in each. Autocorrelation is a number between -1 and +1 which measures how linearly dependent the current value of the chain is on past values (called lags). We can see this with an autocorrelation plot:\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post0$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post1$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.diag(as.mcmc(post1$mu))\n\n\n            [,1]\nLag 0  1.0000000\nLag 1  0.9850078\nLag 5  0.9213126\nLag 10 0.8387333\nLag 50 0.3834563\n\n\nAutocorrelation is important because it tells us how much information is available in our Markov chain. Sampling 1000 iterations from a highly correlated Markov chain yields less information about the stationary distribution than we would obtain from 1000 samples independently drawn from the stationary distribution.\nAutocorrelation is a major component in calculating the Monte Carlo effective sample size of your chain. The Monte Carlo effective sample size is how many independent samples from the stationary distribution you would have to draw to have equivalent information in your Markov chain. Essentially it is the m (sample size) we chose in the lesson on Monte Carlo estimation.\n\n\nCode\nstr(post2) # contains 100,000 iterations\n\n\nList of 2\n $ mu   : num [1:100000] -0.0152 -0.1007 -0.0867 -0.1092 -0.0811 ...\n $ accpt: num 0.958\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post2$mu)) # effective sample size of ~350\n\n\n   var1 \n373.858 \n\n\n\n\nCode\n## thin out the samples until autocorrelation is essentially 0. This will leave you with approximately independent samples. The number of samples remaining is similar to the effective sample size.\ncoda::autocorr.plot(as.mcmc(post2$mu), lag.max=500)\n\n\n\n\n\n\n\n\n\n\n\nCode\nthin_interval = 400 # how far apart the iterations are for autocorrelation to be essentially 0.\nthin_indx = seq(from=thin_interval, to=length(post2$mu), by=thin_interval)\nhead(thin_indx)\n\n\n[1]  400  800 1200 1600 2000 2400\n\n\n\n\nCode\npost2mu_thin = post2$mu[thin_indx]\ntraceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ntraceplot(as.mcmc(post2mu_thin))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post2mu_thin), lag.max=10)\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(as.mcmc(post2mu_thin))\n\n\nvar1 \n 250 \n\n\n\n\nCode\nlength(post2mu_thin)\n\n\n[1] 250\n\n\n\n\nCode\nstr(post0) # contains 10,000 iterations\n\n\nList of 2\n $ mu   : num [1:10000] 0 0 0.315 0.315 0.949 ...\n $ accpt: num 0.382\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post0$mu)) # effective sample size of ~2,500\n\n\n    var1 \n2537.924 \n\n\n?effectiveSize\nThe chain from post0 has 10,000 iterations, but an effective sample size of about 2,500. That is, this chain essentially provides the equivalent of 2,500 independent Monte Carlo samples.\nNotice that the chain from post0 has 10 times fewer iterations than for post2, but its Monte Carlo effective sample size is about seven times greater than the longer (more correlated) chain. We would have to run the correlated chain for 700,000+ iterations to get the same amount of information from both chains.\nIt is usually a good idea to check the Monte Carlo effective sample size of your chain. If all you seek is a posterior mean estimate, then an effective sample size of a few hundred to a few thousand should be enough. However, if you want to create something like a 95% posterior interval, you may need many thousands of effective samples to produce a reliable estimate of the outer edges of the distribution. The number you need can be quickly calculated using the Raftery and Lewis diagnostic.\nraftery.diag(as.mcmc(post0$mu))\n\n\nCode\nraftery.diag(as.mcmc(post0$mu), q=0.005, r=0.001, s=0.95)\n\n\n\nQuantile (q) = 0.005\nAccuracy (r) = +/- 0.001\nProbability (s) = 0.95 \n\nYou need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n## \n## Quantile (q) = 0.005\n## Accuracy (r) = +/- 0.001\n## Probability (s) = 0.95 \n## \n## You need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n?raftery.diag\n\n\nIn the case of the first chain from post0, it looks like we would need about 3,700 effective samples to calculate reliable 95% intervals. With the autocorrelation in the chain, that requires about 13,200 total samples. If we wanted to create reliable 99% intervals, we would need at least 19,100 total samples.",
    "crumbs": [
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>M2L5 - Assessing Convergence</span>"
    ]
  },
  {
    "objectID": "C2-L06.html#burn-in",
    "href": "C2-L06.html#burn-in",
    "title": "38  Assessing Convergence - M2L5",
    "section": "38.2 Burn-in",
    "text": "38.2 Burn-in\nWe have also seen how the initial value of the chain can affect how quickly the chain converges. If our initial value is far from the bulk of the posterior distribution, then it may take a while for the chain to travel there. We saw this in an earlier example.\n\n\nCode\nset.seed(62)\npost3 = mh(n=n, ybar=ybar, n_iter=500, mu_init=10.0, cand_sd=0.3)\ncoda::traceplot(as.mcmc(post3$mu))\n\n\n\n\n\n\n\n\n\nClearly, the first 100 or so iterations do not reflect draws from the stationary distribution, so they should be discarded before we use this chain for Monte Carlo estimates. This is called the “burn-in” period. You should always discard early iterations that do not appear to be coming from the stationary distribution. Even if the chain appears to have converged early on, it is safer practice to discard an initial burn-in.\n\n38.2.1 Multiple chains, Gelman-Rubin\nIf we want to be more confident that we have converged to the true stationary distribution, we can simulate multiple chains, each with a different starting value.\n\n\nCode\nset.seed(61)\n\nnsim = 500\npost1 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=15.0, cand_sd=0.4)\npost1$accpt\n\n\n[1] 0.616\n\n\n\n\nCode\npost2 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-5.0, cand_sd=0.4)\npost2$accpt\n\n\n[1] 0.612\n\n\n\n\nCode\npost3 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=7.0, cand_sd=0.1)\npost3$accpt\n\n\n[1] 0.844\n\n\n\n\nCode\npost4 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=23.0, cand_sd=0.5)\npost4$accpt\n\n\n[1] 0.53\n\n\n\n\nCode\npost5 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-17.0, cand_sd=0.4)\npost5$accpt\n\n\n[1] 0.618\n\n\n\n\nCode\npmc = mcmc.list(as.mcmc(post1$mu), as.mcmc(post2$mu), \n                as.mcmc(post3$mu), as.mcmc(post4$mu), as.mcmc(post5$mu))\nstr(pmc)\n\n\nList of 5\n $ : 'mcmc' num [1:500] 14.8 14 14 13.8 13.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -5 -5 -5 -5 -4.89 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 7 7 7 6.94 6.94 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 23 21.9 21.9 21.8 21.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -17 -17 -16.9 -16.2 -15.7 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n - attr(*, \"class\")= chr \"mcmc.list\"\n\n\n\n\nCode\ncoda::traceplot(pmc)\n\n\n\n\n\n\n\n\n\nIt appears that after about iteration 200, all chains are exploring the stationary (posterior) distribution. We can back up our visual results with the Gelman Rubin diagnostic. This diagnostic statistic calculates the variability within chains, comparing that to the variability between chains. If all chains have converged to the stationary distribution, the variability between chains should be relatively small, and the potential scale reduction factor, reported by the the diagnostic, should be close to one. If the values are much higher than one, then we would conclude that the chains have not yet converged.\n\n\nCode\ncoda::gelman.diag(pmc)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\n[1,]       1.01       1.02\n\n\n\n\nCode\ncoda::gelman.plot(pmc)\n\n\n\n\n\n\n\n\n\n\n\nCode\n?gelman.diag\n\n\n From the plot, we can see that if we only used the first 50 iterations, the potential scale reduction factor or “shrink factor” would be close to 10, indicating that the chains have not converged. But after about iteration 300, the “shrink factor” is essentially one, indicating that by then, we have probably reached convergence. Of course, we shouldn’t stop sampling as soon as we reach convergence. Instead, this is where we should begin saving our samples for Monte Carlo estimation.\n\n\n38.2.2 Monte Carlo estimation\nIf we are reasonably confident that our Markov chain has converged, then we can go ahead and treat it as a Monte Carlo sample from the posterior distribution. Thus, we can use the techniques from Lesson 3 to calculate posterior quantities like the posterior mean and posterior intervals from the samples directly.\n\n\nCode\nnburn = 1000 # remember to discard early iterations\npost0$mu_keep = post0$mu[-c(1:1000)]\nsummary(as.mcmc(post0$mu_keep))\n\n\n\nIterations = 1:9000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 9000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n      0.889449       0.304514       0.003210       0.006295 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n0.2915 0.6825 0.8924 1.0868 1.4890 \n\n\n\n\nCode\nmean(post0$mu_keep &gt; 1.0) # posterior probability that mu  &gt; 1.0\n\n\n[1] 0.3554444",
    "crumbs": [
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>M2L5 - Assessing Convergence</span>"
    ]
  },
  {
    "objectID": "C2-L06-Ex2.html",
    "href": "C2-L06-Ex2.html",
    "title": "40  Homework on M-H algorithm M2L5HW2",
    "section": "",
    "text": "Caution\n\n\n\nSection omitted to comply with the Honor Code",
    "crumbs": [
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Homework on M-H algorithm M2L5HW2</span>"
    ]
  },
  {
    "objectID": "C2-L07-Ex1.html",
    "href": "C2-L07-Ex1.html",
    "title": "42  Homework on Linear Regression Model Part 1 - M2L5HW1",
    "section": "",
    "text": "Caution\n\n\n\nSection omitted to comply with the Honor Code",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Homework on Linear Regression Model Part 1 - M2L5HW1</span>"
    ]
  },
  {
    "objectID": "C2-L07-Ex2.html",
    "href": "C2-L07-Ex2.html",
    "title": "43  Homework on Deviance information criterion - M2L5HW2",
    "section": "",
    "text": "Caution\n\n\n\nSection omitted to comply with the Honor Code",
    "crumbs": [
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Homework on Deviance information criterion - M2L5HW2</span>"
    ]
  },
  {
    "objectID": "C2-L07.html",
    "href": "C2-L07.html",
    "title": "41  M3L7 - Linear regression",
    "section": "",
    "text": "41.1 Introduction to linear regression\nWe discussed linear regression briefly in the previous course. And we fit a few models with non-informative priors. Here, we’ll provide a brief review, demonstrate fitting linear regression models in JAGS And discuss a few practical skills that are helpful when fitting linear models in general.\nThis is not meant to be a comprehensive treatment of linear models, which you can find in numerous courses and textbooks.\nLinear regression is perhaps the simplest way to relate a continuous response variable to multiple explanatory variables.\nThis may arise from observing several variables together and investigating which variables correlate with the response variable. Or it could arise from conducting an experiment, where we carefully assign values of explanatory variables to randomly selected subjects. And try to establish a cause-and-effect relationship.\nA linear regression model has the following form:\ny_i=\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k + \\epsilon_i\n\\\\ \\epsilon_i \\stackrel {iid} \\sim N(0,\\sigma^2)\n\\tag{41.1}\nThis describes the mean, and then we would also add an error, individual term for each observation. We would assume that the errors are IID from a normal distribution means 0 variance \\sigma^2 for observations 1 \\ldots k.\nEquivalently we can write this model for y_i directly as y_i given all of the x_i values, betas and a constant variance \\sigma^2. Again, k is the number of predictor variables.\ny_i\\mid x_i,\\beta_i,\\sigma^2 \\sim N(\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k, \\sigma^2)\n\\\\ \\beta_i \\sim \\mathbb{P}r(\\beta_i)\n\\\\ \\sigma^2 \\sim \\mathbb{P}r(\\sigma^2)\n\\tag{41.2}\nThis yields the following graphical model structure.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeOneSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeTwoSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeThreeSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFourSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFiveSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmtt10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmb10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmss10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['DejaVu Sans Display'] not found. Falling back to DejaVu Sans.\n\n\n\n\n\n\n\n\nFigure 41.1: The graphical model for linear regression\nThe terms of a linear model are always linearly related because of the structure of the model.\nBut the model does not have to be linear necessarily in the xy relationship. For example, it may be that y is related linearly to x^2. Hence we could transform the x and y variables to get new x’s and new y’s but we would still have a linear model. However, in that case, if we transform the variables, we must be careful about how this changes the final interpretation of the results.",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-introduction-to-linear-regression",
    "href": "C2-L07.html#sec-introduction-to-linear-regression",
    "title": "41  M3L7 - Linear regression",
    "section": "",
    "text": "Introduction to linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantUnderstanding the Graphical Models\n\n\n\n\nThis graphical model uses plate notation\nWe’ll start with a plate for all of our different y variables,\n\nIt is repeated i = 1 \\ldots N times\n\ny_i, are random variable - (indicated by a circle)\n\nthey are observed - indicated by a filled shape.\n\nX_i variables.\n\nthey are drawn as squares around to indicate that they are constants and not random variables.\nWe’re always conditioning on the Xs. So they’ll just be constants.\nthey are observed, so they are filled in.\n\nThe y_i depend on the values of the x and the values of these parameters. So, we have \\beta_0, \\ldots, \\beta_k.\nSigma squared.\nSince the y_i depend on all of these, so this would be the graphical model representation.\n\n\n\n\n\n\n\n\n\n\n\nImportantInterpreting Coefficients\n\n\n\nThe basic interpretation of the \\beta_i coefficients is:\nWhile holding all other X variables constant, if we increases X_i by one then the mean of \\bar{y} is expected to increase by \\beta_i .\nThat is \\beta_i describes how the \\bar{y} changes with changes in X_i, while accounting for all the other X variables.\n\n\\beta \\approx  \\frac{\\partial \\bar{y} }{\\partial x_i}\n\\tag{41.3}\nThat’s true for all of the x variables.\n\n\n\n\n\n\n\n\nWarningRegression assumptions\n\n\n\nWe’re going to assume that\n\nThe ys are independent of each other, given the xs.\nThe y_is have the same variance.\nThe residuals are normally distributed with mean 0 and variance \\sigma^2.\n\nThese are actually strong assumptions that are not often not realistic in many situations.\nThere are many statistical models to address that.\nWe’ll look at some hierarchical methods in the coming lessons.\n\n\n\n41.1.1 Priors\nThe model is not complete until we add the prior distributions.\nSo we might say \\beta_0 comes from its prior.\n\\beta_1 would come from its prior, and so forth for all the \\betas. And sigma squared would come from its prior.\nThe most common choice for prior on the \\betas, is a Normal distribution. Or we can do a Multivariate normal for all of the betas at once.\nThis is conditionally conjugate and allows us to do Gibbs sampling.\nIf we want to be non-informative, we can choose Normal(0,\\sigma^2=1e6) priors with very large variance. Which are practically flat for realistic values of beta. The non-informative priors used in the last class are equivalent to using normal priors with infinite variance.\nWe can also use the conditionally conjugate InverseGamma() prior for \\sigma^2 that we’re familiar with.\nAnother common prior for the betas is Double exponential, or the Laplace prior, or Laplace distribution. \nThe Laplace prior has this density:\n\nf(x\\mid \\mu,\\beta)=\\frac{1}{2\\beta} e^{|\\frac{x-\\mu}{\\beta}|}\n\\tag{41.4}\nwhere:\n\n\\mu is the location parameter and\n\\beta is the scale parameter.\n\nThe case where \\mu = 0 and \\beta = 1 is called the standard double exponential distribution\n\nf(x)=\\frac{1}{2} e^{|x|}\n\\tag{41.5}\nAnd the density looks like this.\n\n\n\n\n\n\n\nFigure 41.2: The Double Exponential Distribution\n\n\n\n\n\n\n\n\n\n\nFigure 41.3: The Double Exponential Distribution\n\n\n\n\nRPython\n\n\n\n\nCode\n# Grid of X-axis values\nx &lt;- seq(-10, 10, 0.1)\nplot(x,  ddexp(x, 0, 2), type = \"l\", ylab = \"\", lwd = 2, col = \"red\")\nlines(x, ddexp(x, 0, 1.5), type = \"l\", ylab = \"\", lwd = 2, col = \"green\")\nlines(x, ddexp(x, 0, 1), type = \"l\", ylab = \"\", lwd = 2, col = \"blue\")\nlegend(\"topright\",\n       c(expression(paste(, beta)), \"1.5\",\"1\", \"2\"),\n       lty = c(0, 1, 1, 1),\n       col = c(\"red\",\"green\", \"blue\"), box.lty = 0, lwd = 2\n      )\n\n#x &lt;- rdexp(500, location = 2, scale = 1)\n#de_sample=ddexp(x, 2, 1)\n#CDF &lt;- ecdf(de_sample )\n#plot(CDF)\n\n\n\n\n\n\n\nCode\nloc, scale = 0., 1.\ns = np.random.laplace(loc, scale, 1000)\n\ncount, bins, ignored = plt.hist(s, 30, density=True)\nx = np.arange(-8., 8., .01)\npdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\nplt.plot(x, pdf);\n\ng = (1/(scale * np.sqrt(2 * np.pi)) *\n     np.exp(-(x - loc)**2 / (2 * scale**2)))\nplt.plot(x,g);\n\n\n\n\n\n\nIt’s called double exponential because it looks like the exponential distribution except it’s been reflected over the y axis. It has a sharp peak at x equals 0, or beta equals 0 in this case, which can be useful if we want to do variable selection among our x’s. Because it’ll favor values in your 0 for these betas.\nThis is related to the popular regression technique known as the LASSO. \nMore information is available from:\n\nNIST\nWikipedia",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#eda",
    "href": "C2-L07.html#eda",
    "title": "41  M3L7 - Linear regression",
    "section": "42.1 EDA",
    "text": "42.1 EDA\n\n\nCode\n1pairs(Leinhardt)\n\n\n\n1\n\nUsing pairs to investigate the marginal relationships between each of the four variables.\n\n\n\n\n\n\n\n\n\n\n\n\n42.1.0.1 Simple linear Model\nWe’ll start with a simple linear regression model that relates infant mortality to per capita income.\n\n\nCode\nplot(infant ~ income, data=Leinhardt)\n\n\n\n\n\n\n\n\n\n\n\nCode\nhist(Leinhardt$infant)\n\n\n\n\n\n\n\n\n\nthis is right-skewed (many small values and a number of much larger one)\n\n\nCode\nhist(Leinhardt$income)\n\n\n\n\n\n\n\n\n\nalso right-skewed.\nthis indicates that we may do better if we do a log transform on these two variables.\n\n\n42.1.0.2 Log-Log Linear Model\n\n\nCode\n1Leinhardt$loginfant = log(Leinhardt$infant)\n2Leinhardt$logincome = log(Leinhardt$income)\n\n\n3plot(loginfant ~ logincome,data=Leinhardt)\n\n\n\n1\n\nlog transform infant column.\n\n2\n\nlog transform income column.\n\n3\n\nscatter plot of the log log transformed data.\n\n\n\n\n\n\n\n\n\n\nFigure 42.1: log log transformed infant mortality vs income\n\n\n\n\n\nSince infant mortality and per capita income are positive and right-skewed quantities, we consider modeling them on the logarithmic scale. A linear model appears much more appropriate on this scale.\n\n\nCode\n1scatterplot(loginfant ~ logincome,data=Leinhardt)\n\n\n\n1\n\nscatterplot with a regression fit and uncertainty for the data\n\n\n\n\n\n\n\n\n\n\nFigure 42.2: log log transformed infant mortality vs income scatterplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n42.1.1 Modeling\nThe reference Bayesian analysis (with a non-informative prior) is available directly in R.\n\n\nCode\nlmod0 = lm(loginfant ~ logincome, data=Leinhardt)\nsummary(lmod0)\n\n\n\n\nregression output\nlm(formula = loginfant ~ logincome, data = Leinhardt)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.66694 -0.42779 -0.02649  0.30441  3.08415 \n\nCoefficients: \n            Estimate Std. Error t value Pr(&gt;|t|)    \n1(Intercept)  7.14582    0.31654  22.575   &lt;2e-16 ***\n2logincome   -0.51179    0.05122  -9.992   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n3Residual standard error: 0.6867 on 99 degrees of freedom\n4  (4 observations deleted due to missingness)\n5Multiple R-squared:  0.5021,    Adjusted R-squared:  0.4971\nF-statistic: 99.84 on 1 and 99 DF,  p-value: &lt; 2.2e-16\n\n\n\n1\n\nintercept is \\gg its error so it appears statistically significant (***)\n\n2\n\nposterior mean logincome too\n\n3\n\nResidual standard error gives us an estimate of the left over variance after fitting the model.\n\n4\n\n4 rows were dropped due to missing values\n\n5\n\nAdjusted R-squared is the explained variance adjusted for degrees of freedom",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-residual-checks",
    "href": "C2-L07.html#sec-residual-checks",
    "title": "41  M3L7 - Linear regression",
    "section": "44.1 Residual checks",
    "text": "44.1 Residual checks\n\n\n\n\n\n\nImportant\n\n\n\nAnalysis gets complicated quickly when we have multiple models. What we shall soon see is how to get residuals from the Bayesian model in Stan so we can compare it visually with the reference model we got using LM.\n\n\nChecking residuals (the difference between the response and the model’s prediction for that value) is important with linear models since residuals can reveal violations of the assumptions we made to specify the model. In particular, we are looking for any sign that the model is not linear, normally distributed, or that the observations are not independent (conditional on covariates).\nFirst, let’s look at what would have happened if we fit the reference linear model to the un-transformed variables.\n\n\nCode\nlmod0 = lm(infant ~ income, data=Leinhardt)\nplot(resid(lmod0)) # to check independence (looks okay)\n\n\n\n\n\n\n\n\n\nthere should not be a pattern - but we can see an increase. This is not an issue and due to the data being presorted.\n\n\nCode\nplot(predict(lmod0), resid(lmod0)) # to check for linearity, constant variance (looks bad)\n\n\n\n\n\n\n\n\n\nafter 80 the variance starts increasing\n\n\nCode\nqqnorm(resid(lmod0)) # to check Normality assumption (we want this to be a straight line)\n\n\n\n\n\n\n\n\n\nCode\n#?qqnorm\n\n\nThis looks good except for the last few points.\nNow let’s return to our model fit to the log-transformed variables. In a Bayesian model, we have distributions for residuals, but we’ll simplify and look only at the residuals evaluated at the posterior mean of the parameters.\n\n\nCode\nX = cbind(rep(1.0, data1_jags$n), data1_jags$log_income)\nhead(X)\n\n\n     [,1]     [,2]\n[1,]    1 8.139149\n[2,]    1 8.116716\n[3,]    1 8.115521\n[4,]    1 8.466110\n[5,]    1 8.522976\n[6,]    1 8.105308\n\n\n\n\nCode\n1(pm_params1 = colMeans(mod1_csim))\n\n\n\n1\n\nposterior mean - using (var = expr) forces R to return the value of var\n\n\n\n\n      b[1]       b[2]        sig \n 7.0714211 -0.4996873  0.9709133 \n\n\n\n\nCode\n1yhat1 = drop(X %*% pm_params1[1:2])\n2resid1 = data1_jags$y - yhat1\n3plot(resid1)\n\n\n\n1\n\nwe are evaluating \\\\hat{y} = b_0 \\times 1 + b_1 \\times x_1 via matrix multiplication of [1, data1_jags$log_income] *[b_0,b_1]\n\n2\n\nres_i = y_i- \\hat y = y_i - (b_0 \\times 1 + b_1 \\times x_{1,i})\n\n3\n\nplots the residual against the data index\n\n\n\n\n\n\n\n\n\n\n\nSo to get the residuals from Stan we extract the b parameter.\nAlthough we did not discuss it we could estimate \\hat y by drawing K predictions for each x_i and look at res_i=\\frac{1}{K}\\sum_k|y_i -\\hat y_{i,k}| and plot upper and fit a line as well as lower and upper bounds as well. Also I’m not sure but I guess we can also do with using the predictive posterior dist. Anyhow here is a link to something like this: Extracting and visualizing tidy residuals from Bayesian models -jk\n\n\nCode\nplot(yhat1, resid1) # against predicted values\n\n\n\n\n\n\n\n\n\n\n\nCode\nqqnorm(resid1) # checking normality of residuals\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(predict(lmod0), resid(mod1)) # to compare with reference linear model\n\n\n\n\n\n\n\n\n\n\n\nCode\nrownames(dat)[order(resid1, decreasing=TRUE)[1:5]] # which countries have the largest positive residuals?\n\n\n[1] \"Saudi.Arabia\" \"Libya\"        \"Zambia\"       \"Brazil\"       \"Afganistan\"  \n\n\nThe residuals look pretty good here (no patterns, shapes) except for two strong outliers, Saudi Arabia and Libya. When outliers appear, it is a good idea to double check that they are not just errors in data entry. If the values are correct, you may reconsider whether these data points really are representative of the data you are trying to model. If you conclude that they are not (for example, they were recorded on different years), you may be able to justify dropping these data points from the data set.\nIf you conclude that the outliers are part of data and should not be removed, we have several modeling options to accommodate them. We will address these in the next segment.",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-additional-covariates",
    "href": "C2-L07.html#sec-additional-covariates",
    "title": "41  M3L7 - Linear regression",
    "section": "45.1 Additional covariates",
    "text": "45.1 Additional covariates\nThe first approach is to look for additional covariates that may be able to explain the outliers. For example, there could be a number of variables that provide information about infant mortality above and beyond what income provides.\nLooking back at our data, there are two variables we haven’t used yet: region and oil. The oil variable indicates oil-exporting countries. Both Saudi Arabia and Libya are oil-exporting countries, so perhaps this might explain part of the anomaly.\n\n\nCode\nlibrary(\"rjags\")\n\nmod2_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[i], prec)\n1        mu[i] = b[1] + b[2]*log_income[i] + b[3]*is_oil[i]\n    }\n    \n2    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*10.0/2.0)\n    sig = sqrt( 1.0 / prec )\n} \"\n\n\nset.seed(73)\ndata2_jags = list(y=dat$loginfant, log_income=dat$logincome,\n3                  is_oil=as.numeric(dat$oil==\"yes\"))\ndata2_jags$is_oil\n\nparams2 = c(\"b\", \"sig\")\n\ninits2 = function() {\n4    inits = list(\"b\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod2 = jags.model(textConnection(mod2_string), data=data2_jags, inits=inits2, n.chains=3)\nupdate(mod2, 1e3) # burn-in\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params2,\n                        n.iter=5e3)\n\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim)) # combine multiple chains\n\n\n\n1\n\nwe add the is_oil indicator parameter\n\n2\n\nwe increment the number of parameters\n\n3\n\nencode the is_oil from text to be binary\n\n4\n\ndraw another var for b.\n\n\n\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 101\n   Unobserved stochastic nodes: 4\n   Total graph size: 507\n\nInitializing model\n\n\nAs usual, check the convergence diagnostics.\n\n\nCode\npar(mar = c(2., 1, 2., 1))\nplot(mod2_sim)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod2_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]       1.02       1.05\nb[2]       1.02       1.06\nb[3]       1.00       1.00\nsig        1.00       1.00\n\nMultivariate psrf\n\n1.01\n\n\nCode\nautocorr.diag(mod2_sim)\n\n\n             b[1]       b[2]        b[3]          sig\nLag 0  1.00000000 1.00000000 1.000000000  1.000000000\nLag 1  0.94747699 0.94845546 0.080704361  0.050906460\nLag 5  0.76035333 0.76108681 0.006577258  0.008661499\nLag 10 0.56675783 0.56836804 0.008692565 -0.001946145\nLag 50 0.02775122 0.02941689 0.003194170  0.001214270\n\n\n\n\nCode\n#autocorr.plot(mod2_sim,auto.layout=FALSE )\nautocorr.plot(mod2_csim,auto.layout=FALSE )\n\n\n\n\n\n\n\n\nFigure 45.1: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.2: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.3: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.4: auto-correlation plot\n\n\n\n\n\n\n\nCode\neffectiveSize(mod2_sim)\n\n\n      b[1]       b[2]       b[3]        sig \n  420.0652   418.4183 12578.5791 12969.4631 \n\n\nWe can get a posterior summary of the parameters in our model.\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nb[1]  7.1370 0.42429 0.0034643      0.0207607\nb[2] -0.5208 0.06886 0.0005623      0.0034071\nb[3]  0.7927 0.35144 0.0028695      0.0031354\nsig   0.9514 0.06713 0.0005481      0.0005896\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%     75%   97.5%\nb[1]  6.3193  6.8446  7.1333  7.4258  7.9588\nb[2] -0.6534 -0.5678 -0.5214 -0.4733 -0.3876\nb[3]  0.1038  0.5551  0.7915  1.0312  1.4883\nsig   0.8309  0.9044  0.9473  0.9942  1.0940\n\n\nIt looks like there is a positive relationship between oil-production and log-infant mortality. Because these data are merely observational, we cannot say that oil-production causes an increase in infant mortality (indeed that most certainly isn’t the case), but we can say that they are positively correlated.\nNow let’s check the residuals.\n\n\nCode\nX2 = cbind(rep(1.0, data1_jags$n), data2_jags$log_income, data2_jags$is_oil)\nhead(X2)\n\n\n     [,1]     [,2] [,3]\n[1,]    1 8.139149    0\n[2,]    1 8.116716    0\n[3,]    1 8.115521    0\n[4,]    1 8.466110    0\n[5,]    1 8.522976    0\n[6,]    1 8.105308    0\n\n\n\n\nCode\n(pm_params2 = colMeans(mod2_csim)) # posterior mean\n\n\n      b[1]       b[2]       b[3]        sig \n 7.1369944 -0.5208440  0.7927308  0.9513715 \n\n\n\n\nCode\nyhat2 = drop(X2 %*% pm_params2[1:3])\nresid2 = data2_jags$y - yhat2\nplot(resid2) # against data index\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(yhat2, resid2) # against predicted values\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(yhat1, resid1) # residuals from the first model\n\n\n\n\n\n\n\n\n\n\n\nCode\nsd(resid2) # standard deviation of residuals\n\n\n[1] 0.6488701\n\n\nThese look much better, although the residuals for Saudi Arabia and Libya are still more than three standard deviations away from the mean of the residuals. We might consider adding the other covariate region, but instead let’s look at another option when we are faced with strong outliers.\n\n45.1.1 Student-t likelihood\n\nLet’s consider changing the likelihood.\nThe normal likelihood has thin tails (almost all of the probability is concentrated within the first few standard deviations from the mean).\nThis does not accommodate outliers well.\nConsequently, models with the normal likelihood might be overly-influenced by outliers.\nRecall that the t distribution is similar to the normal distribution, but it has thicker tails which can accommodate outliers.\n\nThe t linear model might look something like this. Notice that the t distribution has three parameters, including a positive “degrees of freedom” parameter. The smaller the degrees of freedom, the heavier the tails of the distribution. We might fix the degrees of freedom to some number, or we can assign it a prior distribution.\n\n\nCode\ncurve(dnorm(x), from = -5, to = 5)\ncurve(dt(x,1), from = -5, to = 5,col=\"red\", add = TRUE)\n\n\n\n\n\n\nnormal and t distributions\n\n\n\n\n\nCode\nmod3_string = \" model {\n1    for (i in 1:length(y)) {\n        y[i] ~ dt( mu[i], tau, df )\n        mu[i] = b[1] + b[2]*log_income[i] + b[3]*is_oil[i]\n    }\n    \n    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n2    nu ~ dexp(1.0)\n3    df = nu + 2.0\n    \n4    tau ~ dgamma(5/2.0, 5*10.0/2.0)\n5    sig = sqrt( 1.0 / tau * df / (df - 2.0) )\n}\"\n\n\n\n1\n\nwe replaced normal likelihood with a student t likelihood which has thicker tails\n\n2\n\n\\nu nu is the degrees of freedom (dof) but the outcome can be 0 or 1\n\n3\n\nwe force the degrees of freedom dof&gt;2 to guarantee the existence of mean and variance in the t dist.\n\n4\n\n\\tau tau is the inverse scale is close to, but not equal to the precision from above so we use the same prior as we used for precision.\n\n5\n\n\\sigma sig standard deviation of errors is a deterministic function of tau, and df\n\n\n\n\nWe fit this model.\n\n\nCode\nset.seed(73)\ndata3_jags = list(y=dat$loginfant, log_income=dat$logincome,\n                  is_oil=as.numeric(dat$oil==\"yes\"))\n\nparams3 = c(\"b\", \"sig\")\n\ninits3 = function() {\n    inits = list(\"b\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, inits=inits3, n.chains=3)\nupdate(mod3, 1e3) # burn-in\n\nmod3_sim = coda.samples(model=mod3,\n                        variable.names=params3,\n                        n.iter=5e3)\n\nmod3_csim = as.mcmc(do.call(rbind, mod3_sim)) # combine multiple chains\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 101\n   Unobserved stochastic nodes: 5\n   Total graph size: 512\n\nInitializing model\n\n\ncheck MCMC convergence visually\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod3_sim)\n\n\n\n\n\n\n\n\n\ncheck MCMC convergence quantitatively using Rubin Gelman\n\n\nCode\ngelman.diag(mod3_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]       1.04       1.14\nb[2]       1.04       1.14\nb[3]       1.00       1.00\nsig        1.02       1.02\n\nMultivariate psrf\n\n1.04\n\n\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n      b[1]       b[2]       b[3]        sig \n  283.1644   287.3594  8071.1542 10216.5792",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-compare-models-using-deviance-information-criterion-dic",
    "href": "C2-L07.html#sec-compare-models-using-deviance-information-criterion-dic",
    "title": "41  M3L7 - Linear regression",
    "section": "45.2 Compare models using Deviance information criterion (DIC)",
    "text": "45.2 Compare models using Deviance information criterion (DIC)\n We have now proposed three different models. How do we compare their performance on our data? In the previous course, we discussed estimating parameters in models using the maximum likelihood method. Similarly, we can choose between competing models using the same idea.\nWe will use a quantity known as the deviance information criterion (DIC). It essentially calculates the posterior mean of the log-likelihood and adds a penalty for model complexity.\nLet’s calculate the DIC for our first two models:\nthe simple linear regression on log-income,\n\n\nCode\ndic.samples(mod1, n.iter=1e3)\n\n\nMean deviance:  231.3 \npenalty 2.959 \nPenalized deviance: 234.3 \n\n\nand the second model where we add oil production.\n\n\nCode\ndic.samples(mod2, n.iter=1e3)\n\n\nMean deviance:  225.3 \npenalty 4.18 \nPenalized deviance: 229.5 \n\n\nand the second model where we introduce the Student t likelihood.\n\n\nCode\ndic.samples(mod3, n.iter=1e3)\n\n\nMean deviance:  230.6 \npenalty 3.884 \nPenalized deviance: 234.5 \n\n\nThe first number is the Monte Carlo estimated posterior mean deviance, which equals -2 times the log-likelihood (plus a constant that will be irrelevant for comparing models). Because of that -2 factor, a smaller deviance means a higher likelihood.\nNext, we are given a penalty for the complexity of our model. This penalty is necessary because we can always increase the likelihood of the model by making it more complex to fit the data exactly. We don’t want to do this because over-fit models generalize poorly. This penalty is roughly equal to the effective number of parameters in your model. You can see this here. With the first model, we had a variance parameter and two betas, for a total of three parameters. In the second model, we added one more beta for the oil effect.\nWe add these two quantities to get the DIC (the last number). The better-fitting model has a lower DIC value. In this case, the gains we receive in deviance by adding the is_oil covariate outweigh the penalty for adding an extra parameter. The final DIC for the second model is lower than for the first, so we would prefer using the second model.\nWe encourage you to explore different model specifications and compare their fit to the data using DIC. Wikipedia provides a good introduction to DIC and we can find more details about the JAGS implementation through the rjags package documentation by entering ?dic.samples in the R console.\n\n\nCode\n#?dic.samples",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-regression-diagnostics",
    "href": "C2-L07.html#sec-regression-diagnostics",
    "title": "41  M3L7 - Linear regression",
    "section": "45.3 Regression Diagnostics",
    "text": "45.3 Regression Diagnostics\nIn production we want to flag regression issues in an automated fashion. However while we develop models we should try to examine these issues visually.\nRegression diagnostics help identify:\n\nshortcoming of our model and the preferred ways to improve them\n\ntransforms of variables\ndifferent likelihood\nadding missing covariate relations to remove patterns in the residuals\nincreasing interpretability by removing covariates that do not contribute to the fit.\n\nissues in the data\n\ntransformation\n\n\nwe should consider the following issues: 1. testing heteroscedasticity with the Breusch-Pagan test\nLet’s try to cover the diagnostic plots which help us validate a regression model.\n\n45.3.1 Residuals vs Fitted\n\nThe “residuals versus fits plot” is the most first diagnostic tool we\nshould look at to determine if the regression is valid. If the regression assumptions are violated we should be able to identify the issues and possibly correct them.\nIt is a scatter plot of residuals on the y axis and fitted values (estimated responses) on the x axis.\nThe plot can be used to detect:\n\nnon-linearity,\nunequal error variances, and\noutliers.\n\n\n\n\nCode\nplot(lmod0, 1)\n\n\n\n\n\nResiduals vs Fitted plot\n\n\n\n\nResiduals will enable us to assess visually whether an appropriate model has been fit to the data no matter how many predictor variables are used. We can checking the validity of a linear regression model by plotting residuals versus x and look for patterns. - Lack of a discernible pattern is indicative of a valid model. - A pattern is is indicative that a function or transformation of X is missing from the model.\n\n\n\n\n\n\nImportantWhat to look for\n\n\n\nLook for patterns that can indicate non-linearity,\n\nthat the residuals all are high in some areas and low in others. Change in variability as X changes - U shape missing quadratic term · we can get this plot as follows.\n\nThe blue line is there to aid the eye - it should ideally be relatively close to a straight line (in this case, it isn’t perfectly straight, which could indicate a mild non-linearity).\n\n\n\n\n45.3.2 QQ plot of the residuals\nThis plot shows if residuals are normally distributed. Do residuals follow a straight line well or do they deviate severely?\nThe regression is valid if the residuals are lined well on the straight dashed line.\nwe can get this plot as follows\n\n\nCode\nplot(lmod0, 2)\n\n\n\n\n\n\n\n\n\nnotice that the two outliers are labeled and should be reviewed for - removal - more robust likelihood\nfor more info see understanding QQ plots\n\n\n45.3.3 Scale Location plot\nThis plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance (homoscedasticity). It’s good if you see a horizontal line with equally (randomly) spread points.\n\n\nCode\nplot(lmod0, 3)\n\n\n\n\n\n\n\n\n\nin this case: - most of the points are to the right - the red line is almost flat which is good - there is increasing variance after 80\n\n\n45.3.4 Cook’s Distance\n\nOriginally introduced in (Cook 1977a) Cook’s Distance is an estimate of the influence of a data point.\nIt takes into account both the leverage and residual of each observation.\nCook’s Distance is a summary of how much a regression model changes when the ith observation is removed.\nWhen it comes to outliers we care about outliers that have a high Cook’s distance as they can have a large impact on the regression model. by shifting the sample fit from the population fit.\nAnother aspect of Cook’s distance is it can be used to identify regions of the design space where the model is poorly supported by the data - i.e. where the model is extrapolating and if we can get more data in that region we can improve the model.\n\n\n\nCode\nplot(lmod0, 4)\n\n\n\n\n\n\n\n\n\nUsed to detect highly influential outliers, i.e. points that can shift the sample fit from the population fit. For large sample sizes, a rough guideline is to consider values above 4/(n-p), where n is the sample size and p is the number of predictors including the intercept, to indicate highly influential points.\nsee Williams (1987)\n\n\n45.3.5 Residuals vs Leverage\n\n\nCode\nplot(lmod0, 5)\n\n\n\n\n\n\n\n\n\nCode\n#plot(mod3, 5)\n\n\nThis plot helps us to sort through the outliers, if there are any. Not all outliers are influential in linear regression analysis. Even though data have extreme values, they might not be influential to determine a regression line. i.e. the fit wouldn’t be much different if we choose to omit them from the analysis. If a point is able to exert a influence on the regression line we call it a high leverage point. Even in this case it might not alter the trend. So we want to identify high leverage points that are at a large distance from their predictor’s mean.\nUnlike the other plots, this time patterns are not relevant. We watch out for outlying values at the upper right corner or at the lower right corner. Those spots are the places where cases can be influential against a regression line. Look for cases outside of the dashed lines. When cases are outside of the dashed lines (meaning they have high “Cook’s distance” scores), the cases are influential to the regression results. The regression results will be altered if we exclude those cases.\nIn this case we see that the pints are within the cook’s distance contours so our outliers are not high leverage points.\n\n\n45.3.6 Cook’s Distance vs Leverage\n\n\nCode\nplot(lmod0, 6)\n\n\n\n\n\n\n\n\nFigure 45.5: Cooks distance v.s. Leverage\n\n\n\n\n\nCook’s distance and leverage are used to detect highly leverage points, i.e. data points that can shift the sample fit from the population fit.\nFor large sample sizes, a rough guideline is to consider Cook’s distance values above 1 to indicate highly influential points and leverage values greater than 2 times the number of predictors divided by the sample size to indicate high leverage observations. High leverage observations are ones which have predictor values very far from their averages, which can greatly influence the fitted model.\nThe contours in the scatterplot are standardized residuals labelled with their magnitudes\nsee Williams (1987)\n\n\n45.3.7 Python\n\nhttps://emredjan.xyz/blog/2017/07/11/emulating-r-plots-in-python/\nhttps://towardsdatascience.com/going-from-r-to-python-linear-regression-diagnostic-plots-144d1c4aa5a\nhttps://modernstatisticswithr.com/regression.html\n\n\n\n\n\n\n\nCook, R. Dennis. 1977b. “Detection of Influential Observation in Linear Regression.” Technometrics 19 (1): 15. https://doi.org/10.2307/1268249.\n\n\n———. 1977a. “Detection of Influential Observation in Linear Regression.” Technometrics 19 (1): 15. https://doi.org/10.2307/1268249.\n\n\nWilliams, D. A. 1987. “Generalized Linear Model Diagnostics Using the Deviance and Single Case Deletions.” Applied Statistics 36 (2): 181. https://doi.org/10.2307/2347550.",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L08-Ex2.html",
    "href": "C2-L08-Ex2.html",
    "title": "46  Homework on Multiple Factor ANOVA - M3L8HW2",
    "section": "",
    "text": "Caution\n\n\n\nSection omitted to comply with the Honor Code",
    "crumbs": [
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Homework on Multiple Factor ANOVA - M3L8HW2</span>"
    ]
  },
  {
    "objectID": "C2-L08.html",
    "href": "C2-L08.html",
    "title": "44  ANOVA - M3L8",
    "section": "",
    "text": "44.1 Introduction to ANOVA (Video)",
    "crumbs": [
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>ANOVA - M3L8</span>"
    ]
  },
  {
    "objectID": "C2-L08.html#sec-intro-anova",
    "href": "C2-L08.html#sec-intro-anova",
    "title": "44  ANOVA - M3L8",
    "section": "",
    "text": "Introduction to ANOVA",
    "crumbs": [
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>ANOVA - M3L8</span>"
    ]
  },
  {
    "objectID": "C2-L08.html#one-way-anova-model-using-jags",
    "href": "C2-L08.html#one-way-anova-model-using-jags",
    "title": "44  ANOVA - M3L8",
    "section": "44.2 One way ANOVA model using JAGS",
    "text": "44.2 One way ANOVA model using JAGS\n\n44.2.1 Data & EDA\nAs an example of a one-way ANOVA, we’ll look at the Plant Growth data in R.\n\n\n\n\nListing 44.1: Plant Growth Query\n\n\n\nCode\ndata(\"PlantGrowth\")\n#?PlantGrowth\nhead(PlantGrowth)\n\n\n\n\n\n  weight group\n1   4.17  ctrl\n2   5.58  ctrl\n3   5.18  ctrl\n4   6.11  ctrl\n5   4.50  ctrl\n6   4.61  ctrl\n\n\nWe first load the dataset (Listing 44.1)\nBecause the explanatory variable group is a factor and not continuous, we choose to visualize the data with box plots rather than scatter plots.\n\n\nCode\nboxplot(weight ~ group, data=PlantGrowth)\n\n\n\n\n\n\n\n\nFigure 44.1: PlantGrowth boxplot\n\n\n\n\n\nThe box plots summarize the distribution of the data for each of the three groups. It appears that treatment 2 has the highest mean yield. It might be questionable whether each group has the same variance, but we’ll assume that is the case.\n\n\n44.2.2 Modeling\nAgain, we can start with the reference analysis (with a noninformative prior) with a linear model in R.\n\n\nCode\nlmod = lm(weight ~ group, data=PlantGrowth)\nsummary(lmod)\n\n\n\nCall:\nlm(formula = weight ~ group, data = PlantGrowth)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4180 -0.0060  0.2627  1.3690 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.0320     0.1971  25.527   &lt;2e-16 ***\ngrouptrt1    -0.3710     0.2788  -1.331   0.1944    \ngrouptrt2     0.4940     0.2788   1.772   0.0877 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6234 on 27 degrees of freedom\nMultiple R-squared:  0.2641,    Adjusted R-squared:  0.2096 \nF-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\n\n\n\n\nCode\nanova(lmod)\n\n\nAnalysis of Variance Table\n\nResponse: weight\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \ngroup      2  3.7663  1.8832  4.8461 0.01591 *\nResiduals 27 10.4921  0.3886                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\nplot(lmod) # for graphical residual analysis\n\n\n\n\n\n\n\n\nFigure 44.2: Graphical residual analysis\n\n\n\n\n\n\n\n\n\n\n\nFigure 44.3: Graphical residual analysis\n\n\n\n\n\n\n\n\n\n\n\nFigure 44.4: Graphical residual analysis\n\n\n\n\n\n\n\n\n\n\n\nFigure 44.5: Graphical residual analysis\n\n\n\n\n\nThe default model structure in R is the linear model with dummy indicator variables. Hence, the “intercept” in this model is the mean yield for the control group. The two other parameters are the estimated effects of treatments 1 and 2. To recover the mean yield in treatment group 1, you would add the intercept term and the treatment 1 effect. To see how R sets the model up, use the model.matrix(lmod) function to extract the X matrix.\nThe anova() function in R compares variability of observations between the treatment groups to variability within the treatment groups to test whether all means are equal or whether at least one is different. The small p-value here suggests that the means are not all equal.\nLet’s fit the cell means model in JAGS.\n\n\nCode\nlibrary(\"rjags\")\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[grp[i]], prec)\n    }\n    \n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*1.0/2.0)\n    sig = sqrt( 1.0 / prec )\n} \"\n\nset.seed(82)\nstr(PlantGrowth)\n\n\n'data.frame':   30 obs. of  2 variables:\n $ weight: num  4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ...\n $ group : Factor w/ 3 levels \"ctrl\",\"trt1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nCode\ndata_jags = list(y=PlantGrowth$weight, \n              grp=as.numeric(PlantGrowth$group))\n\nparams = c(\"mu\", \"sig\")\n\ninits = function() {\n    inits = list(\"mu\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 30\n   Unobserved stochastic nodes: 4\n   Total graph size: 74\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,\n                        variable.names=params,\n                        n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim)) # combined chains\n\n\n\n\n44.2.3 Model checking\nAs usual, we check for convergence of our MCMC.\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nmu[1]          1          1\nmu[2]          1          1\nmu[3]          1          1\nsig            1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n              mu[1]        mu[2]         mu[3]          sig\nLag 0   1.000000000  1.000000000  1.0000000000  1.000000000\nLag 1   0.003656711 -0.002301641 -0.0028973173  0.083759765\nLag 5  -0.001392551 -0.007372979 -0.0108581375  0.006196493\nLag 10  0.008375134 -0.002472894  0.0007090078 -0.002808355\nLag 50 -0.013190019 -0.005104625 -0.0188899301 -0.002283578\n\n\nCode\neffectiveSize(mod_sim)\n\n\n   mu[1]    mu[2]    mu[3]      sig \n15184.55 15000.00 15959.91 12692.50 \n\n\n\n\n\n\n\n\nFigure 44.6: MCMC convergence diagnostics\n\n\n\n\n\nWe can also look at the residuals to see if there are any obvious problems with our model choice.\n\n\nCode\n(pm_params = colMeans(mod_csim))\n\n\n   mu[1]    mu[2]    mu[3]      sig \n5.032301 4.661779 5.525400 0.712715 \n\n\n\n\nCode\nyhat = pm_params[1:3][data_jags$grp]\nresid = data_jags$y - yhat\nplot(resid)\n\n\n\n\n\n\n\n\nFigure 44.7: Residuals vs Index\n\n\n\n\n\n\n\nCode\nplot(yhat, resid)\n\n\n\n\n\n\n\n\nFigure 44.8: Residuals vs Fitted values for PlantGrowth model\n\n\n\n\n\nAgain, it might be appropriate to have a separate variance for each group. We will have you do that as an exercise.\n\n\n44.2.4 Results\nLet’s look at the posterior summary of the parameters.\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD  Naive SE Time-series SE\nmu[1] 5.0323 0.2278 0.0018598      0.0018496\nmu[2] 4.6618 0.2270 0.0018532      0.0018531\nmu[3] 5.5254 0.2255 0.0018413      0.0017909\nsig   0.7127 0.0920 0.0007512      0.0008174\n\n2. Quantiles for each variable:\n\n       2.5%    25%    50%    75%  97.5%\nmu[1] 4.576 4.8840 5.0320 5.1818 5.4810\nmu[2] 4.217 4.5126 4.6614 4.8128 5.1059\nmu[3] 5.080 5.3760 5.5249 5.6723 5.9782\nsig   0.560 0.6475 0.7028 0.7677 0.9193\n\n\n\n\nCode\nHPDinterval(mod_csim)\n\n\n          lower     upper\nmu[1] 4.5721068 5.4751405\nmu[2] 4.2140180 5.1010809\nmu[3] 5.0677772 5.9634712\nsig   0.5439966 0.8945425\nattr(,\"Probability\")\n[1] 0.95\n\n\nThe HPDinterval() function in the coda package calculates intervals of highest posterior density for each parameter.\nWe are interested to know if one of the treatments increases mean yield. It is clear that treatment 1 does not. What about treatment 2?\n\n\nCode\nmean(mod_csim[,3] &gt; mod_csim[,1])\n\n\n[1] 0.939\n\n\nThere is a high posterior probability that the mean yield for treatment 2 is greater than the mean yield for the control group.\nIt may be the case that treatment 2 would be costly to put into production. Suppose that to be worthwhile, this treatment must increase mean yield by 10%. What is the posterior probability that the increase is at least that?\n\n\nCode\nmean(mod_csim[,3] &gt; 1.1*mod_csim[,1])\n\n\n[1] 0.4844667\n\n\nWe have about 50/50 odds that adopting treatment 2 would increase mean yield by at least 10%.",
    "crumbs": [
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>ANOVA - M3L8</span>"
    ]
  },
  {
    "objectID": "C2-L08.html#two-factor-anova",
    "href": "C2-L08.html#two-factor-anova",
    "title": "44  ANOVA - M3L8",
    "section": "44.3 Two Factor ANOVA",
    "text": "44.3 Two Factor ANOVA\n\n44.3.1 Data\nLet’s explore an example with two factors. We’ll use the Warpbreaks data set in R. Check the documentation for a description of the data by typing ?warpbreaks.\n\n\nCode\ndata(\"warpbreaks\")\n#?warpbreaks\nhead(warpbreaks)\n\n\n  breaks wool tension\n1     26    A       L\n2     30    A       L\n3     54    A       L\n4     25    A       L\n5     70    A       L\n6     52    A       L\n\n\n\nCode\n# This chunk is for displaying the output that was previously static.\n# If the static output below is preferred, this chunk can be removed \n# and the static output remains unlabelled as it's not a code cell.\n# For a labeled table, this chunk should generate it.\n# The original file had static output here:\n##   breaks wool tension\n## 1     26    A       L\n## 2     30    A       L\n## 3     54    A       L\n## 4     25    A       L\n## 5     70    A       L\n## 6     52    A       L\n# To make this a labeled table from code:\nhead(warpbreaks)\n\n\n\n\nTable 44.1: Preview of first few rows of warpbreaks data\n\n\n\n  breaks wool tension\n1     26    A       L\n2     30    A       L\n3     54    A       L\n4     25    A       L\n5     70    A       L\n6     52    A       L\n\n\n\n\n\nCode\ntable(warpbreaks$wool, warpbreaks$tension)\n\n\n\n\nTable 44.2: Contingency table of wool type vs tension level\n\n\n\n   \n    L M H\n  A 9 9 9\n  B 9 9 9\n\n\n\n\nAgain, we visualize the data with box plots.\n\n\nCode\nboxplot(breaks ~ wool + tension, data=warpbreaks)\n\n\n\n\n\n\n\n\nFigure 44.9: Warpbreaks boxplot\n\n\n\n\n\n\n\nCode\nboxplot(log(breaks) ~ wool + tension, data=warpbreaks)\n\n\n\n\n\n\n\n\nFigure 44.10: Warpbreaks boxplot with log-transformed breaks\n\n\n\n\n\nThe different groups have more similar variance if we use the logarithm of breaks. From this visualization, it looks like both factors may play a role in the number of breaks. It appears that there is a general decrease in breaks as we move from low to medium to high tension. Let’s start with a one-way model using tension only.\n\n\n44.3.2 One-way model\n\n\nCode\nmod1_string = \" model {\n    for( i in 1:length(y)) {\n        y[i] ~ dnorm(mu[tensGrp[i]], prec)\n    }\n    \n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*2.0/2.0)\n    sig = sqrt(1.0 / prec)\n} \"\n\nset.seed(83)\nstr(warpbreaks)\n\n\n'data.frame':   54 obs. of  3 variables:\n $ breaks : num  26 30 54 25 70 52 51 26 67 18 ...\n $ wool   : Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ tension: Factor w/ 3 levels \"L\",\"M\",\"H\": 1 1 1 1 1 1 1 1 1 2 ...\n\n\nCode\ndata1_jags = list(y=log(warpbreaks$breaks), tensGrp=as.numeric(warpbreaks$tension))\n\nparams1 = c(\"mu\", \"sig\")\n\nmod1 = jags.model(textConnection(mod1_string), data=data1_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 54\n   Unobserved stochastic nodes: 4\n   Total graph size: 123\n\nInitializing model\n\n\nCode\nupdate(mod1, 1e3)\n\nmod1_sim = coda.samples(model=mod1,\n                        variable.names=params1,\n                        n.iter=5e3)\n\n\n\n\nCode\n## convergence diagnostics\nplot(mod1_sim)\n\n\n\n\n\n\n\n\nFigure 44.11: MCMC convergence diagnostics for one-way tension model\n\n\n\n\n\n\n\nCode\ngelman.diag(mod1_sim)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nmu[1]          1          1\nmu[2]          1          1\nmu[3]          1          1\nsig            1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod1_sim)\n\n\n              mu[1]         mu[2]       mu[3]          sig\nLag 0   1.000000000  1.0000000000 1.000000000  1.000000000\nLag 1  -0.003023805  0.0004752912 0.008436290  0.052770937\nLag 5   0.007091078 -0.0033775742 0.005640492  0.007006466\nLag 10  0.006346392  0.0051657346 0.008808167 -0.001324747\nLag 50  0.002963112 -0.0053128002 0.007948405 -0.006532931\n\n\nCode\neffectiveSize(mod1_sim)\n\n\n   mu[1]    mu[2]    mu[3]      sig \n15000.00 15000.00 15430.01 13166.09 \n\n\nThe 95% posterior interval for the mean of group 2 (medium tension) overlaps with both the low and high groups, but the intervals for low and high group only slightly overlap. That is a pretty strong indication that the means for low and high tension are different. Let’s collect the DIC for this model and move on to the two-way model.\n\n\nCode\ndic1 = dic.samples(mod1, n.iter=1e3)\n\n\n\n\n44.3.3 Two-way additive model\nWith two factors, one with two levels and the other with three, we have six treatment groups, which is the same situation we discussed when introducing multiple factor ANOVA. We will first fit the additive model which treats the two factors separately with no interaction. To get the X matrix (or design matrix) for this model, we can create it in R.\n\nCode\nX = model.matrix( ~ wool + tension, data=warpbreaks)\nhead(X)\n\n\n\n\nTable 44.3: Head of the design matrix for the additive model\n\n\n\n  (Intercept) woolB tensionM tensionH\n1           1     0        0        0\n2           1     0        0        0\n3           1     0        0        0\n4           1     0        0        0\n5           1     0        0        0\n6           1     0        0        0\n\n\n\n\n\nCode\ntail(X)\n\n\n\n\nTable 44.4: Tail of the design matrix for the additive model\n\n\n\n   (Intercept) woolB tensionM tensionH\n49           1     1        0        1\n50           1     1        0        1\n51           1     1        0        1\n52           1     1        0        1\n53           1     1        0        1\n54           1     1        0        1\n\n\n\n\nBy default, R has chosen the mean for wool A and low tension to be the intercept. Then, there is an effect for wool B, and effects for medium tension and high tension, each associated with dummy indicator variables.\n\n\nCode\nmod2_string = \" model {\n    for( i in 1:length(y)) {\n        y[i] ~ dnorm(mu[i], prec)\n        mu[i] = int + alpha*isWoolB[i] + beta[1]*isTensionM[i] + beta[2]*isTensionH[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1.0e6)\n    alpha ~ dnorm(0.0, 1.0/1.0e6)\n    for (j in 1:2) {\n        beta[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(3/2.0, 3*1.0/2.0)\n    sig = sqrt(1.0 / prec)\n} \"\n\ndata2_jags = list(y=log(warpbreaks$breaks), isWoolB=X[,\"woolB\"], isTensionM=X[,\"tensionM\"], isTensionH=X[,\"tensionH\"])\n\nparams2 = c(\"int\", \"alpha\", \"beta\", \"sig\")\n\nmod2 = jags.model(textConnection(mod2_string), data=data2_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 54\n   Unobserved stochastic nodes: 5\n   Total graph size: 243\n\nInitializing model\n\n\nCode\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params2,\n                        n.iter=5e3)\n\n\n\n\nCode\n## convergence diagnostics\nplot(mod2_sim)\n\ngelman.diag(mod2_sim)    # Corrected from mod1_sim\n\n\nPotential scale reduction factors:\n\n        Point est. Upper C.I.\nalpha            1       1.01\nbeta[1]          1       1.01\nbeta[2]          1       1.00\nint              1       1.01\nsig              1       1.00\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod2_sim)  # Corrected from mod1_sim\n\n\n               alpha      beta[1]     beta[2]        int           sig\nLag 0   1.0000000000 1.0000000000 1.000000000 1.00000000  1.0000000000\nLag 1   0.4963697431 0.5006823314 0.500402030 0.75583862  0.0844328923\nLag 5   0.0229258403 0.1144710221 0.108038413 0.20066703  0.0128372994\nLag 10 -0.0058353358 0.0168521386 0.021891075 0.03322369 -0.0004074847\nLag 50  0.0003204391 0.0006336824 0.006267782 0.01062358  0.0014607910\n\n\nCode\neffectiveSize(mod2_sim) # Corrected from mod1_sim\n\n\n    alpha   beta[1]   beta[2]       int       sig \n 4970.097  3519.314  3627.036  2367.663 12387.350 \n\n\n\n\n\n\n\n\nFigure 44.12: Convergence and diagnostics for the additive two-way ANOVA model\n\n\n\n\n\n\n\n\n\n\n\nFigure 44.13: Convergence and diagnostics for the additive two-way ANOVA model\n\n\n\n\n\nLet’s summarize the results, collect the DIC for this model, and compare it to the first one-way model.\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean      SD  Naive SE Time-series SE\nalpha   -0.1502 0.12513 0.0010217       0.001778\nbeta[1] -0.2846 0.15235 0.0012439       0.002596\nbeta[2] -0.4847 0.15230 0.0012435       0.002540\nint      3.5721 0.12582 0.0010273       0.002609\nsig      0.4546 0.04536 0.0003703       0.000408\n\n2. Quantiles for each variable:\n\n           2.5%     25%     50%      75%    97.5%\nalpha   -0.3963 -0.2332 -0.1501 -0.06803  0.09724\nbeta[1] -0.5897 -0.3851 -0.2841 -0.18290  0.01549\nbeta[2] -0.7854 -0.5869 -0.4842 -0.38263 -0.18615\nint      3.3228  3.4875  3.5723  3.65728  3.81592\nsig      0.3761  0.4226  0.4516  0.48289  0.55332\n\n\n\n\nCode\n(dic2 = dic.samples(mod2, n.iter=1e3))\n\n\nMean deviance:  55.45 \npenalty 5.217 \nPenalized deviance: 60.66 \n\n\nCode\ndic1\n\n\nMean deviance:  66.59 \npenalty 3.973 \nPenalized deviance: 70.56 \n\n\nThis suggests there is much to be gained adding the wool factor to the model. Before we settle on this model however, we should consider whether there is an interaction. Let’s look again at the box plot with all six treatment groups.\n\n\nCode\nboxplot(log(breaks) ~ wool + tension, data=warpbreaks)\n\n\n\n\n\n\n\n\nFigure 44.14: Re-examining boxplot of log(breaks) by wool and tension for interaction effects\n\n\n\n\n\nOur two-way model has a single effect for wool B and the estimate is negative. If this is true, then we would expect wool B to be associated with fewer breaks than its wool A counterpart on average. This is true for low and high tension, but it appears that breaks are higher for wool B when there is medium tension. That is, the effect for wool B is not consistent across tension levels, so it may appropriate to add an interaction term. In R, this would look like:\n\n\nCode\nlmod2 = lm(log(breaks) ~ .^2, data=warpbreaks)\nsummary(lmod2)\n\n\n\nCall:\nlm(formula = log(breaks) ~ .^2, data = warpbreaks)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.81504 -0.27885  0.04042  0.27319  0.64358 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      3.7179     0.1247  29.824  &lt; 2e-16 ***\nwoolB           -0.4356     0.1763  -2.471  0.01709 *  \ntensionM        -0.6012     0.1763  -3.410  0.00133 ** \ntensionH        -0.6003     0.1763  -3.405  0.00134 ** \nwoolB:tensionM   0.6281     0.2493   2.519  0.01514 *  \nwoolB:tensionH   0.2221     0.2493   0.891  0.37749    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.374 on 48 degrees of freedom\nMultiple R-squared:  0.3363,    Adjusted R-squared:  0.2672 \nF-statistic: 4.864 on 5 and 48 DF,  p-value: 0.001116\n\n\nAdding the interaction, we get an effect for being in wool B and medium tension, as well as for being in wool B and high tension. There are now six parameters for the mean, one for each treatment group, so this model is equivalent to the full cell means model. Let’s use that.\n\n\n44.3.4 Two-way cell means model\nIn this new model, \\mu will be a matrix with six entries, each corresponding to a treatment group.\n\n\nCode\nmod3_string = \" model {\n    for( i in 1:length(y)) {\n        y[i] ~ dnorm(mu[woolGrp[i], tensGrp[i]], prec)\n    }\n    \n    for (j in 1:max(woolGrp)) {\n        for (k in 1:max(tensGrp)) {\n            mu[j,k] ~ dnorm(0.0, 1.0/1.0e6)\n        }\n    }\n    \n    prec ~ dgamma(3/2.0, 3*1.0/2.0)\n    sig = sqrt(1.0 / prec)\n} \"\n\nstr(warpbreaks)\n\n\n'data.frame':   54 obs. of  3 variables:\n $ breaks : num  26 30 54 25 70 52 51 26 67 18 ...\n $ wool   : Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ tension: Factor w/ 3 levels \"L\",\"M\",\"H\": 1 1 1 1 1 1 1 1 1 2 ...\n\n\nCode\ndata3_jags = list(y=log(warpbreaks$breaks), woolGrp=as.numeric(warpbreaks$wool), tensGrp=as.numeric(warpbreaks$tension))\n\nparams3 = c(\"mu\", \"sig\")\n\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 54\n   Unobserved stochastic nodes: 7\n   Total graph size: 179\n\nInitializing model\n\n\nCode\nupdate(mod3, 1e3)\n\nmod3_sim = coda.samples(model=mod3,\n                        variable.names=params3,\n                        n.iter=5e3)\nmod3_csim = as.mcmc(do.call(rbind, mod3_sim))\n\n\n\n\nCode\nplot(mod3_sim)\n\n\n\n\n\n\n\n\nFigure 44.15: Traceplots for the cell means model\n\n\n\n\n\n\n\n\n\n\n\nFigure 44.16: Traceplots for the cell means model\n\n\n\n\n\n\n\nCode\n## convergence diagnostics\ngelman.diag(mod3_sim)\n\n\nPotential scale reduction factors:\n\n        Point est. Upper C.I.\nmu[1,1]          1          1\nmu[2,1]          1          1\nmu[1,2]          1          1\nmu[2,2]          1          1\nmu[1,3]          1          1\nmu[2,3]          1          1\nsig              1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod3_sim)\n\n\n            mu[1,1]       mu[2,1]       mu[1,2]      mu[2,2]     mu[1,3]\nLag 0   1.000000000  1.0000000000  1.0000000000  1.000000000 1.000000000\nLag 1   0.001962758  0.0001267009  0.0009255063 -0.010719996 0.003169282\nLag 5  -0.002710347  0.0075781771  0.0081758033 -0.010380946 0.006443187\nLag 10 -0.004153847  0.0055095473  0.0072886721 -0.006077266 0.007483246\nLag 50 -0.005520895 -0.0027763402 -0.0010552230  0.016245098 0.017451102\n             mu[2,3]           sig\nLag 0   1.0000000000  1.0000000000\nLag 1   0.0064286311  0.1090668514\nLag 5  -0.0053611083  0.0149190505\nLag 10  0.0008457485 -0.0037881215\nLag 50 -0.0010996877 -0.0008233877\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n mu[1,1]  mu[2,1]  mu[1,2]  mu[2,2]  mu[1,3]  mu[2,3]      sig \n15000.00 15000.00 15315.17 15233.12 15068.28 14891.62 12047.40 \n\n\nCode\nraftery.diag(mod3_sim)\n\n\n[[1]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                               \n         Burn-in  Total Lower bound  Dependence\n         (M)      (N)   (Nmin)       factor (I)\n mu[1,1] 2        3995  3746         1.070     \n mu[2,1] 2        3866  3746         1.030     \n mu[1,2] 2        3866  3746         1.030     \n mu[2,2] 2        3620  3746         0.966     \n mu[1,3] 2        3680  3746         0.982     \n mu[2,3] 2        3803  3746         1.020     \n sig     3        4062  3746         1.080     \n\n\n[[2]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                               \n         Burn-in  Total Lower bound  Dependence\n         (M)      (N)   (Nmin)       factor (I)\n mu[1,1] 2        3995  3746         1.070     \n mu[2,1] 2        3620  3746         0.966     \n mu[1,2] 2        3803  3746         1.020     \n mu[2,2] 2        3680  3746         0.982     \n mu[1,3] 2        3803  3746         1.020     \n mu[2,3] 2        3741  3746         0.999     \n sig     2        3741  3746         0.999     \n\n\n[[3]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                               \n         Burn-in  Total Lower bound  Dependence\n         (M)      (N)   (Nmin)       factor (I)\n mu[1,1] 2        3680  3746         0.982     \n mu[2,1] 2        3680  3746         0.982     \n mu[1,2] 2        3803  3746         1.020     \n mu[2,2] 2        3930  3746         1.050     \n mu[1,3] 2        3995  3746         1.070     \n mu[2,3] 2        3741  3746         0.999     \n sig     2        3680  3746         0.982     \n\n\nLet’s compute the DIC and compare with our previous models.\n\n\nCode\n(dic3 = dic.samples(mod3, n.iter=1e3))\n\n\nMean deviance:  51.99 \npenalty 7.275 \nPenalized deviance: 59.26 \n\n\nCode\ndic2\n\n\nMean deviance:  55.45 \npenalty 5.217 \nPenalized deviance: 60.66 \n\n\nCode\ndic1\n\n\nMean deviance:  66.59 \npenalty 3.973 \nPenalized deviance: 70.56 \n\n\nThis suggests that the full model with interaction between wool and tension (which is equivalent to the cell means model) is the best for explaining/predicting warp breaks.\n\n\n44.3.5 Results\n\n\nCode\nsummary(mod3_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean     SD  Naive SE Time-series SE\nmu[1,1] 3.7157 0.1487 0.0012144      0.0012145\nmu[2,1] 3.2819 0.1472 0.0012021      0.0012021\nmu[1,2] 3.1155 0.1473 0.0012031      0.0011911\nmu[2,2] 3.3101 0.1475 0.0012042      0.0011953\nmu[1,3] 3.1196 0.1476 0.0012054      0.0012033\nmu[2,3] 2.9045 0.1478 0.0012067      0.0012113\nsig     0.4422 0.0445 0.0003634      0.0004054\n\n2. Quantiles for each variable:\n\n          2.5%    25%    50%   75%  97.5%\nmu[1,1] 3.4188 3.6188 3.7161 3.814 4.0099\nmu[2,1] 2.9948 3.1834 3.2825 3.380 3.5718\nmu[1,2] 2.8248 3.0168 3.1146 3.212 3.4078\nmu[2,2] 3.0218 3.2116 3.3097 3.409 3.6016\nmu[1,3] 2.8299 3.0206 3.1187 3.219 3.4136\nmu[2,3] 2.6176 2.8055 2.9042 3.003 3.1993\nsig     0.3655 0.4106 0.4383 0.470 0.5405\n\n\n\n\nCode\nHPDinterval(mod3_csim)\n\n\n            lower     upper\nmu[1,1] 3.4123636 4.0004287\nmu[2,1] 2.9924908 3.5688516\nmu[1,2] 2.8369857 3.4170758\nmu[2,2] 3.0299707 3.6079122\nmu[1,3] 2.8138336 3.3956200\nmu[2,3] 2.6091394 3.1885393\nsig     0.3630337 0.5347603\nattr(,\"Probability\")\n[1] 0.95\n\n\n\n\nCode\npar(mfrow=c(3,2)) # arrange frame for plots\ndensplot(mod3_csim[,1:6], xlim=c(2.0, 4.5))\n\n\n\n\n\n\n\n\nFigure 44.17: Posterior densities for cell means\n\n\n\n\n\nIt might be tempting to look at comparisons between each combination of treatments, but we warn that this could yield spurious results. When we discussed the statistical modeling cycle, we said it is best not to search your results for interesting hypotheses, because if there are many hypotheses, some will appear to show “effects” or “associations” simply due to chance. Results are most reliable when we determine a relatively small number of hypotheses we are interested in beforehand, collect the data, and statistically evaluate the evidence for them.\nOne question we might be interested in with these data is finding the treatment combination that produces the fewest breaks. To calculate this, we can go through our posterior samples and for each sample, find out which group has the smallest mean. These counts help us determine the posterior probability that each of the treatment groups has the smallest mean.\n\nCode\nprop.table( table( apply(mod3_csim[,1:6], 1, which.min) ) )\n\n\n\n\nTable 44.5: Posterior probabilities of each treatment group having the smallest mean break rate\n\n\n\n\n         2          3          4          5          6 \n0.01493333 0.11940000 0.01066667 0.11453333 0.74046667 \n\n\n\n\nThe evidence supports wool B with high tension as the treatment that produces the fewest breaks.",
    "crumbs": [
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>ANOVA - M3L8</span>"
    ]
  },
  {
    "objectID": "C2-L08-Ex1.html",
    "href": "C2-L08-Ex1.html",
    "title": "45  Homework on ANOVA - M3L8HW1",
    "section": "",
    "text": "Caution\n\n\n\nSection omitted to comply with the Honor Code",
    "crumbs": [
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Homework on ANOVA - M3L8HW1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html",
    "href": "C4-L03.html",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "",
    "text": "91 The Normal Dynamic Linear Model: Definition, Model classes & The Superposition Principle\nNormal Dynamic Linear Models (NDLMs) are defined and illustrated in this module using several examples Model building based on the forecast function via the superposition principle is explained. Methods for Bayesian filtering, smoothing and forecasting for NDLMs in the case of known observational variances and known system covariance matrices are discussed and illustrated..\nThe Normal Dynamic Linear Model (DLM) is covered (R. Prado, Ferreira, and West 2023, 117–44)\nDynamic Linear Models (DLMs) extend classical linear regression to time-indexed data, introducing dependencies between observations through latent evolving parameters. A Normal DLM (NDLM) assumes Gaussian noise at both observation and system levels, enabling tractable Bayesian inference through the Kalman filter.\nWhile superficially complex, NDLMs are conceptually close to linear regression. Instead of I.I.D. observations indexed by i, we index data by time t and allow parameters to evolve with time, resulting in a two-level hierarchical model. At the top level is the observation equation. Below this there is the evolution equation(s) that can be understood as a latent state transition model that can capture trends, periodicity, and regression. The evolution equations can have more than one level however we will see that with some work these are summarized into a matrix form.\nTo make things simpler this is demonstrated using a white noise process and then a random walk model. What makes the NDLM somewhat different is that that there are two variance elements at two levels, necessitating learning more parameters. Once we cover these to models the instructor walks us though all the bits and pieces of the notation. Later we will see that we can add trends, periodicity, regression components in a more or less systematic way. However we need to pick and choose these components to get a suitable forecast function. This approach require an intimate familiarity with the data generating process to model.\nThis approach is Bayesian in that we draw our parameters from a multivariate normal and use updating to improve this initial estimate by incorporating the data and we end up with a posterior i.e. we have distributional view of the time series incorporating uncertainties. Additionally we have a number of Bayesian quantities that can be derived from the model, such as\nHowever the DLM framework is quite flexible and once you understand it it can ve adapted to support features like seasonality using the superposition principle. NDLMs don’t need to be non-stationary time series.\nAs far as I cen tell NDLMs are just DLM with their errors distributed normally at the different levels.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#ndlm-definition-video",
    "href": "C4-L03.html#ndlm-definition-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.1 NDLM Definition (Video)",
    "text": "91.1 NDLM Definition (Video)\n\n\n\n\nNDLM Motivation\n\n\n\n\nNDLM general form\n\n\n\n\nthe forecast function\n\n\n\n\nIn this module, we will motivate and develop a class of models suitable for for analyzing and forecasting non-stationary time series called normal dynamic linear models . We will talk about Bayesian inference and forecasting within this class of models and describe model building as well.\n\n91.1.1 White Noise - A motivating example\nLet’s begin with a very simple model that has no temporal structure, just a mean value with some variation that is:\n\ny_t = \\mu + v_t \\qquad v_t \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, \\nu) \\qquad  \\text{(white noise model)}\n\\tag{91.1}\nwhere:\n\ny_t is the observed time series at time t,\n\\mu is the expected value of y_t this is characteristic we are interested in,\n\\nu_t is a white noise process as usual iid standard normal N(0,1).\n\nIf we plot this model we might see the following graph:\n\n\nCode\nset.seed(123)\nn &lt;- 100\nV &lt;- 1\nmu &lt;- 0\ny &lt;- mu + rnorm(n, 0, V)\nplot(y, type = \"l\", col = \"blue\", lwd = 2, xlab = \"Time\", ylab = \"y\", main = \"Model with no temporal structure\")\n\n\n\n\n\n\n\n\nFigure 91.1\n\n\n\n\n\nFor this model the mean of the time series is \\mu will be the the expected value of y_t, which is \\mu. And the variance of y_t is \\nu.\n\n\\mathbb{E}[y_t] = \\mu \\qquad \\text{and} \\qquad \\mathbb{V}ar[y_t] = \\nu \\qquad\n\\tag{91.2}\n\n\n91.1.2 A Random walk model with a slowly changing mean\nNext we incorporate some temporal structure, we allow the expected value of the time series, to change over time. To can achieve this, by update the model definition with a \\mu_t where the index indicates that it can change at every time step. And let us keep the noise unchanged. i.e. we set it to \\mu_t \\in N(0,\\nu).\nWe get the following model:\n\ny_t = \\mu_t + \\nu_t \\quad \\nu_t \\overset{\\text{iid}}{\\sim} N(0, V) \\qquad \\text{(radom walk model)}\n\\tag{91.3}\nTo complete this we need to also decide how to incorporate the the changes over time in the parameter \\mu_t. We might consider different options but we should pick the simplest possible to start with. One option is to assume that the expected value of \\mu_t is just the expected value of \\mu_{t-1} plus some noise.\nWe now have that random walk type of structure where \\mu_t can be written in terms of \\mu(t-1). The expected value of \\mu_t, we can think of it as \\mu_{t-1} + \\text{some noise}. This error is once again, assumed to be normally distributed random variable centered at zero and with variance W. Another assumption that we have made here is that the \\nu_t and \\omega_t, are also independent of each other.\nputting this together we get:\n\n\\begin{aligned}\ny_t &= \\mu_t + \\nu_t & \\nu_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, V)  & \\text{(Observation eq.)} \\\\\n\\mu_t &= \\mu_{t-1} + \\omega_t  & \\omega_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, W) & \\text{(System/evolution eq.)}\n\\end{aligned}\n\\tag{91.4}\nWith this model, what we are assuming is that the mean level of the series is changing over time. Note that this is an example of a Gaussian or Normal dynamic linear model.\nNDLMs are a two level hierarchical models where :\n\nAt the top is an observation level equation relating observations y at time t to some time dependent, (hidden) state parameters and some observation level iid distributed error.\nThe system evolution level equation describes the dynamics of parameters over time and incorporates some system iid distributed error.\nThese equations have a linear structure, in the sense that the expected value of y at time t is a linear function of the parameters.\nWe have the assumption of normality for the noise terms in both these equations as well as independence within and between levels.\n\nThis is our first example. Next we will be discuss the general class of models. Later we will consider how to incorporate different structures into the model, and how to perform Bayesian inference for filtering smoothing and forecasting.\n\n\n91.1.3 General form of the NDLM\nThe general class of dynamic linear models can be written as follows:\nWe are going to have two equations. One is the so-called observation equation that relates the observations to the parameters in the model, and the notation we are going to use is as follows.\n\\begin{aligned}\ny_t &= \\vec{F}_t' \\vec{\\theta}_t   + \\nu_t && \\nu_t \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, V_t) && \\text{(obs)} \\\\\n\\vec{\\theta}_t &= G_t \\vec{\\theta}_{t-1} + \\vec{\\omega}_t && \\vec{\\omega}_t \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, W_t) && \\text{(system)}\n\\end{aligned}\n\\tag{91.5}\nWhere:\n\ny_t a univariate observation at time t.\n\\vec{\\theta}_t the state vector is a k-dimensional vector of unknown parameters at time t.\n\\vec{F_t} the observation operator a k*1-dimensional vector at time t that transforms the state parameters into observations.\n\\nu_t is the observation noise at time t from a Normal distribution with variance V_t.\nG_t the state evolution operator is a k \\times k matrix (known)\n\\omega_t the innovation or state evolution noise at time t distributed as N(0,W_t)(known)\nthe noise at the observation level and the system level are each iid and mutually iid.\n\nWe also have the prior distribution for the state vector at time 0:\n\n\\vec{\\theta}_0 \\sim N(\\vec{m}_0,c_0) a prior k-dimensional Normal distribution.\n\nm_0 the mean in the prior is a k-dimensional vector of means. (known)\nc_0 is the covariance matrix k by k. (known)\n\n\n\n\n\n\n\n\nNoteSome Thoughts on NDLM the definition\n\n\n\n\n\nQ. Why are F_t and G_t a vector and a matrix respectively?\n\nIt may helps to think about F and G as follows:\nF_t' acts as a linear transformation that maps the latent state \\vec{\\theta}_t into the observation space, of y.\nG_t is a linear transformation that describes how the state vector evolves over time. I like to think about it as a Hidden Markov state transition matrix.\nIn other words, F_t takes the current hidden state \\theta_t and produces an observation y_t, while G_t takes the current state and produces the next state.\n\nQ. Why is this called a linear model?\n\nThis is because both the observation equation is a linear equation that relates the observations to the parameters in the model and the system equation is a linear equation that tells us how the time-varying parameter is going to be changing over time. This is why we call this a linear model.\n\nQ. Why are the noise terms \\nu_t and \\omega_t assumed to be normally distributed?\n\nThis is a common assumption in time series analysis. It is a convenient assumption that allows us to perform Bayesian inference and forecasting in a very simple way. And this is why we call this a normal dynamic linear model.\n\nQ. Isn’t this just a hierarchical model?\n\nIndeed, this is a hierarchical model. We have a model for the observations and a model for the system level. The system level is changing over time and the observations are related to the system level through the observation equation. And so it is possible to extend this model to more complex structures if we wish to do so by adding another level, etc… However adding more levels leads to extra dynamics that are captured in G without changing the overall framework!\n\n\n\n\n\n\n91.1.4 Inference in the NDLM\nIn terms of the inference, there are a few different kinds of densities and quantities that we are interested in:\n One of the distributions that we are interested in finding is the so-called filtering distribution. We may be interested here in finding what is the density of \\theta_t given all the observations that we have up to time t.Filtering distribution\n\n\\mathcal{D}_t= \\{\\mathcal{D}_0, y_{1:T}\\}\n\\tag{91.6}\nWe will denote information as \\mathcal{D}_t. Usually, it is all the information we have at time zero (i.e. our prior), coupled with all the data points I have up to time t.\nHere we conditioning on all the observed quantities and the prior information up to time t, and I may be interested in just finding what is the distribution for \\theta_t. This is called filtering.\n\n\\mathbb{P}r(\\theta_t \\mid \\mathcal{D}_t) \\qquad \\text{filtering distribution}\n\\tag{91.7}\nforecasting distribution\nAnother distribution that is very important in time series analysis is the forecasting distribution. We may be interested in the distribution of y{t+h}? where we consider h lags into the future and we have all the information \\mathcal{D}_t, up to time t. We want to do a predictions here\n\n\\mathbb{P}r(y_{t+h} \\mid \\mathcal{D}_t) \\qquad \\text{forecasting distribution}\n\\tag{91.8}\n Another important quantity or an important set of distributions is what we call the smoothing distribution. Usually, you have a time series, when you get your data, you observe, I don’t know, 300 data points. As you go with the filtering, you are going to start from zero all the way to 300 and you’re going to update these filtering distributions as you go and move forward. We may want instead to revisit the parameter at time 10, for example, given that you now have observed all these 300 observations. In that case, you’re interested in densities that are of the form. Let’s say that you observe capital T in your process and now you are going to revisit that density for \\theta_t. This is now in the past. Here we assume that t&lt;T. This is called smoothing.Smoothing Distribution\nSo you have more observation once you have seen the data. We will talk about how to perform Bayesian inference to obtain all these distributions under this model setting.\n\n\\mathbb{P}r(\\theta_t \\mid \\mathcal{D}_T)  \\qquad t &lt; T \\qquad \\text{smoothing distribution}\n\\tag{91.9}\n\n\n91.1.5 The forecast function for the NDLM\nIn addition to all the structure that we described before and all the densities that we are interested in finding, we also have as usual, the so-called forecast function, which instead of being the density is just \\mathbb{E}[y(t+h)\\mid \\mathcal{D}_t] i.e. expected value of y at time t given all the information we have before time t.\n\n\\mathbb{E}[y(t+h)\\mid \\mathcal(D_t)] = F'_{t+h} G_{t+h} \\ldots G_{t+1} \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t]\n\\tag{91.10}\nThis is the form of the forecast function.\nThere are particular cases and particular models that we will be discussing in which the F_t=F, i.e. constant and also G_t = G is also constant for all t. In these cases, the forecast function can be simplified and written as:\n\nf_t(h) = \\mathbb{E}(y_{t+h} \\mid D_t) = F'G^h \\mathbb{E}(\\theta_t \\mid \\mathcal{D}_t)\n\\tag{91.11}\nOne thing that we will learn is that the eigen-structure of this matrix is very important to define the form of the forecast function, and it’s very important for model building and for adding components into your model.\n\n\n91.1.6 NDLM short form notation\nFinally, just in terms of short notation, we can always write down when we’re working with normal dynamic linear models, we may be referring to the model instead of writing the two equations, the system and the observation equation. I can just write all the components that define my model. \n\\{F_t, G_t, v_t, W_t\\}\n\\tag{91.12}\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nIn this part of the course, I will discuss the class of normal dynamic linear models for analyzing and forecasting non-stationary time series. We will talk about Bayesian inference and forecasting within this class of models and describe model building as well.\n\n91.1.7 Motivating example\nI want to begin first with a motivating example. Suppose you have a model that is very simple and has no temporal structure here, just a model that looks like this. You have your time series y_t. Then you’re interested in just thinking about what is the mean level of that time series. That mean level, I’m going to call it \\mu and then I have some noise and the noise is normally distributed. They are all independent, identically distributed normal random variables \\mathcal{N}(0,v). Again, I can think of my time series. Suppose that I have my time series here, and then I’m plotting y_t. Then I have something that looks like this. In this model that \\mu is going to try to get the mean of that time series, this expected value of y_t, which is \\mu. The variance here of y_t is v under this model. What may happen in practice again, this model has no temporal structure, I may want to incorporate some temporal structure that says, well, I think that the level of this, the expected value of this time series, should be changing over time. If you were to do that, you will write down a model where the \\mu changes over time, so it’s indexed in time. Then you have still your same noise here. Let’s again assume \\mathcal{N}(0,v). I have now to make a decision on how I’m going to incorporate temporal structure by modeling the changes over time in this parameter \\mu_t. You could consider different options.\nThe simplest possible, probably that you can consider is something that looks like this. You have that random walk type of structure where \\mu_t is now going to be written as \\mu_{t-1}. The expected value of \\mu_t, you’ll think of it as \\mu_{t-1} plus some noise. That error here is going to be again, assume normally distributed random variable centered at zero and with variance w. There is another assumption that we can make here and is that the nu t and omega t here, are also independent of each other. When I have this model, what am assuming here is that the mean level of the series is changing over time.\nThese type of models have a few characteristics. This is an example of a normal dynamic linear model, as we will see later. In this models, we usually have a few things.\nThe first thing is we have two equations. One is the so-called observation equation that is relating your y_t, your observed process to some parameters in the model that are changing over time. The next equation is the so-called system level equation or evolution equation that tells me how that time varying parameter is going to be changing over time. The other thing you may notice is that we have a linear structure both in the observational level and in the system level. The linear structure, in the sense of the expected value of y_t is just a linear function of that \\mu_t. It happens to be \\mu_t in this particular case. In the second level, I can think of the expected value of \\mu_t as a linear function given \\mu_{t-1}, so it’s a function that is linear on \\mu_{t-1}. There is that linear structure. The other thing that we have here is at both levels, we have the assumption of normality for the noise terms in those equations. This is an example of a Gaussian or normal dynamic. These are time-varying parameters linear model. We will be discussing the general class of models. This is just an example. We will also discuss how to build different structures into the model, as well as how to perform Bayesian inference and forecasting.\n\n\n91.1.8 General form of the model\nThe general class of dynamic linear models can be written as follows. Again, we are going to have two equations. One is the so-called observation equation that relates the observations to the parameters in the model, and the notation we are going to use is as follows. Here, my observations are univariate. We are discussing models for univariate time series. I have that related to a vector of parameters, \\theta_t plus some noise here. This is the noise. The noise are assumed to be independent, identically distributed normal random variables, 0, V_t. Then I have another equation which is a system equation that has this form. There is a general G_t matrix. This is going to be depending on \\theta_{t-1}. This is a vector, and then I have again, these are iid multivariate \\mathcal{N}(0, W_t). This is the observation equation. This is the system equation or evolution equation. This defines a normal dynamic linear model. Here, we are going to say that F_t is a vector. The dimension of the vector is going to be the same as the number of parameters in the model. Let’s say we have k. This is a vector of known values. For each t, we are going to assume that we know what that vector is. Then we have the vector of parameters here is also of dimension k of parameters. The G is the next thing we need to define is a known matrix. That one is also assumed to be known, and then I have V_t is variance at the observational level. The W_t we are going to assume at the beginning that these two quantities are also known for all the values t. This is the variance-covariance matrix at the system level. Again, if we think about these two equations, we have the model defined in this way.\nThere is a next piece that we need to consider if we are going to perform based in inference for the model parameters. The next piece that we need to consider to just fully specify the model is what is the prior distribution. In a normal dynamic linear model, the prior distribution is assumed to be conjugate here. In the case again in which V_t and W_t are known, we are going to be assuming that, say that zero, the parameter vector before observing any data is going to be normally distributed Multivariate normal with M_0 and C_0. The mean is a vector, again of the same dimension as \\theta_0. Then I have k by k covariance matrix there as well. These are assumed to be also given to move forward with the model.\n\n\n91.1.9 Inference, forecasting, smoothing, and filtering.\nIn terms of the inference, there are different kinds of densities and quantities that we are interested in. One distribution that we are interested in finding is the so-called filtering distribution. We may be interested here in finding what is the density of \\theta_{t} given all the observations that we have up to time t. I’m going to call and all the information that I have up to time t. I’m going to call that D_t . It can also be, in some cases, I will just write down. So D_t, you can view with all the info up to time t. Usually, it is all the information I have at time zero. Then coupled, if there is no additional information that’s going to be coupled with all the data points I have up to that time. Here I’m conditioning on all the observed quantities and the prior information up to time t, and I may be interested in just finding what is the distribution for \\theta_{t}.\nThis is called filtering. Another quantity that is very important in time series analysis is forecasting.\nI may be interested in just what is the density, the distribution of y_{t+h} ? Again, the number of steps ahead here, here I’m thinking of h, given that I have all this information up to time t. I’m interested in predictions here. We will be talking about forecasting. Then another important quantity or an important set of distributions is what we call the smoothing distribution. Usually, you have a time series, when you get your data, you observe, I don’t know, 300 data points. As you go with the filtering, you are going to start from zero all the way to 300 and you’re going to update these filtering distributions as you go and move forward. But then you may want to revisit your parameter at time 10, for example, given that you now have observed all these 300 observations. In that case, you’re interested in densities that are of the form. Let’s say that you observe capital T in your process and now you are going to revisit that density for \\theta_t. This is now in the past. Here we assume that t is smaller than capital T. This is called smoothing. So you have more observation once you have seen the data. We will talk about how to perform Bayesian inference to obtain all these distributions under this model setting.\n\n\n91.1.10 The forecast function\nIn addition to all the structure that we described before and all the densities that we are interested in finding, we also have as usual, the so-called forecast function, which is just instead of being the density is just expected value of y(t+h) given all the information I have up to time t. In the case of a general normal dynamic linear model, we have the structure for these just using the equations, the observation and the system of equations.\nWe’re going to have here G_{t+h}. We multiply all these all the way to G_(t+1), and then we have the \\mathbb{E}[\\theta_{t}\\mid D_t]. This is the form of the forecast function. There are particular cases and particular models that we will be discussing in which the F_t is equal to F, so is constant for all t and G_t is also constant for all t. In those cases, the forecast function can be simplified and written as F'G^h expected value. One thing that we will learn is that the eigen-structure of this matrix is very important to define the form of the forecast function, and it’s very important for model building and for adding components into your model.\n\n\n91.1.11 Short-form notation\nFinally, just in terms of short notation, we can always write down when we’re working with normal dynamic linear models, we may be referring to the model instead of writing the two equations, the system and the observation equation. I can just write all the components that define my model. This fully specifies the model in terms of the two equations. If I know what Ft is, what Gt is, what Vt is, and the covariance at the system level. I sometimes will be just talking about a short notation like this for defining the model.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#polynomial-trend-models-video",
    "href": "C4-L03.html#polynomial-trend-models-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.2 Polynomial Trend Models (Video)",
    "text": "91.2 Polynomial Trend Models (Video)\n\n\n\n\nfirst and second order polynomial model\n\n\n\n\np-order polynomial model\n\n\nWhile we haven’t talked about the superposition principle yet we start at looking at adding different components to the DLM.\nWe might :\n\nsetting a baseline mean and variance\nadding a random walk with its variance\nadd a trend\nadd a regression\nadd seasonality\n\nNext we want to extend the random walk model to include different types of trends and this will be covered by the polynomial trend models. These are models that are useful to model linear trends or polynomial trends in your time series. So if you have a data set, where you have an increasing trend, or a decreasing trend, you would use one of those components in your model. Also\n\n91.2.1 First order polynomial model\nThe first order model is developed at great detail in chapter In (West and Harrison 2013 ch. 2). I don’t know what to make of it, isn’t this a trivial white noise model?\nThe math for Bayesian updating is fairly straight forward and must be much more complex with more sophisticated dynamics. So this is used by the authors to introduce their DLM and an 30 pages of the book is dedicated to in depth analysis and Bayesian development of this specific model and different distribution of interests as well as including comparison to other models and a look at the signal to noise ratio in the model.\nIt is worthwhile pointing out that these models get their name from their forecast function which will takes the general form Equation 91.22\nThe first order polynomial model is a model that is useful to describe linear trends in your time series. If you have a data set where you have an increasing trend or a decreasing trend, you would use one of those components in your model.\nSo the all those can be incorporated using the general p-order polynomial model, so I will just describe the form of this model.\nA first order polynomial is of the form Ax+B where A is the slope and B is the intercept. This is the same random walk model we saw above.\n\n\\begin{aligned}\ny_t &= \\theta_t + \\nu_t, \\qquad & \\nu_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, V_t) \\\\\n\\theta_t &= \\theta_{t-1} + \\omega_t, \\qquad & \\omega_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, W_t) \\\\\n&\\{1,1,v_t,W_t\\} && \\text{(short form)}\\\\\nf_t(h) &= \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t] && \\text{(forecast fn)}\\\\\n\\end{aligned}\n\\tag{91.13}\nIn the observation equation, \\theta_{t} is the level of the series at time t and \\nu_t is the observation error. In the evolution equation we see the mean for this parameter changing over time as a random walk or a local constant mean with evolution noise \\omega_t.\n(West and Harrison 2013, sec. 2.1) gives the following representation of the model:\nIt is useful to think of \\theta_t as a smooth function of time \\theta(t) with an associated Taylor series representation\n\n\\theta(t + \\delta t) = \\theta(t) + \\text{higher-order terms}\n\\tag{91.14}\nwhere the higher-order terms are assumed to be zero-mean noise. This is a very important point, because it means that we are not trying to model the higher-order terms explicitly, but rather we are assuming that they are just noise.\nwith the model simply describing the higher-order terms as zero-mean noise.\nThis is the genesis of the first-order polynomial DLM: the level model is a locally constant (first-order polynomial) proxy for the underlying evolution.·\nWe can write it down in short form with the following quadruple/\n\n\\{1, 1, V_t, W_t\\} \\qquad f_t(h) = \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t] = k_t \\ \\forall   h&gt;0\n\\tag{91.15}\nNext we can write the forecast function f_t(h) of this model using the representation we gave in Equation 91.15.\nAgain, we’re going to have something of the form F transposed G to the power of h and then the expected value of that \\theta_t given \\mathcal{D}_t. F is 1, G is 1, therefore I’m going to end up having just expected value of \\theta_t given \\mathcal{D}_t.\nWhich depending on the data that you have is you’re just going to have something that is a value that depends on t and it doesn’t depend on h. What this model is telling you is that the forecast function, how you expect to see future values of the series h steps ahead is something that looks like the level that you estimated at time t.\n\n\n91.2.2 Second order Polynomial model AKA Linear Growth model\n(West and Harrison 2013, secs. 7.1–7.2) gives a detailed analysis of this model.\nNow we want to create a model in which captures things that has a linear trend either increasing or decreasing. To do thus we need to have two components in our parameter vector of the state vector. For this we will need two components in our parameter vector of the state vector1.\nSo we have again something that looks like in my observation equation. I’m going to have, I’m going to call it say \\theta_{t,1} \\sim  \\mathcal{N}(v_t), and then I’m going to have say \\theta_{t,1} is going to be of the form to \\theta_{t-1,1} and there is another component here. The other component enters this equation plus let’s call this \\theta_{t-1,2}. And then I have finally also I need an evolution for the second component of the process which is going to be again having a random walk type of behavior.\n\\begin{aligned}\n  y_t &= \\theta_{t,1} + \\nu_t \\quad &\\nu_t &\\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, v_t) \\\\\n  \\theta_{t,1} &= \\theta_{t-1,1} + \\theta_{t-1,2} + \\omega_{t,1} \\qquad &\\omega_{t,1} &\\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, w_{t,11}) \\\\\n  \\theta_{t,2} &= \\theta_{t-1,2} + \\omega_{t,2} \\qquad &\\omega_{t,2} &\\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, w_{t,22})\n\\end{aligned}\n\\tag{91.16}\nSo there are different ways in which you can interpret this two parameters but essentially:\n\n\\theta_{t-1,1} is related to the baseline level of the series\n\\theta_{t-1,2} is related to the rate of change of the of the series.\n\n\n\n\n\n\n\nTipShort form DLM notation\n\n\n\n\n\n\nHaving the short form notation makes the model easier to understand in relation to other DLM models.\nIt will soon be instrumental in communicating the model structure with different software packages.\n\n\n\n\nNext we should summarize this model using the familiar short form DLM representation, which requires a bit of creative algebra.\n\n\\mathbf{\\theta}_t = (\\theta_{t,1}, \\theta_{t,2}) \\qquad \\{\\mathbf{F}, \\mathbf{G}, V_t, \\mathbf{W}_t\\}\n\nFirst we collect the two variances for the evolution two components into the vector \\utilde{w}_t and then assume that this w_t is Normal. Now this is a bi-variate normal.\n\n\\utilde{\\omega}_t = (\\omega_{t,1},\\omega_{t,2})' \\qquad \\utilde{\\omega}_t \\sim  \\mathcal{N}(0,W_t)\n\nSo what would be my F and my G in this model? So again my theta vector has two components, thus my G, so my F is going to be a two dimensional. We can write down F transposed as the only component that appears at this level is the first component of the vector. I’m going to have 1 and then a zero for F transposed. c.f. Equation 91.17 And then my G here if you think about writing down \\theta_t times G say the t-1 + \\omega_t. Then you have that you’re G is going to have this form.\n\n\\begin{aligned}\n\\mathbf{F} &= (1,0)' & V_t &= v_t \\\\\n\\mathbf{G} &= \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n& \\mathbf{W}_t &= \\begin{pmatrix} w_{t,11} & 0 \\\\ 0 & w_{t,22} \\end{pmatrix}\n\\end{aligned}\n\\tag{91.17}\nthis is the form from the video \n\\begin{aligned}\n\\mathbf{F} &= (1,0)' & V_t &= v_t \\\\\n\\mathbf{G} &= \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n& \\mathbf{W}_t &= \\begin{pmatrix} w_{t,11} & w_{t,12} \\\\ w_{t,21} & w_{t,22} \\end{pmatrix}\n\\end{aligned}\n\\tag{91.18}\nthis is the more general form from the handout. Note that in this case we have w_{t,12}=w_{t,21} so there is just one extra parameter.\nThe lesson videos and the handouts differ in the form \\mathbf{W}_t. In the lecture we assumed zero covariance but in the handout the covariance was snuck in. This gives us a slightly more general model. The covariance though is symmetric so we get an extra parameter we need to infer and include in the prior. Anyhow I kept the more general form, though in most cases we will keep the off diagonal terms at zero.\nSo for the first component, I have past values of both components. That’s why I have a 1 and 1 here for the second component I only have the past value of the second component. So there is a zero and a 1. So this tells me what is the structure of this second order polynomial. If I think about how to obtain the forecast function for this second order polynomial is going to be very similar to what we did before. So you can write it down as F transposed G to the power of h, expected value of theta t given Dt. Now the expected value is going to be vector also with two components because theta_t is a two dimensional vector. The structure here if you look at what G is G to the power of h going to be a matrix, that is going to look like 1, h, 0 1. When you multiply that matrix time this times this F what you’re going to end up having is something that looks like 1 h times this expected value of theta t given Dt. So I can think of two components here, so this gives you a constant on h, this part is not going to depend on h. So I can write this down as k t 11 component multiplied by 1 and then I have another constant, multiplied by h. So you can see what happens now is that your forecast function has the form of a linear polynomial. So it’s just a linear function on the number of steps ahead. The slope and the intercept related to that linear function are going to depend on the expected value of, theta_t given the all the information I have up to time t. But essentially is a way to model linear trends. So this is what happens with the second order polynomial model.\nAs we included linear trends and constant values in the forecast function, we may want to also incorporate other kinds of trends, polynomial trends in the model. So you may want to have a quadratic form, the forecast function or a cubic forecast function as a function of h.\n\n\\theta_t = (\\theta_{t,1}, \\theta_{t,2})' \\qquad \\mathbf{G} = \\mathbf{J}_2(1) \\qquad \\mathbf{E}_2 = (1, 0)'\n\n\n\\mathbf{G^h} = \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n\n\n\\begin{aligned}\nf_t(h) &= F' G^h \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t] \\\\\n&= (1,h) \\mathbb{E}[\\theta_{t}\\mid D_t] \\\\\n&= (1,h)(K_{t,0}, K_{t,1})' \\\\\n&= (K_{t,0} + K_{t,1} h)\n\\end{aligned}\n\\tag{91.19}\n\n\\begin{aligned}\n\\mathbf{G^h} &= \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n\\end{aligned}\n\\tag{91.20}\n\n\n91.2.3 General p-th order polynomial model\nWe can consider a so called p-th order polynomial model. This model will have a state-space vector of dimension p and a polynomial of order p − 1 forecast function on h. The model can be written as\n\n\\{E_p, J_p(1), v_t, W_t\\}\n\nwith F_t = E_p = (1, 0, \\ldots, 0)′ and G_t = J_p(1), with\n\nJ_p(1) = \\begin{pmatrix}\n1 & 1 & 0 & \\cdots & 0 & 0  \\\\\n0 & 1 & 1 & \\cdots & 0 & 0  \\\\\n0 & 0 & 1 & \\cdots & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 1 & 1 \\\\\n0 & 0 & 0 & \\cdots & 0 & 1\n\\end{pmatrix}\n\\tag{91.21}\nThe forecast function is given by \nf_t(k) = a_{t_0} +  a_{t_1}k + \\ldots + a_{t_{n-1}} k^{n-1} \\qquad k \\in \\mathbb{N}\n\\tag{91.22}\nwhere a_{t_i} are the coefficients of the polynomial and k is the number of steps ahead we need in our forecast. There is also an alternative parameterization of this model that leads to the same algebraic form of the forecast function given by \\{Ep, Lp, vt, W t\\}, with\n\nL_p = \\begin{pmatrix}\n1 & 1 & 1 & \\cdots & 1 & 1  \\\\\n0 & 1 & 1 & \\cdots & 1 & 1   \\\\\n0 & 0 & 1 & \\cdots & 1 & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 1 & 1 \\\\\n0 & 0 & 0 & \\cdots & 0 & 1\n\\end{pmatrix}\n\\tag{91.23}\nAnd in this type of model, the forecast function is going to have order p-1. So the parameter vector is going to have dimension p. So you’re going to have \\theta_t =  \\theta_{t1:p}.\nThe observation operator F is just a constant and if we write it as a row vector we get F' as a p-dimensional vector with the one in the first entry and zeros everywhere else.\nThe dynamics matrix G may be written using either a J Jordan form Equation 91.21 or as a triangular form Equation 91.23. These result in different parameterization of this model and we will talk a little bit about this.\nIn the Equation 91.21 we have a matrix with ones on the diagonal and the super diagonal, the matrix is needs to be p \\times p i.e. with dimension p to be compatible with the dimension of the hidden state vector \\theta. So this matrix G is what we call a Jordan block of dimension p of 1. So here 1 is the number that appears in the diagonal. And then I have a p I_p matrix, I have ones in the upper diagonal part. So this is the form of the model, so once again I have the F the G, and the W_t. I have my model.\nThe forecast function in this case again can be written as F' G^h \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t]. And when you simplify times expected value of \\theta_t, given D_t. Once you simplify those functions you get something that is a polynomial of order p-1 in h. So I just can write this down as k_t + k_{t,1} h + k_{t, p-1} h^{p-1}, so that’s my forecast function.\nThere is an alternative parameterization of this model that has the same F and the same algebraic form of the forecast function, the same form of the forecast function. But instead of using Equation 91.21 form of the G matrix, it has a Equation 91.23 form that has ones in the diagonal and ones everywhere above the diagonal. So it’s an upper triangular matrix with ones in the diagonal and above the diagonal. That’s a different parameterization of the same model but it leads to the same general form of the forecast function just with a different parameterization.\nSo again, we can consider the way you think about these models?\n\nWhat is you think what kind of forecast function makes sense here ?\nWhat is the type of predictions that I expect to have in my model?\nIf they look like a linear trend, I use a second order polynomial.\nIf it looks like a quadratic trend in the forecast then I would use 3rd order polynomial model representation.\n\nNote that the third order polynomial model is covered in\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\n91.2.4 First order Polynomial Models\nI will begin describing the structure of a particular class of models now, the polynomial trend models. These are models that are useful to describe linear trends or polynomial trends in your time series. So if you have a data set, where you have an increasing trend, or a decreasing trend, you would use one of those components in your model.\nWe will begin with the first order polynomial model, which we have already described. It’s the one that has y_t is a single parameter, I’m going to call it just \\theta_t + \\nu_t. And then a random walk evolution for that single parameter, so that’s the mean level of the series. And then we assume that it changes as a random walk, so this is the first order polynomial model.\nSo in general, I’m going to begin with the first order polynomial model, which we have already described. It’s the one that has y_t is a single parameter, I’m going to call it just \\theta_t + \\nu_t. And then a random walk evolution for that single parameters, so that’s the mean level of the series. And then we assume that it changes As a random walk, so this is the first order polynomial model. In this model if I want to write it down in short form I would have a quadruple that looks like this. So the F here that goes F transposed times the parameter vector in this case we have a scalar vector, scalar parameter. It’s going to be 1 my G that goes next to the state of t-1 is going to also be 1. And then I have vt and Wt here. So this fully defines my model if I think about the forecast function of this model using the representation we had before. Again, we’re going to have something of the form F'G^h and then the expected value of that \\theta_t | \\mathcal{D}_t. F is 1, G is 1, therefore I’m going to end up having just expected value of \\theta_t | \\mathcal{D}_t. Which depending on the data that you have is you’re just going to have something that is a value that depends on t and it doesn’t depend on h.\nWhat this model is telling you is that the forecast function, how you expect to see future values of the series h steps ahead is something that looks like the level that you estimated at time t.\nSo that’s the forecast function, you is a first order is a zero order polynomial is a constant on h and it’s called the first order polynomial model.\n\n\n91.2.5 Second order Polynomial Models\nIn the case of a second order polynomial We are going to now think about about a model in which we want to capture things that are not a constant over time but may have an increasing or decreasing linear trend. In this case we’re going to need two components in your parameter vector in the state vector.\nSo we have again something that looks like in my observation equation. I’m going to have, I’m going to call it say theta{t,1} Normal vt, and then I’m going to have say theta_{t,1} is going to be of the form to theta_{t-1,1} and there is another component here. The other component enters this equation plus let’s call this And then I have finally also I need an evolution for the second component of the process which is going to be again having a random walk type of behavior. So there is different ways in which you can interpret this two parameters but essentially one of them is related to the baseline level of the series the other one is related to the rate of change of the of the series. So if you think about the dlm representation again, these two components, I can collect into the vector wt. and then assume that this wt Is normal. Now this is a bivariate normal. So what would be my F and my G in this model? So again my theta vector has two components My G, so my F is going to be a two dimensional vectors. So I can write down F transposed as the only component that appears at this level is the first component of the vector. I’m going to have 1 and then a zero for F transposed. And then my G here if you think about writing down theta t times G say the t -1 +wt. Then you have that you’re G is going to have this form. So for the first component, I have past values of both components. That’s why I have a 1 and 1 here for the second component I only have the past value of the second component. So there is a zero and a 1. So this tells me what is the structure of this second order polynomial. If I think about how to obtain the forecast function for this second order polynomial is going to be very similar to what we did before. So you can write it down as F transposed G to the power of h, expected value of theta t given Dt. Now the expected value is going to be vector also with two components because theta_t is a two dimensional vector. The structure here if you look at what G is G to the power of h going to be a matrix, that is going to look like 1, h, 0 1. When you multiply that matrix time this times this F what you’re going to end up having is something that looks like 1 h times this expected value of theta t given Dt. So I can think of two components here, so this gives you a constant on h, this part is not going to depend on h. So I can write this down as k t 11 component multiplied by 1 and then I have another constant, multiplied by h. So you can see what happens now is that your forecast function has the form of a linear polynomial. So it’s just a linear function on the number of steps ahead. The slope and the intercept related to that linear function are going to depend on the expected value of, theta_t given the all the information I have up to time t. But essentially is a way to model linear trends. So this is what happens with the second order polynomial model.\n\n\n91.2.6 P-th Order Polynomial Models\nAs we included linear trends and constant values in the forecast function, we may want to also incorporate other kinds of trends, polynomial trends in the model. So you may want to have a quadratic form, the forecast function or a cubic forecast function as a function of h. So the all those can be incorporated using the general p-order polynomial model, so I will just describe the form of this model. And in this type of model, the forecast function is going to have order p-1. So your parameter vector is going to have dimension p. So you’re going to have theta_t theta t1 to tp. Your F matrix is going to be constant if I write it as a row vector. F transpose is going to be a p dimensional vector with the one in the first entry and zeros everywhere else. My G matrix is going to have this form and there is different parameterizations of this model and I will talk a little bit about this. But one way to parameterize the model is something that looks like this. So you have ones in the diagonal of the matrix, the matrix is going to be a p by p has to be the dimension of the p compatible with the dimension of the state vector. And then you have zeros’s below the diagonal above that set of ones that are also ones above the diagonal. So this matrix G is what we call a Jordan block of dimension p of 1. So here 1 is the number that appears in the diagonal. And then I have a p Ip matrix, I have ones in the upper diagonal part. So this is the form of the model, so once again I have the F the G, and the wt. I have my model. The forecast function in this case again can be written as F transposed G to the power of h. And when you simplify times expected value of theta_t, given Dt. Once you simplify those functions you get something that is a polynomial of order p-1 in h. So I just can write this down as kt constant.Plus kt1 h + kt p- 1, h to the p -1, so that’s my forecast function. There is an alternative parameterization of this model that has the same F and the same algebraic form of the forecast function, the same form of the forecast function. But instead of having this G matrix, it has a matrix that has ones in the diagonal and ones everywhere above the diagonal. So it’s an upper triangular matrix with ones in the diagonal and above the diagonal. That’s a different parameterization of the same model is going to have the same general form of the forecast function is a different parameterization. So again, you can consider the way you think about these models is you think what kind of forecast function I want to have for my future? What is the type of predictions that I expect to have in my model? And if they look like a linear trend, I use a second order polynomial. If it looks like a quadratic trend in the forecast then I would use 3rd order polynomial model representation.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-polynomial-trend-models-reading",
    "href": "C4-L03.html#summary-of-polynomial-trend-models-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.3 Summary of polynomial trend models (Reading)",
    "text": "91.3 Summary of polynomial trend models (Reading)\n\n91.3.1 Polynomial Trend Models\n\n91.3.1.1 First-Order Polynomial\n\n\\begin{aligned}\ny_t &= \\mu_t + \\nu_t, \\qquad & \\nu_t &\\sim  \\mathcal{N}(0, v_t) \\\\\n\\mu_t &= \\mu_{t-1} + \\omega_t, \\qquad & \\omega_t &\\sim  \\mathcal{N}(0, w_t)\n\\end{aligned}\n\nIn this case, we have:\n\\theta_t = \\mu_t \\quad \\forall t\n\nF_t = 1 \\quad \\forall t \\qquad G_t = 1 \\quad \\forall t\n\nresulting in:\n\n\\{1, 1, v_t, w_t\\} \\qquad \\text{(short notation)}\n\nThe forecast function is:\n\nf_t(h) = E(\\mu_t \\mid \\mathcal{D}_t) = k_t, \\quad \\forall h &gt; 0.\n\n\n\n91.3.1.2 Second-Order Polynomial\n\\begin{aligned}\n  y_t &= \\theta_{t,1} + \\nu_t, \\quad &\\nu_t &\\sim  \\mathcal{N}(0, v_t) \\\\\n  \\theta_{t,1} &= \\theta_{t-1,1} + \\theta_{t-1,2} + \\omega_{t,1}, \\qquad &\\omega_{t,1} &\\sim  \\mathcal{N}(0, w_{t,11}) \\\\\n  \\theta_{t,2} &= \\theta_{t-1,2} + \\omega_{t,2}, \\qquad &\\omega_{t,2} &\\sim  \\mathcal{N}(0, w_{t,22}),\n\\end{aligned}\n\nwhere we can also have:\n\n\\mathbb{C}ov(\\theta_{t,1}, \\theta_{t,2} ) = w_{t,12} = w_{t,21}\n\nThis can be written as a DLM with the state-space vector \\theta_t = (\\theta_{t,1}, \\theta_{t,2})', and\n\n\\{\\mathbf{F}, \\mathbf{G}, v_t, \\mathbf{W}_t\\}  \\qquad \\text{(short notation)}\n\nwith \\mathbf{F} = (1, 0)' and\n\n\\mathbf{G} =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}, \\quad \\mathbf{W}_t =\n\\begin{pmatrix}\nw_{t,11} & w_{t,12} \\\\\nw_{t,21} & w_{t,22}\n\\end{pmatrix}.\n\nNote that\n\n\\mathbf{G}^2 =\n\\begin{pmatrix}\n1 & 2 \\\\\n0 & 1\n\\end{pmatrix}, \\quad \\mathbf{G}^h =\n\\begin{pmatrix}\n1 & h \\\\\n0 & 1\n\\end{pmatrix},\n\nand so:\n\nf_t(h) = (1, h) E(\\mathbf{\\theta}_t \\mid \\mathcal{D}_t) = (1, h) (k_{t,0}, k_{t,1})' = (k_{t,0} + h k_{t,1}).\n\nHere \\mathbf{G} = \\mathbf{J}_2(1) (see below).\nAlso, we denote \\mathbf{E}_2 = (1, 0)', and so the short notation for this model is\n\n\\{E_2, J_2(1), \\cdot, \\cdot\\}\n\n\n\n91.3.1.3 General p-th Order Polynomial Model\nWe can consider a p-th order polynomial model. This model will have a state-space vector of dimension p and a polynomial of order p-1 forecast function on h. The model can be written as\n\\{E_p, J_p(1), v_t, W_t\\}  \\qquad \\text{(short notation)}\n\nwith \\mathbf{F}_t = \\mathbf{E}_p = (1, 0, \\dots, 0)' and \\mathbf{G}_t = \\mathbf{J}_p(1), with\n\n\\mathbf{J}_p(1) =\n\\begin{pmatrix}\n1 & 1 & 0 & \\cdots & 0 & 0 & 0 \\\\\n0 & 1 & 1 & \\cdots & 0 & 0 & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 0 & 1 & 1 \\\\\n0 & 0 & 0 & \\cdots & 0 & 0 & 1\n\\end{pmatrix}.\n\nThe forecast function is given by\n\nf_t(h) = k_{t,0} + k_{t,1} h + \\dots + k_{t,p-1} h^{p-1}.\n\nThere is also an alternative parameterization of this model that leads to the same algebraic form of the forecast function, given by \\{E_p, L_p, v_t, W_t\\}, with\n\nL_p =\n\\begin{pmatrix}\n1 & 1 & 1 & \\cdots & 1 \\\\\n0 & 1 & 1 & \\cdots & 1 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 1\n\\end{pmatrix}.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#regression-models-video",
    "href": "C4-L03.html#regression-models-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.4 Regression models (Video)",
    "text": "91.4 Regression models (Video)\n\n\n\n\nRegression models\n\n\n91.4.1 Simple dynamic regression\n\n\\begin{aligned}\ny_t &= \\beta_{t,0} + \\beta_{t,1}x_t + ν_t \\\\\n\\beta_{t,0} &= \\beta_{t−1,0} + \\omega_{t,0} \\\\\n\\beta_{t,1} &= \\beta_{t−1,1} + \\omega_{t,1}\n\\end{aligned}\n\\tag{91.24}\nand so \\theta_t = (\\beta_t,0, \\beta_{t,1})′, F_t = (1, x_t)′ and G = I_2.\nThis results in a forecast function of the form\n\nf_t(h) = k_{t,0} + k_{t,1}x_{t+h}\n\\tag{91.25}\nwhere k_{t,0} = \\mathbb{E}[\\beta_{t,0} \\mid \\mathcal{D}_t] and k_{t,1} = \\mathbb{E}[\\beta_{t,1} \\mid \\mathcal{D}_t].\n\n\n91.4.2 General dynamic regression\n\n\\begin{aligned}\ny_t &= \\beta_{t,0} + \\beta_{t,1}x_{t,1} + \\ldots \\beta_{t,M} x_{t,M} + ν_t \\\\\n\\beta_{t,m} &= \\beta_{t−1,m} + \\omega_{t,m,} & m = 0 : M.\n\\end{aligned}\n\\tag{91.26}\nThen, \\theta = (\\beta_t,0, \\ldots , \\beta_{t,M} )′, F_t = (1, x_{t,1}, \\ldots , x_{t,M} )′ and G = I_M . The forecast function is given by\n\nf_t(h) = k_{t,0} + k_{t,1}x_{t+h,1} + \\ldots + k_{t+h,M}x_{t+h,M}\n\\tag{91.27}\nA particular case is of dynamic regressions is the case of time-varying auto-regressions (TVAR) with\n\n\\begin{aligned}\ny_t &= \\varphi_{t,1}y_{t−1} + \\varphi_{t,2}y_{t−2} + \\ldots + \\varphi_{t,p} y_{t−p} + ν_t,\\\\\n\\varphi_{t,m} &= \\varphi_{t−1,m} + \\omega_{t,m,} & m = 1 : p\n\\end{aligned}\n\\tag{91.28}\nThere is a paper (Raquel Prado, Huerta, and West 2000) on TVAR models that is a good reference for this model.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\n91.4.3 Regression Models\nIn regression models, we may also have additional covariates that are also measured sequentially over time. We may want to regress the y_t time series and see what relationships they have with other covariates that are also measured over time. The simplest possible case is the dynamic simple regression model. In this case, I can write down. I have a single covariate, that covariate is X_t that is observed here, and then I have the usual. In this case, I have an intercept and a slope, and this is representing my simple linear regression. It’s just the regression where both the intercept and the slope are time-varying. I can define the variation. I need to specify what’s the evolution of the two components, and we are going to use this random walk. We could use other structures, but again, in the normal linear case, we are going to be using these evolution equations. Then I collect here my W’s as a single vector. The \\omega_t is going to have the two components in here. These are normally distributed zero and variance covariance matrix W_t, that is a two-by-two matrix. This is the case of the simple regression model. In the case of this model, we have F now is time-varying. This is going to change depending on the value of X_t. I can write Ft transpose as one and X_t. My Theta vector. Again, if I think about what it is, is just Beta t, 0 Beta t, 1. I have those two components.\nThe G matrix is going to be the identity, and you can see that essentially the first component is related to the first component in t minus one, and the second component at time t is related to the second component at time t minus 1. So the identity matrix will be the G. Therefore, if I think about my forecast function in the simple linear regression case, this is going to be my F transpose, which is 1 xt times the G, the G is the identity, times the expected value of Theta t, given Dt. For the expected value of Theta t given Dt, This is a two-dimensional vector, so I’m going to have components in there. I can write this down as K_t0 plus K_t1 Xt. We can see that the forecast function is again has that form that depends on that covariate at the time. This should be t plus h because we are evaluating this at t plus h. You need to have the covariate evaluated at t plus h here.\n\n\n91.4.4 General Dynamic Regression Model\nIn the case of general dynamic regression model, we’re going to have a set of covariates. We can have, let’s say k of those covariates or p of those covariates, X_t1. This is my observation equation. Instead of having a single covariate, now I’m going to have p of them. I’m going to have coefficients that go with each of those and I may have the Beta t0 coefficient. My G matrix now, if I think about my parameter vector is just p plus 1 dimensional, p plus 1. Yeah, so that I have the 0 and then the p values, so is a p plus 1 vector. Then my G is the identity. My F_t is going to be a vector, is also p plus 1 dimension. The first entry is one, the second is X_t1 X_tp. My forecast function is going to be similar to this, but now we are going to have more than one covariate, so we end up with a forecast function that has this form, p. This is the case for the dynamic regression.\n\n\n91.4.5 TVAR\nOne particular example of dynamic regression model is the case of a time-varying autoregressive process. This brings us back to those autoregressive processes that we were discussing earlier in the course. When you you’re regressing each of the X’s correspond to pass values, you have a regression model that we call a time-varying ARP. In this case, your observation equation is going to have the AR coefficients, but the AR coefficients are going to be varying over time. If we assume that we put all the coefficients together and have a random walk evolution equation for those. If I said, I call Phi_t the vector that contains all the components with all the coefficients from one to p, then I can now define this evolution equation. Then my Omega_t here is a p-dimensional vector, and I have Omega t, normal zero, WT, and my epsilon t normal 0 vt.\nThis defines a time-varying AR. It’s the same structure that we had before. The only difference is my covariates are just past values of the time series. Therefore my forecast function for the time-varying AR is going to have this form where every_thing is going to depend on past values of the time series. We will study this model in particular and make connections with the AR that we studied earlier in the class.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-regression-models-reading",
    "href": "C4-L03.html#summary-of-regression-models-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.5 Summary of Regression Models (Reading)",
    "text": "91.5 Summary of Regression Models (Reading)\n\n91.5.1 Dynamic Regression Models\n\n91.5.1.1 Simple Dynamic Regression\n\n\\begin{aligned}\n  y_t &= \\beta_{t,0} + \\beta_{t,1} x_t + \\nu_t \\\\\n  \\beta_{t,0} &= \\beta_{t-1,0} + \\omega_{t,0} \\\\\n  \\beta_{t,1} &= \\beta_{t-1,1} + \\omega_{t,1}\n\\end{aligned}\n\nThus:\n\n\\theta_t = (\\beta_{t,0}, \\beta_{t,1})'\n\n\nF_t = (1, x_t)'\n\nand\n\nG = I_2\n\nThis results in a forecast function of the form\n\nf_t(h) = k_{t,0} + k_{t,1} x_{t+h}.\n\n\n\n91.5.1.2 General Dynamic Regression\n\n\\begin{aligned}\ny_t &= \\beta_{t,0} + \\beta_{t,1} x_{t,1} + \\dots + \\beta_{t,M} x_{t,M} + \\nu_t \\\\\n\\beta_{t,m} &= \\beta_{t-1,m} + \\omega_{t,m}, \\quad &m = 0:M.\n\\end{aligned}\n\\tag{91.29}\nThen,\n\\theta_t = (\\beta_{t,0}, \\dots, \\beta_{t,M})',\n\\mathbf{F}_t = (1, x_{t,1}, \\dots, x_{t,M})' and\n\\mathbf{G} = \\mathbf{I}_M.\nThe forecast function is given by:\n\nf_t(h) = k_{t,0} + k_{t,1} x_{t+h,1} + \\dots + k_{t,M} x_{t+h,M}.\n\\tag{91.30}\nA particular case of dynamic regressions is the case of time-varying autoregressive (TVAR) with time-varying autoregressive (TVAR)\n\n\\begin{aligned}\n  y_t &= \\phi_{t,1} y_{t-1} + \\phi_{t,2} y_{t-2} + \\dots + \\phi_{t,p} y_{t-p} + \\nu_t \\\\\n  \\phi_{t,m} &= \\phi_{t-1,m} + \\omega_{t,m}, \\quad m = 1:p.\n\\end{aligned}",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#the-superposition-principle-video",
    "href": "C4-L03.html#the-superposition-principle-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.6 The superposition principle (Video)",
    "text": "91.6 The superposition principle (Video)\n\n\n\n\nThe superposition principle\n\nWe can use the superposition principle to build models that have different kinds of components. The main idea is to think about what is the general structure we want for the forecast function and then isolate the different components of the forecast function and think about the classes of dynamic linear models that are represented in each of those components. Each of those components has a class and then we can build the general dynamic linear model with all those pieces together using this principle.\nTwo references for the Superposition principle are\n\n(West and Harrison 2013, sec. 3.1 p. 98)\n(R. Prado, Ferreira, and West 2023, sec. 4.2.1 p. 136)\n\n\n\n\n\n\n\nImportant 91.1: Superposition Principle\n\n\n\nIn the first the author state:\n\nConditional independence also features strongly in initial model building and in choosing an appropriate parametrization. For example, the linear superposition principle states that any linear combination of deterministic linear models is a linear model. This extends to a normal linear superposition principle:\nAny linear combination of independent normal DLMs is a normal DLM. - &gt; – (West and Harrison 2013, sec. 3.1 p. 98)\n\n\n\nWe will illustrate how to do that with an example:\nLet’s say that we want to create a model here with a forecast function that has a linear trend component. Let’s say we have a linear function as a function of the number of steps ahead that you want to consider. Then suppose you also have a covariate here that you want to include in your model as a regression component. \nf_t(h) = \\underbrace{(k_{t,0} + k_{t,1}\\; h)}_{\\text{linear trend component}} + \\underbrace{(k_{t,2}\\; x_{t+h})}_{\\text{regression component}}\n\\tag{91.31}\nwhere:\n\nf_t(h) is our forecast function.\nk_{t,0}, k_{t,1} and k_{t,2} are just constants (that we index using time t and a second subscript).\nx_{t+h} is a time dependent regression covariate.\n\nWhen we look at the forecast function, we can isolate a linear trend and a regression components as indicated. Each of these can be set in terms of two forecast functions]{.mark}. I’m going to call the forecast function f_{1,t}(h), this is just the first piece.\n\n\\begin{aligned}\nf_t(h) &= f_{1,t}(h) + f_{2,t}(h) \\\\\nf_{1,t}(h) &= k_{t,0} + k_{t,1} & \\text{(linear trend component)} \\\\\nf_{2,t}(h) &= k_{t,2}x_{t+h} & \\text{(regression component)}\n\\end{aligned}\n\\tag{91.32}\nWe know how to represent forecast function f_{1,t} and f_{2,t} in terms of dynamic linear models.\nFor the linear trend component, f_{1,t}(h) , we have a 2-dimensional state vector, \\theta_t = (\\theta_{t,1}, \\theta_{t,2})', which yields the following DLM shortform:\n\n\\{F_1, G_1, \\cdot, \\cdot\\}  \\qquad \\text{(short notation)}\n\\tag{91.33}\n\nWhere we don’t explicitly specify the observational and system variances, V and W\nThe important bit are F and G. The forecast function is given by:\n\n\nF_{1} = E_2 = (1, 0)'\n\\tag{91.34}\n\nG_{1} =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}\n\\tag{91.35}\nfor the regression component f_{2,t}(h) we have the following DLM representation:\n\n\\{F_2,t, G_2, \\cdot, \\cdot\\}  \\qquad \\text{(short notation)}\n\\tag{91.36}\nwhere we have F_{2t} is X_t and my G is simply going to be 1. This is a one-dimensional vector in terms of the state parameter vector.\n\nF_{2,t} = x_{t+h}\n\\tag{91.37}\n\nG_{2} = 1\n\\tag{91.38}\nOnce we have these, we can assemble them into our final model. \\{F_t, G, \\cdot, \\cdot\\}\nWe care more about F, G, and less about the observational variance and some covariance also for the system where the\nF is going to be an F that has, you just concatenate the two Fs. You’re going to get 1, 0 and then you’re going to put the next component here. Again, this one is dependent on time because this component is time dependent and\nThe model with forecast function f_t(h) above is a model with a 3-dimensional state vector with\n\nF_t = (F_1', F_{2,t})' = (1, 0, x_t)'\n\nThen the G, you can create it just taking a block diagonal structure by concatenating G_1 and G_2. though formally there must be a better term for this operation.\n\nG = \\text{blockdiag}[G_1, G_2] =\n\\begin{pmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}.\n\nThis gives us the full G dynamics matrix for the model. A model with this F_t and this G that is constant over time will give us this particular forecast function Equation 91.31 we started with.\nWe used the superposition principle to build this model. If we need additional components, we will learn how to incorporate seasonal components, regression components, trend components. One can build a fairly sophisticated model with different structures into this particular model using the superposition principle.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\n91.6.1 The superposition principle\nWe can use the superposition principle to build models that have different kinds of components. The main idea is to think about what is the general structure we want for the forecast function and then isolate the different components of the forecast function and think about the classes of dynamic linear models that are represented in each of those components. Each of those components has a class and then we can build the general dynamic linear model with all those pieces together using this principle. I will illustrate how to do that with an example. Let’s say that you want to create a model here with a forecast function that has a linear trend component. Let’s say we have a linear function as a function of the number of steps ahead that you want to consider. Then suppose you also have a covariate here that you want to include in your model as a regression component. Let’s say we have a K_t2 and then we have X_t plus h, this is my covariate. Again, the k’s here are just constants, as of constants in terms of h, they are dependent on time here. This is the general structure we want to have for the forecast function. Now you can see that when I look at the forecast function, I can isolate here and separate these two components. I have a component that looks like a linear trend and then I have a component that is a regression component. Each of this can be set in terms of two forecast functions. I’m going to call the forecast function F_1t h, this is just the first piece. Then I have my second piece here. I’m going to call it F_2t, is just this piece here with the regression component. We know how to represent this forecast function in terms of a dynamic linear model. I can write down a model that has an F, G, and some V, and some W that I’m going to just leave here and not specify them explicitly because the important components for the structure of the model are the F and the G. If you’ll recall the F in the case of a forecast function with a linear trend like this, is just my E_2 vector, which is a two-dimensional vector. The first entry is one, and the second one is a zero. Then the G in this case is just this upper triangular matrix that has 1, 1 in the first row and 0, 1 in the second one. Remember, in this case we have a two-dimensional state vector where one of the components in the vector is telling me information about the level of the time series, the other component is telling me about the rate of change in that level. This is a representation that corresponds to this forecast function. For this other forecast function, we have a single covariate, it’s just a regression and I can represent these in terms of an F_2, G_2, and then some observational variance and some system variance here in the case of a single covariate and this one depends on t. We have F_2t is X_t and my G here is simply going to be one. This is a one-dimensional vector in terms of the state parameter vector. We have a single state vector and it’s just going to tell me about the changes, the coefficient that goes with the X_t covariate. Once I have these, I can create my final model and I’m going to just say that my final model is F, G, and then I have some observational variance and some covariance also for the system where the F is going to be an F that has, you just concatenate the two Fs. You’re going to get 1, 0 and then you’re going to put the next component here. Again, this one is dependent on time because this component is time dependent and then the G, you can create it just taking a block diagonal structure, G_1 and G_2. You just put together, the first one is 1, 1, 0, 1 and then I concatenate this one as a block diagonal. This should be one. This gives me the full G function for the model. Now a model with this F_t and this G that is constant over time will give me this particular forecast function. I’m using the superposition principle to build this model. If you want additional components, we will learn how to incorporate seasonal components, regression components, trend components. You can build a fairly sophisticated model with different structures into this particular model using the superposition principle.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#superposition-principle-general-case-reading",
    "href": "C4-L03.html#superposition-principle-general-case-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.7 Superposition principle: General case (Reading)",
    "text": "91.7 Superposition principle: General case (Reading)\nYou can build dynamic models with different components, for example, a trend component plus a regression component, by using the principle of superposition. The idea is to think about the general form of the forecast function you want to have for prediction. You then write that forecast function as a sum of different components where each component corresponds to a class of DLM with its own state-space representation. The final DLM can then be written by combining the pieces of the different components.\nFor example, suppose you are interested in a model with a forecast function that includes a linear polynomial trend and a single covariate x_t, i.e.,\n\nf_t(h) = k_{t,0} + k_{t,1}h + k_{t,3}x_{t+h}.\n\nThis forecast function can be written as f_t(h) = f_{1,t}(h) + f_{2,t}(h), with\n\nf_{1,t}(h) = (k_{t,0} + k_{t,1}h), \\quad f_{2,t}(h) = k_{t,3}x_{t+h}.\n\nThe first component in the forecast function corresponds to a model with a 2-dimensional state vector, F_{1,t} = F_1 = (1, 0)',\n\nG_{1,t} = G_1 =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}.\n\nThe second component corresponds to a model with a 1-dimensional state vector, F_{2,t} = x_t, G_{2,t} = G_2 = 1.\nThe model with forecast function f_t(h) above is a model with a 3-dimensional state vector with F_t = (F_1', F_{2,t})' = (1, 0, x_t)' and\n\nG_t = \\text{blockdiag}[G_1, G_2] =\n\\begin{pmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}.\n\n\n91.7.1 General Case\nThe general case wasn’t covered in the video and we didn’t have a proper statement of the superposition principle. However, in Important 91.1 I extracted the statement of the principle above. This statement clarifies that the principle arises via conditional independence, a tool we also used extensively in the previous course on mixture models. Now let us consider the general case from the handout.\nAssume that you have a time series process y_t with a forecast function\n\nf_t(h) = \\sum_{i=1}^{m} f_{i,t}(h),\n\nwhere each f_{i,t}(h) is the forecast function of a DLM with representation \\{F_{i,t}, G_{i,t}, v_{i,t}, W_{i,t}\\}.\nThen, f_t(h) has a DLM representation \\{F_t, G_t, v_t, W_t\\} with\n\nF_t = (F_{1,t}', F_{2,t}', \\dots, F_{m,t}')',\n\n\nG_t = \\text{blockdiag}[G_{1,t}, \\dots, G_{m,t}],\n\n\nv_t = \\sum_{i=1}^{m} v_{i,t},\n\nand\n\nW_t = \\text{blockdiag}[W_{1,t}, \\dots, W_{m,t}].",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#quiz-the-normal-dynamic-linear-model",
    "href": "C4-L03.html#quiz-the-normal-dynamic-linear-model",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "91.8 Quiz: The Normal Dynamic Linear Model",
    "text": "91.8 Quiz: The Normal Dynamic Linear Model\nOmitted due to Coursera honor code",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#filtering-video",
    "href": "C4-L03.html#filtering-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.1 Filtering (Video)",
    "text": "92.1 Filtering (Video)\n\n\n\n\nDerivation for the Prior and Forecast at Time t\n\n\n\n\nDerivation of the Posterior at Time t\n\n\nRecall we are working in a Bayesian setting where a NDLM model with a normal prior would like this:\n\n\\begin{aligned}\n  y_t &= F_t' \\theta_t + \\nu_t & \\nu_t &\\sim \\mathcal{N}(0, v_t) & \\text{(observation)}\\\\\n  \\theta_t &= G_t \\theta_{t-1} + \\omega_t & \\omega_t &\\sim  \\mathcal{N}(0, W_t) & \\text{(evolution)} \\\\\n  & &(\\theta_0 \\mid \\mathcal{D}_0) & \\sim  \\mathcal{N}(m_0, C_0) & \\text{(prior)}\n\\end{aligned}\n\\tag{92.1}\n\nIn the prior \\mathcal{D}_0 stands for the information that we have before collecting any data and\nWe are assuming \\theta_0 follows a normal distribution with\nm_0 mean\nC_0 variance covariance matrix.\n\nSince we are doing filtering which is a retrospective analysis, of past states we assume that we know m_0, C_0, \\nu_t, \\omega_t, F_t, G_t \\qquad \\forall t.\nHowever, there is often great interest in looking back in time in order to get a clearer picture of what happened.\nWe are interested in performing Bayesian inference in this setting and we talked about different kinds of distributions.\n\nOne is the filtering distribution that allows us to update the distribution of \\theta_t as we receive observations and information over time.\nThe other one is smoothing equations that allows us to just revisit the past once we have observed a chunk of data.\n\nIn a Bayesian setting, you have to set a prior distribution. We will work with the prior distribution that is conjugate.\nIn this case we have to begin with a distribution at time zero for \\theta_0. So before we have seen any data at all, I have this prior distribution.\nWe also assume a prior distribution of the form:\n\n(\\theta_{t} \\mid \\mathcal{D}_{t-1}) \\sim \\mathcal{N}(m_{t-1}, C_{t-1}).\n\\tag{92.2}\nWe assume that this the filtering distribution follows this normal distribution based on\n\nthe prior in Equation 92.9 being conjugate of the normal and\n\nthe linearity of the model in Equation 92.9.\n\nThese result in updates to the model parameters and uncertainty, at each time step, preserving the normal structure from the prior.\nThen, we can obtain the following distributions:\n\nPrior at Time t\n\n\n  (\\theta_t \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(a_t, R_t) \\qquad \\text{(prior at time t)} \\qquad\n   \\tag{92.3}\nwith\n \\begin{aligned}\n  a_t \\doteq& \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_{t-1}] =& G_t  \\mathbb{E}[G_t \\theta_{t-1} \\mid \\mathcal{D}_{t-1} ] =& G_t m_{t-1} \\\\\n  R_t \\doteq& \\mathbb{V}ar[\\theta_t \\mid \\mathcal{D}_{t-1}] =& G_t \\mathbb{V}ar[\\theta_t \\mid \\mathcal{D}_{t-1}] =& G_t C_{t-1} G_t' + W_t.\n  \\end{aligned}\n   \\tag{92.4}\nWhere we simply took the first and second moments of the system equation from Equation 92.9 conditioned on our information set \\mathcal{D}_{t-1}\n\nOne-Step Forecast\n\n\n  (y_t \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(f_t, q_t) \\qquad \\text{(one step forecast fn)} \\qquad\n   \\tag{92.5}\nwith\n\\begin{aligned}\n  f_t\n     & \\doteq \\mathbb{E}[ y_t \\mid \\mathcal{D}_{t-1} ]\n     & = F_t' \\mathbb{E}[ y_t \\mid \\mathcal{D}_{t-1} ]\n     & = F_t' a_t \\\\\n  q_t\n     & \\doteq \\mathbb{V}ar[y_t \\mid \\mathcal{D}_{t-1}]\n     & = F_t' \\mathbb{V}ar[y_t \\mid \\mathcal{D}_{t-1}]  \n     & = F_t' R_t F_t + v_t\n  \\end{aligned}\n   \\tag{92.6}\nWhere we took the first moments on the observation equation conditioned on the information set \\mathcal{D}_t and substituted Equation 92.5\n\nPosterior at Time t\n\n\n  (\\theta_t \\mid \\mathcal{D}_t) \\sim  \\mathcal{N}(m_t, C_t)\n  \nwith\n\\begin{aligned}\n  m_t &= a_t + R_t F_t q_t^{-1} (y_t - f_t), \\\\\n  C_t &= R_t - R_t F_t q_t^{-1} F_t' R_t.\n  \\end{aligned}\n   \\tag{92.7}\nThese can be derived via Normal theory or via the Multivariate Bayes’ theorem. The background for both seems to be provided in (West and Harrison 2013, secs. 17.2.3 p.639)\nNow, denoting e_t = (y_t - f_t) and A_t = R_t F_t q_t^{-1}, we can rewrite the equations above as:\nIt follows that\n\n\\begin{pmatrix}Y \\\\ \\theta\\end{pmatrix} \\sim \\mathcal{N}\n\\left(\n  \\begin{pmatrix}F'a \\\\ a \\end{pmatrix},\n  \\begin{pmatrix} F'RF + V & F'R \\\\ RF & R \\end{pmatrix}\n\\right)\n\nTherefore, identifying Y with X_1 and \\theta with X_2 in the partition of X in 17.2.2, we have RF R )]\nTherefore, identifying Y with X1 and θ with X2 in the partition of X in 17.2.2, we have \nY \\sim \\mathcal{N}[F'a, F'RF + V]\n\n\n(\\theta \\mid Y) \\sim \\mathcal{N}[m, C],\n\nwhere\n\nm = a + RF[F′RF + V]−1[Y − F′a]\n\nand \nC = R − RF[F′RF + V]−1F′R.\n\n\n  \\begin{aligned}\n  \\theta \\mid \\mathcal{D}_t &\\sim \\mathcal{N}(m_t,C_t)\\\\\n  m_t &\\doteq a_t + A_t e_t, \\\\\n  C_t &\\doteq R_t - A_t q_t A_t'\n  \\end{aligned}\n\\tag{92.8}\nEquation 92.4 , Equation 92.6 and Equation 92.8 are often referred to as the Kalman filtering equations.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nI will now discuss Bayesian inference in the case of the normal dynamic linear model where both the observational variance and the system variance are known. We will talk about filtering equations, smoothing equations and also forecasting in this setting using Bayesian approach.\nSo recall we are working with a model that looks like this: … And then this is my first equation, the observation equation and I have a system equation that looks like this.\nWe are going to assume that V_t and W_t are known for every t. And we also know what the F_t’s and the G_t’s are here. So the response is a uni-dimensional y_t and then I have, say, \\theta_t is a vector of a given dimension, depending on the structure of the model.\nWe are interested in performing Bayesian inference in this setting and we talked about different kinds of distributions\n\nOne is the filtering distribution that allows us to update the distribution of \\theta_t as we receive observations and information over time.\nThe other one is smoothing equations that allows us to just revisit the past once we have observed a chunk of data.\n\nSo I will be talking about those and also smoothing.\nIn a Bayesian setting, you have to set a prior distribution. We will work with the prior distribution that is conjugate.\nIn this case I have to begin with distribution at time zero. So before I know, I have seen any data at all, I have this prior distribution. D_0 stands for the information that I have before collecting any data. And we are going to assume, That this \\theta_0 follows a normal distribution with m_0 mean and variance covariance matrix C_0. So these are also specified when you’re working with this model.\nSo we assume that this m_0 and C_0 is known.\nOnce we have this setting using these equations, we can obtain the filtering equations.\nSo the first assumption is going to be that we have, a structure.\nSo for \\theta_{t -1} \\mid \\mathcal{D}_{t-1} is going to have this normal structure which is going to happen basically because we’re using this conjugate prior. And because we have normal structure in the model, is going to lead to the following distribution. So the first one is the prior at time t.\nSo if I want to think about why my distribution for the t is given the information I have up to t-1, I can look at the equations of the model and use this second equation. And by looking at this equation, if I condition on the information I have up to t-1, I can see that, say, \\theta_t is written as a linear function of, \\theta_{t -1} and I have the assumption of normality here.\nTherefore, say, \\theta_t going to follow a normal distribution with some mean and some variance. So now we’re going to compute this mean and this variance using this equation. So if you think about the expected value of \\theta_t, given D_{t -1}, that’s just going to be G_t is a constant here. So I have my G_t and then I have expected value of \\theta_{t -1} given G_{t -1} plus expect the value of this \\omega_t.\nBut \\omega_t is a zero mean, normally distributed quantity, so it’s just going to be zero. Using the assumption that I have this structure, then I have that the \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_{t -1}] = G_t \\times m_{t-1}. We’re going to call this quantity a_t, so we have here a_t. For the variance covariance matrix, then we just have to compute, do the same type of operation. And again, we can use this equation and see that we obtain this G_t variance of \\theta_{t-1} \\mid \\mathcal{D}_{t -1} G_t'. And then we have now the variance of the omega, the variance of the omega is just W_t. So we have G_t = C_{t -1} G_t' + W_t. So we can call this quantity R_t and just have the form of this prior distribution at time t.\nI can now think about another distribution which is the distribution of y_t \\mid \\mathcal{D}_{t-1}. So this is the so called one-step ahead, Forecast, And in the one-step ahead forecast again is a similar type of structure. So now we’re going to use the first equation rather than the second equation and we see that y_t is written in terms of a linear function of \\theta_t. And we have also the Gaussian in assumption here. So again the y_t is going to be normally distributed, And we just have to compute the mean and the variance for this y_t. So using the first equation, we have the expected value of y_t given D_{t -1} is just F_t' \\mathbb{E}[\\theta_t \\mid D_{t -1}]. And we computed this before, so this is, again, the expected value of \\theta_t given D_{t -1} is what we computed here. So this is to be F_t' a_t. And we are going to call this little f_t. Then, for the variance, Again, we use this equation, we have this component, so we are going to get F_t' R_t F_t + D_t. And I’m going to call this q_t. So my final distribution, the one-step ahead forecast distribution, tells me that this follows a normal f_t q_t. The next equations we are going to discuss are the equations that tell me about what is the distribution of \\theta_t once we incorporate the information provided by y_t. The next distribution is the posterior of \\theta_t given D_t. So that’s, \\theta_t given D_t. And we can write D_t as whatever information we have at time t- 1. And the new data point with this just y_t. So we just want to update the distribution of \\theta_t given that we have received this additional data point at time t. There are two ways of computing this distribution. One uses normal theory, the other one uses Bayes’ theorem. And you obtain that the distribution of \\theta_t given D_t is going to be a normal, with mean we call it m_t and variance C_t. We will see how to obtain this distribution or the moments of this distribution using normal theory.\n\n\nSo, again, we can write down, if we think about just combining the vector \\theta_t with the observation\n\n\nY_t given D_{t -1}, right? We have information about \\theta_t \\mid t-1. That’s the prior for \\theta_{ta,t}, based on the information at t -1. And then we also computed before the one step ahead forecast distribution for y_t| \\mathcal{D}_{t -1}. So we know that when we combine these two in a single vector, we’re going to have a multivariate normal distribution and the first component is going to be a_t. The second component is what we have called F_t, so that’s the mean. And then for the covariance matrix. We’re going to have now, what goes here is just the variance of \\theta_t given D_{t -1}, which we have called R_t. What goes here is the variance of y_t \\mid \\mathcal{D}_{t -1} and we have called this q_t. And now we have to compute the covariance between \\theta_t and y_t, and that goes here. And the covariance between y_t and \\theta_t, which is just the transpose of that, is going to go here. So if I think about computing the covariance of \\theta_t and y_t \\mid \\mathcal{D}_{t -1}, I can write y_t using the first equation here as a function of \\theta_t. That’s going to give us, F_t' \\theta_t + v_t given D_{t -1}. And in this one we can see that this is going to give us basically the variance of \\theta_t given D_{t -1} and then multiplied by F_t' F_t which gives me the F_t. So this is going to be variance of \\theta_t given D_{t -1} times F_t. And then there is a term that combines the \\theta_t with the noise but they are independent, so the covariance is going to be zero. So this one is simply going to be my R_t F_t, so this goes here, And what goes here is just the covariance of y_t with \\theta_t or the transpose of this. So this is going to give me F_t' R_t', but R_t is a covariance matrix, so R_t' = R_t. So now I have my full multivariate distribution and I can use properties of the multivariate distribution to compute the distribution of, \\theta_t, given y_t and D_{t -1}. So that’s going to be a conditional distribution, I’m going to condition on the y_t. And when I combine y_t and D_{t -1} that gives me just the information up to time t. So we are interested in just finding, say, \\theta_t given y_t and D_{t -1} which is the same as \\theta_t given D_t. We partition the normal distribution in this way, so I can just think about this is the first component and then I have these different pieces in my covariance matrix. And we know from normal theory that if we have a distribution, if we have a vector that is partitioned into vectors here where they are normally distributed. And I have my mean partition here and let’s say I have one component here, Then we know that if I wanted to compute the distribution of X_1 conditional on X_2, that’s going to give me normal, let’s say \\alpha^*. And let’s call this one the \\sigma^*, where \\alpha^* is going to be my \\alpha_1 + \\sigma_{12}^{-1}. And then I have _1 - \\alpha_2 and then I have my \\sigma^*. And this one gives me my \\sigma_{11} - \\sigma_{21}. So this is a result from normal theory. So if I want my conditional distribution of X_1 given X_2 I can apply these equations. So we notice we have the same type of structure here. If I partition my vector and in \\theta_t and y_t. And now I condition on, I take the distribution of \\theta_t conditioning on y_t. I’m going to have that same structure where this is normal, m_t C_t. And my m_t using normal theory, again, is going to be a_t + \\sigma_{22}^{-1}. And then I have y_t - f_t. So that’s my mean and my covariance matrix. It’s going to be R_t - q_t^{-1} and then I have this transpose again. So if we simplify things a bit here and we call e_t, it’s just the error that we make when we compare y_t, which is the observation with the prediction, right? And then I also use the notation I call a_t, let’s call here A_t R_t F_t q_t^{-1}. Then we can write this down, to mean, we can write as a_t + A_t. And the covariance matrix. We can write it as R_t, A_t q_t A_t'. So this gives me the posterior mean after receiving this y_t observation. And you can see that you can write down the posterior mean, has this usual form of the prior plus something that relates to the error that I make with the prediction.\nSo the y_t appears there and then is weighted by this quantity that we just call a_t.\nAnd for the covariance structure, we are also incorporating information about the prior and what the y_t observation provides. So this gives us our filtering equation for \\theta_t given D_t. And now we can apply all these equations as we receive observations from t = 1 all the way to T. If we happen to have T observations in the time series, we can do this filtering process and obtain these distributions as we receive information.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-filtering-distributions-reading",
    "href": "C4-L03.html#summary-of-filtering-distributions-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.2 Summary of filtering distributions (Reading)",
    "text": "92.2 Summary of filtering distributions (Reading)\n\n92.2.1 Bayesian Inference in NDLM: Known Variances\nConsider an NDLM given by:\n\n\\begin{aligned}\ny_t &= F_t' \\theta_t + \\nu_t, \\quad \\nu_t \\sim  \\mathcal{N}(0, v_t), \\\\\n\\theta_t &= G_t \\theta_{t-1} + \\omega_t, \\quad \\omega_t \\sim  \\mathcal{N}(0, W_t),\n\\end{aligned}\n\\tag{92.9}\nwith F_t, G_t, v_t, and W_t known. We also assume a prior distribution of the form (\\theta_0 \\mid \\mathcal{D}_0) \\sim  \\mathcal{N}(m_0, C_0), with m_0, C_0 known.\n\n92.2.1.1 Filtering\nWe are interested in finding \\mathbb{P}r(\\theta_t \\mid \\mathcal{D}_t) for all t. Assume that the posterior at t-1 is such that:\n\n(\\theta_{t-1} \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(m_{t-1}, C_{t-1}).\n\\tag{92.10}\nThen, we can obtain the following:\n\nPrior at Time t\n\n\n(\\theta_t \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(a_t, R_t),\n\nwith\n\na_t = G_t m_{t-1} \\qquad R_t = G_t C_{t-1} G_t' + W_t.\n\n\nOne-Step Forecast\n\n\n(y_t \\mid D_{t-1}) \\sim  \\mathcal{N}(f_t, q_t),\n\nwith\n\nf_t = F_t' a_t, \\quad q_t = F_t' R_t F_t + v_t.\n\n\nPosterior at Time t: (\\theta_t \\mid \\mathcal{D}_t) \\sim  \\mathcal{N}(m_t, C_t) with\n\n\\begin{aligned}\nm_t &= a_t + R_t F_t q_t^{-1} (y_t - f_t), \\\\\nC_t &= R_t - R_t F_t q_t^{-1} F_t' R_t.\n\\end{aligned}\n\nNow, denoting e_t = (y_t - f_t) and A_t = R_t F_t q_t^{-1}, we can rewrite the equations above as:\n\\begin{aligned}\nm_t &= a_t + A_t e_t, \\\\\nC_t &= R_t - A_t q_t A_t'\n\\end{aligned}",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#rcode-filtering-in-the-ndlm-example-reading",
    "href": "C4-L03.html#rcode-filtering-in-the-ndlm-example-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.3 Rcode Filtering in the NDLM: Example (Reading)",
    "text": "92.3 Rcode Filtering in the NDLM: Example (Reading)\n\n\nCode\n#################################################\n##### Univariate DLM: Known, constant variances\n#################################################\nset_up_dlm_matrices &lt;- function(FF, GG, VV, WW){\n  return(list(FF=FF, GG=GG, VV=VV, WW=WW))\n}\n\nset_up_initial_states &lt;- function(m0, C0){\n  return(list(m0=m0, C0=C0))\n}\n\n### forward update equations ###\nforward_filter &lt;- function(data, matrices, initial_states){\n  ## retrieve dataset\n  y_t &lt;- data$y_t\n  T &lt;- length(y_t)\n  \n  ## retrieve a set of quadruples \n  # FF, GG, VV, WW are scalar\n  FF &lt;- matrices$FF  \n  GG &lt;- matrices$GG\n  VV &lt;- matrices$VV\n  WW &lt;- matrices$WW\n  \n  ## retrieve initial states\n  m0 &lt;- initial_states$m0\n  C0 &lt;- initial_states$C0\n  \n  ## create placeholder for results\n  d &lt;- dim(GG)[1]\n  at &lt;- matrix(NA, nrow=T, ncol=d)\n  Rt &lt;- array(NA, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(NA, nrow=T, ncol=d)\n  Ct &lt;- array(NA, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  \n  for(i in 1:T){\n    # moments of priors at t\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(m0)\n      Rt[, , i] &lt;- GG %*% C0 %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }else{\n      at[i, ] &lt;- GG %*% t(mt[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , i-1] %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(FF) %*% (at[i, ]) \n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% FF / Qt[i]\n    et[i] &lt;- y_t[i] - ft[i]\n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- Rt[, , i] - Qt[i] * At %*% t(At)\n    Ct[, , i] &lt;- 0.5*Ct[, , i]+ 0.5*t(Ct[, , i])\n  }\n  cat(\"Forward filtering is completed!\") # indicator of completion\n  return(list(mt = mt, Ct = Ct, at = at, Rt = \n                Rt, ft = ft, Qt = Qt))\n}\n\nforecast_function &lt;- function(posterior_states, k, matrices){\n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  WW &lt;- matrices$WW\n  VV &lt;- matrices$VV\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state-space parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(mt[T, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , T] %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }else{\n      at[i, ] &lt;- GG %*% t(at[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Rt[, , i-1] %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }\n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(FF) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n  }\n  cat(\"Forecasting is completed!\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval &lt;- function(mu, sigma2, \n                          quantile = c(0.025, 0.975)){\n  z_quantile &lt;- qnorm(quantile)\n  bound &lt;- matrix(0, nrow=length(mu), ncol=2)\n  bound[, 1] &lt;- mu + \n    z_quantile[1]*sqrt(as.numeric(sigma2)) # lower bound\n  bound[, 2] &lt;- mu + \n    z_quantile[2]*sqrt(as.numeric(sigma2)) # upper bound\n  return(bound)\n}\n\n####################### Example: Lake Huron Data ######################\nplot(LakeHuron,main=\"Lake Huron Data\",\n     ylab=\"level in feet\") # Total of 98 observations \n\n\n\n\n\n\n\n\n\nCode\nk=4\nT=length(LakeHuron)-k # We take the first 94 observations \n                      # only as our data\nts_data=LakeHuron[1:T]\nts_validation_data &lt;- LakeHuron[(T+1):98]\n\ndata &lt;- list(y_t = ts_data)\n\n# First order polynomial model \n\n## set up the DLM matrices \nFF &lt;- as.matrix(1)\nGG &lt;- as.matrix(1)\nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(1)\nm0 &lt;- as.matrix(570)\nC0 &lt;- as.matrix(1e4)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF, GG, VV, WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering\nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nnames(results_filtered)\n\n\n[1] \"mt\" \"Ct\" \"at\" \"Rt\" \"ft\" \"Qt\"\n\n\nCode\nci_filtered &lt;- get_credible_interval(results_filtered$mt, \n                                     results_filtered$Ct)\n\n## forecasting \nresults_forecast &lt;- forecast_function(results_filtered,k, \n                                      matrices)\n\n\nForecasting is completed!\n\n\nCode\nci_forecast &lt;- get_credible_interval(results_forecast$ft, \n                                     results_forecast$Qt)\n\nindex=seq(1875, 1972, length.out = length(LakeHuron))\nindex_filt=index[1:T]\nindex_forecast=index[(T+1):98]\n\nplot(index, LakeHuron, ylab = \"level\", \n     main = \"Lake Huron Level\",type='l',\n     xlab=\"time\",lty=3,ylim=c(574,584))\npoints(index,LakeHuron,pch=20)\n\nlines(index_filt, results_filtered$mt, type='l',\n      col='red',lwd=2)\nlines(index_filt, ci_filtered[, 1], type='l', \n      col='red', lty=2)\nlines(index_filt, ci_filtered[, 2], type='l', col='red', lty=2)\n\n\nlines(index_forecast, results_forecast$ft, type='l',\n      col='green',lwd=2)\nlines(index_forecast, ci_forecast[, 1], type='l',\n      col='green', lty=2)\nlines(index_forecast, ci_forecast[, 2], type='l',\n      col='green', lty=2)\n\nlegend('bottomleft', legend=c(\"filtered\",\"forecast\"),\n       col = c(\"red\", \"green\"), lty=c(1, 1))\n\n\n\n\n\n\n\n\n\nCode\n#Now consider a 100 times smaller signal to noise ratio \nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(0.01)\nmatrices_2 &lt;- set_up_dlm_matrices(FF,GG, VV, WW)\n\n## filtering\nresults_filtered_2 &lt;- forward_filter(data, matrices_2, \n                                     initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nci_filtered_2 &lt;- get_credible_interval(results_filtered_2$mt, \n                                       results_filtered_2$Ct)\n\nresults_forecast_2 &lt;- forecast_function(results_filtered_2, \n                             length(ts_validation_data), \n                             matrices_2)\n\n\nForecasting is completed!\n\n\nCode\nci_forecast_2 &lt;- get_credible_interval(results_forecast_2$ft, \n                                       results_forecast_2$Qt)\n\n\nplot(index, LakeHuron, ylab = \"level\", \n     main = \"Lake Huron Level\",type='l',\n     xlab=\"time\",lty=3,ylim=c(574,584))\npoints(index,LakeHuron,pch=20)\n\nlines(index_filt, results_filtered_2$mt, type='l', \n      col='magenta',lwd=2)\nlines(index_filt, ci_filtered_2[, 1], type='l', \n      col='magenta', lty=2)\nlines(index_filt, ci_filtered_2[, 2], type='l', \n      col='magenta', lty=2)\n\nlines(index_forecast, results_forecast_2$ft, type='l', \n      col='green',lwd=2)\nlines(index_forecast, ci_forecast_2[, 1], type='l', \n      col='green', lty=2)\nlines(index_forecast, ci_forecast_2[, 2], type='l', \n      col='green', lty=2)\n\nlegend('bottomleft', legend=c(\"filtered\",\"forecast\"),\n       col = c(\"magenta\", \"green\"), lty=c(1, 1))\n\n\n\n\n\n\n\n\n\nCode\nplot(index_filt,results_filtered$mt,type='l',col='red',lwd=2,\n     ylim=c(574,584),ylab=\"level\")\nlines(index_filt,results_filtered_2$mt,col='magenta',lwd=2)\npoints(index,LakeHuron,pch=20)\nlines(index,LakeHuron,lty=2)",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#smoothing-and-forecasting-video",
    "href": "C4-L03.html#smoothing-and-forecasting-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.4 Smoothing and forecasting (Video)",
    "text": "92.4 Smoothing and forecasting (Video)\n\n\n\n\nSmoothing\n\n\n\n\nForecasting\n\n\nWe now discuss the smoothing equations for the case of the NDLM, where we are assuming that the variance at the observation level \\nu_t and the covariance matrix at the system level \\mathbf{W}_t are both known.\n \\begin{aligned}\ny_t &= \\mathbf{F}_t' \\mathbf{\\theta}_t + \\nu_t, &\\nu_t &\\sim \\mathcal{N} (0, v_t), & \\text{(observation)} \\\\\n\\mathbf{\\theta}_t & = \\mathbf{G}_t \\mathbf{\\theta}_{t-1} + \\mathbf{\\omega}_t, &\\mathbf{\\omega}_t & \\sim \\mathcal{N} (0, \\mathbf{W}_t), & \\text{(evolution)} \\\\\n&\\{ \\mathbf{F}_t, \\mathbf{G}_t, v_t, \\mathbf{W}_t \\}  &(\\mathbf{\\omega}_0 \\mid \\mathcal{D}_0) & \\sim \\mathcal{N}(\\mathbf{m}_0, \\mathbf{C}_0) & \\text{(prior)}\n\\end{aligned}\n\\tag{92.11}\nwith F_t, G_t, v_t, W_t, m_0 and C_0 known.\nWe have discussed the filtering equations, i.e. the process for obtaining the distributions of \\theta_t \\mid \\mathcal{D}_t, as we collect observations over time, called filtering.\nWe do this by updating the distribution of \\theta_t given the data we have collected step by step, as we move forward in time - updating the from the prior distribution.\nNow we will discuss what happens when we do smoothing, meaning when we revisit the distributions of \\theta_t, given now that we have received a set of observations.\n\n92.4.0.1 Smoothing\nFor t &lt; T, we have that:\n\n(\\theta_t \\mid D_T) \\sim  \\mathcal{N}(a_T(t - T), R_T(t - T)),\n\nwhere\n\na_T(t - T) = m_t - B_t [a_{t+1} - a_T(t - T + 1)],\n\n\nR_T(t - T) = C_t - B_t [R_{t+1} - R_T(t - T + 1)] B_t',\n\nfor t = (T - 1), (T - 2), \\dots, 0, with B_t = C_t G_t' R_{t+1}^{-1}, and a_T(0) = m_T, R_T(0) = C_T. Here a_t, m_t, R_t, and C_t are obtained using the filtering equations as explained before.\n\n\n92.4.0.2 Forecasting\nFor h \\geq 0, it is possible to show that:\n\n(\\theta_{t+h} \\mid D_t) \\sim  \\mathcal{N}(a_t(h), R_t(h)),\n\n\n(y_{t+h} \\mid D_t) \\sim  \\mathcal{N}(f_t(h), q_t(h)),\n\nwith\n\na_t(h) = G_{t+h} a_t(h - 1),\n\n\nR_t(h) = G_{t+h} R_t(h - 1) G_{t+h}' + W_{t+h},\n\n\nf_t(h) = F_{t+h}' a_t(h),\n\n\nq_t(h) = F_{t+h}' R_t(h) F_{t+h} + v_{t+h},\n\nand\n\na_t(0) = m_t, \\quad R_t(0) = C_t.\n\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\nSmoothing\n\nWe know, we now discuss the smoothing equations for the case of the normal dynamic linear model. When we are assuming that both the variance at the observation level is known and the covariance matrix at the system level is also known.\n\n\n\nthe NDLM we will be inferring\n\nRecall we have two equations here, we have the observation equation, where y_t is modeled as F_t'\\theta_t + \\text{noise} the noise is \\mathcal{N}(0,\\nu_t). And we’re assuming that the vt is given. We are also assuming that we know Ft for all t. And then in the evolution equation we have \\theta_t= G_t \\theta(t-1) + noise. And then again, the assumption for the w_t is here is that they are normally distributed with mean zero, and these variants co variance matrix, capital W_t. So we can summarize the model in terms of F_t, G_t, Vt and W_t, that are given for all t. We have discussed the filtering equations.\n\n\n\nRecall what is Filtering?\n\nSo the process for obtaining the distributions of \\theta_t \\mid \\mathcal{D}_t, as we collect observations over time is called filtering.\n\n\n\nRecall what is Smoothing?\n\nNow we will discuss what happens when we do smoothing, meaning when we revisit the distributions of \\theta_t, given now that we have received a set of observations.\n\n\n\nFiltering illustrated\n\nSo Just to illustrate the process, we have here, \\theta_0,\\theta_1 all way up to \\theta_4. And we can assume just for the sake of the example, that we are going to receive three observations. So we are going to proceed with the filtering, and then once we receive the last observation at time three, we’re going to go backwards and we’re going to revisit the distributions for the state parameters.\nSo just to remind you how the filtering works, we move forward, before we receive any observations. In the NDLM, when we have all the variances known. The conjugate prior distribution is a \\mathcal{N}(m_0,C_0), and this is specified by the user, before collecting any observations.\nWe can then use the structure of the model, meaning the system equation and the observation equation to obtain the distribution of \\theta_t \\mid \\mathcal{D}_0. Before observing the first y. This gives us first the distribution of \\theta_t, \\theta_1 \\mid \\mathcal{D}_0, which is \\mathcal{N}(a_1, R_1). And then we can also get the one step ahead forecast distribution for y_1 \\mid  \\mathcal{D}_0, which is a \\mathcal{N}(f_1, q_1). And we have discussed how to obtain these moments using the filtering equations.\nThen we received the first observation, and the first observation can allows us to update the distribution of . So we obtain now the distribution of \\theta1 \\mid y_1, and whatever information we have at \\mathcal{D}_0. So this gives us \\mathcal{N}(m_1, C_1). And using again the structure of the model, we can get the prior distribution for \\theta_2 given the one and that’s a \\mathcal{N}(a_2, R_2). And then the one step ahead forecast distribution now for y_2 \\mid \\mathcal{D}_1 and that’s a \\mathcal{N}(f_2, q_2). So we can receive y_2 update the distribution of and we can continue this process, now get the priors at T=3. And then once we get the observation at T=3, we update the distribution. And we can continue like this with the prior for \\theta_4 and so on. Let’s say that we stop here, at T=3.\n\n\nAnd now we are interested in answering the question. Well, what is the distribution for example of \\theta_2 given that, now, I obtain not only y_1 and y_2, but also y_3. I want to revisit that distribution using all that information. Same thing for say, the distribution of \\theta_0 \\mid D_0, y_1, y_2, y_3. So that’s what it’s called smoothing.\nSo the smoothing equations, allow us to obtain those distributions. So just to talk a little bit about the notation again, in the normal dynamic linear model where v_t and w_t are known for all t’s. We have that this is a normal, so the notation here, the T &gt;t, here. So we’re looking at the distribution of \\theta_t, now in the past and that one follows a normal distribution with mean aT(t-T). So the notation here for the subscript T means that I’m conditioning on all the information I have to T. And then the variance covariance matrix is given by this, RT(t-T). So this is just going to indicate how many steps I’m going to go backwards as you will see in the example.\n\n\nSo we have some recursions in the same way that we have the filtering equations. Now we have the smoothing equations. And for these smoothing equations we have that the mean. You can see here, that whenever you’re computing a particular step t- T, you’re going to need a quantity that you computed in the previous step, t-T+1. So you’re going to need that, is a recursion, but you’re also going to need mt and and at+1. So those are quantities that you computed using the filtering equations. So in order to get the smoothing equations, you first have to proceed with the filtering. Similarly for RT(t-T), you have also that depends on something you previously obtained. And then you also have the Ct, the Rt+1 and so on. So those quantities you computed when you were updating the filtering equations. The recursion begins with aT(0) meaning that you are not going to go backwards any points in time. So that is precisely the mean is going to be whatever you computed with the filtering equations of up to T, that’s mT. And then RT(0) is going to be CT. So just to again illustrate how this would work in the example, if we start here right? If we condition, so the first step would be to compute again to initialize using the distribution of given D3. And that is a normal with mean a3(0) and variance covariance matrix R3(0), But those are precisely m3 and C3 respectively. Then we go backwards one step. And if we want to look at what is the distribution of \\theta^2, now conditional on D3. That’s a normal with mean a3(-1) and variance covariance matrix R3(-1). So if you look at the equations down here, you will see that, in order to compute a3 (-1), and R3(-1). You’re going to need m2,C2, a3,R3 and then what you computed here these moments in the previous step, a3(0) and R3(0). Then you obtain that distribution and you can now look at the distribution of given D3, that’s the normal a3(-2), R3(-2). And once again, to compute these moments, you’re going to need m1,C1,a2,R2 and then you’re going to need a3(-1),R3(-1). And you can continue all the way down to given D3 using these recursions. So the smoothing equations allow us to, just compute all these distributions. And the important equations work basically because of the linear and Gaussian structure in the normal dynamic linear model.\n\n\n\n92.4.1 Forecasting\n\nIn a similar way, we can compute the forecasting distributions. Now we are going to be looking forward, and in the case of forecasting, we are interested in the distribution of \\theta(t+h) given D_t. And now h is a positive lag. So here we assume that is h≥0. So we are going to have the recursion is a N(a_t(h), R_t(h)). The mean is a_t(h) and we are going to use the structure of the model to obtain these recursions, again. So here we are using the system equation, and the moment at(h) depends on what you computed at a_t(h-1) the previous lag, times G_{t+h}. And then, would you initialize the recursion with a_t(0)=m_t.\n\n\nSimilarly, for the covariance matrix h steps ahead, you’re going to have a recursion that depends on Rt(h-1). And then you’re going to need to input also G_{t+h} and W_{t+h}. To initialize, the recursion with Rt(0)= Ct. So you can see that in order to compute these moments, you’re going to need mt and Ct to start with. And then you’re also going to have to input all the G’s and the W’s for the number of steps ahead that you require.\n\n\nSimilarly, you can compute the distribution, the h steps ahead distribution of y_t+h given Dt. And that one also follows a normal, with mean f_t(h), q_t(h). And now we also have a recursion here, ft(h) depends on at(h) and as we said, a_t(h) depends on a_t(h-1) and so on. And q_t(h) is just given by these equations. So once again, you have to have access to F_{t+h} for all the h, a number of steps ahead that you are trying to compute this distribution. And then you also have to provide the observational variance for every h value. So that you get v_{t+h}. So this is specified in the modeling framework as well. If you want proceed with the forecasting distributions.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-the-smoothing-and-forecasting-distributions-reading",
    "href": "C4-L03.html#summary-of-the-smoothing-and-forecasting-distributions-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.5 Summary of the smoothing and forecasting distributions (reading)",
    "text": "92.5 Summary of the smoothing and forecasting distributions (reading)\n\n\n92.5.1 Bayesian Inference in NDLM: Known Variances\nConsider the NDLM given by:\n \\begin{aligned}\ny_t &= \\mathbf{F}_t' \\mathbf{\\theta}_t + \\nu_t, &\\nu_t &\\sim \\mathcal{N} (0, v_t), \\\\\n\\mathbf{\\theta}_t &= \\mathbf{G}_t \\mathbf{\\theta}_{t-1} + \\mathbf{\\omega}_t, &\\mathbf{\\omega}_t &\\sim \\mathcal{N} (0, \\mathbf{W}_t), \\\\\n&\\{ \\mathbf{F}_t, \\mathbf{G}_t, v_t, \\mathbf{W}_t \\}  &(\\mathbf{\\omega}_0 \\mid \\mathcal{D}_0) &\\sim  \\mathcal{N}(\\mathbf{m}_0, \\mathbf{C}_0)\n\\end{aligned}\n\\tag{92.12}\nwith F_t, G_t, v_t, and W_t known.\nWe also assume a prior distribution of the form (\\theta_0 \\mid D_0) \\sim  \\mathcal{N}(m_0, C_0), with m_0 and C_0 known.\n\n92.5.1.1 Smoothing\nFor t &lt; T, we have that:\n\n(\\theta_t \\mid D_T) \\sim  \\mathcal{N}(a_T(t - T), R_T(t - T)),\n\nwhere\n\na_T(t - T) = m_t - B_t [a_{t+1} - a_T(t - T + 1)],\n\n\nR_T(t - T) = C_t - B_t [R_{t+1} - R_T(t - T + 1)] B_t',\n\nfor t = (T - 1), (T - 2), \\dots, 0, with B_t = C_t G_t' R_{t+1}^{-1}, and a_T(0) = m_T, R_T(0) = C_T. Here a_t, m_t, R_t, and C_t are obtained using the filtering equations as explained before.\n\n\n92.5.1.2 Forecasting\nFor h \\geq 0, it is possible to show that:\n\n(\\theta_{t+h} \\mid D_t) \\sim  \\mathcal{N}(a_t(h), R_t(h)),\n\n\n(y_{t+h} \\mid D_t) \\sim  \\mathcal{N}(f_t(h), q_t(h)),\n\nwith\n\na_t(h) = G_{t+h} a_t(h - 1),\n\n\nR_t(h) = G_{t+h} R_t(h - 1) G_{t+h}' + W_{t+h},\n\n\nf_t(h) = F_{t+h}' a_t(h),\n\n\nq_t(h) = F_{t+h}' R_t(h) F_{t+h} + v_{t+h},\n\nand\n\na_t(0) = m_t, \\quad R_t(0) = C_t.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#smoothing-in-the-ndlm-example-video",
    "href": "C4-L03.html#smoothing-in-the-ndlm-example-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.6 Smoothing in the NDLM, Example (Video)",
    "text": "92.6 Smoothing in the NDLM, Example (Video)",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#r-code-smoothing-in-the-ndlm-example-reading",
    "href": "C4-L03.html#r-code-smoothing-in-the-ndlm-example-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.7 R-code: Smoothing in the NDLM, Example (Reading)",
    "text": "92.7 R-code: Smoothing in the NDLM, Example (Reading)\n\n\nCode\n#################################################\n##### Univariate DLM: Known, constant variances\n#################################################\nset_up_dlm_matrices &lt;- function(FF, GG, VV, WW){\n  return(list(FF=FF, GG=GG, VV=VV, WW=WW))\n}\n\nset_up_initial_states &lt;- function(m0, C0){\n  return(list(m0=m0, C0=C0))\n}\n\n### forward update equations ###\nforward_filter &lt;- function(data, matrices, initial_states){\n  ## retrieve dataset\n  y_t &lt;- data$y_t\n  T &lt;- length(y_t)\n  \n  ## retrieve a set of quadruples \n  # FF, GG, VV, WW are scalar\n  FF &lt;- matrices$FF  \n  GG &lt;- matrices$GG\n  VV &lt;- matrices$VV\n  WW &lt;- matrices$WW\n  \n  ## retrieve initial states\n  m0 &lt;- initial_states$m0\n  C0 &lt;- initial_states$C0\n  \n  ## create placeholder for results\n  d &lt;- dim(GG)[1]\n  at &lt;- matrix(NA, nrow=T, ncol=d)\n  Rt &lt;- array(NA, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(NA, nrow=T, ncol=d)\n  Ct &lt;- array(NA, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  \n  \n  for(i in 1:T){\n    # moments of priors at t\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(m0)\n      Rt[, , i] &lt;- GG %*% C0 %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(mt[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(FF) %*% (at[i, ]) \n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% FF / Qt[i]\n    et[i] &lt;- y_t[i] - ft[i]\n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- Rt[, , i] - Qt[i] * At %*% t(At)\n    Ct[,,i] &lt;- 0.5*Ct[,,i] + 0.5*t(Ct[,,i]) \n  }\n  cat(\"Forward filtering is completed!\") # indicator of completion\n  return(list(mt = mt, Ct = Ct, at = at, Rt = Rt, \n              ft = ft, Qt = Qt))\n}\n\n\nforecast_function &lt;- function(posterior_states, k, matrices){\n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  WW &lt;- matrices$WW\n  VV &lt;- matrices$VV\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(mt[T, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , T] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(at[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Rt[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(FF) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n  }\n  cat(\"Forecasting is completed!\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval &lt;- function(mu, sigma2, \n                          quantile = c(0.025, 0.975)){\n  z_quantile &lt;- qnorm(quantile)\n  bound &lt;- matrix(0, nrow=length(mu), ncol=2)\n  bound[, 1] &lt;- mu + z_quantile[1]*sqrt(as.numeric(sigma2)) # lower bound\n  bound[, 2] &lt;- mu + z_quantile[2]*sqrt(as.numeric(sigma2)) # upper bound\n  return(bound)\n}\n\n### smoothing equations ###\nbackward_smoothing &lt;- function(data, matrices, \n                               posterior_states){\n  ## retrieve data \n  y_t &lt;- data$y_t\n  T &lt;- length(y_t) \n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  at &lt;- posterior_states$at\n  Rt &lt;- posterior_states$Rt\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  for(i in T:1){\n    # moments for the distributions of the state vector given D_T\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n      Cnt[, , i] &lt;- 0.5*Cnt[, , i] + 0.5*t(Cnt[, , i]) \n    }else{\n      inv_Rtp1&lt;-solve(Rt[,,i+1])\n      Bt &lt;- Ct[, , i] %*% t(GG) %*% inv_Rtp1\n      mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n      Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i + 1] - Rt[, , i+1]) %*% t(Bt)\n      Cnt[,,i] &lt;- 0.5*Cnt[,,i] + 0.5*t(Cnt[,,i]) \n    }\n    # moments for the smoothed distribution of the mean response of the series\n    fnt[i] &lt;- t(FF) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(FF) %*% t(Cnt[, , i]) %*% FF\n  }\n  cat(\"Backward smoothing is completed!\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n####################### Example: Lake Huron Data ######################\nplot(LakeHuron,main=\"Lake Huron Data\",ylab=\"level in feet\") \n\n\n\n\n\n\n\n\n\nCode\n# 98 observations total \nk=4\nT=length(LakeHuron)-k # We take the first 94 observations \n                     #  as our data\nts_data=LakeHuron[1:T]\nts_validation_data &lt;- LakeHuron[(T+1):98]\n\ndata &lt;- list(y_t = ts_data)\n\n## set up matrices\nFF &lt;- as.matrix(1)\nGG &lt;- as.matrix(1)\nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(1)\nm0 &lt;- as.matrix(570)\nC0 &lt;- as.matrix(1e4)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF,GG,VV,WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering\nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nci_filtered&lt;-get_credible_interval(results_filtered$mt,\n                                   results_filtered$Ct)\n## smoothing\nresults_smoothed &lt;- backward_smoothing(data, matrices, \n                                       results_filtered)\n\n\nBackward smoothing is completed!\n\n\nCode\nci_smoothed &lt;- get_credible_interval(results_smoothed$mnt, \n                                     results_smoothed$Cnt)\n\n\nindex=seq(1875, 1972, length.out = length(LakeHuron))\nindex_filt=index[1:T]\n\nplot(index, LakeHuron, main = \"Lake Huron Level \",type='l',\n     xlab=\"time\",ylab=\"level in feet\",lty=3,ylim=c(575,583))\npoints(index,LakeHuron,pch=20)\n\nlines(index_filt, results_filtered$mt, type='l', \n      col='red',lwd=2)\nlines(index_filt, ci_filtered[,1], type='l', col='red',lty=2)\nlines(index_filt, ci_filtered[,2], type='l', col='red',lty=2)\n\nlines(index_filt, results_smoothed$mnt, type='l', \n      col='blue',lwd=2)\nlines(index_filt, ci_smoothed[,1], type='l', col='blue',lty=2)\nlines(index_filt, ci_smoothed[,2], type='l', col='blue',lty=2)\n\nlegend('bottomleft', legend=c(\"filtered\",\"smoothed\"),\n       col = c(\"red\", \"blue\"), lty=c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#second-order-polynomial-filtering-and-smoothing-example-video",
    "href": "C4-L03.html#second-order-polynomial-filtering-and-smoothing-example-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.8 Second order polynomial: Filtering and smoothing example (Video)",
    "text": "92.8 Second order polynomial: Filtering and smoothing example (Video)\nIn this video walk through the code provided in the section below the comment\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nWe now consider another example where instead of fitting a first order polynomial we’re fitting a second order polynomial DLM. So I just want to show you how to set up the structure of the model in a case in which you have a state parameter vector. That is of dimension larger than one in this particular case we have a bivariate state parameter vector. So once again we are going to source this file that has all the DLM functions for the case in which the F, G, V and W are known. So we’re just assuming that this is the case and then we’re assuming that F, G, V and W are constant over time in these examples. So we just I’m going to use a new data set which is also data set available in R this data set corresponds to the atmospheric CO2 concentrations in parts per million in the location of Mauna Loa. And this is monthly data so I’m just plotting the data here. If you look at the data you can see that it has two important features. One of them is an increasing trend as the time increases the concentration increases. And then the other very specific feature that you can see in this data set is this seasonal behavior. So right now what I’m going to do with this example is we are going to ignore the seasonal behavior, and we are going to try to fit the model that captures the linear increasing trend using a second order polynomial model.\nSo I’m going to just specify everything here. We are going to use the entire data set here. We’re going to analyze the entire data. We are going to read in this into a list and then we’re going to set up the DLM in matrices. So here because the model it’s a second order polynomial we are going to have a state vector. That is of dimension two the F matrix is going to be, so it’s a vector that has 1 in the first entry and 0 in the second one. And then G is this upper triangular matrix that has 1s in the diagonal and 1 above the diagonal as well. So the two parameters that we’re fitting here one of them you can view the two components in the state of theta_t parameter vector. The first component corresponds to the baseline of the level and then the second component corresponds to the rate of growth in that level that we are fitting. So just defining the F and G like that. And then V the observational variance I’m just going to set it at 10. You can play with different numbers here, and the W is a diagonal matrix with .0001 in each of the elements in the diagonal. So these models are not as flexible as the ones that we are going to consider later. So in particular we are using an assumption that the two components in the state sector are independent over time which is usually not very realistic. And we can consider more flexible models later but just to show you here how to fit these models, for the prior distribution I have again two components. So I’m going to say that a priori my baseline is 315 parts per million. And then for the second, the rate of growth is going to be 0 a priori. And then I have C0 which is this 10 times the diagonal of dimension 2 so this is an identity matrix. So is we have a diagonal with the elements in the diagonal equal to 10. So we wrap up all the DLM matrices with the functions that we defined before. And then we proceed with the filtering equations just using the forward filter function. We can obtain credible intervals for the expected value of y_t via this filtering equations.\nSo the reason why I’m calling it the expected value of y_t via filtering it’s just the first component of the say that theta_t vectors. So that corresponds to the level of the series, the expected value of that y_t. And then, I can compute the smoothing equations using the backward smoothing. And again I have to pass the data, the structure of the model in terms of the matrices and the results that I obtained via the filtering equations. And I can compute credible intervals for this expected value via smoothing and as we mentioned before, it has the same structure the smoothing and the filtering is just that, we call the mean and the variance mt and Ct. In the case of the filtering equations for the smoothing equations we just call them mnt and Cnt. So now we can plot all the results here. I’m just going to plot the results that correspond to the smoothing distributions just for you to see. And we can see here that is this trend that is estimated here is capturing the structure of this linear increasing trend. And you can play with different values of the signal to noise ratio. So different values of the V and the W. And if you change the values so that there is more or less signal to noise ratio, you will see that you will capture more of the seasonal structure and less of this linear trend structure. If you were to change those values. So if I go back a little bit here you can see that I have a very low signal to noise ratio and I picked this on purpose, because I didn’t want to capture any of the seasonal behavior that I observe in the series through these parameters. So I’m assuming that a lot of the variation that I see now I’m just keeping it in the noise. Just because I want to just get a very smooth estimate for this linear trend through a second order polynomial model. In practice what we’re going to do later is we really want to construct a model in which we have a component for the linear trend using the second order polynomial model. And then we add another component that will allow us to capture also the seasonal behavior that we observe in this series using a Fourier component model. So we will illustrate that later, in a separate example here is just again to show you how to use the code for specifying a second order polynomial.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#using-the-dlm-package-in-r-video",
    "href": "C4-L03.html#using-the-dlm-package-in-r-video",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.9 Using the dlm package in R (Video)",
    "text": "92.9 Using the dlm package in R (Video)\nThe dlm package in R is a powerful tool for working with dynamic linear models. The package provides a wide range of functions for filtering, smoothing, forecasting, and parameter estimation in DLMs. In this video, we walk through the code provided in Listing 92.7.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nSo here I’m going to show you how to use the dlm package to fit these dynamic linear models as well. So the dlm is package that is available from Cran. And it allows you to compute the filtering smoothing and forecasting equations for dynamic linear models. So I’m just going to show you how to do the same thing we’ve been doing with the code that I provided just using the dlm package. So I’m going to just run here the first examples that we ran. And I’m going to show you how to do the same again. So here, I’m just going through the Lake Huron data. So just setting up every_thing as we did before. And then going through the filtering and smoothing equations. And so we can now plot the results and just want to have all the results here. So we have the red line corresponds to the posterior mean for the distribution of \\theta_t given the Dt using a first order polynomial model to fit the data. And the blue line corresponds to the smoothing mean. So the mean of the posterior distribution of the smoothing equations here. So now we can look at how to fit this with the dlm package. So you have to call, install the package if you don’t have it installed. And then just call that library once you have installed the package. And the dlm package has a different set of functions to construct the model first.\nSo I’m going to use the function that is called the dlmModPoly, which allows you to fit polynomial models. So it constructs the polynomial models. The default function as you can see here is a function in that assumes that the polynomial model is of order 2. So here I want to polynomial model of all the 1. And then I’m going to specify the variance at the observational level, which is called dV in that package. dW is the variance at the evolution level. And then I have my prior mean for theta and the prior variance. I’m just using exactly the same prior distribution. And the package provides two functions of the dlm filter function allows you to providing the data. And the model that you just define computes the filtering recursions here. And then there is another function that is called the dlmSmooth that you essentially pass the results of the filtering equations. And then you obtain the smoothing distributions. So we’re just going to do that. And now I’m going to plot the results that I obtained from those filtering equations. One thing that you can see here, if I do names of, let’s say results_filter_dlm. You can see that the way in which the dlm functions from the dlm package keep the results. It has a particular format. So in the case of the dlm package, you’re going to have the information about what model you fitted. Then you have the mean of theta_t given Dt is kept in this m object. And then you have a is the prior mean of theta_t, given the t -1. And then f is the mean of the one step ahead forecast distribution. And then you have these U.C, D.C, U.R, D.R, those are just decompositions of the C variance matrix. So each of the Cs at time t. And then if you have also the composition of the R matrices. So the model, the way in which the functions are implemented in this dlm package. Assume used an SVD decomposition of all the matrices. So you have to keep in mind if you’re going to recover the structure here for the different components in the model. You have to keep this in mind. So for the filtering results, this is the structure. If you do names of the results, smooth, with the dlm package. You’re going to have again, here is the mean here that is called S and then you have the decomposition of the matrix as well. So, I’m just going to plot now for the filtering results. I’m just going to plot the mean here. And then for the smoothing distribution, I’m also going to plot that means. In this case, we’re working with the first order polynomial. So the dimension of the state vector is 1. So you can see that we obtain exactly the same results. And you can compare them numerically. The upper plot corresponds to the results we get with the code that we’ve been using. And the second block corresponds to just using the code from the dlm package. We can also run the example with the second order polynomial. So again, if I use the specification of the model that we use before with the functions that we described. I can keep my results there. And if I use the dlm package, I can use again, this is a second order polynomial model. I say that the order of the polynomial is 2, I use this dlmModPoly function. I specify the observational variance, the system variance m0 and C0. So I’m using exactly the same priors in this case. And then I use the dlm filter function and the dlm smooth just to compute the moments of the filtering and smoothing distributions. And then I can plot every_thing here. We are plotting just the first component here. The posterior distribution for the first component of the theta vector. Which also corresponds to the expected value of the y_t. And then if I do the same with the dlm package, you can see that you obtain the same results. So again, the upper plot corresponds to the results that we get from the code that we’ve been using. And then the bottom plot corresponds to the results that we get from the dlm package. So I just wanted to illustrate this. You’re welcome to always use the dlm package. Just keep in mind the structure in which the matrices are kept is a little bit different than what we have been discussing. Because the dlm package uses and SVD decomposition of the covariance matrices and keeps every_thing like that. So there are some differences. But you can also use this package to obtain inference in the case of dynamic linear models.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#r-code-using-the-dlm-package-in-r-reading",
    "href": "C4-L03.html#r-code-using-the-dlm-package-in-r-reading",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.10 R-code: Using the dlm package in R (Reading)",
    "text": "92.10 R-code: Using the dlm package in R (Reading)\n\n\n\n\nListing 92.1: Using the dlm package for dynamic linear models\n\n\n\nCode\n#################################################\n##### Univariate DLM: Known, constant variances\n#################################################\nset_up_dlm_matrices &lt;- function(FF, GG, VV, WW){\n  return(list(FF=FF, GG=GG, VV=VV, WW=WW))\n}\n\nset_up_initial_states &lt;- function(m0, C0){\n  return(list(m0=m0, C0=C0))\n}\n\n### forward update equations ###\nforward_filter &lt;- function(data, matrices, initial_states){\n  ## retrieve dataset\n  y_t &lt;- data$y_t\n  T &lt;- length(y_t)\n  \n  ## retrieve a set of quadruples \n  # FF, GG, VV, WW are scalar\n  FF &lt;- matrices$FF  \n  GG &lt;- matrices$GG\n  VV &lt;- matrices$VV\n  WW &lt;- matrices$WW\n  \n  ## retrieve initial states\n  m0 &lt;- initial_states$m0\n  C0 &lt;- initial_states$C0\n  \n  ## create placeholder for results\n  d &lt;- dim(GG)[1]\n  at &lt;- matrix(NA, nrow=T, ncol=d)\n  Rt &lt;- array(NA, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(NA, nrow=T, ncol=d)\n  Ct &lt;- array(NA, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  \n  \n  for(i in 1:T){\n    # moments of priors at t\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(m0)\n      Rt[, , i] &lt;- GG %*% C0 %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(mt[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(FF) %*% (at[i, ]) \n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% FF / Qt[i]\n    et[i] &lt;- y_t[i] - ft[i]\n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- Rt[, , i] - Qt[i] * At %*% t(At)\n    Ct[,,i] &lt;- 0.5*Ct[,,i] + 0.5*t(Ct[,,i]) \n  }\n  cat(\"Forward filtering is completed!\") # indicator of completion\n  return(list(mt = mt, Ct = Ct, at = at, Rt = Rt, \n              ft = ft, Qt = Qt))\n}\n\nforecast_function &lt;- function(posterior_states, k, matrices){\n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  WW &lt;- matrices$WW\n  VV &lt;- matrices$VV\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(mt[T, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , T] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(at[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Rt[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(FF) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n  }\n  cat(\"Forecasting is completed!\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval &lt;- function(mu, sigma2, \n                          quantile = c(0.025, 0.975)){\n  z_quantile &lt;- qnorm(quantile)\n  bound &lt;- matrix(0, nrow=length(mu), ncol=2)\n  bound[, 1] &lt;- mu + z_quantile[1]*sqrt(as.numeric(sigma2)) # lower bound\n  bound[, 2] &lt;- mu + z_quantile[2]*sqrt(as.numeric(sigma2)) # upper bound\n  return(bound)\n}\n\n### smoothing equations ###\nbackward_smoothing &lt;- function(data, matrices, \n                               posterior_states){\n  ## retrieve data \n  y_t &lt;- data$y_t\n  T &lt;- length(y_t) \n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  at &lt;- posterior_states$at\n  Rt &lt;- posterior_states$Rt\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  for(i in T:1){\n    # moments for the distributions of the state vector given D_T\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n      Cnt[, , i] &lt;- 0.5*Cnt[, , i] + 0.5*t(Cnt[, , i]) \n    }else{\n      inv_Rtp1&lt;-solve(Rt[,,i+1])\n      Bt &lt;- Ct[, , i] %*% t(GG) %*% inv_Rtp1\n      mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n      Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i + 1] - Rt[, , i+1]) %*% t(Bt)\n      Cnt[,,i] &lt;- 0.5*Cnt[,,i] + 0.5*t(Cnt[,,i]) \n    }\n    # moments for the smoothed distribution of the mean response of the series\n    fnt[i] &lt;- t(FF) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(FF) %*% t(Cnt[, , i]) %*% FF\n  }\n  cat(\"Backward smoothing is completed!\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n\n####################### Example: Lake Huron Data ######################\nplot(LakeHuron) # 98 observations total \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 92.2: Using the dlm package for dynamic linear models\n\n\n\nCode\nk=4\nT=length(LakeHuron)-k # We take the first \n                      # 94 observations only as our data\nts_data=LakeHuron[1:T]\nts_validation_data &lt;- LakeHuron[(T+1):98]\n\ndata &lt;- list(y_t = ts_data)\n\n## set up dlm matrices\nGG &lt;- as.matrix(1)\nFF &lt;- as.matrix(1)\nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(1)\nm0 &lt;- as.matrix(570)\nC0 &lt;- as.matrix(1e4)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF, GG, VV, WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering and smoothing \nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\n\n\n\nForward filtering is completed!\n\n\n\n\nListing 92.3: Using the dlm package for dynamic linear models\n\n\n\nCode\nresults_smoothed &lt;- backward_smoothing(data, matrices, \n                                       results_filtered)\n\n\n\n\n\nBackward smoothing is completed!\n\n\n\n\nListing 92.4: Using the dlm package for dynamic linear models\n\n\n\nCode\nindex=seq(1875, 1972, length.out = length(LakeHuron))\nindex_filt=index[1:T]\n\n\npar(mfrow=c(2,1), mar = c(3, 4, 2, 1))\nplot(index, LakeHuron, main = \"Lake Huron Level \",type='l',\n     xlab=\"time\",ylab=\"feet\",lty=3,ylim=c(575,583))\npoints(index,LakeHuron,pch=20)\nlines(index_filt, results_filtered$mt, type='l', \n      col='red',lwd=2)\nlines(index_filt, results_smoothed$mnt, type='l', \n      col='blue',lwd=2)\n\n\n# Now let's look at the DLM package \nlibrary(dlm)\nmodel=dlmModPoly(order=1,dV=1,dW=1,m0=570,C0=1e4)\nresults_filtered_dlm=dlmFilter(LakeHuron[1:T],model)\nresults_smoothed_dlm=dlmSmooth(results_filtered_dlm)\n\nplot(index_filt, LakeHuron[1:T], ylab = \"level\", \n     main = \"Lake Huron Level\",\n     type='l', xlab=\"time\",lty=3,ylim=c(575,583))\npoints(index_filt,LakeHuron[1:T],pch=20)\nlines(index_filt,results_filtered_dlm$m[-1],col='red',lwd=2)\nlines(index_filt,results_smoothed_dlm$s[-1],col='blue',lwd=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 92.5: Using the dlm package for dynamic linear models\n\n\n\nCode\n# Similarly, for the second order polynomial and the co2 data:\nT=length(co2)\ndata=list(y_t = co2)\n\nFF &lt;- (as.matrix(c(1,0)))\nGG &lt;- matrix(c(1,1,0,1),ncol=2,byrow=T)\nVV &lt;- as.matrix(200)\nWW &lt;- 0.01*diag(2)\nm0 &lt;- t(as.matrix(c(320,0)))\nC0 &lt;- 10*diag(2)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF,GG, VV, WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering and smoothing \nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\n\n\n\nForward filtering is completed!\n\n\n\n\nListing 92.6: Using the dlm package for dynamic linear models\n\n\n\nCode\nresults_smoothed &lt;- backward_smoothing(data, matrices, \n                                       results_filtered)\n\n\n\n\n\nBackward smoothing is completed!\n\n\n\n\nListing 92.7: Using the dlm package for dynamic linear models\n\n\n\nCode\n#### Now, using the DLM package: \nmodel=dlmModPoly(order=2,dV=200,dW=0.01*rep(1,2),\n                 m0=c(320,0),C0=10*diag(2))\n# filtering and smoothing \nresults_filtered_dlm=dlmFilter(data$y_t,model)\nresults_smoothed_dlm=dlmSmooth(results_filtered_dlm)\n\npar(mfrow=c(2,1), mar = c(3, 4, 2, 1))\nplot(as.vector(time(co2)),co2,type='l',xlab=\"time\",\n     ylim=c(300,380))\nlines(as.vector(time(co2)),results_filtered$mt[,1],\n      col='red',lwd=2)\nlines(as.vector(time(co2)),results_smoothed$mnt[,1],\n      col='blue',lwd=2)\n\nplot(as.vector(time(co2)),co2,type='l',xlab=\"time\",\n     ylim=c(300,380))\nlines(as.vector(time(co2)),results_filtered_dlm$m[-1,1],\n      col='red',lwd=2)\nlines(as.vector(time(co2)),results_smoothed_dlm$s[-1,1],\n      col='blue',lwd=2)",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#practice-graded-assignment-ndlm-sensitivity-to-the-model-parameters",
    "href": "C4-L03.html#practice-graded-assignment-ndlm-sensitivity-to-the-model-parameters",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.11 Practice Graded Assignment: NDLM – sensitivity to the model parameters",
    "text": "92.11 Practice Graded Assignment: NDLM – sensitivity to the model parameters\nOmitted due to the Coursera honor code.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#quiz---ndlm-part-i-review",
    "href": "C4-L03.html#quiz---ndlm-part-i-review",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "92.12 Quiz - NDLM, Part I: Review",
    "text": "92.12 Quiz - NDLM, Part I: Review\nOmitted due to the Coursera honor code.\n\n\n\n\n\n\nPrado, Raquel, Gabriel Huerta, and Mike West. 2000. “Bayesian Time-Varying Autoregressions: Theory, Methods and Applications.” Resenhas Do Instituto de Matemática e Estatı́stica Da Universidade de São Paulo 4 (4): 405–22. https://www2.stat.duke.edu/~mw/MWextrapubs/Prado2001.pdf.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#footnotes",
    "href": "C4-L03.html#footnotes",
    "title": "90  Normal Dynamic Linear Models, Part 1",
    "section": "",
    "text": "the state makes it’s appearance↩︎",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  }
]