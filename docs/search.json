[
  {
    "objectID": "C5-L03.html",
    "href": "C5-L03.html",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "",
    "text": "103.1 Prediction for Location Mixture of AR Models 🎥\nUnfortunately the course was missing the video with the derivation of the full conditional distributions.\n\\begin{split}\n\\mathbb{P}r(\\omega,\\beta,L,\\nu \\mid y) &\\propto \\prod_{k=1}^K  \n  \\underbrace{\n    \\prod_{t:L_t=k} \\mathcal{N}(y_t \\mid f_t^\\top \\beta_k,\\nu)  \n    }_{\n    \\text{Likelihood of the data }  \\mid \\theta\n    }\n  \\underbrace{\n    \\prod_{k=1}^K \\omega_k^{\\sum_{t=1}^T \\mathbb{1}_{(L_t=k)}}\n    \\prod_{k=1}^K \\omega_k^{a_k-1}\n  }_{\n    \\text{Prior for the weights }\\omega\n    }\n  \\underbrace{\n    \\prod_{k=1}^K \\mathcal{N}(\\beta_k \\mid m_0, \\nu C_0)\n    }_{\n      \\text{Prior for the AR coefficients}\n  }\n  \\underbrace{\n      \\mathcal{IG}(\\nu \\mid \\frac{n_0}{2},\\frac{d_0}{2})\n  }_{\n    \\text{Prior for the variance }\\nu\n  }\n\\end{split}\n\\tag{103.1}",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C5-L03.html#sec-capstone-prediction",
    "href": "C5-L03.html#sec-capstone-prediction",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "",
    "text": "Figure 103.1: full posterior distribution\n\n\n\n\n\n\n\n\n\n\nFigure 103.2: full posterior distribution\n\n\n\n\n\n\n\n\nFigure 103.3: full posterior distribution",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C5-L03.html#sec-capstone-fc",
    "href": "C5-L03.html#sec-capstone-fc",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "103.2 Full conditional distributions of model parameters 🎥",
    "text": "103.2 Full conditional distributions of model parameters 🎥\n\n\n\n\n\n\n\nFigure 103.4: full posterior distribution\n\n\n\n\n\n\n\n\nFigure 103.5: weights\n\n\n\n\n\n\n\n\nFigure 103.6: ar\n\n\n\n\n\n\n\n\nFigure 103.7: nu\n\n\n\n\n\n\n\n\nFigure 103.8: beta\n\n\n\n\n\n\n\n\nFigure 103.9: summary\n\n\n\n\n\n\n\n\nFigure 103.10: summary\n\n\n\n\n\n\n\n\nFigure 103.11: full posterior distribution\n\n\n\n\n\n\n\n\n\nIn this class, we will discuss the Gibbs sampler for obtaining posterior samples of model parameters as well as obtaining in-sample posterior predictions. Last time, we have derived for the mixture model, the full posterior distribution of model parameters have these huge form. We will start from here to find the full conditional distributions for each parameter. Let us start with the weight vector Omega. The full posterior distribution of Omega conditioning [inaudible] dot-dot-dot, we will use this three dot to represent the cracked conditioning.\nRemember, to calculate full conditional distributions, we will select out from this full posterior distribution the specific terms that contains the variable of interest. Trying to recognize those terms as forming a kernel of a family that we know and can recognize.\nFor the Omega vector here, we have these two terms containing Omega. Here, this is proportional to the product of k running from 1 to capital K, Omega k. The summation of indicators t from p plus 1 to capital T, indicator L_t equals to k. Also the product of k from 1 to capital K is Omega k, a_k minus 1. I’ll briefly recount combining terms here. This is proportional to the product of k from 1 to capital K Omega k summation of t equals to p plus 1 to capital T, the indicator L_t equals to k plus a_k minus 1. This is a form of the Chernoff Dirichlet distribution.",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C5-L03.html#coding-the-gibbs-sampler",
    "href": "C5-L03.html#coding-the-gibbs-sampler",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "103.3 Coding the Gibbs sampler",
    "text": "103.3 Coding the Gibbs sampler\nIn this section we walk through some of the code in the next section.",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C5-L03.html#sec-capstone-lm-gibbs",
    "href": "C5-L03.html#sec-capstone-lm-gibbs",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "103.4 Sample code for the Gibbs sampler",
    "text": "103.4 Sample code for the Gibbs sampler\n\n103.4.1 Step 1 Simulate data\nWe genereate some data from the three component mixture of AR(2) process Given y_1=-1 and y_2=0 we generate y_3 to y_{3:200} from the following distribution:\n\n\\begin{split}\ny_i \\sim 0.5\\ \\mathcal{N}(0.1 y_{t-1} + 0.1 y_{t-2}, 0.25)  \\\\\n       +\\ 0.3\\ \\mathcal{N}(0.4 y_{t-1} - 0.5 y_{t-2}, 0.25) \\\\\n       +\\ 0.2\\ \\mathcal{N}(0.3 y_{t-1} + 0.5 y_{t-2}, 0.25)  \n\\end{split}\n\n\n## simulate data\ny=c(-1,0,1)\nn.all =200\n\nfor (i in 3:n.all) {\n  set.seed(i)\n  U=runif(1)\n  if(U&lt;=0.5){\n    y.new=rnorm(1,0.1*y[i-1]+0.1*y[i-2],0.25)\n  }else if(U&gt;0.8){\n    y.new=rnorm(1,0.3*y[i-1]+0.5*y[i-2],0.25)\n  }else{\n    y.new=rnorm(1,0.4*y[i-1]-0.5*y[i-2],0.25)\n  }\n  y=c(y,y.new)\n}\n\n\nplot(y,type='l',xlab='Time',ylab='Simulated Time Series')\n\n\n\n\n\n\n\n\n\n\n103.4.2 THe prior\n\n\\begin{aligned}\n\\omega  &\\sim Dir(a_1 \\ldots a_k) \\\\\n\\beta_i &\\sim \\mathcal{N}(\\mathbf{m}_0,\\nu \\mathbf{C}_0) \\\\\n\\nu     &\\sim \\mathcal{IG}(n_0/2,d_0/2)\n\\end{aligned}\n\n\n## Model setup\n\nlibrary(MCMCpack)\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\nlibrary(mvtnorm)\n\n\np=2 ## order of AR process\nK=3 ## number of mixing component\nY=matrix(y[3:200],ncol=1) ## y_{p+1:T}\nFmtx=matrix(c(y[2:199],y[1:198]),nrow=2,byrow=TRUE) ## design matrix F\nn=length(Y) ## T-p\n\n## prior hyperparameters\nm0=matrix(rep(0,p),ncol=1) # weakly informative prior\nC0=10*diag(p)\nC0.inv=0.1*diag(p)\nn0=0.02\nd0=0.02\na=rep(1,K) ##  parameter for dirichlet distribution\n\n\n#### MCMC setup\n\n## number of iterations\n1nsim=20000\n\n## store parameters\n\n2beta.mtx =matrix(0,nrow=p*K,ncol=nsim)\n3L.mtx    =matrix(0,nrow=n,ncol=nsim)\n4omega.mtx=matrix(0,nrow=K,ncol=nsim)\nnu.vec   =rep(0,nsim)\n\n## initial value\n5beta.cur=rep(0,p*K)\n6L.cur=rep(1,n)\n7omega.cur=rep(1/K,K)\n8nu.cur=1\n\n\n1\n\nwe want 20,000 samples\n\n2\n\neach iteration will need p coefficients and there are K components, and there is one column per iteration.\n\n3\n\nL will be a vector of length n, and there is one column per iteration.\n\n4\n\nThe weights omega will be a vector of length K, and there is one column per iteration.\n\n5\n\nWe init \\beta as 0 which means we assume all coefficients are 0 at the beginning.\n\n6\n\nWe init L as 1, which means we assume all observations are from the first component at the beginning.\n\n7\n\nWe init the weights equally as 1/K, the number components,\n\n8\n\nWe init the variance \\nu as 1\n\n\n\n\n\n\n103.4.3 Helper functions to sample from the full conditional distributions\n\nthese are helper functions for doing sampling from:\n\nomega\nL_1 single latent variable\nL sample from L the latent variable\nnu\nbeta\n\n\n\n#### sample functions\n\n1sample_omega=function(L.cur){\n  n.vec=sapply(1:K, function(k){sum(L.cur==k)})\n  rdirichlet(1,a+n.vec)\n}\n\n2sample_L_one=function(beta.cur,omega.cur,nu.cur,y.cur,Fmtx.cur){\n  prob_k=function(k){\n    beta.use=beta.cur[((k-1)*p+1):(k*p)]\n    omega.cur[k]*dnorm(y.cur,mean=sum(beta.use*Fmtx.cur),sd=sqrt(nu.cur))\n  }\n  prob.vec=sapply(1:K, prob_k)\n  L.sample=sample(1:K,1,prob=prob.vec/sum(prob.vec))\n  return(L.sample)\n}\n\n\nsample_L=function(y,x,beta.cur,omega.cur,nu.cur){\n  L.new=sapply(1:n, function(j){sample_L_one(beta.cur,omega.cur,nu.cur,y.cur=y[j,],Fmtx.cur=x[,j])})\n  return(L.new)\n}\n\nsample_nu=function(L.cur,beta.cur){\n  n.star=n0+n\n  err.y=function(idx){\n    L.use=L.cur[idx]\n    beta.use=beta.cur[((L.use-1)*p+1):(L.use*p)]\n    err=Y[idx,]-sum(Fmtx[,idx]*beta.use)\n    return(err^2)\n  }\n  d.star=d0+sum(sapply(1:n,err.y))\n  1/rgamma(1,shape=n.star/2,rate=d.star/2)\n}\n\n\nsample_beta=function(k,L.cur,nu.cur){\n  idx.select=(L.cur==k)\n  n.k=sum(idx.select)\n  if(n.k==0){\n    m.k=m0\n    C.k=C0\n  }else{\n    y.tilde.k=Y[idx.select,]\n    Fmtx.tilde.k=Fmtx[,idx.select]\n    e.k=y.tilde.k-t(Fmtx.tilde.k)%*%m0\n    Q.k=t(Fmtx.tilde.k)%*%C0%*%Fmtx.tilde.k+diag(n.k)\n    Q.k.inv=chol2inv(chol(Q.k))\n    A.k=C0%*%Fmtx.tilde.k%*%Q.k.inv\n    m.k=m0+A.k%*%e.k\n    C.k=C0-A.k%*%Q.k%*%t(A.k)\n  }\n  \n  rmvnorm(1,m.k,nu.cur*C.k)\n}\n\n\n1\n\nthis samples \\omega using a dirichlet RV parametrized by vector of sum of indicators from the current latent vars L.cur\n\n2\n\nto sample the Configuration variable L probability of each one L_k for a single observation y_t\n\n\n\n\nSample \\omega\n\n\\omega \\mid \\cdots \\sim Dir(a_i + \\sum_{t=1}^T \\mathbb{I}_{(L_t=i)}, \\cdots, \\sum_{t=1}^T \\mathbb{I}_{(L_t=K)}) \\qquad k=1,\\cdots,K\n\n\n## Gibbs Sampler\n\nfor (i in 1:nsim) {\n  set.seed(i)\n  \n  ## sample omega\n  omega.cur=sample_omega(L.cur)\n  omega.mtx[,i]=omega.cur\n  \n  ## sample L\n  L.cur=sample_L(Y,Fmtx,beta.cur,omega.cur,nu.cur)\n  L.mtx[,i]=L.cur\n  \n  ## sample nu\n  nu.cur=sample_nu(L.cur,beta.cur)\n  nu.vec[i]=nu.cur\n  \n  ## sample beta\n  beta.cur=as.vector(sapply(1:K, function(k){sample_beta(k,L.cur,nu.cur)}))\n  beta.mtx[,i]=beta.cur\n  \n  ## show the numer of iterations \n  if(i%%1000==0){\n    print(paste(\"Number of iterations:\",i))\n  }\n  \n}\n\n[1] \"Number of iterations: 1000\"\n[1] \"Number of iterations: 2000\"\n[1] \"Number of iterations: 3000\"\n[1] \"Number of iterations: 4000\"\n[1] \"Number of iterations: 5000\"\n[1] \"Number of iterations: 6000\"\n[1] \"Number of iterations: 7000\"\n[1] \"Number of iterations: 8000\"\n[1] \"Number of iterations: 9000\"\n[1] \"Number of iterations: 10000\"\n[1] \"Number of iterations: 11000\"\n[1] \"Number of iterations: 12000\"\n[1] \"Number of iterations: 13000\"\n[1] \"Number of iterations: 14000\"\n[1] \"Number of iterations: 15000\"\n[1] \"Number of iterations: 16000\"\n[1] \"Number of iterations: 17000\"\n[1] \"Number of iterations: 18000\"\n[1] \"Number of iterations: 19000\"\n[1] \"Number of iterations: 20000\"\n\n#### show the result\n\nsample.select.idx=seq(10001,20000,by=1)\n\npost.pred.y.mix=function(idx){\n  \n  k.vec.use=L.mtx[,idx]\n  beta.use=beta.mtx[,idx]\n  nu.use=nu.vec[idx]\n  \n  \n  get.mean=function(s){\n    k.use=k.vec.use[s]\n    sum(Fmtx[,s]*beta.use[((k.use-1)*p+1):(k.use*p)])\n  }\n  mu.y=sapply(1:n, get.mean)\n  sapply(1:length(mu.y), function(k){rnorm(1,mu.y[k],sqrt(nu.use))})\n  \n}\n\ny.post.pred.sample=sapply(sample.select.idx, post.pred.y.mix)\n\nsummary.vec95=function(vec){\n  c(unname(quantile(vec,0.025)),mean(vec),unname(quantile(vec,0.975)))\n}\n\nsummary.y=apply(y.post.pred.sample,MARGIN=1,summary.vec95)\n\nplot(Y,type='b',xlab='Time',ylab='',pch=16,ylim=c(-1.2,1.5))\nlines(summary.y[2,],type='b',col='grey',lty=2,pch=4)\nlines(summary.y[1,],type='l',col='purple',lty=3)\nlines(summary.y[3,],type='l',col='purple',lty=3)\nlegend(\"topright\",legend=c('Truth','Mean','95% C.I.'),lty=1:3,\n      col=c('black','grey','purple'),horiz = T,pch=c(16,4,NA))",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C5-L03.html#prediction-for-location-mixture-of-ar-model",
    "href": "C5-L03.html#prediction-for-location-mixture-of-ar-model",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "103.5 Prediction for location mixture of AR model",
    "text": "103.5 Prediction for location mixture of AR model",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C5-L03.html#determine-the-number-of-components",
    "href": "C5-L03.html#determine-the-number-of-components",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "103.6 Determine the number of components",
    "text": "103.6 Determine the number of components\n\n## Function to determine the number of mixing components\n## It is a combination of posterior inference for mixture model and calculation of DIC\n\nlibrary(MCMCpack)\n\nmodel_comp_mix=function(tot_num_comp){\n  \n  ## hyperparameters\n  m0=matrix(rep(0,p),ncol=1) ## p is the order of AR process\n  C0=10*diag(p)\n  C0.inv=0.1*diag(p)\n  n0=0.02\n  d0=0.02\n  K=tot_num_comp ## let the number of mixing component to vary by input\n  a=rep(1,K)\n  \n  Y=matrix(y[(p+1):n.all],ncol=1) ## y_{p+1:T} n.all is the value of T\n  Fmtx=matrix(c(y[p:(n.all-1)],y[1:(n.all-p)]),nrow=2,byrow=TRUE) ## design matrix F\n  n=length(Y)\n  \n  \n  ## The code below is used to obtain posterior samples of model parameters\n  ## Just copy from the last lecture\n  \n  sample_omega=function(L.cur){\n    n.vec=sapply(1:K, function(k){sum(L.cur==k)})\n    rdirichlet(1,a+n.vec)\n  }\n  \n  sample_L_one=function(beta.cur,omega.cur,nu.cur,y.cur,Fmtx.cur){\n    prob_k=function(k){\n      beta.use=beta.cur[((k-1)*p+1):(k*p)]\n      omega.cur[k]*dnorm(y.cur,mean=sum(beta.use*Fmtx.cur),sd=sqrt(nu.cur))\n    }\n    prob.vec=sapply(1:K, prob_k)\n    L.sample=sample(1:K,1,prob=prob.vec/sum(prob.vec))\n    return(L.sample)\n  }\n  \n  sample_L=function(y,x,beta.cur,omega.cur,nu.cur){\n    L.new=sapply(1:n, function(j){sample_L_one(beta.cur,omega.cur,nu.cur,y.cur=y[j,],Fmtx.cur=x[,j])})\n    return(L.new)\n  }\n  \n  sample_nu=function(L.cur,beta.cur){\n    n.star=n0+n+p*K\n    err.y=function(idx){\n      L.use=L.cur[idx]\n      beta.use=beta.cur[((L.use-1)*p+1):(L.use*p)]\n      err=Y[idx,]-sum(Fmtx[,idx]*beta.use)\n      return(err^2)\n    }\n    err.beta=function(k.cur){\n      beta.use=beta.cur[((k.cur-1)*p+1):(k.cur*p)]\n      beta.use.minus.m0=matrix(beta.use,ncol=1)-m0\n      t(beta.use.minus.m0)%*%C0.inv%*%beta.use.minus.m0\n    }\n    \n    d.star=d0+sum(sapply(1:n,err.y))+sum(sapply(1:K,err.beta))\n    1/rgamma(1,shape=n.star/2,rate=d.star/2)\n  }\n  \n  \n  sample_beta=function(k,L.cur,nu.cur){\n    idx.select=(L.cur==k)\n    n.k=sum(idx.select)\n    if(n.k==0){\n      m.k=m0\n      C.k=C0\n    }else{\n      y.tilde.k=Y[idx.select,]\n      Fmtx.tilde.k=Fmtx[,idx.select]\n      e.k=y.tilde.k-t(Fmtx.tilde.k)%*%m0\n      Q.k=t(Fmtx.tilde.k)%*%C0%*%Fmtx.tilde.k+diag(n.k)\n      Q.k.inv=chol2inv(chol(Q.k))\n      A.k=C0%*%Fmtx.tilde.k%*%Q.k.inv\n      m.k=m0+A.k%*%e.k\n      C.k=C0-A.k%*%Q.k%*%t(A.k)\n    }\n    \n    rmvnorm(1,m.k,nu.cur*C.k)\n  }\n  \n  nsim=20000\n  \n  ## store parameters\n  \n  beta.mtx=matrix(0,nrow=p*K,ncol=nsim)\n  L.mtx=matrix(0,nrow=n,ncol=nsim)\n  omega.mtx=matrix(0,nrow=K,ncol=nsim)\n  nu.vec=rep(0,nsim)\n  \n  ## initial value\n  \n  beta.cur=rep(0,p*K)\n  L.cur=rep(1,n)\n  omega.cur=rep(1/K,K)\n  nu.cur=1\n  \n  ## Gibbs Sampler\n  \n  for (i in 1:nsim) {\n    set.seed(i)\n    \n    ## sample omega\n    omega.cur=sample_omega(L.cur)\n    omega.mtx[,i]=omega.cur\n    \n    ## sample L\n    L.cur=sample_L(Y,Fmtx,beta.cur,omega.cur,nu.cur)\n    L.mtx[,i]=L.cur\n    \n    ## sample nu\n    nu.cur=sample_nu(L.cur,beta.cur)\n    nu.vec[i]=nu.cur\n    \n    ## sample beta\n    beta.cur=as.vector(sapply(1:K, function(k){sample_beta(k,L.cur,nu.cur)}))\n    beta.mtx[,i]=beta.cur\n    \n    if(i%%1000==0){\n      print(i)\n    }\n    \n  }\n  \n  ## Now compute DIC for mixture model\n  ## Somilar as the calculation of DIC in Module 2\n  \n  cal_log_likelihood_mix_one=function(idx,beta,nu,omega){\n    norm.lik=rep(0,K)\n    for (k.cur in 1:K) {\n      mean.norm=sum(Fmtx[,idx]*beta[((k.cur-1)*p+1):(k.cur*p)])\n      norm.lik[k.cur]=dnorm(Y[idx,1],mean.norm,sqrt(nu),log=FALSE)\n    }\n    log.lik=log(sum(norm.lik*omega))\n    return(log.lik)\n  }\n  \n  cal_log_likelihood_mix=function(beta,nu,omega){\n    sum(sapply(1:n, function(idx){cal_log_likelihood_mix_one(idx=idx,beta=beta,nu=nu,omega=omega)}))\n  }\n  \n  sample.select.idx=seq(10001,20000,by=1)\n  \n  beta.mix=rowMeans(beta.mtx[,sample.select.idx])\n  nu.mix=mean(nu.vec[sample.select.idx])\n  omega.mix=rowMeans(omega.mtx[,sample.select.idx])\n  \n  log.lik.bayes.mix=cal_log_likelihood_mix(beta.mix,nu.mix,omega.mix)\n  \n  post.log.lik.mix=sapply(sample.select.idx, function(k){cal_log_likelihood_mix(beta.mtx[,k],nu.vec[k],omega.mtx[,k])})\n  E.post.log.lik.mix=mean(post.log.lik.mix)\n  \n  p_DIC.mix=2*(log.lik.bayes.mix-E.post.log.lik.mix)\n  \n  DIC.mix=-2*log.lik.bayes.mix+2*p_DIC.mix\n  \n  return(DIC.mix)\n}\n\n## Run this code will give you DIC corresponding to mixture model with 2:5 mixing components\nmix.model.all=sapply(2:5,model_comp_mix)\n\n[1] 1000\n[1] 2000\n[1] 3000\n[1] 4000\n[1] 5000\n[1] 6000\n[1] 7000\n[1] 8000\n[1] 9000\n[1] 10000\n[1] 11000\n[1] 12000\n[1] 13000\n[1] 14000\n[1] 15000\n[1] 16000\n[1] 17000\n[1] 18000\n[1] 19000\n[1] 20000\n[1] 1000\n[1] 2000\n[1] 3000\n[1] 4000\n[1] 5000\n[1] 6000\n[1] 7000\n[1] 8000\n[1] 9000\n[1] 10000\n[1] 11000\n[1] 12000\n[1] 13000\n[1] 14000\n[1] 15000\n[1] 16000\n[1] 17000\n[1] 18000\n[1] 19000\n[1] 20000\n[1] 1000\n[1] 2000\n[1] 3000\n[1] 4000\n[1] 5000\n[1] 6000\n[1] 7000\n[1] 8000\n[1] 9000\n[1] 10000\n[1] 11000\n[1] 12000\n[1] 13000\n[1] 14000\n[1] 15000\n[1] 16000\n[1] 17000\n[1] 18000\n[1] 19000\n[1] 20000\n[1] 1000\n[1] 2000\n[1] 3000\n[1] 4000\n[1] 5000\n[1] 6000\n[1] 7000\n[1] 8000\n[1] 9000\n[1] 10000\n[1] 11000\n[1] 12000\n[1] 13000\n[1] 14000\n[1] 15000\n[1] 16000\n[1] 17000\n[1] 18000\n[1] 19000\n[1] 20000",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C5-L03.html#sec-capstone-lsm",
    "href": "C5-L03.html#sec-capstone-lsm",
    "title": "103  Bayesian location mixture of AR(p) models - M3L3",
    "section": "103.7 Location and scale mixture of AR model",
    "text": "103.7 Location and scale mixture of AR model\nIn this part, we will extend the location mixture of AR models to the location and scale mixture of AR models. We will show the derivation of the Gibbs sampler for the model parameters as well as the R code for the full posterior inference.\n\n103.7.1 The Model\nThe location and scale mixture of AR(p) model for the data can be written hierarchically as follows:\n\n\\begin{split}\n&y_t\\sim\\sum_{k=1}^K\\omega_kN(\\mathbf{f}^T_t\\boldsymbol{\\beta}_k,\\nu_k),\\quad \\mathbf{f}^T_t=(y_{t-1},\\cdots,y_{t-p})^T,\\quad t=p+1,\\cdots,T\\\\\n&\\omega_k\\sim Dir(a_1,\\cdots,a_k),\\quad \\boldsymbol{\\beta}_k\\sim N(\\mathbf{m}_0,\\nu_k\\mathbf{C}_0),\\quad \\nu_k\\sim IG(\\frac{n_0}{2},\\frac{d_0}{2})\n\\end{split}\n\\tag{103.2}\nIntroducing latent configuration variable L_t \\in \\{1,2,\\cdots,K\\}, such that L_t=k \\iff y_t\\sim N(\\mathbf{f}^T_t\\boldsymbol{\\beta}_k,\\nu_k), and denote \\boldsymbol{\\beta}=(\\beta_1,\\cdots,\\beta_K), \\boldsymbol{\\omega}=(\\omega_1,\\cdots,\\omega_K), \\mathbf{L}=(L_1,\\cdots,L_T), we can write the full posterior distribution as:\n\np(\\boldsymbol{\\beta},\\boldsymbol{\\nu},\\boldsymbol{\\omega},\\mathbf{L}|\\mathbf{Y},\\mathbf{F}) \\propto p(\\mathbf{Y}|\\boldsymbol{\\beta},\\boldsymbol{\\nu},\\boldsymbol{\\omega},\\mathbf{F})p(\\boldsymbol{\\beta})p(\\boldsymbol{\\nu})p(\\boldsymbol{\\omega})p(\\mathbf{L})\n we can write the full posterior distribution as \n\\begin{split}\np(\\boldsymbol{\\omega},\\boldsymbol{\\beta},\\nu,\\mathbf{L}|\\mathbf{y})&\\propto p(\\mathbf{y}|\\boldsymbol{\\omega},\\boldsymbol{\\beta},\\nu,\\mathbf{L})p(\\mathbf{L}|\\boldsymbol{\\omega})p(\\boldsymbol{\\omega})p(\\boldsymbol{\\beta})p(\\nu)\\\\\n&\\propto \\prod_{k=1}^K\\prod_{\\{t:L_t=k\\}}N(y_t|\\mathbf{f}^T_t\\boldsymbol{\\beta}_k,\\nu)\\prod_{k=1}^K\\omega_k^{\\sum_{t=1}^T\\mathbf{1}(L_t=k)}\\prod_{k=1}^K\\omega_k^{a_k-1}\\prod_{k=1}^K(N(\\boldsymbol{\\beta}_k|\\mathbf{m}_0,\\mathbf{C}_0)IG(\\nu_k|\\frac{n_0}{2},\\frac{d_0}{2}))\n\\end{split}\n\n1.For , we have :\n\n\\boldsymbol{\\omega}|\\cdots\\sim Dir(a_1+\\sum_{t=1}^T\\mathbf{1}(L_t=1),\\cdots,a_K+\\sum_{t=1}^T\\mathbf{1}(L_t=K))\n\n\nFor L_t we have\n\n\np(L_t=k\\mid\\cdots)\\propto \\omega_kN(y_t\\mid\\mathbf{f}^T_t\\boldsymbol{\\beta}_k,\\nu)\n\nTherefore, L_t follows a discrete distribution on \\{1,\\cdots,K\\}. with probability that L_t taking k proportional to \\omega_k N(y_t\\mid\\mathbf{f}^T_t\\boldsymbol{\\beta}_k,\\nu).\n\nFor ν_k and \\boldsymbol{\\beta}_k denote \\mathbf{\\tilde{y}}_k:= \\{y_t: L_t=k\\} and \\mathbf{\\tilde{F}}_k as the design matrix belonging to \\mathbf{\\tilde{y}}_k, and n_l=\\sum_{}^{T}\\mathbb{1}(L_t=k), we have \\nu_k\\mid \\cdots \\sim \\mathcal{IG}(\\frac{n_k^*}{2},\\frac{d_k^*}{2}) and \\boldsymbol{\\beta}_k \\sim \\mathcal{N}(\\mathbf{m}_k,\\nu_k\\mathbf{C}_k) , where \n\\begin{aligned}\n\\mathbf{e}_k  &= \\mathbf{\\tilde{y}}_k-\\mathbf{\\tilde{F}}_k^T\\mathbf{m}_0,\n&\\mathbf{Q}_k &= \\mathbf{\\tilde{F}}_k^T\\mathbf{C}_0\\mathbf{\\tilde{F}}_k+\\mathbf{I}_{n_k},\n&\\mathbf{A}_k &= \\mathbf{C}_0\\mathbf{\\tilde{F}}_k\\mathbf{Q}_k^{-1} \\\\\n\\mathbf{m}_k  &= \\mathbf{m}_0+\\mathbf{A}_k\\mathbf{e}_k,\n&\\mathbf{C}_k &= \\mathbf{C}_0-\\mathbf{A}_k\\mathbf{Q}_k\\mathbf{A}_k^{T} \\\\\nn_k^*         &= n_0+n_k,\n&d_k^*        &= d_0+\\mathbf{e}_k^T\\mathbf{Q}_k^{-1}\\mathbf{e}_k\n\\end{aligned}\n\n\nNow we have the full conditional distributions for all model parameters. We proceed to implement the model in R with a simulate dataset.\n\n\n103.7.2 Step 1 Simulate data\nWe generate some data from the three component mixture of AR(2) process Given y_1=-1 and y_2=0 we generate y_3 to y_{3:200} from the following distribution:\n\n\\begin{split}\ny_i \\sim 0.5\\ \\mathcal{N}(0.1 y_{t-1} + 0.1 y_{t-2}, 0.25)  \\\\\n       +\\ 0.3\\ \\mathcal{N}(0.4 y_{t-1} - 0.5 y_{t-2}, 0.25) \\\\\n       +\\ 0.2\\ \\mathcal{N}(0.3 y_{t-1} + 0.5 y_{t-2}, 0.25)  \n\\end{split}\n\n\n## simulate data\ny=c(-1,0,1)\nT.all=400\n\nfor (i in 4:T.all) {\n  set.seed(i)\n  U=runif(1)\n  if(U&lt;=0.5){\n    y.new=rnorm(1,0.1*y[i-1]+0.1*y[i-2],0.25)\n  }else if(U&gt;0.8){\n    y.new=rnorm(1,0.3*y[i-1]+0.5*y[i-2],0.25)\n  }else{\n    y.new=rnorm(1,0.4*y[i-1]-0.5*y[i-2],0.25)\n  }\n  y=c(y,y.new)\n}\n\n\nplot(y,type='l',xlab='Time',ylab='Simulated Time Series')\n\n\n\n\n\n\n\nFigure 103.12: Simulated Time Series\n\n\n\n\n\n\n\n103.7.3 Setting the Prior\nWe will fit a location and scale mixture of AR(2) models using 3 components. That is, p=2 and K=3. Firstly, we set up the model by choosing prior hyperparameters. We use weakly informative prior for all parameters. That is, we set a_1 = a_2 = a_3 = 1, m_0 = (0, 0)^T, C_0 = 10 \\times I_2, and n_0 = d_0 = 1. They are specified using the following code.\n\nlibrary(MCMCpack)\nlibrary(mvtnorm)\n\n\n## \np=2 ## order of AR process\nK=3 ## number of mixing component\nY=matrix(y[3:200],ncol=1) ## y_{p+1:T}\nFmtx=matrix(c(y[2:199],y[1:198]),nrow=2,byrow=TRUE) ## design matrix F\nn=length(Y) ## T-p\n\n\n## prior hyperparameters\nm0=matrix(rep(0,p),ncol=1)\nC0=10*diag(p)\nC0.inv=0.1*diag(p)\nn0=1\nd0=1\na=rep(1,K)\n\n\n\n103.7.4 Sampling Functions\n\nsample_omega=function(L.cur){\n  n.vec=sapply(1:K, function(k){sum(L.cur==k)})\n  rdirichlet(1,a+n.vec)\n}\n\n\nsample_L_one=function(beta.cur,omega.cur,nu.cur,y.cur,Fmtx.cur){\n  prob_k=function(k){\n    beta.use=beta.cur[((k-1)*p+1):(k*p)]\n    omega.cur[k]*dnorm(y.cur,mean=sum(beta.use*Fmtx.cur),sd=sqrt(nu.cur[k]))\n  }\n  prob.vec=sapply(1:K, prob_k)\n  L.sample=sample(1:K,1,prob=prob.vec/sum(prob.vec))\n  return(L.sample)\n}\n\n\nsample_L=function(y,x,beta.cur,omega.cur,nu.cur){\n  L.new=sapply(1:n, function(j){sample_L_one(beta.cur,omega.cur,nu.cur,y.cur=y[j,],Fmtx.cur=x[,j])})\n  return(L.new)\n}\n\n\nsample_nu=function(k,L.cur){\n  idx.select=(L.cur==k)\n  n.k=sum(idx.select)\n  if(n.k==0){\n    d.k.star=d0\n    n.k.star=n0\n  }else{\n    y.tilde.k=Y[idx.select,]\n    Fmtx.tilde.k=Fmtx[,idx.select]\n    e.k=y.tilde.k-t(Fmtx.tilde.k)%*%m0\n    Q.k=t(Fmtx.tilde.k)%*%C0%*%Fmtx.tilde.k+diag(n.k)\n    Q.k.inv=chol2inv(chol(Q.k))\n    d.k.star=d0+t(e.k)%*%Q.k.inv%*%e.k\n    n.k.star=n0+n.k\n  }  \n  1/rgamma(1,shape=n.k.star/2,rate=d.k.star/2)\n}\n\nsample_beta=function(k,L.cur,nu.cur){\n  nu.use=nu.cur[k]\n  idx.select=(L.cur==k)\n  n.k=sum(idx.select)\n  if(n.k==0){\n    m.k=m0\n    C.k=C0\n  }else{\n    y.tilde.k=Y[idx.select,]\n    Fmtx.tilde.k=Fmtx[,idx.select]\n    e.k=y.tilde.k-t(Fmtx.tilde.k)%*%m0\n    Q.k=t(Fmtx.tilde.k)%*%C0%*%Fmtx.tilde.k+diag(n.k)\n    Q.k.inv=chol2inv(chol(Q.k))\n    A.k=C0%*%Fmtx.tilde.k%*%Q.k.inv\n    m.k=m0+A.k%*%e.k\n    C.k=C0-A.k%*%Q.k%*%t(A.k)\n  }\n  \n  rmvnorm(1,m.k,nu.use*C.k)\n}\n\n\n\n103.7.5 The Gibbs Sampler\n\n## number of iterations\nnsim=20000\n\n\n## store parameters\n\n\nbeta.mtx=matrix(0,nrow=p*K,ncol=nsim)\nL.mtx=matrix(0,nrow=n,ncol=nsim)\nomega.mtx=matrix(0,nrow=K,ncol=nsim)\nnu.mtx=matrix(0,nrow=K,ncol=nsim)\n\n\n## initial value\nbeta.cur=rep(0,p*K)\nL.cur=rep(1,n)\nomega.cur=rep(1/K,K)\nnu.cur=rep(1,K)\n\nNow everything has been set up, we can start to code the loop. Note it may take a while to complete the loop.\n\n## Gibbs Sampler\nfor (i in 1:nsim) {\n  set.seed(i)\n  \n  ## sample omega\n  omega.cur=sample_omega(L.cur)\n  omega.mtx[,i]=omega.cur\n  \n  ## sample L\n  L.cur=sample_L(Y,Fmtx,beta.cur,omega.cur,nu.cur)\n  L.mtx[,i]=L.cur\n  \n  ## sample nu\n  nu.cur=sapply(1:K,function(k){sample_nu(k,L.cur)})\n  nu.mtx[,i]=nu.cur\n  \n  ## sample beta\n  beta.cur=as.vector(sapply(1:K, function(k){sample_beta(k,L.cur,nu.cur)}))\n  beta.mtx[,i]=beta.cur\n  \n  ## show the numer of iterations \n  if(i%%1000==0){\n    print(paste(\"Number of iterations:\",i))\n  }\n  \n}\n\n[1] \"Number of iterations: 1000\"\n[1] \"Number of iterations: 2000\"\n[1] \"Number of iterations: 3000\"\n[1] \"Number of iterations: 4000\"\n[1] \"Number of iterations: 5000\"\n[1] \"Number of iterations: 6000\"\n[1] \"Number of iterations: 7000\"\n[1] \"Number of iterations: 8000\"\n[1] \"Number of iterations: 9000\"\n[1] \"Number of iterations: 10000\"\n[1] \"Number of iterations: 11000\"\n[1] \"Number of iterations: 12000\"\n[1] \"Number of iterations: 13000\"\n[1] \"Number of iterations: 14000\"\n[1] \"Number of iterations: 15000\"\n[1] \"Number of iterations: 16000\"\n[1] \"Number of iterations: 17000\"\n[1] \"Number of iterations: 18000\"\n[1] \"Number of iterations: 19000\"\n[1] \"Number of iterations: 20000\"\n\n\n\n\n103.7.6 Checking the Posterior Inference Result\nFinally, we plot the posterior mean and interval estimate of the original data using the later 10000 posterior samples, which is shown below.\n\nsample.select.idx=seq(10001,20000,by=1)\n\n\npost.pred.y.mix=function(idx){\n  \n  k.vec.use=L.mtx[,idx]\n  beta.use=beta.mtx[,idx]\n  nu.use=nu.mtx[,idx]\n  \n  \n  get.mean=function(s){\n    k.use=k.vec.use[s]\n    sum(Fmtx[,s]*beta.use[((k.use-1)*p+1):(k.use*p)])\n  }\n  get.sd=function(s){\n    k.use=k.vec.use[s]\n    sqrt(nu.use[k.use])\n  }\n  mu.y=sapply(1:n, get.mean)\n  sd.y=sapply(1:n, get.sd)\n  sapply(1:length(mu.y), function(k){rnorm(1,mu.y[k],sd.y[k])})\n  \n}  \n\n\n\n\ny.post.pred.sample=sapply(sample.select.idx, post.pred.y.mix)\n\n\nsummary.vec95=function(vec){\n  c(unname(quantile(vec,0.025)),mean(vec),unname(quantile(vec,0.975)))\n}\n\n\nsummary.y=apply(y.post.pred.sample,MARGIN=1,summary.vec95)\n\n\nplot(Y,type='b',xlab='Time',ylab='',pch=16,ylim=c(-1.2,1.5))\nlines(summary.y[2,],type='b',col='grey',lty=2,pch=4)\nlines(summary.y[1,],type='l',col='purple',lty=3)\nlines(summary.y[3,],type='l',col='purple',lty=3)\nlegend(\"topright\",legend=c('Truth','Mean','95% C.I.'),lty=1:3,\n       col=c('black','grey','purple'),horiz = T,pch=c(16,4,NA))\n\n\n\n\n\n\n\nFigure 103.13",
    "crumbs": [
      "Capstone Project",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayesian location mixture of AR(p) models - M3L3</span>"
    ]
  },
  {
    "objectID": "C6-L00.html",
    "href": "C6-L00.html",
    "title": "Bayesian Non-Parametric Models",
    "section": "",
    "text": "Overview\nHere is a question I raised in my Feynman Notebook:\nThis is not available as a course on Coursera and isn’t a part of the specialization which ended in the last course. So this notes are my own personal notes gathered from tutorials and courses I found on the web. - Tamara Broderick’s Gaussian Processes for Regression tutorials from - 2025 slides video and code - 2024 slides - Tamara Broderick",
    "crumbs": [
      "Bayesian Non-Parametric Models"
    ]
  },
  {
    "objectID": "C6-L00.html#overview",
    "href": "C6-L00.html#overview",
    "title": "Bayesian Non-Parametric Models",
    "section": "",
    "text": "In this course we learn to:\n\nDemonstrate a wide range of skills and knowledge in Bayesian statistics.\nExplain essential concepts in Bayesian statistics.\nApply what you know to real-world data.\n\nWe will build the following skills:\n\nProbability Distribution\nR Programming\nTime Series Analysis and Forecasting\nStatistical Modeling\nPredictive Modeling\nAdvanced Analytics\nBayesian Statistics\nSampling (Statistics)\nStatistical Methods\nData Analysis\nTechnical Communication\nMarkov Model\nfour Analysis\n\nThere are five modules in this course:\n\nGaussian Processes for Regression: We will focus on Gaussian processes as a flexible prior distribution for regression problems, allowing us to capture complex relationships in the data. 1.1 Gaussian process model slides 1.2 Gaussian process regression slides 1.3 Squared exponential kernel and observation noise slides 1.4 What uncertainty are we quantifying? slides 1.5 A list of resources: slide\nDirichlet process: We will explore the Dirichlet process as a prior distribution over probability measures, allowing for flexible modeling of unknown distributions.\nChinese restaurant process: We will introduce the Chinese restaurant process as a metaphor for the Dirichlet process, providing an intuitive understanding of how it works.\nThe peer reviewed data analysis project: We will develop the model and then evaluate other students’ models.",
    "crumbs": [
      "Bayesian Non-Parametric Models"
    ]
  },
  {
    "objectID": "C6-L00.html#prerequisite-skill-checklist",
    "href": "C6-L00.html#prerequisite-skill-checklist",
    "title": "Bayesian Non-Parametric Models",
    "section": "Prerequisite skill checklist 📖",
    "text": "Prerequisite skill checklist 📖\n\n\n\n\n\n\nNotePrerequisite skill checklist\n\n\n\n\n\n\nBayesian Statistics\n\nInterpret and specify the components of Bayesian statistical models: likelihood, prior, posterior.\nExplain the basics of sampling algorithms, including sampling from standard distributions and using MCMC to sample from non-standard posterior distributions.\nAssess the performance of a statistical model and compare competing models using posterior samples.\nCoding in R to achieve the above tasks.\n\n\n\nMixture Models\n\nDefine mixture model.\nExplain the likelihood function associated with a random sample from a mixture distribution.\nDerive Markov chain Monte Carlo algorithms for fitting mixture models.\nCoding in R to achieve the above tasks.\n\n\n\nTime Series Analysis\n\nDefine time series and stochastic processes (univariate, discrete-time, equally-spaced)\nDefine strong and weak stationarity\nDefine the auto-covariance function, the auto-correlation function (ACF), and the partial autocorrelation function (PACF)\nDefinition of the general class of autoregressive processes of order p.",
    "crumbs": [
      "Bayesian Non-Parametric Models"
    ]
  },
  {
    "objectID": "C6-L00.html#some-references",
    "href": "C6-L00.html#some-references",
    "title": "Bayesian Non-Parametric Models",
    "section": "Some References:",
    "text": "Some References:\n\nGaussian Processes Rasmussen and Williams (2006)\nSurrogates Gramacy (2020)\nA Tutorial on Bayesian Optimization Frazier (2018)\n\n\nIt builds a surrogate for the objective and quantifies the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function defined from this surrogate to decide where to sample\nthree common acquisition functions:\n\nexpected improvement\nentropy search\nknowledge gradient\n\n\n\n\n\n\n\n\nFrazier, Peter I. 2018. “A Tutorial on Bayesian Optimization.” https://arxiv.org/abs/1807.02811.\n\n\nGramacy, Robert B. 2020. Surrogates: Gaussian Process Modeling, Design, and Optimization for the Applied Sciences. Chapman & Hall/CRC the r Series. CRC Press. https://bookdown.org/rbg/surrogates/.\n\n\nRasmussen, Carl Edward, and Christopher K. I. Williams. 2006. Gaussian Processes for Machine Learning. Adaptive Computation and Machine Learning Series. MIT Press. https://gaussianprocess.org/gpml/.",
    "crumbs": [
      "Bayesian Non-Parametric Models"
    ]
  },
  {
    "objectID": "C6-L01.html",
    "href": "C6-L01.html",
    "title": "104  Gaussian Processes for Regression",
    "section": "",
    "text": "104.1 Why GPs",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#why-gps",
    "href": "C6-L01.html#why-gps",
    "title": "104  Gaussian Processes for Regression",
    "section": "",
    "text": "Why Gaussian processes (GPs)?\nExample 1:\n\nThe ocean current (velocity vector field) varies by space & time\nScientists get sparse observations of the current from buoys\nGoal: estimate the current\nc.f. [Ryan, Özgökmen 2023; Zewe 2023; Gonçalves et al 2019; Lodise et al 2020; Berlinghieri et al 2023]\n\nChallenges:\n\nSparse & expensive data, not on a grid\nCurrent is highly nonlinear but smooth in space-time\nWe want uncertainty quantification\nc.f.\n\n[Gramacy,Lee 2008]\n[Gramacy 2020]\n\n\nExample 2: Surrogate model\n\nThe lift force of a rocket booster varies as a function of\n\nspeed at re-entry,\nangle of attack, and\nsideslip angle\n\nScientists can run expensive simulations at chosen input settings\nGoal: estimate how lift varies as a function of input settings\n\nExample 3: learn (& optimize) performance in machine learning as a function of tuning parameters\n\nc.f. [Snoek et al 2012; 2015; Garnett 2023]\n\nMotif:\n\nSparse, noisy, costly but but smooth data.\nOutput may have a nonlinear relationship to the inputs.\nWant uncertainty quantification.\nLow-dimensional inputs.\n\nBonus benefits:\n\nEase of use (software, tuning)\nSupports optimization of outcome\nPredictions & uncertainties over derivatives & integrals\nModule in more-complex methods\n\n\n\n\n\n\n\n\nImportant⚡ Overthinking parameters in Bayesian nonparametric models\n\n\n\n\nLet’s talk about the elephant in the room nonparametrics do have parameters!\nThe classical form of a distribution based on a few fixed number parameters is replaced in these by a notion similar to a euclidean line which can be arbitrary extended. This is the nature of the nonparametric parameter vector \\theta.\nTo make the analogy more precise and what the above and many examples illustrate is that we often are interested in some behavior Y but as we get more and more data X, we will notice that there are new types of behavior that we did not observe earlier.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#more-examples",
    "href": "C6-L01.html#more-examples",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.2 More Examples:",
    "text": "104.2 More Examples:\n\nnew species are being daily\nnew friend set appear as social networks expand\nnew entities appear in images as the data set expands\nnew wikipedia articles are discovered as we click on wikilinks\nnew alleles are identified as we sequence more genomes",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#roadmap",
    "href": "C6-L01.html#roadmap",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.3 Roadmap",
    "text": "104.3 Roadmap\n\nA Bayesian approach\nWhat is a Gaussian process?\n\nPopular version using a squared exponential kernel\n\nGaussian process inference.\n\nPrediction & uncertainty quantification.\n\nGoal:\n\nLearn the mechanism behind standard GPs to identify benefits and pitfalls",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#a-bayesian-approach",
    "href": "C6-L01.html#a-bayesian-approach",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.4 A Bayesian approach",
    "text": "104.4 A Bayesian approach\n\n\n\n\n\n\n\nFigure 104.1: posterior\n\n\n\n\n\n\n\n\nFigure 104.2: joint\n\n\n\n\n\\underbrace{\n  \\mathbb{P}r(unknowns \\mid data) }_{\n    \\substack{\n      \\text{Given the data we've seen} \\\\\n      \\text{what do we know about } \\\\\n      \\text{the underlying function?}\n    }\n  }\n\\propto\n\\underbrace{\n  \\mathbb{P}r(data \\mid unknowns)\n  \\mathbb{P}r(unknowns)}_{  \n    \\substack{\n      \\text{A (statistical) model} \\\\\n      \\text{that can generate} \\\\\n      \\text{functions and data} \\\\\n      \\text{of interest}\n    }\n  }",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#sec-multivariate-gaussian-locations",
    "href": "C6-L01.html#sec-multivariate-gaussian-locations",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.5 Multivariate Gaussian using locations",
    "text": "104.5 Multivariate Gaussian using locations\n\n\n\n\n\n\n\nFigure 104.3\n\n\n\nM =2 bivariate Gaussian [y^{(1)} y^{(2)}] \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\nwith \\mu = [0,0]^\\top and k = \\sigma^2 \\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1\\end{bmatrix} where \\rho is the correlation between the two dimensions.\nWhat if we let the correlation \\rho depend on the input x?\n\nLet \\rho(x)= \\rho(\\mid x^{(1)} - x^{(2)} \\mid)\nWhere the correlation goes to 1 as the x’s get close\nAnd goes to 0 as the x’s get far\n\nNext: Use a Similar setup but an M-long Gaussian instead of just a bivariate\n\nWe have M locations (need not be in order): X^{(m)} \\in \\mathbb{R}^d\nWe generate [y^{(1)}, \\ldots,y^{(m)}]^\\top \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{K})\nwith \\mu=0_M and K such that \\mathbf{K}_{ij} = \\sigma^2 \\rho\\mid (x^{(i)}, x^{(j)}\\mid)\nLet’s try \\rho(\\Delta)=\\exp(-\\tfrac{1}{2} \\Delta^2)\n\n\\rho(0)=1 ,\n\\lim_{\\Delta \\to \\infty} \\rho(\\Delta)=0 and\n\\rho(\\Delta) is monotonically decreasing",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#demo-1-draws-from-a-multivariate-normal-distribution",
    "href": "C6-L01.html#demo-1-draws-from-a-multivariate-normal-distribution",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.6 Demo 1 : Draws from a multivariate normal distribution",
    "text": "104.6 Demo 1 : Draws from a multivariate normal distribution\n\n\n\nListing 104.1\n\n\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\nrng = np.random.RandomState()\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\n\n\n\n\nsignal_stddev = 1.0\nkern = signal_stddev**2*RBF(\n  length_scale=1.0,\n1  length_scale_bounds=\"fixed\")\nn_samples = 3\ngp = GaussianProcessRegressor(kernel=kern)\nnumx=100\nxstart=-0.5\nxstop=3.5\nx=np.linspace(start=xstart,stop=xstop,num=numx)\n2twosd=2*signal_stddev*np.ones(numx)\nplt.fill_between(x,twosd,-twosd,color=\"gray\",alpha=0.3)\nxdraw=np.array([0.0,0.05]).reshape(-1,1); \ny_all_draws=gp.sample_y(xdraw,random_state=rng,\n                        n_samples=n_samples); \nmarker_collection=[\"o\",\"^\",\"x\"]\nfor i, ydraw in enumerate(y_all_draws.T): \n  plt.scatter(\n    xdraw,ydraw,\n3    marker=marker_collection[np.mod(i,n_samples)])\n4plt.xlim([xstart,xstop])\nplt.ylim((-3*signal_stddev,3*signal_stddev))\npltaxes = plt.gca()\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\noutput = plt.title(\"Multivariate normal draws; correlation decreases as x distance increases\")\n\n\n1\n\nset the kernel\n\n2\n\ncoloring 2 std dev range\n\n3\n\nplotting the draws\n\n4\n\nmake the plot\n\n\n\n\n\n\n\n\n\n\nFigure 104.4: Multivariate normal 2 draws\n\n\n\n\n\n\nsignal_stddev = 1.0\nkern = signal_stddev**2*RBF(\n  length_scale=1.0,\n1length_scale_bounds=\"fixed\")\ngp = GaussianProcessRegressor(kernel=kern)\nnumx=100\nxstart=-0.5\nxstop=3.5\nx=np.linspace(\n  start=xstart,\n  stop=xstop,\n  num=numx)\n2twosd=2*signal_stddev*np.ones(numx)\nplt.fill_between(x,\n  twosd,-twosd,\n  color=\"gray\",\n  alpha=0.3)\nxdraw=np.array([0.0,0.05,3.0]).reshape(-1,1)\ny_all_draws=gp.sample_y(\n  xdraw,random_state=rng,n_samples=3)\nmarker_collection=[\"o\",\"^\",\"x\"]\nfor i, ydraw in enumerate(y_all_draws.T): \n  plt.scatter(\n    xdraw,\n    ydraw,\n3    marker=marker_collection[np.mod(i,3)])\nplt.xlim([xstart,xstop])\nplt.ylim((-3*signal_stddev,3*signal_stddev))\n4pltaxes = plt.gca()\noutput = plt.title(\"Multivariate normal draws; correlation decreases as x distance increases\") # &lt;4&gt;plot\n\n\n1\n\nset the kernel\n\n2\n\ncoloring 2 std dev range\n\n3\n\nplotting the draws\n\n4\n\nmake the plot\n\n\n\n\n\n\n\n\n\n\nFigure 104.5: Multivariate normal three points unevenly spaced\n\n\n\n\n\n\nsignal_stddev = 1.0\nkern = signal_stddev**2*RBF(length_scale=1.0,length_scale_bounds=\"fixed\") # set the kernel\ngp = GaussianProcessRegressor(kernel=kern)\nnumx=200\nxstart=-0.5\nxstop=3.5\nx=np.linspace(start=xstart,stop=xstop,num=numx)\ntwosd=2*signal_stddev*np.ones(numx) # coloring 2 std dev range\nplt.fill_between(x,\n  twosd,-twosd,color=\"gray\",\n  alpha=0.3) # coloring 2 std dev range\nxdraw=np.linspace(\n  start=xstart,stop=xstop,\n  num=numx).reshape(-1,1)\ny_all_draws=gp.sample_y(\n  xdraw,random_state=rng,\n  n_samples=3) \nmarker_collection=[\"o\",\"^\",\"x\"]\nfor i, ydraw in enumerate(y_all_draws.T): \n  plt.scatter(xdraw,ydraw,marker=marker_collection[np.mod(i,3)]) \n  plt.plot(xdraw,ydraw) # plotting the draws\nplt.xlim([xstart,xstop])\nplt.ylim((-3*signal_stddev,3*signal_stddev))\npltaxes = plt.gca() # make the plot\noutput = plt.title(\"Multivariate normal draws; correlation decreases as x distance increases\") # make the plot\n\n\n\n\n\n\n\nFigure 104.6: Multivariate normal 50 point evenly spaced\n\n\n\n\n\nwe just drew random functions from a type of “Gaussian process”!",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#sec-gaussian-processes",
    "href": "C6-L01.html#sec-gaussian-processes",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.7 Gaussian processes",
    "text": "104.7 Gaussian processes\n\nDefinition: “A Gaussian process is a collection of random variables, any finite number of which have a joint Gaussian distribution.” – (Rasmussen and Williams 2006)\nE.g. the function is a collection indexed by input x:   \n  f(x) \\sim \\mathcal{GP}(m, k)\n\nIt is specified by its mean function and covariance function:\n\nMean function m(x)=E[f(x)]\nCovariance function (a.k.a. kernel) k(x,x')=\\mathbb{E}[(f(x) - m(x))(f(x') - m(x'))]\nA common default (e.g. in software) is m(x)=0\nOne very commonly used covariance function is the squared exponential or radial basis function (RBF)\nWe’ll see a more general form later, but for now we’re using: k(x, x') = \\sigma^2 \\exp\\left(-\\frac{1}{2} \\|x - x'\\|^2\\right)\nFor now, assume data is observed without noise\n\n\nLet’s look at a draw from the Gaussian process, i.e. we are just generating synthetic data from the Gaussian process model.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#demo-2-draw-from-a-gaussian-process",
    "href": "C6-L01.html#demo-2-draw-from-a-gaussian-process",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.8 Demo 2: Draw from a Gaussian process",
    "text": "104.8 Demo 2: Draw from a Gaussian process\n\nsignal_stddev = 1.0; \nkern = signal_stddev**2*RBF(\n  length_scale=1.0,\n  length_scale_bounds=\"fixed\") # set the kernel\ngp = GaussianProcessRegressor(kernel=kern)\nxobs = np.array([0.0,0.05,0.7,3.0]); \nNobs = xobs.shape[0]\nnumx=50; \nxstart=-0.5; \nxstop=3.5; x=np.linspace(\n  start=xstart,stop=xstop,num=numx); \ntwosd=2*signal_stddev*np.ones(numx) # coloring 2 std dev range\nplt.fill_between(\n  x,\n  twosd,\n  -twosd,\n  color=\"gray\",\n  alpha=0.3) # coloring 2 std dev range\nxcurve=np.linspace(start=xstart,stop=xstop,num=numx); \nxall = np.concatenate((xcurve,xobs)).reshape(-1,1)\nyall = gp.sample_y(xall,random_state=rng,n_samples=1); \nycurve=yall[0:numx]; \nyobs=yall[numx:numx+Nobs]\nplt.plot(xcurve,ycurve,linestyle=\"dashed\",color=\"blue\"); \nplt.scatter(xobs,yobs,color=\"black\",marker=\"x\")\nplt.xlim([xstart,xstop]); \nplt.ylim((-3*signal_stddev,3*signal_stddev)); \npltaxes = plt.gca() # make the plot\noutput = plt.title(\"A draw from a Gaussian process with \" + str(Nobs) + \" simulated data points\") # make the plot\n\n\n\n\n\n\n\nFigure 104.7\n\n\n\n\n\n\n# just the training data\nplt.fill_between(x,twosd,-twosd,color=\"gray\",alpha=0.3) # coloring 2 std dev range\nplt.scatter(xobs,yobs,color=\"black\",marker=\"x\")\nplt.xlim([xstart,xstop]); plt.ylim((-3*signal_stddev,3*signal_stddev)); pltaxes = plt.gca() # make the plot\noutput = plt.title(str(Nobs) + \" simulated data points\") # make the plot\n\n\n\n\n\n\n\nFigure 104.8: A draw from a Gaussian process with 4 simulated data points",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#note-on-dimension-of-the-input",
    "href": "C6-L01.html#note-on-dimension-of-the-input",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.9 Note on “dimension” of the input",
    "text": "104.9 Note on “dimension” of the input\n\n\n\n\n\n\n\n\nFigure 104.9\n\n\n\n\n\n\n\n\nFigure 104.10\n\n\n\n\nLet’s be careful to separate two types of “dimension”\n\nWe’re using a superscript y^{(1)} to denote (M or N) number of points in the space\nWe’ll use a subscript for the (D) different elements of a point’s vector\n\nNote: all of our real-life examples from the start had number of inputs D &gt; 1\nD = 1 is much easier to visualize, but might not be representative.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#inference-about-unknowns-given-data.",
    "href": "C6-L01.html#inference-about-unknowns-given-data.",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.10 Inference about Unknowns given data.",
    "text": "104.10 Inference about Unknowns given data.\n\nLet X collect the N “training” data points (indexed 1 to N)\nLet X' collect the M “test” data points X: N\\times D\n\nWhere we want to evaluate the function\nIndexed N+1:N+M\n\nK(X,X') os the N \\times M matrix with (n,m) entry k(x^{(n)}, x^{(N+m)})\nThen by our model (dimension are annotated in blue) \n\\begin{bmatrix}\n\\overbrace{f(X)}^{\\color{blue}N\\times 1} \\\\\n\\underbrace{f(X')}_{\\color{blue}M\\times 1}\n\\end{bmatrix}\n\\sim \\mathcal{N}\n\\left(\n  \\underbrace{\n    \\begin{bmatrix}\n    0_N \\\\\n    0_M\n    \\end{bmatrix}}_{\\color{blue}(N+M)\\times 1 } ,\n  \\underbrace{\n\\begin{bmatrix}\n  K(X, X) & K(X, X') \\\\\n  K(X', X) & K(X', X')\n\\end{bmatrix}}_{\n  \\color{blue}(N+M)\\times (N+M)\n}\n\\right)\n\nThe conditional satisfies f(X')\\mid f(X), X, X' \\sim \\mathcal{N}\n\nCan compute mean (\\color{blue}M\\times 1) & covariance (\\color{blue}M\\times M) in closed form with Gaussian facts\n\n\n\n\\begin{aligned}\nk(x, x') = \\sigma^2 \\exp\\left(-\\tfrac{1}{2}(x - x')^2\\right), \\sigma^2 = 1\n\\end{aligned}\n\nNow we can flip this around using the Bayesian machinery and use that to get information. When we don’t know the function, but we do know the data, which is real life. In real life You know the data, but you don’t know the function and you’re trying to learn that direction.\nIf we want to draw a curve we need M to be very large. And we will need to generate a M \\times D matrix of points.\nSo now what we’re going to do is we’re going to run Gaussian process regression on those points. And what do I mean by, say, running Gaussian process regression I’m literally talking about exactly what we just did on the slide together.\n\ngpfit = GaussianProcessRegressor(\n1  kernel=kern, optimizer=None)\ngpfit.fit(xobs.reshape(-1,1),yobs.reshape(-1,1))\nmean_pred, stddev_pred = gpfit.predict(\n  xcurve.reshape(-1,1), \n  return_std=True)\nplt.scatter(\n  xobs,yobs,color=\"black\",\n  marker=\"x\", label=\"training data\")\nplt.plot(\n  xcurve,ycurve,linestyle=\"dashed\",\n  color=\"blue\", label=\"original function\")\nplt.plot(\n  xcurve,mean_pred,color=\"green\", \n  label=\"mean predictions\")\nplt.fill_between(\n  xcurve,mean_pred-2*stddev_pred,\n  mean_pred+2*stddev_pred,color=\"green\",\n  alpha=0.3,label=r\"+/-2 std dev interval\")\nplt.legend(); \nplt.xlim([xstart,xstop]); \nplt.ylim((-3*signal_stddev,3*signal_stddev)); \nplotout = plt.title(\"Gaussian process predictions\")\n\n\n1\n\nNOT fitting kernel hyperparameters\n\n\n\n\n\n\n\n\n\n\nFigure 104.11: Gaussian process predictions\n\n\n\n\n\nWe’re saying hey jointly You can think of the joint distribution of the value of the value of the Gaussian process at all of these different X locations, all of these different horizontal locations.\nWhat we would have is we would have everything else. In this plot we’d have The black X’s, that’s our observed data. So we totally know that.\n\nWe have:\n\nOur observed data, the black X’s, which is our training data.\nOur predictions. that is the solid green line it is the mean of the Gaussian process at all of these different X locations away from the observations. We are creating it just like we created our draws or like we created our, our big prior Gaussian process before.\nWe’re saying, hey, what’s the mean? In this case, it’s non-trivial. It’s not just zero because it’s conditioned on the data.\nWe have our uncertainties, our plus or minus two standard deviation interval.\n\n\nNow, before, this was pretty boring. When we were first generating things a priori when we didn’t have any data. The plus or minus two standard deviation interval is just plus or minus two everywhere. Now, because we’ve observed some data, it’s not trivial. We’re actually seeing that it differs depending on where we are in the space.\nAnd I just want to point out some things that might be considered useful about this.\n\nWhen I’m really near my data points\n\nwe see there’s very little uncertainty.\nvery little uncertainty going between them. Because this is basically the only way we can smoothly and quickly go between these two points.\n\nwhen we get much farther away we have a lot of uncertainty because there’s a good number of different ways that we could have gotten between these two points. It makes sense that our uncertainty would be larger As we get farther away.\n\n\n1gpfit = GaussianProcessRegressor(kernel=kern, optimizer=None)\ngpfit.fit(xobs.reshape(-1,1),yobs.reshape(-1,1))\nmean_pred, stddev_pred = gpfit.predict(xcurve.reshape(-1,1), return_std=True)\ny_all_draws=gpfit.sample_y(xcurve.reshape(-1,1),random_state=rng,n_samples=3)\ncolor_options=[\"red\",\"blue\",\"orange\"]\nplt.scatter(xobs,yobs,color=\"black\",marker=\"x\", label=\"training data\")\n\nfor i, ydraw in enumerate(y_all_draws.T): \n  plt.plot(xcurve,ydraw,label=\"random draw\",color=color_options[np.mod(i,3)])\nplt.fill_between(\n  xcurve,mean_pred-2*stddev_pred,mean_pred+2*stddev_pred,\n  color=\"green\",alpha=0.3,label=r\"+/-2 std dev interval\")\nplt.legend(); \nplt.xlim([xstart,xstop]); \nplt.ylim((-3*signal_stddev,3*signal_stddev)); \nplotout = plt.title(\"Random draws of f from the predictive distribution\")\n\n\n1\n\nNOT fitting kernel hyperparameters\n\n\n\n\n\n\n\n\n\n\nFigure 104.12: Gaussian process predictions with noise\n\n\n\n\n\nNow we have these four data points. And so we’ve constrained our random draws of the functions to go through the four data points.\nAnd here are just three draws from it. Because again, it’s just a multivariate Gaussian is all that we’re doing here. We’re just making this multivariate Gaussian the same way we did before by having draws at many dense x values at many dense input values. And so we can do the same thing here. It’s just a different multivariate Gaussian.\nThis is meant to express Our uncertainty and our best guess, our best guess could be seen as this mean This posterior mean. So these are the mean predictions this solid green line. So that could be thought of as our best guess. And then our uncertainty around that\nIs the plus or minus two standard deviation interval conditional on the data that we’ve seen. And now we’re going to dig a little bit more. Into some choices we’ve made and what are their implications.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#sec-squared-exponential-kernel-revisited",
    "href": "C6-L01.html#sec-squared-exponential-kernel-revisited",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.11 Squared exponential kernel revisited",
    "text": "104.11 Squared exponential kernel revisited\nWhat if we happened to measure our data on a different scale?\nWe’ve been using this particular kernel:\n\n\\begin{aligned}\nk(x, x') &= \\sigma^2 \\exp\\left(-\\tfrac{1}{2}(x - x')^2\\right), \\sigma^2 = 1\n\\end{aligned}\n\n\nWhat do we expect from the scale of f(x) a priori?\n\nAt one x, with ~95% probability a priori, f(x) is in the interval [-2\\sigma, \\sigma].\nMarginal variance cannot increase with data\n\nWhat counts as “close” in x?\n\n\n\\exp(-\\tfrac{1}{2}(2)^2) \\approx 0.14 \\quad\n\\exp(-\\tfrac{1}{3}(3)^2) \\approx 0.11 \\quad\n\\exp(-\\tfrac{1}{2}(4)^2) \\approx 0.0034 \\quad\n\n\n# observed y values are 100 times what they were in the nice example\ngpfit = GaussianProcessRegressor(\n1  kernel=kern, optimizer=None)\ngpfit.fit(xobs.reshape(-1,1),\n  100*yobs.reshape(-1,1))\nmean_pred, stddev_pred = gpfit.predict(\n  xcurve.reshape(-1,1), \n  return_std=True)\nplt.scatter(xobs,100*yobs,color=\"black\",\nmarker=\"x\", label=\"training data\")\nplt.plot(xcurve,100*ycurve,linestyle=\"dashed\",\ncolor=\"blue\", label=\"original function\")\nplt.plot(xcurve,mean_pred,color=\"green\", \nlabel=\"mean predictions\")\nplt.fill_between(\n  xcurve,\n  mean_pred-2*stddev_pred,mean_pred+2*stddev_pred,\n  color=\"green\",alpha=0.3,\n  label=r\"+/-2 std dev interval\")\nplt.legend(); \nplt.xlim([xstart,xstop]); \nplt.ylim(\n  (-100*3*signal_stddev, 100*3*signal_stddev)); \nplotout = plt.title(\"Gaussian process predictions\")\n\n\n1\n\nNOT fitting kernel hyperparameters\n\n\n\n\n\n\n\n\n\n\nFigure 104.13: issues when we scale the y values by 100\n\n\n\n\n\nIn this sample the +/-2 \\sigma confidence interval is now 100 times smaller than in the nice example, and the mean prediction is also 100 times smaller than in the nice example. So while it is still there it seems to have vanished.\n\n# observed x values are 100 times what they were in the nice example\ngpfit = GaussianProcessRegressor(\n  kernel=kern, optimizer=None) # NOT fitting kernel hyperparameters\ngpfit.fit(100*xobs.reshape(-1,1),yobs.reshape(-1,1))\nxall=np.sort(np.concatenate((xcurve,xobs)))\nmean_pred, stddev_pred = gpfit.predict(\n  100*xall.reshape(-1,1), \n  return_std=True)\nplt.scatter(100*xobs,\n  yobs,color=\"black\",marker=\"x\", \n  label=\"training data\")\nplt.plot(\n  100*xall,mean_pred,\n  color=\"green\", label=\"mean predictions\")\nplt.plot(\n  100*xcurve,ycurve,\n  linestyle=\"dashed\",\n  color=\"blue\", \n  label=\"original function\")\nplt.fill_between(\n  100*xall,mean_pred-2*stddev_pred,\n  mean_pred+2*stddev_pred,color=\"green\",\n  alpha=0.3,label=r\"+/-2 std dev interval\")\nplt.legend(); \nplt.xlim([100*xstart,100*xstop]); \nplt.ylim((-3*signal_stddev,3*signal_stddev)); \nplotout = plt.title(\"Gaussian process predictions\")\n\n\n\n\n\n\n\nFigure 104.14: Issue when we scale the x values by 100\n\n\n\n\n\nin this example the points are now so far apart that at most point on the graph we are quickly jumping to the prior and getting the maximum uncertainty.\n\n\n\nListing 104.2\n\n\nprint(np.exp(-0.5*2.0**2))\n\n0.13533528323661267\n\n\n\n\n\nWhat can we do to handle different x and f(x) scales?\n\nNormalization in y can help; in x, can still be hiccups\n\nA common option in practice and in software is to fit the hyperparameters of a more general squared exponential kernel from data\n\nMore general form of the squared exponential:\n\n\n\nk(x, x') = \\underbrace{\\sigma^2}_{\\color{red}\\text{signal variance}} \\exp\\left(-\\frac{1}{2}\\sum_{d=1}^D \\frac{(x_d - x'_d)^2}{\\underbrace{l_d^2}_{\\color{red}\\text{length scale}}}\\right), \\sigma^2 = 1\n\\tag{104.1}\n\nParameters (here, f) parametrize the distribution of the data. If we knew them, we could generate the data.\n\nGPs: nonparametric model: infinite # of latent params\n\nHyperparameters parametrize the distribution of the parameters. If known, we could generate the parameters.\nAlgorithm:\n\nFit a value for the hyperparameters using the data.\nGiven those values, now compute and report the mean and uncertainty intervals\n\n\n\n104.11.1 Demo 3 – Learning the signal and the length scale and\n\nsignal_stddev = 2.0; \nkern = signal_stddev**2*RBF(\n  length_scale=0.3,\n  length_scale_bounds=\"fixed\") # set the kernel\ngp = GaussianProcessRegressor(kernel=kern)\nxstart=-0.5; \nxstop=3.5; \nNobs = 10; \nxobs = rng.uniform(xstart,xstop,size=Nobs)\nnumx=200; \nx=np.linspace(start=xstart,stop=xstop,num=numx); \ntwosd=2*signal_stddev*np.ones(numx) # coloring 2 std dev range\nplt.fill_between(x,twosd,-twosd,color=\"gray\",alpha=0.3) # coloring 2 std dev range\nxcurve=np.linspace(start=xstart,stop=xstop,num=numx); \nxall = np.concatenate((xcurve,xobs)).reshape(-1,1)\nyall = gp.sample_y(xall,random_state=rng,n_samples=1); \nycurve=yall[0:numx]; \nyobs=yall[numx:numx+Nobs]\nplt.plot(xcurve,ycurve,linestyle=\"dashed\",color=\"blue\"); \nplt.scatter(xobs,yobs,color=\"black\",marker=\"x\")\nplt.xlim([xstart,xstop]); \nplt.ylim((-3*signal_stddev,3*signal_stddev)); \npltaxes = plt.gca() # make the plot\noutput = plt.title(\n  \"A draw from a Gaussian process with \" + str(Nobs) + \n  \" simulated data points\") # make the plot\n\n\n\n\n\n\n\nFigure 104.15: A draw from a Gaussian process with 10 simulated data points\n\n\n\n\n\nwe have drawn 10 points and the ground truth\nbut what goes to the algorithm is just the data points as follows:\n\n# just the training data\nplt.scatter(xobs,yobs,color=\"black\",marker=\"x\")\nplt.xlim([xstart,xstop]); plt.ylim((-3*signal_stddev,3*signal_stddev)); pltaxes = plt.gca() # make the plot\noutput = plt.title(str(Nobs) + \" simulated data points\") # make the plot\n\n\n\n\n\n\n\nFigure 104.16: the data\n\n\n\n\n\n\nsignal_stddev_init = 1.0; \nkern_fit = signal_stddev_init**2*RBF(\n  length_scale=1.0,length_scale_bounds=(0.01, 100))\ngpfit = GaussianProcessRegressor(\n1  kernel=kern_fit,n_restarts_optimizer=10)\ngpfit.fit(xobs.reshape(-1,1),yobs.reshape(-1,1));\nprint(\"Original kernel: \" + str(kern)); \nprint(\"Fit kernel: \" + str(gpfit.kernel_))\nmean_pred, stddev_pred = gpfit.predict(\n  xcurve.reshape(-1,1), return_std=True)\nplt.scatter(\n  xobs,yobs,color=\"black\",\n  marker=\"x\", label=\"training data\")\nplt.plot(\n  xcurve,ycurve,linestyle=\"dashed\",\n  color=\"blue\", label=\"original function\")\nplt.plot(\n  xcurve,mean_pred,color=\"green\", \n  label=\"mean predictions\")\nplt.fill_between(\n  xcurve,mean_pred-2*stddev_pred,\n  mean_pred+2*stddev_pred,\n  color=\"green\",alpha=0.3,\n  label=r\"+/-2 std dev interval\")\nplt.legend(); \nplt.xlim([xstart,xstop]); \nplt.ylim((-3*signal_stddev,3*signal_stddev)); \nplotout = plt.title(\"Gaussian process predictions\")\n\n\n1\n\nnow we ARE fitting the hyperparameters\n\n\n\n\nOriginal kernel: 2**2 * RBF(length_scale=0.3)\nFit kernel: 1.53**2 * RBF(length_scale=0.304)\n\n\n\n\n\n\n\n\nFigure 104.17: GP scaled by the algorithm",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#what-next",
    "href": "C6-L01.html#what-next",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.12 What next",
    "text": "104.12 What next\n\nadding observation noise variance\nextrapolation\nhigh-dimensional inputs\n\nAlways ask: What uncertainty are we quantifying? 1",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#observation-noise",
    "href": "C6-L01.html#observation-noise",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.13 Observation noise",
    "text": "104.13 Observation noise\n\nSo far we’ve been assuming that we observed f(x) directly\nBut often the actual observation y has additional noise:\n\n\nf \\sim \\mathcal{GP}(m, k) \\qquad y^{(n)} = f(x) + \\epsilon^{(n)}, \\qquad \\epsilon^{(n)} \\stackrel{iid}{\\sim} \\mathcal{N}(0, \\tau^2)\n\n\nwe observe \\{(x^{(n)}, y^{(n)})\\}_{n=1}^N and want to learn the latent f\n\nThe y are multivariate-Gaussian distributed with mean and covariance summed.\nThe mean of y^{(n)} is given by the function m(x^{(n)}). and \\mathbb{C}ov[y^{(n)},y^{(n')}]=k(x^{(n)},x^{(n')})+\\tau^2\\mathbb{1}_{n=n'}\nThe covariance is given by the kernel function:\n\n\n\ny \\sim \\mathcal{N}(f(x), \\tau^2 I)\n\nBefore: \n\\begin{bmatrix}\nf(X) \\\\\nf(X')\n\\end{bmatrix}\n\\sim \\mathcal{N}\n  \\left(    \n    \\begin{bmatrix}\n      0_N \\\\\n      0_M\n      \\end{bmatrix}\n    \\begin{bmatrix}\n    K(X, X) & K(X, X') \\\\\n    K(X', X) & K(X', X')\n    \\end{bmatrix}    \n  \\right)\n Now :\n\n\\begin{bmatrix}\ny^{(1:N)} \\\\\nf(X')\n\\end{bmatrix}\n\\sim \\mathcal{N}\n  \\left(    \n    \\begin{bmatrix}\n      0_N \\\\\n      0_M\n      \\end{bmatrix}\n    \\begin{bmatrix}\n    K(X, X)+ \\tau \\mathbb{I} & K(X, X') \\\\\n    K(X', X) & K(X', X')\n    \\end{bmatrix}    \n  \\right)",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#sec-what-uncertainty",
    "href": "C6-L01.html#sec-what-uncertainty",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.14 What uncertainty are we quantifying?",
    "text": "104.14 What uncertainty are we quantifying?\n\nIt’s worth being aware that data science (ML/stats/AI) often overloads common colloquial terms with terms of art\n\nE.g. “significance”, “bias”, “generalization”\nEvery precise use of “uncertainty” has this issue\n\nE.g. frequentist sampling, Bayesian, etc.\n\nWe should always make sure we can distinguish what is, and what is not, covered by the term of art\n\nA standard setup (our setup so far):\n\nWe model the data as generated according to a GP with squared exponential kernel and observation noise\nWe fit the hyperparameters (the signal variance, the length scale(s), and the noise variance) to single values\nThe reported uncertainties are what result when the GP model and fitted hyperparameters are exactly correct\n\n\nAre there other uncertainties that aren’t being quantified here?",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#sec-other-sources-of-uncertainty",
    "href": "C6-L01.html#sec-other-sources-of-uncertainty",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.15 Some other sources of uncertainty",
    "text": "104.15 Some other sources of uncertainty\n\nThere may be multiple sets of substantively different hyperparameter values that are both plausible and consistent with the observed data\nWhat can we do? First: unit test, plot, sense check!\n\nAsk what is possible to learn with the data available\nMultiple random restarts: plot the results\nBayesian model of the hyperparameters\n\nA GP with your mean & kernel may be meaningfully misspecified for the data\n\nBox: “All models are wrong, but some are useful”\nWhat can we do?\n\nFirst: unit test, plot, sense check!\nCan change the mean and/or kernel\n\nE.g. local/heteroskedastic models, periodic kernels, linear mean function, many many more.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#sec-extrapolation",
    "href": "C6-L01.html#sec-extrapolation",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.16 Extrapolation",
    "text": "104.16 Extrapolation\n\nExtrapolation: Estimation/prediction beyond the observed data\nCompare to interpolation: estimation/prediction within the observed data\nWhen using GPs with a squared exponential kernel:\nData points that are more than a handful of length scales from other data points will revert to prior behavior\nNote: extrapolation isn’t a special issue unique to GPs. It’s a fundamentally hard problem for all data analysis methods\nTo extrapolate, you need to make assumptions\nWhen you have domain knowledge of a system, you might be able to use it to extrapolate\nWhen you’re letting a machine learning method use its defaults, it’s making assumptions. Do you know what those assumptions are?",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#more-than-one-input",
    "href": "C6-L01.html#more-than-one-input",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.17 More than one input",
    "text": "104.17 More than one input\n\n\n\n\n\n\n\nFigure 104.18: histogram of squared inter-point distances\n\n\n\nOur illustrations have almost all been for one input so far\nBut in real life, it’s typical to have more than one input\nWhat could go wrong? Previous lessons apply, but also:\n\nPossibly different length scales. Check defaults.\nRegression in high dimensions is a fundamentally hard problem (without additional assumptions)\n\nAll points are “far away” in high dimensions. Illustration:\nUniformly randomly sample 10,000 points on [0,1]^D\nMake a histogram of squared inter-point distances\nRecall: points “far” from data default to the prior mean and variance.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#sec-high-points",
    "href": "C6-L01.html#sec-high-points",
    "title": "104  Gaussian Processes for Regression",
    "section": "104.18 Some high points of what got cut for time",
    "text": "104.18 Some high points of what got cut for time\n\nWe ran out of time! Here are some high-level summary points beyond what we discussed together:\n\nThere are other challenges with many inputs, both conceptual and practical\nRunning time for GP regression can be an issue with a large number of training data points\n\nIn particular, the matrix inverse can be expensive\nThere are incredibly many papers about fast approximations to the exact Gaussian process\n\nEach approximation has pros and cons\n\n\n\nBayesian optimization inherits many of the pros and cons of Gaussian processes for regression\n\nExercise: once you learn about Bayesian optimization, think about how the pros and cons we discussed together might translate there\n\n\n\n\n\n\n\n\nRasmussen, Carl Edward, and Christopher K. I. Williams. 2006. Gaussian Processes for Machine Learning. Adaptive Computation and Machine Learning Series. MIT Press. https://gaussianprocess.org/gpml/.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L01.html#footnotes",
    "href": "C6-L01.html#footnotes",
    "title": "104  Gaussian Processes for Regression",
    "section": "",
    "text": "This is key as in real life there are many sources of uncertainty and in our models we only get to quantify one!↩︎",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Gaussian Processes for Regression</span>"
    ]
  },
  {
    "objectID": "C6-L02.html",
    "href": "C6-L02.html",
    "title": "105  Dirichlet Process",
    "section": "",
    "text": "105.1 Nonparametric Bayes",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Dirichlet Process</span>"
    ]
  },
  {
    "objectID": "C6-L02.html#nonparametric-bayes",
    "href": "C6-L02.html#nonparametric-bayes",
    "title": "105  Dirichlet Process",
    "section": "",
    "text": "Bayesian statistics that is not parametric\nBayesian: \n\\mathbb{P}r(parameters \\mid data) \\propto \\mathbb{P}r(data \\mid parameters) \\mathbb{P}r(parameters)\n\nNot parametric (i.e. not finite parameter, unbounded/growing/infinite number of parameters)\nexamples:\n\nWikipedia articles\nSpecies\ndensity estimation [Escobar, West 1995; Ghosal et al 1999]\nsurvival analysis curves\nFitness exercises [Fox et al 2014]\nGenetics [Ewens 1972; Hartl, Clark 2003]\nNewborn babies [Saria et al 2010]\nSocial networks [Llyod et all 2012; Miller et al 2010]\nImages [Sudderth, Jordan 2009]",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Dirichlet Process</span>"
    ]
  },
  {
    "objectID": "C6-L02.html#sec-NPB-nonparametric-bayes",
    "href": "C6-L02.html#sec-NPB-nonparametric-bayes",
    "title": "105  Dirichlet Process",
    "section": "105.2 Nonparametric Bayes",
    "text": "105.2 Nonparametric Bayes\n\nA theoretical motivation: De Finetti’s Theorem\nA data sequence is infinitely exchangeable if the distribution of any N data points doesn’t change when permuted:\n\n\np(X_1, \\ldots , X_N ) = p(X_{\\sigma(1)} , \\ldots , X_{\\sigma(N)} )\n\n\nDe Finetti’s Theorem (roughly): A sequence is infinitely exchangeable \\iff, for all N and some distribution P \np(X_1, \\ldots , X_N ) = \\int_\\theta \\prod_{}^N p(X_n\\mid\\theta)P(d\\theta)\n\nMotivates:\n\nParameters and likelihoods\nPriors\n“Nonparametric Bayesian” priors\n\nNote: that De Finetti’s proved his theorem in 1931 but for finite exchangeability.\nIn (Hewitt and Savage 1955) Savage and Hewitt extended the result from finite to infinite exchangeability in 1955.\nThere were also a few other related results by Diaconis and Freedman in the 1970s.\nIn (Aldous 1983) Aldous proved a more general for arrays 1983.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Dirichlet Process</span>"
    ]
  },
  {
    "objectID": "C6-L02.html#sec-NPM-generative-model",
    "href": "C6-L02.html#sec-NPM-generative-model",
    "title": "105  Dirichlet Process",
    "section": "105.3 Generative Model",
    "text": "105.3 Generative Model\n\n  \\mathbb{P}r(parameters \\mid data) \\propto \\mathbb{P}r(data \\mid parameters) \\mathbb{P}r(parameters)\n\n\nFinite Gaussian mixture model (K=2 clusters) \nz_n \\stackrel{iid}{\\sim} \\text{Categorical}(\\rho_1, \\rho_2)\n\n\n\nx_n \\stackrel{indep}{\\sim} \\mathcal{N}(\\mu_0, \\Sigma)\n\n\nDon’t know \\mu_1 , \\mu_2 \n\\mu_k \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu_0, \\sigma_0^2) \\quad k=1,2\n\nDon’t know \\rho_1 , \\rho_2 \n\\rho_1 \\sim \\text{Beta}(\\alpha_0, \\beta_0)\n\n\n\n\\rho_2 = 1 - \\rho_1\n\nInference goal: assignments of data points to clusters, cluster parameters",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Dirichlet Process</span>"
    ]
  },
  {
    "objectID": "C6-L02.html#beta-distribution-review",
    "href": "C6-L02.html#beta-distribution-review",
    "title": "105  Dirichlet Process",
    "section": "105.4 Beta distribution review",
    "text": "105.4 Beta distribution review\n\n\n\\text{Beta}(\\rho \\mid \\alpha_1, \\alpha_2) = \\frac{\\Gamma(\\alpha_1 + \\alpha_2)}{\\Gamma(\\alpha_1)\\Gamma(\\alpha_2)} \\rho^{\\alpha_1 - 1} (1 - \\rho)^{\\alpha_2 - 1}\n\n\n\\alpha_1, \\alpha_2 &gt; 0\n\\rho \\in [0,1]\nGamma function \\Gamma\ninteger m: \\Gamma(m+1) = m!\nfor x &gt; 0: \\Gamma(x+1) = x\\Gamma(x)\nWhat happens?\n\na = a_1 = a_2 \\to 0\na = a_1 = a_2 \\to \\infty\na_1 &gt; a_2\n\nBeta is conjugate to Cat\n\n\n\\rho \\sim \\text{Beta}(\\alpha_1, \\alpha_2),\\qquad z \\sim \\text{Cat}(\\rho_1, \\rho_2)\n\n\np(\\rho_1 , z) \\propto \\rho_1^{\\mathbb{1}_{z=1}} (1 - \\rho_1 )^{\\mathbb{1}_{z=2}} \\rho_1^{a_1 -1} (1 - \\rho_1 )^{a_2 -1}\n\n\np(\\rho_1 , z) \\propto \\rho_1^{\\mathbb{1}_{z=1-1}} (1 - \\rho_1 )^{\\mathbb{1}_{z=2}-1} \\propto \\text{Beta}(\\rho_1 \\mid a_1 + \\mathbb{1}_{z=1}, a_2 + \\mathbb{1}_{z=2})\n\n\n\n\n\n\n\nAldous, David. 1983. “Random Walks on Finite Groups and Rapidly Mixing Markov Chains.” In Séminaire de Probabilités XVII 1981/82: Proceedings, 243–97. Springer.\n\n\nHewitt, Edwin, and Leonard J Savage. 1955. “Symmetric Measures on Cartesian Products.” Transactions of the American Mathematical Society 80 (2): 470–501.",
    "crumbs": [
      "Bayesian Non-Parametric Models",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Dirichlet Process</span>"
    ]
  },
  {
    "objectID": "A01.html",
    "href": "A01.html",
    "title": "Appendix A — Appendix: Notation",
    "section": "",
    "text": "A.1 The argmax function\nParameters describe the population and are usually designated with Greek letters and the preferred letter is \\theta\n\\theta\n\\tag{A.1}\nother common parameters are: \n\\mu, \\sigma^2, \\alpha, \\beta\n\\tag{A.2}\nwhere \\mu is the mean, \\sigma^2 is the variance, \\alpha is the intercept, and \\beta is the slope in a linear regression context.\nStatistics are population estimates of parameters and are usually designated with Latin letters, such as \\hat{\\theta}.\n\\hat{p}\n\\tag{A.3}\nthe Certain event\n\\Omega\nprobability of RV X taking value x\n\\mathbb{P}r(X=x)\nodds\n\\mathcal{O}(X)\nrandom variables \nX\nX is distributed as\nX\n\\sim N(\\mu, \\sigma^2)\nX is proportional to\nX\\propto N(\\mu, \\sigma^2)\nProbability of A and B\n\\mathbb{P}r(X \\cap Y)\nConditional probability\n\\mathbb{P}r(X \\mid Y)\nJoint probability\n\\mathbb{P}r(X,Y)\nY_i \\stackrel{iid}\\sim N(\\mu, \\sigma^2)\nApproximately distributed as (say using the CLT)\nY_i \\stackrel{.}\\sim N(\\mu, \\sigma^2)\n\\mathbb{E}[X_i]\nThe expected value of an RV X set to 0 (A.K.A. a fair bet)\n\\mathbb{E}[X_i]  \\stackrel{set} = 0\nThe variance of an RV\n\\mathbb{V}ar[X_i]\nlogical implication\n\\implies\nif and only if\n\\iff\ntherefore\n\\therefore\nindependence\nA \\perp \\!\\!\\! \\perp B \\iff \\mathbb{P}r(A \\mid B) = \\mathbb{P}r(A)\nIndicator function \n\\mathbb{I}_{\\{A\\}} = \\begin{cases}\n1 & \\text{if } A \\text{ is true} \\\\ 0 & \\text{otherwise} \\end{cases}\nDirichlet function\nThis is a continuous version of the indicator function, defined as a limit.\n\\delta(x) = \\lim_{\\varepsilon \\to 0} \\frac{1}{2\\varepsilon} \\mathbb{I}_{\\{|x| &lt; \\varepsilon\\}}\nThe Dirichlet function is used to represent a point mass at a point, often used as a component for zero inflated mixtures.\nThe following are from course 4\nWhen we want to maximize a function f(x), there are two things we may be interested in:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendix: Notation</span>"
    ]
  },
  {
    "objectID": "A01.html#sec-argmax-function",
    "href": "A01.html#sec-argmax-function",
    "title": "Appendix A — Appendix: Notation",
    "section": "",
    "text": "The value f(x) achieves when it is maximized, which we denote \\max_x f(x).\nThe x-value that results in maximizing f(x), which we denote \\hat x = \\arg \\max_x f(x). Thus \\max_x f(x) = f(\\hat x).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendix: Notation</span>"
    ]
  },
  {
    "objectID": "A01.html#sec-indicator-functions",
    "href": "A01.html#sec-indicator-functions",
    "title": "Appendix A — Appendix: Notation",
    "section": "A.2 Indicator Functions",
    "text": "A.2 Indicator Functions\nThe concept of an indicator function is a really useful one. This is a function that takes the value one if its argument is true, and the value zero if its argument is false. Sometimes these functions are called Heaviside functions or unit step functions. I write an indicator function as \\mathbb{I}_{A}(x), although sometimes they are written \\mathbb{1}_{A}(x). If the context is obvious, we can also simply write I{A}.\nExample:\n\n    \\mathbb{I}_{x&gt;3}(x)=\n    \\begin{cases}\n      0, & \\text{if}\\ x \\le 3 \\\\\n      1, & \\text{otherwise}\n    \\end{cases}\n\nNote: Indicator functions are easy to implement in code using a lambda function. They can be combined using a dictionary.\nBecause 0 · 1 = 0, the product of indicator functions can be combined into a single indicator function with a modified condition.\n\nA.2.1 Products of Indicator Functions:\n\n    \\mathbb{I}{x&lt;5} \\cdot \\mathbb{I}{x≥0} = \\mathbb{I}{0≤x&lt;5}\n\n\n    \\prod_{i=1}^N \\mathbb{I}_{(x_i&lt;2)} = \\mathbb{I}_{(x_i&lt;2) \\forall i} = \\mathbb{I}_{\\max_i x_i&lt;2}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendix: Notation</span>"
    ]
  },
  {
    "objectID": "A02.html",
    "href": "A02.html",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "",
    "text": "B.1 Discrete Uniform",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-discrete-uniform",
    "href": "A02.html#sec-discrete-uniform",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "",
    "text": "B.1.1 Stories\n\n\n\n\n\n\nNoteDiscrete Uniform Finite set Parametrization\n\n\n\nLet C be a finite, nonempty set of numbers and X random variable associated with the event of choosing one of these numbers uniformly at random, that is all values being equally likely X(x=c)\nThen X is said to have the Discrete Uniform distribution with parameter C.\nWe denote this by X ∼ DUnif(C).\n\n\n\n\n\n\n\n\nNoteDiscrete Uniform with Lower and Upper bound Parametrization\n\n\n\nWhen the set C above is C=\\{c \\in \\mathbb{Z} \\mid a \\le c \\le b\\ \\}.\nThen X is said to have the Discrete Uniform distribution with lower bound parameter a and upper bound parameter b.\nWe denote this by X ∼ DUnif(a,b).\n\n\n\n\n\n\n\n\nNoteUrn Model\n\n\n\nSuppose we have an urn with n balls labeled with the numbers a 1, \\dots, a_n . One drawing from the urn produces a discrete uniform random variable on the set \\{a_1, \\dots, a_n \\}.\n\n\n\n\nB.1.2 Moments\n\n\\begin{aligned}\n    \\phi_X(t)&={\\displaystyle {\\frac {e^{at}-e^{(b+1)t}}{n(1-e^{t})}}}  && \\text{(MGF)}\\\\  \n    \\mathbb{E}[X] &= \\frac{a + b}{2} && \\text{(Expectation)} \\\\\n    \\mathbb{V}ar[X] &= \\frac{(b - a + 1)^2 - 1}{12} && \\text{(Variance)}\n\\end{aligned}\n\\tag{B.1}\n\n\nB.1.3 Probability mass function (PMF)\n\nf(x \\mid a, b) = \\frac{1}{b - a + 1}\n\n\n\nB.1.4 Cumulative distribution function (CDF)\n\nF(x \\mid a, b) = \\frac{\\lfloor x \\rfloor - a - 1}{b - a + 1} \\\\\n\\text{where} \\lfloor x \\rfloor \\text{ is the floor function (rounds down reals to nearest smaller integer)}\n\n\n\nB.1.5 Prior\nSince a number of families have the uniform as a special case we can use them as priors when we want a uniform prior:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-bernoulli-distribution",
    "href": "A02.html#sec-bernoulli-distribution",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.2 Bernoulli Distribution",
    "text": "B.2 Bernoulli Distribution\n. \n\nB.2.1 Stories\n\n\n\n\n\n\nNote\n\n\n\nThe Bernoulli distribution arises when modeling the outcome of a binary event called a Bernoulli trial.\nLet X be the indicator variable corresponding to the success of getting “heads” in a “coin toss”, with a coin that has probability of success p for getting “heads”.\nThen X has a Bernoulli Distribution with parameter p\nWe denote this as X \\sim Bern(p)\n\n\n\n\nB.2.2 Parameters\nBecause of this story, the parameter p is often called the success probability of the Bern(p) distribution.\n\n\nB.2.3 Examples\n\n\n\n\n\n\nNote\n\n\n\n\nfair coin toss\nunfair coin toss\nad click\nweb site conversion\ndeath or survival of a patient in a medical trial\nindicator random variable\n\n\n\n\n\nB.2.4 Checklist\n\n\n\n\n\n\nNote\n\n\n\n\nDiscrete data\nA single trial\nOnly two trial outcomes: success and failure (These do not need to literally represent successes and failures, but this shorthand is typically used.)\n\n\n\n\n\\begin{aligned}\nX &\\sim Bernoulli(p)\\\\\n  & \\sim Bern(p)\\\\\n  & \\sim B(p)  \n\\end{aligned}\n\\tag{B.2}\n\n\nB.2.5 Moments\n\nM_X(t)=q+pe^{t} \\qquad \\text{(MGF)}\n\\tag{B.3}\n\n\\mathbb{E}[X]= p \\qquad \\text{(Expectation)}\n\\tag{B.4}\n\n\\mathbb{V}ar[x]= \\mathbb{P}r(1-p) \\qquad \\text{(Variance)}\n\\tag{B.5}\n\n\nB.2.6 PMF\nWhere parameter p is the probability of getting heads.\nThe probability for the two events is:\n\n\\mathbb{P}r(X=1) = p \\qquad \\mathbb{P}r(X=0)=1-p\n\n\n    \\begin{cases}\n        1-p     & \\text{if } k=0 \\\\\n        p       & \\text{if } k=1\n    \\end{cases}\n  \\qquad \\text{(PMF)}\n\\tag{B.6}\n\n\nB.2.7 CDF\n\n    \\begin{cases}\n        0&{\\text{if }}k&lt;0  \\\\\n        1-p&{\\text{if }}0\\leq k&lt;1 \\\\\n        1&{\\text{if }}k\\geq 1\n    \\end{cases}\n    \\qquad \\text{(CDF)}\n\\tag{B.7}\n\n\nB.2.8 Likelihood\n\nL(\\theta) = \\prod p^x(1-p)^{1-x} \\mathbb{I}_{[0,1]}(x)  \\qquad \\text{(Likelihood)}\n\\tag{B.8}\n\n\\mathcal{L}(\\theta) =log(p) \\sum x + log(1-p)\\sum (1-x)  \\qquad \\text{(Log Likelihood)}\n\\tag{B.9}\n\n\nB.2.9 Entropy and Information\n\n\\mathbb{H}(x)= -q \\ln(q)- p \\ln(p) \\qquad \\text{(Entropy)}\n\\tag{B.10}\n\n\\mathcal{I}[X]\\frac{1}{\\mathbb{P}r(1-p)} \\qquad \\text{(Fisher Information)}\n\\tag{B.11}\n\nBeta(x) \\qquad \\text{(Conjugate Prior)}\n\\tag{B.12}\n\n\nB.2.10 Usage\n\n\n\nTable B.1: Usage of Bernoulli\n\n\n\n\n\nPackage\nSyntax\n\n\n\n\nNumPy\nrg.choice([0, 1], p=[1-theta, theta])\n\n\nSciPy\nscipy.stats.bernoulli(theta)\n\n\nStan\nbernoulli(theta)\n\n\n\n\n\n\n\n\nB.2.11 Plots\n\nimport numpy as np\nfrom scipy.stats import bernoulli\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1)\np = 0.3\nmean, var, skew, kurt = bernoulli.stats(p, moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\nmean=0.30, var=0.21, skew=0.87, kurt=-1.24\n\nx = np.arange(bernoulli.ppf(0.01, p),\n              bernoulli.ppf(0.99, p))\nax.plot(x, bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')\nax.vlines(x, 0, bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)\n\nrv = bernoulli(p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n## Generate random numbers\nr = bernoulli.rvs(p, size=10)\nr\n\narray([0, 0, 0, 1, 0, 0, 1, 0, 0, 0])\n\n\n\n\n\n\nA Swiss stamp issueed in 1994 depicting Mathematician Jakob Bernouilli and the formula and diagram of the law of large numbers\n\n\n\n\n\n\n\nTipBiographical note on Jacob Bernoulli\n\n\n\n\nIt seems that to make a correct conjecture about any event whatever, it is necessary to calculate exactly the number of possible cases and then to determine how much more likely it is that one case will occur than another. (Bernoulli 1713)\n\nThe Bernoulli distribution as well as The Binomial distribution are due to Jacob Bernoulli (1655-1705) who was a prominent mathematician in the Bernoulli family. He discovered the fundamental mathematical constant e. With his brother Johann, he was among the first to develop Leibniz’s calculus, introducing the word integral and applying it to polar coordinates and the study of curves such as the catenary, the logarithmic spiral and the cycloid\nHis most important contribution was in the field of probability, where he derived the first version of the law of large numbers (LLN). The LLN is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value and will tend to become closer to the expected value as more trials are performed. A special form of the LLN (for a binary random variable) was first proved by Jacob Bernoulli. It took him over 20 years to develop sufficiently rigorous mathematical proof.\n\nFor a more extensive biography visit the following link\n\n\nThe Bernoulli distribution is built on a trial of a coin toss (possibly biased).\n\nWe use the Bernoulli distribution to model a random variable for the probability of such a coin toss trial.\nWe use the Binomial distribution to model a random variable for the probability of getting k heads in N independent trails.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-binomial-distribution",
    "href": "A02.html#sec-binomial-distribution",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.3 Binomial distribution",
    "text": "B.3 Binomial distribution\n\nB.3.1 Stories\n\n\n\n\n\n\nNote\n\n\n\n\n\\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N\n\\tag{B.13}\nThe Binomial distribution arises when we conduct multiple independent Bernoulli trials and wish to model X the number of successes in Y_i\\mid \\theta identically distributed Bernoulli trials with the same probability of success \\theta. If n independent Bernoulli trials are performed, each with the same success probability p. The distribution of X is called the Binomial distribution with parameters n and p. We write X \\sim \\text{Bin}(n, p) to mean that X has the Binomial distribution with parameters n and p, where n is a positive integer and 0 &lt; p &lt; 1.\n\n\n\n\nB.3.2 Parameters\n\n\\theta - the probability of success in the Bernoulli trials\nN - the total number of trials being conducted\n\n\n\nB.3.3 Conditions\n\n\n\n\n\n\nTip\n\n\n\n\nDiscrete data\nTwo possible outcomes for each trial\nEach trial is independent and\nThe probability of success/failure is the same in each trial\nThe outcome is the aggregate number of successes\n\n\n\n\n\nB.3.4 Examples\n\nto model the aggregate outcome of clinical drug trials,\nto estimate the proportion of the population voting for each political party using exit poll data (where there are only two political parties).\n\n\nX \\sim Bin[n,p]\n\\tag{B.14}\n\nf(X=x \\mid \\theta) = {n \\choose x} \\theta^x(1-\\theta)^{n-x}\n\\tag{B.15}\n\nL(\\theta)=\\prod_{i=1}^{n} {n\\choose x_i}  \\theta ^ {x_i} (1− \\theta) ^ {(n−x_i)}\n\\tag{B.16}\n\n\\begin{aligned}\n\\ell( \\theta) &= \\log \\mathcal{L}( \\theta) \\\\\n              &= \\sum_{i=1}^n \\left[\\log {n\\choose x_i} + x_i \\log  \\theta + (n-x_i)\\log (1- \\theta) \\right]\n\\end{aligned}\n\\tag{B.17}\n\n\\mathbb{E}[X]= N \\times  \\theta\n\\tag{B.18}\n\n\\mathbb{V}ar[X]=N \\cdot \\theta \\cdot (1-\\theta)\n\\tag{B.19}\n\n\\mathbb{H}(X) = \\frac{1}{2}\\log_2 \\left (2\\pi n \\theta(1 - \\theta)\\right) + O(\\frac{1}{n})\n\\tag{B.20}\n\n\\mathcal{I}(\\theta)=\\frac{n}{ \\theta \\cdot (1- \\theta)}\n\\tag{B.21}\n\n\nB.3.5 Usage\n\n\n\nTable B.2: Usage of Binomial\n\n\n\n\n\nPackage\nSyntax\n\n\n\n\nNumPy\nrg.binomial(N, theta)\n\n\nSciPy\nscipy.stats.binom(N, theta)\n\n\nStan\nbinomial(N, theta)\n\n\n\n\n\n\n\n\nB.3.6 Relationships\n\n\n\nbinomial distribution relations\n\n\n The Binomial Distribution is related to\n\nThe Binomial is a special case of the Multinomial distribution with K =2 (two categories).\nthe Poisson distribution distribution. If X \\sim Binomial(n, p) rv and Y \\sim Poisson(np) distribution then \\mathbb{P}r(X = n) ≈ \\mathbb{P}r(Y = n) for large n and small np.\nThe Bernoulli distribution is a special case of the the Binomial distribution \n\\begin{aligned}\nX & \\sim \\mathrm{Binomial}(n=1, p) \\\\\n\\implies X &\\sim \\mathrm{Bernoulli}(p)\n\\end{aligned}\n\nthe Normal distribution If X \\sim \\mathrm{Binomial}(n, p) RV and Y \\sim \\mathcal{N}(\\mu=np,\\sigma=n\\mathbb{P}r(1-p)) then for integers j and k, \\mathbb{P}r(j ≤ X ≤ k) ≈ \\mathbb{P}r(j – 1/2 ≤ Y ≤ k + 1/2). The approximation is better when p ≈ 0.5 and when n is large. For more information, see normal approximation to the Binomial\nThe Binomial is a limit of the Hypergeometric. The difference between a binomial distribution and a hypergeometric distribution is the difference between sampling with replacement and sampling without replacement. As the population size increases relative to the sample size, the difference becomes negligible. So If X \\sim \\mathrm{Binomial}(n, p) RV and Y \\sim \\mathrm{HyperGeometric}(N,a,b) then\n\n\\lim_{n\\to \\infty} X = Y\n\n\n\nB.3.7 Plots\n\nimport numpy as np\nfrom scipy.stats import binom\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\nn, p = 5, 0.4\nmean, var, skew, kurt = binom.stats(n, p, moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\nmean=2.00, var=1.20, skew=0.18, kurt=-0.37\n\nx = np.arange(binom.ppf(0.01, n, p),\n              binom.ppf(0.99, n, p))\nax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\nax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)\nrv = binom(n, p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n## generate random numbers\nr = binom.rvs(n, p, size=10)\nr\n\narray([1, 1, 2, 2, 4, 1, 3, 2, 1, 2])\n\n\nfrom __future__ import print_function\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\nimport numpy as np\nimport scipy\nfrom scipy.special import gamma, factorial, comb\nimport plotly.express as px\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\n#pyo.init_notebook_mode()\nINTERACT_FLAG=False\ndef binomial_vector_over_y(theta, n):\n    total_events = n\n    y =  np.linspace(0, total_events , total_events + 1)\n    p_y = [comb(int(total_events), int(yelem)) * theta** yelem * (1 - theta)**(total_events - yelem) for yelem in y]\n\n    fig = px.line(x=y, y=p_y, color_discrete_sequence=[\"steelblue\"], \n                  height=600, width=800, title=\" Binomial distribution for theta = %lf, n = %d\" %(theta, n))\n    fig.data[0].line['width'] = 4\n    fig.layout.xaxis.title.text = \"y\"\n    fig.layout.yaxis.title.text = \"P(y)\"\n    fig.show()\n    \nif(INTERACT_FLAG):    \n    interact(binomial_vector_over_y, theta=0.5, n=15)\nelse:\n    binomial_vector_over_y(theta=0.5, n=10)\n\n\n\n\n\n\n\nVideo B.1: Binomial Distribution",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-hypergeometric-distribution",
    "href": "A02.html#sec-hypergeometric-distribution",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.4 Hypergeometric distribution",
    "text": "B.4 Hypergeometric distribution\n\nB.4.1 story 1 - Urn Model\nThe beta-binomial distribution with parameters \\alpha success rate and \\beta failure and n the number of trials can be motivated by an Pólya urn model.\nImagine a trial in which a ball is drawn without replacement from urn containing \\alpha white balls and \\beta black balls. If this is repeated n times, then the probability of observing x white balls follows a hypergeometric distribution with parameters n, \\alpha and \\beta.\nNote: is we used a\nIf the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.\n\n\n\n\n\n\n\nVideo B.2: The Hypergeometric Distribution\n\n\n\n\nB.4.2 Examples\n\nk white balls from an in Urn without replacement\ncapture-recapture\nAces in a poker hand\n\n\n\nB.4.3 Story\nConsider an urn with w white balls and b black balls. We draw n balls out of the urn at random without replacement, such that all w+b samples are equally likely. Let X be the number of white balls in n the sample. Then X is said to have the Hypergeometric distribution with parameters w, b, and n; we denote this by X \\sim \\mathcal{HG}(w, b, n) or X \\sim \\mathrm{HyperGeom}(w, b, n) or",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-poisson-distribution",
    "href": "A02.html#sec-poisson-distribution",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.5 Poisson distribution",
    "text": "B.5 Poisson distribution\n\nB.5.1 Stories\n\n\n\n\n\n\nNotePoisson Parametrization\n\n\n\nThe Poisson distribution arises when modeling the number of successes of independent and identically distributed (IID) events in a fixed interval of time or space, occurring at a constant rate \\lambda. Let X represent the count of the number of phone calls received at a call center in a given interval, such as an hour, with the parameter \\lambda corresponding to the average rate at which events occur in that interval. Then X is said to have the Poisson distribution with parameter \\lambda, and we denote this as X \\sim \\mathrm{Pois}(\\lambda).\n\nX \\sim \\mathrm{Pois}(\\lambda)\n\\tag{B.22}\n\n\n\n\n\n\n\n\n\nVideo B.3: The Poisson Distribution\n\n\n\n\nB.5.2 Checklist\n\nCount of discrete events\nIndividual events occur at a given rate and independently of other events\nFixed amount of time or space in which the events can occur\n\n\n\nB.5.3 Examples\n\nThe number of emails you receive in an hour. There are a lot of people who could potentially email you at that hour, but it is unlikely that any specific person will actually email you at that hour. Alternatively, imagine subdividing the hour into milliseconds. There are 3.6×106 seconds in an hour, but in any specific millisecond, it is unlikely that you will get an email.\nThe number of chips in a chocolate chip cookie. Imagine subdividing the cookie into small cubes; the probability of getting a chocolate chip in a single cube is small, but the number of cubes is large.\nThe number of earthquakes in a year in some regions of the world. At any given time and location, the probability of an earthquake is small, but there are a large number of possible times and locations for earthquakes to occur over the course of the year.\nCount of component failures per week\nestimating the failure rate of artificial heart valves,\nestimating the prevalence of violent crimes in different districts,\napproximating the binomial which is, itself, being used to explain the prevalence of autism in the UK.\n\n\n\nB.5.4 Moments\n\n\\mathrm{E}(X) = \\lambda\n\n\n\\mathrm{V}ar(X) = \\lambda\n\n\n\nB.5.5 Probability mass function (PMF)\n\nf(x \\mid \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\\tag{B.23}\n\n\nB.5.6 Cumulative distribution function (CDF)\n\nF(x \\mid \\lambda) = \\frac{\\Gamma(\\lfloor x+1\\rfloor,\\lambda)}{\\lfloor x \\rfloor !} \\qquad \\text{CDF}\n\\tag{B.24}\n\n\\text{where }\\Gamma(u,v)=\\int_{v}^{\\infty}t^{u-1}e^{-t} \\mathrm{d}t \\text{ is the upper incomplete gamma function}\n\\tag{B.25}\n\n\\text{and } \\lfloor x \\rfloor \\text{ is the floor function (rounds down reals to nearest smaller integer)}\n\\tag{B.26}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-geometric-distribution",
    "href": "A02.html#sec-geometric-distribution",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.6 Geometric distribution",
    "text": "B.6 Geometric distribution\n\nB.6.1 Stories\n\n\n\n\n\n\nNoteGeometric Distribution Failures before success\n\n\n\nConsider a sequence of independent Bernoulli trials, each with the same success probability p \\in (0, 1), with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by X \\sim Geom(p).\nFor example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).\nTo get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0’s (failures) ending in a single 1 (success). Each 0 has probability q = 1 − p and the final 1 has probability p, so a string of k failures followed by one success has probability q^kp.\n\n\n\n\n\n\n\n\nNoteGeometric distribution Failures and success\n\n\n\nConsider a sequence of independent Bernoulli trials, each with the same success probability p \\in (0, 1), with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by X \\sim Geom(p).\nFor example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).\nTo get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0’s (failures) ending in a single 1 (success). Each 0 has probability q = 1 − p and the final 1 has probability p, so a string of k failures followed by one success has probability q^kp.\n\n\n\n\nB.6.2 Conditions\n\n\n\n\n\n\nTip\n\n\n\n\nDiscrete data\nTwo possible outcomes for each trial\nEach trial is independent and\nThe probability of success/failure is the same in each trial\nThe outcome is the count of failures before the first success\n\n\n\n\n\nB.6.3 Examples\n\nConsider polymerization of an actin filament. At each time step, an actin monomer may add to the end of the filament (“failure”), or an actin monomer may fall off the end (“success”) with (usually very low) probability θ. The length of actin filaments, measured in a number of constitutive monomers, is Geometrically distributed.\n\nThe Geometric distribution arises when we want to know “What is the number of Bernoulli trials required to get the first success?”, i.e., the number of Bernoulli events until a success is observed, such as the probability of getting the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).\n\n\n\n\n\n\n\nVideo B.4: The Geometric Distribution\n\n\n\nX \\sim Geo(p)\n\\tag{B.27}\n\n\nB.6.4 Moments\n\n\\mathbb{M}_X[t] = \\frac{pe^t}{1-(1-p)e^t} \\qquad t&lt;-ln(1-p)\n\\tag{B.28}\n\n\\mathbb{E}[X] = \\frac{1}{p}\n\\tag{B.29}\n\n\\mathbb{V}ar[X]=\\frac{1-p}{p^2}\n\\tag{B.30}\n\n\nB.6.5 PMF\n\n\\mathbb{P}r(X = x \\mid p) = \\mathbb{P}r(1-p)^{x-1} \\qquad \\forall x \\in N;\\quad 0\\le p \\le 1\n\\tag{B.31}\n\n\nB.6.6 CDF\n\n1-(1-p)^{\\lfloor x\\rfloor } \\qquad x&lt;1\n\\tag{B.32}\n\n\nB.6.7 Memoryless property\n\nThe geometric distribution is based on geometric series.\nThe geometric distribution has the memoryless property:\n\nP (X &gt; s \\mid X &gt;  t) = P (X &gt; s − t)\n\nOne can say that the distribution “forgets” what has occurred, so that The probability of getting an additional s − t failures, having already observed t failures, is the same as the probability of observing s − t failures at the start of the sequence. In other words, the probability of getting a run of failures depends only on the length of the run, not on its position.\nY=X-1 is the \\text{negative binomial}(1,p)\n\n\nB.6.8 Worked out Examples\n\nExample B.1 (Geometric Distribution) The Geometric distribution arises when we consider how long we will have to “wait for a success” during repeated Bernoulli trials.\nWhat is the probability that we flip a fair coin four times and don’t see any heads?\nThis is the same as asking what is \\mathbb{P}r(X &gt; 4) where X ∼ Geo(1/2).\n\n  \\begin{aligned}\n    \\mathbb{P}r(X &gt; 4) &= 1 − \\mathbb{P}r(X =1)−\\mathbb{P}r(X = 2)−\\mathbb{P}r(X = 3)−\\mathbb{P}r(X = 4) \\\\\n    &= 1−(\\frac{1}{2})−(\\frac{1}{2})(\\frac{1}{2})−(\\frac{1}{2})(\\frac{1}{2})^2−(\\frac{1}{2})(\\frac{1}{2})^3  \\\\\n   &= \\frac{1}{16}\n    \\end{aligned}\n\nOf course, we could also have just computed it directly, but here we see an example of using the geometric distribution and we can also see that we got the right answer.\n\n\n\nB.6.9 Plots\n\nimport numpy as np\nfrom scipy.stats import geom\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\np = 0.5\nmean, var, skew, kurt = geom.stats(p,moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\nmean=2.00, var=2.00, skew=2.12, kurt=6.50\n\nx = np.arange(geom.ppf(0.01, p),\n              geom.ppf(0.99, p))\nax.plot(x, geom.pmf(x, p), 'bo', ms=8, label='geom pmf')\nax.vlines(x, 0, geom.pmf(x, p), colors='b', lw=5, alpha=0.5)\n\nrv = geom(p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\nr = geom.rvs(p,size=10)\nr\n\narray([ 1, 10,  2,  2,  1,  2,  3,  1,  1,  2])",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-negative-binomial-distribution",
    "href": "A02.html#sec-negative-binomial-distribution",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.7 Negative Binomial Distribution",
    "text": "B.7 Negative Binomial Distribution\n\nB.7.1 Story\n\n\n\n\n\n\nNote\n\n\n\nIn a sequence of independent Bernoulli trials with success probability p, if X is the number of failures before the rth success, then X is said to have the Negative Binomial distribution with parameters r and p, denoted X \\sim NBin(r, p).\n\n\nBoth the Binomial and the Negative Binomial distributions are based on independent Bernoulli trials; they differ in the stopping rule and in what they are counting.\nThe Binomial counts the number of successes in a fixed number of trials; the Negative Binomial counts the number of failures until a fixed number of successes.\nIn light of these similarities, it comes as no surprise that the derivation of the Negative Binomial PMF bears a resemblance to the corresponding derivation for the Binomial.\n\n\nB.7.2 Parameters\n\nr the number of successes.\np the probability of the Bernoulli trial.\n\n\n\nB.7.3 Conditions\n\n\n\n\n\n\nTip\n\n\n\n\nCount of discrete events\nNon-independent events; it is sometimes said that the events can exhibit contagion, meaning that if one event occurs, it is more likely that another will also occur\nCan model a data-generating process where the variance exceeds the mean\nFixed amount of time or space in which the events can occur\n\n\n\n\n\nB.7.4 Examples\n\nStamp collection - Suppose there are n types of stamps, which you are collecting one by one, with the goal of getting a complete set. When collecting stamps, the stamp types are random. Assume that each time you collect a stamp, it is equally likely to be any of the n types. What is the expected number of toys needed until you have a complete set?\neverything the Poisson can do and more,\nto model the number of measles cases that occur on an island,\nthe number of banks that collapse in a financial crisis.\nthe length of a hospital stay\nthe probability you will have to visit Y houses if you must sell r cookies before returning home\n\n\n\nB.7.5 Moments\n\n\\mathrm{E}(X) = \\lambda\n\n\nvar(X) = \\lambda + \\frac{\\lambda^2}{\\kappa}\n\n\n\nB.7.6 Probability mass function (PMF)\n\nf(x \\mid \\lambda,\\kappa) = \\frac{\\Gamma(x+\\kappa)}{x!\\Gamma(\\kappa+1)}\\left(\\frac{\\lambda}{\\lambda+\\kappa}\\right)^x \\left(\\frac{\\kappa}{\\lambda+\\kappa}\\right)^\\kappa\n\n\n\nB.7.7 Cumulative distribution function (CDF)\n\nF(x \\mid \\lambda,\\kappa) =\n\\begin{cases}\n  I_{\\frac{\\kappa}{\\kappa+\\lambda}}(\\kappa,1+\\lfloor x \\rfloor), & x \\ge q 0 \\\\\n  0,                                                             & \\text{Otherwise}\n\\end{cases}\n\n\n\\text{where } I_w(u,v) \\text{ is the regularised incomplete beta function: }\nI_w(u,v) = \\frac{B(w; u, v)}{B(u,v)}\n\n\n\\text{where } B(w; u,v)=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the incomplete beta function and }\\\\\nB(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the complete beta function}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-multinomial-distribution",
    "href": "A02.html#sec-multinomial-distribution",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.8 Multinomial Distribution",
    "text": "B.8 Multinomial Distribution\nThe Multinomial distribution is a generalization of the Binomial. Whereas the Binomial distribution counts the successes in a fixed number of trials that can only be categorized as success or failure, the Multinomial distribution keeps track of trials whose outcomes can fall into multiple categories, such as excellent, adequate, poor; or red, yellow, green, blue.\n\nB.8.1 Story\nMultinomial distribution. Each of N objects is independently placed into one of k categories. An object is placed into category j with probability p_j ,P where the p_j are non-negative and \\sum^k_{j=1} p_j = 1. Let X_1 be the number of objects in category 1, X_2 the number of objects in category 2, etc., so that X_1 + \\dots + X_k = n. Then X = (X_1 , \\dots , X_k ) is said to have the Multinomial distribution with parameters n and p = (p_1 , \\dots , p_k ). We write this as X \\sim Mult_k(n, p).\nWe call X a random vector because it is a vector of random variables. The joint PMF of X can be derived from the story.\n\n\nB.8.2 Examples\n\nBlood type counts across n individuals\nNumbers of people voting for each party in a sample\n\n\n\nB.8.3 Moments\n\n\\mathrm{E}(X_i) = n p_i \\text{, }\\forall i\n\n\nvar(X_i) = n p_i (1-p_i) \\text{, }\\forall i\n\n\ncov(X_i,X_j) = -n p_i p_j \\text{, }\\forall i\\neq j\n\n\n\nB.8.4 Probability Mass Function (PMF)\n\nf(x_1,x_2,\\dots,x_d \\mid n,p_1,p_2,\\dots,p_d) = \\frac{n!}{x_1 ! x_2 ! \\dots x_d !} p_1^{x_1} p_2^{x_2}\\dots p_d^{x_d}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#beta-binomial",
    "href": "A02.html#beta-binomial",
    "title": "Appendix B — Appendix: Discrete Distributions",
    "section": "B.9 Beta Binomial",
    "text": "B.9 Beta Binomial\n\nB.9.1 Story 1 - Polya Urn Model\nThe beta-binomial distribution with parameters \\alpha success rate and \\beta failure and n the number of trials can be motivated by an Pólya urn model.\nImagine an urn containing \\alpha red balls and \\beta black balls, where random draws are made. If a red ball is observed, then two red balls are returned to the urn. Likewise, if a black ball is drawn, then two black balls are returned to the urn. If this is repeated n times, then the probability of observing x red balls follows a beta-binomial distribution with parameters n, \\alpha and \\beta.\nIf the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.\n\n\nB.9.2 Story 2 compound distribution\nThe Beta distribution is a conjugate distribution of the binomial distribution. This fact leads to an analytically tractable compound distribution constructed in a hierarchical fashion where one can think of the p parameter in the binomial distribution as being randomly drawn from a beta distribution.\nSuppose we were interested in predicting the number of heads, x in n future trials. This is given by\n\n{\\displaystyle {\n    \\begin{aligned}\n        f(x\\mid n,\\alpha ,\\beta )&=\\int _{0}^{1}\\mathrm {Bin} (x \\mid n,p)\\mathrm {Beta} (p\\mid \\alpha ,\\beta )\\,dp\\\\\n                            [6pt]&={n \\choose x}{\\frac {1}{\\mathrm {B} (\\alpha ,\\beta )}}\\int _{0}^{1}p^{x+\\alpha -1}(1-p)^{n-x+\\beta -1}\\,dp \\\\\n                            [6pt]&={n \\choose x}{\\frac {\\mathrm {B} (x+\\alpha ,n-x+\\beta )}{\\mathrm {B} (\\alpha ,\\beta )}}.\n    \\end{aligned}}}\n\n\n{\\displaystyle f(x\\mid n,\\alpha ,\\beta )={\\frac {\\Gamma (n+1)}{\\Gamma (x+1)\\Gamma (n-x+1)}}{\\frac {\\Gamma (x+\\alpha )\\Gamma (n-x+\\beta )}{\\Gamma (n+\\alpha +\\beta )}}{\\frac {\\Gamma (\\alpha +\\beta )}{\\Gamma (\\alpha )\\Gamma (\\beta )}}.}\n\n\n\nB.9.3 Moments\n\n\\mathrm{E}(X) = \\frac{n\\alpha}{\\alpha+\\beta}\n \nvar(X) = \\frac{n\\alpha\\beta(\\alpha+\\beta+n)}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n\n\n\nB.9.4 Probability mass function (PMF)\n\nf(x \\mid n,\\alpha,\\beta) = \\binom{n}{x}\\frac{B(x+\\alpha,n-x+\\beta)}{B(\\alpha,\\beta)}\n\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the (complete) beta function }\n\n\n\nB.9.5 Cumulative distribution function (CDF)\n\nF(x\\mid n,\\alpha,\\beta) = \\begin{cases}\n0, & x&lt;0 \\\\\n\\binom{n}{x}\\frac{B(x+\\alpha,n-x+\\beta)}{B(\\alpha,\\beta)} {}_{3}F_2(1,-x,n-x+\\beta;n-x-1,1-x-\\alpha;1), & 0\\leq x \\leq n \\\\\n1, & x&gt;n \\end{cases}\n\n\n\\text{where } {}_{3}F_2(a,b,x) \\text{ is the generalised hypergeometric function}\n\n\n\nB.9.6 Relations\n\nThe Pascal distribution (after Blaise Pascal) is special cases of the negative binomial distribution. Used with an integer-valued stopping-time parameter r\nThe Pólya distribution (for George Pólya) is special cases of the negative binomial distribution. Used with a real-valued-valued stopping-time parameter r\n\n\n\n\n\nA photo of Hungarian Mathematician George Pólya\n\n\n\n\n\n\n\nTipBiographical note on George Pólya\n\n\n\n\nThe cookbook gives a detailed description of ingredients and procedures but no proofs for its prescriptions or reasons for its recipes; the proof of the pudding is in the eating … Mathematics cannot be tested in exactly the same manner as a pudding; if all sorts of reasoning are debarred, a course of calculus may easily become an incoherent inventory of indigestible information. (Polya 1945)\n\nPólya was arguably the most influential mathematician of the 20th century. His basic research contributions span complex analysis, mathematical physics, probability theory, geometry, and combinatorics. He was a teacher par excellence who maintained a strong interest in pedagogical matters throughout his long career.\nHe was awarded a doctorate in mathematics having studied, essentially without supervision, a problem in the theory of geometric probability. Later Pólya looked at the Fourier transform of a probability measure, showing in 1923 that it was a characteristic function. He wrote on the normal distribution and coined the term “central limit theorem” in 1920 which is now standard usage.\nIn 1921 he proved his famous theorem on random walks on an integer lattice. He considered a d-dimensional array of lattice points where a point moves to any of its neighbors with equal probability. He asked whether given an arbitrary point A in the lattice, a point executing a random walk starting from the origin would reach A with probability 1. Pólya’s surprising answer was that it would for d=1 and for d=2, but it would not for d\\ge 3. In later work he looked at two points executing independent random walks and also at random walks satisfying the condition that the moving point never passed through the same lattice point twice.\nOne of Pólya’s notable achievements was his collaboration with the economist Abraham Wald during World War II. They developed statistical techniques to solve military problems, including estimating enemy troop movements and predicting the effectiveness of bombing missions. These contributions played a vital role in aiding the Allies during the war.\nHis book “How to Solve It,” published in 1945, presented problem-solving heuristics applicable to various mathematical domains, including probability and statistics. This influential work emphasized the importance of understanding the problem, devising a plan, executing the plan, and reflecting on the results. Pólya’s problem-solving strategies continue to be widely taught and practiced.\n\nFor a more extensive biography visit the following link\n\n\n\n\n\n\n\n\nBernoulli, J. 1713. Ars Conjectandi [the Art of Conjecturing]. Impensis Thurnisiorum. https://books.google.co.il/books?id=Ba5DAAAAcAAJ.\n\n\nPolya, G. 1945. How to Solve It. Princeton University Press. https://doi.org/10.1515/9781400828678.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html",
    "href": "A03.html",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "",
    "text": "C.1 The Continuous Uniform\nFollowing a subjective view of distribution, which is more amenable to reinterpretation I use an indicator function to place restrictions on the range of parameter of the PDF.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-continuous-uniform",
    "href": "A03.html#sec-continuous-uniform",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "",
    "text": "C.1.1 Stories\n\n\n\n\n\n\nNoteDiscrete Uniform Finite set Parametrization\n\n\n\n\n\n\n\nX \\sim U[\\alpha,\\beta]\n\\tag{C.1}\n\n\nC.1.2 Moments\n\n\\mathbb{E}[X]=\\frac{(\\alpha+\\beta)}{2}\n\\tag{C.2}\n\n\\mathbb{V}ar[X]=\\frac{(\\beta-\\alpha)^2}{12}\n\\tag{C.3}\n\n\nC.1.3 Probability mass function (PDF)\n\nf(x)= \\frac{1}{\\alpha-\\beta} \\mathbb{I}_{\\{\\alpha \\le x \\le \\beta\\}}(x)\n\\tag{C.4}\n\n\nC.1.4 Cumulative distribution function (CDF)\n\nF(x\\mid \\alpha,\\beta)=\\begin{cases}\n  0,  & \\text{if }x &lt; \\alpha \\\\\n  \\frac{x-\\alpha}{\\beta-\\alpha}, & \\text{if } x\\in [\\alpha,\\beta]\\\\\n  1, & \\text{if } x &gt; \\beta\n  \\end{cases}\n\\tag{C.5}\n\n\nC.1.5 Prior\nSince a number of families have the uniform as a special case we can use them as priors when we want a uniform prior:\nNormal(0,1)= Beta(1,1)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-beta-distribution",
    "href": "A03.html#sec-the-beta-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.2 The Beta Distribution",
    "text": "C.2 The Beta Distribution\n\n\nC.2.1 Story\nThe Beta distribution is used for random variables which take on values between 0 and 1. For this reason (and other reasons we will see later in the course), the Beta distribution is commonly used to model probabilities.\n\nX \\sim Beta(\\alpha, \\beta)\n\\tag{C.6}\n\n\nC.2.2 PDF & CDF\n\nf(x \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha−1}(1 − x)^{\\beta−1}\\mathbb{I}_{x\\in(0,1)}\\mathbb{I}_{\\alpha\\in\\mathbb{R}^+}\\mathbb{I}_{\\beta\\in\\mathbb{R}^+} \\qquad \\text{(PDF)}\n\\tag{C.7}\n\n\\begin{aligned}\n                 & F(x \\mid \\alpha,\\beta) &= I_x(\\alpha,\\beta) && \\text{(CDF)} \\\\\n   \\text{where } & I_w(u,v) & &&\\text{ is the regularized beta function: } \\\\\n                 & I_w(u,v) &= \\frac{B(w; u, v)}{B(u,v)} \\\\\n    \\text{where }& B(w; u,v) &=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t  && \\text{ is the incomplete beta function  }\\\\\n    \\text{and }  & B(u,v)& && \\text{ is the (complete) beta function}\n\\end{aligned}\n\\tag{C.8}\n\n\nC.2.3 Moments\n\n\\mathbb{E}[X] = \\frac{\\alpha}{\\alpha + \\beta} \\qquad (\\text{expectation})\n\\tag{C.9}\n\n\\mathbb{V}ar[X] = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)} \\qquad (\\text{variance})\n\\tag{C.10}\n\n\\mathbb{M}_X(t) = 1+ \\sum^\\infty_{i=1} \\left ( {\\prod^\\infty_{j=0} \\frac{\\alpha+j}{\\alpha + \\beta + j} } \\right ) \\frac{t^i}{i!}\n\\tag{C.11}\nwhere \\Gamma(·) is the Gamma function introduced with the gamma distribution.\nNote also that \\alpha &gt; 0 and \\beta &gt; 0.\n\n\nC.2.4 Relations\n\n\n\nRelations of the Beta distribution\n\n\nThe standard Uniform(0, 1) distribution is a special case of the beta distribution with \\alpha = \\beta = 1.\n\nUniform(0, 1) = Beta(1,1)\n\\tag{C.12}\n\n\nC.2.5 As a prior\nThe Beta distribution is often used as a prior for parameters that are probabilities,since it takes values from 0 and 1.\nDuring prior elicitation the parameters can be set using\n\nthe mean: \\alpha \\over \\alpha +\\beta which I would interpret here as count of successes over trials prior to seeing the data.\nvariance: Equation C.10 or\nThe effective sample size which is \\alpha+\\beta (see course 1 lesson 7.3 for the derivation).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-cauchy",
    "href": "A03.html#sec-cauchy",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.3 The Cauchy Distribution",
    "text": "C.3 The Cauchy Distribution\n\n\nC.3.1 PDF\n\n\\text{Cauchy}(y\\mid\\mu,\\sigma) = \\frac{1}{\\pi \\sigma} \\\n\\frac{1}{1 + \\left((y - \\mu)/\\sigma\\right)^2} \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{C.13}\n\n\nC.3.2 CDF\n\nF(x \\mid \\mu, \\sigma) = \\frac{1}{2} + \\frac{1}{\\pi}\\text{arctan}\\left(\\frac{x-\\mu}{\\sigma}\\right) \\qquad \\text{(CDF)}\n\\tag{C.14}\n\n\\mathbb{E}(X) = \\text{ undefined}\n\n\n\\mathbb{V}ar[X] = \\text{ undefined}\n\n\n\nC.3.3 As a prior\n\nThe Cauchy despite having no mean or variance is recommended as a prior for regression coefficients in Logistic regression. see (Gelman et al. 2008) this is analyzed and discussed in (Ghosh, Li, and Mitra 2018)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-double-exponential",
    "href": "A03.html#sec-double-exponential",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.4 Double Exponential Distribution (Laplace)",
    "text": "C.4 Double Exponential Distribution (Laplace)\n\n\n\\text{DoubleExponential}(y \\mid \\mu,\\sigma) =\n\\frac{1}{2\\sigma} \\exp \\left( - \\, \\frac{\\|y - \\mu\\|}{\\sigma} \\right)\n\\qquad \\text (PDF)\n\\tag{C.15}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-gamma-distribution",
    "href": "A03.html#sec-the-gamma-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.5 The Gamma Distribution",
    "text": "C.5 The Gamma Distribution\n\n\nC.5.1 Story\nIf X_1, X_2, ..., X_n are independent (and identically distributed \\mathrm{Exp}(\\lambda)) waiting times between successive events, then the total waiting time for all n events to occur Y = \\sum X_i will follow a gamma distribution with shape parameter \\alpha = n and rate parameter \\beta = \\lambda:\nWe denote this as:\n\nY =\\sum^N_{i=0} \\mathrm{Exp}_i(\\lambda) \\sim \\mathrm{Gamma}(\\alpha = N, \\beta = \\lambda)\n\\tag{C.16}\n\n\nC.5.2 PDF\n\nf(y \\mid \\alpha , \\beta) = \\frac{\\beta^\\alpha} {\\Gamma(\\alpha)} y^{\\alpha−1} e^{− \\beta y} \\mathbb{I}_{y \\ge \\theta }(y)\n\\tag{C.17}\n\n\nC.5.3 Moments\n\n\\mathbb{E}[Y] = \\frac{\\alpha}{ \\beta}\n\\tag{C.18}\n\n\\mathbb{V}ar[Y] = \\frac{\\alpha}{ \\beta^2}\n\\tag{C.19}\nwhere \\Gamma(·) is the gamma function, a generalization of the factorial function which can accept non-integer arguments. If n is a positive integer, then \\Gamma(n) = (n − 1)!.\nNote also that \\alpha &gt; 0 and $ &gt; 0$.\n\n\nC.5.4 Relations\n\n\n\nRelations of the Gamma Distribution\n\n\nThe exponential distribution is a special case of the Gamma distribution with \\alpha = 1. The gamma distribution commonly appears in statistical problems, as we will see in this course. It is used to model positive-valued, continuous quantities whose distribution is right-skewed. As \\alpha increases, the gamma distribution more closely resembles the normal distribution.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#inverse-gamma-distribution",
    "href": "A03.html#inverse-gamma-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.6 Inverse Gamma Distribution",
    "text": "C.6 Inverse Gamma Distribution\n\n\nC.6.1 PDF\n\n\\mathcal{IG}(y\\mid\\alpha,\\beta) =\n\\frac{1} {\\Gamma(\\alpha)}\\frac{\\beta^{\\alpha}}{y^{\\alpha + 1}}  e^{- \\frac{ \\beta}{y}}\n   \\ \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{\\beta \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)\n\\tag{C.20}\n\n\nC.6.2 Moments\n\n\\mathbb{E}[X]=\\frac{\\beta}{\\alpha - 1} \\qquad \\text{Expectation}\n\\tag{C.21}\n\n\\mathbb{V}ar[X]=\\frac{\\beta^2}{(\\alpha-1)^2(\\alpha-2)}\\qquad \\text{Variance}\n\\tag{C.22}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#the-z-or-standard-normal-distribution",
    "href": "A03.html#the-z-or-standard-normal-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.7 The Z or Standard normal distribution",
    "text": "C.7 The Z or Standard normal distribution\n· The Standard normal distribution is given by:\n\nZ \\sim \\mathcal{N}[1,0]\n\\tag{C.23}\n\nf(z) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}\n\\tag{C.24}\n\n\\mathcal{L}(\\mu,\\sigma)=\\prod_{i=1}^{n}{1 \\over 2 \\pi \\sigma}e^{−(x_i−\\mu)^2 \\over 2 \\sigma^2}\n\\tag{C.25}\n\n\\begin{aligned}\n\\ell(\\mu, \\sigma) &= \\log \\mathcal{L}(\\mu, \\sigma) \\\\\n&= -\\frac{n}{2}\\log(2\\pi) - n\\log\\sigma - \\sum_{i=1}^n \\frac{(x_i-\\mu)^2}{2\\sigma^2}\n\\end{aligned}\\sigma^2\n\\tag{C.26}\n\n\\begin{aligned}\n  \\mathbb{E}(Z)&= 0 \\quad \\text{(Expectation)} \\qquad  \\mathbb{V}ar(Z)&= 1 \\quad \\text{(Variance)}\n\\end{aligned}\n\\tag{C.27}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-normal-distribution",
    "href": "A03.html#sec-the-normal-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.8 The Normal Distribution",
    "text": "C.8 The Normal Distribution\n The normal, or Gaussian distribution is one of the most important distributions in statistics.\nIt arises as the limiting distribution of sums (and averages) of random variables. This is due to the Section F.1. Because of this property, the normal distribution is often used to model the “errors,” or unexplained variations of individual observations in regression models.\nNow consider X = \\sigma Z+\\mu where \\sigma &gt; 0 and \\mu is any real constant. Then \\mathbb{E}[X] = \\mathbb{E}[\\sigma Z+\\mu] = \\sigma E[Z] + \\mu = \\sigma_0 + \\mu = \\mu and \\mathbb{V}ar[X] = Var(\\sigma^2 Z + \\mu) = \\sigma^2 Var(Z) + 0 = \\sigma^2 \\cdot 1 = \\sigma^2\nThen, X follows a normal distribution with mean \\mu and variance \\sigma^2 (standard deviation \\sigma) denoted as\n\nX \\sim N[\\mu,\\sigma^2]\n\\tag{C.28}\n\nC.8.1 PDF\n\nf(x\\mid\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}  e^{-\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}(x-\\mu)^2}\n\\tag{C.29}\n\n\nC.8.2 Moments\n\n\\mathbb{E}(x)= \\mu\n\\tag{C.30}\n\nVar(x)= \\sigma^2\n\\tag{C.31}\n\nThe normal distribution is symmetric about the mean \\mu and is often described as a bell-shaped curve.\nAlthough X can take on any real value (positive or negative), more than 99% of the probability mass is concentrated within three standard deviations of the mean.\n\nThe normal distribution has several desirable properties.\nOne is that if X_1 \\sim N(\\mu_1, \\sigma^2_1) and X_2 ∼ N(\\mu_2, \\sigma^2_2) are independent, then X_1+X_2 \\sim N(\\mu_1+\\mu_2, \\sigma^2_1+\\sigma^2_2).\nConsequently, if we take the average of n Independent and Identically Distributed (IID) Normal random variables we have:\n\n\\bar X = \\frac{1}{n}\\sum_{i=1}^n X_i \\sim N(\\mu, \\frac{\\sigma^2}{n})\n\\tag{C.32}\n\nimport numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = norm.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\nmean=0.00, var=1.00, skew=0.00, kurt=0.00\n\nx = np.linspace(norm.ppf(0.01),\n                norm.ppf(0.99), 100)\nax.plot(x, norm.pdf(x),\n       'r-', lw=5, alpha=0.6, label='norm pdf')\n\nrv = norm()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\nr = norm.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n(array([0.00737665, 0.00368832, 0.01106497, 0.05901319, 0.06270151,\n       0.10696141, 0.12909135, 0.23236443, 0.25080606, 0.35776746,\n       0.31719589, 0.35039081, 0.36145579, 0.37989741, 0.32088422,\n       0.2581827 , 0.20285784, 0.12909135, 0.05532487, 0.03688324,\n       0.02581827, 0.0147533 , 0.00368832, 0.00737665, 0.00368832]), array([-3.19698904, -2.92586321, -2.65473738, -2.38361155, -2.11248572,\n       -1.84135989, -1.57023406, -1.29910823, -1.0279824 , -0.75685656,\n       -0.48573073, -0.2146049 ,  0.05652093,  0.32764676,  0.59877259,\n        0.86989842,  1.14102425,  1.41215008,  1.68327591,  1.95440174,\n        2.22552757,  2.4966534 ,  2.76777923,  3.03890506,  3.31003089,\n        3.58115672]), [&lt;matplotlib.patches.Polygon object at 0x73ba9cfc1e40&gt;])\n\nax.set_xlim([x[0], x[-1]])\n\n(-2.3263478740408408, 2.3263478740408408)\n\nax.legend(loc='best', frameon=False)\nplt.show()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-t-distribution",
    "href": "A03.html#sec-the-t-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.9 The t-Distribution",
    "text": "C.9 The t-Distribution\n If we have normal data, we can use (Equation C.32) to help us estimate the mean \\mu. Reversing the transformation from the previous section, we get:\n\n\\frac {\\hat X - \\mu}{\\sigma / \\sqrt(n)} \\sim N(0, 1)\n\\tag{C.33}\nHowever, we may not know the value of \\sigma. If we estimate it from data, we can replace it with S = \\sqrt{\\sum_i \\frac{(X_i-\\hat X)^2}{n-1}}, the sample standard deviation. This causes the expression (Equation C.33) to no longer be distributed as a Standard Normal; but as a standard t-distribution with ν = n − 1 degrees of freedom\n\nX \\sim t[\\nu]\n\\tag{C.34}\nf(t\\mid\\nu) = \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\nu\\pi}}\\left (1 + \\frac{t^2}{\\nu}\\right)^{-(\\frac{\\nu+1}{2})}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{C.35}\n\n\\text{where }\\Gamma(w)=\\int_{0}^{\\infty}t^{w-1}e^{-t}\\mathrm{d}t \\text{ is the gamma function}\n\nf(t\\mid\\nu)={\\frac {1}{{\\sqrt {\\nu }}\\,\\mathrm {B} ({\\frac {1}{2}},{\\frac {\\nu }{2}})}}\\left(1+{\\frac {t^{2}}{\\nu }}\\right)^{-(\\nu +1)/2}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{C.36}\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the beta function}\n\n\\begin{aligned}\n&& F(t)&=\\int _{-\\infty }^{t}f(u)\\,du=1-{\\tfrac {1}{2}}I_{x(t)}\\left({\\tfrac {\\nu }{2}},{\\tfrac {1}{2}}\\right) &&\\text{(CDF)} \\\\\n   \\text{where } && I_{x(t)}&= \\frac{B(x; u, v)}{B(u,v)}                 &&\\text{is the regularized Beta function} \\\\\n   \\text{where } && B(w; u,v)&=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t &&  \\text{ is the incomplete Beta function } \\\\\n   \\text {and }  && B(u,v)&=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t    && \\text{ is the (complete) beta function}\n\\end{aligned}\n\\tag{C.37}\n\\int _{-\\infty }^{t}f(u)\\,du={\\tfrac {1}{2}}+t{\\frac {\\Gamma \\left({\\tfrac {1}{2}}(\\nu +1)\\right)}{{\\sqrt {\\pi \\nu }}\\,\\Gamma \\left({\\tfrac {\\nu }{2}}\\right)}}\\,{}_{2}F_{1}\\left({\\tfrac {1}{2}},{\\tfrac {1}{2}}(\\nu +1);{\\tfrac {3}{2}};-{\\tfrac {t^{2}}{\\nu }}\\right)\n\n\n\\mathcal{L}(\\mu, \\sigma, \\nu) = \\prod_{i=1}^n \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu\\pi}\\Gamma(\\frac{\\nu}{2})} \\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right)^{-\\frac{\\nu+1}{2}}\n\\tag{C.38}\n\n\\begin{aligned}\n\\ell(\\mu, \\sigma, \\nu) &= \\log \\mathcal{L}(\\mu, \\sigma, \\nu) \\\\\n&= \\sum_{i=1}^n \\left[\\log\\Gamma\\left(\\frac{\\nu+1}{2}\\right) - \\log\\sqrt{\\nu\\pi} - \\log\\Gamma\\left(\\frac{\\nu}{2}\\right) - \\frac{\\nu+1}{2}\\log\\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right)\\right] \\\\\n&= n\\log\\Gamma\\left(\\frac{\\nu+1}{2}\\right) - n\\log\\sqrt{\\nu\\pi} - n\\log\\Gamma\\left(\\frac{\\nu}{2}\\right) - \\frac{\\nu+1}{2}\\sum_{i=1}^n\\log\\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right).\n\\end{aligned}\n\\tag{C.39}\n\n\\mathbb{E}[Y] = 0 \\qquad \\text{ if } \\nu &gt; 1\n\\tag{C.40}\n\n\\mathbb{V}ar[Y] = \\frac{\\nu}{\\nu - 2} \\qquad \\text{ if } \\nu &gt; 2\n\\tag{C.41}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#location-scale-parametrization-t-distribution",
    "href": "A03.html#location-scale-parametrization-t-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.10 Location Scale Parametrization t-distribution",
    "text": "C.10 Location Scale Parametrization t-distribution\n\nX=\\mu+\\sigma T\n\nThe resulting distribution is also called the non-standardized Student’s t-distribution.\nthis is another parameterization of the student-t with:\n\nlocation \\mu \\in \\mathbb{R}^+\nscale \\sigma \\in \\mathbb{R}^+\ndegrees of freedom \\nu \\in \\mathbb{R}^+\n\n\nf(x \\mid \\mu, \\sigma, \\nu) = \\frac{\\left(\\frac{\\nu }{\\nu +\\frac{(x-\\mu )^2}{\\sigma ^2}}\\right)^{\\frac{\\nu+1}{2}}}{\\sqrt{\\nu } \\sigma  B\\left(\\frac{\\nu }{2},\\frac{1}{2} \\right)}\n\\tag{C.42}\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the beta function}\n\n\nF(\\mu, \\sigma, \\nu) =\n\\begin{cases}\n\\frac{1}{2} I_{\\frac{\\nu  \\sigma ^2}{(x-\\mu )^2+\\nu  \\sigma  ^2}}\\left(\\frac{\\nu }{2},\\frac{1}{2}\\right),                & x\\leq \\mu  \\\\\n\\frac{1}{2} \\left(I_{\\frac{(x-\\mu )^2}{(x-\\mu )^2+\\nu  \\sigma   ^2}}\\left(\\frac{1}{2},\\frac{\\nu }{2}\\right)+1\\right), & \\text{Otherwise}\n\\end{cases}\n\\tag{C.43}\nwhere I_w(u,v) is the regularized incomplete beta function:\n\nI_w(u,v) = \\frac{B(w; u, v)}{B(u,v)}\n\nwhere B(w; u,v) is the incomplete beta function:\n\nB(w; u,v) =\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t\n\nAnd B(u,v) is the (complete) beta function\n\n\\mathbb{E}[X] =\n  \\begin{cases}\n    \\mu,               & \\text{if }\\nu &gt; 1  \\\\\n    \\text{undefined} & \\text{ otherwise}\n  \\end{cases}\n\\tag{C.44}\n\n\\mathbb{V}ar[X] = \\frac{\\nu \\sigma^2}{\\nu-2}\n\\tag{C.45}\nThe t distribution is symmetric and resembles the Normal Distribution but with thicker tails. As the degrees of freedom increase, the t distribution looks more and more like the standard normal distribution.\n\n\n\n\n\n\n\nFigure C.1: William Sealy Gosset AKA Student\n\n\n\n\n\n\n\n\nTipHistorical Note on The William Sealy Gosset A.K.A Student\n\n\n\n The student-t distribution is due to Gosset, William Sealy (1876-1937) who was an English statistician, chemist and brewer who served as Head Brewer of Guinness and Head Experimental Brewer of Guinness and was a pioneer of modern statistics. He is known for his pioneering work on small sample experimental designs. Gosset published under the pseudonym “Student” and developed most famously Student’s t-distribution – originally called Student’s “z” – and “Student’s test of statistical significance”.\nHe was told to use a Pseudonym and choose ‘Student’ after a predecessor at Guinness published a paper that leaked trade secrets. Gosset was a friend of both Karl Pearson and Ronald Fisher. Fisher suggested a correction to the student-t using the degrees of freedom rather than the sample size. Fisher is also credited with helping to publicize its use.\nfor a full biography see (Pearson et al. 1990)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-exponential-distribution",
    "href": "A03.html#sec-the-exponential-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.11 The Exponential Distribution",
    "text": "C.11 The Exponential Distribution\n\n\nC.11.1 Story\nThe Exponential distribution models the waiting time between events for events with a rate lambda. Those events, typically, come from a Poisson process\nThe exponential distribution is often used to model the waiting time between random events. Indeed, if the waiting times between successive events are independent then they form an Exp(λ) distribution. Then for any fixed time window of length t, the number of events occurring in that window will follow a Poisson distribution with mean tλ.\n\nX \\sim Exp[\\lambda]\n\\tag{C.46}\n\n\nC.11.2 PDF\n\nf(x \\mid \\lambda) = \\frac{1}{\\lambda} e^{- \\frac{x}{\\lambda}}(x)\\mathbb{I}_{\\lambda\\in\\mathbb{R}^+ } \\mathbb{I}_{x\\in\\mathbb{R}^+_0 } \\quad \\text{(PDF)}\n\\tag{C.47}\n\n\nC.11.3 CDF\n\nF(x \\mid \\lambda) = 1 - e^{-\\lambda x} \\qquad \\text{(CDF)}\n\n\n\\mathcal{L}(\\lambda) = \\prod_{i=1}^n \\lambda e^{-\\lambda x_i}\n\\tag{C.48}\n\n\\begin{aligned} \\ell(\\lambda) &= \\log \\mathcal{L}(\\lambda) \\\\\n&= \\sum_{i=1}^n \\log(\\lambda) - \\lambda x_i \\\\\n&= n\\log(\\lambda) - \\lambda\\sum_{i=1}^n x_i \\end{aligned}\n\\tag{C.49}\n\n\nC.11.4 Moments\n\n\\mathbb{E}(x)= \\lambda\n\\tag{C.50}\n\n\\mathbb{V}ar[X]= \\lambda^2\n\\tag{C.51}\n\n\\mathbb{M}_X(t)= \\frac{1}{1-\\lambda t} \\qquad t &lt; \\frac{1}{\\gamma}\n\\tag{C.52}\n\n\nC.11.5 Special cases:\n \n\nWeibull Y = X^{\\frac{1}{\\gamma}}\nRayleigh Y = \\sqrt{\\frac{2X}{\\lambda}}\nGumbel Y=\\alpha - \\gamma \\log(\\frac{X}{\\lambda})\n\n\n\nC.11.6 Properties:\n\nmemoryless\n\n\nimport numpy as np\nfrom scipy.stats import expon\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = expon.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\nmean=1.00, var=1.00, skew=2.00, kurt=6.00\n\nx = np.linspace(expon.ppf(0.01), expon.ppf(0.99), 100)\nax.plot(x, expon.pdf(x), 'r-', lw=5, alpha=0.6, label='expon pdf')\n\nrv = expon()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n\nr = expon.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n(array([0.79628554, 0.68381583, 0.60283764, 0.44088126, 0.37789822,\n       0.32391276, 0.29692003, 0.15745759, 0.15745759, 0.12596607,\n       0.10347213, 0.05848425, 0.06298304, 0.04498788, 0.08547698,\n       0.02249394, 0.02249394, 0.02699273, 0.0404891 , 0.00899758,\n       0.        , 0.01349637, 0.00899758, 0.00449879, 0.        ,\n       0.00449879, 0.01349637, 0.        , 0.        , 0.        ,\n       0.00899758, 0.        , 0.        , 0.00449879]), array([2.39229972e-03, 2.24674371e-01, 4.46956443e-01, 6.69238515e-01,\n       8.91520587e-01, 1.11380266e+00, 1.33608473e+00, 1.55836680e+00,\n       1.78064887e+00, 2.00293095e+00, 2.22521302e+00, 2.44749509e+00,\n       2.66977716e+00, 2.89205923e+00, 3.11434130e+00, 3.33662338e+00,\n       3.55890545e+00, 3.78118752e+00, 4.00346959e+00, 4.22575166e+00,\n       4.44803373e+00, 4.67031581e+00, 4.89259788e+00, 5.11487995e+00,\n       5.33716202e+00, 5.55944409e+00, 5.78172617e+00, 6.00400824e+00,\n       6.22629031e+00, 6.44857238e+00, 6.67085445e+00, 6.89313652e+00,\n       7.11541860e+00, 7.33770067e+00, 7.55998274e+00]), [&lt;matplotlib.patches.Polygon object at 0x73ba9cedc940&gt;])\n\nax.set_xlim([x[0], x[-1]])\n\n(0.010050335853501442, 4.605170185988091)\n\nax.legend(loc='best', frameon=False)\nplt.show()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-lognormal-distribution",
    "href": "A03.html#sec-lognormal-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.12 LogNormal Distribution",
    "text": "C.12 LogNormal Distribution\nThe long normal arises when the a log transform is applied to the normal distribution.\n\n\n\\text{LogNormal}(y\\mid\\mu,\\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\ \\sigma} \\, \\frac{1}{y} \\ \\exp \\! \\left( - \\, \\frac{1}{2} \\, \\left( \\frac{\\log y - \\mu}{\\sigma} \\right)^2 \\right) \\ \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)\n\\tag{C.53}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-pareto-distribution",
    "href": "A03.html#sec-pareto-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.13 Pareto Distribution",
    "text": "C.13 Pareto Distribution\n\n\n\\text{Pareto}(y|y_{\\text{min}},\\alpha) = \\frac{\\displaystyle\n\\alpha\\,y_{\\text{min}}^\\alpha}{\\displaystyle y^{\\alpha+1}} \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{y_{min} \\in \\mathbb{R}^+}\\mathbb{I}_{y\\ge y_{min} \\in \\mathbb{R}^+}\n\\qquad \\text (PDF)\n\\tag{C.54}\n\n\\mathrm{Pareto\\_Type\\_2}(y|\\mu,\\lambda,\\alpha) = \\\n\\frac{\\alpha}{\\lambda} \\, \\left( 1+\\frac{y-\\mu}{\\lambda}\n\\right)^{-(\\alpha+1)} \\! \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\lambda \\in \\mathbb{R}^+}\\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{y\\ge \\mu \\in \\mathbb{R}}\n\\qquad \\text (PDF)\n\\tag{C.55}\n\n\\mathbb{E}[X]=\\displaystyle{\\frac{\\alpha y_\\mathrm{min}}{\\alpha - 1}}\\mathbb{I}_{\\alpha&gt;1} \\qquad \\text (expectation)\n\\tag{C.56}\n\n\\mathbb{V}ar[X]=\\displaystyle{\\frac{\\alpha y_\\mathrm{min}^2}{(\\alpha - 1)^2(\\alpha - 2)}}\\mathbb{I}_{\\alpha&gt;2} \\qquad \\text (variance)\n\\tag{C.57}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-weibull-distribution",
    "href": "A03.html#sec-weibull-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.14 Weibull Distribution",
    "text": "C.14 Weibull Distribution\n\n\nC.14.1 PDF\n\n\\text{Weibull}(y|\\alpha,\\sigma) =\n\\frac{\\alpha}{\\sigma} \\, \\left( \\frac{y}{\\sigma} \\right)^{\\alpha - 1} \\, e^{ - \\left( \\frac{y}{\\sigma} \\right)^{\\alpha}} \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-chi-squared-distribution",
    "href": "A03.html#sec-chi-squared-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.15 Chi Squared Distribution",
    "text": "C.15 Chi Squared Distribution\n\nThe chi squared distribution is a special case of the gamma. It is widely used in hypothesis testing and the construction of confidence intervals. It is parameterized using parameter \\nu for the degrees of predom\n\nC.15.1 PDF:\n\n\\text{ChiSquare}(y\\mid\\nu) = \\frac{2^{-\\nu/2}}     {\\Gamma(\\nu / 2)} \\,\ny^{\\nu/2 - 1} \\, \\exp \\! \\left( -\\, \\frac{1}{2} \\, y \\right) \\mathbb{I}_{\\nu \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}} \\qquad \\text (PDF)\n\\tag{C.58}\n\n\nC.15.2 CDF:\n\n{\\frac {1}{\\Gamma (\\nu/2)}}\\;\\gamma \\left({\\frac {\\nu}{2}},\\,{\\frac {x}{2}}\\right) \\qquad \\text (CDF)\n\\tag{C.59}\n\n\nC.15.3 MOMENTS\n\n\\mathbb{E}[X]=\\nu\n\\tag{C.60}\n\n\\mathbb{V}ar[X] = 2\\nu\n\\tag{C.61}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-logistic-distribution",
    "href": "A03.html#sec-logistic-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.16 Logistic Distribution",
    "text": "C.16 Logistic Distribution\n\n\\text{Logistic}(y|\\mu,\\sigma) = \\frac{1}{\\sigma} \\\n\\exp\\!\\left( - \\, \\frac{y - \\mu}{\\sigma} \\right) \\ \\left(1 + \\exp\n\\!\\left( - \\, \\frac{y - \\mu}{\\sigma} \\right) \\right)^{\\!-2} \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}}  \\qquad \\text (PDF)\n\\tag{C.62}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-f-distribution",
    "href": "A03.html#sec-f-distribution",
    "title": "Appendix C — Appendix: Continuous Distributions",
    "section": "C.17 F Distribution",
    "text": "C.17 F Distribution\n   The F-distribution or F-ratio, arises frequently as the null distribution of a test statistic, in the analysis of variance (ANOVA) and other F-tests.F DistributionF-ratio\n\nC.17.1 PDF\n\n\\frac {\\sqrt {\\frac {(d_{1}x)^{d_{1}}d_{2}^{d_{2}}}{(d_{1}x+d_{2})^{d_{1}+d_{2}}}}}{x\\,\\mathrm {B} \\!\\left({\\frac {d_{1}}{2}},{\\frac {d_{2}}{2}}\\right)}\n\\tag{C.63}\n\n\nC.17.2 CDF\n\n\\mathbb{I}_{\\frac {d_{1}x}{d_{1}x+d_{2}}}\\left({\\tfrac {d_{1}}{2}},{\\tfrac {d_{2}}{2}}\\right)\n\\tag{C.64}\n\n\nC.17.3 Moments\n\n\\mathbb{E}[X]=\\frac {d_{2}}{d_{2}-2}\n\\tag{C.65}\n\n\\mathbb{V}ar[X] = {\\frac {2\\,d_{2}^{2}\\,(d_{1}+d_{2}-2)}{d_{1}(d_{2}-2)^{2}(d_{2}-4)}}\n\\tag{C.66}\n\n\n\n\n\n\nGelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” The Annals of Applied Statistics 2 (4). https://doi.org/10.1214/08-aoas191.\n\n\nGhosh, Joyee, Yingbo Li, and Robin Mitra. 2018. “On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression.” Bayesian Analysis 13 (2). https://doi.org/10.1214/17-ba1051.\n\n\nPearson, E. S., W. S. Gosset, R. L. Plackett, and G. A. Barnard. 1990. Student: A Statistical Biography of William Sealy Gosset. Clarendon Press. https://books.google.co.il/books?id=LBDvAAAAMAAJ.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A05.html",
    "href": "A05.html",
    "title": "Appendix D — Appendix: Exponents & Logarithms",
    "section": "",
    "text": "D.1 Exponents\nExponents are of the form a^x where:\nRecall that a^0 = 1. Exponents have the following useful properties\nNote: that the first property requires that both terms have the same base a.\nWe cannot simplify a^x ·b^y if a \\ne b.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A05.html#sec-exponents",
    "href": "A05.html#sec-exponents",
    "title": "Appendix D — Appendix: Exponents & Logarithms",
    "section": "",
    "text": "a (called the base) and\nx (called the exponent) is any real number.\n\n\n\na^x· a^y = a^{x+y}\n(a^x)^y = a^{x·y}\n\n\n\n\nOne common base is the number e which is approximately equal to 2.7183.\nThe function e^x is so common in mathematics and has its own symbol e^x = \\exp(x).\nBecause e &gt; 0 we have e^x &gt; 0 for all real numbers x\n\\lim_{x \\to \\infty} x = e^{−x} = 0.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A05.html#sec-natural-logarithms",
    "href": "A05.html#sec-natural-logarithms",
    "title": "Appendix D — Appendix: Exponents & Logarithms",
    "section": "D.2 Natural Logarithms",
    "text": "D.2 Natural Logarithms\nWe will need to manipulate long products of probabilities. Since there often comprise small fractions, their calculation on computers can be problematic due to the underflow of floats. We will therefore prefer to convert these products into sums of logarithms.\n\nDefinition D.1 (The Logarithm) A log is the inverse of a power. We can use (Equation D.1).\n\ny = a^x \\implies log_a(y) = x\n\\tag{D.1}\n\n\nDefinition D.2 (The Natural log) The natural logarithm function has base e and is written without the subscript\n\nlog_e(y) = log(y)\n\\tag{D.2}\n\n\nTheorem D.1 (Logs take positive values) logs only exist for values greater than 0\n\n\\forall x(e^x &gt; 0) \\implies \\exists \\log(y) \\iff {y &gt; 0}\n\n\nWe can use the properties of exponents from the previous section to obtain some important properties of logarithms:\n\nDefinition D.3 (Log of a product) we can use Equation D.3 to convert a log of a product to a sum of logs.\n\n\\log(x·y) = \\log(x) + \\log(y)\n\\tag{D.3}\n\n\nDefinition D.4 (Log of a quotient) we can use Equation D.4 to convert a log of a quotient to a difference of logs.\n\n\\log(\\frac{x}{y}) = log(x) − log(y)\n\\tag{D.4}\n\n\nDefinition D.5 (Log of a power) we can use Equation D.5 to convert a log of a variable raised to a power into the product.\n\n    \\log(x^b) = b \\cdot log(x)\n\\tag{D.5}\n\n\nDefinition D.6 (Log of one) we can use (Equation D.6) to replace a log of 1 with zero since $x(x^0 = 1) $\n\n    \\log(1)=0\n\\tag{D.6}\n\n\nD.2.1 Log of exponent\nwe can use (Equation D.7) to cancel a log of an exponent since the log is the inverse function of the exponent.\n\nexp(log(y)) = log(exp(y)) = y\n\\tag{D.7}\n\nExample D.1 (Logarithm) \n    \\begin{aligned}\n    log \\frac{5^2}{10}= 2 log(5) − log(10) ≈ 0.916.\n    \\end{aligned}\n\n\n\nDefinition D.7 (Change of base for a log) we can use (Equation D.8) to change the base of a logarithm.\n\n    \\log_b(a)=\\frac{\\log_c(a)}{\\log_c(n)}\n\\tag{D.8}\n\n\nDefinition D.8 (Derivative of a Log) we can use (Equation D.9) to differentiate a log.\n\n    \\frac{d}{dx} \\log_(x)=\\frac{1}{x}\n\\tag{D.9}\n\n\nBecause the natural logarithm is a monotonically increasing one-to-one function, finding the x which maximizes any (positive-valued function) f(x) is equivalent to maximizing log(f(x)).\nThis is useful because we often take derivatives to maximize functions.\nIf f(x) has product terms, then log(f(x)) will have summation terms, which are usually simpler when taking derivatives.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A07.html",
    "href": "A07.html",
    "title": "Appendix E — Appendix: The Law of Large Numbers",
    "section": "",
    "text": "E.1 Law of large numbers\nSuppose we observe data D=\\{x_1, \\ldots, x_n\\} with each x_i \\sim F .\nBy the strong law of large numbers the empirical distribution \\hat{F}_n based on data D=\\{x_1, \\ldots, x_n\\} converges to the true underlying distribution F as n \\rightarrow \\infty almost surely:\n\\hat{F}_n\\overset{a. s.}{\\to} F\nThe Glivenko–Cantelli asserts that the convergence is uniform. Since the strong law implies the weak law we also have convergence in probability:\n\\hat{F}_n\\overset{P}{\\to} F\nCorrespondingly, for n \\rightarrow \\infty the average \\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{i=1}^n h(x_i) converges to the expectation \\text{E}_{F}(h(x)) .",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Appendix: The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "A08.html",
    "href": "A08.html",
    "title": "Appendix F — Appendix: The Central Limit Theorem",
    "section": "",
    "text": "F.1 Central Limit Theorem\nThe Central Limit Theorem is one of the most important results in statistics, stating that with sufficiently large sample sizes, the sample average approximately follows a normal distribution. This underscores the importance of the normal distribution, as well as most of the methods commonly used which make assumptions about the data being normally distributed.\nLet’s first stop and think about what it means for the sample average to have a distribution. Imagine going to the store and buying a bag of your favorite brand of chocolate chip cookies. Suppose the bag has 24 cookies in it. Will each cookie have the exact same number of chocolate chips in it? It turns out that if you make a batch of cookies by adding chips to dough and mixing it really well, then putting the same amount of dough onto a baking sheet, the number of chips per cookie closely follows a Poisson distribution. (In the limiting case of chips having zero volume, this is exactly a Poisson process.) Thus we expect there to be a lot of variability in the number of chips per cookie. We can model the number of chips per cookie with a Poisson distribution. We can also compute the average number of chips per cookie in the bag. For the bag we have, that will be a particular number. But there may be more bags of cookies in the store. Will each of those bags have the same average number of chips? If all of the cookies in the store are from the same industrial-sized batch, each cookie will individually have a Poisson number of chips. So the average number of chips in one bag may be different from the average number of chips in another bag. Thus we could hypothetically find out the average number of chips for each bag in the store. And we could think about what the distribution of these averages is, across the bags in the store, or all the bags of cookies in the world. It is this distribution of averages that the central limit theorem says is approximately a normal distribution, with the same mean as the distribution for the individual cookies, but with a standard deviation that is divided by the square root of the number of samples in each average (i.e., the number of cookies per bag).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Appendix: The Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "A08.html#sec-cl-theorem",
    "href": "A08.html#sec-cl-theorem",
    "title": "Appendix F — Appendix: The Central Limit Theorem",
    "section": "",
    "text": "Theorem F.1 (Central Limit Theorem) Let X_1, ..., X_n be independent and identically distributed (IID) with \\mathbb{E}(X_i) = \\mu and Var(X_i) = \\sigma^2 &lt;\\infty\nThen:\n\n\\lim_{n\\to\\infty} \\sqrt{n} \\sum_{i=0}^{n} \\frac{1}{n}\\frac{(X_i-\\mu)}{\\sigma} = \\sum_{i=0}^{n} \\frac{X_i-\\mu}{\\sqrt{n} \\sigma} = N(0, 1)\n\nThat is, \\hat{X_n} is approximately normally distributed with mean µ and variance \\frac{\\sigma}{2/n} or standard deviation \\frac{\\sigma}{\\sqrt{n}}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Appendix: The Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "A09.html",
    "href": "A09.html",
    "title": "Appendix G — Appendix: Conjugate Priors",
    "section": "",
    "text": "G.1 Conjugate Priors",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Appendix: Conjugate Priors</span>"
    ]
  },
  {
    "objectID": "A09.html#sec-conjugate-priors",
    "href": "A09.html#sec-conjugate-priors",
    "title": "Appendix G — Appendix: Conjugate Priors",
    "section": "",
    "text": "Table G.1: Conjugate prior\n\n\n\n\n\n\n\n\n\n\n\nLikelihood\nConjugate prior\nPosterior\nPosterior predictive\n\n\n\n\n\\text{Bernoulli}(p)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle \\text{Beta}\\left( \\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +n-\\sum _{i=1}^{n}x_{i}\\right)}\n{\\displaystyle \\mathbb{P}r({\\tilde {x}}=1)={\\frac {\\alpha '}{\\alpha '+\\beta '}}}\n\n\n\\text{Binomial}(trials=m,p)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle \\text{Beta}\\left(\\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +\\sum _{i=1}^{n}N_{i}-\\sum _{i=1}^{n}x_{i}\\right)}\n{\\displaystyle \\operatorname {BetaBin} ({\\tilde {x}}|\\alpha ',\\beta ')}\n\n\n\\text{NegBinomial}(fails=r)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle \\text{Beta}\\left( \\alpha +rn,\\beta + \\sum _{i=1}^{n} x_{i}\\right)}\n{\\displaystyle \\operatorname {BetaNegBin} ({\\tilde {x}}|\\alpha ',\\beta ')}\n\n\n\\text{Poisson}(rate=\\lambda)\n\\text{Gamma}(k,\\theta)\n{\\displaystyle \\text{Gamma}\\left( k+\\sum _{i=1}^{n}x_{i},\\ {\\frac {\\theta }{n\\theta +1}}\\!\\right)}\n{\\displaystyle \\operatorname {NB} \\left({\\tilde {x}}\\mid k',{\\frac {1}{\\theta '+1}}\\right)}\n\n\n\\text{Poisson}(rate=\\lambda)\n\\text{Gamma}(\\alpha,\\beta)\n{\\displaystyle\\text{Gamma}\\left( \\alpha +\\sum _{i=1}^{n}x_{i},\\ \\beta +n\\!\\right)}\n{\\displaystyle \\operatorname {NB} \\left({\\tilde {x}}\\mid \\alpha ',{\\frac {\\beta '}{1+\\beta '}}\\right)}\n\n\n\\text{Categorical}(probs=p,cats=k)\n\\text{Dir}(\\alpha_k)\\mathbb{I}_{k\\ge1}\n{\\displaystyle \\text{Dir}\\left({ {\\boldsymbol {\\alpha }}+(c_{1},\\ldots ,c_{k})}\\right)}\n{\\displaystyle {\\begin{aligned}\\mathbb{P}r({\\tilde {x}}=i)&={\\frac {{\\alpha _{i}}'}{\\sum _{i}{\\alpha _{i}}'}} \\\\ &={\\frac {\\alpha _{i}+c_{i}}{\\sum _{i}\\alpha _{i}+n}}\\end{aligned}}}\n\n\n\\text{Multinomial}(probs=p,cats=k)\n\\text{Dir}(\\alpha_k)\\mathbb{I}_{k\\ge1}\n{\\displaystyle \\text{Dir}\\left({ {\\boldsymbol {\\alpha }}+\\sum _{i=1}^{n}\\mathbf {x} _{i}\\!}\\right)}\n{\\displaystyle \\operatorname {DirMult} ({\\tilde {\\mathbf {x} }}\\mid {\\boldsymbol {\\alpha }}')}\n\n\n\\text{Hypergeometric}(pop=n)\n\\text{BetaBinomial}(\\alpha,\\beta,n=N)\n{\\displaystyle \\text{BetaBinomial}\\left({\\displaystyle \\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +\\sum _{i=1}^{n}N_{i}-\\sum _{i=1}^{n}x_{i}}\\right)}\n\n\n\n\\text{Geometric}(p)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle\\text{Beta}\\left( \\alpha +n,\\,\\beta +\\sum _{i=1}^{n}x_{i}\\right)}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Appendix: Conjugate Priors</span>"
    ]
  },
  {
    "objectID": "A10.html",
    "href": "A10.html",
    "title": "Appendix H — Appendix: Link Function",
    "section": "",
    "text": "H.1 Link functions\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\nThe link function provides the relationship between the linear predictor and the mean of the distribution function. There are many commonly used link functions, and their choice is informed by several considerations. There is always a well-defined canonical link function which is derived from the exponential of the response’s density function. However, in some cases, it makes sense to try to match the domain of the link function to the range of the distribution function’s mean, or use a non-canonical link function for algorithmic purposes, for example Bayesian probit regression.\nWhen using a distribution function with a canonical parameter \\theta , the canonical link function is the function that expresses \\theta in terms of \\mu i.e. \\theta =b(\\mu) . For the most common distributions, the mean μ is one of the parameters in the standard form of the distribution’s Density function, and then b(\\mu ) is the function as defined above that maps the density function into its canonical form. When using the canonical link function, b(\\mu )=\\theta =\\mathbf {X} {\\boldsymbol {\\beta }} , which allows \\mathbf{X}^{T}\\mathbf{Y} to be a sufficient statistic for \\beta .\nFollowing is a table of several exponential-family distributions in common use and the data they are typically used for, along with the canonical link functions and their inverses (sometimes referred to as the mean function, as done here).\nIn the cases of the exponential and gamma distributions, the domain of the canonical link function is not the same as the permitted range of the mean. In particular, the linear predictor may be positive, which would give an impossible negative mean. When maximizing the likelihood, precautions must be taken to avoid this. An alternative is to use a non-canonical link function.\nIn the case of the Bernoulli, binomial, categorical and multinomial distributions, the support of the distributions is not the same type of data as the parameter being predicted. In all of these cases, the predicted parameter is one or more probabilities, i.e. real numbers in the range [0,1]. The resulting model is known as Logistic regression (or Multinomial logistic regression in the case that K-way rather than binary values are being predicted).\nFor the Bernoulli and binomial distributions, the parameter is a single probability, indicating the likelihood of occurrence of a single event. The Bernoulli still satisfies the basic condition of the generalized linear model in that, even though a single outcome will always be either 0 or 1, the expected value will nonetheless be a real-valued probability, i.e. the probability of occurrence of a “yes” (or 1) outcome. Similarly, in a binomial distribution, the expected value is Np, i.e. the expected proportion of “yes” outcomes will be the probability to be predicted.\nFor categorical and multinomial distributions, the parameter to be predicted is a K-vector of probabilities, with the further restriction that all probabilities must add up to 1. Each probability indicates the likelihood of occurrence of one of the K possible values. For the multinomial distribution, and for the vector form of the categorical distribution, the expected values of the elements of the vector can be related to the predicted probabilities similarly to the binomial and Bernoulli distributions.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Appendix: Link Function</span>"
    ]
  },
  {
    "objectID": "A10.html#sec-link-function",
    "href": "A10.html#sec-link-function",
    "title": "Appendix H — Appendix: Link Function",
    "section": "",
    "text": "Common distributions with typical uses and canonical link functions\n\n\n\n\n\n\n\n\n\n\nDistribution\nSupport\nUses\nLink name\nLink fn\nMean fn\n\n\n\n\nNormal\n\\mathbb{R}\n\nIdentity\n\\mathbf {X} {\\boldsymbol {\\beta }}=\\mu\n\n\n\nExpoential\n\\mathbb{R}^+_0\n\nNegative inverse\n\\mathbf {X} {\\boldsymbol {\\beta }}=-\\mu^{-1}\n\n\n\nGamma\n\\mathbb{R}^+_0\n\nNegative inverse\n\\mathbf {X} {\\boldsymbol {\\beta }}=-\\mu^{-1}\n\n\n\nInverse Gamma\n\\mathbb{R}^+_0\n\nInverse squared\n\\mathbf {X} {\\boldsymbol {\\beta }}=\\mu^{-2}\n\n\n\nPoisson\n\\mathbb{N}_0\n\nLog\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\mu)\n\n\n\nBernuolli\n\\{0,1\\}\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{1-\\mu})\n\n\n\nBinomial\n\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{n-\\mu})\n\n\n\nCategorical\n\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{1-\\mu})\n\n\n\nMultinomial\n\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{1-\\mu})",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Appendix: Link Function</span>"
    ]
  },
  {
    "objectID": "A10.html#credits",
    "href": "A10.html#credits",
    "title": "Appendix H — Appendix: Link Function",
    "section": "Credits:",
    "text": "Credits:\nThis page is based on the Generalized linear model article on Wikipedia, which is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License. By Wikimedia contributors, available under CC BY-SA 3.0.\nThe text has been modified for clarity and conciseness.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Appendix: Link Function</span>"
    ]
  },
  {
    "objectID": "A11.html",
    "href": "A11.html",
    "title": "Appendix I — Appendix: Bayes by backprop",
    "section": "",
    "text": "I.1 Introduction\nThis appendix reviews of a method to introduce weight uncertainty into neural networks called the “Bayes by Backprop” method introduced in (Blundell et al. 2015). where, the main question is how to determine the parameters of the distribution for each network weight. I learned about it from Probabilistic Deep Learning with TensorFlow 2 by Dr Kevin Webster, S reading from based this on\nThe authors note that prior work which considered uncertainty at the hidden unit (H_i) an approach that allows to state the uncertainty with respect to a particular observation and which is an easier problem since the number of weight is greater by two orders of magnitude. But considering the uncertainty in the weights is complementary, in the sense that it captures uncertainty about which neural network is appropriate, leading to regularization of the weights and model averaging. This weight uncertainty can be used to drive the exploration/exploitation in contextual bandit problems using Thompson sampling . Weights with greater uncertainty introduce more variability into the decisions made by the network, naturally leading to exploration. As more data are observed, the uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the environment is better understood.\nIn a traditional neural network, as shown in the upper left, each weight has a single value. But in the true value for these weights is not certain. Much of this uncertainty comes from imperfect training data, which is an approximation of the the distribution of the data generating process from which the data were sampled. Recall that this is called epistemic uncertainty, which we expect to decrease as the amount of training data increases.\nIn this method, we want to include such uncertainty in deep learning models. This is done by changing each weight from a single deterministic value to a probability distribution. We then learn the parameters of this distribution. Consider a neural network weight w_i . In a standard (deterministic) neural network, this has a single value \\hat{w}_i , learnt via backpropagation. In a neural network with weight uncertainty, each weight is represented by a probability distribution, and the parameters of this distribution are learned via backpropagation. Suppose, for example, that each weight has a normal distribution. This has two parameters: a mean \\mu_i and a standard deviation \\sigma_i .\nSince the weights are uncertain, the feedforward value of some input x_i is not constant. A single feedforward value is determined in two steps: 1. Sample each network weight from their respective distributions – this gives a single set of network weights. 2. Use these weights to determine a feedforward value \\hat{y}_i .\nHence, the key question is how to determine the parameters of the distribution for each network weight. The paper introduces exactly such a scheme, called Bayes by Backprop.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Appendix: Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#introduction",
    "href": "A11.html#introduction",
    "title": "Appendix I — Appendix: Bayes by backprop",
    "section": "",
    "text": "Fig. 1 from (Blundell et al. 2015) contrasting traditional and Bayesian neural networks\n\n\n\n\n\nClassic deterministic NN: w_i = \\hat{w}_i\nNN with weight uncertainty represented by normal distribution: w_i \\sim N(\\hat{\\mu}_i, \\hat{\\sigma}_i) .",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Appendix: Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#bayesian-learning",
    "href": "A11.html#bayesian-learning",
    "title": "Appendix I — Appendix: Bayes by backprop",
    "section": "I.2 Bayesian learning",
    "text": "I.2 Bayesian learning\nNote: We use the notation P to refer to a probability density. For simplicity, we’ll only consider continuous distributions (which have a density). In the case of discrete distributions, P would represent a probability mass and integrals should be changed to sums. However, the formulae are the same.\nWhat you need to know now is that Bayesian methods can be used to calculate the distribution of a model parameter given some data. In the context of weight uncertainty in neural networks, this is convenient, since we are looking for the distribution of weights (model parameters) given some (training) data. The key step relies on Bayes’ theorem. This theorem states, in mathematical notation, that\n\n\\mathbb{P}r(w \\mid D) = \\frac{\\mathbb{P}r(D \\mid w) \\mathbb{P}r(w)}{\\int \\mathbb{P}r(D \\mid w') \\mathbb{P}r(w') \\text{d}w'}\n\nwhere the terms mean the following:\n\nD is some data, e.g. x and y value pairs: D = \\{(x_1, y_1), \\ldots, (x_n, y_n)\\} . This is sometimes called the evidence.\nw is the value of a model weight.\n\\mathbb{P}r(w) is called the prior. This is our “prior” belief on the probability density of a model weight, i.e. the distribution that we postulate before seeing any data.\n\\mathbb{P}r(D \\mid w) is the likelihood of having observed data D given weight w . It is precisely the same likelihood used to calculate the negative log-likelihood.\n\\mathbb{P}r(w \\mid D) is the posterior density of the distribution of the model weight at value w , given our training data. It is called posterior since it represents the distribution of our model weight after taking the training data into account.\n\nNote that the term {\\int \\mathbb{P}r(D \\mid w') \\mathbb{P}r(w') \\text{d}w'} = \\mathbb{P}r(D) does not depend on w (as the w' is an integration variable). It is only a normalization term. For this reason, we will from this point on write Bayes’ theorem as\n\n\\mathbb{P}r(w \\mid D) = \\frac{\\mathbb{P}r(D \\mid w) \\mathbb{P}r(w)}{\\mathbb{P}r(D)}.\n\nBayes’ theorem gives us a way of combining data with some “prior belief” on model parameters to obtain a distribution for these model parameters that considers the data, called the posterior distribution.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Appendix: Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#bayesian-neural-network-with-weight-uncertainty-in-principle",
    "href": "A11.html#bayesian-neural-network-with-weight-uncertainty-in-principle",
    "title": "Appendix I — Appendix: Bayes by backprop",
    "section": "I.3 Bayesian neural network with weight uncertainty – in principle",
    "text": "I.3 Bayesian neural network with weight uncertainty – in principle\nThe above formula gives a way to determine the distribution of each weight in the neural network:\n\nPick a prior density \\mathbb{P}r(w) .\nUsing training data D , determine the likelihood \\mathbb{P}r(D \\mid w) .\nDetermine the posterior density \\mathbb{P}r(w \\mid D) using Bayes’ theorem.\n\nThis is the distribution of the NN weight.\nWhile this works in principle, in many practical settings it is difficult to implement. The main reason is that the normalization constant {\\int \\mathbb{P}r(D \\mid w') \\mathbb{P}r(w') \\text{d}w'} = \\mathbb{P}r(D) may be very difficult to calculate, as it involves solving or approximating a complicated integral. For this reason, approximate methods, such as Variational Bayes described below, are often employed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Appendix: Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#variational-bayes",
    "href": "A11.html#variational-bayes",
    "title": "Appendix I — Appendix: Bayes by backprop",
    "section": "I.4 Variational Bayes",
    "text": "I.4 Variational Bayes\n Variational Bayes methods approximate the posterior distribution with a second function, called a variational posterior. This function has a known functional form, and hence avoids the need to determine the posterior \\mathbb{P}r(w \\mid D) exactly. Of course, approximating a function with another one has some risks, since the approximation may be very bad, leading to a posterior that is highly inaccurate. In order to mediate this, the variational posterior usually has a number of parameters, denoted by \\theta , that are tuned so that the function approximates the posterior as well as possible. Let’s see how this works below.\nInstead of \\mathbb{P}r(w \\mid D) , we assume the network weight has density q(w \\mid \\theta) , parameterized by \\theta . q(w \\mid \\theta) is known as the variational posterior . We want q(w \\mid \\theta) to approximate \\mathbb{P}r(w \\mid D) , so we want the “difference” between q(w \\mid \\theta) and \\mathbb{P}r(w \\mid D) to be as small as possible. This “difference” between the two distributions is measured by the Kullback-Leibler divergence D_{\\text{KL}} (note that this is unrelated to the D we use to denote the data). The Kullback-Leibler divergence between two distributions with densities f(x) and g(x) respectively is defined as\n\nD_{KL} (f(x) \\parallel g(x)) = \\int f(x) \\log \\left( \\frac{f(x)}{g(x)} \\right) \\text{d} x\n\nNote that this function has value 0 (indicating no difference) when f(x) \\equiv g(x) , which is the result we expect. We use the convention that \\frac{0}{0} = 1 here.\n Viewing the data D as a constant, the Kullback-Leibler divergence between q(w \\mid \\theta) and \\mathbb{P}r(w \\mid D) is hence:\n\n\\begin{aligned}\n  D_{KL} (q(w \\mid \\theta) \\parallel \\mathbb{P}r(w \\mid D)) &= \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta)}{\\mathbb{P}r(w \\mid D)} \\right) \\text{d} w \\\\\n&= \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta) \\mathbb{P}r(D)}{\\mathbb{P}r(D \\mid w) \\mathbb{P}r(w)} \\right) \\text{d} w \\\\\n&= \\int q(w \\mid \\theta) \\log \\mathbb{P}r(D) \\text{d} w + \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta)}{\\mathbb{P}r(w)} \\right) \\text{d} w - \\int q(w \\mid \\theta) \\log \\mathbb{P}r(D \\mid w) \\text{d} w \\\\\n&= \\log \\mathbb{P}r(D) + D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w))\n\\end{aligned}\n\nwhere, in the last line, we have used\n\n\\int q(w \\mid \\theta) \\log \\mathbb{P}r(D) \\text{d}w = \\log \\mathbb{P}r(D) \\int q(w \\mid \\theta) \\text{d} w = \\log \\mathbb{P}r(D)\n\nsince q(w \\mid \\theta) is a probability distribution and hence integrates to 1. If we consider the data D to be constant, the first term is a constant also, and we may ignore it when minimizing the above. Hence, we are left with the function\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w))\n\\end{aligned}\n\nNote that this function depends only on \\theta and D , since w is an integration variable. This function has a nice interpretation as the sum of: - The Kullback-Leibler divergence between the variational posterior q(w \\mid \\theta) and the prior \\mathbb{P}r(w) . This is called the complexity cost, and it depends on \\theta and the prior but not the data D . - The expectation of the negative log likelihood \\log \\mathbb{P}r(D \\mid w) under the variational posterior q(w \\mid \\theta) . This is called the likelihood cost and it depends on \\theta and the data but not the prior.\nL(\\theta \\mid D) is the loss function that we minimize to determine the parameter \\theta . Note also from the above derivation, that we have\n\n\\begin{aligned}\n\\log \\mathbb{P}r(D) &= \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) - D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) + D_{KL} (q(w \\mid \\theta) \\parallel \\mathbb{P}r(w \\mid D))\\\\\n&\\ge \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) - D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) =: ELBO\n\\end{aligned}\n\nwhich follows because\n\nD_{KL} (q(w \\mid \\theta) \\parallel \\mathbb{P}r(w \\mid D))\n\nis non negative. The final expression on the right hand side is therefore a lower bound on the log-evidence, and is called the evidence lower bound, often shortened to ELBO. The ELBO is the negative of our loss function, so minimizing the loss function is equivalent to maximizing the ELBO.\nMaximizing the ELBO requires a trade off between the KL term and expected log-likelihood term. On the one hand, the divergence between q(w \\mid \\theta) and \\mathbb{P}r(w) should be kept small, meaning the variational posterior shouldn’t be too different to the prior. On the other, the variational posterior parameters should maximize the expectation of the log-likelihood \\log \\mathbb{P}r(D \\mid w) , meaning the model assigns a high likelihood to the data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Appendix: Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#a-backpropagation-scheme",
    "href": "A11.html#a-backpropagation-scheme",
    "title": "Appendix I — Appendix: Bayes by backprop",
    "section": "I.5 A backpropagation scheme",
    "text": "I.5 A backpropagation scheme\n\nI.5.1 The idea\nWe can use the above ideas to create a neural network with weight uncertainty, which we will call a Bayesian neural network. From a high level, this works as follows. Suppose we want to determine the distribution of a particular neural network weight w .\n\nAssign the weight a prior distribution with density \\mathbb{P}r(w) , which represents our beliefs on the possible values of this network before any training data. This may be something simple, like a unit Gaussian. Furthermore, this prior distribution will usually not have any trainable parameters.\nAssign the weight a variational posterior with density q(w \\mid \\theta) with some trainable parameter \\theta .\nq(w \\mid \\theta) is the approximation for the weight’s posterior distribution. Tune \\theta to make this approximation as accurate as possible as measured by the ELBO.\n\nThe remaining question is then how to determine \\theta . Recall that neural networks are typically trained via a backpropagation algorithm, in which the weights are updated by perturbing them in a direction that reduces the loss function. We aim to do the same here, by updating \\theta in a direction that reduces L(\\theta \\mid D) .\nHence, the function we want to minimise is\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) \\\\\n&= \\int q(w \\mid \\theta) ( \\log q(w \\mid \\theta) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w) ) \\text{d}w.\n\\end{aligned}\n\nIn principle, we could take derivatives of L(\\theta \\mid D) with respect to \\theta and use this to update its value. However, this involves doing an integral over w , and this is a calculation that may be impossible or very computationally expensive. Instead, we want to write this function as an expectation and use a Monte Carlo approximation to calculate derivatives. At present, we can write this function as\n\nL(\\theta \\mid D) = \\mathbb{E}_{q(w \\mid \\theta)} ( \\log q(w \\mid \\theta) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w) )\n\nHowever, taking derivatives with respect to \\theta is difficult because the underlying distribution the expectation is taken with respect to depends on \\theta . One way we can handle this is with the reparameterization trick.\n\n\nI.5.2 The reparameterization trick\nThe reparameterization trick is a way to move the dependence on \\theta around so that an expectation may be taken independently of it. It’s easiest to see how this works with an example. Suppose q(w \\mid \\theta) is a Gaussian, so that \\theta = (\\mu, \\sigma) . Then, for some arbitrary f(w; \\mu, \\sigma) , we have\n\n\\begin{aligned}\n\\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\int q(w \\mid \\mu, \\sigma) f(w; \\mu, \\sigma) \\text{d}w \\\\\n&= \\int \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( -\\frac{1}{2 \\sigma^2} (w - \\mu)^2 \\right) f(w; \\mu, \\sigma) \\text{d}w \\\\\n&= \\int \\frac{1}{\\sqrt{2 \\pi}} \\exp \\left( -\\frac{1}{2} \\varepsilon^2 \\right) f \\left( \\mu + \\sigma \\varepsilon; \\mu, \\sigma \\right) \\text{d}\\varepsilon \\\\\n&= \\mathbb{E}_{\\varepsilon \\sim N(0, 1)} (f \\left( \\mu + \\sigma \\varepsilon; \\mu, \\sigma \\right) )\n\\end{aligned}\n\nwhere we used the change of variable w = \\mu + \\sigma \\varepsilon . Note that the dependence on \\theta = (\\mu, \\sigma) is now only in the integrand and we can take derivatives with respect to \\mu and \\sigma:\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\mu} \\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\frac{\\partial}{\\partial \\mu} \\mathbb{E}_{\\varepsilon \\sim N(0, 1)} (f \\left( w; \\mu, \\sigma \\right) ) = \\mathbb{E}_{\\varepsilon \\sim N(0, 1)} \\frac{\\partial}{\\partial \\mu} f \\left( \\mu + \\sigma \\varepsilon; \\mu, \\sigma \\right)\n\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\sigma} \\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\frac{\\partial}{\\partial \\sigma} \\mathbb{E}_{\\varepsilon \\sim N(0, 1)} (f \\left( w; \\mu, \\sigma \\right) ) = \\mathbb{E}_{\\varepsilon \\sim N(0, 1)} \\frac{\\partial}{\\partial \\sigma} f \\left( \\mu + \\sigma \\varepsilon; \\mu, \\sigma \\right)\n\\end{aligned}\n\nFinally, note that we can approximate the expectation by its Monte Carlo estimate:\n\n\\begin{aligned}\n\\mathbb{E}_{\\varepsilon \\sim N(0, 1)}  \\frac{\\partial}{\\partial \\theta} f \\left( \\mu + \\sigma \\varepsilon; \\mu, \\sigma \\right) \\approx \\sum_{i}  \\frac{\\partial}{\\partial \\theta} f \\left( \\mu + \\sigma \\varepsilon_i; \\mu, \\sigma \\right),\\qquad \\varepsilon_i \\sim N(0, 1).\n\\end{aligned}\n\nThe above reparameterization trick works in cases where we can write the w = g(\\varepsilon, \\theta) , where the distribution of the random variable \\varepsilon is independent of \\theta .\n\n\nI.5.3 Implementation\nPutting this all together, for our loss function L(\\theta \\mid D) \\equiv L(\\mu, \\sigma \\mid D) , we have\n\nf(w; \\mu, \\sigma) = \\log q(w \\mid \\mu, \\sigma) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w)\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\mu} L(\\mu, \\sigma \\mid D) \\approx \\sum_{i} \\left( \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\mu} \\right)\n\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\sigma} L(\\mu, \\sigma \\mid D) \\approx \\sum_{i} \\left( \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} \\varepsilon_i + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\sigma} \\right)\n\\end{aligned}\n\n\nf(w; \\mu, \\sigma) = \\log q(w \\mid \\mu, \\sigma) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w)\n\nwhere w_i = \\mu + \\sigma \\varepsilon_i, \\, \\varepsilon_i \\sim N(0, 1) . In practice, we often only take a single sample \\varepsilon_1 for each training point. This leads to the following backpropagation scheme:\n\nSample \\varepsilon_i \\sim N(0, 1) . 2. Let w_i = \\mu + \\sigma \\varepsilon_i\nCalculate\n\n\n\\nabla_{\\mu}f = \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\mu} \\hspace{3em} \\nabla_{\\sigma}f = \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} \\varepsilon_i + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\sigma}\n\n\nUpdate the parameters with some gradient-based optimizer using the above gradients.\n\nThis is how we learn the parameters of the distribution for each neural network weight.\n\n\nI.5.4 Minibatches\nNote that the loss function (or negative of the ELBO) is\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) \\\\\n& = D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\sum_{j=1}^N \\log \\mathbb{P}r(y_j, x_j \\mid w_j)\n\\end{aligned}\n\nwhere j runs over all the data points in the training data (N in total) and w_j = \\mu + \\sigma \\varepsilon_j is sampled using \\varepsilon_j \\sim N(0, 1) (we assume a single sample from the approximate posterior per data point for simplicity).\nIf training occurs in minibatches of size B , typically much smaller than N , we instead have a loss function\n\n\\begin{aligned}\nD_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\sum_{j=1}^{B} \\log \\mathbb{P}r(y_j, x_j \\mid w_j).\n\\end{aligned}\n\nNote that the scaling factors between the first and second terms have changed, since before the sum ran from 1 to N , but it now runs from 1 to B . To correct for this, we should add a correction factor \\frac{N}{B} to the second term to ensure that its expectation is the same as before. This leads to the loss function, after dividing by N to take the average per training value, of\n\n\\begin{aligned}\n\\frac{1}{N} D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\frac{1}{B} \\sum_{j=1}^{B} \\log \\mathbb{P}r(y_j, x_j \\mid w_j).\n\\end{aligned}\n\nBy default, when Tensorflow calculates the loss function, it calculates the average across the minibatch. Hence, it already uses the factor \\frac{1}{B} present on the second term. However, it does not, by default, divide the first term by N . In an implementation, we will have to specify this. You’ll see in the next lectures and coding tutorials how to do this.\n\n\nI.5.5 Conclusion\nWe introduced the Bayes by Backpropagation method, which can be used to embed weight uncertainty into neural networks. Good job getting through it, as the topic is rather advanced. This approach allows the modelling of epistemic uncertainty on the model weights. We expect that, as the number of training points increases, the uncertainty on the model weights decreases. This can be shown to be the case in many settings. In the next few lectures and coding tutorials, you’ll learn how to apply these methods to your own models, which will make the idea much clearer.\n\n\nI.5.6 Further reading and resources\n\nBayes by backprop paper (Blundell et al. 2015)\nWikipedia article on Bayesian inference\n\n\n\n\n\n\n\nBlundell, Charles, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015. “Weight Uncertainty in Neural Networks.” https://doi.org/10.48550/ARXIV.1505.05424.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Appendix: Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A12.html",
    "href": "A12.html",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "",
    "text": "J.1 Introduction to Probability\nA number of books on Bayesian statistics and time series analysis are available in both R and Python. A number of these are introduced in the specilization and many others are worth mentioning.\nThere are many books in R and Python that can help you learn more about these languages and how to use them for data analysis.\nHere are some of the most popular books on R and Python:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#introduction-to-probability",
    "href": "A12.html#introduction-to-probability",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "",
    "text": "Introduction to Probability by Dennis L. Sun",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#sec-bayesian-books",
    "href": "A12.html#sec-bayesian-books",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "J.2 Books in R",
    "text": "J.2 Books in R\n\nR for Data Science by Hadley Wickham & Garrett Grolemund\nAdvanced R by Hadley Wickham\nggplot2: Elegant Graphics for Data Analysis (3e)\nR Graphics Cookbook, 2nd edition\nAn Introduction to Statistical Learning\nEngineering Production-Grade Shiny Apps\nForecasting: Principles and Practice (3rd ed)\nExploratory Data Analysis with R Roger D. Peng\nModern R with the tidyverse by Bruno Rodrigues\nModern Statistics with R by Benjamin S. Baumer, Daniel T. Kaplan, and Nicholas J. Horton\nMastering Shiny by Hadley Wickham, Winston Chang, and Joe Cheng\nLearning Statistics with R by Danielle Navarro\nText Mining with R by Julia Silge and David Robinson",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#books-in-python",
    "href": "A12.html#books-in-python",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "J.3 Books in Python",
    "text": "J.3 Books in Python\n\n(James et al. 2013) An Introduction to Statistical Learning with python by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\n(McKinney 2022) Python for Data Analysis by Wes McKinney of Pandas infamy parquet and Apache Arrow\n(VanderPlas 2016) Python Data Science Handbook by Jake VanderPlas\nThink Stats by Allen B. Downey\nThink Bayes by Allen B. Downey\nProbabilistic Programming & Bayesian Methods for Hackers by Cameron Davidson-Pilon",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#bayesian-statistics-techniques-and-models",
    "href": "A12.html#bayesian-statistics-techniques-and-models",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "J.4 Bayesian Statistics: Techniques and Models",
    "text": "J.4 Bayesian Statistics: Techniques and Models\nAt the end of the course there is a handout called further reading. In this course the following titles are recommended for further reading and reference, unfortunately some of the links were out of date.\n\n\n\n\n\n\n\nFigure J.1: Doing Bayesian Data Analysis\n\n\n(Kruschke 2011) Doing Bayesian Data Analysis this is the favorite on Bayesian statistics. It is a great book for learning Bayesian statistics and covers a wide range of topics in Bayesian modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields. This text is recommended for further reading in the course 2\n\n\n\n\n\n\n\nFigure J.2: Statistical Rethinking\n\n\n(McElreath 2015) Statistical Rethinking: A Bayesian Course with Examples in R and Stan by Richard McElreath is, the runner up in terms of a popular book on Bayesian Statistics. This book is a great resource for learning Bayesian statistics and covers a wide range of topics in Bayesian modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields. McElreath is a gifted and entertaining explainer but he is not a full-fledged statistician. I find that in most cases the examples in this book are rather weak and challenging to adapt to real life settings. On the other hand his use of metaphors and his ability to pass on his intuition is unparalleled and has helped to shape my own thinking about statistics as is evidenced by the many references to his work in these notes. This text is recommended for further reading in the course 2\n\n\n\n\n\n\n\nFigure J.3: Bayesian Data Analysis\n\n\n(Gelman et al. 2013) Bayesian Data Analysis by Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, Donald B. Rubin. This book is considered the Graduate level text on Bayesian statistics and covers a wide range of topics in Bayesian data analysis. The book is suitable for graduate students and researchers in statistics, computer science, and related fields. This book is harder to read than the previous two books. I’d recommend reading and viewing McElreath’s book and videos first and only then moving to this book later. This text is recommended for further reading in the course 2 but with a cautionary caveat that a solid background in calculus-based probability will be useful, as many details are left to the reader. I took an undergraduate course in probability and statistics that was based on measure theory but I’m not sure this was the kind of background these authors have in mind.\n\n\n\n\n\n\n\nFigure J.4: The BUGS book\n\n\n(Lunn et al. 2012) The BUGS book: A Practical Introduction to Bayesian Analysis is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian modeling, computation, and inference. IT focuses on simulation using BUGS. This text is recommended for further reading in the course 2\nSome addition books that were mentioned in the course bibliography:\n(Carlin and Louis 2008) Bayesian Methods for Data Analysis\n(Agresti 2012) This is a graduate level book on categorical data which often poses extra challenges for Bayesian statistics. Section 17.5 covers Bayesian methods for Categorical Data.\n(Spiegelhalter et al. 2002) “Measures of Model Complexity and Fit” by David Spiegelhalter, Andrew Thomas, Nicky Best, and W. Brian Gilks. This paper considers the problem of model selection in Bayesian Hierarchical Models and proposes a new measure of model complexity and fit, the Deviance Information Criterion (DIC).\n(Banerjee, Gelfand, and Carlin 2026) Hierarchical Modeling and Analysis for Spatial Data by Sudipto Banerjee, Bradley P. Carlin, and Alan E. Gelfand. This book is a comprehensive introduction to hierarchical modeling and analysis for spatial data and covers a wide range of topics in spatial statistics, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields. data etc\n(Carlin and Louis 2008) Bayesian Methods for Data Analysis\n(Gelman and Hill 2006) This is too is a classic book on data analysis using regression and multilevel/hierarchical models. I read this one may years ago and is fairly approachable and recommended Unless the next edition has come out?",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#mixture-models",
    "href": "A12.html#mixture-models",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "J.5 Mixture Models",
    "text": "J.5 Mixture Models\n\n\n\n\n\n\n\nFigure J.5: Finite Mixture and Markov Switching Models\n\n\nThere were no books recommended in this course but (Frühwirth-Schnatter 2006) was in the bibliography from the previous course. Finite Mixture and Markov Switching Models by Sylvia Frühwirth-Schnatter. This book is a comprehensive introduction to finite mixture and Markov switching models and covers a wide range of topics in mixture modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n(Fruhwirth-Schnatter, Celeux, and Robert 2019) Handbook of Mixture Analysis by Christian P. Robert, Gilles Celeux, Sylvia Fruhwirth-Schnatter\n(McLachlan and Peel 2004) Finite Mixture Models by Geoffrey J. McLachlan and David Peel. A comprehensive account of major issues in finite mixture modeling. Advanced text on finite mixture models. Lacks exercises and requires deep diving into papers.\n(Chen 2023) Statistical Inference Under Mixture Models by Jiahua Chen. A more recent introduction to mixture models with recent developments in testing hypothesis for the order of the mixture and insights on inference for mixture models.\n(Yao and Xiang 2024) Mixture Models: Parametric, Semiparametric, and New Directions by Weixin Yao and Sijia Xiang.\n(Visser and Speekenbrink 2022) Mixture and Hidden Markov Models with R by Visser, I. and Speekenbrink, M.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#non-parametric-bayesian-statistics",
    "href": "A12.html#non-parametric-bayesian-statistics",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "J.6 Non-parametric Bayesian Statistics",
    "text": "J.6 Non-parametric Bayesian Statistics\n(Bayesian Nonparametrics 2010) “Bayesian Nonparametrics” by Peter M. Hjort, Chris Holmes, Maria E. Müller, and Stephen G. Walker. This book is a comprehensive introduction to Bayesian nonparametric methods and covers a wide range of topics in nonparametric modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#bayesian-time-series-bibliography",
    "href": "A12.html#bayesian-time-series-bibliography",
    "title": "Appendix J — Bayesian Books in R & Python",
    "section": "J.7 Bayesian Time Series Bibliography",
    "text": "J.7 Bayesian Time Series Bibliography\nWe start with some books from the course, I collected here both the recommended books and some others that I found useful.\n\n\n\n\n\n\n\nFigure J.6: Bayesian Forecasting and Dynamic Models\n\n\n(West and Harrison 2013) Bayesian Forecasting and Dynamic Models by Mike West and Jeff Harrison. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian forecasting and dynamic models. The book is suitable for graduate students and researchers in statistics, computer science, and related fields. This is a much easier read than the following book and is a great introduction to Bayesian time series analysis. It soon became my goto reference for understanding the more challenging aspects of the course. It provides simple explanations with better motivations.\nI have some criticism. The authors sometimes become very meta discussing their models at very abstract level that is more relevant to philosophy majors than statistics. For example a dynamic model is a defined as a set of models whose parameters may change at any index of time series. That’s a very poor definition - its like asking us to use a 1:1 map for navigation. When I took a course on function approximation in RL we got a much neater exposition to parameterization of to very similar markov state space models. I found that the white noise model getting a very extensive treatment, perhaps, because it is easier to analyze. This is a random walk and the rudiments of which are easily taught in a single high-school lesson. They also digress into statistical war stories type anecdotes that rather than instil confidence that the authors know what they are talking about they are effectively making a case that they failed to communicate effectively with their clients with disastrous effect. Mathematically the book is very much self contained and this shows great integrity. I’ve seen some talks by Mike West in which he highlights research by his students and this are great if very challenging to follow.\nThe authors also published a second book [Applied Bayesian Forecasting and Time Series Analysis]](https://www2.stat.duke.edu/~mw/bats.html) this one is based on the BATS software package which is no longer maintained. However it does contain a large number of datasets\n\n\n\n\n\n\n\nFigure J.7: Time Series: Modeling, Computation, and Inference\n\n\n(Prado, Ferreira, and West 2023) Time Series: Modeling, Computation, and Inference by course instructor Raquel Prado and Marco A. R. Ferreira, Mike West. This book, now in its second edition is a comprehensive introduction to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nWhile learning this course I found some of the material harder to follow than I expected. The book helped to clarify definitions and so on however the book is rather comprehensive and mathematically advanced unlike some other books on statistics.\nThe teacher frequently point out that many aspects of Times series and are beyond the scope of the course. Yet this book covers much more ground like unequally spaced time series and vector valued time series.\nFor example we look at EKG data which the authors have been working on for years. However we look at it in this course in terms of a univariate time series while in reality EKG is usually sampled at 12 sites simultaneously yielding a multi-variate time series.\nOnce this course is done I will probably want to dive deeper into the subject and try to devote more time to other models in the book.\nc.f. (Nielsen 2019)\n\n\n\n\n\n\n\nFigure J.8: Practical Times Series Analysis\n\n\n(Nielsen 2019) Practical Time Series Analysis: Prediction with Statistics and Machine Learning by Aileen Nielsen. Is a good resource for practitioners getting started with time series analysis. I also recommend any videos by Aileen Nielsen on the subject. In many ways this is a recommended introductory book on time series analysis. It covers, finding and wrangle time series data. EDA for TS. How to store temporal data. Simulate time series data. Generate and select features for a time series. Estimate errors, evaluate accuracy and performance. Forecast and classify time series with machine or deep learning.\n\n\n\n\n\n\n\nFigure J.9: Statistical Analysis in Climate Research\n\n\n(Storch and Zwiers 2002) Statistical Analysis in Climate Research I came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks promising. Here is the description from the publisher:\n\nClimatology is, to a large degree, the study of the statistics of our climate. The powerful tools of mathematical statistics therefore find wide application in climatological research. The purpose of this book is to help the climatologist understand the basic precepts of the statistician’s art and to provide some of the background needed to apply statistical methodology correctly and usefully. The book is self contained: introductory material, standard advanced techniques, and the specialized techniques used specifically by climatologists are all contained within this one source. There are a wealth of real-world examples drawn from the climate literature to demonstrate the need, power and pitfalls of statistical analysis in climate research. Suitable for graduate courses on statistics for climatic, atmospheric and oceanic science, this book will also be valuable as a reference source for researchers in climatology, meteorology, atmospheric science, and oceanography.\n\n\nHans von Storch is Director of the Institute of Hydrophysics of the GKSS Research Centre in Geesthacht, Germany and a Professor at the Meteorological Institute of the University of Hamburg.\n\n\nFrancis W. Zwiers is Chief of the Canadian Centre for Climate Modelling and Analysis, Atmospheric Environment Service, Victoria, Canada, and an Adjunct Professor at the Department of Mathematics and Statistics of the University of Victoria.\n\n\n\n\n\n\n\n\nFigure J.10: Bayesian Modeling and Computation in Python\n\n\n(Martin, Kumar, and Lao 2021) Bayesian Modeling and Computation in Python by Osvaldo Martin is a great book for learning Bayesian statistics and covers a wide range of topics in Bayesian modeling, computation, and inference. I found the chapter on state space modeling and the Kalman filter particularly useful. The book is a great resource for translating what we learned in the course to Python. The book is suitable for undergraduate students in statistics, computer science, and related fields.\n\n\n\n\n\n\n\nFigure J.11: Introductory Time Series with R\n\n\n(Cowpertwait and Metcalfe 2009) Introductory Time Series with R by Cowpertwait and Metcalfe\n\nYearly global mean temperature and ocean levels, daily share prices, and the signals transmitted back to Earth by the Voyager space craft are all examples of sequential observations over time known as time series. This book gives you a step-by-step introduction to analyzing time series using the open source software R. Each time series model is motivated with practical applications, and is defined in mathematical notation. Once the model has been introduced it is used to generate synthetic data, using R code, and these generated data are then used to estimate its parameters. This sequence enhances understanding of both the time series model and the R function used to fit the model to data. Finally, the model is used to analyze observed data taken from a practical application. By using R, the whole procedure can be reproduced by the reader.\nAll the data sets used in the book are available on the website at datasets\nThe book is written for undergraduate students of mathematics, economics, business and finance, geography, engineering and related disciplines, and postgraduate students who may need to analyze time series as part of their taught programme or their research.\n\nPaul Cowpertwait is an associate professor in mathematical sciences (analytics) at Auckland University of Technology with a substantial research record in both the theory and applications of time series and stochastic models.\nAndrew Metcalfe is an associate professor in the School of Mathematical Sciences at the University of Adelaide, and an author of six statistics text books and numerous research papers. Both authors have extensive experience of teaching time series to students at all levels.\n\n\n\n\n\n\n\nFigure J.12: Analysis of Integrated and Cointegrated Time Series with R\n\n\n(Pfaff 2008) “Analysis of Integrated and Cointegrated Time Series with R” by Bernhard Pfaff. Its been a long time since I read this book and rather than do it an injustice I direct you to the review by Dirk Eddelbuettel in the Journal of Statistical Software is available at review. Or the book’s website at Analysis of Integrated and Cointegrated Time Series with R.\n\nThe analysis of integrated and co-integrated time series can be considered as the main methodology employed in applied econometrics. This book not only introduces the reader to this topic but enables him to conduct the various unit root tests and co-integration methods on his own by utilizing the free statistical programming environment R. The book encompasses seasonal unit roots, fractional integration, coping with structural breaks, and multivariate time series models. The book is enriched by numerous programming examples to artificial and real data so that it is ideally suited as an accompanying text book to computer lab classes.\nThe second edition adds a discussion of vector auto-regressive, structural vector auto-regressive, and structural vector error-correction models.\n\n(Broemeling 2019) Bayesian Analysis of Time Series by Lyle D. Broemeling\nIn many branches of science relevant observations are taken sequentially over time. Bayesian Analysis of Time Series discusses how to use models that explain the probabilistic characteristics of these time series and then utilizes the Bayesian approach to make inferences about their parameters. This is done by taking the prior information and via Bayes theorem implementing Bayesian inferences of estimation, testing hypotheses, and prediction. The methods are demonstrated using both R and WinBUGS. The R package is primarily used to generate observations from a given time series model, while the WinBUGS packages allows one to perform a posterior analysis that provides a way to determine the characteristic of the posterior distribution of the unknown parameters.\nThe book covers pretty much the material in the course. It uses R and WinBUGS to demonstrate the models and methods. Models considered include: white noise, Wiener process (random walk), AR(p),ARMA(p,q), ARIMA, Regression, Regression with MA and Seasonal effects, DLM , TAR\n\n\n\n\n\n\n\nFigure J.13: Bayesian Inference for Stochastic Processes by Lyle D. Broemeling\n\n\n(Broemeling 2019) Bayesian Inference for Stochastic Processes by Lyle D. Broemeling is a comprehensive introduction to the analysis of stochastic processes using Bayesian methods. The book covers a wide range of topics in stochastic process modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields. The code for R and WinBUGS is available at code It is based on WinBUGS which is a bit dated but still useful and a bit dated but it covers a lot of the material in the course.\n\n\n\n\n\n\n\nFigure J.14: Dynamic Time Series Models using R-INLA: An Applied Perspective\n\n\n(Ravishanker, Raman, and Soyer 2022) Dynamic Time Series Models using R-INLA: An Applied Perspective is a new book that covers the use of the R-INLA package for fitting dynamic time series models. The book is available online gitbook\nThis is a very interesting book which covers a new approach to fitting time series models using the R-INLA package. INLA stands for Integrated Nested Laplace Approximation and is a method for fitting Bayesian models that is faster than MCMC. The book covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n\n\n\n\n\nFigure J.15: Statistics for Spatio-Temporal Data\n\n\n(Cressie and Wikle 2011) Statistics for Spatio-Temporal Data is a book I came across when I tried to understand the NDLM model. NDLMs have a two level hierarchical form and it seems possible to extend this formulation will non-normally distributed shocks and possibly non linear relation. In this book the authors take an interesting approach of not only looking at NDLM as a hierarchical model but they also extend the time series model into a spatio-temporal model.\nThis book is a comprehensive introduction to the analysis of spatio-temporal data and covers a wide range of topics in spatio-temporal statistics. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\na newer title from the authors is:\n\n\n\n\n\n\n\nFigure J.16: Spatio-Temporal Statistics with R\n\n\n(Wikle, Zammit-Mangion, and Cressie 2019) Spatio-Temporal Statistics with R\n\n\n\n\n\n\n\nFigure J.17: Bayesian Analysis of Stochastic Process Models\n\n\n(Rios Insua, Ruggeri, and Wiper 2012) Bayesian Analysis of Stochastic Process Models by David Rios Insua, Fabrizio Ruggeri, Michael P. Wiper. This book is a comprehensive introduction to the analysis of stochastic process models using Bayesian methods. It covers a wide range of topics in stochastic process modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nThere are also a number of books on NDLM that I’ve come across:\nDynamic linear model tutorial matlab\nForecasting, structural time series and the Kalman filter by Andrew C. Harvey\nDynamic Linear Models with R by Giovanni Petris Sonia Petrone Patrizia Campagnoli\nTime Series Analysis by State Space Methods by J. Durbin and S.J. Koopman\n\n\n\n\n\n\n\nFigure J.18: Machine Learning: A Bayesian and Optimization Perspective\n\n\n(Theodoridis 2015) Machine Learning: A Bayesian and Optimization Perspective Has two chapters on bayesian learning which are summarized in this summer school slide deck. I came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks like a good book on machine learning and the slide deck indicates it covers some of the essential material missing from this specialization like particle filtering.\n\n\n\n\n\n\nAgresti, A. 2012. Categorical Data Analysis. Wiley Series in Probability and Statistics. Wiley. https://books.google.co.il/books?id=UOrr47-2oisC.\n\n\nBanerjee, S., A. E. Gelfand, and B. P. Carlin. 2026. Hierarchical Modeling and Analysis for Spatial Data. CRC Press LLC. https://books.google.co.il/books?id=GRFT0QEACAAJ.\n\n\nBayesian Nonparametrics. 2010. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press.\n\n\nBroemeling, Lyle D. 2019. Bayesian Analysis of Time Series. CRC Press.\n\n\nCarlin, B. P., and T. A. Louis. 2008. Bayesian Methods for Data Analysis. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=GTJUt8fcFx8C.\n\n\nChen, J. 2023. Statistical Inference Under Mixture Models. ICSA Book Series in Statistics. Springer Nature Singapore. https://books.google.co.il/books?id=sBXlEAAAQBAJ.\n\n\nCowpertwait, P. S. P., and A. V. Metcalfe. 2009. Introductory Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=QFiZGQmvRUQC.\n\n\nCressie, N., and C. K. Wikle. 2011. Statistics for Spatio-Temporal Data. CourseSmart Series. Wiley. https://books.google.co.il/books?id=-kOC6D0DiNYC.\n\n\nFruhwirth-Schnatter, S., G. Celeux, and C. P. Robert. 2019. Handbook of Mixture Analysis. Chapman & Hall/CRC Handbooks of Modern Statistical Methods. CRC Press. https://books.google.co.il/books?id=N3yCDwAAQBAJ.\n\n\nFrühwirth-Schnatter, S. 2006. Finite Mixture and Markov Switching Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=f8KiI7eRjYoC.\n\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. Bayesian Data Analysis, Third Edition. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis.\n\n\nGelman, Andrew, and Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. Analytical Methods for Social Research. Cambridge University Press. https://books.google.co.il/books?id=c9xLKzZWoZ4C.\n\n\nJames, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. An Introduction to Statistical Learning: With Applications in r. Springer Texts in Statistics. Springer New York. https://books.google.co.il/books?id=qcI_AAAAQBAJ.\n\n\nKruschke, John K. 2011. Doing Bayesian Data Analysis: A Tutorial with R and BUGS. Burlington, MA: Academic Press. http://www.amazon.com/Doing-Bayesian-Data-Analysis-Tutorial/dp/0123814855.\n\n\nLunn, D., C. Jackson, N. Best, A. Thomas, and D. Spiegelhalter. 2012. The BUGS Book: A Practical Introduction to Bayesian Analysis. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis. https://books.google.co.il/books?id=Cthz3XMa_VQC.\n\n\nMartin, Osvaldo A., Ravin Kumar, and Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. Boca Raton.\n\n\nMcElreath, Richard. 2015. Statistical Rethinking, a Course in r and Stan.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and Jupyter. 3rd ed. O’Reilly Media.\n\n\nMcLachlan, G. J., and D. Peel. 2004. Finite Mixture Models. Wiley Series in Probability and Statistics. Wiley. https://books.google.co.il/books?id=c2_fAox0DQoC.\n\n\nNielsen, A. 2019. Practical Time Series Analysis: Prediction with Statistics and Machine Learning. O’Reilly Media. https://books.google.co.il/books?id=xNOwDwAAQBAJ.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=ca5MkRbF3fYC.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nRavishanker, N., B. Raman, and R. Soyer. 2022. Dynamic Time Series Models Using r-INLA: An Applied Perspective. CRC Press.\n\n\nRios Insua, David, Fabrizio Ruggeri, and Michael P Wiper. 2012. Bayesian Analysis of Stochastic Process Models. John Wiley & Sons.\n\n\nSpiegelhalter, David J., Nicola G. Best, Bradley P. Carlin, and Angelika Van Der Linde. 2002. “Bayesian Measures of Model Complexity and Fit.” Journal of the Royal Statistical Society Series B: Statistical Methodology 64 (4): 583–639. https://doi.org/10.1111/1467-9868.00353.\n\n\nStorch, H. von, and F. W. Zwiers. 2002. Statistical Analysis in Climate Research. Cambridge University Press.\n\n\nTheodoridis, S. 2015. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science.\n\n\nVanderPlas, Jake. 2016. Python Data Science Handbook: Essential Tools for Working with Data. 1st ed. O’Reilly Media, Inc. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nVisser, I., and M. Speekenbrink. 2022. Mixture and Hidden Markov Models with r. Use r! Springer International Publishing. https://books.google.co.il/books?id=Eep3EAAAQBAJ.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.\n\n\nWikle, C. K., A. Zammit-Mangion, and N. Cressie. 2019. Spatio-Temporal Statistics with r. Chapman & Hall/CRC the r Series. CRC Press. https://books.google.co.il/books?id=FD-IDwAAQBAJ.\n\n\nYao, W., and S. Xiang. 2024. Mixture Models: Parametric, Semiparametric, and New Directions. Chapman & Hall/CRC Monographs on Statistics and Applied Probability. CRC Press. https://books.google.co.il/books?id=scP9EAAAQBAJ.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A13.html",
    "href": "A13.html",
    "title": "Appendix K — Appendix: Yule-Walker Equations & Durbin-Levinson Recursion",
    "section": "",
    "text": "K.1 Durbin-Levinson recursion\nDurbin-Levinson recursion is a method in linear algebra for computing the solution to an equation involving a Toeplitz matrix AKA a diagonal-constant matrix where descending diagonals are constant. The recursion runs in O(n^2) time rather then O(n^3) time required by Gauss-Jordan elimination.\nIn the course on Bayesian time series analysis, the Professor mentions the Durbin-Levinson recursion several times without explaining what this is. It is a shame as it is a very elegant bit of linear algebra for solving the Yule-Walker equations more efficiently. I tried to find a good explanation in the context of the course, However I wrote some notes that can help you understand this topic. One final point is that Durbin-Levinson recursion is not the last word on solving this system of equations. There are today numerous improvements which are both faster and more numerically stable!\nLike me, you might be curious about the Durbin-Levinson recursion mentioned above. This is not covered in the course, and turned out to be an enigma wrapped in a mystery.\nI present my finding in the note below - much of it is due to (Wikipedia contributors 2024b) and (Wikipedia contributors 2024a)\nIn (Yule 1927) and (Walker 1931), Yule and Walker proposed a method for estimating the parameters of an autoregressive model. The method is based on the Yule-Walker equations which are a set of linear equations that can be used to estimate the parameters of an autoregressive model.\nDue to the autoregressive structure of the model, the matrix for these equations is sparse and of a well known form called a Toeplitz matrix. \n\\begin{array}{c} {\\displaystyle \\qquad {\\begin{bmatrix}a&b&c&d&e\\\\f&a&b&c&d\\\\g&f&a&b&c\\\\h&g&f&a&b\\\\i&h&g&f&a\\end{bmatrix}}.} \\end{array}\n\\tag{K.1}\nIn the 1930s, Yule and Walker would have had to solve these equations using Gauss-Jordan elimination which has an O(n^3) time complexity.\nThis is where Durbin and Levinson come in. A decade or two later in (Levinson 1946) and (Durbin 1960) the authors came up for with a weakly stable yet more efficient algorithm for solving these autocorrelated system of equations which requires only O(n^2) in time complexity. Later their work was further refined in (Trench 1964) and (Zohar 1969) to just 3\\times n^2 multiplication.\nA cursory search reveals that Toeplitz matrix inversion is still an area of active research with papers covering parallel algorithms and stability studies. Not surprising as most of the more interesting deep learning models, including LLMs are autoregressive!\nSo the Durbin-Levinson recursion is just an elegant bit of linear algebra for solving the Yule-Walker equations more efficiently.\nHere is what I dug up:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Appendix: Yule-Walker Equations & Durbin-Levinson Recursion</span>"
    ]
  },
  {
    "objectID": "A13.html#sec-durbin-levinson",
    "href": "A13.html#sec-durbin-levinson",
    "title": "Appendix K — Appendix: Yule-Walker Equations & Durbin-Levinson Recursion",
    "section": "",
    "text": "K.1.1 Durbin-Levinson and the Yule-Walker equations (Off-Course Reading)\nThe Durbin-Levinson recursion is a method in linear algebra for computing the solution to an equation involving a Toeplitz matrix AKA a diagonal-constant matrix where descending diagonals are constant. The recursion runs in O(n^2) time rather then O(n^3) time required by Gauss-Jordan elimination.\nThe recursion can be used to compute the coefficients of the autoregressive model of a stationary time series. It is based on the Yule-Walker equations and is used to compute the PACF of a time series.\nThe Yule-Walker equations can be stated as follows for an AR(p) process:\n\n\\gamma_m = \\sum_{k=1}^p \\phi_k \\gamma_{m-k} + \\sigma_\\varepsilon^2\\delta_{m,0} \\qquad \\text{(Yule-Walker equations)}\n\\tag{K.2}\nwhere:\n\n\\gamma_m is the autocovariance function of the time series,\n\\phi_k are the AR coefficients,\n\\sigma_\\varepsilon^2 is the variance of the white noise process, and\n\\delta_{m,0} is the Kronecker delta function.\n\nwhen m=0 the equation simplifies to:\n\n\\gamma_0 = \\sum_{k=1}^p \\phi_k \\gamma_{-k} + \\sigma_\\varepsilon^2 \\qquad \\text{(Yule-Walker equations for m=0)}\n\\tag{K.3}\nfor m &gt; 0 the equation simplifies to:\n\n  \\begin{bmatrix}\n    \\gamma_1 \\\\\n    \\gamma_2 \\\\\n    \\gamma_3 \\\\\n    \\vdots   \\\\\n    \\gamma_p\n  \\end{bmatrix} =  \n  \\begin{bmatrix}\n    \\gamma_0     & \\gamma_{-1}  & \\gamma_{-2}  & \\cdots \\\\\n    \\gamma_1     & \\gamma_0     & \\gamma_{-1}  & \\cdots \\\\\n    \\gamma_2     & \\gamma_1     & \\gamma_0     & \\cdots \\\\\n    \\vdots       & \\vdots       & \\vdots       & \\ddots \\\\\n    \\gamma_{p-1} & \\gamma_{p-2} & \\gamma_{p-3} & \\cdots\n\\end{bmatrix}  \n\\begin{bmatrix}\n    \\phi_{1} \\\\\n    \\phi_{2} \\\\\n    \\phi_{3} \\\\\n    \\vdots   \\\\\n    \\phi_{p}\n\\end{bmatrix}\n\n and since this matrix is Toeplitz, we can use Durbin-Levinson recursion to efficiently solve the system for \\phi_k \\forall k.\nOnce \\{\\phi_m \\qquad m=1,2, \\dots ,p \\} are known, we can consider m=0 and solved for \\sigma_\\varepsilon^2 by substituting the \\phi_k into Equation K.3 Yule-Walker equations.\nOf course the Durbin-Levinson recursion is not the last word on solving this system of equations. There are today numerous improvements which are both faster and more numerically stable.\nThe Yule-Walker equations are a set of p linear equations in the p unknowns \\phi_1, \\phi_2, \\ldots, \\phi_p that can be used to estimate the parameters of an autoregressive model of order p. The Yule-Walker equations are derived by setting the sample autocorrelation function equal to the theoretical autocorrelation function of an AR(p) model and then solving for the unknown parameters. The Yule-Walker equations are given by:\n\n\\begin{aligned}\n\\gamma(0) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(2) + \\ldots + \\phi_p \\gamma(p) \\\\\n\\gamma(1) & = \\phi_1 \\gamma(0) + \\phi_2 \\gamma(1) + \\ldots + \\phi_p \\gamma(p-1) \\\\\n\\gamma(2) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(0) + \\ldots + \\phi_p \\gamma(p-2) \\\\\n\\vdots \\\\\n\\gamma(p) & = \\phi_1 \\gamma(p-1) + \\phi_2 \\gamma(p-2) + \\ldots + \\phi_p \\gamma(0) \\\\\n\\end{aligned}\n\nwhere \\gamma(k) is the sample autocorrelation function at lag k. The Yule-Walker equations can be solved using matrix algebra to obtain the estimates of the AR parameters \\phi_1, \\phi_2, \\ldots, \\phi_p.\n\n\n\n\n\n\nDurbin, J. 1960. “The Fitting of Time-Series Models.” Revue de l’Institut International de Statistique / Review of the International Statistical Institute 28 (3): 233–44. http://www.jstor.org/stable/1401322.\n\n\nLevinson, Norman. 1946. “The Wiener (Root Mean Square) Error Criterion in Filter Design and Prediction.” Journal of Mathematics and Physics 25 (1-4): 261–78. https://doi.org/https://doi.org/10.1002/sapm1946251261.\n\n\nTrench, William F. 1964. “An Algorithm for the Inversion of Finite Toeplitz Matrices.” Journal of the Society for Industrial and Applied Mathematics 12 (3): 515–22. http://ramanujan.math.trinity.edu/wtrench/research/papers/TRENCH_RP_6.PDF.\n\n\nWalker, Gilbert Thomas. 1931. “On Periodicity in Series of Related Terms.” Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character 131 (818): 518–32. https://doi.org/10.1098/rspa.1931.0069.\n\n\nWikipedia contributors. 2024a. “Autoregressive Model — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Autoregressive_model&oldid=1233171855#Estimation_of_AR_parameters.\n\n\n———. 2024b. “Levinson Recursion — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Levinson_recursion&oldid=1229942891.\n\n\nYule, George Udny. 1927. “VII. On a Method of Investigating Periodicities Disturbed Series, with Special Reference to Wolfer’s Sunspot Numbers.” Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character 226 (636-646): 267–98. https://doi.org/10.1098/rsta.1927.0007.\n\n\nZohar, Shalhav. 1969. “Toeplitz Matrix Inversion: The Algorithm of w. F. Trench.” J. ACM 16: 592–601. https://api.semanticscholar.org/CorpusID:3115290.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Appendix: Yule-Walker Equations & Durbin-Levinson Recursion</span>"
    ]
  },
  {
    "objectID": "A14.html",
    "href": "A14.html",
    "title": "Appendix L — Moore-Penrose Inversion & Cholesky Decomposition",
    "section": "",
    "text": "L.1 Properties of transpose\nThe Moore-Penrose inversion and the Cholesky decomposition are two important methods in linear algebra for solving linear equations efficiently. They are widely used in various applications, including statistics, machine learning, and numerical analysis.\ntranspose of a row vector is a column vector and vice versa:\nkA^{T} = {kA}^T \\qquad \\text{scalar multiplication }\n\\tag{L.1}\n(A^{T})^T = A \\qquad \\text { involution }\n\\tag{L.2}\n(A+B)^{T} = A^T + B^T \\qquad\\text {  distributivity under addition }\n\\tag{L.3}\n(AB)^T = B^T A^T \\qquad\\text {   anti }\n\\tag{L.4}\nnote that we swap the order of the matrices in the product when taking the transpose.\nif A is a square matrix, then the following are equivalent: \nSq = A^t*A = A*A^t\n where Sq is a symmetric positive definite matrix.\nSk = A^t*A = A*A^t",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Moore-Penrose Inversion & Cholesky Decomposition</span>"
    ]
  },
  {
    "objectID": "A14.html#sec-full-rank",
    "href": "A14.html#sec-full-rank",
    "title": "Appendix L — Moore-Penrose Inversion & Cholesky Decomposition",
    "section": "L.2 Full Rank",
    "text": "L.2 Full Rank\nA matrix is said to be of full row rank if its rows are linearly independent, and it is of full column rank if its columns are linearly independent. A matrix is said to be of full rank if it is either of full row rank or full column rank.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Moore-Penrose Inversion & Cholesky Decomposition</span>"
    ]
  },
  {
    "objectID": "A14.html#sec-moore-penrose",
    "href": "A14.html#sec-moore-penrose",
    "title": "Appendix L — Moore-Penrose Inversion & Cholesky Decomposition",
    "section": "L.3 Generelised (Moore-Penrose) Inverse",
    "text": "L.3 Generelised (Moore-Penrose) Inverse\nThe Moore-Penrose inversion is a method for computing the pseudoinverse of a matrix. The pseudoinverse is a generalization of the inverse of a matrix that can be used to solve linear equations when the matrix is rectangular, not-invertible or even singular.\n\nDefinition L.1 (Definition of the Moore-Penrose Inverse 1) The Moore–Penrose inverse of the m × n matrix A is the n × m matrix, denoted by A^+, which satisfies the conditions\n\nAA+ A = A\n\\tag{L.5}\n  \nA^+AA^+ = A^+\n\\tag{L.6}\n\n(AA^+ )' = AA^+\n\\tag{L.7}\n\n(A^+A)' = A^+A\n\\tag{L.8}\n\nAn important features of the Moore–Penrose inverse, is that it is uniquely defined.\nCorresponding to each m × n matrix A, one and only one n × m matrix A^+ exists satisfying conditions (Equation L.5)–(Equation L.8).\nDefinition Definition L.1 is the definition of a generalized inverse given by Penrose (1955).\nThe following alternative definition, which we will find useful on some occasions, utilizes properties of the Moore–Penrose inverse that were first illustrated by Moore (1935).\n\nDefinition L.2 (Definition of the Moore-Penrose Inverse 2) Let A be an m × n matrix. Then the Moore–Penrose inverse of A is the unique n × m matrix A^+ satisfying\n\nAA^+ = P_{R(A)}\n\\tag{L.9}\n\nA^+ A = P_{R(A^+)}\n\\tag{L.10}\nwhere P_{R(A)} and P_{R(A^+)} are the projection matrices of the range spaces of A and A^+, respectively.\n\n\nTheorem L.1 (Properties of the Moore-Penrose inverse) Let A be an m \\times n matrix. Then:\n\n(αA)^+ = α^{-1} A^+ , \\text{ if } \\alpha \\ne 0 \\text{ is a scalar}\n(A^T)^+ = (A^+)^T\n(A^+)^+ = A\nA^+ = A^{-1} ,\\text{if A is square and nonsingular}\n(A^T A)^+ = A^+ A^T and (AA^T)^+ = A^T A^+\n(AA^+)^+ = AA^+ and (A^+ A)^+ = A^+ A\nA^+ = (A^T A)^+ A^T = A^T (AA^T)^+\nA^+ = (A^T A)^{-1} A^T and A^+ A = I_n , \\text{ if } rank(A) = n\nA^+ = A^T (AA^T)^{-1} and AA^+ = I_m , \\text{ if } rank(A) = m\nA^+ = A^T if the columns of A are orthogonal, that is, A^T A = I_n\n\n\n\nTheorem L.2 (Rank of Moore-Penrose Inverse) For any m \\times n matrix A, \\text{rank}(A) = \\text{rank}(A^+) = \\text{rank}(AA^+) = \\text{rank}(A^+ A).\n\n\nTheorem L.3 (Symmetric Moore-Penrose Inverse) Let A be an m × m symmetric matrix. Then a. A^+ is also symmetric, b. AA^+ = $A^+A, c. A^+ = A, if A is idempotent.\n\n\nThe Moore-Penrose inverse is particularly useful in maximum likelihood estimation (MLE) for linear models. In MLE, we often need to solve linear equations of the form Ax = b, where A is the design matrix and b is the response vector. If A is not full rank or is not square, we can use the Moore-Penrose inverse to find a solution that minimizes the residual sum of squares.\nIn the context of MLE, the Moore-Penrose inverse allows us to obtain parameter estimates even when the design matrix is singular or when there are more predictors than observations. This is achieved by projecting the response vector onto the column space of the design matrix, leading to a solution that is consistent and has desirable statistical properties.\nwe start with:\n\ny = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol\\varepsilon \\qquad \\boldsymbol\\varepsilon \\sim \\mathcal{N} (0, v\\mathbf{I})\n\nwe want MLE of \\boldsymbol{\\beta}, which is given by: \n\\hat{\\boldsymbol{\\beta}}_{NKE} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T y\n\nAlso in the baysian setting we can show that MLE is equivalent to minimizing the negative log-likelihood function, under a uniform prior on \\boldsymbol{\\beta}, which is equivalent to minimizing the residual sum of squares.\nwe can show that if we use least squares AKA l_2 norm minimization, we will end up with the Moore-Penrose inverse to find the solution:\nwe can write this explicitly as:\n\n\\mathbb{E}_{l_2}(\\boldsymbol{\\beta}) = \\frac{1}{2} \\sum (y - \\boldsymbol{\\beta}^T \\mathbf{X})^2",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Moore-Penrose Inversion & Cholesky Decomposition</span>"
    ]
  },
  {
    "objectID": "A14.html#sec-cholesky",
    "href": "A14.html#sec-cholesky",
    "title": "Appendix L — Moore-Penrose Inversion & Cholesky Decomposition",
    "section": "L.4 Cholesky Decomposition",
    "text": "L.4 Cholesky Decomposition\nThe Cholesky decomposition is a method for factorizing a positive definite matrix into the product of a lower triangular matrix and its transpose. It is particularly useful for solving systems of linear equations and for generating samples from multivariate normal distributions.\n\nDefinition L.3 (Definition of the Cholesky Decomposition) André-Louis Cholesky (1875–1918) was a cartographer in the French army, who introduced a method for decomposing a symmetric positive definite matrix into the product of a lower triangular matrix and its transpose. This decomposition is known as the Cholesky decomposition.\nLet A be a symmetric positive definite matrix. The Cholesky decomposition of A is a factorization of the form: \nA = LL^T\n\\tag{L.11} where L is a lower triangular matrix with positive diagonal entries.\n\nThe Cholesky decomposition is unique for a given positive definite matrix, and it can be computed efficiently using algorithms such as the Doolittle algorithm or the Crout algorithm.\n\nL.4.1 Doolittle Algorithm\n\ndef doolittle(A):\n    \"\"\"Performs Doolittle LU decomposition: A = LU, with L unit lower triangular and U upper triangular.\"\"\"\n    n = len(A)\n    L = [[0.0]*n for _ in range(n)]\n    U = [[0.0]*n for _ in range(n)]\n    \n    for i in range(n):\n        # Upper Triangular\n        for k in range(i, n):\n            U[i][k] = A[i][k] - sum(L[i][j]*U[j][k] for j in range(i))\n        \n        # Lower Triangular\n        L[i][i] = 1.0\n        for k in range(i+1, n):\n            if U[i][i] == 0:\n                raise ZeroDivisionError(\"Zero pivot encountered.\")\n            L[k][i] = (A[k][i] - sum(L[k][j]*U[j][i] for j in range(i))) / U[i][i]\n    \n    return L, U\n\n\ndef print_matrix(M, name=\"Matrix\"):\n    print(f\"{name} =\")\n    for row in M:\n        print(\"  [\" + \"  \".join(f\"{val:8.3f}\" for val in row) + \"]\")\n    print()\n\n\nA = [\n    [2, 3, 1],\n    [4, 7, 7],\n    [6, 18, 22]\n]\n\nprint_matrix(A, name=\"A\")\n\n\nL, U = doolittle(A)\nprint_matrix(L, name=\"L\")\nprint_matrix(U, name=\"U\")\n\nA =\n  [   2.000     3.000     1.000]\n  [   4.000     7.000     7.000]\n  [   6.000    18.000    22.000]\n\nL =\n  [   1.000     0.000     0.000]\n  [   2.000     1.000     0.000]\n  [   3.000     9.000     1.000]\n\nU =\n  [   2.000     3.000     1.000]\n  [   0.000     1.000     5.000]\n  [   0.000     0.000   -26.000]\n\n\n\n\n\nL.4.2 Doolittle’s Algorithm with Partial Pivoting\nWhen performing LU decomposition, it is often necessary to use partial pivoting to ensure numerical stability and to handle cases where the matrix may be singular or nearly singular. Partial pivoting involves swapping rows of the matrix to place the largest absolute value in the pivot position.\nAdding partial pivoting is algebraically equivalent to multiplying the original matrix by a permutation matrix P, such that PA = LU, where P is a permutation matrix, L is a lower triangular matrix, and U is an upper triangular matrix.\n\ndef doolittle_partial_pivoting(A):\n    \"\"\"Performs LU decomposition with partial pivoting: PA = LU.\"\"\"\n    n = len(A)\n    # Deep copy of A\n    A = [row[:] for row in A]\n    P = list(range(n))\n    L = [[0.0]*n for _ in range(n)]\n    U = [[0.0]*n for _ in range(n)]\n\n    for k in range(n):\n        # Partial pivoting: find row with max abs value in column k\n        pivot_row = max(range(k, n), key=lambda i: abs(A[i][k]))\n        if A[pivot_row][k] == 0:\n            raise ZeroDivisionError(\"Matrix is singular.\")\n\n        # Swap rows in A and record permutation\n        A[k], A[pivot_row] = A[pivot_row], A[k]\n        P[k], P[pivot_row] = P[pivot_row], P[k]\n        for i in range(k):\n            L[k][i], L[pivot_row][i] = L[pivot_row][i], L[k][i]\n\n        # Compute U[k][k:] and L[k+1:][k]\n        L[k][k] = 1.0\n        for j in range(k, n):\n            U[k][j] = A[k][j] - sum(L[k][s]*U[s][j] for s in range(k))\n        for i in range(k+1, n):\n            L[i][k] = (A[i][k] - sum(L[i][s]*U[s][k] for s in range(k))) / U[k][k]\n\n    # Permutation matrix P as a 2D matrix\n    P_matrix = [[1 if j == P[i] else 0 for j in range(n)] for i in range(n)]\n    return P_matrix, L, U\n\nDemo for Doolittle’s algorithm with partial pivoting:\n\nA = [\n    [0, 3, 1],\n    [4, 7, 7],\n    [6, 18, 22]\n]\n\nprint_matrix(A, name=\"A\")\n\n\nP, L, U = doolittle_partial_pivoting(A)\nprint_matrix(P, name=\"P\")\nprint_matrix(L, name=\"L\")\nprint_matrix(U, name=\"U\")\n\nA =\n  [   0.000     3.000     1.000]\n  [   4.000     7.000     7.000]\n  [   6.000    18.000    22.000]\n\nP =\n  [   0.000     0.000     1.000]\n  [   0.000     1.000     0.000]\n  [   1.000     0.000     0.000]\n\nL =\n  [   1.000     0.000     0.000]\n  [   0.667     1.000     0.000]\n  [   0.000    -0.600     1.000]\n\nU =\n  [   6.000    18.000    22.000]\n  [   0.000    -5.000    -7.667]\n  [   0.000     0.000    -3.600]\n\n\n\n\nA = [\n    [2, 1, 1, 3, 2],\n    [1, 2, 2, 1, 1],\n    [3, 2, 3, 2, 1],\n    [2, 1, 2, 2, 1],\n    [1, 1, 1, 1, 1]\n]\n\nP, L, U = doolittle_partial_pivoting(A)\n\nprint_matrix(P, \"P\")\nprint_matrix(L, \"L\")\nprint_matrix(U, \"U\")\n\ndef matmul(A, B):\n    return [[sum(A[i][k] * B[k][j] for k in range(len(B)))\n             for j in range(len(B[0]))]\n            for i in range(len(A))]\n\ndef permute(A, P):\n    \"\"\"P is a permutation matrix; return PA.\"\"\"\n    return matmul(P, A)\n\nPA = permute(A, P)\nLU = matmul(L, U)\n\n# Print comparison\nprint_matrix(PA, \"PA\")\nprint_matrix(LU, \"LU\")\n\nP =\n  [   0.000     0.000     1.000     0.000     0.000]\n  [   0.000     1.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     1.000     0.000]\n  [   1.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     1.000]\n\nL =\n  [   1.000     0.000     0.000     0.000     0.000]\n  [   0.333     1.000     0.000     0.000     0.000]\n  [   0.667    -0.250     1.000     0.000     0.000]\n  [   0.667    -0.250    -3.000     1.000     0.000]\n  [   0.333     0.250    -1.000     0.250     1.000]\n\nU =\n  [   3.000     2.000     3.000     2.000     1.000]\n  [   0.000     1.333     1.000     0.333     0.667]\n  [   0.000     0.000     0.250     0.750     0.500]\n  [   0.000     0.000     0.000     4.000     3.000]\n  [   0.000     0.000     0.000     0.000     0.250]\n\nPA =\n  [   3.000     2.000     3.000     2.000     1.000]\n  [   1.000     2.000     2.000     1.000     1.000]\n  [   2.000     1.000     2.000     2.000     1.000]\n  [   2.000     1.000     1.000     3.000     2.000]\n  [   1.000     1.000     1.000     1.000     1.000]\n\nLU =\n  [   3.000     2.000     3.000     2.000     1.000]\n  [   1.000     2.000     2.000     1.000     1.000]\n  [   2.000     1.000     2.000     2.000     1.000]\n  [   2.000     1.000     1.000     3.000     2.000]\n  [   1.000     1.000     1.000     1.000     1.000]\n\n\n\n\n\nL.4.3 Vectorization of the doolittle algorithm\n\nimport numpy as np\n\ndef doolittle_numpy(A):\n    \"\"\"LU decomposition with partial pivoting using NumPy. Returns P, L, U such that PA = LU.\"\"\"\n    A = np.array(A, dtype=float)\n    n = A.shape[0]\n    P = np.eye(n)\n    L = np.zeros((n, n))\n    U = A.copy()\n\n    for k in range(n):\n        # Partial pivoting\n        pivot = np.argmax(abs(U[k:, k])) + k\n        if U[pivot, k] == 0:\n            raise ZeroDivisionError(\"Matrix is singular.\")\n        if pivot != k:\n            U[[k, pivot]] = U[[pivot, k]]\n            P[[k, pivot]] = P[[pivot, k]]\n            L[[k, pivot], :k] = L[[pivot, k], :k]\n\n        L[k, k] = 1.0\n        L[k+1:, k] = U[k+1:, k] / U[k, k]\n        U[k+1:] -= np.outer(L[k+1:, k], U[k])\n\n    return P, L, U\n\n\ndef random_sign_matrix(n, seed=None):\n    \"\"\"Generate an n×n matrix with random entries in {-1, 0, 1}.\"\"\"\n    rng = np.random.default_rng(seed)\n    return rng.choice([-1, 0, 1], size=(n, n))\n\nA = [\n    [2, 3, 1],\n    [4, 7, 7],\n    [6, 18, 22]\n]\nA = random_sign_matrix(16, seed=42)\n\nprint_matrix(A, name=\"A\")\n\nP, L, U = doolittle_numpy(A)\n\nprint_matrix(P, name=\"P\")\n\nprint_matrix(L, name=\"L\")\n\nprint_matrix(U, name=\"U\")\n\nA =\n  [  -1.000     1.000     0.000     0.000     0.000     1.000    -1.000     1.000    -1.000    -1.000     0.000     1.000     1.000     1.000     1.000     1.000]\n  [   0.000    -1.000     1.000     0.000     0.000     0.000    -1.000     1.000     1.000     0.000     0.000     1.000     0.000     0.000     0.000    -1.000]\n  [  -1.000     0.000     1.000    -1.000     1.000     1.000    -1.000     0.000    -1.000     1.000     1.000     0.000    -1.000     1.000     0.000     1.000]\n  [   1.000     1.000     1.000    -1.000     0.000     0.000     0.000    -1.000     0.000    -1.000     1.000     1.000     1.000     1.000     0.000     1.000]\n  [   0.000    -1.000     1.000     0.000    -1.000     0.000     1.000    -1.000     0.000    -1.000     1.000     0.000    -1.000    -1.000     0.000     1.000]\n  [   1.000     0.000    -1.000     1.000     0.000     1.000    -1.000    -1.000     1.000     1.000     0.000     1.000     1.000     0.000     1.000    -1.000]\n  [  -1.000     1.000     0.000    -1.000     1.000    -1.000     1.000    -1.000     1.000     1.000     1.000     0.000     0.000     1.000    -1.000     1.000]\n  [   0.000     0.000     0.000     0.000    -1.000    -1.000    -1.000    -1.000     0.000     1.000     0.000     0.000     1.000     0.000    -1.000     1.000]\n  [   0.000     0.000     0.000     0.000    -1.000     0.000     1.000    -1.000     0.000    -1.000     0.000     0.000     1.000    -1.000    -1.000     0.000]\n  [   1.000     1.000    -1.000    -1.000     1.000    -1.000     1.000    -1.000     1.000    -1.000     0.000     0.000    -1.000     0.000     0.000     1.000]\n  [   1.000     0.000     0.000     0.000     0.000     1.000    -1.000    -1.000     0.000    -1.000    -1.000    -1.000     1.000     1.000     1.000     0.000]\n  [   1.000    -1.000     1.000     0.000     1.000    -1.000     0.000     1.000     0.000     0.000    -1.000     0.000    -1.000    -1.000     1.000     0.000]\n  [   0.000     0.000     1.000    -1.000     0.000    -1.000     0.000     1.000     0.000     1.000     0.000     1.000     0.000    -1.000     1.000     1.000]\n  [  -1.000     1.000    -1.000     1.000     1.000     0.000     1.000    -1.000    -1.000    -1.000     0.000     1.000    -1.000     0.000     1.000    -1.000]\n  [   1.000    -1.000     1.000     0.000     0.000    -1.000     0.000     1.000    -1.000     1.000     0.000     1.000     0.000     0.000    -1.000     0.000]\n  [  -1.000     0.000    -1.000     0.000     0.000    -1.000     1.000     0.000     1.000    -1.000    -1.000     0.000    -1.000    -1.000     0.000    -1.000]\n\nP =\n  [   1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.000]\n\nL =\n  [   1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [  -1.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [  -1.000     1.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [  -1.000     0.500     0.750     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [  -1.000     0.000    -0.500     0.000     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   1.000    -0.500    -0.750    -1.000     0.667     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [  -0.000     0.000    -0.000     0.000    -0.667    -0.571     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   1.000     0.000     0.500     0.667     0.667    -0.714    -0.938     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [   1.000     0.000    -0.000    -0.667     0.333    -0.143    -0.187     0.537     1.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [  -0.000    -0.500    -0.750    -0.333     0.333     0.286     0.375    -0.232     0.670     1.000     0.000     0.000     0.000     0.000     0.000     0.000]\n  [  -1.000     0.500     0.250     0.333     0.000     0.429     0.125    -0.189    -0.393     0.619     1.000     0.000     0.000     0.000     0.000     0.000]\n  [  -0.000     0.000    -0.500    -0.667     0.000     0.000     0.438    -0.242     0.214    -0.636    -0.177     1.000     0.000     0.000     0.000     0.000]\n  [  -1.000     0.000    -0.500     0.000     0.333    -0.143     0.250    -0.211    -0.625    -0.996    -0.786     0.408     1.000     0.000     0.000     0.000]\n  [  -0.000     0.000    -0.000     0.000    -0.667    -0.143    -0.188     0.032    -0.161     0.360     0.480     0.771     0.733     1.000     0.000     0.000]\n  [  -0.000    -0.500    -0.750    -0.333    -0.333     0.143    -0.250     0.042    -0.045     0.933     0.070     0.108     0.143     0.431     1.000     0.000]\n  [   1.000    -0.500     0.250    -0.333    -0.333    -0.286     0.062     0.158     0.554     0.895     0.568     0.802     0.025     0.140    -0.221     1.000]\n\nU =\n  [  -1.000     1.000     0.000     0.000     0.000     1.000    -1.000     1.000    -1.000    -1.000     0.000     1.000     1.000     1.000     1.000     1.000]\n  [   0.000     2.000     1.000    -1.000     0.000     1.000    -1.000     0.000    -1.000    -2.000     1.000     2.000     2.000     2.000     1.000     2.000]\n  [   0.000     0.000    -2.000     0.000     1.000    -1.000     1.000     0.000     1.000     0.000    -1.000    -1.000    -2.000    -1.000     0.000     0.000]\n  [   0.000     0.000     0.000     1.500    -0.750     2.250    -2.250     0.000    -0.250     1.000     0.250     1.750     2.500     0.750     1.500    -1.000]\n  [   0.000     0.000     0.000     0.000     1.500    -0.500    -0.500     2.000    -0.500    -1.000    -1.500     0.500    -1.000    -0.500     2.000     1.000]\n  [   0.000     0.000     0.000     0.000     0.000     2.333    -1.667    -2.333     0.333     2.667     2.000     0.667     0.667     1.333    -0.333    -0.667]\n  [   0.000     0.000     0.000     0.000     0.000     0.000    -2.286    -1.000    -0.143     1.857     0.143     0.714     0.714     0.429     0.143     1.286]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000    -5.938     0.104     3.646     2.896     0.146    -0.854     0.688    -2.437    -1.271]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.965     1.772     0.425     0.151     1.688     0.568    -0.379    -0.172]\n  [   0.000     0.000     0.000     0.000     0.000    -0.000     0.000     0.000     0.000    -2.134     0.095     1.141    -1.120    -0.096     0.064    -1.137]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000    -1.551    -2.328     1.486     0.788     0.474     0.854]\n  [   0.000     0.000     0.000     0.000     0.000    -0.000     0.000     0.000     0.000     0.000     0.000     1.671    -0.663    -1.065     1.553    -1.072]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.449     2.208    -1.697    -0.149]\n  [   0.000     0.000     0.000     0.000     0.000    -0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000    -2.134     0.123     1.760]\n  [   0.000     0.000     0.000     0.000     0.000    -0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     1.765     2.843]\n  [   0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.802]\n\n\n\n\n\nL.4.4 Crout’s Algorithm\nCrout’s algorithm is another method for performing LU decomposition, similar to Doolittle’s algorithm. It constructs the lower triangular matrix L directly, while the upper triangular matrix U is obtained from the original matrix A.\nthe key parts are the formula for computing the entries of L:\n\nL[i][j] = A[i][j] - \\sum_{k=0}^{j-1} L[i][k] U[k][j]\n\nand using this to computing the entries of U:\n\nU[j][i] = \\frac{A[j][i] - \\sum_{k=0}^{j-1} L[j][k] U[k][i]}{L[j][j]}\n\n\nimport numpy as np\n\ndef crout_lu(A, *, pivot=True, rtol=1e-9, atol=None):\n    \"\"\"\n    Robust Crout LU with partial pivoting.\n\n    Improvements\n    ------------\n    1. Pivot is selected from the *updated* column, eliminating the\n       “false zero-pivot” issue.\n    2. Test `abs(pivot) &lt; max(atol, rtol*‖A‖∞)` so tolerance scales with data.\n\n    Returns L, U, P such that  P @ A = L @ U.\n    \"\"\"\n    A = np.asarray_chkfinite(A, dtype=float)\n    n  = A.shape[0]\n    if A.ndim != 2 or n != A.shape[1]:\n        raise ValueError(\"square matrix required\")\n\n    L = np.zeros_like(A)\n    U = np.eye(n, dtype=A.dtype)\n    P = np.eye(n, dtype=A.dtype)\n    rows = np.arange(n)\n\n    if atol is None:\n        atol = np.finfo(A.dtype).eps * np.linalg.norm(A, np.inf) * 10\n\n    for k in range(n):\n        # current residual column\n        col = A[rows[k:], k] - L[k:, :k] @ U[:k, k]\n\n        if pivot:\n            j = k + np.argmax(np.abs(col))        # best row\n            if np.abs(col[j - k]) &lt; max(atol, rtol*np.abs(col).max()):\n                raise np.linalg.LinAlgError(\"matrix is numerically singular\")\n            if j != k:                            # swap logical rows\n                rows[[k, j]] = rows[[j, k]]\n                L[[k, j], :k] = L[[j, k], :k]\n                P[[k, j]] = P[[j, k]]\n                col[[0, j - k]] = col[[j - k, 0]]\n\n        L[k:, k] = col\n        if np.abs(L[k, k]) &lt; max(atol, rtol*np.abs(col).max()):\n            raise np.linalg.LinAlgError(\"zero pivot encountered\")\n\n        # row k of U (unit diagonal)\n        U[k, k+1:] = (A[rows[k], k+1:] - L[k, :k] @ U[:k, k+1:]) / L[k, k]\n\n    return L, U, P\n\nTest the Crout LU decomposition with a random full rank sign matrix:\n\ndef random_full_rank_sign_matrix(n, seed=42):\n    rng = np.random.default_rng(seed)\n    while True:\n        A = rng.choice([-1,0, 1], size=(n, n))\n        if np.linalg.matrix_rank(A) == n:\n            return A\n\nA = random_full_rank_sign_matrix(12, seed=42)\nprint_matrix(A, name=\"A\")\nA_orig = A.copy()  # Keep original for verification\nL, U, P = crout_lu(A)\n\n# Check correctness\nassert np.allclose(P @ A_orig, L @ U, atol=1e-8)\n\nA =\n  [  -1.000     1.000     0.000     0.000     0.000     1.000    -1.000     1.000    -1.000    -1.000     0.000     1.000]\n  [   1.000     1.000     1.000     1.000     0.000    -1.000     1.000     0.000     0.000     0.000    -1.000     1.000]\n  [   1.000     0.000     0.000     1.000     0.000     0.000     0.000    -1.000    -1.000     0.000     1.000    -1.000]\n  [   1.000     1.000    -1.000     0.000    -1.000     1.000     1.000     0.000    -1.000     1.000     0.000     1.000]\n  [   1.000     1.000     1.000    -1.000     0.000     0.000     0.000    -1.000     0.000    -1.000     1.000     1.000]\n  [   1.000     1.000     0.000     1.000     0.000    -1.000     1.000     0.000    -1.000     0.000     1.000    -1.000]\n  [   0.000    -1.000     1.000     0.000    -1.000    -1.000     0.000     1.000     1.000     0.000    -1.000     1.000]\n  [   0.000     1.000    -1.000    -1.000     1.000     1.000     0.000     1.000     1.000     0.000     1.000    -1.000]\n  [  -1.000     1.000     0.000    -1.000     1.000    -1.000     1.000    -1.000     1.000     1.000     1.000     0.000]\n  [   0.000     1.000    -1.000     1.000     0.000     0.000     0.000     0.000    -1.000    -1.000    -1.000    -1.000]\n  [   0.000     1.000     0.000     0.000     1.000     0.000    -1.000     1.000     0.000     0.000     0.000     0.000]\n  [  -1.000     0.000     1.000    -1.000     0.000    -1.000     0.000     0.000     1.000    -1.000    -1.000     0.000]\n\n\n\nThe Cholesky decomposition has several important properties:\n\nIf A is positive definite, then L is unique and has positive diagonal entries.\nThe Cholesky decomposition can be used to solve linear systems of equations of the form Ax = b by first solving Ly = b for y, and then solving L^Tx = y.\nThe Cholesky decomposition can be used to generate samples from a multivariate normal distribution by transforming samples from a standard normal distribution using the Cholesky factor L.\n\nThe Cholesky decomposition is widely used in various applications, including numerical optimization, Bayesian inference, and machine learning. It is particularly useful for solving linear systems efficiently and for generating samples from multivariate normal distributions.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Moore-Penrose Inversion & Cholesky Decomposition</span>"
    ]
  },
  {
    "objectID": "A14.html#sec-kron-hadamard",
    "href": "A14.html#sec-kron-hadamard",
    "title": "Appendix L — Moore-Penrose Inversion & Cholesky Decomposition",
    "section": "L.5 Kronecker Product and Hadamard Product",
    "text": "L.5 Kronecker Product and Hadamard Product\nThe Kronecker product and Hadamard product are two important operations in linear algebra that are used to manipulate matrices in various ways. These operations are particularly useful in applications such as signal processing, image processing, and machine learning, where they can be used as short hand notation for certain matrix operations used in many algorithms.\nThe Kronecker product is a matrix operation that takes two matrices and produces a block matrix by multiplying each element of the first matrix by the entire second matrix.\nThe Hadamard product, on the other hand, is an element-wise multiplication of two matrices of the same dimensions.\n\nDefinition L.4 (Definition of the Kronecker Product) The Kronecker product of two matrices A and B, denoted by A \\otimes B, is defined as the block matrix formed by multiplying each element of A by the entire matrix B. If A is an m \\times n matrix and B is a p \\times q matrix, then the Kronecker product A \\otimes B is an (mp) \\times (nq) matrix given by:\n\nA \\otimes B = \\begin{bmatrix}\na_{11}B & a_{12}B & \\cdots & a_{1n}B \\\\\na_{21}B & a_{22}B & \\cdots & a_{2n}B \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1}B & a_{m2}B & \\cdots & a_{mn}B\n\\end{bmatrix}\n\\tag{L.12}\nwhere a_{ij} are the elements of matrix A.\n\nsome properties of the Kronecker product include:\n\nTheorem L.4 (Properties of the Kronecker Product) Let A be an m \\times n matrix and B be a p \\times q matrix. Then:\n\na \\otimes A = A\\otimes a for any scalar a (scalar multiplication property)\n(aA) \\otimes (bB) = ab(A \\otimes B) for any scalars a and b (scalar multiplication property)\n(A \\otimes B) \\otimes C =  A \\otimes (B\\otimes C) (associative property)\n(A+B) \\otimes C = (A \\otimes C) + (B \\otimes C) when A,B,C are matrices of the same size (distributive property)\nA \\otimes (B+C) = (A \\otimes B) + (A \\otimes C) when A,B,C are matrices of the same size (distributive property)\n(A \\otimes B)^{\\prime} = A^{\\prime} \\otimes B^{\\prime} (transpose property)\n(\\mathbf{a} \\otimes \\mathbf{b})^{\\prime} = \\mathbf{a}^{\\prime} \\otimes \\mathbf{b}^{\\prime} (commutativity property for vectors)\n\\text{det}(A \\otimes B) = \\text{det}(A)^{p} \\cdot \\text{det}(B)^{m} (determinant property)\n\\text{rank}(A \\otimes B) = \\text{rank}(A) \\cdot \\text{rank}(B) (rank property)\n(A \\otimes B)^{-1} = A^{-1} \\otimes B^{-1}, if both A and B are invertible (inverse property)\n(A \\otimes B)(C \\otimes D) = (AC) \\otimes (BD) (multiplication property) ;. \\text{tr}(A \\otimes B) = \\text{tr}(A) \\cdot \\text{tr}(B) (trace property)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Moore-Penrose Inversion & Cholesky Decomposition</span>"
    ]
  },
  {
    "objectID": "A15.html",
    "href": "A15.html",
    "title": "Appendix M — Appendix: Inequalities",
    "section": "",
    "text": "M.1 Markov’s inequality\nMarkov’s inequality is a foundational result in measure theory and probability theory that provides an upper bound on the probability that a non-negative random variable exceeds a certain threshold. It is particularly useful for establishing the existence of moments and for proving other inequalities.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Appendix: Inequalities</span>"
    ]
  },
  {
    "objectID": "A15.html#sec-markov-inequality",
    "href": "A15.html#sec-markov-inequality",
    "title": "Appendix M — Appendix: Inequalities",
    "section": "",
    "text": "Theorem M.1 (Markov’s Inequality) Let X be a non-negative random variable and let a &gt; 0. Then,\n\n\\Pr(X \\geq a) \\leq \\frac{\\mathbb{E}[X]}{a}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Appendix: Inequalities</span>"
    ]
  },
  {
    "objectID": "A15.html#sec-chebyshev-inequality",
    "href": "A15.html#sec-chebyshev-inequality",
    "title": "Appendix M — Appendix: Inequalities",
    "section": "M.2 Chebyshev’s inequality",
    "text": "M.2 Chebyshev’s inequality\nChebyshev’s inequality is a powerful tool in probability theory that provides an upper bound on the probability that a random variable deviates from its mean. It is particularly useful for establishing the concentration of measure and for proving other inequalities.\n\nTheorem M.2 (Chebyshev’s Inequality) Let X be a random variable with mean \\mu = \\mathbb{E}[X] and variance \\sigma^2 = \\operatorname{Var}(X). Then for any k &gt; 0, \n\\Pr(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}.\n\n\n\nTheorem M.3 (Measure-theoretic Chebyshev’s Inequality) Let (\\Omega, \\mathcal{F}, \\mathbb{P}) be a probability space and let X be a random variable measurable with respect to \\mathcal{F}. If \\mu = \\mathbb{E}[X] and \\sigma^2 = \\operatorname{Var}(X), then for any k &gt; 0, \n\\Pr(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Appendix: Inequalities</span>"
    ]
  },
  {
    "objectID": "A15.html#sec-cantellis-inequality",
    "href": "A15.html#sec-cantellis-inequality",
    "title": "Appendix M — Appendix: Inequalities",
    "section": "M.3 Cantelli’s inequality",
    "text": "M.3 Cantelli’s inequality\nCantelli’s inequality is a refinement of Chebyshev’s inequality that provides a one-sided bound on the probability that a random variable deviates from its mean. It is particularly useful in statistical inference and hypothesis testing.\n\nTheorem M.4 (Cantelli’s Inequality) Let X be a random variable with mean \\mu = \\mathbb{E}[X] and variance \\sigma^2 = \\operatorname{Var}(X). Then for any k &gt; 0, \n\\Pr(X - \\mu \\geq k\\sigma) \\leq \\frac{1}{1 + k^2}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Appendix: Inequalities</span>"
    ]
  },
  {
    "objectID": "A15.html#sec-bhattacharyyas-inequality",
    "href": "A15.html#sec-bhattacharyyas-inequality",
    "title": "Appendix M — Appendix: Inequalities",
    "section": "M.4 Bhattacharyya’s inequality",
    "text": "M.4 Bhattacharyya’s inequality\nBhattacharyya’s inequality is a refinement of Cantelli’s inequality that provides a two-sided bound on the probability that a random variable deviates from its mean. It is particularly useful in statistical inference and hypothesis testing.\nThe neat idea is that it uses the third and fourth moments of the distribution to do this.\n\nTheorem M.5 (Bhattacharyya’s Inequality) Let X be a random variable with mean \\mu = \\mathbb{E}[X] and variance \\sigma^2 = \\operatorname{Var}(X). Then for any k &gt; 0, \n\\Pr(|X - \\mu| \\geq k\\sigma) \\leq \\frac{2}{1 + k^2}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Appendix: Inequalities</span>"
    ]
  },
  {
    "objectID": "A15.html#sec-kolmogorov-inequality",
    "href": "A15.html#sec-kolmogorov-inequality",
    "title": "Appendix M — Appendix: Inequalities",
    "section": "M.5 Kolmogorov’s inequality",
    "text": "M.5 Kolmogorov’s inequality\nKolmogorov’s inequality is a fundamental result in probability theory that provides an upper bound on the probability of the maximum absolute value of a sum of independent random variables exceeding a certain threshold. It is particularly useful in the context of stochastic processes and random walks.\n\nIt can be used to prove the weak law of large numbers.\nIt can be used like the empirical rule but for a broad class of distributions. Stating that at least 75% of the values lie within two standard deviations of the mean and at least 89% of the values lie within three standard deviations of the mean.\n\n\nTheorem M.6 (Kolmogorov’s Inequality) Let X_1, X_2, \\ldots, X_n be a sequence of independent random variables with zero expectation and finite variances. Then for any \\lambda \\geq 0,\n\n\\Pr \\left(\\max _{1\\leq k\\leq n}|S_{k}|\\geq \\lambda \\right)\\leq {\\frac {1}{\\lambda ^{2}}}\\operatorname {Var} [S_{n}]\\equiv {\\frac {1}{\\lambda ^{2}}}\\sum _{k=1}^{n}\\operatorname {Var} [X_{k}]={\\frac {1}{\\lambda ^{2}}}\\sum _{k=1}^{n}{\\text{E}}[X_{k}^{2}],\n\\tag{M.1}\nwhere S_k = X_1 + X_2 + \\ldots + X_k is the partial sum of the first k random variables.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Appendix: Inequalities</span>"
    ]
  },
  {
    "objectID": "A16.html",
    "href": "A16.html",
    "title": "Appendix N — Appendix: Wold’s theorem",
    "section": "",
    "text": "N.1 Wold’s theorem - (extra curricular) circa 1939\nWhenever we talk about innovation in the TS course we are alluding to Wold’s theorem, which is a fundamental result in time series analysis that provides a representation of stationary time series as a sum of deterministic and stochastic components.\nI researched this appendix to understand the Moving Average (MA) representation of the AR(p) process, which is a key result in this course. I think that this short appendix help provide a historical perspective on the development of time series analysis and helps other students put this and some other more esoteric concepts within a historical rather than seeing them in a purely mathematical context.\nI found that this approach helped me to understand and remember many results in a number of fields like geometry Ostermann and Wanner (2012), analysis Hairer and Wanner (2008), Ebbinghaus and Ewing (1991), complex analysis Remmert and Burckel (2012) integration Bressoud (2008) and algebra Golan (2012)\nIn the 1920s George Udny Yule and Soviet economists Eugen Slutsky were researching time series and they came up with two different ways to represent a time series.\nwe can use the two schemes together and get the ARMA(p,q) model:\n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t} + \\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{N.3}\nwhere:\nThe following is due in part to Wikipedia contributors (2025)\nWold’s decomposition AKA called the Wold representation theorem states that:\nFormally:\n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{\\infty }  \\underbrace{b_{j}\\varepsilon _{t-j}}_{\\text{stochastic}} + \\underbrace{\\eta _{t}}_{\\text{deterministic}} \\\\\n&= \\sum _{j=0}^{\\infty } b_{j}\\varepsilon _{t-j} + \\phi_{j} y_{t-j}\n\\end{aligned}\nwhere:\nThe moving average coefficients have these properties:\nAny stationary process has this seemingly special representation. Not only is the existence of such a simple linear and exact representation remarkable, but even more so is the special nature of the moving average model.\nThis result is used without stating its name in the course when we are show the AR(p) representation in terms of moving averages.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Appendix: Wold's theorem</span>"
    ]
  },
  {
    "objectID": "A16.html#wolds-theorem---extra-curricular-circa-1939",
    "href": "A16.html#wolds-theorem---extra-curricular-circa-1939",
    "title": "Appendix N — Appendix: Wold’s theorem",
    "section": "",
    "text": "Yule’s researches led to the notion of the autoregressive scheme. \n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t}\n\\end{aligned}\n\\tag{N.1}\nSlutsky’s researches led to the notion of a moving average scheme. \n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{N.2}\n\n\n\n\n\n\n\nEvery covariance-stationary time series Y_{t} can be written as the sum of two time series, one deterministic and one stochastic.\n\n\n\n\n\n{Y_{t}} is the time series being considered,\n{\\varepsilon _{t}} is an white noise sequence called innovation process that acts as an input to the linear filter {\\{b_{j}\\}}.\n{b} is the possibly infinite vector of moving average weights (coefficients or parameters)\n{\\eta _{t}} is a “deterministic” time series, in the sense that it is completely determined as a linear combination of its past values It may include “deterministic terms” like sine/cosine waves of {t}, but it is a stochastic process and it is also covariance-stationary, it cannot be an arbitrary deterministic process that violates stationarity.\n\n\n\nStable, that is, square summable \\sum _{j=1}^{\\infty } \\mid b_{j}|^{2} &lt; \\infty\nCausal (i.e. there are no terms with j &lt; 0)\nMinimum delay\nConstant (b_j independent of t)\nIt is conventional to define b_0=1\n\n\n\n\n\n\n\n\n\nBressoud, D. M. 2008. A Radical Approach to Lebesgue’s Theory of Integration. Classroom Resource Materials. Cambridge University Press. https://books.google.co.il/books?id=TxxMoGjXC-wC.\n\n\nEbbinghaus, H. D., and J. H. Ewing. 1991. Numbers. Graduate Texts in Mathematics. Springer New York. https://books.google.co.il/books?id=OKcKowxXwKkC.\n\n\nGolan, J. S. 2012. The Linear Algebra a Beginning Graduate Student Ought to Know. Mathematics and Statistics. Springer Netherlands. https://books.google.co.il/books?id=inwjR-k1dlkC.\n\n\nHairer, E., and G. Wanner. 2008. Analysis by Its History. Undergraduate Texts in Mathematics. Springer New York. https://books.google.co.il/books?id=ncxGAAAAQBAJ.\n\n\nOstermann, A., and G. Wanner. 2012. Geometry by Its History. Undergraduate Texts in Mathematics. Springer Berlin Heidelberg. https://books.google.co.il/books?id=eOSqPHwWJX8C.\n\n\nRemmert, R., and R. B. Burckel. 2012. Theory of Complex Functions. Graduate Texts in Mathematics. Springer New York. https://books.google.co.il/books?id=kIHlBwAAQBAJ.\n\n\nWikipedia contributors. 2025. “Wold’s Theorem — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Wold%27s_theorem&oldid=1295347901.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Appendix: Wold's theorem</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Appendix O — References",
    "section": "",
    "text": "O.1 Bibliography",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "references.html#bibliography",
    "href": "references.html#bibliography",
    "title": "Appendix O — References",
    "section": "",
    "text": "Agresti, A. 2012. Categorical Data Analysis. Wiley Series in\nProbability and Statistics. Wiley. https://books.google.co.il/books?id=UOrr47-2oisC.\n\n\nAldous, David. 1983. “Random Walks on Finite Groups and Rapidly\nMixing Markov Chains.” In Séminaire de\nProbabilités XVII 1981/82: Proceedings, 243–97.\nSpringer.\n\n\nAldrich, John. 2008. “R. A. Fisher on Bayes and Bayes’\nTheorem.” Bayesian Analysis 3 (March). https://doi.org/10.1214/08-BA306.\n\n\nAutolatry. 2015. “Why Square Brackets for Expectation.”\nMathematics Stack Exchange. https://math.stackexchange.com/q/1302543.\n\n\nBanerjee, S., A. E. Gelfand, and B. P. Carlin. 2026. Hierarchical\nModeling and Analysis for Spatial Data. CRC Press LLC. https://books.google.co.il/books?id=GRFT0QEACAAJ.\n\n\nBayesian Nonparametrics. 2010. Cambridge Series in Statistical\nand Probabilistic Mathematics. Cambridge University Press.\n\n\nBelsley, David A., Edwin Kuh, and Roy E. Welsch. 1980. Regression\nDiagnostics. John Wiley & Sons, Inc. https://doi.org/10.1002/0471725153.\n\n\nBernoulli, J. 1713. Ars Conjectandi [the Art of Conjecturing].\nImpensis Thurnisiorum. https://books.google.co.il/books?id=Ba5DAAAAcAAJ.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning.\nInformation Science and Statistics. Springer (India) Private Limited. https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf.\n\n\nBlundell, Charles, Julien Cornebise, Koray Kavukcuoglu, and Daan\nWierstra. 2015. “Weight Uncertainty in Neural Networks.” https://doi.org/10.48550/ARXIV.1505.05424.\n\n\nBressoud, D. M. 2008. A Radical Approach to Lebesgue’s Theory of\nIntegration. Classroom Resource Materials. Cambridge University\nPress. https://books.google.co.il/books?id=TxxMoGjXC-wC.\n\n\nBrockwell, Peter J, and Richard A Davis. 1991. Time Series: Theory\nand Methods. Springer science & business media.\n\n\nBroemeling, Lyle D. 2019. Bayesian Analysis of Time Series. CRC\nPress.\n\n\nCarlin, B. P., and T. A. Louis. 2008. Bayesian Methods for Data\nAnalysis. Chapman & Hall/CRC Texts in Statistical Science. CRC\nPress. https://books.google.co.il/books?id=GTJUt8fcFx8C.\n\n\nCasella, G., and R. L. Berger. 2002. Statistical Inference.\nDuxbury Advanced Series in Statistics and Decision Sciences. Thomson\nLearning. http://home.ustc.edu.cn/~zt001062/MaStmaterials/George%20Casella&Roger%20L.Berger--Statistical%20Inference.pdf.\n\n\nChen, J. 2023. Statistical Inference Under Mixture Models. ICSA\nBook Series in Statistics. Springer Nature Singapore. https://books.google.co.il/books?id=sBXlEAAAQBAJ.\n\n\nCook, R. Dennis. 1977. “Detection of Influential Observation in\nLinear Regression.” Technometrics 19 (1): 15. https://doi.org/10.2307/1268249.\n\n\nCowpertwait, P. S. P., and A. V. Metcalfe. 2009. Introductory Time\nSeries with r. Use r! Springer New York. https://books.google.co.il/books?id=QFiZGQmvRUQC.\n\n\nCressie, N., and C. K. Wikle. 2011. Statistics for Spatio-Temporal\nData. CourseSmart Series. Wiley. https://books.google.co.il/books?id=-kOC6D0DiNYC.\n\n\nDavidson-Pilon, Cameron. 2015. Bayesian Methods for Hackers:\nProbabilistic Programming and Bayesian Inference. Addison-Wesley\nData & Analytics Series. Pearson Education. https://books.google.co.il/books?id=rMKiCgAAQBAJ.\n\n\nDempster, Arthur P, Nan M Laird, and Donald B Rubin. 1977.\n“Maximum Likelihood from Incomplete Data via the EM\nAlgorithm.” Journal of the Royal Statistical Society: Series\nB (Methodological) 39 (1): 1–22.\n\n\nDurbin, J. 1960. “The Fitting of Time-Series Models.”\nRevue de l’Institut International de Statistique / Review of the\nInternational Statistical Institute 28 (3): 233–44. http://www.jstor.org/stable/1401322.\n\n\nEbbinghaus, H. D., and J. H. Ewing. 1991. Numbers. Graduate\nTexts in Mathematics. Springer New York. https://books.google.co.il/books?id=OKcKowxXwKkC.\n\n\nFinetti, Bruno de. 1937. “La Prévision: Ses Lois Logiques, Ses\nSources Subjectives.” Annales de l’Institut Henri\nPoincaré 7 (1): 1–68.\n\n\n———. 2017. “Theory of Probability.” Edited by Antonio Machí\nand Adrian Smith. Wiley Series in Probability and Statistics,\nJanuary. https://doi.org/10.1002/9781119286387.\n\n\nFisher, R. A. 1925. Statistical Methods for Research Workers.\n1st ed. Edinburgh Oliver & Boyd.\n\n\nFrazier, Peter I. 2018. “A Tutorial on Bayesian\nOptimization.” https://arxiv.org/abs/1807.02811.\n\n\nFruhwirth-Schnatter, S., G. Celeux, and C. P. Robert. 2019. Handbook\nof Mixture Analysis. Chapman & Hall/CRC Handbooks of Modern\nStatistical Methods. CRC Press. https://books.google.co.il/books?id=N3yCDwAAQBAJ.\n\n\nFrühwirth-Schnatter, S. 2006. Finite Mixture and Markov Switching\nModels. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=f8KiI7eRjYoC.\n\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki\nVehtari, and Donald B. Rubin. 2013. Bayesian Data Analysis, Third\nEdition. Chapman & Hall/CRC Texts in Statistical Science.\nTaylor & Francis.\n\n\nGelman, Andrew, and Jennifer Hill. 2006. Data Analysis Using\nRegression and Multilevel/Hierarchical Models. Analytical Methods\nfor Social Research. Cambridge University Press. https://books.google.co.il/books?id=c9xLKzZWoZ4C.\n\n\nGelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su.\n2008. “A Weakly Informative Default Prior Distribution for\nLogistic and Other Regression Models.” The Annals of Applied\nStatistics 2 (4). https://doi.org/10.1214/08-aoas191.\n\n\nGeman, Stuart, and Donald Geman. 1984. “Stochastic Relaxation,\nGibbs Distributions, and the Bayesian Restoration of Images.”\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nPAMI-6 (6): 721–41. https://doi.org/10.1109/tpami.1984.4767596.\n\n\nGhosh, Joyee, Yingbo Li, and Robin Mitra. 2018. “On the Use of\nCauchy Prior Distributions for Bayesian Logistic Regression.”\nBayesian Analysis 13 (2). https://doi.org/10.1214/17-ba1051.\n\n\nGolan, J. S. 2012. The Linear Algebra a Beginning Graduate Student\nOught to Know. Mathematics and Statistics. Springer Netherlands. https://books.google.co.il/books?id=inwjR-k1dlkC.\n\n\nGramacy, Robert B. 2020. Surrogates: Gaussian Process Modeling,\nDesign, and Optimization for the Applied Sciences. Chapman &\nHall/CRC the r Series. CRC Press. https://bookdown.org/rbg/surrogates/.\n\n\nHairer, E., and G. Wanner. 2008. Analysis by Its History.\nUndergraduate Texts in Mathematics. Springer New York. https://books.google.co.il/books?id=ncxGAAAAQBAJ.\n\n\nHärdle, Wolfgang Karl, and Léopold Simar. 2019. Applied Multivariate\nStatistical Analysis. Springer International Publishing. https://doi.org/10.1007/978-3-030-26006-4.\n\n\nHewitt, Edwin, and Leonard J Savage. 1955. “Symmetric Measures on\nCartesian Products.” Transactions of the American\nMathematical Society 80 (2): 470–501.\n\n\nHobbs, N. Thompson, and Mevin B. Hooten. 2015. Bayesian Models: A\nStatistical Primer for Ecologists. STU - Student edition. Princeton\nUniversity Press. http://www.jstor.org/stable/j.ctt1dr36kz.\n\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical\nMethods. Springer New York. https://doi.org/10.1007/978-0-387-92407-6.\n\n\nJackman, Simon. 2009. “Bayesian Analysis for the Social\nSciences.” Wiley Series in Probability and Statistics,\nOctober. https://doi.org/10.1002/9780470686621.\n\n\nJames, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. An\nIntroduction to Statistical Learning: With Applications in r.\nSpringer Texts in Statistics. Springer New York. https://books.google.co.il/books?id=qcI_AAAAQBAJ.\n\n\nJeffreys, H. 1983. Theory of Probability. International Series\nof Monographs on Physics. Clarendon Press.\n\n\nJohnson, R. A., and D. W. Wichern. 2001. Applied Multivariate\nStatistical Analysis. Pearson Modern Classics for Advanced\nStatistics Series. Prentice Hall. https://books.google.co.il/books?id=QBqlswEACAAJ.\n\n\nKruschke, John K. 2011. Doing Bayesian Data Analysis: A Tutorial\nwith R and BUGS. Burlington, MA: Academic\nPress. http://www.amazon.com/Doing-Bayesian-Data-Analysis-Tutorial/dp/0123814855.\n\n\nLevinson, Norman. 1946. “The Wiener (Root Mean Square) Error\nCriterion in Filter Design and Prediction.” Journal of\nMathematics and Physics 25 (1-4): 261–78. https://doi.org/https://doi.org/10.1002/sapm1946251261.\n\n\nLunn, D., C. Jackson, N. Best, A. Thomas, and D. Spiegelhalter. 2012.\nThe BUGS Book: A Practical Introduction to Bayesian Analysis.\nChapman & Hall/CRC Texts in Statistical Science. Taylor &\nFrancis. https://books.google.co.il/books?id=Cthz3XMa_VQC.\n\n\nMartin, Osvaldo A., Ravin Kumar, and Junpeng Lao. 2021. Bayesian Modeling and Computation in Python.\nBoca Raton.\n\n\nMcElreath, Richard. 2015. Statistical Rethinking, a Course in r and\nStan.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis: Data Wrangling with\nPandas, NumPy, and Jupyter. 3rd ed. O’Reilly Media.\n\n\nMcLachlan, G. J., and D. Peel. 2004. Finite Mixture Models.\nWiley Series in Probability and Statistics. Wiley. https://books.google.co.il/books?id=c2_fAox0DQoC.\n\n\nMoivre, Abraham De. 1718. The Doctrine of Chances. H. Woodfall.\nhttps://tellingstorieswithdata.com.\n\n\nMorita, Satoshi, Peter F Thall, and Peter Müller. 2008.\n“Determining the Effective Sample Size of a Parametric\nPrior.” Biometrics 64 (2): 595–602.\n\n\nNielsen, A. 2019. Practical Time Series Analysis: Prediction with\nStatistics and Machine Learning. O’Reilly Media. https://books.google.co.il/books?id=xNOwDwAAQBAJ.\n\n\nOstermann, A., and G. Wanner. 2012. Geometry by Its History.\nUndergraduate Texts in Mathematics. Springer Berlin Heidelberg. https://books.google.co.il/books?id=eOSqPHwWJX8C.\n\n\nPearson, E. S., W. S. Gosset, R. L. Plackett, and G. A. Barnard. 1990.\nStudent: A Statistical Biography of William Sealy Gosset.\nClarendon Press. https://books.google.co.il/books?id=LBDvAAAAMAAJ.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series\nwith r. Use r! Springer New York. https://books.google.co.il/books?id=ca5MkRbF3fYC.\n\n\nPoisson, S. -D. 2019. “English Translation of Poisson’s\n\"Recherches Sur La Probabilité Des Jugements En Matière Criminelle Et En\nMatière Civile\" / \"Researches into the Probabilities of Judgements in\nCriminal and Civil Cases\".” https://arxiv.org/abs/1902.02782.\n\n\nPolya, G. 1945. How to Solve It. Princeton University Press. https://doi.org/10.1515/9781400828678.\n\n\nPrado, Raquel, Gabriel Huerta, and Mike West. 2000. “Bayesian\nTime-Varying Autoregressions: Theory, Methods and Applications.”\nResenhas Do Instituto de Matemática e\nEstatı́stica Da Universidade de São Paulo\n4 (4): 405–22. https://www2.stat.duke.edu/~mw/MWextrapubs/Prado2001.pdf.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series:\nModeling, Computation, and Inference. Chapman & Hall/CRC Texts\nin Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nRamsey, Frank P. 1926. “Truth and Probability.” In The\nFoundations of Mathematics and Other Logical Essays, edited by R.\nB. Braithwaite, 156–98. McMaster University Archive for the History of\nEconomic Thought. https://EconPapers.repec.org/RePEc:hay:hetcha:ramsey1926.\n\n\nRasmussen, Carl Edward, and Christopher K. I. Williams. 2006.\nGaussian Processes for Machine Learning. Adaptive Computation\nand Machine Learning Series. MIT Press. https://gaussianprocess.org/gpml/.\n\n\nRavishanker, N., B. Raman, and R. Soyer. 2022. Dynamic Time Series\nModels Using r-INLA: An Applied Perspective. CRC Press.\n\n\nRemmert, R., and R. B. Burckel. 2012. Theory of Complex\nFunctions. Graduate Texts in Mathematics. Springer New York. https://books.google.co.il/books?id=kIHlBwAAQBAJ.\n\n\nRios Insua, David, Fabrizio Ruggeri, and Michael P Wiper. 2012.\nBayesian Analysis of Stochastic Process Models. John Wiley\n& Sons.\n\n\nSchott, James R. 2016. Matrix Analysis for Statistics. Wiley\nSeries in Probability and Statistics. Wiley. https://books.google.co.il/books?id=Y2PpCgAAQBAJ.\n\n\nSheather, Simon. 2009. A Modern Approach to Regression with r.\nSpringer New York. https://doi.org/10.1007/978-0-387-09608-7.\n\n\nSpanos, A. 2019. Probability Theory and Statistical Inference.\nCambridge University Press. https://books.google.co.il/books?id=9nCiDwAAQBAJ.\n\n\nSpiegelhalter, David J., Nicola G. Best, Bradley P. Carlin, and Angelika\nVan Der Linde. 2002. “Bayesian Measures of Model Complexity and\nFit.” Journal of the Royal Statistical Society Series B:\nStatistical Methodology 64 (4): 583–639. https://doi.org/10.1111/1467-9868.00353.\n\n\nStorch, H. von, and F. W. Zwiers. 2002. Statistical Analysis in\nClimate Research. Cambridge University Press.\n\n\nTheodoridis, S. 2015. Machine Learning: A Bayesian and Optimization\nPerspective. Elsevier Science.\n\n\nTrench, William F. 1964. “An Algorithm for the Inversion of Finite\nToeplitz Matrices.” Journal of the Society for Industrial and\nApplied Mathematics 12 (3): 515–22. http://ramanujan.math.trinity.edu/wtrench/research/papers/TRENCH_RP_6.PDF.\n\n\nVanderPlas, Jake. 2016. Python Data Science Handbook: Essential\nTools for Working with Data. 1st ed. O’Reilly Media, Inc. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nVisser, I., and M. Speekenbrink. 2022. Mixture and Hidden Markov\nModels with r. Use r! Springer International Publishing. https://books.google.co.il/books?id=Eep3EAAAQBAJ.\n\n\nWalker, Gilbert Thomas. 1931. “On Periodicity in Series of Related\nTerms.” Proceedings of the Royal Society of London. Series A,\nContaining Papers of a Mathematical and Physical Character 131\n(818): 518–32. https://doi.org/10.1098/rspa.1931.0069.\n\n\nWeckerle, Melissa. 2022. “Statistics\nprofessor wins prestigious professional statistics society award\n Baskin School of Engineering.” https://engineering.ucsc.edu/news/statistics-professor-wins-zellner-medal.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic\nModels. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.\n\n\nWiesenfarth, Manuel, and Silvia Calderazzo. 2020. “Quantification\nof Prior Impact in Terms of Effective Current Sample Size.”\nBiometrics 76 (1): 326–36. https://doi.org/https://doi.org/10.1111/biom.13124.\n\n\nWikipedia contributors. 2023a. “68–95–99.7 Rule —\nWikipedia.” https://en.wikipedia.org/w/index.php?title=68%E2%80%9395%E2%80%9399.7_rule.\n\n\n———. 2023b. “Functional (Mathematics) —\nWikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Functional_(mathematics)&oldid=1148699341.\n\n\n———. 2024a. “Autoregressive Model —\nWikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Autoregressive_model&oldid=1233171855#Estimation_of_AR_parameters.\n\n\n———. 2024b. “Levinson Recursion —\nWikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Levinson_recursion&oldid=1229942891.\n\n\n———. 2025. “Wold’s Theorem — Wikipedia,\nthe Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Wold%27s_theorem&oldid=1295347901.\n\n\nWikle, C. K., A. Zammit-Mangion, and N. Cressie. 2019.\nSpatio-Temporal Statistics with r. Chapman & Hall/CRC the r\nSeries. CRC Press. https://books.google.co.il/books?id=FD-IDwAAQBAJ.\n\n\nWoodward, W. A., B. P. Sadler, and S. Robertson. 2022. Time Series\nfor Data Science: Analysis and Forecasting. Chapman & Hall/CRC\nTexts in Statistical Science. CRC Press. https://books.google.co.il/books?id=_W16EAAAQBAJ.\n\n\nYao, W., and S. Xiang. 2024. Mixture Models: Parametric,\nSemiparametric, and New Directions. Chapman & Hall/CRC\nMonographs on Statistics and Applied Probability. CRC Press. https://books.google.co.il/books?id=scP9EAAAQBAJ.\n\n\nYule, George Udny. 1927. “VII. On a Method of Investigating\nPeriodicities Disturbed Series, with Special Reference to Wolfer’s\nSunspot Numbers.” Philosophical Transactions of the Royal\nSociety of London. Series A, Containing Papers of a Mathematical or\nPhysical Character 226 (636-646): 267–98. https://doi.org/10.1098/rsta.1927.0007.\n\n\nZohar, Shalhav. 1969. “Toeplitz Matrix Inversion: The Algorithm of\nw. F. Trench.” J. ACM 16: 592–601. https://api.semanticscholar.org/CorpusID:3115290.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>References</span>"
    ]
  }
]