[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistics",
    "section": "",
    "text": "Preface\nThese are my notes on Bayesian Statistics. They are based on online courses I took after I worked as a Data Scientist for a number of years. Over this time I have often felt that if i was better at statistics I could overcome limitations in the data with mathematics, build even better models, and perhaps most importantly make better inferences using model I have already developed.\nI tried to review the main result in statistic and probability theory, and I started to get better results and so I decided to take some classes. I often felt that the material was introductory and simplistic. Real world problems are monsters and the examples are usually trivial in comparison. The issues raised in class are rarely the troubles I saw at work. But I do believe deep down that the two are somehow related. And indeed as I covered more material certain aspects began to connect.\nI noticed that like in real classes the teachers made mistakes, their motivation was not always clear and that they skipped steps or reffered to certain results. On the other hand each teacher offered different insights into this complicated area of data analysis.\nI therefore have a number main areas of Focus:\n\nWhat are the questions one should ask\nWhat are the explicit details of each examples or problem.\nWhat is the mathematical representation of the model for these\nWhat is the code representation for this in R and in Python.\nCan I find or create diagrams to make interpretation of probabilities clearer.\nCan I annotate the main equations to break them down.\nCan I keep track of the most useful Mathematical results in Probability and Statistics?\n\nI tried to keep these handy as appendices to keep the main material less cluttered. However as time goes by these keep expanding.\n\nCan I learn to communicate my intuitions of these concepts to laymen and to colleages\n\nSome courses have discussion prompts, but I tried to make the most of these, and included them in these notes.\nI realized that while I often get excited about a new paper or technique my colleges are smart and talented people and quickly ask questions that are difficult to answer. These question often indicate gaps of knowledge which can dampen the enthusiasm for implementing these new ideas.\nI found that good communicators can overcome these issues more readily and connect what they already know.\n\n\nI have often found exercises rather easy to solve and so I often breezed through them with little notice. This time I resolved to make the most of these as opportunities to get better at using and manipulating probabilities and posterior distributions. So although I could get around 75% in each exercises based on intuition I took the extra effort to understand what is realty going on here mathematically.\nAt work one of the main challenges is making the problem conform to a simple model. This can be even more challenging when the goal is a latent (unobserved) variable or when you are considering a synergy of multiple effects and you have seen and unseen confounds. In many cases it is unclear how to proceed based on the simple examples we see in these classes. However I am now able to look at the problems with more critical point of view. Also I see great advantages of a quick expositions to many new simple models. In Bayesian hierarchical framework each can become a link to adding just a little more complexity, integrating new types of prior information and so on. So I view these as jumping boards for overcoming my next challenges.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "1  About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction to Bayesian Statistics",
    "section": "",
    "text": "3 Introduction\nWhat is covered is:\nWith this goal in mind, the content is divided into the following three main sections (courses).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#why-inference",
    "href": "intro.html#why-inference",
    "title": "2  Introduction to Bayesian Statistics",
    "section": "3.1 Why Inference?",
    "text": "3.1 Why Inference?\nThe purpose of the set of courses is to focus on Inferential Statistics as opposed to Descriptive Statistics.\nAll the samples in the group that we are interested in learning about make up a population. Populations can be described by parameters such as the mean and variance since they represent all of the data. Often, we do not have access to all the data in our population and have to sample from the population. The metrics of mean and variance computed from these samples are not called parameters but statistics of the data.\n\n3.1.1 Descriptive Statistics\nThis is used to summarize the data so that we have a quantitative way to understand data. This allows to understand and visualize data qualitatively. We can draw conclusions about the nature of the data. Descriptive statistics is applied to a population and hence can provide measures such as the mean and variance of the data. They do not allow us to make predictions about data that we have not analyzed.\n\n\n3.1.2 Inferential Statistics\nInferential Statistics allow us to make generalizations about the population from the samples. This process of sampling introduces errors as this is never a perfect representation of the underlying data. The statistics thus computed are supposed to be an estimate of the true population parameters. It allows you to form a distribution of the population from the sampled data by accounting for the errors in the sampling, thereby allowing you to make predictions about data that is not yet seen or sampled.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#how-is-inference-different-from-prediction",
    "href": "intro.html#how-is-inference-different-from-prediction",
    "title": "2  Introduction to Bayesian Statistics",
    "section": "3.2 How is Inference different from Prediction?",
    "text": "3.2 How is Inference different from Prediction?\nReference\n\n3.2.1 Prediction\nIf you happen to come from a background in Machine Learning, you are probably used to making predictions. This is exactly what it sounds like, you use a model to make predictions on unseen data. The predictive process involves the following steps\n\nCreate the model\nSelect the best model using performance metrics such as accuracy, F1 scores on out-of-sample data\nMake predictions on new data\n\n\n\n3.2.2 Inference\nIn Inference, you are trying to model a distribution and understand the process that generates the data. This involves the following steps\n\nCreate the model, usually involves some prior understanding of the data generation process\nSelect the model using goodness-of-fit measures such as such as residual analysis, deviance, AIC scores etc.\nPerform inference by generating distributions that describe the data, or the data generation process",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#references",
    "href": "intro.html#references",
    "title": "2  Introduction to Bayesian Statistics",
    "section": "3.3 References",
    "text": "3.3 References\n\n(Casella and Berger 2002) e-book solutions\n(Spanos 2019)\n(Hobbs and Hooten 2015) ebook website\n(VanderPlas 2016) ebook notebooks\n(Bishop 2006) ebook website\n\n\n\n\n\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. Information Science and Statistics. Springer (India) Private Limited. https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf.\n\n\nCasella, G., and R. L. Berger. 2002. Statistical Inference. Duxbury Advanced Series in Statistics and Decision Sciences. Thomson Learning. http://home.ustc.edu.cn/~zt001062/MaStmaterials/George%20Casella&Roger%20L.Berger--Statistical%20Inference.pdf.\n\n\nHobbs, N. Thompson, and Mevin B. Hooten. 2015. Bayesian Models: A Statistical Primer for Ecologists. STU - Student edition. Princeton University Press. http://www.jstor.org/stable/j.ctt1dr36kz.\n\n\nSpanos, A. 2019. Probability Theory and Statistical Inference. Cambridge University Press. https://books.google.co.il/books?id=9nCiDwAAQBAJ.\n\n\nVanderPlas, J. 2016. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "C1-L01.html",
    "href": "C1-L01.html",
    "title": "3  M1L1 - Probability",
    "section": "",
    "text": "3.1 Introduction\nIn these notes I supplement the course material with my own notes for establishing an axiomatic foundation for probability. These were ostentatiously omitted from the specialization material, but alluded to in many places as a form of hand waving for introducing results. I found their absence increasingly irksome that I decided to add them to my notes. In reality probability theory is a beautiful part of Mathematics and bring together many results from analysis, topology, functional analysis and integration theory. I hope that adding this material will make your journey easier and not more challenging. In the future I hope to dive a little deeper, as progressing with the specialization has uncovered additional topics in probability theory that might be useful to review. When this happens, I will move most of these extras into thier own appendecies.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-rules-of-probability-odds--expectation",
    "href": "C1-L01.html#sec-rules-of-probability-odds--expectation",
    "title": "3  M1L1 - Probability",
    "section": "3.2 Rules of Probability, Odds & Expectation",
    "text": "3.2 Rules of Probability, Odds & Expectation\n\nBackground reading: This reviews the rules of probability, odds, and expectation.\n\nFor all its discussion of different paradigms of probability, the course lacks a rigorous definition of probability.\n\nDefinition 3.1 (Sample Space and Sample Point)  Sample space \\Omega\n\n\\Omega = \\{ \\forall w \\mid w \\text { is an outcome of an experiment} \\} \\ne \\emptyset\n\\tag{3.1}\nthen \\Omega is called a sample space.\nSince\n\n\\Omega \\ne \\emptyset \\implies  \\exists\\ \\omega \\in \\Omega\n\\tag{3.2}\nthen \\omega is called a sample point  Sample point \\omega\n\n\nDefinition 3.2 (Event)  Event A\n\n\\Omega \\ne \\emptyset \\implies  \\exists \\mathcal{F} \\subset 2^\\Omega \\implies \\exists A\\in F\n\\tag{3.3}\nLet \\mathcal{F} denote a family of subsets of a sample space \\Omega, and A any such subset. Then A is called an event\n\n\nDefinition 3.3 (Elementary Event) An event composed of a single point \\omega is called an elementary event.\n\n\nDefinition 3.4 (Outcome) We say that event A happened if when conducting the experiment we got an outcome \\omega and \\omega\\in A.\n\n\nDefinition 3.5 (Certain Event) \\Omega is called the certain event.\n\n\nDefinition 3.6 (Impossible Event) \\emptyset is called the impossible event.\n\n\nDefinition 3.7 (σ-Algebra) A family of events \\mathcal{F} with the following properties:\n\n\\Omega is the universal set\n\n\\Omega \\in \\mathcal{F}\n  \\tag{3.4}\n\\mathcal{F} is closed under complement operation:\n\n\\forall A \\in \\mathcal{F} \\implies A^c \\in \\mathcal{F}\n\\tag{3.5}\n\\mathcal{F} is closed under countable unions:\n\n\\exists A_i \\in \\mathcal{F} \\quad  i \\in \\mathcal{N} \\implies \\bigcup_{n=1}^\\infty {A_i} \\in \\mathcal{F}\n\\tag{3.6}\n\nis called a \\sigma-algebra or a \\sigma-field .\n\nsome properties of \\sigma-algebra\n\nhttps://math.stackexchange.com/questions/1330649/difference-between-topology-and-sigma-algebra-axioms\nAn epsilon of room: pages from year three of a mathematical blog section 2.7\n\n\nDefinition 3.8 (Probability Measure) if \\Omega is a sample space Definition 3.1 and \\mathcal{F} a \\sigma-algebra Definition 3.7 for \\Omega then a function P: \\mathcal{f} \\to [0,1] with the following properties:\n\nTotal measure of the sample space is 1: \n     \\mathbb{P}r(\\Omega)=1\n  \\tag{3.7}\ncountably additive for pairwise disjoint countable collections of events: is called a probability measure over \\mathcal{F}. \n\\forall E_{ i \\in \\mathbb{N} } \\quad   \\mathbb{P}r(\\bigcup_{n\\in \\mathbb{N} }{E_n})=\\sum_{n\\in \\mathbb{N} } \\mathbb{P}r(E_n)\n\\tag{3.8}\nthen P is a probability measure over \\mathcal{F}\n\n\n\nDefinition 3.9 (Probability Space) If \\Omega is a sample space Definition 3.1 and \\mathcal{F} a \\sigma-algebra Definition 3.7 for \\Omega, and P a probability measure (Definition 3.8) for \\mathcal{F} then the ordered set &lt;\\Omega,\\mathcal{F},P &gt; is called a probability space\n\n\n\n\n\n\n\n\nFigure 3.1: Illustration of a probability space by Ziggystar\n\n\n\n\n\n\n\n\nTipNotation\n\n\n\nsometimes \\mathcal{F} is replaced with \\Sigma. for the \\sigma-algebra like in the figure below",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-properties-of-probability-measures",
    "href": "C1-L01.html#sec-properties-of-probability-measures",
    "title": "3  M1L1 - Probability",
    "section": "3.3 Properties of Probability Measures",
    "text": "3.3 Properties of Probability Measures\nThe probability of the null event is 0.\n\n\\mathbb{P}r(\\emptyset) = 0\n\\tag{3.9}\nProbabilities of all possible events (the space of all possible outcomes) must sum to one.\n\n\\mathbb{P}r(\\Omega) = 1\n\\tag{3.10}\n\nA\\cap B = \\emptyset \\implies \\mathbb{P}r(A \\cup B) = \\mathbb{P}r(A)+\\mathbb{P}r(B)\n\\tag{3.11}\n\n\n\\mathbb{P}r(A^c) =1-\\mathbb{P}r(A) \\qquad \\forall A\\in\\Omega\n\\tag{3.12}\n\nif A is an event in \\Omega then A^C is in Omega and since they are mutually exclusive by Equation 3.10\nIf S is the certain event in class C \\Omega then\nFor every event X in class \\Omega\n\n1 \\ge \\mathbb{P}r(X) \\ge 0 \\qquad \\forall X \\in \\Omega \\qquad \\text{(P1)} \\qquad\n\\tag{3.13}\nProbabilities add to one:\n\n\\sum_{i\\in \\Omega} \\mathbb{P}r(X=i)=1 \\qquad \\text{(P2)}\\qquad\n\\tag{3.14}\nThe complement of an event A is A^c\n\n\\mathbb{P}r(S) = 1\n\\tag{3.15}\nIf events A_\\lambda are mutually exclusive (only one event may happen):\n\n\\mathbb{P}r(A_1 \\cup A_2) = \\mathbb{P}r(A_1) + \\mathbb{P}r(A_2) - \\mathbb{P}r(A_1\\cap A_1)\n\\tag{3.16}\n\n\\mathbb{P}r(\\bigcup_{\\lambda\\in \\Omega} A_\\lambda)=\\sum_{\\lambda \\in \\Omega} \\mathbb{P}r(A_\\lambda)\n\\tag{3.17}\nif {B_i} is a finite or countably infinite partition of a sample space \\Omega then\n\n\\mathbb{P}r(A) = {\\sum_{i=1}^{N} \\mathbb{P}r(A \\cap B_i)}= {\\sum_{i=1}^{N} \\mathbb{P}r(A|B_i)\\mathbb{P}r(B_i)}\n\\tag{3.18}\n\n3.3.1 Odds\n\nC-3PO: Sir, the possibility of successfully navigating an asteroid field is approximately 3,720 to 1!  Han Solo: Never tell me the odds! — Star Wars Episode V: The Empire Strikes Back\n\nAnother way to think about probabilities is using odds Equation 3.19. Odds are more intuitive when we are thinking about the risk of an event happening or not happening. and when we consider the risk associated with uncertainty odds are a handy way of considering the risks.\n\nDefinition 3.10 (Odds Definitions) the odds of an event A are:\n\n\\mathcal{O}(A)  = \\frac{\\mathbb{P}r(A)}{\\mathbb{P}r(A^c)} = \\frac{ \\mathbb{P}r(A)}{1-\\mathbb{P}r(A)}\n\\tag{3.19}\n\nIt is also possible to convert odds to probabilities Equation 3.20\n\nTheorem 3.1 (Probability from odds) \n\\mathbb{P}r(A) = \\frac{ \\mathcal{O}(A)} {1+ \\mathcal{O}(A)}\n\\tag{3.20}\n\n\nProof. \n\\begin{aligned}\n& & \\mathcal{O}(A)  &= \\frac{\\mathbb{P}r(A)}{1-\\mathbb{P}r(A)} && \\text{(odds definition)}\n  \\\\&\\implies & \\mathbb{P}r(A) &= \\mathcal{O}(A) (1-\\mathbb{P}r(A))  && (\\times \\text{ denominator})\n  \\\\&\\implies &  \\mathbb{P}r(A) &= \\mathcal{O}(A) - \\mathcal{O}(A) \\mathbb{P}r(A) && \\text{(expand)}\n  \\\\&\\implies &  \\mathbb{P}r(A)(1+ \\mathcal{O}(A)) &= \\mathcal{O}(A) && \\text{(collect)}  \n  \\\\&\\implies & \\mathbb{P}r(A) &= \\frac{ \\mathcal{O}(A)} {1+ \\mathcal{O}(A)} && \\blacksquare  \n\\end{aligned}\n\n\nIf we are at the races and thinking about each horse a horse what we may care about is if it will win or lose. In such a case the odds can summarize the ratio of past successes and failures to win. Odds seem to be in line with a frequentist view summarizing ratios of success to failure. In reality, the other horses have odds as well and we may want to consider the probability of winning given the other horses in the race, and perhaps other parameters, like the track type, length of the race, jockey, and perhaps some hot tips. So let us not get ahead of ourselves\n\n\n\n\n\n\nTipData Scientist - insights.\n\n\n\nMany of these formulas are rather tedious. But, once you start to work on a data science project you will often discover that there are some problems with the data and because of that you cannot use your favorite algorithm. Or worse when you do the results are not very useful. It is at this point that the ability to think back to first principles will be very fruitful. The more of this material you can recall, the more the dots will connect, and your ability will translate into models of increasing sophistication. Luckily, the rules of probability are logical. So it is fairly easy to remember or even derive if you take some time to understand them.\nI realize that figuring out which results are more useful is easier in hindsight. And one of the reasons I am taking these courses is to annotate in my note the results I think to be most useful.\n\n\n\n\n3.3.2 Expectation\nThe expectation of a random variable (RV) X is the weighted average of the outcomes it can take weighted by their probabilities.\n\nDefinition 3.11 (Expectation for a discrete RV) \n\\mathbb{E}(x) = \\sum^N_{i=1} x_i \\times \\mathbb{P}r(X=x_i)\n\\tag{3.21}\n\n\nDefinition 3.12 (Expectation for a continuous RV) \n\\mathbb{E}(x) = \\int_{\\Omega} x \\mathbb{P}r(X=x) dx\n\\tag{3.22}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-probability-paradigms",
    "href": "C1-L01.html#sec-probability-paradigms",
    "title": "3  M1L1 - Probability",
    "section": "3.4 Probability Paradigms",
    "text": "3.4 Probability Paradigms\n\n\n\n\n\n\n\nFigure 3.2: Probability Paradigms\n\n\nWe start by looking at probability as defined or interpreted under three paradigms. Probability is at its root a logical and scientific approach to formalizing and modeling uncertainty.\nThe three paradigms are:\n\nDefinition 3.13 (Classical Probability) Deals primarily with cases where probabilities are distributed equally, like with dice and cards.\n\n\n\n\n\n\n\n\nFigure 3.3: Abraham De Moivre\n\n\n\n\n\n\n\n\nTipBiographical note on Abraham de Moivre\n\n\n\n\n\n\nThe Probability of an Event is greater or less, according to the number of chances by which it may happen, compared with the whole number of chances by which it may either happen or fail. — (Moivre 1718)\n\nAbraham de Moivre (1667-1754) was a prominent French mathematician known for his significant contributions to the field of probability and his work on the foundations of Bayesian statistics. His research and writings played a crucial role in establishing the mathematical principles of probability theory and laid the groundwork for future advancements in the field.\nDe Moivre is best known for his work on the theory of probability. He made significant advancements in understanding the Binomial distribution and its application to games of chance and coin tossing. In his influential book, “The Doctrine of Chances” (1718), he presented a comprehensive treatise on probability theory, providing mathematical explanations for various phenomena such as the law of large numbers and the central limit theorem. His book became a standard reference in the field and greatly influenced subsequent research on probability.\nFurthermore, de Moivre’s work laid the foundation for Bayesian statistics, although the term “Bayesian” was not coined until many years after his death. He developed a formula known as de Moivre’s theorem, which establishes a connection between the normal distribution and the binomial distribution. This theorem became a fundamental tool in probability theory and enabled the calculation of probabilities for large sample sizes. It provided a bridge between frequentist and Bayesian approaches, allowing for the estimation of parameters and the quantification of uncertainty.\n\nAnd thus in all cases it will be found, that although Chance produces irregularities, still the Odds will be infinitely great, that in process of Time, those Irregularities will bear no proportion to the recurrency of that Order which naturally results from Original Design. (Moivre 1718)\n\nHe was an active participant in scientific societies and maintained correspondence with renowned mathematicians of his time, including Isaac Newton and James Stirling. His work played a crucial role in disseminating mathematical knowledge and promoting the study of probability theory across Europe. De Moivre’s research and writings laid the groundwork for the development of probability theory and Bayesian statistics. His ideas and formulas continue to be foundational in the field, and his contributions have had a lasting impact on mathematics, statistics, and the broader scientific community.\nHis work remains an essential reference for researchers and serves as a testament to his profound understanding of probability and statistics.\n\nFurther, the same Arguments which explode the Notion of Luck, may, on the other side, be useful in some cases to establish a due comparison between Chance and Design: We may imagine Chance and Design to be, as it were, in Competition with each other, for the production of some sorts of Events, and many calculate what Probability there is, that those Events should be rather be owing to the one than to the other. (Moivre 1718)\n\n\n\n\n\nDefinition 3.14 (Frequentist Probability) Defines probabilities using long-run limits of frequencies from repeated independent sampling generated by a hypothetical infinite sequence of experiments from a population\nFrequentist probability or frequentism is an interpretation of probability; it defines an event’s probability as the limit of its relative frequency in many trials AKA long-run probability. Probabilities can be found, in principle, by a repeatable objective process and are thus ideally devoid of opinion. The continued use of frequentist methods in scientific inference, however, has been called into question.\n\nSince in reality we cannot repeat most experiments many times.\n“by definition, scientific researchers do not possess sufficient knowledge about the relevant and irrelevant aspects of their tests and populations to be sure that their replications will be equivalent to one another” - Mark Rubin 2020\n\n\n\nDefinition 3.15 (Bayesian Probability) Defines probability starting with a subjective view of the problem called a prior and updates it as evidence comes in using Bayes Rule.\n\nThe lesson and assignments test these views with examples - but the division is rather artificial to me. Not that it does not exist, but rather different authors on the subject treat it differently.\n\n\n\n\n\n\n\nVideo 3.1: Interview with Dennis Lindley, a pioneer of Bayesian statistics, discussing the history and philosophy of Bayesian methods, and his contributions to the field. He emphasizes the importance of subjective probability and the role of prior beliefs in statistical inference.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-bayesian-probability-and-coherence",
    "href": "C1-L01.html#sec-bayesian-probability-and-coherence",
    "title": "3  M1L1 - Probability",
    "section": "3.5 Bayesian Probability and Coherence",
    "text": "3.5 Bayesian Probability and Coherence\n\n\n\n\n\n\n\nFigure 3.4: Coherence\n\n\nA notion of a fair bet - one which we would take either way for the same reward.\n\ncoherence following the rules of statistics\nincoherence or Dutch book one would be guaranteed to lose money.\n\n\n\n\n\n\n\n\nFigure 3.5: Bruno de Finetti\n\n\n\n\n\n\n\n\nTipBiographical note on Bruno de Finetti\n\n\n\n\n\n\nFrom the subjective standpoint, no assertion is possible without a priori opinion, but the variety of possible opinions makes problems depending on different opinions interesting.\n\nBruno de Finetti 1906-1985 was born in Innsbruck (Austria) to an Italian family. He studied mathematics at the University of Trieste, where he developed a keen interest in probability theory and its applications.\nAfter completing his doctoral studies in 1928, de Finetti embarked on a distinguished academic career. His first research work dealt with mathematical biology and was published, in 1926 when he was still an undergraduate. After graduation and up to 1931, he worked in the mathematical office of the Central Italian Agency for Statistics. From 1931-46, de Finetti worked in Trieste at Assicurazioni Generali, one of the most important insurance companies in Italy. In the same period, he lectured at the University of Trieste and the University of Padua.\nOne of de Finetti’s most significant contributions was his development of the theory of subjective probability, also known as the Bayesian interpretation of probability. He developed his ideas independently of F. P. Ramsey who also published on this (Ramsey 1926)\nIn his seminal work, (Finetti 1937), he proposed that probability should be interpreted as a personal measure of belief or degree of uncertainty rather than as a frequency or long-run proportion. This subjective approach allowed for the incorporation of prior information and updating of beliefs in light of new data, forming the basis of Bayesian inference.\n\nProbabilistic reasoning – always to be understood as subjective – merely stems from our being uncertain about something. (Finetti 2017 § preface)\n\nIt is impossible to summarize in a few paragraphs the scientific activity of de Finetti in the different fields of mathematics (probability), measure theory, analysis, geometry, mathematics of finance, economics, the social sciences, teaching, computer science, and biomathematics or to describe his generous and complex personality as a scientist and a humanitarian. De Finetti discussed his own life in a book edited by Gani (1982). See also the article by Lindley (1989).\n\nMy thesis, paradoxically, and a little provocatively, but nonetheless genuinely, is simply this :  PROBABILITY DOES NOT EXIST.  … Probability, too, if regarded as something endowed with some kind of objective existence, is no less a misleading misconception, an illusory attempt to exteriorize or materialize our true probabilistic beliefs. (Finetti 2017 § preface page x)\n\nde Finetti was a brilliant statistician but his books and papers have garnered a reputation of being challenging to read both in the original Italian, French and English translation. The above quote embodies his radical point of view which he challenged other statisticians to rethink their views.\nWhat I think he meant is that meant primarily was that probabilities unlike physical quantities cannot be measured in the objective sense. de Fineti was well versed with quantum mechanics, where physical quantities like the position and speed of an electron are interpreted primarily through probabilities in a wave equation, to include a discussion in the start of his second volume.\nA large part of this course is that we are inferring parameters - which are often probabilities.\nAnother milestone result by de Finetti is his theorem\n\n\n\n\n\n\n\n\n\nNoteQuestion\n\n\n\n\n\nRepresenting uncertainty with probability: Don’t use any outside information on this question, just determine probabilities subjectively. The country of Chile is divided into 15 administrative regions. The size of the country is 756,096 square kilometers. How big do you think the region of Atacama is? Let:\n\nA_1 be the event: Atacama is less than 10,000 km^2.\nA_2 be the event: Atacama is between 10,000 and 50,000 km^2\nA_3 be the event: Atacama is between 50,000 and 100,000 km^2\nA_4 be the event: Atacama is more than 100,000 km^2 Assign probabilities to A_1 \\ldots A_4\n\n\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n0\n10k\n\\frac{1}{4}\n\n\nA_2\n10k\n50k\n\\frac{1}{4}\n\n\nA_3\n50k\n100k\n\\frac{1}{4}\n\n\nA_4\n100k\n\n\\frac{1}{4}\n\n\n\n\nWhat do I know at this point?\n\nThe expected area for the region is \\frac{750,000}{15}=50,000\\ km^2 .\n\nWhat Do I believe?\n\nI believe that the administrative regions have significantly different sizes\nfrom my familiarity with some other countries.\nAs I don’t know if Atacama is large or small my best bet is to assign equal probabilities to each event.\n\n\n\n\n\n\n\n\nNoteMore information 1\n\n\n\nAtacama is the fourth largest of 15 regions. Using this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10k\n\\frac{1}{16}\n\n\nA_2\n10k\n50k\n\\frac{3}{16}\n\n\nA_3\n50k\n100k\n\\frac{6}{16}\n\n\nA_4\n100k\n\n\\frac{6}{16}\n\n\n\n\nWhat do I know?\n\nThe expected area is \\frac{750,000}{15}=50,000\\ km^2 .\nI know that Atacama is the Fourth largest.\n\nWhat Do I believe?\n\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\n\nHow do I revise my guesstimate?\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3 .\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out.\nA_1 seems extremely unlikely as it necessitates the top three regions account for almost all of the area of the country. \\frac{750,000 - 14 * 10,000}{3} = 203,333.3 that’s about 4 times the average for each state.\nA_2 is fairly unlikely to require the top three regions to account for \\frac{(750,000-14*20000)}{3}=170,000 each that’s more than 3 times the average.\n\n\n\n\n\n\n\n\nNoteMore information 2\n\n\n\nThe smallest region is the capital region, Santiago Metropolitan, which has an area of 15,403 km^2. Using this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10k\n0\n\n\nA_2\n10k\n50k\n\\frac{1}{8}\n\n\nA_3\n50k\n100k\n\\frac{4}{8}\n\n\nA_4\n100k\n\n\\frac{3}{8}\n\n\n\nWhat do I know?\n\nThe expected area is \\frac{750,000}{15}=50,000 \\quad km^2\n\\mathbb{P}r(A_1)=0 since the smallest region is $ 15,403 km^2$.\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\nI know that Atacama is the Fourth largest.\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3.\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out. But A1 and A2 are now very unlikely as they would require the top three regions to account for almost all of the area of the country.\n\n\n\n\n\n\n\n\nNoteMore information 3\n\n\n\nThe third largest region is Aysén del General Carlos Ibáñez del Campo, which has an area of 108,494 km^2.\nUsing this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10K\n0\n\n\nA_2\n10k\n50K\n\\frac{1}{8}\n\n\nA_3\n50k\n100K\n\\frac{6}{8}\n\n\nA_4\n100k\n\n\\frac{1}{8}\n\n\n\n\nThe expected area is \\frac{750,000}{15}=50,000 \\quad km^2\n\\mathbb{P}r(A1)=0 since the smallest region is $15,403 km^2 $ .\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\nI know that Atacama is the Fourth largest.\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3 .\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out. But A1 and A2 are now very unlikely as they would require the top three regions to account for almost all of the area of the country.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-discussions-objectivity",
    "href": "C1-L01.html#sec-discussions-objectivity",
    "title": "3  M1L1 - Probability",
    "section": "3.6 Discussions: Objectivity",
    "text": "3.6 Discussions: Objectivity\n\n\n\n\n\n\nTipDiscussion: Objectivity\n\n\n\nIn what ways could the frequentist paradigm be considered objective? In what ways could the Bayesian paradigm be considered objective? Identify ways in which each paradigm might be considered subjective.\n\nFrequentist:\n\nThe orthodox approach is statisticians should establish an objective statistical methodology and field researchers should then use it to solve their problems. This leads to following flow charts for analysis and tests without fully understanding the model and how it works. At best one makes mistakes due to misunderstanding. But we can see that there is a systematic gaming of this methodology using p-hacking, multiple hypotheses, and hiding failed experiments leading to the publication of outrageously good results, which then cannot be replicated.\nThe analysis is done on data that is supposedly sampled from a population. But the same data may belong to different populations (the city, the country, etc) each with different statistics. We should assume the same long-run frequencies would converge to different to each one of these statistics if we repeat the experiment enough times.\nThe sample size, or how long we run the experiment is a tricky decision to make in advance and without prior knowledge. And if we do not decide in advance, but periodically as the data comes in. It turns out that this can completely change the outcomes of the experiment - even if both approaches have the same data.\nThe choice of H_0 and H_1 is often subjective and each hypothesis can lead to yet another.\nThe choice of the confidence level 95%, 99%, etc. used for statistical significance is subjective.\nIf an effect size is considered large is subjective and depends on the field one studies.\n\nBayesian:\n\nthe prior should be highly informative and therefore subjective. But it can be\nuninformative and hence more objective.\nit can be difficult to decide what impact the prior should have on the posterior. Ideally, we can quantify the effective sample size for the prior data and we can understand how much information each contributes to the posterior.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-expected-values",
    "href": "C1-L01.html#sec-expected-values",
    "title": "3  M1L1 - Probability",
    "section": "3.7 Expected values",
    "text": "3.7 Expected values\nThe expectation of an RV is a measure of its central tendency.\nThe expected value, also known as the expectation or mean, of a random variable X is denoted \\mathbb{E}[X]. It is the weighted average of all values X could take, weighted by their probabilities.\n\n\n\n\n\n\nTip\n\n\n\n\nI looked this up and found the following answer, see (https://math.stackexchange.com/users/25097/autolatry) (n.d.).\nThe RV X is a function whereas the Expectation is a Functional (a mapping from a function to a number). Mathematicians adopt the use of square brackets for functionals.\nSee Wikipedia contributors (2023) for more information on what a Functional is.\n\n\nWhy Square Brackets for Expectation\n3.7.1 Expectation of a discrete random variable\nIf X is a discrete-valued random variable then its expectation is defined by(?eq-expectation-discrete-RV)\n\n\\mathbb{E}[X]=\\sum^N_{i=1} x_i \\cdot \\mathbb{P}r(X=x_i) = \\sum^N_{i=1} x_i \\cdot f(x)\n\\tag{3.23}\nwhere f(x) is the probability mass function (PMF) of X.\n\n\n3.7.2 Expectation of a continuous random variable\nIf X is a continuous random variable then its expectation is defined by(?eq-expectation-continuous-RV)\n\n\\mathbb{E}[X]=\\int_{-\\infty}^{\\infty} x \\cdot f(x) dx\n\\tag{3.24}\nwhile the mean is an important descriptive statistic for central tendencies, we often prefer the median which is robust to outliers, and pick the mode as a representative if we need a value in the data set.\n\n\n3.7.3 Properties of Expectation\nSum and integral are linear operators so the Expectation is also a linear operator\n\n\\mathbb{E}[c]= c\n\\tag{3.25}\n\n\\mathbb{E}[aX+bY] = a\\mathbb{E}[X] + b\\mathbb{E}[Y]\n\\tag{3.26}\n\n\\mathbb{E}[g[X]]  = \\int{g(x)f(x)dx}\n\\tag{3.27}\nwhere g[X] is a function of the random variable X.\nIf X & Y are independent\n\n\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y]\n\\tag{3.28}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-variance",
    "href": "C1-L01.html#sec-variance",
    "title": "3  M1L1 - Probability",
    "section": "3.8 Variance",
    "text": "3.8 Variance\nVariance is the dispersion of a distribution about the mean.\n\nDefinition 3.16 For a discrete random variable, the Variance is defined using (Equation 3.29)\n\n\\mathbb{V}ar(X)=\\sum^N_{i=1} (x_i-\\mu)^2 \\mathbb{P}r(X=x_i)\n\\tag{3.29}\n\n\nDefinition 3.17 For a continuous random variable, the Variance is defined using (Equation 3.30)\n\n\\mathbb{V}ar[X]=\\int_{- \\infty}^{\\infty} (x-\\mu)^2 f(x)dx\n\\tag{3.30}\n\n\n3.8.1 Properties of Variance\n\n\\mathbb{V}ar[c] = 0\n\\tag{3.31}\nif X and Y are independent then\n\n\\mathbb{V}ar[aX+by] = a^2\\mathbb{V}ar[X] +b^2\\mathbb{V}ar[Y]\n\\tag{3.32}\notherwise\n\n\\mathbb{V}ar[aX+by] = a^2\\mathbb{V}ar[X] +b^2\\mathbb{V}ar[Y] + 2ab\\mathbb{C}ov(X,Y)\n\\tag{3.33}\nwhere \\mathbb{C}ov(X,Y) is the covariance of X and Y.\nHere is one of the most useful identities (Equation 3.34) for wrangling with variance using the expectation of X and X^2.\n\n\\begin{aligned}\n    \\mathbb{V}ar[X] &= \\mathbb{E}[(X- \\mathbb{E}[X])^2]\n    \\\\&= \\mathbb{E}[X^2] − (\\mathbb{E}[X])^2\n\\end{aligned}\n\\tag{3.34}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-covariance",
    "href": "C1-L01.html#sec-covariance",
    "title": "3  M1L1 - Probability",
    "section": "3.9 Covariance",
    "text": "3.9 Covariance\nCovariance is a measure of the joint variability of two random variables. It indicates the direction of the linear relationship between the variables.\nIf X and Y are two random variables, the covariance of X and Y is defined as:\n\n\\begin{aligned}\n\\mathrm{Cov}(X,Y) &= \\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])]\n\\\\ &= \\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]\n\\end{aligned}\n\\tag{3.35}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-correlation",
    "href": "C1-L01.html#sec-correlation",
    "title": "3  M1L1 - Probability",
    "section": "3.10 Correlation",
    "text": "3.10 Correlation\nCorrelation is a standardized measure of the linear relationship between two random variables. It is a dimensionless quantity that ranges from -1 to 1.\nThe correlation coefficient \\rho_{XY} is defined as the covariance of X and Y divided by the product of their standard deviations:\n\n\\rho_{XY} = \\frac{\\mathrm{Cov}(X,Y)}{\\sigma_X\\sigma_Y}\n\\tag{3.36}\n\n\n\n\n\n\nFinetti, Bruno de. 1937. “La Prévision: Ses Lois Logiques, Ses Sources Subjectives.” Annales de l’Institut Henri Poincaré 7 (1): 1–68.\n\n\n———. 2017. “Theory of Probability.” Edited by Antonio Machí and Adrian Smith. Wiley Series in Probability and Statistics, January. https://doi.org/10.1002/9781119286387.\n\n\n(https://math.stackexchange.com/users/25097/autolatry), Autolatry. n.d. “Why Square Brackets for Expectation.” Mathematics Stack Exchange. https://math.stackexchange.com/q/1302543.\n\n\nMoivre, Abraham De. 1718. The Doctrine of Chances. H. Woodfall. https://tellingstorieswithdata.com.\n\n\nRamsey, Frank P. 1926. “Truth and Probability.” In The Foundations of Mathematics and Other Logical Essays, edited by R. B. Braithwaite, 156–98. McMaster University Archive for the History of Economic Thought. https://EconPapers.repec.org/RePEc:hay:hetcha:ramsey1926.\n\n\nWikipedia contributors. 2023. “Functional (Mathematics) — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Functional_(mathematics)&oldid=1148699341.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>M1L1 - Probability</span>"
    ]
  },
  {
    "objectID": "C1-L01-Ex1.html",
    "href": "C1-L01-Ex1.html",
    "title": "4  Homework on paradigms of probability",
    "section": "",
    "text": "Exercise 4.1 paradigms\nIf you randomly guess the answer to this question, you have a .25 probability of being correct. Which probabilistic paradigm from Lesson 1 does this argument best demonstrate?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nClassical\n\n\n\n\nExercise 4.2 paradigms\nOn a multiple-choice test, you do not know the answer to a question with three alternatives. One of the options, however, contains a keyword that the professor used disproportionately often during lectures. Rather than randomly guessing, you select the option containing the keyword, supposing you have a better than 1/3 chance of being correct.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nBayesian\n\n\n\n\nExercise 4.3 paradigms\nOn average, one in three students at your school participates in extracurricular activities. You conclude that the probability that a randomly selected student from your school participates is 1/3. Which probabilistic paradigm from Lesson 1 does this argument best demonstrate?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nFrequentist\n\n\n\n For Questions Exercise 4.4-Exercise 4.6, consider the following scenario:Chess\nYour friend offers a bet that she can beat you in a game of chess. If you win, she owes you USD 5, but if she wins, you owe her 3 USD.\n\nExercise 4.4 Chess\nSuppose she is 100% confident that she will beat you. What is her expected return for this game?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nIf she is certain she will win, then she can expect to receive 3 USD.\n3 \\cdot (1) − 5 \\cdot (0).\n\n\n\n\nExercise 4.5 Chess\nSuppose she is only 50% confident that she will beat you (her personal probability of winning is p=0.5). What is her expected return now?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n3 \\cdot (0.5) − 5 \\cdot (0.5) = -1.\n\n\n\n\nExercise 4.6 Chess\nNow assuming your friend will only agree to fair bets (expected return of 0 USD), find her personal probability that she will win.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nAny value of p (the probability of her winning) lower than \\frac{5}{8} would result in a negative expected return for your friend. She would not have offered these odds for such a p\n\n\n\n For Questions Exercise 4.7-Exercise 4.8, consider the following “Dutch book” scenario:Dutch book\nSuppose your friend offers a pair of bets:\n\nB1: if it rains or is overcast tomorrow, you pay him 4 USD, otherwise, he pays you 6 USD.\nB2: if it is sunny you pay him 5 USD, otherwise, he pays you 5 USD.\n\n\nExercise 4.7 Dutch book\nSuppose rain and overcast are the only events in consideration. If you make both bets simultaneously, this is called a “Dutch book,” as you are guaranteed to win money. How much do you win regardless of the outcome?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\ndef l01q07():\n    p  = {'overcast':1/3,'sunny':1/3}\n    o1 = {'overcast':-4,'sunny':6}\n    o2 = {'overcast':5,'sunny':-5}\n    dutch_df=pd.DataFrame({'o1':o1,'o2':o2})\n    return dutch_df.sum(axis=1)\n\nl01q07()\n\n\novercast    1\nsunny       1\ndtype: int64\n\n\n\n\n\n\nExercise 4.8 Dutch book\nYour friend doesn’t understand the laws of probability. Let’s examine the bets he offered:\n\nFor bet 1 to be fair, his probability that it is overcast must be .6 (you can verify this by calculating his expected return and setting it equal to 0 USD).\nFor bet 2 to be fair, his probability that it will be sunny must be .5.\n\nThis results in a “Dutch book” because your friend’s probabilities are not coherent. They do not add up to 1.\nWhat do they add up to?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n  \\begin{aligned}\n  \\\\  0                  & \\stackrel{set}{=}   \\mathbb{E}(B1)       && \\text{fairness defn}\n  \\\\                     &= -4  \\mathbb{P}r( overcast) + 6  \\mathbb{P}r(sunny)          && \\text{bet 1 terms}\n  \\\\                     &= -4  \\mathbb{P}r( overcast) + 6  [1-\\mathbb{P}r( overcast)]  && \\text{prob. complement}\n  \\\\                     &= -4  \\mathbb{P}r( overcast) + 6-6\\mathbb{P}r( overcast)      && \\text{expanding}\n  \\\\  10 \\mathbb{P}r(overcast)     &= 6                                       && \\text{collecting}\n  \\\\  \\mathbb{P}r(overcast)        &= 0.6  \n  \\\\\n  \\\\  0                  & \\stackrel{set}{=} \\mathbb{E}(B2)         && \\text{fairness def}\n  \\\\                     &= 5 \\mathbb{P}r(overcast)  - 5 \\mathbb{P}r(sunny)             && \\text{bet 2  terms}\n  \\\\                     &= 5 [1-\\mathbb{P}r(sunny)] - 5   \\mathbb{P}r(sunny)           && \\text{prob. complement}\n  \\\\                     &= 5 -5 \\mathbb{P}r(sunny) - 5   \\mathbb{P}r(sunny)            && \\text{expanding }\n  \\\\  10  \\mathbb{P}r(sunny)       &= 5                                       && \\text{  collecting}\n  \\\\  \\mathbb{P}r(sunny)  &= 0.5\n  \\\\ \\therefore \\mathbb{P}r(sunny) + \\mathbb{P}r( overcast) &= 1.1                      && \\text{incoherent (dutch book)}\n  \\end{aligned}\n\n\n\n\nnote:\nThese exercises introduced some bets and let us look at different notions of a fair bet B1 more concretely. We determine fairness by setting Expected payoffs to be zero for the opposite bet \\hat{B1}\n\n\\begin{aligned}\n    \\mathbb{E}[\\mathbb{P}r(B1) - \\mathbb{P}r(\\bar{B1})] &= \\text{payoff}(B1) \\times \\mathbb{P}r(B1) - \\text{payoff}(\\bar{B1}) \\times \\mathbb{P}r(\\bar{B1}) = 0\n    \\\\ &= \\text{payoff}(B1) \\times \\mathbb{P}r(B1) - \\text{payoff}(\\bar{B1}) \\times 1(- \\mathbb{P}r(B1)) = 0\n\\end{aligned}\n\nWe also saw a couple of bets that are not coherent - I.E. although the events are mutually exclusive, their probabilities do not add up to one. This means some combinations will always lose and others always win money. We call this a Dutch Book",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Homework on paradigms of probability</span>"
    ]
  },
  {
    "objectID": "C1-L02.html",
    "href": "C1-L02.html",
    "title": "5  M1L2 - Bayes’ Theorem",
    "section": "",
    "text": "5.1 Bayes’ Theorem",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>M1L2 - Bayes' Theorem</span>"
    ]
  },
  {
    "objectID": "C1-L02.html#sec-conditional-probability",
    "href": "C1-L02.html#sec-conditional-probability",
    "title": "5  M1L2 - Bayes’ Theorem",
    "section": "5.2 Conditional Probability",
    "text": "5.2 Conditional Probability\n\n\n\n\n\n\n\nFigure 5.1: conditional probability\n\n\n\n\\mathbb{P}r(A \\mid B)=\\frac{\\mathbb{P}r(A \\cap B)}{\\mathbb{P}r(B)}\n\\tag{5.1}\nindependence\n\n\\mathbb{P}r(A \\mid B) = \\mathbb{P}r(A) \\implies \\mathbb{P}r(A \\cap B) = \\mathbb{P}r(A)\\mathbb{P}r(B)\n\\tag{5.2}\n\n5.2.1 Conditional Probability Example - Female CS Student\nSuppose there are 30 students, 9 of whom are female. Of the 30 students, 12 are computer science majors. 4 of those 12 computer science majors are female.\nWe want to estimate what is the probability of a student being female given that she is a computer science major\nWe start by writing the above in the language of probability by converting frequencies to probabilities. We start with the marginal.\nFirst, the probability of a student being female from the data given above.\n\n\\mathbb{P}r(Female) = \\frac{9}{30} = \\frac{3}{10}\n\nNext, we estimate the probability of a student being a computer science major again just using the data given above.\n\n\\mathbb{P}r(CS) = \\frac{12}{30} = \\frac{2}{5}\n\nNext, we can estimate the joint probability, i.e. the probability of being female and being a CS major. Again we have been given the numbers in the data above.\n\n\\mathbb{P}r(F\\cap CS) = \\frac{4}{30} = \\frac{2}{15}\n\nFinally, we can use the definition of conditional probability and substitute the above\n\n\\mathbb{P}r(F \\mid CS) = \\frac{\\mathbb{P}r(F \\cap CS)}{\\mathbb{P}r(CS)} = \\frac{2/15}{2/5} = \\frac{1}{3}\n\n\nAn intuitive way to think about a conditional probability is that we’re looking at a sub-segment of the original population, and asking a probability question within that segment\n\n\\mathbb{P}r(F \\mid CS^c) = \\frac{\\mathbb{P}r(F\\cap CS^c)}{PS(CS^c)} = \\frac{5/30}{18/30} = \\frac{5}{18}\n\nThe concept of independence is when one event does not depend on another.\n\nA \\perp \\!\\!\\! \\perp B \\iff \\mathbb{P}r(A \\mid B) = \\mathbb{P}r(A)\n\nIt doesn’t matter that B occurred.\nIf two events are independent then the following is true:\n\nA \\perp \\!\\!\\! \\perp B \\iff \\mathbb{P}r(A\\cap B) = \\mathbb{P}r(A)\\mathbb{P}r(B)\n\\tag{5.3}\nThis can be derived from the conditional probability equation.\n\n5.2.2 Inverting Conditional Probabilities\nIf we don’t know \\mathbb{P}r(A \\mid B) but we do know the inverse probability \\mathbb{P}r(B \\mid A) is. We can then rewrite \\mathbb{P}r(A \\mid B) in terms of \\mathbb{P}r(B \\mid A)\n\n\\mathbb{P}r(A \\mid B) = \\frac{\\mathbb{P}r(B \\mid A)\\mathbb{P}r(A)}{\\mathbb{P}r(B \\mid A)\\mathbb{P}r(A) + \\mathbb{P}r(B \\mid A^c)\\mathbb{P}r(A^c)}\n\\tag{5.4}\n\n\n5.2.3 Conditional Probability Example - ELISA HIV test\n\n\n\n\n\n\n\nVideo 5.1\n\n\nLet’s look at an example of an early test for HIV antibodies known as the ELISA test. - The test has a true positive rate of 0.977. - It has a true negative rate of 0.926. - The incidence of HIV in North America is .0026.\nNow we want to know the probability of an individual having the disease given that they tested positive \\mathbb{P}r(HIV | +).\nThis is the inverse probability of the true positive, so we will need to use Bayes’ theorem.\nWe start by encoding the above using mathematical notation, so we know what to substitute into Bayes’ theorem.\nThe true positive rate is:\n\n\\mathbb{P}r(+ \\mid HIV) = 0.977\n\nThe true negative rate is:\n\n\\mathbb{P}r(- \\mid NO\\_HIV) = 0.926\n\nThe probability of someone in North America having this disease was\n\n\\mathbb{P}r(HIV) = .0026\n\nwhat we want is: \\mathbb{P}r(HIV \\mid +)\n\n\\begin{aligned}\n\\mathbb{P}r(HIV \\mid +) &= \\frac{\\mathbb{P}r(+ \\mid HIV)\\mathbb{P}r(HIV)}{\\mathbb{P}r(+ \\mid HIV)\\mathbb{P}r(HIV) + \\mathbb{P}r(+ \\mid NO\\_HIV){\\mathbb{P}r(NO\\_HIV)}}  \\\\ &= \\frac{(.977)(.0026)}{(.977)(.0026) + (1-.977)(1-.0026)}  \\\\ &=  0.033\n\\end{aligned}\n\nThis is a bit of a surprise - although the test has 90% + true and false accuracy - taking it once is only valid 3% of the time. How is this possible?\nWhat happens in Bayes law is that we are updating probabilities. And since we started with such a low probability of .0026, Bayesian updating only brings it up to 0.03.\n\n\\begin{aligned}\n\\mathbb{P}r(A \\mid B) = \\frac{\\mathbb{P}r(B \\mid A_1){(A_1)}}{\\sum_{i=1}^{n}{\\mathbb{P}r(B \\mid A_i)}\\mathbb{P}r(A_i)} \\end{aligned}\n\n\nNote: (McElreath (2015)) discusses how this can be presented less surprisingly.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>M1L2 - Bayes' Theorem</span>"
    ]
  },
  {
    "objectID": "C1-L02.html#sec-bayes-theorem-video",
    "href": "C1-L02.html#sec-bayes-theorem-video",
    "title": "5  M1L2 - Bayes’ Theorem",
    "section": "5.3 Bayes’ theorem (Video)",
    "text": "5.3 Bayes’ theorem (Video)\n\n\n\n\n\n\n\nVideo 5.2: Bayes Theorem in Probability with Examples\n\n\n\n\n\n\n\n\nFigure 5.2: Bayes theorem\n\n\n\nHere are a few formulations of Bayes’ theorem. We denote H for our hypothesis and E as our evidence i.e. the data!\nWe start by using the definition of conditional probability:\n\n\\mathbb{P}r(A \\mid B) = \\frac{ \\mathbb{P}r(A \\cap B)}{\\mathbb{P}r(B)} \\quad \\text{(conditional probability)}\n\n\n\\begin{aligned}\n{\\color{orange} \\overbrace{\\color{orange} \\mathbb{P}r(H|E)}^{\\text{Posterior}}} &= \\frac{  {\\color{pink} \\overbrace{\\color{pink} \\mathbb{P}r(H \\cap E)}^{\\text{Joint}}}  } {  {\\color{green} \\underbrace{{\\color{green} \\mathbb{P}r(\\text{E})}}_{\\text{Marginal Evidence}}} } \\\\ &= \\frac{  {\\color{red} \\overbrace{\\color{red} P (\\text{H})}^{\\text{Prior}}} \\cdot  {\\color{blue} \\overbrace{\\color{blue} P (E \\mid H)}^{\\text{Likelihood}}} } { {\\color{green} \\underbrace{{\\color{green} \\mathbb{P}r(E)}}_{\\text{Marginal Evidence}}} } \\\\ &= \\frac{  {\\color{red} \\overbrace{\\color{red} P (H)}^{\\text{Prior}}} \\cdot {\\color{blue} \\overbrace{\\color{blue} P (E \\mid H)}^{\\text{Likelihood}}} }{  {\\color{green} \\underbrace{\\color{green} \\mathbb{P}r(E \\mid H) \\mathbb{P}r(H) + \\mathbb{P}r(E \\mid H^c) \\mathbb{P}r(H^c)  }_{\\text{Marginal Evidence}}}}\n\\end{aligned}\n\nWe can extend Bayes theorem to cases with multiple mutually exclusive events:\n\n\n\n\n\n\n\nFigure 5.3: mutually exclusive events\n\n\nif H_1 \\ldots H_n are mutually exclusive events that sum to 1:\n\n\\begin{aligned} \\mathbb{P}r(H_1 \\mid E)\n  & = \\frac{\\mathbb{P}r(E \\mid H)\\mathbb{P}r(H_1)}{\\mathbb{P}r(E \\mid H_1)\\mathbb{P}r(H_1) +\\ldots  + \\mathbb{P}r(E \\mid H_n)\\mathbb{P}r(H_N)} \\\\\n  & = \\frac{\\mathbb{P}r(E \\mid H)\\mathbb{P}r(H_1)}{\\sum_{i=1}^{N} \\mathbb{P}r(E \\mid H_i)\\mathbb{P}r(H_i)} \\end{aligned}\n\nwhere we used the law of total probability in the denominator\nif \\{B_i\\} is a finite or countably finite partition of a sample space then\n\n\\mathbb{P}r(A) = {\\sum_{i=1}^{N} \\mathbb{P}r(A \\cup B_i)}= {\\sum_{i=1}^{N} \\mathbb{P}r(A \\mid B_i)\\mathbb{P}r(B_i)}\n\n\n{\\color{orange} P (\\text{H} \\mid \\text{E})} = \\frac {{\\color{red} \\mathbb{P}r(\\text{H})} \\times {\\color{blue}\\mathbb{P}r(\\text{E} \\mid \\text{H})}} {\\color{gray} {\\mathbb{P}r(\\text{E})}}\n\n\n{\\color{orange} \\overbrace{\\color{orange} P (\\text{Unknown} \\mid \\text{Data})}^{\\text{Posterior}}} = \\frac {{\\color{red} \\overbrace{\\color{red} P (\\text{Unknown})}^{\\text{Prior}}} \\times {\\color{blue} \\overbrace{\\color{blue} P (\\text{Data} \\mid \\text{Unknown})}^{\\text{Likelihood}}}} {{\\color{green} \\underbrace{{\\color{green} \\mathbb{P}r(\\text{E})}}_{\\text{Average likelihood}}}}\n\nThe following is a video explaining Bayes law.\n\n\n\n\n\n\n\nVideo 5.3",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>M1L2 - Bayes' Theorem</span>"
    ]
  },
  {
    "objectID": "C1-L02.html#bayes-theorem-for-continuous-distributions",
    "href": "C1-L02.html#bayes-theorem-for-continuous-distributions",
    "title": "5  M1L2 - Bayes’ Theorem",
    "section": "5.4 Bayes’ Theorem for continuous distributions",
    "text": "5.4 Bayes’ Theorem for continuous distributions\nWhen dealing with a continuous random variable \\theta, we can write the conditional density for \\theta given y as:\n\nf(\\theta \\mid y) =\\frac{f(y\\mid\\theta)f(\\theta)}{\\int f(y\\mid\\theta) f(\\theta) d\\theta }\n\\tag{5.5}\nThis expression does the same thing that the versions of Bayes’ theorem from Lesson 2 do. Because \\theta is continuous, we integrate over all possible values of \\theta in the denominator rather than take the sum over these values. The continuous version of Bayes’ theorem will play a central role from Lesson 5 on.\n\n\n\n\n\n\n\nFigure 5.4: Rev. Thomas Bayes by Mark Riehl\n\n\n\n\n\n\n\n\nTipHistorical Note on The Reverend Thomas Bayes\n\n\n\nBayes Rule is due to Thomas Bayes (1701-1761) who was an English statistician, philosopher and Presbyterian minister. Although Bayes never published what would become his most famous accomplishment; his notes were edited and published posthumously by Richard Price.\n\n\n\n\n\n\n\n\nMcElreath, Richard. 2015. Statistical Rethinking, a Course in r and Stan.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>M1L2 - Bayes' Theorem</span>"
    ]
  },
  {
    "objectID": "C1-L02-Ex1.html",
    "href": "C1-L02-Ex1.html",
    "title": "6  Conditional Probability and Bayes’ Law",
    "section": "",
    "text": "6.1 Homework - Conditional Probability and Bayes’ Law\nCode\nimport pandas as pd\ndf=pd.read_csv(\"data/titanic.csv\",index_col='class')\nprint(df) \n\n\n       survived  drowned\nclass                   \n1           203      122\n2           118      167\n3           178      528\n0           212      673\nagain I put the data for this into a CSV file and loaded it as follows\nCode\nimport pandas as pd\n\nmdf=pd.read_csv(\"data/marbles.csv\",index_col='bag')\nprint(mdf) \n\n\n     red  blue\nbag           \na    2.0   3.0\nb    5.0   1.0\nc    3.0   0.0",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability and Bayes' Law</span>"
    ]
  },
  {
    "objectID": "C1-L02-Ex1.html#homework---conditional-probability-and-bayes-law",
    "href": "C1-L02-Ex1.html#homework---conditional-probability-and-bayes-law",
    "title": "6  Conditional Probability and Bayes’ Law",
    "section": "",
    "text": "I put the data from the Titanic for this problem into a .csv file and loaded it into a data frame as follows:Titanic data\n\n\nExercise 6.1  If we randomly select a person’s name from the complete list of passengers and crew, what is the probability that this person traveled in 1st class? Round your answer to two decimal places.Titanic data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q01(df):\n    return  round(df.loc[1].sum() / df.values.sum(),2)\nl02q01(df)\n\n\n0.15\n\n\n\n\n\n\nExercise 6.2  What is the probability that a (randomly selected) person survived? Round your answer to two decimal places.Titanic data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q02(df):\n    return  round(df.survived.sum() / df.values.sum(),2)\n\nl02q02(df)\n\n\n0.32\n\n\n\n\n\n\nExercise 6.3  What is the probability that a (randomly selected) person survived, given that they were in 1st class? Round your answer to two decimal places.Titanic data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q03(df):\n    return round(\n        df.loc[1,'survived'].sum() /\n        df.loc[1,].sum(),\n        2)\n\nl02q03(df)\n\n\n0.62\n\n\n\n\n\n\nExercise 6.4  True/False: The events concerning class and survival are statistically independent.Titanic data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nFalse\n\n\n\n You have three bags, labeled A, B, and C. Bag A contains two red marbles and three blue marbles. Bag B contains five red marbles and one blue marble. Bag C contains three red marbles only.Marbles data\n\n\n\nExercise 6.5  If you select from bag B, what is the probability that you will draw a red marble?Marbles data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q05(df):\n    p = {}\n    p['red n b'] = df.loc['b','red'].sum() / df.loc['b',].sum()\n    \n    print(f\"pr['red n b'] = {df.loc['b','red'].sum()} / {df.loc['b',].sum()} = {p['red n b']}\")        \n\nl02q05(mdf)\n\n\npr['red n b'] = 5.0 / 6.0 = 0.8333333333333334\n\n\n\n\n\n\nExercise 6.6  If you randomly select one of the three bags with equal probability, so that \\mathbb{P}r(A)=\\mathbb{P}r(B)=\\mathbb{P}r(C)=1/3, and then randomly draw a marble from that bag, what is the probability that the marble will be blue? Round your answer to two decimal places.Marbles data\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nThis is the marginal probability \\mathbb{P}r(blue). You can obtain this using the law of total probability (which appears in the denominator of Bayes’ theorem). It is\n\n\\begin{aligned}\n    \\mathbb{P}r(blue) &= \\mathbb{P}r(blue \\cap A) + \\mathbb{P}r(blue \\cap B) + \\mathbb{P}r(blue \\cap C)\n    \\\\      &= \\mathbb{P}r(blue \\mid A) \\cdot \\mathbb{P}r(A)+\\mathbb{P}r(blue \\mid B)\\cdot \\mathbb{P}r(B) + \\mathbb{P}r(blue \\mid C) \\cdot \\mathbb{P}r(C)\n    \\end{aligned}\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q06(df):\n    p = {}\n    for bag in ['a','b','c']:\n        p[f'blue|{bag}'] = df.loc[bag,'blue'] / df.loc[bag,].sum() \n        p[bag] = 1/3\n        p[f'blue n {bag}'] =  p[f'blue|{bag}'] * p[bag]\n    return round(p['blue n a'] +  p['blue n b'] +  p['blue n c'],2)  \n\nprint(f'pr(blue)={l02q06(mdf)}')\n\n\npr(blue)=0.26\n\n\n\n\n\n\nExercise 6.7  Suppose a bag is randomly selected (again, with equal probability), but you do not know which it is. You randomly draw a marble and observe that it is blue. What is the probability that the bag you selected this marble from is A? That is, find \\mathbb{P}r(A\\mid \\text{blue}).Marbles data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q07(df):\n    p = {}\n    for bag in ['a','b','c']:\n        p[f'blue|{bag}'] = df.loc[bag,'blue'] / df.loc[bag,].sum() \n        p[bag] = 1/3\n        p[f'blue n {bag}'] =  p[f'blue|{bag}'] * p[bag]   \n    p['blue']= p['blue n a'] +  p['blue n b'] +  p['blue n c'] \n    p['a|blue']=p['blue|a']*p['a']/p['blue']\n    return p \n\np=l02q07(mdf)\nprint(f\"{p['a|blue']=:1.2f}\")\n\n\np['a|blue']=0.78\n\n\n\n\n\n\nExercise 6.8  Suppose a bag is randomly selected (again, with equal probability), but you do not know which it is. You randomly draw a marble and observe that it is blue. What is the probability that the bag you selected is C? That is, find \\mathbb{P}r(C\\mid \\text{blue}).Marbles data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q08(df):\n    p = {}\n    for bag in ['a','b','c']:\n        p[f'blue|{bag}'] = df.loc[bag,'blue'] / df.loc[bag,].sum() \n        p[bag] = 1/3\n        p[f'blue n {bag}'] =  p[f'blue|{bag}'] * p[bag] \n    p['blue']= p['blue n a'] +  p['blue n b'] +  p['blue n c'] \n    p['z|blue']=p['blue|a']*p['a']/p['blue']\n\n    p['c|blue']=p['blue|c']*p['c']/p['blue']\n\n    return p \n\np=l02q08(mdf)\nprint(f\"{p['c|blue']=:1.2f}\")\n\n\np['c|blue']=0.00\n\n\n\n\n\n\nExercise 6.9  Suppose a bag is randomly selected (again, with equal probability), but you do not know which it is. You randomly draw a marble and observe that it is red. What is the probability that the bag you selected is C? That is, find \\mathbb{P}r(C\\mid \\text{red}).Marbles data\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndef l02q09(df):\n    p = {}\n    for bag in ['a','b','c']:\n        p[f'blue|{bag}'] = df.loc[bag,'blue'] / df.loc[bag,].sum() \n        p[f'red|{bag}'] = df.loc[bag,'red'] / df.loc[bag,].sum() \n\n        p[bag] = 1/3\n        p[f'blue n {bag}'] =  p[f'blue|{bag}'] * p[bag]\n        p[f'red n {bag}'] =  p[f'red|{bag}'] * p[bag]\n\n    #print(f'{p}')\n    \n    p['blue'] = p['blue n a'] +  p['blue n b'] + p['blue n c'] \n    p['red' ] = p['red n a'] +  p['red n b'] + p['red n c'] \n    p['z|blue'] = p['blue|a'] * p['a'] / p['blue']\n    p['c|blue'] = p['blue|c'] * p['c'] / p['blue']\n    p['c|red' ] = p['red|c']  * p['c'] / p['red']\n\n    return p \n\np=l02q09(mdf)\nprint(f\"{p['c|red']=:1.2f}\")\n\n\np['c|red']=0.45",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability and Bayes' Law</span>"
    ]
  },
  {
    "objectID": "C1-L02-Ex2.html",
    "href": "C1-L02-Ex2.html",
    "title": "7  Conditional Probability and Bayes’ Law",
    "section": "",
    "text": "8 Probability and Bayes’ Theorem",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional Probability and Bayes' Law</span>"
    ]
  },
  {
    "objectID": "C1-L02-Ex2.html#homework-honors-1",
    "href": "C1-L02-Ex2.html#homework-honors-1",
    "title": "7  Conditional Probability and Bayes’ Law",
    "section": "8.1 Homework Honors 1",
    "text": "8.1 Homework Honors 1\n\nExercise 8.1 Which must be true if random variable X is a continuous RV with PDF f(x)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nf(x) \\ge 0 \\: \\forall x\n\\lim_{x \\to \\infty} f(x)=1\n\n\n\n\n\nExercise 8.2 If X∼Exp(3), what is the value of \\mathbb{P}r(X&gt;1/3)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n0.37\n\n\\begin{aligned}\n\\mathbb{P}r(X&gt;1/3) &= \\int_{1/3}^\\infty 3 e^{−3x} dx \\\\ &= −e|_{−3x}^\\infty \\\\ &= 0- (-e^{-3/3}) = e^-1 = 0.368 \\end{aligned}\n\n\n\n\n\nExercise 8.3 Suppose X∼Uniform(0,2) and Y∼Uniform(8,10). What is the value of \\mathbb{E}(4X+Y)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned} \\mathbb{E}(4X+Y)&=4\\mathbb{E}(X)+\\mathbb{E}(Y)\\\\&=4(1)+9 \\\\&= 13\\end{aligned}\n\n\n\n\n For the following questions:Adding normals\nSuppose X∼N(1,25) and Y∼N(−2,9) and that X and Y are independent. We have Z=X+Y∼N(μ,σ^2) because the sum of normal random variables also follows a normal distribution.\n\nExercise 8.4  What is the value of \\mu?Adding normals\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\\mu=\\mathbb{E}[Z]=\\mathbb{E}[X+Y]=\\mathbb{E}[X]+\\mathbb{E}[Y]=1+(−2)\n\n\n\n\nExercise 8.5  What is the value of σ^2?Adding normals\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nIf two random variables are independent, the variance of their sum is the sum of their variances.\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n=Var(Z)=Var(X+Y)=Var(X)+Var(Y)=25+9=34\n\n\n\n\nExercise 8.6  If RVs X and Y are not independent, we still have \n\\mathbb{E}(X+Y)=\\mathbb{E}(X)+\\mathbb{E}(Y)\nAdding normals\nbut now\n\n\\mathbb{V}ar(X+Y)=Var(X)+Var(Y)+2 Cov(X, Y)\n\nwhere\n\nCov(X, Y)=\\mathbb{E}[(X−\\mathbb{E}(X))\\cdot(Y−\\mathbb{E}(Y))]\n\nis called the covariance between X and Y.\n\n\n\n\n\n\nImportant\n\n\n\nA convenient identity for calculating variance:\n\n\\mathbb{V}ar(X) = \\mathbb{E}[(X−\\mathbb{E}[X])^2 ]=\\mathbb{E}[X^2]−(\\mathbb{E}[X])^2\n\n\n\nWhich of the following is an analogous expression for the covariance of X and Y?\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\n\nExpand the terms inside the expectation in the definition of Cov(X, Y)\nRecall that \\mathbb{E}(X) and \\mathbb{E}(Y) are just constants.\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nCov(X,Y) = \\mathbb{E}(XY)−\\mathbb{E}(X)\\mathbb{E}(Y)\n\nsince\n\n\\begin{aligned}\n    Cov(X,Y)&\\equiv \\mathbb{E}[(X−\\mathbb{E}[X])(Y−\\mathbb{E}[Y])] \\\\\n            &= \\mathbb{E}[XY−X\\mathbb{E}(Y)−\\mathbb{E}(X)Y+\\mathbb{E}(X)\\mathbb{E}(Y)] \\\\\n            &= \\mathbb{E}[XY]−\\mathbb{E}[X\\mathbb{E}(Y)]−\\mathbb{E}[\\mathbb{E}(X)Y]+\\mathbb{E}[\\mathbb{E}(X)\\mathbb{E}(Y)] \\\\\n            &= \\mathbb{E}[XY]-  \\mathbb{E}(X)\\mathbb{E}(Y)− \\cancel{ \\mathbb{E}(X)\\mathbb{E}(Y)}+\\cancel{\\mathbb{E}(X)\\mathbb{E}(Y)}\n\\end{aligned}\n\n\n\n\n\nExercise 8.7  Consider again X∼N(1,5^2) and Y∼N(−2,3^2), but this time X and Y are not independent. Then Z=X+Y is still normally distributed with the same mean found in (Exercise 8.4). What is the variance of Z if \\mathbb{E}(XY)=−5?Adding normals\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nUse the formulas introduced in Question (Exercise 8.6).\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\nVar(Z) &= Var(X) + Var(Y) + 2Cov(X,Y) \\\\ &= 25 + 9 + 2Cov(X,Y) \\\\ &= 34 + 2 (\\mathbb{E}[XY] − \\mathbb{E}[X] \\mathbb{E}[Y] ) \\\\  &= 34 + 2 (−5−1(−2))=34−2(3) =28\n\\end{aligned}\n\n\n\n\n\nExercise 8.8 Use the definition of conditional probability to show that for events A and B, we have\n\n\\begin{aligned}\n\\mathbb{P}r(A \\cap B) = \\mathbb{P}r(B \\mid A)\\mathbb{P}r(A) = \\mathbb{P}r(A \\mid B)\\mathbb{P}r(B)\n\\end{aligned}\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\n\\mathbb{P}r(B \\mid A)= \\frac{\\mathbb{P}r(A \\cap B)}{\\mathbb{P}r(A)} \\\\\\mathbb{P}r(B \\mid A)\\mathbb{P}r(A)=\\mathbb{P}r(A \\cap B)\n\\end{aligned}\n\n\n\n\n\nExercise 8.9 Show that the two expressions for independence \\mathbb{P}r(A∣B)=\\mathbb{P}r(A) and \\mathbb{P}r(A∩B) = \\mathbb{P}r(A)\\mathbb{P}r(B) are equivalent.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nPlug these expressions into those from (Exercise 8.8).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional Probability and Bayes' Law</span>"
    ]
  },
  {
    "objectID": "C1-L03.html",
    "href": "C1-L03.html",
    "title": "8  M1L3 - Distributions",
    "section": "",
    "text": "8.1 Distributions",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03.html#sec-the-bernoulli--binomial-distribution",
    "href": "C1-L03.html#sec-the-bernoulli--binomial-distribution",
    "title": "8  M1L3 - Distributions",
    "section": "8.2 The Bernoulli & Binomial Distribution",
    "text": "8.2 The Bernoulli & Binomial Distribution\n\n\n\n\n\n\n\nFigure 8.1: Bernoulli and Binomial Distributions\n\n\nThese two distributions are built on a trial of a coin toss (possibly biased).\n\nWe use the Bernoulli distribution to model a random variable for the probability of such a coin toss trial.\nWe use the Binomial distribution to model a random variable for the probability of getting k heads in N independent trials.\n\n\n8.2.1 The Bernoulli Distribution\nArises when modeling events with two possible outcomes, Success and Failure for a coin toss these can be Heads and Tails\n\nX \\sim \\text{Bernoulli}(p) =\n\\begin{cases}\n   \\mathbb{P}r(X=1) = p & \\text{success} \\\\\n   \\mathbb{P}r(X=0)=1-p & \\text{failure}\n\\end{cases}\n\\tag{8.1}\nWhere parameter p is the probability of getting heads.\nThe probability for the two events is:\nNotation:\n\nwe use (Roman) p if its value is known.\n\nwe use (Greek) \\theta when its value is unknown.\n\nThis is a probability mass function since it is discrete. But we call it a Probability Density Function (PDF) in the measure-theoretic sense.\n\nf(X=x\\mid p) = p^x(1-p)^x \\mathbb{I}_{[0,1]}(x)\n\\tag{8.2}\n\n\\mathbb{E}(x)= p\n\\tag{8.3}\n\n\\text{Var}(x)= \\mathbb{P}r(1-p)\n\\tag{8.4}\n\n\nCode\nimport numpy as np\nfrom scipy.stats import bernoulli\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1)\np = 0.3\nmean, var, skew, kurt = bernoulli.stats(p, moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=0.30, var=0.21, skew=0.87, kurt=-1.24\n\n\nCode\nx = np.arange(bernoulli.ppf(0.01, p),\n              bernoulli.ppf(0.99, p))\nax.plot(x, bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')\nax.vlines(x, 0, bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)\n\nrv = bernoulli(p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\nBernoulli distribution\n\n\n\n\nCode\n## Generate random numbers\nr = bernoulli.rvs(p, size=10)\nr\n\n\narray([1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n\n\n\n\n\n\n\n\n\nFigure 8.2: Jacob Bernoulli\n\n\n\n\n\n\n\n\nTipBiographical note on Jacob Bernoulli\n\n\n\n\nIt seems that to make a correct conjecture about any event whatever, it is necessary to calculate exactly the number of possible cases and then to determine how much more likely it is that one case will occur than another. (Bernoulli 1713)\n\nThe Bernoulli distribution as well as The Binomial distribution are due to Jacob Bernoulli (1655-1705) who was a prominent mathematicians in the Bernoulli family. He discovered the fundamental mathematical constant e. However, his most important contribution was in the field of probability, where he derived the first version of the law of large numbers.\nfor a fuller biography see\n\n\n\n\n8.2.2 The Binomial Distribution\n\n\\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N\n\\tag{8.5}\nThe Binomial distribution models counts of successes in independent Bernoulli trials . It arises when we need to consider the summing N independent and identically distributed Bernoulli RV with the same probability of success \\theta.\n\n\n\n\n\n\nTipConditions\n\n\n\n\nDiscrete data\nTwo possible outcomes for each trial\nEach trial is independent\nThe probability of success/failure is the same in each trial\n\n\n\n\n\n\n\n\n\n\n\n\nBinomial reparams mindmap\n\n\n\n\n\nX \\sim Bin[n,p]\n\\tag{8.6}\nthe probability function\n\nf(X=x \\mid \\theta) = {n \\choose x} \\theta^x(1-\\theta)^{n-x}\n\\tag{8.7}\n\n\\mathcal{L}(\\theta)=\\prod_{i=1}^{n} {n\\choose x_i}  \\theta ^ {x_i} (1− \\theta) ^ {(n−x_i)}\n\\tag{8.8}\n\n\\begin{aligned}\n\\ell( \\theta) &= \\log \\mathcal{L}( \\theta) \\\\\n              &= \\sum_{i=1}^n \\left[\\log {n\\choose x_i} + x_i \\log  \\theta + (n-x_i)\\log (1- \\theta) \\right]\n\\end{aligned}\n\\tag{8.9}\n\n\\mathbb{E}[X]= N \\times  \\theta\n\\tag{8.10}\n\n\\mathbb{V}ar[X]=N \\cdot \\theta \\cdot (1-\\theta)\n\\tag{8.11}\n\n\\mathbb{H}(X) = \\frac{1}{2}\\log_2 \\left (2\\pi n \\theta(1 - \\theta)\\right) + O(\\frac{1}{n})\n\\tag{8.12}\n\n\\mathcal{I}(\\theta)=\\frac{n}{ \\theta \\cdot (1- \\theta)}\n\\tag{8.13}\n\n8.2.2.1 Relationships\n\n\n\n\n\n\n\nFigure 8.3: binomial distribution relations\n\n\nThe Binomial Distribution is related to:\n\nthe Geometric distribution,\nThe Multinomial distribution with two categories is the binomial.\nthe Poisson distribution distribution. If X \\sim \\mathrm{Binomial}(n, p) rv and Y \\sim \\mathrm{Poisson}(np) distribution then \\mathbb{P}r(X = n) \\approx \\mathbb{P}r(Y = n) for large n and small np.\nthe Bernoulli distribution If X \\sim \\mathrm{Binomial}(n, p) RV with n = 1, X \\sim Bernoulli(p) RV.\nthe Normal distribution If X \\sim \\mathrm{Binomial}(n, p) RV and Y \\sim Normal(\\mu=np,\\sigma=n\\mathbb{P}r(1-p)) then for integers j and k, \\mathbb{P}r(j \\le X \\le k) \\approx \\mathbb{P}r(j – {1 \\over 2} \\le Y \\le k + {1 \\over 2}). The approximation is better when p ≈ 0.5 and when n is large. For more information, see normal approximation to binomial\nHypergeometric: The difference between a binomial distribution and a hypergeometric distribution is the difference between sampling with replacement and sampling without replacement. As the population size increases relative to the sample size, the difference becomes negligible. So If X \\sim Binomial(n, p) RV and Y \\sim HyperGeometric(N,a,b) then\n\n\n\\lim_{n\\to \\infty} X = Y\n\n\n\nCode\nimport numpy as np\nfrom scipy.stats import binom\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1)\nn, p = 5, 0.4\nmean, var, skew, kurt = binom.stats(n, p, moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=2.00, var=1.20, skew=0.18, kurt=-0.37\n\n\nCode\nx = np.arange(binom.ppf(0.01, n, p), binom.ppf(0.99, n, p))\nax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\nax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)\nrv = binom(n, p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n## generate random numbers\nr = binom.rvs(n, p, size=10)\nr\n\n\narray([3, 2, 3, 2, 2, 2, 2, 1, 1, 3])\n\n\n\n\n\n\n The Bernoulli Distribution\n\n\nVideo 8.1\n\n\n\n\n\n8.2.3 The Discrete Uniform Distribution\n\nX \\sim U[0,1]\n\\tag{8.14}\n\n    f(x)=\n    \\begin{cases}\n      1, & \\text{if}\\ x \\in [0,1] \\\\\n      0, & \\text{otherwise}\n    \\end{cases}\n    = \\mathbb{I}_{\\{0 \\le x \\le 1\\}}(x)\n\\tag{8.15}\n\n\nCode\nimport numpy as np\nfrom scipy.stats import uniform\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = uniform.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=0.50, var=0.08, skew=0.00, kurt=-1.20\n\n\nCode\n# we use ppf to get the domain from a range of (0.01,0.99)\nx = np.linspace(uniform.ppf(0.01), uniform.ppf(0.99), 100)\nax.plot(x, uniform.pdf(x), 'r-', lw=5, alpha=0.6, label='uniform pdf')\nrv = uniform()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n\n## generate random numbers\nr = uniform.rvs(size=1000)\n\n# And compare the histogram:\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n\n(array([0.97089651, 1.02606108, 1.10329149, 0.95986359, 0.91573193,\n       0.91573193, 1.13639023, 1.07019274, 0.98192942, 1.04812691,\n       0.90469902]), array([0.00226389, 0.09290177, 0.18353965, 0.27417753, 0.3648154 ,\n       0.45545328, 0.54609116, 0.63672904, 0.72736692, 0.8180048 ,\n       0.90864268, 0.99928056]), [&lt;matplotlib.patches.Polygon object at 0x725e1dc1e6b0&gt;])\n\n\nCode\nax.set_xlim([x[0], x[-1]])\n\n\n(0.01, 0.99)\n\n\nCode\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n8.2.4 The Continuous Uniform Distribution\n\nX \\sim \\mathrm{Uniform}[\\theta_1,\\theta_2]\n\\tag{8.16}\n\nf(x)= \\frac{1}{\\theta_2-\\theta_1} \\mathbb{I}_{\\{\\theta_1 \\le x \\le \\theta_2\\}}(x)\n\\tag{8.17}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03.html#sec-the-normal-z-t-distributions",
    "href": "C1-L03.html#sec-the-normal-z-t-distributions",
    "title": "8  M1L3 - Distributions",
    "section": "8.3 The Normal, Z, t Distributions",
    "text": "8.3 The Normal, Z, t Distributions\n The normal, AKA Gaussian distribution is one of the most important distributions in statistics.\nIt arises as the limiting distribution of sums (and averages) of random variables. This is due to the Section 100.1. Because of this property, the normal distribution is often used to model the “errors,” or unexplained variations of individual observations in regression models.\n\n8.3.1 The Standard Normal distribution\n The standard normal distribution is given by\n\n\\mathcal{Z} \\sim \\mathcal{N}[1,0]\n\\tag{8.18}\n\nf(z) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}\n\\tag{8.19}\n\n\\mathbb{E}[\\mathcal{Z}] = 0\n\\tag{8.20}\n\n\\mathbb{V}ar[\\mathcal{Z}]= 1\n\\tag{8.21}\n\n\n8.3.2 The Normal distribution\n Now consider X = \\sigma \\mathcal{Z}+\\mu where \\sigma &gt; 0 and \\mu is any real constant. Then \\mathbb{E}(X) = \\mathbb{E}(\\sigma \\mathcal{Z}+\\mu) = \\sigma \\mathbb{E}(\\mathcal{Z}) + \\mu = \\sigma \\times 0 + \\mu = \\mu and Var(X) = Var(\\sigma^2 + \\mu) = \\sigma^2 Var(\\mathcal{Z}) + 0 = \\sigma^2 \\cdot 1 = \\sigma^2\nThen, X follows a normal distribution with mean \\mu and variance \\sigma^2 (standard deviation \\sigma) denoted as\n\nX \\sim \\mathcal{N}[\\mu,\\sigma^2]\n\\tag{8.22}\n\nf(x\\mid \\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}  e^{-\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}(x-\\mu)^2}\n\\tag{8.23}\n\n\\mathbb{E}[x]= \\mu\n\\tag{8.24}\n\n\\mathbb{V}ar[x]= \\sigma^2\n\\tag{8.25}\n\nThe normal distribution is symmetric about the mean \\mu and is often described as a bell-shaped curve.\nAlthough X can take on any real value (positive or negative), more than 99% of the probability mass is concentrated within three standard deviations of the mean.\n\nThe normal distribution has several desirable properties.\nOne is that if X_1 \\sim \\mathcal{N}(\\mu_1, \\sigma^2_1) and X_2 \\sim \\mathcal{N}(\\mu_2, \\sigma^2_2) are independent, then X_1+X_2 \\sim \\mathcal{N}(\\mu_1+\\mu_2, \\sigma^2_1+\\sigma^2_2).\nConsequently, if we take the average of n Independent and Identically Distributed (IID) normal random variables we have\n\n\\bar X = \\frac{1}{n}\\sum_{i=1}^n X_i \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n})\n\\tag{8.26}\n\n\nCode\nimport numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = norm.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=0.00, var=1.00, skew=0.00, kurt=0.00\n\n\nCode\nx = np.linspace(norm.ppf(0.01),\n                norm.ppf(0.99), 100)\nax.plot(x, norm.pdf(x),\n       'r-', lw=5, alpha=0.6, label='norm pdf')\n\nrv = norm()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\nr = norm.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n\n(array([0.01110758, 0.01851263, 0.03332273, 0.05183536, 0.05183536,\n       0.11848082, 0.22215154, 0.22215154, 0.3184172 , 0.39246772,\n       0.40727782, 0.3184172 , 0.34803741, 0.33692983, 0.31471468,\n       0.21844901, 0.1295884 , 0.07405051, 0.07034799, 0.02591768,\n       0.00740505, 0.00370253, 0.00370253, 0.00370253]), array([-2.98387099, -2.71378508, -2.44369918, -2.17361327, -1.90352736,\n       -1.63344145, -1.36335554, -1.09326963, -0.82318372, -0.55309781,\n       -0.2830119 , -0.01292599,  0.25715992,  0.52724583,  0.79733174,\n        1.06741765,  1.33750356,  1.60758946,  1.87767537,  2.14776128,\n        2.41784719,  2.6879331 ,  2.95801901,  3.22810492,  3.49819083]), [&lt;matplotlib.patches.Polygon object at 0x725e1dc387f0&gt;])\n\n\nCode\nax.set_xlim([x[0], x[-1]])\n\n\n(-2.3263478740408408, 2.3263478740408408)\n\n\nCode\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n8.3.3 The t-Distribution\n If we have normal data, we can use (Equation 97.32) to help us estimate the mean \\mu. Reversing the transformation from the previous section, we get\n\n\\frac {\\hat X - \\mu}{\\sigma / \\sqrt(n)} \\sim N(0, 1)\n\\tag{8.27}\nHowever, we may not know the value of \\sigma. If we estimate it from data, we can replace it with S = \\sqrt{\\sum_i \\frac{(X_i-\\hat X)^2}{n-1}}, the sample standard deviation. This causes the expression (Equation 97.33) to no longer be distributed as a Standard Normal; but as a standard t-distribution with ν = n − 1 degrees of freedom\n\nX \\sim t[\\nu]\n\\tag{8.28}\n\nf(t\\mid\\nu) = \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\nu\\pi}}\\left (1 + \\frac{t^2}{\\nu}\\right)^{-(\\frac{\\nu+1}{2})}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{8.29}\n\n\\text{where }\\Gamma(w)=\\int_{0}^{\\infty}t^{w-1}e^{-t}\\mathrm{d}t \\text{ is the gamma function}\n\n\nf(t\\mid\\nu)={\\frac {1}{{\\sqrt {\\nu }}\\,\\mathrm {B} ({\\frac {1}{2}},{\\frac {\\nu }{2}})}}\\left(1+{\\frac {t^{2}}{\\nu }}\\right)^{-(\\nu +1)/2}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{8.30}\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the beta function}\n\n\n\\mathbb{E}[Y] = 0 \\qquad \\text{ if } \\nu &gt; 1\n\\tag{8.31}\n\n\\mathbb{V}ar[Y] = \\frac{\\nu}{\\nu - 2} \\qquad \\text{ if } \\nu &gt; 2\n\\tag{8.32}\nThe t distribution is symmetric and resembles the Normal Distribution but with thicker tails. As the degrees of freedom increase, the t distribution looks more and more like the standard normal distribution.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03.html#the-exponential-distribution",
    "href": "C1-L03.html#the-exponential-distribution",
    "title": "8  M1L3 - Distributions",
    "section": "8.4 The Exponential Distribution",
    "text": "8.4 The Exponential Distribution\n The Exponential distribution models the waiting time between events for events with a rate \\lambda. Those events, typically, come from a Poisson process.\nThe Exponential distribution is often used to model the waiting time between random events. Indeed, if the waiting times between successive events are independent then they form an \\exp(r(\\lambda) distribution. Then for any fixed time window of length t, the number of events occurring in that window will follow a Poisson distribution with mean t\\lambda.\n\nX \\sim Exp[\\lambda]\n\\tag{8.33}\n\nf(x \\mid \\lambda) = \\frac{1}{\\lambda} e^{- \\frac{x}{\\lambda}}(x)\\mathbb{I}_{\\lambda\\in\\mathbb{R}^+ } \\mathbb{I}_{x\\in\\mathbb{R}^+_0 } \\quad \\text{(PDF)}\n\\tag{8.34}\n\n\\mathbb{E}(x)= \\lambda\n\\tag{8.35}\n\n\\mathbb{V}ar[X]= \\lambda^2\n\\tag{8.36}\n\n\nCode\nimport numpy as np\nfrom scipy.stats import expon\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = expon.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=1.00, var=1.00, skew=2.00, kurt=6.00\n\n\nCode\nx = np.linspace(expon.ppf(0.01), expon.ppf(0.99), 100)\nax.plot(x, expon.pdf(x), 'r-', lw=5, alpha=0.6, label='expon pdf')\n\nrv = expon()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n\nr = expon.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n\n(array([0.88212488, 0.83158647, 0.55592245, 0.41349604, 0.39052403,\n       0.29404163, 0.27566402, 0.20215362, 0.13323761, 0.10567121,\n       0.08729361, 0.11486001, 0.0551328 , 0.05972721, 0.0367552 ,\n       0.022972  , 0.0321608 , 0.0137832 , 0.0091888 , 0.0137832 ,\n       0.0091888 , 0.        , 0.0045944 , 0.0045944 , 0.0137832 ,\n       0.0045944 , 0.        , 0.0045944 , 0.0091888 , 0.        ,\n       0.0045944 , 0.        , 0.0045944 , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.0045944 ]), array([4.79108724e-05, 2.17704169e-01, 4.35360428e-01, 6.53016686e-01,\n       8.70672945e-01, 1.08832920e+00, 1.30598546e+00, 1.52364172e+00,\n       1.74129798e+00, 1.95895424e+00, 2.17661050e+00, 2.39426675e+00,\n       2.61192301e+00, 2.82957927e+00, 3.04723553e+00, 3.26489179e+00,\n       3.48254805e+00, 3.70020430e+00, 3.91786056e+00, 4.13551682e+00,\n       4.35317308e+00, 4.57082934e+00, 4.78848560e+00, 5.00614186e+00,\n       5.22379811e+00, 5.44145437e+00, 5.65911063e+00, 5.87676689e+00,\n       6.09442315e+00, 6.31207941e+00, 6.52973566e+00, 6.74739192e+00,\n       6.96504818e+00, 7.18270444e+00, 7.40036070e+00, 7.61801696e+00,\n       7.83567321e+00, 8.05332947e+00, 8.27098573e+00, 8.48864199e+00,\n       8.70629825e+00, 8.92395451e+00, 9.14161077e+00, 9.35926702e+00,\n       9.57692328e+00, 9.79457954e+00, 1.00122358e+01]), [&lt;matplotlib.patches.Polygon object at 0x725e1db27400&gt;])\n\n\nCode\nax.set_xlim([x[0], x[-1]])\n\n\n(0.010050335853501442, 4.605170185988091)\n\n\nCode\nax.legend(loc='best', frameon=False)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03.html#sec-the-geometric-distribution",
    "href": "C1-L03.html#sec-the-geometric-distribution",
    "title": "8  M1L3 - Distributions",
    "section": "9.1 The Geometric Distribution",
    "text": "9.1 The Geometric Distribution\n The Geometric distribution arises when we want to know “What is the number of Bernoulli trials required to get the first success?”, i.e., the number of Bernoulli events until a success is observed, such as the probability of getting the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).\n\n\n\n\n\n\n\nVideo 9.1: The Geometric Distribution\n\n\n\nX \\sim \\mathrm{Geo}(p)\n\\tag{9.1}\n\n\\mathbb{P}r(X = x\\mid p) = \\mathbb{P}r(1-p)^{x-1} \\qquad \\forall x \\in N;\\quad 0\\le p \\le 1\n\\tag{9.2}\n\n\\mathbb{E}[X] = \\frac{1}{p}\n\\tag{9.3}\n\n\\mathbb{V}ar[X]=\\frac{1-p}{p^2}\n\\tag{9.4}\n\n\\mathbb{M}_X[t] = \\frac{pe^t}{1-(1-p)e^t} \\qquad t &lt; -log(1-p)\n\\tag{9.5}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03.html#sec-the-multinomial-distribution",
    "href": "C1-L03.html#sec-the-multinomial-distribution",
    "title": "8  M1L3 - Distributions",
    "section": "9.2 The Multinomial Distribution",
    "text": "9.2 The Multinomial Distribution\nAnother generalization of the Bernoulli distribution and the Binomial distribution is the Multinomial distribution , which sums the successes of Bernoulli trials when there are n different possible outcomes. Suppose we have n trials and there are k different possible outcomes that occur with probabilities p_1, \\ldots, p_k. For example, we are rolling a six-sided die that might be loaded so that the sides are not equally likely, then n is the total number of rolls, k = 6, p_1 is the probability of rolling a one, and we denote by x_1, \\ldots, x_6 a possible outcome for the number of times we observe rolls of each of one through six, where\n\nX \\sim \\mathrm{Multinomial}(p_1,...p_k)\n\n\nP (X = x \\mid p_1,\\ldots,p_k) = \\frac{n!}{x_1! \\cdot \\cdot \\cdot x_k! } \\prod_i p_i^{x_i}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03.html#sec-the-poisson-distribution",
    "href": "C1-L03.html#sec-the-poisson-distribution",
    "title": "8  M1L3 - Distributions",
    "section": "9.3 The Poisson Distribution",
    "text": "9.3 The Poisson Distribution\nThe Poisson distribution arises when modeling count data. The parameter \\lambda &gt; 0 is the rate at which we expect to observe the thing we are counting. We write this as X \\sim \\mathrm{Poisson}(\\lambda)\n\n\\mathbb{P}r(X = x \\mid \\lambda) = \\frac{\\lambda^x e^{−\\lambda}}{x!} \\qquad \\forall x \\in \\mathbb{N}_0 \\qquad \\text{PDF}\n\\tag{9.6}\n\n\\mathbb{E}[X] = \\lambda \\qquad \\text{Expectation}\n\\tag{9.7}\n\n\\mathbb{V}ar[X] = \\lambda \\qquad \\text{Variance}\n\\tag{9.8}\n\n\\mathbb{M}_X(t) = \\exp[\\lambda(e^t-1)] \\qquad \\text{Moment Generating fn.}\n\\tag{9.9}\n\n\\mathcal{I}_X(t) = \\frac{1}{\\lambda}\n\\tag{9.10}\n\n9.3.1 Relations\n\n\n\n\n\n\n\nFigure 9.1: Relations of the Poisson distribution\n\n\n A Poisson process is a process wherein events occur on average at rate \\mathbb{E}, events occur one at a time, and events occur independently of each other.\n\n\n\n\n\n\n\nFigure 9.2: Siméon Denis Poisson\n\n\n\n\n\n\n\n\nTipBiographical Note on The Siméon Denis Poisson\n\n\n\nThe Poisson distribution is due to Baron Siméon Denis Poisson (1781-1840) see (Poisson 2019, 205–7) was a French mathematician and physicist who worked on statistics, complex analysis, partial differential equations, the calculus of variations, analytical mechanics, electricity and magnetism, thermodynamics, elasticity, and fluid mechanics.\nfor a fuller biography see",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03.html#hypergeometric-distribution",
    "href": "C1-L03.html#hypergeometric-distribution",
    "title": "8  M1L3 - Distributions",
    "section": "9.4 Hypergeometric Distribution",
    "text": "9.4 Hypergeometric Distribution\n\nConsider an urn with a white balls and b black balls. Draw N balls from this urn without replacement. The number white balls drawn, n is Hypergeometrically distributed.\n\nX \\sim \\mathrm{Hypergeometric}(n \\mid N,a,b)\n\n\n\\mathrm{Hypergeometric}(n\\mid N,a,b) = \\frac{\\normalsize{\\binom{a}{n} \\binom{b}{N - n}}} {\\normalsize{\\binom{a + b}{N}}} \\quad \\text{(PDF)}\n\\tag{9.11}\n\n\\mathbb{E}[X]=N\\frac{a}{a+b} \\qquad \\text{(expectation)}\n\\tag{9.12}\n\n\\mathbb{V}ar[X]=N\\,\\frac{ab}{(a + b)^2}\\,\\frac{a+b-N}{a+b-1} \\qquad \\text{(variance)}\n\\tag{9.13}\n\n\n\n\n\n\nBernoulli, J. 1713. Ars Conjectandi [the Art of Conjecturing]. Impensis Thurnisiorum. https://books.google.co.il/books?id=Ba5DAAAAcAAJ.\n\n\nPoisson, S. -D. 2019. “English Translation of Poisson’s \"Recherches Sur La Probabilité Des Jugements En Matière Criminelle Et En Matière Civile\" / \"Researches into the Probabilities of Judgements in Criminal and Civil Cases\".” https://arxiv.org/abs/1902.02782.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>M1L3 - Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L03-Ex1.html",
    "href": "C1-L03-Ex1.html",
    "title": "9  Homework on Random Variables",
    "section": "",
    "text": "Exercise 9.1  When using random variable notation, X denotes what?random variables\n\n\n\n\n\n\nTipSolution: random variable.\n\n\n\n\n\n\n\n\n\n\n\nExercise 9.2  When using random variable notation, little x or X=x denotes what?random variables\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\na realization of a random variable. It is a possible value the random variable can take.\n\n\n\n\n\nExercise 9.3 When using random variable notation, X \\sim denotes what?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\ndistributed as.\n\n\n\n\nExercise 9.4 What is the value of f(x)=−5\\mathbb{I}_{x&gt;2}(x)+x\\mathbb{I}_{x&lt;−1}(x) when x=3?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n5 Only the first term is evaluated as non-zero.\n\n\n\n\nExercise 9.5 What is the value of f(x)=−5\\mathbb{I}_{x&gt;2}(x)+x \\mathbb{I}_{x&lt;−1}(x) when x=0?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n0 as all indicator functions evaluate to zero.\n\n\n\n\nExercise 9.6 Which of the following scenarios could should one model with a Bernoulli RV?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nPredicting whether your hockey team wins its next game (tie counts as a loss)\n\n\n\n\nExercise 9.7 Calculate the expected value of the following random variable: X takes on values \\{0, 1, 2, 3\\} with corresponding probabilities \\{0.5, 0.2, 0.2, 0.1\\}.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n0(.5)+1(.2)+2(.2)+3(.1) =0.9\n\n\n\n\nExercise 9.8 Which of the following scenarios could we appropriately model using a binomial RV (with n &gt; 1)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nPredicting the number of wins in a series of three games against a single opponent (ties count as losses)\n\n\n\n\nExercise 9.9 If X\\sim Binomial(3,0.2). Calculate \\mathbb{P}r(X=0).\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nimport math \n\ndef binom(n,p,x):\n    return round(math.comb(n,x) * p**x * (1-p)**(n-x),2)\n\nprint(f'{binom(n=3,p=0.2,x=0)=}')\n\n\nbinom(n=3,p=0.2,x=0)=0.51\n\n\n\n\n\n\nExercise 9.10 If X\\sim Binomial(3,0.2). Calculate \\mathbb{P}r(X \\le 2).\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nprint(f'{binom(n=3,p=0.2,x=0)+binom(n=3,p=0.2,x=1)+binom(n=3,p=0.2,x=2)}')\n\n\n0.99",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Homework on Random Variables</span>"
    ]
  },
  {
    "objectID": "C1-L03-Ex2.html",
    "href": "C1-L03-Ex2.html",
    "title": "10  Homework on Distributions",
    "section": "",
    "text": "Exercise 10.1 If RV X has a probability density function (PDF) f(x), what is the interpretation of \\int_{−2}^5 f(x)dx ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nSince the area under the PDF curve is the probability, integrating the PDF calculates the total probability within the range of the integral. We can write this probability in several forms.\n\n\\mathbb{P}r(X \\ge -2 \\cap X \\le 5)\n\nor a more sensible notation\n\n\\mathbb{P}r(-s \\ge X \\ge 5)\n\n\n\n\n\nExercise 10.2 If X \\sim \\text{Uniform}(0,1), then what is the value of \\mathbb{P}r(−3 &lt; X &lt; 0.2)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\int_{−3}^{0.2} I_{[0,1]} dx = \\int_{0}^{0.2} 1 dx = 0.2\n\n\n\n\n\nExercise 10.3 If X \\sim \\text{Exponetial}(5), then what is \\mathbb{E}(X) ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\mathbb{E}(X) = \\frac{1}{\\lambda} = \\frac{1}{5} = 0.2\n\n\n\n\n\nExercise 10.4 Which of the following scenarios could we most appropriately model using an exponentially distributed random variable?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nThe exponential distribution models the times between events so I would go with the lifetime of a light-bulb.\n\n\n\n\nExercise 10.5 if X \\sim \\text{Uniform}(2,6) what would its PDF look like?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom scipy.stats import uniform\n\nx= np.arange(0.0,8.0,0.001)\nfig, ax = plt.subplots()\nplt.plot(x, uniform.pdf(x,loc=2,scale=4))\n#values = uniform(2.0, 6.00, 1000) \n#sns.histplot(values,kde=True,bins=10,ax=ax)\nax.set_xlim(0,10)\nax.set_ylim(0,0.4)\nplt.show()\n\n\n\n\n\n\n\n\n\nThis PDF has a uniform value (1/4) over the interval [2,6] and is 0 everywhere else.\n\n\n\n\nExercise 10.6 If X \\sim \\text{Uniform}(2,6), then what is the value of \\mathbb{P}r(2 &lt; X &lt; 3.2) ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\int_{3}^{2} 1/4 dx = 0.25\n\n\n\n\n\nExercise 10.7 if X∼N(0,1), which is the PDF of X\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom scipy.stats import uniform, norm\n\nx= np.arange(-3.,3.0,0.001)\nfig, ax = plt.subplots()\nplt.plot(x, norm.pdf(x,loc=0,scale=1))\n#values = uniform(2.0, 6.00, 1000) \n#sns.histplot(values,kde=True,bins=10,ax=ax)\nax.set_xlim(-3,3)\nax.set_ylim(0,.5)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 10.8 if X∼N(2,1), which is \\mathbb{E}(-5X)\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\mathbb{E}(-5X)=-5\\mathbb{E}(X)=-5 \\times2=-10\n\n\n\n\n\nExercise 10.9 if X∼N(1,1), and Y\\sim N(4,9) which is \\mathbb{E}(X+Y)\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\mathbb{E}(X+Y) = \\mathbb{E}(X)+\\mathbb{E}(Y)= 1 + 4 = 5\n\n\n\n\n\nExercise 10.10 The normal distribution is also linear in the sense that if X\\sim N(\\mu,\\sigma^2), then for any real constants a\\ne 0 and b Y=aX+b is distributed N(a\\times \\mu +b,a^2\\times \\sigma^2).\nUsing this fact, what is the distribution of Z = \\frac{X-\\mu}{\\sigma} ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nZ=N(0,1)\n\n\n\n\nExercise 10.11  \n\nWhich of the following random variables would yield the highest value of \\mathbb{P}r(−1&lt;X&lt;1) ?\n\n\n\n\n\n\n\nNoteHint:\n\n\n\n\n\nRandom variables with larger variance are more dispersed.\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nX_1 \\sim N(0,0.1)\nX_2 \\sim N(0,1)\nX_3 \\sim N(0,10)\nX_4 \\sim N(0,100)\n\nOf the four options, X_4 is the least dispersed, meaning that most of the probability is associated with small values of X.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Homework on Distributions</span>"
    ]
  },
  {
    "objectID": "C1-L04.html",
    "href": "C1-L04.html",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "",
    "text": "11.1 Confidence Intervals\nA brief review of the frequentist approach to inference will be useful for contrasting with the Bayesian approach. (Kruschke 2011) Chapter 2 suggests that CI provides the basis for a Bayesian workflow and that the rest of the text fills in the missing pieces.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-confidence-intervals",
    "href": "C1-L04.html#sec-confidence-intervals",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "",
    "text": "Figure 11.1: frequentist approach to confidence intervals\n\n\n\n\n\n\n\n\n\nImportantFrequentist paradigm\n\n\n\nUnder the frequentist paradigm, one views the data as a random sample from some larger, potentially hypothetical population. We can then make probability statements i.e. long-run frequency statements based on this larger population.\n\n\n\nExample 11.1 (Coin Flip Example - Central Limit Theorem) Suppose we flip a coin 100 times. And we get 44 heads and 56 tails. We can view these 100 flips as a random sample from a much larger infinite hypothetical population of flips from this coin. We can say that each flip is X_i an RV which follows a Bernoulli distribution with some probability p. In this case p is unknown, but we can assume it is fixed since we are using a specific physical coin.\n\nX_i \\sim B(p)\n\\tag{11.1}\nWe ask :\n\nWhat is our best estimate of p the probability of getting a head?\nHow confident are we in the estimate of p?\n\nTo estimate p we will apply the Central limit theorem c.f. Theorem 100.1 which states that the mean of a large number of IID RV with mean \\mu and variance \\sigma^2 is approximately N(\\mu,\\sigma^2).\n\n\\sum^{100}_{i=1} X_i\\mathrel{\\dot \\sim } N(100 \\enspace p, 100 \\enspace \\mathbb{P}r(1-p))\n\\tag{11.2}\nGiven that this is a Normal distribution, we can use the empirical rule often called the 68-95-99.7 rule see (Wikipedia contributors 2023), that says 95% of the time we will get a result is in within 1.96 standard deviations of the mean. This is referred to as a Confidence Interval or (CI).\n\n95\\% \\: \\text{CI}= 100 \\: \\hat{p} \\pm 1.96\\sqrt{100 \\: \\hat{p}(1-\\hat{p})}\n\\tag{11.3}\nSince we observed 44 heads we can estimate \\hat{p} as\n\n\\hat p = \\frac{44}{100} = .44\n\\tag{11.4}\nThis answers our first questions. Now we want to quantify our uncertainty.\n\\begin{aligned}\n95\\% \\: \\text{CI for 100 tosses} &= 100 \\: (.44) \\pm 1.96\\sqrt{100(0.44)(1-0.44)} \\\\ &= 44 \\pm 1.96\\sqrt{(44) (0.56)} \\\\ &= 44 \\pm 1.96\\sqrt{23.64} \\\\ &= (34.27,53.73) \\end{aligned}\n\\tag{11.5}\nWe can be 95% confident that 100\\times \\hat{p} \\in [34.3,53.7] We can say that we’re 95% confident that the true probability p \\in (.343, .537).\nIf one were to ask do I think this coin is Fair ? This is a reasonable hypothesis, since 0.5 \\in [.343,.537].\nBut we can also step back and say what does this interval mean when we say we’re 95% confident? Under the frequentist paradigm, we have to think back to our infinite hypothetical sequence of events, were we to repeat this trial an arbitrarily large number of times and each time create a confidence interval, then on average 95% of the intervals we make will contain the true value of p. This makes senses as a long run frequency explanation.\nOn the other hand, we might want to know something about this particular interval. Does this interval contain the true p. What’s the probability that this interval contains a true p? Well, we don’t know for this particular interval. But under the frequentist paradigm, we’re assuming that there is a fixed right answer for p. Either p is in that interval or it’s not in that interval. And so technically, from a frequentist perspective, the probability that p is in this interval is either 0 or 1. This is not a particularly satisfying explanation. In the other hand when we get to the Bayesian approach we will be able to compute an interval and actually say there is probably a p is in this interval is 95% based on a random interpretation of an unknown parameter.\n\n\n\n\n\n\n\nTip\n\n\n\nIn this example of flipping a coin 100 times, observing 44 heads resulted in the following 95% confidence interval for p: (.343, .537). From this, we concluded that it is plausible that the coin may be fair because p=.5 is in the interval.\nSuppose instead that we flipped the coin 100,000 times, observing 44,000 heads (the same percentage of heads as before). Then using the method just presented, the 95% confidence interval for p is (.437, .443). Is it still reasonable to conclude that this is a fair coin with 95% confidence?\nNo Because 0.5 \\not\\in (.437, .443), we must conclude that p=.5 is not a plausible value for the population mean . Observing 100,000 flips increases the power of the experiment, leading to a more precise estimate with a narrower CI, due to the law of large numbers.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-likelihood-function-and-MLE",
    "href": "C1-L04.html#sec-likelihood-function-and-MLE",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "11.2 Likelihood function and MLE",
    "text": "11.2 Likelihood function and MLE\n\n\n\n\n\n\n\nFigure 11.2: Likelihood fn and MLE\n\n\n\nExample 11.2 (Heart Attack Patients - MLE) Consider a hospital where 400 patients are admitted over a month for heart attacks, and a month later 72 of them have died and 328 of them have survived.\nwhat’s our estimate of the mortality rate?\n\n\n\n\n\n\nWarningReference Population\n\n\n\nUnder the frequentist paradigm, we must first establish our reference population. This is the cornerstone of our thinking as we are considering how the sample parameter approximates the population statistic. What do we think our reference population is here?\n\nRef Pop 1: Heart attack patients in the region.\nRef Pop 2: Heart attack patients that are admitted to this hospital, but over a longer period.\nRef Pop 3: The people in the region who might have a heart attack and might get admitted to this hospital.\n\nBoth Ref Pop 1 and Ref Pop 2 seem like viable options. Unfortunately, in our data is not a random sample drawn from either. We could pretend they are and move on, or we could also try to think harder about what our data is sampled from, perhaps Ref Pop 3.\nThis is an odd hypothetical situation, and so there are some philosophical issues with the setup of this whole problem within the frequentist paradigm\n\n\n\nY_i \\sim Bernulli(p)\n\\tag{11.6}\nSince this is a Bernoulli trial we need to specify what we interpret as the success . In this case, the success is a mortality.\n\n\\mathbb{P}r(Y_i=1) = \\theta\n\\tag{11.7}\nThe PDF for the dataset can be written in vector form. \\mathbb{P}r(\\vec{Y}=\\vec{y} \\mid \\theta) is the Probability of all the Y’s take some value little y given a value of theta.\n\n\\begin{aligned}\n\\mathbb{P}r(\\vec{Y}=\\vec{y} \\mid \\theta) &= \\mathbb{P}r(Y_1=y,\\dots,Y_n=y_n \\mid \\theta) && \\text{(joint probability)}\n\\\\&= \\mathbb{P}r(Y_1=y_1 \\mid \\theta) \\cdots \\mathbb{P}r(Y_n=y_n \\mid \\theta)            && \\text {(independence)}\n\\\\&= \\prod^n_{i=1} \\mathbb{P}r(Y_i=y_i \\mid \\theta)                            && \\text {(product notation)}\n\\\\&= \\prod^n_{i=1} \\theta^{y_i} (1-\\theta)^{1-y_i}                   && \\text {(Bernoulli PMF)}\n\\end{aligned}\n\\tag{11.8}\nWe now cal the expression for \\mathbb{P}r(\\vec{Y}=\\vec{y} \\mid \\theta) above the likelihood function L(\\theta \\mid \\vec{y} ):\n  \n\\mathcal{L}(\\theta\\mid\\vec{y}) = \\prod^n_{i=1} \\theta^{y_i} (1-\\theta)^{1-y_i}\n\\tag{11.9}\nRecall that we want to find the mortality rate parameter \\theta for our Sample \\vec Y.\nSince it is a probability, it has a range of values from 0 to 1. One way to estimate it is that there should be one value that maximizes (Equation 11.9). It makes the data the most likely to occur for the particular data we observed. This is referred to as the maximum likelihood estimate (MLE).\n\n\\mathop{\\mathrm{MLE}}(\\hat \\theta) = \\mathop{\\mathrm{argmax}} \\; \\mathcal{L}(\\theta\\mid y)\n\nAlthough we are trying to find the \\theta that maximizes the likelihood, in practice, it’s usually easier to maximize the natural logarithm of the likelihood, commonly referred to as the log-likelihood.\n \\begin{aligned}\n  \\mathcal{L}(\\theta) &= \\log(L(\\theta|\\vec{y}))  &&\n\\\\        &= \\log(\\prod^n_{i=1} {\\theta^{y_i} (1-\\theta)^{1-y_i}})  && \\text{subst. liklihood}\n\\\\        &= \\sum^n_{i=1}{ \\log(\\theta^{y_i}) + \\log(1-\\theta)^{1-y_i}} && \\text{log product rule}\n\\\\        &= \\sum^n_{i=1}{ y_i \\log(\\theta) + (1-y_i) \\log(1-\\theta)} && \\text{log power rule}\n\\\\        &= \\log(\\theta) \\sum^n_{i=1}{  y_i + \\log(1-\\theta)} \\sum^n_{i=1}{  (1-y_i) }&& \\text{extracting logs}\n\\end{aligned}\n\\tag{11.10}\nWhat is the interpretation of the MLE of \\theta in the context of the heart attack example?\nIf \\hat \\theta is the MLE for \\theta, the 30-day mortality rate, then all possible values of θ produce a lower value of the likelihood than \\hat \\theta.\nTo calculate the MLE one should differentiate \\mathcal{L}(\\theta) w.r.t. \\theta and then set it equal to 0.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-computing-the-MLE",
    "href": "C1-L04.html#sec-computing-the-MLE",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "11.3 Computing the MLE",
    "text": "11.3 Computing the MLE\n\n\n\n\n\n\n\nFigure 11.3: Computing the MLE\n\n\n\n\\begin{aligned}\n   && \\mathcal{L}'(\\theta)=& \\frac{1}{\\theta}\\sum_{i=1}^n y_i-\\frac{1}{1-\\theta}\\sum_{i=1}^n 1-y_i \\stackrel{\\text{set}}{=}0  \\text {set derivative to 0}\n\\\\ & \\implies   & \\frac{1}{\\hat \\theta}\\sum_{i=1}^n y_i & = \\frac{1}{1- \\hat \\theta}\\sum_{i=1}^n 1 - y_i\n\\\\ & \\implies   & (1 -\\hat \\theta) \\sum_{i=1}^n{y_i}    &= \\hat\\theta \\sum_{i=1}^n {1-y_i}  \n\\\\ & \\implies   & 1 \\sum_{i=1}^n{y_i} - \\cancel{ \\hat \\theta \\sum_{i=1}^{n}{y_i}} &= \\hat\\theta \\sum_{i=1}^n {1} - \\cancel{\\hat\\theta \\sum_{i=1}^n {y_i}}  \n\\\\ & \\implies   & \\sum_{i=1}^n{y_i}  &= \\hat\\theta N\n\\\\ & \\implies   &  \\hat \\theta &= \\frac{1}{N} \\sum_{i=1}^n y_i  = \\hat p = \\frac{72}{400}=.18\n\\end{aligned}\n\nMaximum Likelihood Estimates (MLEs) possess the following favorable properties:\n\nUnbiased - Thus given sufficient data the MLE will converge to the true value. As a consequence, MLEs are asymptotically unbiased. As we will see in the examples they can still be biased in finite samples.\nconsistent - One important property of maximum likelihood is that it produces consistent estimates.\ninvariant - The invariance principle states that the MLE is invariant against reparameterization.\n\nusing the Central Limit theorem (see Theorem 100.1).\n\n\\hat \\theta \\pm 1.96\\sqrt\\frac{\\hat \\theta(1-\\hat \\theta)}{n}\n\n\n\\hat \\theta \\simeq \\mathcal{N}(\\theta,\\frac{1}{\\mathcal{I} (\\hat \\theta)})\n\nwhere \\mathcal{I} is the Fischer information which for the Bernoulli distribution is:\n\n\\mathcal{I}( \\hat \\theta) = \\frac{1}{\\theta(1-\\theta)}\n\nNote: The Fischer information is a measure of how much information about theta is in each data point!\n\n\n\n\n\n\nTipExplainable AI (XAI) & Fischer information\n\n\n\nIn XAI we use discuss local and global explanations.\n\nGlobal explanations explain a black box model’s predictions based on each feature, via its parameters.\nLocal explanations explain the prediction of a specific datum from its features.\n\nsince Fischer information quantifies the information in a data point on a parameter we should be able to use it to produce local and perhaps even global explanations for Bayesian models.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-computing-the-MLE-examples",
    "href": "C1-L04.html#sec-computing-the-MLE-examples",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "11.4 Computing the MLE: examples",
    "text": "11.4 Computing the MLE: examples\nSome more examples of maximum likelihood estimators.\n\n11.4.1 Computing the MLE for Exponential RV\n\n\n\n\n\n\n\nFigure 11.4: computing the MLE for Exponential RV\n\n\nLet’s say X_i are exponential distributed\n\nX_i \\sim Exp(\\lambda)\n\nLet’s say the data is independent and identically distributed, therefore making the overall density function\n\n\\begin{aligned}\n  f(x \\mid \\lambda) &= \\prod_{i = 1}^n{\\lambda e^{-\\lambda x_i}} && \\text {(simplifying)}\n  \\\\ &= \\lambda^ne^{-\\lambda \\sum{x_i}}\n\\end{aligned}\n\\tag{11.11}\nNow the likelihood function is\n\nL(\\lambda \\mid x)=\\lambda^ne^{-\\lambda \\sum{x_i}}\n\\tag{11.12}\nthe log likelihood is\n\n\\mathcal{L}(\\lambda) = n\\ln{\\lambda} - \\lambda\\sum_i{x_i}\n\\tag{11.13}\nTaking the derivative\n\n\\begin{aligned}\n  \\mathcal{L}^\\prime(\\lambda) &= \\frac{n}{\\lambda} - \\sum_i{x_i} \\stackrel{\\text{set}}{=}0 && \\text {(set derivative = 0)}\n\\\\ \\implies \\frac{n}{\\hat{\\lambda}} &= \\sum_i{x_i} && \\text{(rearranging)}\n\\end{aligned}\n\\tag{11.14}\n\n\\hat{\\lambda} = \\frac{n}{\\sum_i{x_i}} = \\frac{1}{\\bar{x}}\n\\tag{11.15}\n\n\n11.4.2 Computing the MLE for Uniform RV\n\n\n\n\n\n\n\nFigure 11.5: computing the MLE for Uniform RV\n\n\n\nX_i \\sim  \\mathrm{Uniform}[0, \\theta]\n\\tag{11.16}\n\nf(x \\mid \\theta) = \\prod_{i = 1}^n{\\frac{1}{\\theta}\\mathbb{I}_{0 \\le x_i \\le \\theta}}\n\\tag{11.17}\nCombining all the indicator functions, for this to be a 1, each of these has to be true. These are going to be true if all the observations are bigger than 0, as in the minimum of the x is bigger than or equal to 0. The maximum of the x’s is also less than or equal to \\theta.\n\n\\mathcal{L}(\\theta|x) = \\theta^{-1} \\mathbb{I}_{0\\le min(x_i) \\le max(x_i) \\le \\theta}\n\\tag{11.18}\n\n\\mathcal{L}^\\prime(\\theta) = -n\\theta^{-(n + 1)}\\mathbb{I}_{0 \\le min(x_i) \\le max(x_i)\\le \\theta}\n\\tag{11.19}\nWe ask, can we set this equal to zero and solve for \\theta? It turns out, this is not equal to zero for any \\theta positive value. We need \\theta to be strictly larger than zero. But for \\theta positive, this will always be negative. The derivative is negative, that says this is a decreasing function. Therefore this function will be maximized when we pick \\theta as small as possible. What’s the smallest possible value of \\theta we can pick? Well we need in particular for \\theta to be larger than all of the X_i. And so, the maximum likelihood estimate is the maximum of X_i\n\n\\hat{\\theta} = max(x_i)\n\\tag{11.20}",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-cumulative-distribution-function",
    "href": "C1-L04.html#sec-cumulative-distribution-function",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "11.5 Cumulative Distribution Function",
    "text": "11.5 Cumulative Distribution Function\nThe cumulative distribution function (CDF) exists for every distribution. We define it as F(x) = \\mathbb{P}r(X \\le x) for random variable X.\nIf X is discrete-valued, then the CDF is computed with summation F(x) = \\sum_{t = -\\infty}^x {f(t)}. where f(t) = \\mathbb{P}r(X = t) is the probability mass function (PMF) which we’ve already seen.\nIf X is continuous, the CDF is computed with an integral F(x) = \\int_{-\\infty}^x{f(t)dt}\nThe CDF is convenient for calculating probabilities of intervals. Let a and b be any real numbers with a &lt; b. Then the probability that X falls between a and b is equal to \\mathbb{P}r(a &lt; X &lt; b) = \\mathbb{P}r(X \\le b) - \\mathbb{P}r(X \\le a) = F(b) - F(a)\n\n\n\n\n\n\nFigure 11.6: Illustration of using the CDF to calculate the probability of an interval for continuous random variable X. Probability values are represented with shaded regions in the graphs.\n\n\n\n\nExample 11.3 (CDF example 1) Suppose X ∼ Binomial(5, 0.6). Then\n\n  \\begin{aligned}\n  F(1) &= \\mathbb{P}r(X \\le 1)\n\\\\ &= \\sum_{−∞}^1 f(t)\n\\\\ &= \\sum_{t=−∞}^{-1} 0 + \\sum_{t=0}^1 {5 \\choose t} 0.6^t (1 − 0.6)^{5−t}\n\\\\ &= {5 \\choose 0} 0.6^0 (1 − 0.6)5−0 +{5 \\choose 1} 0.6^1 (1 − 0.6)^{5−1}\n\\\\ &= (0.4)^5 + 5(0.6)(0.4)^4\n\\\\ &≈ 0.087\n\\end{aligned}\n\\tag{11.21}\n\n\nExample 11.4 (CDF example 1) Example: Suppose Y ∼ Exp(1). Then\n\n\\begin{aligned}\nF(2) &= \\mathbb{P}r(Y \\le 2)\n\\\\ &= \\int^{2}_{−∞} e^{−t}\\mathbb{I}_{(t≥0)} dt\n\\\\ &= \\int^{2}_{0} e^{−t}dt\n\\\\ &= −e^{−t}|^2_0\n\\\\ &= −(e^{−2} − e^0)\n\\\\ &= 1−e^{−2}\n\\\\ &≈ 0.865\n\\end{aligned}\n\\tag{11.22}",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-quantile-function",
    "href": "C1-L04.html#sec-quantile-function",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "11.6 Quantile Function",
    "text": "11.6 Quantile Function\nThe CDF takes a value for a random variable and returns a probability. Suppose instead we start with a number between 0 and 1, which we call p, and we wish to find a value x so that \\mathbb{P}r(X \\le x) = p. The value x which satisfies this equation is called the p quantile. (or 100p percentile) of the distribution of X.\n\nExample 11.5 (Quantile Function example 1) In a standardized test, the 97th percentile of scores among all test-takers is 23. Then 23 is the score you must achieve on the test in order to score higher than 97% of all test-takers. We could equivalently call q = 23 the .97 quantile of the distribution of test scores.\n\n\nExample 11.6 (Quantile Function example 2) The middle 50% of probability mass for a continuous random variable is found between the .25 and .75 quantiles of its distribution. If Z \\sim N(0, 1), then the .25 quantile is −0.674 and the .75 quantile is 0.674. Therefore, \\mathbb{P}r(−0.674 &lt;Z &lt;0.674) = 0.5.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-plotting-the-likelihood-function-in-r",
    "href": "C1-L04.html#sec-plotting-the-likelihood-function-in-r",
    "title": "11  M2L4 - Frequentist Inference",
    "section": "12.1 Plotting the likelihood function in R",
    "text": "12.1 Plotting the likelihood function in R\nGoing back to the hospital example\n\n\nCode\nlikelihood = function(n, y, theta) {\n  return(theta^y * (1 - theta)^(n - y))\n}\ntheta = seq(from = 0.01, to = 0.99, by = 0.01)\nplot(theta, likelihood(400, 72, theta))\n\n\n\n\n\n\n\n\n\nYou can also do this with log likelihoods. This is typically more numerically stable to compute\n\n\nCode\nloglike = function(n, y, theta) {\n  return(y * log(theta) + (n - y) * log(1 - theta))\n}\nplot(theta, loglike(400, 72, theta))\n\n\n\n\n\n\n\n\n\nHaving these plotted as points makes it difficult to see, let’s plot it as lines\n\n\nCode\nplot(theta, loglike(400, 72, theta), type = \"l\")",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>M2L4 - Frequentist Inference</span>"
    ]
  },
  {
    "objectID": "C1-L04-Ex1.html",
    "href": "C1-L04-Ex1.html",
    "title": "12  Homework - Frequentist MLE",
    "section": "",
    "text": "100 coin flips\nFor Questions (Exercise 12.1 — Exercise 12.3), consider the following scenario:\nIn the example from Lesson 4.1 of flipping a coin 100 times, suppose instead that you observe 47 heads and 53 tails.\n\nExercise 12.1  Report the value of \\hat p, the MLE (Maximum Likelihood Estimate) of the probability of obtaining heads.100 coin flips\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n.47\nThis is simply {47 \\over 100}, the number of successes normalized by the number of trials.\n\n\n\n\nExercise 12.2 100 coin flips\nUsing the central limit theorem as an approximation, and following the example of Lesson 4.1, construct a 95% confidence interval for p, the probability of obtaining heads. Report the lower end of this interval.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n.37\nWe have \\hat{p} - 1.96\\sqrt{\\hat{p}(1-\\hat{p})/n} =.47 - 1.96\\sqrt{(.47)(.53)/100} = .372, which is the lower end of a 95% confidence interval for p.\n\n\n\n\nExercise 12.3 100 coin flips\nReport the upper end of this interval and round your answer to two decimal places.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n.57\nWe have \\hat{p} + 1.96\\sqrt{\\hat{p}(1-\\hat{p})/n} =.47 + 1.96\\sqrt{(.47)(.53)/100} = .568, which is the upper end of a 95% confidence interval for p.\n\n\n\n\nExercise 12.4 likelihood function\nThe likelihood function for parameter θ with data y is based on which of the following?\n\n\\mathbb{P}r(θ∣y)\n\\mathbb{P}r(y∣θ)\n\\mathbb{P}r(θ)\n\\mathbb{P}r(y)\nNone of the above.\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nThe likelihood is based on the sampling distribution of the data, given the parameter. Note that although the likelihood has the same functional form as \\mathbb{P}r(y\\mid\\theta), it is considered a function of \\theta.\n\n\n\n\nExercise 12.5 Mean MLE\nRecall from Lesson 4.4 that if X_1,\\ldots,X_n \\stackrel {IID} \\sim Exponential(\\lambda) (IID means independent and identically distributed), then the MLE for \\lambda is \\frac{1}{\\bar x} where \\bar x is the sample mean. Suppose we observe the following data: X1=2.0, X2=2.5, X3=4.1, X4=1.8, X5=4.0.\nCalculate the MLE for λ. Round your answer to two decimal places.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n0.35\nThe sample mean is \\bar x = 2.88.\n\n\n\n\nExercise 12.6 Exp MLE\nIt turns out that the sample mean \\bar x is involved in the MLE calculation for several models. In fact, if the data are independent and identically distributed from a Bernoulli(p), Poisson(λ), or Normal(μ, σ^2), then \\bar x is the MLE for p, \\lambda, and μ respectively.\nSuppose we observe n=4 data points from a normal distribution with unknown mean \\mu. The data are x=\\{−1.2,0.5,0.8,−0.3\\}.\nWhat is the MLE for μ ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n-0.05\nThis is (−1.2+0.5+0.8−0.3)/4.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Homework - Frequentist MLE</span>"
    ]
  },
  {
    "objectID": "C1-L05.html",
    "href": "C1-L05.html",
    "title": "13  M2L5 - Bayesian Inference",
    "section": "",
    "text": "13.1 Inference example: frequentist\nWe’ll start by defining the unknown parameter \\theta, this is either that the coin is fair or it’s a loaded coin.\n\\theta = \\{\\text{fair},\\ \\text{loaded}\\} \\qquad \\text{(parameter)}\n\\tag{13.1}\nwe get to flip it five times but we do not know what kind of coin it is\nX \\sim Bin(5, \\theta) \\qquad \\text{(model)}\n\\tag{13.2}\neach value of theta gives us a competing binomial likelihood:\nf(x\\ mid\\theta) = \\begin{cases}\n      {5 \\choose x}(\\frac{1}{2})^5            & \\theta = \\text{fair}\n\\\\    {5 \\choose x} (.7)^x (.3)^{5 - x}       & \\theta = \\text{loaded}\n   \\end{cases} \\qquad \\text{(likelihood)}\n\\tag{13.3}\nWe can also rewrite the likelihood f(x \\mid \\theta) using indicator functions\nf(x\\mid\\theta) = {5\\choose x}(.5)^5\\mathbb{I}_{\\{\\theta= \\text{fair}\\}} + {5 \\choose x}(.7)^x(.3)^{5 - x}\\mathbb{I}_{\\{\\theta = \\text{loaded}\\}} \\qquad \\text{(likelihood)}\n\\tag{13.4}\nIn this case, we observed that x = 2\nf(\\theta \\mid x = 2) = \\begin{cases}\n    0.3125 & \\theta = \\text{fair} \\\\\n    0.1323 & \\theta = \\text{loaded}\n\\end{cases} \\qquad \\text{(sub. x=2)}\n\\tag{13.5}\n\\therefore \\hat{\\theta} = \\text{fair} MLE\n\\tag{13.6}\nThat’s a good point estimate, but then how do we answer the question, how sure are you?\nThis is not a question that’s easily answered in the frequentest paradigm. Another question is that we might like to know what is the probability that theta equals fair, give, we observe two heads.\n\\mathbb{P}r(\\theta = \\text{fair} \\mid x = 2) = ?\n\\tag{13.7}\nIn the frequentest paradigm, the coin is a physical quantity. It’s a fixed coin, and therefore it has a fixed probability of coining up heads. It is either the fair coin, or it’s the loaded coin.\n\\mathbb{P}r(\\theta = \\text{fair}) = \\{0,1\\}",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>M2L5 - Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "C1-L05.html#sec-inference-example-frequentist",
    "href": "C1-L05.html#sec-inference-example-frequentist",
    "title": "13  M2L5 - Bayesian Inference",
    "section": "",
    "text": "Figure 13.1: coin probability inference\n\n\n\nExample 13.1 (Two Coin Example) Suppose your brother has a coin that you know to be loaded so that it comes up heads 70% of the time. He then comes to you with some coin, you’re not sure which one and he wants to make a bet with you. Betting money that it’s going to come up heads.\nYou’re not sure if it’s the loaded coin or if it’s just a fair one. So he gives you a chance to flip it 5 times to check it out.\nYou flip it five times and get 2 heads and 3 tails.\nWhich coin do you think it is and how sure are you about that?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>M2L5 - Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "C1-L05.html#sec-bayesian-approach-to-the-problem",
    "href": "C1-L05.html#sec-bayesian-approach-to-the-problem",
    "title": "13  M2L5 - Bayesian Inference",
    "section": "13.2 Bayesian Approach to the Problem",
    "text": "13.2 Bayesian Approach to the Problem\n\n\n\n\n\n\n\nFigure 13.2: Bayesian coin probability inference\n\n\nAn advantage of the Bayesian approach is that it allows you to easily incorporate prior information when you know something in advance of looking at the data. This is difficult to do under the frequentist paradigm.\nIn this case, we’re talking about your brother. You probably know him pretty well. So suppose you think that before you’ve looked at the coin, there’s a 60% probability that this is the loaded coin.\nIn this case, we put this into our prior. Our prior belief is that the probability the coin is loaded is 0.6. We can update our prior beliefs with the data to get our posterior beliefs, and we can do this using the Bayes theorem.\n\n\\begin{aligned}\n  \\mathbb{P}r(\\text{loaded}) &= 0.6\\ && \\text{(prior)}\n\\\\ f(\\theta \\mid x) &= \\frac{f(x \\mid \\theta)f(\\theta)}{\\sum_\\theta{f(x \\mid \\theta)f(\\theta)}} && \\text{(Bayes)}\n\\\\ f(\\theta\\mid x=2)&= \\frac{{5\\choose x} \\left [(\\frac{1}{2})^5(1-0.6)\\ \\mathbb{I}_{(\\theta = \\text{fair})} + (.7)^x (.3)^{5-x}(.6)\\ \\mathbb{I}_{(\\theta = \\text{loaded})}  \\right] } {{5\\choose x} \\left [(\\frac{1}{2})^5(.4) + (.7)^x (.3)^{5-x}(0.6)  \\right] }&& \\text{(sub. x=2)}\n\\\\ &= \\frac{0.0125\\ \\mathbb{I}_{(\\theta = \\text{fair})}  + 0.0079\\ \\mathbb{I}_{(\\theta = \\text{loaded})} }{0.0125+0.0079}&& \\text{(normalize)}\n\\\\ &= \\textbf{0.612}\\ \\mathbb{I}_{(\\theta=\\text{fair})} + 0.388\\ \\mathbb{I}_{(\\theta = \\text{loaded})} && \\text{(MLE)}\n\\end{aligned}\n\\tag{13.8}\nAs you can see in the calculation Equation 13.8, we have the likelihood times the prior in the numerator, and a normalizing constant in the denominator. When we divide the two, we’ll get an answer that adds up to 1. These numbers match exactly in this case because it’s a very simple problem.\nThis is a concept that we will revisit — what’s in the denominator here is always a normalizing constant.\n\n\\mathbb{P}r(\\theta = loaded \\mid x = 2) = 0.388\n\nThis here updates our beliefs after seeing some data about what the probability might be.\nWe can also examine what would happen under different choices of prior.\n\n\\mathbb{P}r(\\theta = loaded) = \\frac{1}{2} \\implies \\mathbb{P}r(\\theta = loaded \\mid x = 2) = 0.297\n\n\n\\mathbb{P}r(\\theta = loaded) = 0.9 \\implies \\mathbb{P}r(\\theta = loaded \\mid x = 2) = 0.792\n\nIn this case, the Bayesian approach is inherently subjective. It represents your perspective, and this is an important part of the paradigm. If you have a different perspective, you will get different answers, and that’s okay. It’s all done in a mathematically vigorous framework, and it’s all mathematically consistent and coherent.\nAnd in the end, we get interpretable results.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>M2L5 - Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "C1-L05.html#sec-continuous-version-of-bayes-theorem",
    "href": "C1-L05.html#sec-continuous-version-of-bayes-theorem",
    "title": "13  M2L5 - Bayesian Inference",
    "section": "13.3 Continuous version of Bayes’ theorem",
    "text": "13.3 Continuous version of Bayes’ theorem\n\n\n\n\n\n\n\nFigure 13.3: Continuous version of Bayes’ theorem",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>M2L5 - Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "C1-L05.html#sec-posterior-intervals",
    "href": "C1-L05.html#sec-posterior-intervals",
    "title": "13  M2L5 - Bayesian Inference",
    "section": "13.4 Posterior Intervals",
    "text": "13.4 Posterior Intervals\n\n\n\n\n\n\n\nFigure 13.4: Posterior Intervals",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>M2L5 - Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "C1-L05.html#sec-discussion-cis",
    "href": "C1-L05.html#sec-discussion-cis",
    "title": "13  M2L5 - Bayesian Inference",
    "section": "13.5 Discussion CIs",
    "text": "13.5 Discussion CIs\n\nFrequentist confidence intervals have the interpretation that “If you were to repeat many times the process of collecting data and computing a 95% confidence interval, then on average about 95% of those intervals would contain the true parameter value; however, once you observe data and compute an interval the true value is either in the interval or it is not, but you can’t tell which.”\nBayesian credible intervals have the interpretation that “Your posterior probability that the parameter is in a 95% credible interval is 95%.”\nBayesian intervals treat their bounds as fixed and the estimated parameter as a random variable.\nFrequentist confidence intervals treat their bounds as random variables and the parameter as a fixed value.\n\n\n\n\n\n\n\nNoteDiscussion Under what circumstances would you prefer a frequentist CI or a Bayesian CI?\n\n\n\n13.5.1 Focusing on Bayesian / Frequentist paradigms\n\nA Frequentist CI might be preferred if:\n\nI had plenty of data to support a frequentist construction of frequentist CI and\nI was doing research and refining or refuting a result that has been established using frequentist hypothesis testing.\n\nI would want to show that for H_1 against some null hypothesis, H_0 the parameters have a certain p-value for some effect.\nParticularly when we are interested in the inference and are less interested in using the value of the parameter.\n\nI cannot justify introducing some subjective priors.\n\nA Bayesian CI might be better if:\n\nMy dataset is too small.\nWhat I care about is the parameter’s value and less about hypothesis testing\nI need an estimate of uncertainty for the parameter for the inference it is used in.\nI had subjective reasons to introduce a prior:\n\nI know about constraints\nI have access to expert knowledge\n\nI wish to introduce pooling between groups, to share information for reducing uncertainty.\nMy results are in a Bayesian-oriented domain.\n\n\n\n\n\n\n\n\n\n\nNoteDiscussion: Under what circumstances would you prefer a frequentist CI or a Bayesian CI?\n\n\n\n13.5.2 Focusing on the CI choices\nLet’s point out that this is what we call a loaded question, as it has a bias against the frequentist approach by stating one of its shortcomings when it is still possible to get a point estimate for the parameter and compare it to the CI. Typically one will have already done it say using regression before considering the CI.\nNext, we have all the standard reasons for choosing between the Frequentist and the Bayesian paradigms. I could list them but I don’t think that is the real point of this question, but rather what would we prefer if both were viable options and why?\nCIs are primarily a tool for understanding uncertainties about parameters that encode effects. In the parametric Bayesian approach we are learning the distribution of our parameters so they have uncertainties baked into them. In the Frequentist approach, we look for the least squares point estimates for our parameters and consider using the CI to approximate the long-run uncertainty due to sampling.\nFrequentist CI might be preferable if I am worried about Aletoric uncertainty due to sampling i.e. to what degree can I be certain my experimental outcomes are not due to chance? I would feel this way since I am a classical physicist or a botanist studying a predominately deterministic effect and I see errors in estimating the parameters as artifacts of sampling that can be made smaller till the parameters will converge with the true population statistics and the error will become vanishingly small.\nGiven that I did my best to get a good data sample I just need to check how sure to decide the cardinal question do I publish or do I perish? I need to decide that the result is due to the effect and not due to some conspiracy bad samples.\nBayesian CIs are just a result of using Bayesian analysis which is a requirement to investigate what are predominately random effects that are the domain of quantum physicists, an ecologist, or a geneticist. Since almost everything I study is predominantly random and I need random variables and Bayes law to get to my results. I also need to report confidence intervals for my work when I publish - but if one is a Bayesian, one will use a Bayesian credible interval?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>M2L5 - Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "C1-L05-Ex1.html",
    "href": "C1-L05-Ex1.html",
    "title": "14  Homework on Likelihoods and MLEs",
    "section": "",
    "text": "Political preferences\nYou are trying to ascertain your American colleague’s political preferences. To do so, you design a questionnaire with five yes/no questions relating to current issues. The questions are all worded so that a “yes” response indicates a conservative viewpoint. X_i \\sim Bernoulli(\\theta)\\quad i\\in 1...5\nLet \\theta be the unknown political viewpoint of your colleague, which we will assume can only take values ‘Conservative’ or ‘Liberal’ . You have no reason to believe that your colleague leans one way or the other, so you assign the prior .\\theta \\in \\{\\text{C}, \\text{L}\\}\\mathbb{P}r(\\theta = \\text{C}) = 0.5\nAssume the five questions are independent and let Y count the number of “yes” responses. Y\\stackrel{iid}\\sim \\sum_{i=0}^5 X_i(x=y)\n\nIf your colleague is ‘conservative’, then the probability of a “yes” response to any given question is 0.8. \nIf your colleague is ‘liberal’, the probability of a “no” response on any given question is 0.7.\n\n\\mathbb{P}r(X_i=y \\mid \\theta=\\text{C}) = 0.8\\mathbb{P}r(X_i = n \\mid \\theta=\\text{L}) = 0.7\nExercise 14.1  What is an appropriate likelihood for this scenario?Political preferences\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\nf(\\theta \\mid y) &=  {5 \\choose y} \\cdot  0.8^y \\cdot  0.2^{5-y}\\cdot  \\mathbb{I}_{(\\theta=C)} \\\\\n                 &+ {5 \\choose y} \\cdot 0.3^y \\cdot 0.7^{5-y} \\cdot \\mathbb{I}_{(\\theta=L)}\n\\end{aligned}\n\nIf your colleague is conservative, the number of “yes” responses will follow a Binomial(5, 0.8). If liberal, the number of “yes” responses will follow a Binomial(5, 0.3).\n\n\n\n\nExercise 14.2  Suppose you ask your colleague the five questions and he answers “no” to all of them. What is the MLE for \\theta?Political preferences\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nsince all answers are the same the MLE is easy to simplify\n\n\\begin{aligned}\n{5 \\choose 0} 0.8^0 0.2^{5} \\mathbb{I}_{\\{\\theta=C\\}} + {5 \\choose 0} 0.3^0 0.7^{5} \\mathbb{I}_{\\{\\theta=L\\}} = \\\\ 0.2^{5} \\mathbb{I}_{\\{\\theta=C\\}} + 0.7^{5} \\mathbb{I}_{\\{\\theta=L\\}} =\n\\end{aligned}\n\nI implemented this expression as a function using python\n\n\nCode\nfrom math import comb\ndef l5q2(y:int=0,\n         N=5,\n         Py1C=0.8,\n         Pn1L=0.7,\n         theta='C'): \n    \"\"\"    estimates the MLE of parameter theta using\n    Args:\n        y (int): number of yes answers. Defaults to 0.\n        N (int, optional): number of questions in the poll. Defaults to 5.\n        Py1C (float, optional): Probability of answering yes conditioned on conservative. Defaults to 0.8.\n        Pn1L (float, optional): Probability of answering no conditioned on liberal. Defaults to 0.7.\n        theta (string): 'C' if conservative 'L' if liberal. Defaults to 'C'\n    Returns:\n        float: the MLE estimate\n    \"\"\"    \n    \n    # indicator functions \n    I_c = lambda theta : theta == 'C'    \n    I_l = lambda theta : theta == 'L'\n\n    y_comp = N-y # complement for y for use in power\n    Pn1C = 1 - Py1C\n    Py1L = 1 - Pn1L\n    binomial = comb(5,y)\n\n    mle = \\\n    binomial * (Py1C ** y) * (Pn1C ** y_comp) * I_c(theta)+\\\n    binomial * (Py1L ** y) * (Pn1L ** y_comp) * I_l(theta)\n\n    return round(mle,4)\n\nprint(f\"MLE of theta=comservative: {l5q2(y=0, theta='C')}\")\nprint(f\"MLE of theta=liberal:      {l5q2(y=0, theta='L')}\")\n\n\nMLE of theta=comservative: 0.0003\nMLE of theta=liberal:      0.1681\n\n\nsince the expected value for \\mathbb{E}(\\text{L}) = 0.17 &gt; \\mathbb{E}(\\text{C})=0.00 is greater, the MLE is: liberal\nThis result is intuitive because if your colleague answered “no” to all conservative-leaning questions, he is unlikely to be a conservative.\n\n\n\n\nExercise 14.3  Recall that Bayes’ theorem givesPolitical preferences\n\nf(\\theta \\mid y)=\\frac{f(y \\mid \\theta )\\color{red}{f (\\theta)} }{\\sum_{\\theta} f(y \\mid \\theta )f( \\theta )}\n\nWhat is the corresponding expression for this problem?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nf(\\theta \\mid y)= \\frac{ {5 \\choose y} 0.8^y 0.2^{5-y} {\\color{red}(0.5)} \\mathbb{I}_{(\\theta=C)} + {5 \\choose y} 0.3^y 0.7^{5-y} {\\color{red}(0.5)}\\mathbb{I}_{(\\theta=L) } }{ {5 \\choose y} 0.8^y 0.2^{5-y} {\\color{red}(0.5)} + {5 \\choose y} 0.3^y 0.7^{5-y}{\\color{red}(0.5)}}\n\n\nThe prior probability was 0.5 for both values of \\theta.\nWe have summed over all possibilities of \\theta to get the denominator.\nThe denominator is the marginal probability of observing y, which gives us a normalizing constant, which does not contains \\theta and evaluates to a number when we plug in y.\n\n\n\n\n\nExercise 14.4  Evaluate the expression in Exercise 14.3 for y=0 and report the posterior probability that your colleague is conservative, given that he responded “no” to all of the questions.Political preferences\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nand this is code to implement Bayes’ rule\n\n\nCode\nfrom math import comb\ndef l5q4(y:int=0,\n         Py1C:float=0.8,\n         Pn1L:float=0.7,\n         prior={'C': 0.5,'L': 0.5},\n         theta='C')-&gt;float:\n    \"\"\" The posterior probability for theta, the political preference is given y 'yes' answers in a poll, using Bayes rule with:\n\n    Args:\n        y (int): number of yes answers. Defaults to 0.\n        N (int, optional): number of questions in the poll. Defaults to 5.\n        Py1C (float, optional): Probability of answering yes conditioned on conservative. Defaults to 0.8.\n        Pn1L (float, optional): Probability of answering no conditioned on liberal. Defaults to 0.7.\n        prior (dict, optional): Prior for theta the political preference. Defaults to {'C': 0.5,'L': 0.5}.\n        theta (string): 'C' if conservative 'L' if liberal. Defaults to 'C'\n\n    Returns:\n        float: the posterior probability for theta given y. \n    \"\"\"    \n    i_c = lambda theta : theta=='C'    \n    i_l = lambda theta : theta=='L'\n\n    y_comp=5-y\n    Pn1C=1-Py1C\n    Py1L=1-Pn1L\n    binomial=comb(5,y)\n\n    numerator = \\\n    binomial * (Py1C**y) * (Pn1C**y_comp) * prior['C'] * i_c (theta)+\\\n    binomial * (Py1L**y) * (Pn1L**y_comp) * prior['L'] * i_l(theta)\n    denominator = \\\n    binomial*(Py1C**y)*(Pn1C**y_comp)*prior['C'] +\\\n    binomial*(Py1L**y)*(Pn1L**y_comp)*prior['L']\n    posterior = numerator / denominator\n    return round(posterior,3)\n\nprint(f\"{l5q4(y=0, theta='C')=}\")\n\n\nl5q4(y=0, theta='C')=0.002\n\n\n\n\n\n\nExercise 14.5  Evaluate the expression in Exercise 14.3 for y=0 and report the posterior probability that your colleague is liberal, given that he responded “no” to all of the questions.Political preferences\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nwe can reuse the function\n\n\nCode\nprint(f\"{l5q4(y=0, theta='L')=}\")\n\n\nl5q4(y=0, theta='L')=0.998\n\n\n\n\n\n\nExercise 14.6  Recall in Example 13.1, your brother has a fair coin which comes up heads 50% of the time and a loaded coin which comes up heads 70% of the time.Loaded Coins\nSuppose now that he has a third coin that comes up tails 70% of the time. Again, you don’t know which coin your brother has brought you, so you are going to test it by flipping it 4 times, where X counts the number of heads. Let \\theta identify the coin so that there are three possibilities \\theta =fair, \\theta =loaded favoring heads and \\theta =loaded favoring heads, and =loaded favoring tails\nSuppose the prior is now \\mathbb{P}r( \\theta = fair)=0.4, \\mathbb{P}r( \\theta =loaded heads)=0.3, and loaded tails \\mathbb{P}r( \\theta =loaded tails) = 0.3. Our prior probability that the coin is loaded is still 0.6, but we do not know which loaded coin it is, so we split the probability evenly between the two options.\n\nWhat is the form of the likelihood now that we have three options?\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n  \n\\begin{aligned}\nf(x|\\theta) =&  {4 \\choose x} 0.5^x 0.5^{4-x} \\mathbb{I}_{\\{\\theta=fair\\}} + \\\\\n            &   {4 \\choose x} 0.3^x 0.7^{4-x} \\mathbb{I}_{\\{\\theta=loaded heads\\}} +\\\\\n            &   {4 \\choose x} 0.7^x 0.3^{4-x} \\mathbb{I}_{\\{\\theta=loaded tails\\}}\n\\end{aligned}\n\n\n\n\n\nExercise 14.7  Suppose you flip the coin four times and it comes up heads twice. What is the MLE for \\theta?Loaded Coins\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n  \n{4 \\choose x} 0.5^4\n\nis the highest value among the three when X=2\n\n\n\n\nExercise 14.8  Suppose you flip the coin four times and it comes up heads twice. What is the posterior probability that this is a fair coin?Loaded Coins\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n# key\n# 'F' for fair, 'LH' for Loaded Heads, 'LT' for Loaded Tails\n# PH1F is the conditional probability of heads given Fair\n\ndef l5q8(x,\n         PH1F=0.5,\n         PH1LH=0.7,\n         PT1LT=0.7,\n         prior={'F':0.4,'LH':0.3,'LT':0.3},\n         theta='F'):\n\n\n    # indicator functions\n    i_F  = lambda theta : theta == 'F'    \n    i_LH = lambda theta : theta == 'LH'    \n    i_LT = lambda theta : theta == 'LT'\n\n    c_comp=4-x\n    PT1F =1-PH1F \n    PT1LH=1-PH1LH\n    PH1LT=1-PT1LT\n    binomial=comb(4,x)\n\n    numerator=binomial*(PH1F**x)*(PT1F**c_comp)*prior['F']*i_F(theta) + \\\n    binomial*(PH1LH**x)*(PT1LH**c_comp)*prior['LH']*i_LH(theta) +\\\n    binomial*(PH1LT**x)*(PT1LT**c_comp)*prior['LT']*i_LT(theta)\n    denominator = binomial*(PH1F**x)*(PT1F**c_comp)*prior['F'] + \\\n    binomial*(PH1LH**x)*(PT1LH**c_comp)*prior['LH'] +\\\n    binomial*(PH1LT**x)*(PT1LT**c_comp)*prior['LT']\n    posterior=numerator/denominator\n    return round(posterior,2)\n\nprint(f\"{l5q8(x=2,theta='F')=}\")\n\n\nl5q8(x=2,theta='F')=0.49\n\n\n\n\n\n\nExercise 14.9  Suppose you flip the coin four times and it comes up heads twice. What is the posterior probability that this is a loaded coin (favoring either heads or tails)? Round your answer to two decimal places.Loaded Coins\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nprint(f\"{1-l5q8(x=2,theta='F')=}\")\n\nprint(f\"{l5q8(x=2,theta='LH')+l5q8(x=2,theta='LT')=}\")\n\n\n1-l5q8(x=2,theta='F')=0.51\nl5q8(x=2,theta='LH')+l5q8(x=2,theta='LT')=0.52\n\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nI think that the above is pretty neat for a quick calculation but that one could do better. The conditional probabilities and the priors can be specified using a map from keys to probabilities.\n\n\nCode\nfrom math import comb\n\n# key\n# 'F' for fair, 'LH' for Loaded Heads, 'LT' for Loaded Tails\n# PH1F is the conditional probability of heads given Fair\n\ndef l5bayes(N: int, x:int, cond: dict[str, float], prior: dict[str, float],theta:str) -&gt; float:\n    \"\"\" estimates the posterior probability for a Bernoulli experiment with three types of coins using Bayes' law and a binomial likelihood. \n\n    Args:\n        N (int): total trials.\n        x (int): count of successful trials (Heads).\n        cond (dict[str, float]): conditional probability of \"H|F\" expressed as a map from keys to their probability.\n        prior (dict[str, float]): prior probability expressed as a map from keys {F,LT,LH} to their to the probability.\n        theta (str): the value of the parameter F for fair LH and LT for loaded heads and tails.\n    Returns:\n        int: the posterior probability for the given value of the parameter theta\n    \"\"\"\n\n    thetas =  list(prior.keys()) # we get the parameter's keys from the prior. \n    binomial=comb(N,x)\n\n    indicator = {}\n    likelihood = {}\n    joint_terms = {}\n    marginal_terms = {}\n    joint_probability,marginal = 0,0\n    for theta_key in thetas:\n        indicator[theta_key] = lambda theta : theta == theta_key \n        likelihood[theta_key] = binomial * cond[f'H|{theta_key}'] ** x * cond[f'T|{theta_key}'] ** (N-x)\n        joint_terms[theta_key] = likelihood[theta_key] * prior[theta_key] * indicator[theta_key](theta)\n        marginal_terms[theta_key] = likelihood[theta_key] * prior[theta_key] \n        joint_probability   += joint_terms[theta_key]\n        marginal += marginal_terms[theta_key] \n\n    posterior = joint_probability / marginal\n    return round(posterior,3)\n\ncond_p_map: dict[str, float] = {'H|F': 0.5,'T|F': 0.5, 'H|LH': 0.7,'T|LH': 0.3, 'H|LT': 0.3,'T|LT': 0.7}\nprior_map: dict[str, float] = {'F': 0.4, 'LH': 0.3, 'LT': 0.3} \nN: int=5\nprint(f\"{l5bayes(x=2, N=N, cond=cond_p_map, prior=prior_map, theta='F')=}\")\nprint(f\"{1 - l5bayes(x=2, N=N, cond=cond_p_map, prior=prior_map, theta='F')=}\")\nprint(f\"{l5bayes(x=2, N=N, cond=cond_p_map, prior=prior_map, theta='LH') + l5bayes(x=2,N=N, cond=cond_p_map, prior=prior_map, theta='LT')=}\")\n\n\nl5bayes(x=2, N=N, cond=cond_p_map, prior=prior_map, theta='F')=0.486\n1 - l5bayes(x=2, N=N, cond=cond_p_map, prior=prior_map, theta='F')=0.514\nl5bayes(x=2, N=N, cond=cond_p_map, prior=prior_map, theta='LH') + l5bayes(x=2,N=N, cond=cond_p_map, prior=prior_map, theta='LT')=0.514\n\n\n\n\n\nI still think I could do better: - this has the binomial encoded into the likelihood, perhaps when we look at other problems it can use for the distribution and prior actual functions, possibly from SCIPY. - I like that the values of theta are collected from the prior. - the H, T events are hard coded, it would be better if they too were derived from the cond_p_map event-values set.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Homework on Likelihoods and MLEs</span>"
    ]
  },
  {
    "objectID": "C1-L05-Ex2.html",
    "href": "C1-L05-Ex2.html",
    "title": "15  Homework on Bayesian Inference",
    "section": "",
    "text": "Exercise 15.1 Bayes’ theorem\nWhen do we use the continuous version of Bayes’ theorem?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\theta is continuous\nY is continuous\nf(y\\mid\\theta) is continuous\nAll of the above\nNone of the above\n\nIf \\theta is continuous, we use a probability density for the prior.\n\n\n\n\nExercise 15.2 Consider the coin-flipping example from the lesson. Recall that the likelihood for this experiment was Bernoulli with unknown probability of heads, i.e., f(y \\mid \\theta) = \\theta^y(1-\\theta)^{1-y} I_{\\{ 0 \\le \\theta \\le 1 \\}} and we started with a uniform prior on the interval [0,1]\nAfter the first flip resulted in heads (Y_1=1), the posterior for \\theta became f(\\theta \\mid Y_1=1) = 2\\theta I_{\\{ 0 \\le \\theta \\le 1 \\}}\nNow use this posterior as your prior for \\theta before the next (second) flip. Which of the following represents the posterior PDF for \\theta after the second flip also results in heads (Y_2=1)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nf(\\theta \\mid Y_2=1) = \\frac{ (1-\\theta) \\cdot 2\\theta } { \\int_0^1 (1-\\theta) \\cdot 2\\theta d\\theta} I_{\\{ 0 \\le \\theta \\le 1 \\}}\nf(\\theta \\mid Y_2=1) = \\frac{ \\theta \\cdot 2\\theta} { \\int_0^1 \\theta \\cdot 2\\theta d\\theta} I_{\\{ 0 \\le \\theta \\le 1 \\}}\nf(\\theta \\mid Y_2=1) = \\frac{ \\theta (1-\\theta) \\cdot 2\\theta} { \\int_0^1 \\theta (1-\\theta) \\cdot 2\\theta d\\theta} I_{\\{ 0 \\le \\theta \\le 1 \\}}\n\nThis simplifies to the posterior PDF f(\\theta \\mid Y_2=1) = 3 \\theta^2 I_{\\{ 0 \\le \\theta \\le 1 \\}}.\nIncidentally, if we assume that the two coin flips are independent, we would have arrived at the same posterior if we had again started with a uniform prior and performed a single update using Y_1=1 and Y_2=1.\n\n\n\n\nExercise 15.3 Consider again the coin-flipping example from the lesson. Recall that we used a \\text{Uniform}(0,1) prior for \\theta.\nWhich of the following is a correct interpretation of \\mathbb{P}r(0.3 &lt; \\theta &lt; 0.9) = 0.6?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n(0.3, 0.9) is a 60% credible interval for \\theta before observing any data.\n(0.3, 0.9) is a 60% credible interval for \\theta after observing Y=1.\n(0.3, 0.9) is a 60% confidence interval for \\theta.\nThe posterior probability that θ\\in(0.3,0.9) is 0.6.\n\nThe probability statement came from our prior, so the prior probability that \\theta is in this interval is 0.6.\n\n\n\n\nExercise 15.4 Consider again the coin-flipping example from the lesson. Recall that the posterior PDF for θ, after observing Y=1, was f(\\theta \\mid Y=1) = 2\\theta I_{\\{0 \\le \\theta \\le 1 \\}}. Which of the following is a correct interpretation of \\mathbb{P}r(0.3 &lt; \\theta &lt; 0.9 \\mid Y=1) = \\int_{0.3}^{0.9} 2\\theta d\\theta = 0.72?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n(0.3, 0.9) is a 72% credible interval for \\theta before observing any data.\n(0.3, 0.9) is a 72% credible interval for \\theta after observing Y=1.\n(0.3, 0.9) is a 72% confidence interval for \\theta.\nThe prior probability that θ \\in (0.3,0.9) is 0.72.\n\nThe probability statement came from the posterior, so the posterior probability that \\theta is in this interval is 0.72.\n\n\n\n\nExercise 15.5 Which two quantiles are required to capture the middle 90% of a distribution (thus producing a 90% equal-tailed interval)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n.025 and .975\n.10 and .90\n.05 and .95\n0 and .9\n\n90% of the probability mass is contained between the .05 and .95 quantiles (or equivalently, the 5th and 95th percentiles). 5% of the probability lies on either side of this interval.\n\n\n\n\nSuppose you collect measurements to perform inference about a population mean \\theta. Your posterior distribution after observing data is \\theta \\mid \\mathbf{y} \\sim \\text{N}(0,1).\nReport the upper end of a 95% equal-tailed interval for θ.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nqnorm(p=0.975, mean=0, sd=1)\n\n\n[1] 1.959964\n\n\nwhere probability=0.975, mean=0, standard_dev=1\n\n\n\n\nExercise 15.6 What does “HPD interval” stand for?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nHighest precision density interval\nHighest point distance interval\nHighest partial density interval\nHighest posterior density interval\n\n\n\n\n\nExercise 15.7 Each of the following graphs depicts a 50% credible interval from a posterior distribution. Which of the intervals represents the HPD interval?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n50% interval: θ∈(0.500,1.000)\n50% interval: θ∈(0.400,0.756)\n50% interval: θ∈(0.196,0.567)\n50% interval: θ∈(0.326,0.674)\n\nThis is the 50% credible interval with the highest posterior density values. It is the shortest possible interval containing 50% of the probability under this posterior distribution.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Homework on Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "C1-L06.html",
    "href": "C1-L06.html",
    "title": "16  M3L6 - Priors",
    "section": "",
    "text": "16.1 Priors and prior predictive distributions\nIn this section, we will delve more deeply into choices of Priors and how they influence Bayesian CI by developing the prior predictive (Definition 16.1) and posterior predictive (Definition 16.2) intervals.\nTheoretically, we’re defining a cumulative distribution function for the parameter\n\\mathbb{P}r(\\theta \\le c) \\qquad \\forall c \\in \\mathbb{R}\nWe need to do this for an infinite number of possible sets but it isn’t practical to do, and it would be very difficult to do it coherently so that all the probabilities were consistent. Therefore in practice, we tend to work with a convenient family that is flexible enough for members to represent our beliefs.\nGenerally if one has enough data, the information in the data will overwhelm the information in the prior. This makes it seem like the prior is less important in terms of the form and substance of the posterior. Once the prior is overwhelmed, any reasonable choice of prior will lead to approximately the same posterior. This is a point where the Bayesian approach should converge to the frequentist and can be shown to be more or less objective.\nOn the other hand choices of priors can be important because even with masses of data, groups and items can be distributed very sparsely in which case priors can have a lasting impact on the posteriors. Secondly, we can decide to pick priors that have a long-lasting impact on operating as regularizing constraints within our models. In such cases, the impact of the prior can be significant.\nOne of our guiding questions will be to consider how much information the prior and the data contribute to the posterior. We will consider the effective sample size of different priors.\nFinally, a bad choice of priors can lead to specific issues.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>M3L6 - Priors</span>"
    ]
  },
  {
    "objectID": "C1-L06.html#sec-priors-and-prior-predictive-distributions",
    "href": "C1-L06.html#sec-priors-and-prior-predictive-distributions",
    "title": "16  M3L6 - Priors",
    "section": "",
    "text": "ImportantChoosing a prior\n\n\n\nHow should we choose a prior?\n\nOur prior needs to represent our perspectives, beliefs, and our uncertainties.\nIt should encode any constraints on the data or parameters.\n\nage is positive and less than 120\n\nIt can regularize the data\nIt could encode expert knowledge we have elicited from domain experts.\nIt should prefer informative priors over uninformative ones.\n\n\n\n\n\n\n\n\n\n\n\nExample 16.1 (Example of Bad Prior) Suppose we chose a prior that says the probability of \\mathbb{P}r(\\theta = \\frac{1}{2}) = \\delta( \\frac{1}{2})= 1\nAnd thus, the probability of \\theta equaling any other value is 0. If we do this, our data won’t make a difference since we only put a probability of 1 at a single point.\n\nf(\\theta \\mid y) \\propto f(y \\mid\\theta)f(\\theta) = f(\\theta) = \\delta(\\theta)\n\\tag{16.1}\n\n\n\n\n\n\n\nCautionAvoid priors that assign 0 or 1\n\n\n\n\nEvents with a prior probability of 0 will always have a posterior probability of 0 because f(\\theta)=0 in (Equation 16.1) the product will and therefore the posterior be 0\nEvents with a prior probability of 1, will always have a posterior probability of 1. This is a little harder to see. In this case f(\\theta^c)=0 in (Equation 16.1) so that the posterior will again be zero elsewhere.\n\n\n\n\nIt is good practice to avoid assigning a probability of 0 or 1 to any event that has already occurred or is already known not to occur.\nIf the priors avoid 0 and 1 values the information within the data will eventually overwhelm the information within the prior.\n\n\n16.1.1 Calibration - making priors precise\n\n\nQ. How do we calibrate our prior probability to reality?\nCalibration of predictive intervals is a useful concept in terms of choosing priors. If we make an interval where we’re saying we predict 95% of new data points will occur in this interval. It would be good if, in reality, 95% of new data points did fall in that interval. This is a frequentist concept but this is important for practical statistical purposes so that our results reflect reality.\n\n\n\n\n\n\n\nFigure 16.1: Prior Predictive Distribution\n\n\nWe can compute a predictive interval. This is an interval such that 95% of new observations are expected to fall into it. It’s an interval for the data rather than an interval for \\theta\n\nDefinition 16.1 (Prior Predictive Distribution) The prior predictive distribution expresses our uncertainty about a parameter, i.e. the distribution of its possible values before we observe any data.\n\n\\begin{aligned}\nf(y) &= \\int{f(y \\mid\\theta)f(\\theta)d\\theta} &&\\text {by Bayes theorem}\n\\\\&= \\int{f(y, \\theta)d\\theta} && \\text{the joint probability}\n\\end{aligned}\n\\tag{16.2}\n\nf(y,\\theta) is the joint density of y and \\theta.\nIf we are integrating out \\theta, we will end up with a marginalized probability distribution of the data.\nHowever, we may well decide to not integrate out \\theta completely, so we will end up with a predictive interval.\nBut no data y has been observed, so this is the prior predictive before any data is observed.\nIt is used in prior predictive checks to assess whether the choice of prior distribution captures our prior beliefs.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>M3L6 - Priors</span>"
    ]
  },
  {
    "objectID": "C1-L06.html#sec-prior-predictive-binomial-example",
    "href": "C1-L06.html#sec-prior-predictive-binomial-example",
    "title": "16  M3L6 - Priors",
    "section": "16.2 Prior Predictive: Binomial Example",
    "text": "16.2 Prior Predictive: Binomial Example\n\n\n\n\n\n\n\nFigure 16.2: Prior Predictive Distribution Binomial Example\n\n\nSuppose we’re going to flip a coin 10 times and count the number of heads we see. But we are thinking about this in advance of actually doing it, and we are interested in the predictive distribution\n\n\nQ. How many heads do we predict we’re going to see?\nQ. What’s the probability that it shows up heads?\nSo, we’ll need to choose a prior.\n\nN=10 \\qquad \\text {number of coin flips}\n\nWhere Y_i represents individual coin flips. with Head being a success\n\nY \\sim \\text{Bernoulli}(\\theta)\n\nOur data is the count of successes (heads) in N flips.\n\nX = \\sum_{i=0}^N Y_i \\qquad\n\nIf we think that all possible coins or all possible probabilities are equally likely, then we can put a prior for \\theta that’s flat over the interval from 0 to 1. That is the Uniform prior (Equation 8.17):\n\nf(\\theta)=\\mathbb{I}_{[0 \\le \\theta \\le 1]}\n\nThe predictive probability is a binomial likelihood times the prior = 1\n\nf(x) = \\int f(x \\mid\\theta) f(\\theta) d\\theta = \\int_0^1 \\frac{10!}{x!(10-x)!} \\theta^x(1-\\theta)^{10-x}(1) d \\theta\n\nNote that because we’re interested in X at the end, it’s important that we distinguish between a Binomial density and a Bernoulli density. Here we just care about the total count rather than the exact ordering which would be Bernoulli.\nFor most of the analyses, we’re doing, where we’re interested in \\theta rather than x, the binomial and the Bernoulli are interchangeable because the part in here that depends on \\theta is the same.\nTo solve this integral let us recall that:\n\nn! =\\Gamma(n+1)\n\\tag{16.3}\nand\n\nZ \\sim \\text{Beta}(\\alpha,\\beta)\n\nThe PDF for the beta distribution is given as:\n\nf(z)= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} z^{\\alpha−1}(1−z)^{\\beta−1}I_{(0 &lt; z &lt;1)}\n\nwhere \\alpha&gt;0 and \\beta&gt;0.\n\n\\begin{aligned}\n  f(x) &= \\int f(x \\mid\\theta) f(\\theta) d\\theta && \\text {prior predictive dfn}\n\\\\ &= \\int_0^1 \\frac{10!}{x!(10-x)!} \\theta^x(1-\\theta)^{10-x}( \\mathbb{I_{[0,1]}}) d \\theta && \\text {subst. Binomial, } \\mathbb{I_{[0,1]}}\n\\\\ &= \\int_0^1 \\frac{\\Gamma(11)}{\\Gamma(x+1)\\Gamma(11-x)} \\theta^{(x+1)-1}(1-\\theta)^{(11-x)-1}(1) d \\theta && \\text {convert to Beta(x+1,11-x), }\n\\\\ &=\\frac{\\Gamma(11)}{\\Gamma(12)}\n\\cancel{\n  \\int_0^1 \\frac{\\Gamma(12)}{\\Gamma(x+1)\\Gamma(11-x)}\\theta^{(x+1)-1}(1-\\theta)^{(11-x)-1}(1)d \\theta\n} && \\text {integrating PDF=1 }\n\\\\ &=\\frac{\\Gamma(11)}{\\Gamma(12)} \\times 1\n= \\frac{10!}{11!}\n=\\frac{1}{11} && \\forall x \\in \\{1,2,\\dots,10\\}\n\\end{aligned}\n\nThus we see that if we start with a uniform prior, we then end up with a discrete uniform predictive density for X. If all possible \\theta probabilities are equally likely, then all possible sums X outcomes are equally likely.\nThe integral above is a beta density, all integrals of valid beta densities equal one.\n\nf(x) = \\frac{\\Gamma(11)}{\\Gamma(12)} = \\frac{10!}{11!} = \\frac{1}{11}",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>M3L6 - Priors</span>"
    ]
  },
  {
    "objectID": "C1-L06.html#posterior-predictive-distribution",
    "href": "C1-L06.html#posterior-predictive-distribution",
    "title": "16  M3L6 - Priors",
    "section": "16.3 Posterior Predictive Distribution",
    "text": "16.3 Posterior Predictive Distribution\n\n\n\n\nPosterior Predictive Distribution\n\nWhat about after we’ve observed data? What’s our posterior predictive distribution?\nGoing from the previous example, let us observe after one flip that we got a head.\nWe want to ask, what’s our predictive distribution for the second flip, given we saw a head on the first flip?",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>M3L6 - Priors</span>"
    ]
  },
  {
    "objectID": "C1-L06.html#posterior-predictive-distribution-1",
    "href": "C1-L06.html#posterior-predictive-distribution-1",
    "title": "16  M3L6 - Priors",
    "section": "16.4 Posterior Predictive Distribution",
    "text": "16.4 Posterior Predictive Distribution\nThe posterior predictive distribution is produced analogously to the posterior predictive distribution by marginalizing the posterior with respect to the parameter.\n\nDefinition 16.2 (Posterior Predictive Distribution) \n\\begin{aligned}\nf(y_2 \\mid y_1) &= \\text{likelihood}\\times \\text{posterior} \\\\\n&= \\int{f(y_2 \\mid \\theta,y_1) \\; f(\\theta \\mid y_1)}d\\theta\n\\end{aligned}\n\\tag{16.4}\n\n\n\n\n\n\n\nTipMarginalizing distribution\n\n\n\nSuppose we have an experiment with events based on two RVs: - (C) a coin toss - (D) and a dice toss. And we call this event X = \\mathbb{P}r(C,D) = \\mathbb{P}r(C) \\times \\mathbb{P}r(D)\n\n\n\nC D\n1\n2\n3\n4\n5\n6\n\\mathbb{P}r(C)\n\n\n\n\nH\n1/12\n1/12\n1/12\n1/12\n1/12\n1/12\n6/12\n\n\nT\n1/12\n1/12\n1/12\n1/12\n1/12\n1/12\n6/12\n\n\n\\mathbb{P}r(D)\n2/12\n2/12\n2/12\n2/12\n2/12\n2/12\n1\n\n\n\nWe can recover the \\mathbb{P}r(C) coin’s distribution or the dice distribution \\mathbb{P}r(D) by marginalization. \\mathbb{P}r(X) This is done by summing over the row or columns.\nThe marginal distribution let us subset a joint distribution. The marginal distribution has removed the uncertainty due to a parameter.\nwe use three terms interchangeably :\n\nmarginalizing the posterior w.r.t. \\theta\nintegrating/summing over \\theta\nintegrating \\theta out\n\nThe first is the real idea, the others are the techniques being used to do it. For a predictive distribution we may want to marginalize all the parameters so we end up with the RV we wish to predict.\n\n\nWe’re going to assume that Y_2 is independent of Y_1. Therefore,\n\nf(y_2 \\mid y_1) = \\int{f(y_2 \\mid \\theta)f(\\theta \\mid y_1)d\\theta}\n\nSuppose we’re thinking of a uniform distribution for \\theta and we observe the first flip is a “head”. What do we predict for the second flip?\nThis is no longer going to be a uniform distribution like it was before because we have some data. We’re going to think it’s more likely that we’re going to get a second head. We think this because since we observed a head \\theta is now likely to be at least \\frac{1}{2} possibly larger.\n\nf(y_2 \\mid Y_1 = 1) = \\int_0^1{\\theta^{y_2}(1-\\theta)^{1-y_2}2\\theta d\\theta}\n\n\nf(y_2 \\mid Y_1 = 1) = \\int_0^1{2\\theta^{y_2 + 1}(1-\\theta)^{1-y_2}d\\theta}\n\nWe could work this out in a more general form, but in this case, Y_2 has to take the value 0 or 1. The next flip is either going to be heads or tails so it’s easier to just plop in a particular example.\n\n\\mathbb{P}r(Y_2 = 1 \\mid Y_1 = 1) = \\int_\\theta^1 {2 \\theta^2 d \\theta} = \\frac{2}{3}\n\n\n\\mathbb{P}r(Y_2 = 0 \\mid Y_1 = 1) = 1 - \\mathbb{P}r(Y_2 = 1 \\mid Y_1 = 1) = 1 - \\frac{2}{3} = \\frac{1}{3}\n\nWe can see here that the posterior is a combination of the information in the prior and the information in the data. In this case, our prior is like having two data points, one head and one tail.\nSaying we have a uniform prior for \\theta is equivalent in an information sense to saying “we have observed one ‘Head’ and one ‘Tail’”.\nSo then when we observe one head, it’s like we now have seen two heads and one tail. So our predictive distribution for the second flip says if we have two heads and one tail, then we have a \\frac{2}{3} probability of getting another head and a \\frac{1}{3} probability of getting another tail.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>M3L6 - Priors</span>"
    ]
  },
  {
    "objectID": "C1-L06-Ex1.html",
    "href": "C1-L06-Ex1.html",
    "title": "17  Homework Posterior Probabilities",
    "section": "",
    "text": "For the next two questions, consider the following experiment:\n\nExample 17.1 (calibrating a thermometer) calibrating a thermometer\nSuppose you are trying to calibrate a thermometer by testing the temperature it reads when water begins to boil. Because of natural variation, you take several measurements (experiments) to estimate \\theta, the mean temperature reading for this thermometer at the boiling point.\nYou know that at sea level, water should boil at 100 degrees Celsius, so you use a precise prior with \\mathbb{P}r(\\theta = 100) = 1. You then observe the following five measurements: 94.6, 95.4, 96.2, 94.9, 95.9.\n\n\nExercise 17.1  What will the posterior for \\theta look like?calibrating a thermometer see Example 17.1\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nMost posterior probability will be concentrated near the sample mean of 95.4 \\degree C.\nMost posterior probability will be spread between the sample mean of 95.4 \\degree C and the prior mean of 100 \\degree C.\nThe posterior will be \\theta=100 with probability 1, regardless of the data.\nNone of the above.\n\nBecause all prior probability is on a single point (100 \\degree C), the prior completely dominates any data. If we are 100% certain of the outcome before the experiment, we learn nothing by performing it.\nThis was a poor choice of prior, especially in light of the data we collected.\nSince bad priors with \\mathbb{P}r(X=x)=1 or \\mathbb{P}r(X=x)=0 will ignore any additional data.\n\n\n\n\nExercise 17.2  Suppose you believe before the experiments that the thermometer is biased high so that on average it would read 105 \\degree C, and you are 95% confident that the average would be between 100 and 110.calibrating a thermometer see Example 17.1\nWhich of the following prior PDFs most accurately reflects this prior belief?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nThe prior mean is 105 degrees Celsius and approximately 95% of the prior probability is assigned to the interval (100, 110).\n\n\n\n\nExercise 17.3 Recall that for positive integer n, the gamma function has the following property: \\Gamma(n)=(n−1)!. What is the value of \\Gamma(6)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n    \\Gamma(6)=5!=120\n\n\n\n\n\nExercise 17.4 Find the value of the normalizing constant, c, which will cause the following integral to evaluate to 1.\n\n    \\int_0^1c⋅z^3(1-z)^1 dz.\n\n\n\n\n\n\n\n\nImportantHint:\n\n\n\nNotice that this is proportional to a beta density. We only need to find the values of the parameters \\alpha and \\beta and plug those into the usual normalizing constant for a Beta() density.\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n20 = \\frac{\\Gamma(4)\\Gamma(2) }{\\Gamma(4+2)} = {5!}{3!1!}\n\n\n\n\n\nExercise 17.5  Consider the coin-flipping coin-flipping example from Lesson 5. The likelihood for each coin flip was Bernoulli with a probability of heads \\theta, or f(y \\mid \\theta) = \\theta^y (1−\\theta)^{1−y} for y=0 or y=1, and we used a uniform prior on \\theta.coin-flipping see Example 11.1\nRecall that if we had observed Y_1 = 0 instead of Y_1 = 1, the posterior distribution for \\theta would have been f(\\theta \\mid Y_1 = 0 ) = 2(1−\\theta)I{\\{0 \\le \\theta \\le 1\\}}. Which of the following is the correct expression for the posterior predictive distribution for the next flip Y_2 \\mid Y_1 = 0?\n\nf(y_2 \\mid Y_1 = 0 ) = \\int_0^1 \\theta^{y_2}(1−\\theta)^{1−y_2}d\\theta \\: for \\: y_2 = 0 \\: or \\: y_2 = 1\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nThis is just the integral over likelihood × posterior. This expression simplifies to\n\\begin{aligned}\nf(y_2 \\mid Y_1 = 0 ) &= \\int_0^1 2 \\theta^{y_2} (1−\\theta)^{2−y_2}d \\theta \\mathbb{I}_{(y_2 \\in \\{0,1\\}) } \\\\\n                 &= \\frac {2}{\\Gamma(4)} \\Gamma(y_2 +1)\\Gamma(3-y_2) \\mathbb{I}_{(y_2 \\in \\{0,1\\}) } \\\\\n                 &= \\frac{2}{3} \\mathbb{I}_{(y_2 = 0)} + \\frac{1}{3} \\mathbb{I}_{(y_2 =1) } \\end{aligned}\n\n\n\n\n\nExercise 17.6 The prior predictive distribution for X, when \\theta is continuous, is given by\n\n\\int f(x\\mid \\theta) \\cdot f(\\theta)\\ d\\theta \\qquad \\text(prior\\ predictive\\ distribution)\n\nThe analogous expression when \\theta is discrete is\n\n\\sum_{\\theta} f(x \\mid \\theta)\\cdot f(\\theta) \\qquad \\text(prior\\ predictive\\ distribution)\n\nsumming over all possible values of \\theta.\nLet’s return to the loaded coin  of your brother’s. Recall that he has a fair coin where heads come up on average 50 \\% of the time (p=0.5) and a loaded coin (p=0.7). If we flip the coin five times, the likelihood is binomial: f(x \\mid p) = {5 \\choose x} p^x (1−p)^{5−x} where X counts the number of heads.loaded coin see Example 13.1\nSuppose you are confident, but not sure that he has brought you the loaded coin, so that your prior is f(p)=0.9 \\mathbb{I}_{(p=0.7)} +0.1 \\mathbb{I}_{(p=0.5)}. Which of the following expressions gives the prior predictive distribution of X?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n    f(x) = {5 \\choose x} .7^x .3^{5-x} (0.9) + {5 \\choose x} .5^x .5^{5-x} (0.1)\n\nThis is a weighted average of binomials, with weights being your prior probabilities for each scenario (loaded or fair).",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Homework Posterior Probabilities</span>"
    ]
  },
  {
    "objectID": "C1-L07.html",
    "href": "C1-L07.html",
    "title": "18  M3L7 - Binomial Data",
    "section": "",
    "text": "18.1 Bernoulli/Binomial likelihood with a uniform prior\nWhen we use a uniform prior for a Bernoulli likelihood, we get a beta posterior.\nThe Bernoulli likelihood of \\vec Y \\mid \\theta is\n{\\color{green}f(\\vec Y \\mid \\theta) = {\\theta^{\\sum{y_i}}(1-\\theta)^{n - \\sum{y_i}}}} \\qquad \\text{Bernoulli Likelihood}\nOur prior for \\theta is just a Uniform distribution\n{\\color{red}f(\\theta) = I_{\\{0 \\le \\theta \\le 1\\}} }\\qquad \\text {Uniform prior}\nThus our posterior for \\theta is \n\\begin{aligned}\nf(\\theta \\mid y) & = \\frac{f(y \\mid \\theta) f(\\theta)}{\\int f(y \\mid \\theta)f(\\theta) \\, d\\theta} & \\text{Bayes law} \\\\\n& = \\frac{\\theta^{\\sum{y_i}} (1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}}}{\\int_0^1 \\theta^{\\sum{y_i}}(1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}} \\, d\\theta} & \\text{subst. Likelihood \\& Prior} \\\\\n& = \\frac{\\theta^{\\sum{y_i}} (1-\\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}}}{\\frac{\\Gamma(\\sum{y_i} + 1)\\Gamma(n - \\sum{y_i} + 1)}{\\Gamma(n + 2)} \\cancel{\\int_0^1 \\frac{\\Gamma(n + 2)}{\\Gamma(\\sum{y_i} + 1) \\Gamma(n - \\sum{y_i} + 1)} \\theta^{\\sum{y_i}} (1 - \\theta)^{n - \\sum{y_i}} \\, d\\theta}} & \\text{Beta PDF integrates to 1} \\\\\n& = \\frac{\\Gamma(n + 2)}{\\Gamma(\\sum{y_i}+ 1) \\Gamma(n - \\sum{y_i}+ 1)} \\theta^{\\sum{y_i}}(1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}} & \\text{simplifying} \\\\\n& = \\mathrm{Beta} \\left (\\sum{y_i} + 1, n - \\sum{y_i} + 1 \\right )\n\\end{aligned}\nWhere we used a trick of recognizing the denominator as a Beta distribution (Equation 97.7) we then manipulate it to take the exact form of Beta. We can then cancel it since the beta density integrates to 1, we can simplify this as From here we can see that the posterior follows a beta distribution\n\\theta | y \\sim Beta(\\sum{y_i} + 1, n - \\sum{y_i} + 1)",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>M3L7 - Binomial Data</span>"
    ]
  },
  {
    "objectID": "C1-L07.html#bernoullibinomial-likelihood-with-a-uniform-prior",
    "href": "C1-L07.html#bernoullibinomial-likelihood-with-a-uniform-prior",
    "title": "18  M3L7 - Binomial Data",
    "section": "",
    "text": "Figure 18.1: Binomial likelihood with a Uniform prior\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipHistorical Note on R.A. Fisher\n\n\n\n R.A. Fisher’s objection to the Bayesian approach is that “The theory of inverse probability is founded upon an error, and must be wholly rejected” (Fisher 1925) was specifically referring to this example of a”Binomial with a Uniform prior”. The gist of it is that the posterior depends on the parametrization of the prior.(Aldrich 2008). R.A. Jeffry who corresponded with Fisher went on to develop his eponymous priors which were invariant to reparametrization. Which we will consider in Section 27.2",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>M3L7 - Binomial Data</span>"
    ]
  },
  {
    "objectID": "C1-L07.html#conjugate-priors",
    "href": "C1-L07.html#conjugate-priors",
    "title": "18  M3L7 - Binomial Data",
    "section": "18.2 Conjugate Priors",
    "text": "18.2 Conjugate Priors\n\n\n\n\nConjugate Priors\n\nThe uniform distribution is Beta(1, 1)\nAny beta distribution is conjugate for the Bernoulli distribution. Any beta prior will give a beta posterior.\n\nf(\\theta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha - 1}(1-\\theta)^{\\beta -1}\\mathbb{I}_{\\{\\theta \\le \\theta \\le 1\\}}\n\n\nf(\\theta \\mid y) \\propto f(y \\mid \\theta)f(\\theta) = \\theta^{\\sum{y_i}}(1-\\theta)^{n - \\sum{y_i}}\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha - 1}(1 - \\theta)^{\\beta - 1}\\mathbb{I}_{\\{\\theta \\le \\theta \\le 1\\}}\n\n\nf(y \\mid\\theta)f(\\theta) \\propto \\theta^{\\alpha + \\sum{y_i}-1}(1-\\theta)^{\\beta + n - \\sum{y_i} - 1}\n\nThus we see that this is a beta distribution\n\n\\theta \\mid y \\sim \\mathrm{Beta}(\\alpha + \\sum{y_i}, \\beta + n - \\sum{y_i})\n\nWhen \\alpha and \\beta are one like in the uniform distribution, then we get the same result as earlier.\nThis whole process where we choose a particular form of prior that works with a likelihood is called using a conjugate family.\nA family of distributions is referred to as conjugate if when you use a member of that family as a prior, you get another member of that family as your posterior.\nThe beta distribution is conjugate for the Bernoulli distribution. It’s also conjugate for the binomial distribution. The only difference in the binomial likelihood is that there is a combinatorics term. Since that does not depend on \\theta, we get the same posterior.\nWe often use conjugate priors because they make life much simpler, sticking to conjugate families allows us to get closed-form solutions easily.\nIf the family is flexible enough, then you can find a member of that family that closely represents your beliefs.\n\nthe Uniform distribution can be written as the Beta(1,1) prior.\nAny Beta prior will give a Beta posterior.\nBeta is conjugate for Binomial and for Bernoulli",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>M3L7 - Binomial Data</span>"
    ]
  },
  {
    "objectID": "C1-L07.html#posterior-mean-and-effective-sample-size",
    "href": "C1-L07.html#posterior-mean-and-effective-sample-size",
    "title": "18  M3L7 - Binomial Data",
    "section": "18.3 Posterior mean and effective sample size",
    "text": "18.3 Posterior mean and effective sample size\n\n\n\n\nEffective Sample Size\n\nReturning to the beta posterior model it is clear how both the prior and the data contribute to the posterior.\nFor a prior Beta(\\alpha,\\beta) we can say that the effective sample size of the prior is\n\n\\alpha + \\beta \\qquad \\text {(ESS)}\n\\tag{18.1}\nRecall that the expected value or mean of a Beta distribution is \\frac{\\alpha}{\\alpha + \\beta}\nTherefore we can derive the posterior mean as\n\n\\begin{aligned}\n   posterior_{mean} &= \\frac{\\alpha + \\sum{y_i}}{\\alpha + \\sum{y_i}+\\beta + n - \\sum{y_i}}\n\\\\                  &= \\frac{\\alpha+\\sum{y_i}}{\\alpha + \\beta + n}\n\\\\                  &= \\frac{\\alpha + \\beta}{\\alpha + \\beta + n}\\frac{\\alpha}{\\alpha + \\beta} + \\frac{n}{\\alpha + \\beta + n}\\frac{\\sum{y_i}}{n}\n\\\\ &= (\\text{prior weight} \\times \\text{prior mean}) + (\\text{data weight} \\times \\text{data mean})\n\\end{aligned}\n\\tag{18.2}\ni.e. The posterior mean is a weighted average of the prior mean and the data mean.\nThis effective sample size gives you an idea of how much data you would need to make sure that your prior does not have much influence on your posterior.\nIf \\alpha + \\beta is small compared to n then the posterior will largely just be driven by the data. If \\alpha + \\beta is large relative to n then the posterior will be largely driven by the prior.\nWe can make a 95% credible interval using our posterior distribution for \\theta . We can find an interval that has 95 \\% probability of containing \\theta.\nUsing Bayesian Statistics we can do sequential analysis by doing a sequential update every time we get new data. We can get a new posterior, and we just use our previous Posterior as a Prior for doing another update using Bayes’ theorem.\n\nfor a Beta prior, its effective sample size is a + b\nif n &gt;&gt; \\alpha+\\beta the posterior will be predominantly determined by the prior\nif n &lt;&lt; \\alpha+\\beta the posterior will be predominantly determined by the data\nthe idea of an effective sample size of the prior is a useful concept to work with.\n(Wiesenfarth and Calderazzo 2020)\n\nEffective Sample Size (ESS)\nEffective Current Sample size (ECSS)\n\n\n\nESS algorithms\n\n\nwith (Morita, Thall, and Müller 2008) on the left and ECSS on the right\n\n\n\nExercise 18.1 (Discussion on Prior elicitation) Suppose we are interested in global temperatures, and that we have a summary measure that represents the average global temperature for each year. Now we could ask “What is the probability that next year will have a higher average global temperature than this year?” What would be your choice of prior and why? Be specific about the distribution and its parameters. You may use any other information that you want to bring into this problem.\n\nSolution. It is possible to get historical estimates using:\n\nmeteorological and satellites for the last 200 years. \nice cores for the last 800,000 years \ndeep sea sediment oxygen 18 isotope fractation for the last 5 million years.  or yearly temperature data from 1850 till today based on meteorological readings. We can also consider Greenland ice core data covering 800,000 years.\n\nOne simple way is to model the yearly temperature as a random walk\ni.e. Each year is a Bernoulli trial where success is the temperature getting warmer. We can then use the historical data since 1800 to estimate theta the probability that we get warmer.\nI suppose we can use a Binomial prior with parameters for alpha the count of years the temperature increased and N for the total number of years and p the probability the a given year is hotter than the previous.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>M3L7 - Binomial Data</span>"
    ]
  },
  {
    "objectID": "C1-L07.html#data-analysis-example-in-r",
    "href": "C1-L07.html#data-analysis-example-in-r",
    "title": "18  M3L7 - Binomial Data",
    "section": "18.4 Data Analysis Example in R",
    "text": "18.4 Data Analysis Example in R\nSuppose we’re giving two students a multiple-choice exam with 40 questions, where each question has four choices. We don’t know how much the students have studied for this exam, but we think that they’ll do better than just guessing randomly\n\nWhat are the parameters of interest?\n\nThe parameters of interests are \\theta_1 = true the probability that the first student will answer a question correctly, \\theta_2 = true the probability that the second student will answer a question correctly.\n\nWhat is our likelihood?\n\nThe likelihood is \\mathrm{Binomial}(40, \\theta) if we assume that each question is independent and that the probability a student gets each question right is the same for all questions for that student.\n\nWhat prior should we use?\n\nThe Conjugate Prior is a Beta Distribution. We can plot the density with dbeta\n\n\nCode\ntheta = seq(from = 0, to = 1, by = 0.1)\n# Uniform\nplot(theta, dbeta(theta, 1, 1), type = 'l')\n\n\n\n\n\n\n\n\n\nCode\n# Prior mean 2/3\nplot(theta, dbeta(theta, 4, 2), type = 'l')\n\n\n\n\n\n\n\n\n\nCode\n# Prior mean 2/3 but higher effect size (more concentrated at mean)\nplot(theta, dbeta(theta, 8, 4), type = 'l')\n\n\n\n\n\n\n\n\n\n\nWhat are the prior probabilities \\mathbb{P}r(\\theta &gt; 0.25)? \\mathbb{P}r(\\theta &gt; 0.5)? \\mathbb{P}r(\\theta &gt; 0.8)?\n\n\n\nCode\n1 - pbeta(0.25, 8, 4)\n\n\n[1] 0.9988117\n\n\nCode\n#[1] 0.998117\n1 - pbeta(0.5, 8, 4)\n\n\n[1] 0.8867188\n\n\nCode\n#[1] 0.8867188\n1 - pbeta(0.8, 8, 4)\n\n\n[1] 0.1611392\n\n\nCode\n#[1] 0.16113392\n\n\n\nSuppose the first student gets 33 questions right. What is the posterior distribution for \\theta_1 ? \\mathbb{P}r(\\theta &gt; 0.25) ? \\mathbb{P}r(\\theta &gt; 0.5) ? \\mathbb{P}r(\\theta &gt; 0.8) ? What is the 95% posterior credible interval for \\theta_1?\n\n\\text{Posterior} \\sim Beta(8 + 33, 4 + 40 - 33) = Beta(41, 11)\n\nWith a posterior mean of \\frac{41}{41+11} = \\frac{41}{52}\n\nWe can plot the posterior distribution with the prior\n\n\nCode\nplot(theta, dbeta(theta, 41, 11), type = 'l')\nlines(theta, dbeta(theta, 8 ,4), lty = 2) #Dashed line for prior\n\n\n\n\n\n\n\n\n\nPosterior probabilities\n\n\nCode\n1 - pbeta(0.25, 41, 11)\n\n\n[1] 1\n\n\nCode\n#[1] 1\n1 - pbeta(0.5, 41, 11)\n\n\n[1] 0.9999926\n\n\nCode\n#[1] 0.9999926\n1 - pbeta(0.8, 41, 11)\n\n\n[1] 0.4444044\n\n\nCode\n#[1] 0.4444044\n\n\nEqual-tailed 95% credible interval\n\n\nCode\nqbeta(0.025, 41, 11)\n\n\n[1] 0.6688426\n\n\nCode\n#[1] 0.6688426\nqbeta(0.975, 41, 11)\n\n\n[1] 0.8871094\n\n\nCode\n#[1] 0.8871094\n\n\n95% confidence that \\theta_1 is between 0.67 and 0.89\n\nSuppose the second student gets 24 questions right. What is the posterior distribution for \\theta_2? \\mathbb{P}r(\\theta &gt; 0.25)? \\mathbb{P}r(\\theta &gt; 0.5)? \\mathbb{P}r(\\theta &gt; 0.8)? What is the 95% posterior credible interval for \\theta_2\n\n\n\\text{Posterior} \\sim Beta(8 + 24, 4 + 40 - 24) = Beta(32, 20)\n\nWith a posterior mean of \\frac{32}{32+20} = \\frac{32}{52}\nWe can plot the posterior distribution with the prior\n\n\nCode\nplot(theta, dbeta(theta, 32, 20), type = 'l')\nlines(theta, dbeta(theta, 8 ,4), lty = 2) #Dashed line for prior\n\n\n\n\n\n\n\n\n\nPosterior probabilities\n\n\nCode\n1 - pbeta(0.25, 32, 20)\n\n\n[1] 1\n\n\nCode\n#[1] 1\n1 - pbeta(0.5, 32, 20)\n\n\n[1] 0.9540427\n\n\nCode\n#[1] 0.9540427\n1 - pbeta(0.8, 32, 20)\n\n\n[1] 0.00124819\n\n\nCode\n#[1] 0.00124819\n\n\nEqual-tailed 95% credible interval\n\n\nCode\nqbeta(0.025, 32, 20)\n\n\n[1] 0.4808022\n\n\nCode\n#[1] 0.4808022\nqbeta(0.975, 32, 20)\n\n\n[1] 0.7415564\n\n\nCode\n#[1] 0.7415564\n\n\n95% confidence that \\theta_1 is between 0.48 and 0.74\n\nWhat is the posterior probability that \\theta_1 &gt; \\theta_2?\n\ni.e., that the first student has a better chance of getting a question right than the second student?\nEstimate by simulation: draw 1,000 samples from each and see how often we observe \\theta_1 &gt; \\theta_2\n\n\nCode\ntheta1 = rbeta(100000, 41, 11)\ntheta2 = rbeta(100000, 32, 20)\nmean(theta1 &gt; theta2)\n\n\n[1] 0.97509\n\n\nCode\n#[1] 0.975\n\n\n\n\n\n\n\n\nAldrich, John. 2008. “R. A. Fisher on Bayes and Bayes’ Theorem.” Bayesian Analysis 3 (March). https://doi.org/10.1214/08-BA306.\n\n\nFisher, R. A. 1925. Statistical Methods for Research Workers. 1st ed. Edinburgh Oliver & Boyd.\n\n\nMorita, Satoshi, Peter F Thall, and Peter Müller. 2008. “Determining the Effective Sample Size of a Parametric Prior.” Biometrics 64 (2): 595–602.\n\n\nWiesenfarth, Manuel, and Silvia Calderazzo. 2020. “Quantification of Prior Impact in Terms of Effective Current Sample Size.” Biometrics 76 (1): 326–36. https://doi.org/https://doi.org/10.1111/biom.13124.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>M3L7 - Binomial Data</span>"
    ]
  },
  {
    "objectID": "C1-L07-Ex1.html",
    "href": "C1-L07-Ex1.html",
    "title": "19  Homework on Priors",
    "section": "",
    "text": "For Questions Exercise 19.1-Exercise 19.5, consider the example of flipping a coin with unknown probability of heads (\\theta):\nSuppose we use a Bernoulli likelihood for each coin flip,\ni.e., f(y_i \\mid \\theta) = \\theta^{y_i} (1-\\theta)^{1-y_i} I_{\\{ 0 \\le \\theta \\le 1 \\}} for y_i=0 or y_i=1, and a uniform prior for \\theta.\n\nExercise 19.1 flipping a coin\nWhat is the posterior distribution for \\theta if we observe the following sequence: (T, T, T, T) where H denotes heads (Y=1) and T denotes tails (Y=0)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nBeta(1,4)\nBeta(4,0)\nBeta(0, 4)\nUniform(0,4)\nBeta(1, 5)\n\nThis is the PDF of a Beta(1,5).\n\n\n\n\nExercise 19.2 Which of the following graphs depicts the posterior PDF of \\theta if we observe the sequence (T, T, T, T)? (You may want to use R to plot the posterior.)\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ntheta = seq(from = 0, to = 1, by = 0.1)\n# Uniform\nplot(theta, dbeta(theta, 1, 5), type = 'l')\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 19.3 What is the maximum likelihood estimate (MLE) of θ if we observe the sequence (T, T, T, T)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n4*0/4\n\n\n[1] 0\n\n\nThe main issue here seems to be if we need to consider the prior in the sample size ?\n\n\n\n\nExercise 19.4 What is the posterior mean estimate of \\theta if we observe the sequence (T, T, T, T)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=1\nb=5\na/(a+b)\n\n\n[1] 0.1666667\n\n\n\n\n\n\nExercise 19.5 Use R or Excel to find the posterior probability that θ&lt;0.5 if we observe the sequence (T,T,T,T).\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=1\nb=5\npbeta(q=0.5, shape1=a, shape2=b)\n\n\n[1] 0.96875\n\n\n\n\n\nFor Questions Exercise 19.6-Exercise 19.9, consider the following scenario:\n An engineer wants to assess the reliability of a new chemical refinement process by measuring \\theta, the proportion of samples that fail a battery of tests. These tests are expensive, and the budget only allows 20 tests on randomly selected samples. Assuming each test is independent, she assigns a binomial likelihood where X counts the samples which fail. Historically, new processes pass about half of the time, so she assigns a \\text{Beta}(2,2) prior for \\theta (prior mean 0.5 and prior sample size 4). The outcome of the tests is 6 fails and 14 passes.Chemical refinement\n\nExercise 19.6 Chemical refinement\nWhat is the posterior distribution for θ? Beta(8,16)\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nBeta(8,16)\nBeta(14,6)\nBeta(6,14)\nBeta(6, 20)\nBeta(16,8)\n\n\n\n\n\nExercise 19.7 Chemical refinement\nUse R to calculate the upper end of an equal-tailed 95% credible interval for θ. Round your answer to two decimal places.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=8\nb=16\nqbeta(p=0.975, shape1=a, shape2=b)\n\n\n[1] 0.5291917\n\n\nwhere probability=0.975, alpha=8, and beta=16.\n\n\n\n\nExercise 19.8 Chemical refinement\nThe engineer tells you that the process is considered promising and can proceed to another phase of testing if we are 90% sure that the failure rate is less than .35.\nCalculate the posterior probability \\mathbb{P}r(\\theta &lt; .35 \\mid x). In your role as the statistician, would you say that this new chemical should pass?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=8\nb=16\npbeta(q=0.35, shape1=a, shape2=b)\n\n\n[1] 0.586431\n\n\n\nYes, \\mathbb{P}r(θ&lt;.35 \\mid x_1,x_2)≥0.9.\nNo, \\mathbb{P}r(θ&lt;.35 \\mid x_1,x_2)&lt;0.9.\n\n\n\n\n\nExercise 19.9 Chemical refinement\nIt is discovered that the budget will allow five more samples to be tested. These tests are conducted and none of them fail.\nCalculate the new posterior probability \\mathbb{P}r(\\theta &lt; .35 \\mid x_1, x_2). In your role as the statistician, would you say that this new chemical should pass (with the same requirement as in the previous question)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nHint: You can use the posterior from the previous analysis as the prior for this analysis. Assuming independence of tests, this yields the same posterior as the analysis in which we begin with the Beta(2,2) prior and use all 25 tests as the data.\n\n\nCode\na=8\nb=16\na2=a+0\nb2=b+5\npbeta(q=0.35, shape1=a2, shape2=b2)\n\n\n[1] 0.8179064\n\n\nwhere x=0.5, alpha=8, beta=21, and cumulative=TRUE.\n\nYes, \\mathbb{P}r(θ&lt;.35 \\mid x)≥0.9.\nNo, \\mathbb{P}r(θ&lt;.35 \\mid x)&lt;0.9.\n\n\n\n\n\nExercise 19.10 let X \\mid \\theta \\sim \\text{Binomial}(9, \\theta) and assume a \\text{Beta}(\\alpha,\\beta) prior for \\theta. Suppose your prior guess (prior expectation) for \\theta is 0.4 and you wish to use a prior effective sample size of 5, what values of α and β should you use?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nα=4, β=6\nα=4, β=10\nα=2, β=5\nα=2, β=3\n\nHere α+β=5 and \\frac{\\alpha}{\\alpha+\\beta} =0.4.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Homework on Priors</span>"
    ]
  },
  {
    "objectID": "C1-L08.html",
    "href": "C1-L08.html",
    "title": "20  M3L8 - Poisson Data",
    "section": "",
    "text": "Figure 20.1: Poisson likelihood with a Gamma prior\n\n\n\n\n20.0.1 Poisson - Chocolate Chip Cookie\nIn mass-produced chocolate chip cookies, they make a large amount of dough; mix in a large number of chips; then chunk out the individual cookies. In this process, the number of chips per cookie approximately follows a Poisson distribution.\nIf we were to assume that chips have no volume, then this would be exactly a Poisson process and follow exactly a Poisson distribution. In practice, since chips are not that small, so they follow approximately a Poisson distribution for the number of chips per cookie.\n\n\n\nY_i \\sim \\mathrm{Poisson}(\\lambda)\n\\tag{20.1}\n The likelihood of the data is given by the Poisson distribution.What is the likelihood of the data?\n\n\\begin{aligned}\n{\\color{red}f(y \\mid \\lambda) = \\frac{\\lambda^{\\sum{y_i}}e^{-n\\lambda}}{\\prod_{i = 1}^n{y_i!}}} \\quad \\forall (\\lambda &gt; 0) && \\text{ Poisson Likelihood }\n\\end{aligned}\n\n It would be convenient if we could put a conjugate prior. What distribution looks like \\lambda raised to a power and e raised to a negative power?What type of prior should we put on \\lambda ?\nFor this, we’re going to use a Gamma prior.\n\n\\begin{aligned} \\lambda &\\sim \\mathrm{Gamma}(\\alpha, \\beta) && \\text{Gamma Prior} \\\\ \\color{green}{ f(\\lambda)} &= \\color{green}{\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\lambda^{\\alpha - 1}e^{-\\beta\\lambda}} && \\text{subst. Gamma PDF} \\end{aligned}\n\\tag{20.2}\n We can use Bayes theorem to find the posterior.What is the posterior?\n\n\\begin{aligned} {\\color{blue}f(\\lambda \\mid y)} &\\propto \\color{red}{ f(y \\mid \\lambda)} \\color{green}{ f(\\lambda)} && \\text{Bayes without the denominator} \\\\ &\\propto \\color{red}{\\lambda^{\\sum{y_i}}e^{-n\\lambda}}\\color{green}{\\lambda^{\\alpha - 1}e^{-\\beta \\lambda} } && \\text{subst. Likelihood and Prior}\n\\\\ & \\propto { \\color{blue} \\lambda^{\\alpha + \\sum{y_i} - 1}e^{-(\\beta + n)\\lambda} } && \\text{collecting terms}\n\\\\ & \\propto { \\color{blue} \\mathrm{Gamma}(\\alpha + \\sum{y_i}, \\beta + n)}\n\\end{aligned}\n\\tag{20.3}\n The posterior is a Gamma distribution with parameters \\alpha + \\sum{y_i} and \\beta + n.What is the posterior distribution?\nThus we can see that the posterior is a Gamma Distribution\n\n\\lambda \\mid y \\sim \\mathrm{Gamma}(\\alpha + \\sum{y_i}, \\beta + n)\n\\tag{20.4}\n The posterior mean of a Gamma distribution is given byWhat is the posterior mean?\nThe mean of Gamma under this parameterization is: \\frac{\\alpha}{\\beta}\nThe posterior mean is going to be\n\n\\begin{aligned}\n{\\color{blue}\\mu_{\\lambda}} &= \\frac{\\alpha + \\sum{y_i}}{\\beta + n} && \\text{(Posterior Mean)} \\\\\nposterior_{\\mu}\n&= \\frac{\\alpha + \\sum{y_i}}{\\beta + n} \\\\\n&= \\frac{\\beta}{\\beta + n}\\frac{\\alpha}{\\beta} + \\frac{n}{\\beta + n}\\frac{\\sum{y_i}}{n} \\\\\n& \\propto  \\beta \\cdot \\mu_\\text{prior} + n\\cdot \\mu_\\text{data}\n\\end{aligned}\n\\tag{20.5}\n The posterior variance of a Gamma distribution is given byWhat is the posterior variance?\nAs you can see here the posterior mean of the Gamma distribution is also the weighted average of the prior mean and the data mean.\nTherefore, the effective sample size (ESS) of the Gamma prior is \\beta\n\n\n\n\n\n\nTipPrior Elicitation of Gamma Hyper-parameters\n\n\n\nHere are two strategies for choose the hyper-parameters \\alpha and \\beta\n\nAn informative prior with a prior mean guess of \\mu=\\frac{a}{b} e.g. what is the average number of chips per cookie?\n\nNext we need another piece of knowledge to pinpoint both parameters.\nCan you estimate the error for the mean? I.e. what do you think the standard deviation is? Since for the Gamma prior\nWhat is the effective sample size \\text{ESS}=\\beta ?\nHow many units of information do you think we have in our prior v.s. our data points ? \\sigma = \\frac{ \\sqrt{\\alpha} }{\\beta}\n\nA vague prior refers to one that’s relatively flat across much of the space.\n\nFor a Gamma prior we can choose \\Gamma(\\epsilon, \\epsilon) where \\epsilon is small and strictly positive. This would create a distribution with a \\mu = 1 and a huge \\sigma stretching across the whole space. And the effective sample size will also be \\epsilon Hence the posterior will be largely driven by the data and very little by the prior.\n\n\n\n\nThe first strategy with a mean and an ESS will be used in numerous models going forward so it is best to remember these two strategies!",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>M3L8 - Poisson Data</span>"
    ]
  },
  {
    "objectID": "C1-L08-Ex1.html",
    "href": "C1-L08-Ex1.html",
    "title": "21  Homework on Poisson Data",
    "section": "",
    "text": "For Questions Exercise 21.1-Exercise 21.8, consider the chocolate chip cookie example from the lesson Cookies\nAs in the lesson, we used a Poisson likelihood to model the number of chips per cookie, and a conjugate gamma prior for \\lambda, the expected number of chips per cookie.\nSuppose your prior expectation for \\lambda is 8.\n\nExercise 21.1 Cookies\nThe conjugate prior with mean 8 and effective sample size of 2 is Gamma(\\alpha,2). Find the value of \\alpha.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nif X \\sim \\mathrm{Gamma}(a,b) the mean for X is \\frac{a}{b}\n\n\\begin{aligned}\n8 &= \\frac{\\alpha}{\\beta}=\\frac{\\alpha}{2} \\\\\n\\implies \\alpha&=16\n\\end{aligned}\n\n\n\n\n\nExercise 21.2 Cookies\nThe conjugate prior with mean 8 and standard deviation 1 is\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\nsd &= \\frac{\\sqrt{\\alpha}}{8}= \\frac{\\sqrt{64}}{8} so\\\\\na &= 64\n\\end{aligned}\n\n\n\n\n\nExercise 21.3 Cookies\nSuppose you are not very confident in your prior guess of 8, so you want to use a prior effective sample size of 1/100 cookies. Then the conjugate prior is Gamma(a,0.01). Find the value of a\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\na=8\n\n\\begin{aligned}\n8 &= \\frac{\\alpha}{\\beta} \\\\\n  &=\\frac{\\alpha}{0.01} \\\\\n\\implies a &= 0.08\n\\end{aligned}\n\n\n\n\n\nExercise 21.4 Cookies\nSuppose you decide on the prior \\mathrm{Gamma}(8, 1), which has a prior mean of 8 and an effective sample size of 1 cookie.\nWe collect data, by sampling five cookies and counting the chips in each. We find 9, 12, 10, 15, and 13 chips.\nWhat is the posterior distribution for \\lambda?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\n\\lambda \\mid y &\\sim \\Gamma(\\alpha + \\sum{y_i}, \\beta + n) \\\\\n               &= \\mathrm{Gamma}(8 + (9+12+10+15+13),1+5) \\\\\n               &= \\mathrm{Gamma}(67,6)\n\\end{aligned}\n\n\n\n\n\nExercise 21.5 Cookies\nContinuing Exercise 21.4, what of the following graphs shows the prior density (dotted line) and posterior density (solid line) of \\lambda?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n# Generate x-values\nx &lt;- seq(0, 20, length.out = 1000)\n\n# posterior parameters\nshape &lt;- 67.\nscale &lt;- 6.\n# Generate y-values for posterior using dgamma\ny_post &lt;- dgamma(x, shape, scale)\n# prior parameters\nshape &lt;- 16.\nscale &lt;- 2\n# Generate y-values for prior using dgamma\ny_prior &lt;- dgamma(x, shape, scale)\n\n# Plot the distribution\n\nplot(x, y_post, type = \"l\", xlab = expression(theta), ylab = expression(paste(\"f(\",theta,\"|\", x,\")\")),  main = \"Gamma Distribution\", xlim = c(0, 20),lty=1,col='blue')\nlines(x, y_prior, lty=3,col='red')\nlegend(1,20,legend=c(\"prior\",\"posterior\"), col=c(\"blue\",\"red\"), lty=c(1,3), ncol=1)\n\n\n\n\n\n\n\n\nFigure 21.1\n\n\n\n\n\n\n\n\n\nExercise 21.6 Cookies\nContinuing Exercise 21.4, what is the posterior mean for λ? Round your answer to one decimal place.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nposterior_{mean} = \\frac{\\alpha + \\sum{y_i}}{\\beta + n}\n\\\\= \\frac{8 + (9+12+10+15+13)}{1 + 5} = 67/6=11.1667=11.2\n\n\n\n\n\nExercise 21.7 Cookies\nContinuing Exercise 21.4, use R or Excel to find the lower end of a 90% equal-tailed credible interval for λ.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n# Set parameters\nshape &lt;- 8+59\nrate &lt;- 1+5\n\n\n# Calculate 90% equal-tailed credible interval\nlower &lt;- qgamma(0.05, shape = shape, rate = rate)\nupper &lt;- qgamma(0.95, shape = shape, rate = rate)\n\n# Print interval\ncat(\"90% equal-tailed credible interval: [\", round(lower, 2), \", \", round(upper, 2), \"]\\n\")\n\n\n90% equal-tailed credible interval: [ 9.02 ,  13.5 ]\n\n\n\n\n\n\nExercise 21.8 Cookies\nContinuing Exercise 21.4, suppose that in addition to the five cookies reported, we observe an additional ten cookies with 109 total chips. What is the new posterior distribution for λ, the expected number of chips per cookie?\nHint: You can either use the posterior from the previous analysis as the prior here, or you can start with the original Gamma(8,1) prior and update with all fifteen cookies. The result will be the same.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\\mathrm{Gamma}(176, 16)\n\n\n\nFor Questions Exercise 21.9-Exercise 21.10, consider the following scenario:\nA retailer notices that a certain type of customer tends to call their customer service hotline more often than other customers, so they begin keeping track. They decide a Poisson process model is appropriate for counting calls, with a calling rate of \\theta calls per customer per day.\nThe model for the total number of calls is then Y \\sim Poisson(n \\cdot t \\cdot \\theta) where:\n\nn is the number of customers in the group and\nt is the number of days.\n\nThat is, if we observe the calls from a group with 24 customers for 5 days, the expected number of calls would be 24 \\cdot 5\\cdot \\theta = 120\\cdot \\theta\nThe likelihood for Y is then f(y \\mid \\theta) = \\frac{(nt\\theta)^y e^{-nt\\theta}}{y!} \\propto \\theta^y e^{-nt\\theta}.\nThis model also has a conjugate gamma prior θ \\sim \\mathrm{Gamma}(a,b) which has density (PDF) f(\\theta) = \\frac{b^a}{\\Gamma(a)} \\theta^{a-1} e^{-b\\theta} \\propto \\theta^{a-1} e^{-b\\theta}.\n\nExercise 21.9 Poisson process\nFollowing the same procedure outlined in the lesson, find the posterior distribution for \\theta\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nThe posterior density is proportional to the likelihood times the prior, which is\n\n\\begin{aligned}\nf(\\theta \\mid y) & \\propto \\theta ^y e^{− n t \\theta} \\theta ^{a−1}e^{−b \\theta}\\\\\n                 & = \\theta ^{y + a - 1} e^{b+nt \\theta}\\\\\n                 & = \\mathrm{Gamma}(a + y,b + nt)\n\\end{aligned}\n\nCombining the like-terms. What gamma distribution is this?\n\n\\mathrm{Gamma}(a+1,b+y)\n\\mathrm{Gamma}(a+y−1,b+1)\n\\mathrm{Gamma}(a+y,b+nt)\n\\mathrm{Gamma}(y,nt)\n\n\n\n\n\nExercise 21.10 Poisson process\nOn average, the retailer receives 0.01 calls per customer per day. To give this group the benefit of the doubt, they set the prior mean for \\theta at 0.01 with a standard deviation of 0.5. This yields a Gamma( 1/2500,1/25) prior for \\theta.\nSuppose there are n=24 customers in this particular group of interest, and the retailer monitors calls from these customers for t=5 days. They observe a total of y=6 calls from this group.\nThe following graph shows the resulting Gamma(6.0004,120.04) posterior for \\theta, the calling rate for this group. The vertical dashed line shows the average calling rate of 0.01.\n\n\nCode\n# Set parameters\nshape &lt;- 6.0004\nscale &lt;- 120.04\n\n# Generate x-values\nx &lt;- seq(0, 0.15, length.out = 1000)\n\n# Generate y-values using dgamma\ny &lt;- dgamma(x, shape, scale)\n# Plot the distribution\n\nplot(x, y, type = \"l\", xlab = expression(theta), ylab = expression(paste(\"f(\",theta,\"|\", x,\")\")),  main = \"Gamma Distribution\", xlim = c(0, 0.15))\n\n# Add a vertical dashed line for the average calling rate\nabline(v = 0.01, lty = 2, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n\nDoes this posterior inference for \\theta suggest that the group has a higher calling rate than the average of 0.01 calls per customer per day?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nYes, most of the posterior mass (probability) is concentrated on values of θ greater than 0.01. The posterior probability that θ &gt; 0.01 is 0.998.\n\n\n\n\n\n\n\n\n\nTipLatex Labels\n\n\n\n\n\nTo get latex labels into the graph in R I used xlab = expression(theta) and ylab = expression(paste(\"f(\",theta,\"|\", x,\")\")),",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Homework on Poisson Data</span>"
    ]
  },
  {
    "objectID": "C1-L08-Ex2.html",
    "href": "C1-L08-Ex2.html",
    "title": "22  Honors Quiz - Beta Bernoulli",
    "section": "",
    "text": "Exercise 22.1 Identify which of the following conditions (possibly more than one) must be true for the sum of n Bernoulli random variables (with success probability p) to follow a binomial distribution.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\np must be the same for each of the Bernoulli random variables\neach Bernoulli random variable is independent of all others\np must be less than .5\nthe sum must exceed n\nthe sum must be greater than zero\n\n\n\n\nFor Questions 2-4, consider the following:\n\nExercise 22.2 In Lesson 6.3 we found the prior predictive distribution for a Bernoulli trial under a uniform prior on the success probability \\theta. We now derive the prior predictive distribution when the prior is any conjugate beta distribution.\nThere are two straightforward ways to do this. The first approach is the same as in the lesson. The marginal distribution of y is\n\nf(y)= \\int^1_0  f(y \\mid θ)f(θ)dθ\n\nNow f(θ) is a beta PDF, but the same principles apply: we can move constants out of the integral and find a new normalizing constant to make the integral evaluate to 1.\nAnother approach is to notice that we can write Bayes’ theorem as\n\nf(θ \\mid y)= \\frac{f(y \\mid θ)f(θ)}{f(y)}\n\nIf we multiply both sides by f(y) and divide both sides by f(θ∣y), then we get\n\nf(y) = \\frac{f(y \\mid θ)f(θ)}{f(θ\\mid y)}\n\nwhere:\n\nf(θ) is the beta prior PDF and\nf(θ \\mid y) is the updated beta posterior PDF.\n\nBoth approaches yield the same answer.\nWhat is the prior predictive distribution f(y) for this model when the prior for \\theta is Beta(a,b)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nf(y)=\\frac{Γ(a+b)}{Γ(a+b+1)}\\cdot \\frac{Γ(a+y)}{Γ(a)} \\cdot \\frac{Γ(b+1−y)}{Γ(b)}  \\qquad \\text{for }  y = 0,1\n\nAll the terms involving \\theta canceled out as they should.\n\n\n\n\nExercise 22.3 Now suppose the prior for \\theta is Beta(2,2). What is the prior predictive probability that y^∗=1 for a new observation y^∗?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\n    \\mathrm{Beta}(2,2) &= \\frac{Γ(2+2)}{Γ(2+2+1)} \\cdot \\frac{Γ(2+y)}{Γ(2)} \\cdot \\frac{Γ(2+1−y)}{Γ(2)} \\\\\n    &= \\frac{Γ(4)}{Γ(5)} \\cdot \\frac{Γ(3)}{Γ(2)} \\cdot \\frac{Γ(2)}{Γ(2)} && \\text{(subst. y=1)} \\\\\n    &= \\frac{4! 3! 2!}{5! 2! 2!} && \\text{( subst. } x! = \\Gamma(x+1) )\\\\\n    &= \\frac{12}{24}  && \\text{ (simplifying)}\n\\end{aligned}\n\n\n\n\n\nExercise 22.4 After specifying our Beta(2,2) prior for \\theta, we observe 10 Bernoulli trials, 3 of which are successes. What is the posterior predictive probability that y^∗=1? for the next (11th) observation y^∗? Round your answer to two decimal places.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\\begin{aligned}\nBeta(5,9)   &= \\frac{Γ(5+9)}{Γ(5+9+1)}\\cdot \\frac{Γ(5+y)}{Γ(5)} \\cdot \\frac{Γ(9+1−y)}{Γ(9)}\\\\\n            &= \\frac{Γ(14)}{Γ(15)}    \\cdot \\frac{Γ(6)}{Γ(5)}   \\cdot \\frac{Γ(9)}{Γ(9)} && \\text{(subst.  y=1)}\\\\\n            &= \\frac{13! 5! 8!}{14! 4! 8!} && \\text{ (subst. x! =} \\mathrm{Gamma}(x+1))\\\\\n            &= \\frac{5}{14} && \\text{(simplifying)}\n\\end{aligned}",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Honors Quiz - Beta Bernoulli</span>"
    ]
  },
  {
    "objectID": "C1-L09.html",
    "href": "C1-L09.html",
    "title": "23  M4L9 - Exponential Data",
    "section": "",
    "text": "Figure 23.1: Exponential likelihood with a Gamma prior\n\n\n Suppose you’re waiting for a bus that you think comes on average once every 10 minutes, but you’re not sure exactly how often it comes.Time between buses\n\nY \\sim \\mathrm{Exp}(\\lambda)\n\\tag{23.1}\nYour waiting time has a prior expectation of \\frac{1}{\\lambda}\nThe Gamma distribution is conjugate for an Exponential likelihood. We need to specify a prior, or a particular Gamma in this case. If we think that the buses come on average every ten minutes, that’s a rate of one over ten.\n\nprior_{\\mu} = \\frac{1}{10}\n\nThus, we’ll want to specify a gamma distribution so that the first parameter divided by the second parameter is {1 \\over 10}\nWe can now think about our variability. Perhaps you specify\n\n\\mathrm{Gamma}(100, 1000)\n\nThis will indeed have a prior mean of {1 \\over 10} and it’ll have a standard deviation of {1 \\over 100}. If you want to have a rough estimate of our mean plus or minus two standard deviations then we have the following\n\n0.1 \\pm 0.02\n\nSuppose that we wait for 12 minutes and a bus arrives. Now you want to update your posterior for \\lambda about how often this bus will arrive.\n\nf(\\lambda \\mid y) \\propto f(y\\mid \\lambda)f(\\lambda)\n\n\nf(\\lambda \\mid y) \\propto \\lambda e^{-\\lambda y}\\lambda^{\\alpha - 1}e^{-\\beta \\lambda}\n\n\nf(\\lambda \\mid y)  \\propto \\lambda^{(\\alpha + 1) - 1}e^{-(\\beta + y)\\lambda}\n\n\n\\lambda \\mid y \\sim \\mathrm{Gamma}(\\alpha + 1, \\beta + y)\n\nPlugging in our particular prior gives us a posterior for \\lambda which is\n\n\\lambda \\mid y \\sim \\mathrm{Gamma}(101, 1012)\n\nThus our posterior mean is going to be \\frac{101}{1012} = 0.0998.\nThis one observation does not contain a lot of data under this likelihood. When the bus comes and it takes 12 minutes instead of 10, it barely shifts our posterior mean up.\nOne data point does not have a big impact here.\n\nExercise 23.1 We can generalize the result from the lesson to more than one data point.\n\nSuppose\n\nY_1, \\ldots, Y_n \\stackrel{iid}\\sim Exp(\\lambda)=\\lambda e^{-\\lambda x}\\mathbb{I}_{x\\ge0}\n\nwith mean\n\n\\mathbb{E}[Y]=\\frac{1}{\\lambda}\n\nand assume a\n\nf(\\lambda)= \\mathrm{Gamma}(\\alpha, \\beta) \\qquad (\\text{prior for }\\lambda)\n\nThe likelihood is then:\n\nf(y \\mid \\lambda) = \\prod \\lambda e^{-\\lambda x}\\mathbb{I}_{x\\ge0} =  \\lambda ^ n e^{− \\lambda \\sum y_i}\\cdot1\n\nand we can follow the same steps from the lesson to obtain the posterior distribution (try to derive it yourself):\n\n\\lambda \\mid y ∼ \\mathrm{Gamma}(\\alpha + n, \\beta + \\sum y_i)\n\n What is the prior effective sample size (ess) in this model?\n\nSolution. The data sample size n is added to \\alpha to update the first parameter. Thus \\alpha can be interpreted as the sample size equivalent in the prior.\n\nIt might be helpful to think about a related problems…\n\nWe are waiting at a bus stop with 1 bus line, the information at the bus stop say that the bus comes on average every 10 minutes at this time. How long do we expect to wait for the bus?\nwhat if we have waited for k minutes and the bus has not arrived yet? How long do we expect to wait for the bus?\nWhile we are waiting more people arrive at the bus stop. You notice the bus stop features a digital counter and a display with long term mean E and V variance of the number of people at the bus stop. Can we use this information to get a better estimate of our bus arrival time?\nIf we wait at a bus stop with K different bus lines each with the same lambda, and we see a L people waiting. Can we get a better estimate of our bus arrival time?\nWhat if more people come. And we know the mean and variance of the people waiting at the bus stop?\nWhat if a different bus line arrives and the number of people waiting is now M?\nWhat if each bus line has a different lambda, but we know the mean and variance of the people waiting at the bus stop?",
    "crumbs": [
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>M4L9 - Exponential Data</span>"
    ]
  },
  {
    "objectID": "C1-L09-Ex1.html",
    "href": "C1-L09-Ex1.html",
    "title": "24  Homework exponential data",
    "section": "",
    "text": "TipExponential data\n\n\n\nThe following are useful for solving the problems\n\n\\begin{aligned}\nY  &\\sim Exp(\\lambda) && RV \\\\ f(y|\\lambda)&= \\color{red}{\\lambda^n e^{- \\lambda n \\bar{y} }} && Likelihood \\\\ f(\\lambda)&\\sim Gamma(a,b) && Conj. Prior \\\\&=\\color{blue}{\\lambda^{a - 1}e^{-b \\lambda}} && Prior \\\\ \\therefore \\mathbb{E}[f] &= a/b && Prior\\ mean \\\\ \\therefore \\mathbb{V}ar[f] &= a/b^2 && Prior\\ variance \\\\ \\therefore ESS[f] &= a && Prior ESS \\\\f(\\lambda \\mid y) &\\propto f(y|\\lambda)f(\\lambda) && Posterior \\\\  &\\propto \\color{red}{\\lambda^n e^{-\\lambda n \\bar{y} }}\\color{blue}{\\lambda^{a - 1}e^{-b \\lambda}} \\\\ &\\sim \\Gamma(\\alpha =a + n, \\beta=b + \\lambda n \\bar{y} ) \\\\ \\therefore \\mathbb{E}[f(y|\\lambda)] &= \\alpha / \\beta && Post\\ mean \\\\ \\therefore \\mathbb{V}ar[f(y|\\lambda)] &= \\alpha/\\beta^2 && Post\\ variance \\\\ \\therefore ESS[f(y|\\lambda)] &= a && Post\\ Prior\\ ESS \\\\ \\therefore ESS[f(y|\\lambda)] &= n && Post\\ Data\\ ESS\n\\end{aligned}\n\n\n\n\nExercise 24.1 See ?exm-bus-times bus waiting time example\nRecall that we used the conjugate gamma prior for \\lambda, the arrival rate in buses per minute. Suppose our prior belief about this rate is that it should have a mean 1/20 arrivals per minute with a standard deviation 1/5. Then the prior is Gamma(a,b) with a=1/16.\nFind the value of b.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n1.25\n\n\n\n\nExercise 24.2 See ?exm-bus-times bus waiting time example\nSuppose that we wish to use a prior with the same mean (1/20), but with an effective sample size of one arrival. Then the prior for \\lambda is Gamma(1,20).\nIn addition to the original Y_1 = 12, we observe the waiting times for four additional buses: Y_2 = 15, Y_3 = 8, Y_4 = 13.5, Y_5 = 25\nRecall that with multiple (independent) observations, the posterior for \\lambda is Gamma(\\alpha,\\beta) where α=a+n and \\beta = b + \\sum y_i What is the posterior mean for \\lambda?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n=(1+5)/(20+12+15+8+13.5+25)=\n\n\nCode\n(1+5)/(20+12+15+8+13.5+25)\n\n\n[1] 0.06417112\n\n\n\n\n\n\nExercise 24.3 See ?exm-bus-times bus waiting time example\nBus waiting times:\nContinuing Exercise 24.2, use R or Excel to find the posterior probability that \\lambda &lt; 1/10?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\npgamma(q=1/10,shape=6,rate=93.5)\n\n\n[1] 0.9039699\n\n\n\n\n\nFor Questions 4-10, consider the following earthquake data:\n\nExercise 24.4  The United States Geological Survey maintains a list of significant earthquakes worldwide. We will model the rate of earthquakes of magnitude 4.0+ in the state of California during 2015. An IID Exponential model on the waiting time between significant earthquakes is appropriate if we assume:Earthquake data\n\nearthquake events are independent,\nthe rate at which earthquakes occur does not change during the year, and\nthe earthquake hazard rate does not change (i.e., the probability of an earthquake happening tomorrow is constant regardless of whether the previous earthquake was yesterday or 100 days ago).\n\nLet Y_i denote the waiting time in days between the ith earthquake and the following earthquake. Our model is Y_i \\stackrel{iid}\\sim Exponential(\\gamma) where the expected waiting time between earthquakes is \\mathbb{E}[Y]=1/\\lambda days.\nAssume the conjugate prior \\lambda \\sim Gamma(a,b). Suppose our prior expectation for \\mathbb{E}[\\lambda]= 1/30, and we wish to use a prior effective sample size of one interval between earthquakes.\n\nWhat is the value of a ?\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\na is the effective sample size of the prior which we were given as 1.\na=1\n\n\n\n\nExercise 24.5 What is the value of b?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nThe prior mean is a/b = 1/30, and since we know the effective sample size a=1, we have b=30.\n\n\n\n\nExercise 24.6 The significant earthquakes of magnitude 4.0+ in the state of California during 2015 occurred on the following dates (http://earthquake.usgs.gov/earthquakes/browse/significant.php?year=2015):\nJanuary 4, January 20, January 28, May 22, July 21, July 25, August 17, September 16, December 30.\nRecall that we are modeling the waiting times between earthquakes in days. Which of the following is our data vector?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\ny = (3, 16, 8, 114, 60, 4, 23, 30, 105, 1)\ny = (0, 0, 4, 2, 0, 1, 1, 3)\ny = (3, 16, 8, 114, 60, 4, 23, 30, 105)\ny = (16, 8, 114, 60, 4, 23, 30, 105)\n\nBeginning the data vector with a wait period of three days implicitly assumes an event occurred on Jan. 1, which is not the case. This would bias our estimate of average wait times on the low side. So we should drop the first point.\n\n\n\n\nExercise 24.7 Earthquake data\nThe posterior distribution is for \\lambda ∼ Gamma(\\alpha ,\\beta). What is the value of \\alpha?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\\alpha = a + n = 1+8=9\n\n\n\n\nExercise 24.8 Earthquake data\nThe posterior distribution is for \\lambda \\sim Gamma(\\alpha,\\beta). What is the value of \\beta?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nsum(16, 8, 114, 60, 4, 23, 30, 105, 30)\n\n\n[1] 390\n\n\n\\beta = b + \\sum {y_i} = 30 + sum(16, 8, 114, 60, 4, 23, 30, 105,30)=420\n\n\n\n\nExercise 24.9 Earthquake data\nThe posterior distribution is for \\lambda ∼ Gamma(\\alpha,\\beta). What is the value of \\beta?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nqgamma(p=0.975, shape=9, rate=390)\n\n\n[1] 0.04041843\n\n\n\n\n\n\nExercise 24.10 Earthquake data\nThe posterior predictive density for a new waiting time y^∗ in days is:\n\n\\begin{aligned}\nf(y^∗ \\mid y) &= \\int f(y^∗ \\mid \\lambda) \\cdot f(\\lambda \\mid y) d \\lambda \\\\&= \\frac{\\beta^αΓ(\\alpha+1) }{(\\beta+y^*)^{\\alpha+1}Γ(\\alpha)} I_{(y^∗\\ge 0)} \\\\&= \\frac{ \\beta ^ \\alpha \\alpha}{(\\beta+y^*)^{\\alpha+1}} I_{(y^∗\\ge 0)}\n\\end{aligned}\n\nwhere f(\\lambda \\mid y) is the Gamma(α,β) posterior found earlier.\nUse R or Excel to evaluate this posterior predictive PDF.\nWhich of the following graphs shows the posterior predictive distribution for y^∗ ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\npost_pred = function(alpha, beta, y_star) {\n  return(beta^alpha / (beta+y_star)^(alpha+1))\n}\ny_star= seq(from = 0.01, to = 120, by =  .01)\nplot(y_star, post_pred(9, 390, y_star),xlab = 'y*', ylab ='f(y*|y)')",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Homework exponential data</span>"
    ]
  },
  {
    "objectID": "C1-L10.html",
    "href": "C1-L10.html",
    "title": "25  M4L10 - Normally distributed Data",
    "section": "",
    "text": "25.1 Normal Likelihood with known variance\nNormally distributed data is not that common. However, modeling using a normal RV is second to none.(Hoff 2009, 75). The CLT is the primary reason that the normal is a good approximation if there are enough IID samples. We will look at two types of conjugate normal priors, and in the next unit we will consider two more uninformative priors for Normally distributed data.\nCharles Zaiontz provides pro types of conjugate priors for normally distributed data:\nIn each case, the unknown refer to population statistics. Since we are able to estimate sample parameters such as the mean and variance quite easily. A key question to consider is how well does our posterior distribution of the parameter representative of the unknown population statistic?\nIdeally, I will update the notes below with proofs of conjugate, prior and posterior and marginal distribution.\nSome of the proofs are in here as well\nSee (Hoff 2009, sec. 5.2)\nLet’s suppose the standard deviation or variance \\sigma^2 is known and we’re only interested in learning about the mean. This is a situation that often arises in monitoring industrial production processes.\nX_i \\stackrel{iid}\\sim \\mathcal{N}(\\mu, \\sigma^2)\n\\tag{25.1}\nIt turns out that the Normal distribution is conjugate for itself when looking for the mean parameter\nPrior\n\\mu \\sim \\mathcal{N}(m_0,S_0^2)\n\\tag{25.2}\nBy Bayes rule:\nf(\\mu \\mid x ) \\propto f(x \\mid \\mu)f(\\mu)\n\\mu \\mid x \\sim \\mathcal{N} \\left (\\frac{\\frac{n\\bar{x}}{\\sigma_0^2} + \\frac{m_0}{s_0^2} }{\\frac{n}{\\sigma_0^2} +\\frac{1}{s_0^2}}, \\frac{1}{\\frac{n}{\\sigma_0^2} + \\frac{1}{s_0^2}}\\right )\n\\tag{25.3}\nwhere:\nLet’s look at the posterior mean\n\\begin{aligned}\nposterior_{\\mu} &= \\frac{\n          \\frac{n}{\\sigma_0^2}}\n       {\\frac{n}{\\sigma_0^2}s + \\frac{1}{s_0^2}}\\bar{x} +     \n          \\frac{ \\frac{1}{s_0^2} }{ \\frac{n}{\\sigma_0^2} + \\frac{1}{s_0^2}\n        }m\n\\\\ &= \\frac{n}{n + \\frac{\\sigma_0^2}{s_0^2} }\\bar{x} + \\frac{ \\frac{\\sigma_0^2}{s_0^2} }{n + \\frac{\\sigma_0^2}{s_0^2}}m\n\\end{aligned}\n\\tag{25.4}\nThus we see, that the posterior mean is a weighted average of the prior mean and the data mean. And indeed that the effective sample size for this prior is the ratio of the variance for the data to the variance in the prior.\nPrior\\ ESS= \\frac{\\sigma_0^2}{s_0^2}\n\\tag{25.5}\nThis makes sense, because the larger the variance of the prior, the less information that’s in it.\nThe marginal distribution for Y is\n\\mathcal{N}(m_0, s_0^2 + \\sigma^2)\n\\tag{25.6}",
    "crumbs": [
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>M4L10 - Normally distributed Data</span>"
    ]
  },
  {
    "objectID": "C1-L10.html#sec-normal-likelihood-with-unknown-mean",
    "href": "C1-L10.html#sec-normal-likelihood-with-unknown-mean",
    "title": "25  M4L10 - Normally distributed Data",
    "section": "",
    "text": "Figure 25.1: Normal likelihood with variance known\n\n\n\n\n\n\n\n\n\n\n\n\n\nn is the sample size\n\\bar{x}=\\frac{1}{n}\\sum x_i is the sample mean\n\\sigma =\\frac{1}{n} \\sum (x_i-\\bar{x})^2 is the sample variance\nindexing parameters with 0 seems to be a convention that they are from the prior:\ns_0 is the prior variance\nm_0 is the prior mean\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nshould we use n-1 in the sample variance?\n\n\n\n\n\n\n\n\n25.1.1 Prior (and posterior) predictive distribution\nThe prior (and posterior) predictive distribution for data is particularly simple in the conjugate normal model .\nIf \ny \\mid \\theta \\sim \\mathcal{N}(\\theta,\\sigma^2)\n and \n\\theta \\sim \\mathcal{N}(m, s_0^2)\n\nthen the marginal distribution for Y, obtained as\n\n\\int f(y,\\theta) d\\theta = \\mathcal{N}(m_0,s_0^2)\n\\tag{25.7}\n\nExample 25.1 Suppose your data are normally distributed with \\mu=\\theta and \\sigma^2=1.\n\ny \\mid \\theta \\sim \\mathcal{N}(\\theta,1)\n\nYou select a normal prior for \\theta with mean 0 and variance 2.\n\n\\theta \\sim \\mathcal{N}(0, 2)\n\nThen the prior predictive distribution for one data point would be N(0, a). What is the value of a?\nSince, m_0 =0, and s^2_0=2 and \\sigma^2=1, the predictive distribution is N(0,2+1).",
    "crumbs": [
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>M4L10 - Normally distributed Data</span>"
    ]
  },
  {
    "objectID": "C1-L10.html#sec-normal-likelihood-with-expectation-and-variance-unknown",
    "href": "C1-L10.html#sec-normal-likelihood-with-expectation-and-variance-unknown",
    "title": "25  M4L10 - Normally distributed Data",
    "section": "25.2 Normal likelihood with expectation and variance unknown",
    "text": "25.2 Normal likelihood with expectation and variance unknown\n\n\n\n\n\n\n\nFigure 25.2: Normal likelihood with a unknown variance\n\n\n\n\n\n\n\n\nTipChallenging\n\n\n\nThis section is challenging.\n\nThe updating derivation is skipped,\nthe posterior\nupdating rule values are introduced without motivations and explanation.\nThe model is also the most complicated in the course, the note at the end says this can be extended hierarchically if we want to specify hyper priors for m, w and \\beta\nOther text discuss this case using a inverse chi squared distribution\n\nIf we can understand the model the homework is going to make sense. Also this is probably the level needed for the other courses in the specialization.\nIt can help to review some of the books:\n\nSee (Hoff 2009, sec. 5.3) which has some R examples.\nSee (Gelman et al. 2013, sec. 5)\n\n\n\nIf both \\mu and \\sigma^2 are unknown, we can specify a conjugate prior in a hierarchical fashion.\n\nX_i \\mid \\mu, \\sigma^2 \\stackrel{iid}\\sim \\mathcal{N}(\\mu, \\sigma^2) \\qquad \\text{(the data given the params) }\n\n\nThis is the level 1 hierarchically model - X_i model our observations.\nWe state on the left, that the RV X is conditioned on the \\mu and \\sigma^2.\nBut the variables \\mu and \\sigma^2 are unknown population statistics which we will need to infer from the data. We can call them latent variables.\n\nNext we add a prior from \\mu conditional on the value for \\sigma^2\n\n\\mu \\mid \\sigma^2 \\sim \\mathcal{N}(m, \\frac{\\sigma^2}{w}) \\qquad \\text{(prior of the mean conditioned on the variance)}\n\nwhere:\n\nw is going to be the ratio of \\sigma^2 and some variance for the Normal distribution. This is the effective sample size of the prior.\nWhy is the mean conditioned on the variance. We can have a model where they are independent too?\nlater on (in the homework) we are told that w can express the confidence in the prior.\nI think this means that Since this is a knowledge of m, i.e. giving w a weight of 1/10 expresses that we value\n\nPerhaps this is due to CLT ?\nThis is level 2 of the model\n\nFinally, the last step is to specify a prior for \\sigma^2. The conjugate prior here is an inverse gamma distribution with parameters \\alpha and \\beta.\n\n\\sigma^2 \\sim \\mathrm{Gamma}^{-1}(\\alpha, \\beta)  \\qquad \\text{prior of the variance}\n\nAfter many calculations… we get the posterior distribution\n\n\\sigma^2 \\mid x \\sim \\mathrm{Gamma}^{-1}(\\alpha + \\frac{n}{2}, \\beta + \\frac{1}{2}\\sum_{i = 1}^n{(x-\\bar{x}^2 + \\frac{nw}{2(n+2)}(\\bar{x} - m)^2)})\n\\tag{25.8}\n\n\\mu \\mid \\sigma^2,x \\sim \\mathcal{N}(\\frac{n\\bar{x}+wm}{n+w}, \\frac{\\sigma^2}{n + w})\n\\tag{25.9}\nWhere the posterior mean can be written as the weighted average of the prior mean and the data mean.\n\n\\frac{n\\bar{x}+wm}{n+w} = \\frac{w}{n + w}m + \\frac{n}{n + w}\\bar{x} \\qquad \\text{post. mean}\n\\tag{25.10}\nIn some cases, we only care about \\mu. We want some inference on \\mu and we may want it such that it does not depend on \\sigma^2. We can marginalize that \\sigma^2 integrating it out. The posterior for \\mu marginally follows a t distribution.\n\n\\mu \\mid x \\sim t\n\nSimilarly, the posterior predictive distribution also is a t distribution.\nFinally, note that we can extend this in various directions, this can be extended to the multivariate normal case that requires matrix vector notations and can be extended hierarchically if we want to specify priors for m, w, \\beta\n\n\n\n\n\n\nGelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. Bayesian Data Analysis, Third Edition. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis. https://books.google.co.il/books?id=ZXL6AQAAQBAJ.\n\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical Methods. Springer New York. https://doi.org/10.1007/978-0-387-92407-6.",
    "crumbs": [
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>M4L10 - Normally distributed Data</span>"
    ]
  },
  {
    "objectID": "C1-L10-Ex1.html",
    "href": "C1-L10-Ex1.html",
    "title": "26  Homework Normal data",
    "section": "",
    "text": "Exercise 26.1 See Example 17.1 thermometer calibration problem\nSuppose you are trying to calibrate a thermometer by testing the temperature it reads when water begins to boil. Because of natural variation, you take n independent measurements (experiments) to estimate \\theta, the mean temperature  reading for this thermometer at the boiling point. Assume a normal likelihood for these data, with mean \\theta and known variance \\sigma^2=0.25 (which corresponds to a standard deviation of 0.5^\\circ Celsius). \\theta := boiling point\\mathcal{L}(\\theta\\mid Y)=N(\\theta,0.25)\nSuppose your prior for \\theta is (conveniently) the conjugate normal. You know that at sea level, water should boil at 100^\\circ Celsius, so you set the prior mean at m_0 =100. f(\\theta)=N(100,s_0^2)\nIf you specify a prior variance s^2_0 for \\theta, which of the following accurately describes the model for your measurements Y_i\\qquad \\forall i\\in\\{1,…,n\\}?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nwe are told Y is IID with normal likelihood with \\mu=\\theta and \\sigma^2=0.25 so\n\nY_i \\mid\\theta \\stackrel{iid}\\sim N(\\theta,0.25) \\qquad (\\text{likelihood})\n\nwe are also told the prior is a conjugate normal with \\mu=100 and \\sigma^2=s^2_0\n\nf(\\theta) \\sim N(100,s^2_0) \\qquad (\\text{prior})\n\n\nY_i \\mid θ \\stackrel{iid}\\sim N(θ,0.25) ; \\theta ∼N(100,s_0^2)\n\n\n\n\n\nExercise 26.2 See Example 17.1 thermometer calibration problem\nYou decide you want the prior to be equivalent (in effective sample size) to one measurement.\nWhat value should you select for s^2_0 the prior variance of θ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nby Equation 25.4\n\n1 = \\frac{\\sigma_0^2}{s_0^2} =  \\frac{0.25 }{0.25 } \\therefore s_0^2=0.25\n\n\n\n\n\nExercise 26.3 See Example 17.1 thermometer calibration problem\nYou collect the following n=5 measurements: (94.6, 95.4, 96.2, 94.9, 95.9).\nWhat is the posterior distribution for \\theta?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nso the key point is to realize is that there prior mean is also a a point. n=5\n\\bar{y}=94.6\nPlugging all relevant quantities (including \\bar{y} =95.4) into the update formula in Lesson 10.1, the posterior mean is \\frac{2308}{24} and the posterior variance is \\frac{1}{24}\n\ns_0=0.25\n\n\n\\sigma_0=0.445\n\n\n\nCode\nlibrary(testit)\ny &lt;- c(94.6, 95.4, 96.2, 94.9, 95.9)\nsample_mean = mean(y)\nn=5.0\nassert('sample_mean',sample_mean==95.4)\nsample_var = sum( (y-sample_mean)^2)/(length(y)-1)\nsample_var= var(y)\npop_var=0.25\nprint(paste('sample_var=',sample_var))\n\n\n[1] \"sample_var= 0.445000000000003\"\n\n\nCode\nassert('sample_var',round(sample_var,1)==0.4)\n\nprior_var=0.25\nprior_mean=100.0\npost_mean= (n * sample_mean/pop_var + prior_mean/prior_var ) / ( n / pop_var + 1./prior_var)\nprint(paste('post_mean',round(post_mean,2),'expected result',round(2308/24,2),digits = 7))\n\n\n[1] \"post_mean 96.17 expected result 96.17 7\"\n\n\nCode\nassert('post_mu',round(post_mean,2) == round(2308/24,2))\npost_variance = round(1/(n/pop_var + 1/prior_var),3)\nprint(paste('post_variance',post_variance,'expected result',round(1/24,3),digits = 7))\n\n\n[1] \"post_variance 0.042 expected result 0.042 7\"\n\n\nCode\nassert('post_variance', post_variance == round(1/24,3))\nprint(paste('n(',post_mean,',',post_variance,')'))\n\n\n[1] \"n( 96.1666666666667 , 0.042 )\"\n\n\nresulting in N(96.17,0.0417)\n\n\n\n\nExercise 26.4 See Example 17.1 thermometer calibration problem\nUse R or Excel to find the upper end of a 95% equal-tailed credible interval for \\theta\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=96.17\nb=0.042\nqnorm(p=0.975, mean=a, sd=sqrt(b))\n\n\n[1] 96.57167\n\n\nThis is the 0.975 quantile of the posterior distribution.\n\n\n\n\nExercise 26.5 After collecting these data, is it reasonable to conclude that the thermometer is biased toward low values?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=96.17\nb=0.042\npnorm(q=100, mean=a, sd=sqrt(b))\n\n\n[1] 1\n\n\nYes, we have \\mathbb{P}r(\\theta &lt;100 \\mid y) &gt; 0.9999.\n\n\n\n\nExercise 26.6 What is the posterior predictive distribution of a single future observation Y^*\nThis is the posterior distribution for θ. Use the expression given at the end of Lesson 10.1, using the posterior parameters in place of m_0 and s_0^2\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nwe have\n\nlikelihood Y \\mid \\theta,\\sigma^2\\sim N(\\mu=\\theta,\\sigma^2=0.25)\nprior \\theta \\sim N(m_0=100,s^2_0=0.25)\nposterior N(96.17,0,0.42)\n\nwe need to ‘plug’ this into N(m_0,s_0^2)\nThis is the posterior distribution for θ. Use the expression given at the end of Lesson 10.1, using the posterior parameters in place of m0 and s02.\nN(96.17,0.042+0.25) N(96.17,0.292)\n\n\n\n\nExercise 26.7 Restaurants\nFor Questions 7-10, consider the following scenario:\nYour friend moves from City A to City B and is delighted to find her favorite restaurant chain at her new location. After several meals, however, she suspects that the restaurant in City B is less generous. She decides to investigate.\nShe orders the main dish on 30 randomly selected days throughout the year and records each meal’s weight in grams. You still live in city A, so you assist by performing the same experiment at your restaurant. Assume that the dishes are served on identical plates (measurements subtract the plate’s weight) and that your scale and your friend’s scale are consistent.\nThe following histogram shows the 30 measurements from Restaurant B taken by your friend\nIs it reasonable to assume that these data are normally distributed?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nNo, there appear to be a few extreme observations (outliers).\nThe three points above 700 are about five (sample) standard deviations above the (sample) mean.\n\n\n\n\nExercise 26.8 Restaurants\nYour friend investigates the three observations above 700 grams and discovers that she had ordered the incorrect meal on those dates. She removes these observations from the data set and proceeds with the analysis using n=27.\nShe assumes a normal likelihood for the data with unknown mean μ and unknown variance σ^2. She uses the model presented in Section 25.2 where, conditional on σ^2, the prior for \\mu is normal with mean m and variance \\sigma^2/w. Next, the marginal prior for \\sigma^2 is \\text{Inverse-Gamma}(a,b).\nYour friend’s prior guess on the mean dish weight is 500 grams, so we set m=500. She is not very confident with this guess, so we set the prior effective sample size w=0.1. Finally, she sets a=3 and b=200.\nWe can learn more about this inverse-gamma prior by simulating draws from it. If a random variable X follows a \\text{Gamma}(a,b) distribution, then 1/X follows an \\text{Inverse-Gamma}(a,b) distribution. Hence, we can simulate draws from a gamma distribution and take their reciprocals, which will be draws from an inverse-gamma.\nTo simulate 1000 draws in R (replace a and b with their actual values):\nSimulate a large number of draws (at least 300) from the prior for σ^2 and report your approximate prior mean from these draws. It does not need to be exact.\nwhere\n\na' = a + \\frac{n}{2} = 3 + \\frac{27}{2} = 16.5\n\n\nb' = b + \\frac{n-1}{2} s^2 + \\frac{wn}{2(w+n)}(\\bar{y}-m)^2 = 200 + \\frac{27-1}{2} 401.8 + \\frac{0.1\\cdot 27}{2(0.1+27)}(609.7-500)^2 = 6022.9\n\n\nm' = \\frac{n\\bar{y} + wm}{w + n} =  \\frac{27\\cdot 609.7 + 0.1\\cdot 500}{0.1 + 27} = 609.3\n\nw=0.1\nw+n=27.1\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n#liklihood N(mu,sigma_sq)=N(m,sigma_sq/w)\nm=500 # mean dish wight\nw=0.1 # effective sample size\n#with sigma_sq prior IG(a,b)\na=3\nb=200\nz &lt;- rgamma(n=1000, shape=a, rate=b) #prior for variance square\nx &lt;- 1/z\nmean(x)\n\n\n[1] 101.4303\n\n\n\nThe actual prior mean for \\sigma^2=b/a-1 = 200/2=100\nThe prior variance for \\sigma^2=b^2/((a-1)^2(a-2))=10000\n\n\n\n\n\nExercise 26.9 Restaurants\nWith the n=27 data points, your friend calculates the sample mean \\bar{y} = 609.7 and sample variance s^2 = 1\\frac{1}{n-1} \\sim (y_i-\\hat{y})^2 = 401.8\nUsing the update formulas from Lesson 10.2, she calculates the following posterior distributions:\n\n\\sigma \\mid y \\sim \\mathrm{Inverse-Gamma}(a',b')\n\n\ny \\mid \\sigma^2,y \\sim \\mathcal{N}(m', \\frac{\\sigma^2}{w+n})\n\nTo simulate draws from this posterior, begin by drawing values for \\sigma^2 from its posterior using the method from the preceding question. Then, plug these values for \\sigma^2 into the posterior for μ and draw from that normal distribution.\nTo simulate 1000 draws in R:\n\n\nCode\nz &lt;- rgamma(1000, shape=16.5, rate=6022.9)\nsig2 &lt;- 1/z\nmu &lt;- rnorm(1000, mean=609.3, sd=sqrt(sig2/27.1))\n\n\nWe can use these simulated draws to help us approximate inferences for μ and σ^2.\nFor example, we can obtain a 95% equal-tailed credible for μ by calculating the quantiles/percentiles of the simulated values.\n\n\nCode\nquantile(x=mu, probs=c(0.025, 0.975))\n\n\n    2.5%    97.5% \n602.1272 617.1896 \n\n\nPerform the posterior simulation described above and compute your approximate 95% equal-tailed credible interval for μ. Based on your simulation, which of the following appears to be the actual interval?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nI got this part wrong many times so I figured out how to add assertions to verify the numbers were what I expected. Since R was rounding off some numbers and not others.\n\n\nCode\n1library(testit)\n2n &lt;- 27.0\n3y_hat &lt;- 609.7\n4s_sq &lt;- 401.8\n5a &lt;- 3.0\n6b &lt;- 200.0\n7w &lt;- 0.1\n8a_tag&lt;- a + n / 2.\nassert(\"a_tag\", a_tag == 16.5)\n9m=500.0\nb_tag = round(b + (n-1)*s_sq *0.5 + (w*n)/2/(w + n)*(y_hat-m)^2,1)  \nprint( b_tag,digits = 7)\nassert(\"b_tag\", b_tag == 6022.9)\nm_tag = round(((n * y_hat) + (w*m)) / (w+n),1)\nprint(m_tag,digits = 7)\nassert(\"m_tag\",m_tag == 609.3)\n\n\n\n1\n\nsupport for assertions\n\n2\n\nn is n is the sample size after removing the outliers.\n\n3\n\ny_hat is \\bar{y}, the sample mean\n\n4\n\ns^2 or s_sq is the sample variance\n\n5\n\na is the initial a.\n\n6\n\nb is the initial b.\n\n7\n\nw is the confidence level used in the denominator of the prior variance.\n\n8\n\na_tag is a', the updated value of a. We are given a value of 16.5\n\n9\n\nm is the prior dish weight from Exercise 26.8\n\n\n\n\n[1] 6022.9\n[1] 609.3\n\n\n\n\nCode\nz &lt;- rgamma(1000, shape=16.5, rate=6022.9)\nsig2 &lt;- 1/z\nmu &lt;- rnorm(1000, mean=609.3, sd=sqrt(sig2/27.1))\nquantile(x=mu, probs=c(0.025, 0.975))\n\n\n    2.5%    97.5% \n601.5668 616.3313 \n\n\n(602,617)\nThis is the actual interval, calculated from the exact marginal posterior (t distribution) for \\mu\n\n\n\n\nExercise 26.10 Restaurants\nYou complete your experiment at Restaurant A with m=30 data points, which appear to be normally distributed. You calculate the sample mean \\hat{y} = 622.8 and sample variance s^2=\\frac{1}{n-1}\\sum{(y_i-\\bar{y})^2}=403.1\nRepeat the analysis from Question 9 using the same priors and draw samples from the posterior distribution of \\sigma^2_A and \\mu_A (where the A denotes that these parameters are for Restaurant A).\nTreating the data from Restaurant A as independent from Restaurant B, we can now attempt to answer your friend’s original question: is restaurant A more generous? To do so, we can compute posterior probabilities of hypotheses like \\mu_A&gt; \\mu_B. This is a simple task if we have simulated draws for \\mu_A and \\mu_B. For i=1,…,N (the number of simulations drawn for each parameter), make the comparison \\mu_A&gt; \\mu_B using the ith draw for \\mu_A and \\mu_B. Then count how many of these return a TRUE value and divide by N, the total number of simulations.\nIn R (using 1000 simulated values):\n\n\nCode\n# sum( muA &gt; muB ) / 1000\n\n\nWould you conclude that the main dish from restaurant A weighs more than the main dish from restaurant B on average?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nI first wanted to replicate the derivation of the numbers given as they seemed rather arbitrary. I thought I would need this in the simulation but then I understood that we need to use the same priors and all that changes in the simulation is the mean \\mu for each restaurant.\nThis R code for the actual simulation is as follows:\n\n\nCode\n1z &lt;- rgamma(1000, shape=18, rate=6796.4)\n2sig2 &lt;- 1/z\n3muA &lt;- rnorm(1000, mean=622.4, sd=sqrt(sig2/30.1))\nz &lt;- rgamma(1000, shape=16.5, rate=6022.9)\nsig2 &lt;- 1/z\n4muB &lt;- rnorm(1000, mean=609.3, sd=sqrt(sig2/27.1))\n5sum( muA &gt; muB ) / 1000\n\n\n\n1\n\nsample from \\sigma^2 from gamma prior\n\n2\n\ninvert since we need inverse-gamma\n\n3\n\nsample form \\mu_A\n\n4\n\nsample form \\mu_B\n\n5\n\nsum the comparison \\mu_A &gt; \\mu_B\n\n\n\n\n[1] 0.993\n\n\nYes, the posterior probability that \\mu_A &gt; \\mu_B is at least 0.95.\nThis is fairly strong evidence that the mean weight of the dish from Restaurant A is greater than the mean weight of the dish from Restaurant B.",
    "crumbs": [
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Homework Normal data</span>"
    ]
  },
  {
    "objectID": "C1-L11.html",
    "href": "C1-L11.html",
    "title": "27  M4L11 - Non-Informative Priors",
    "section": "",
    "text": "27.1 Non-Informative Priors\nWe’ve seen examples of choosing priors that contain a significant amount of information. We’ve also seen some examples of choosing priors where we’re attempting to not put too much information in to keep them vague.\nAnother approach is referred to as objective Bayesian statistics or inference where we explicitly try to minimize the amount of information that goes into the prior.\nThis is an attempt to have the data have maximum influence on the posterior\nLet’s go back to coin flipping\nY_i \\sim B(\\theta)\nHow do we minimize our prior information in \\theta? One obvious intuitive approach is to say that all values of \\theta are equally likely. So we could have a prior for \\theta which follows a uniform distribution on the interval [0, 1]\nSaying all values of \\theta are equally likely seems like it would have no information in it.\nRecall however, that a Uniform(0, 1) is the same as Beta(1, 1)\nThe effective sample size of a beta prior is the sum of its two parameters. So in this case, it has an effective sample size of 2. This is equivalent to data, with one head and one tail already in it.\nSo this is not a completely non-informative prior.\nWe could think about a prior that has less information. For example Beta(\\frac{1}{2}, \\frac{1}{2}), this would have half as much information with an effective sample size of one.\nWe can take this even further. Think about something like Beta(0.001, 0.001) This would have much less information, with the effective sample size fairly close to zero. In this case, the data would determine the posterior and there would be very little influence from the prior.",
    "crumbs": [
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>M4L11 - Non-Informative Priors</span>"
    ]
  },
  {
    "objectID": "C1-L11.html#sec-non-informative-priors",
    "href": "C1-L11.html#sec-non-informative-priors",
    "title": "27  M4L11 - Non-Informative Priors",
    "section": "",
    "text": "Figure 27.1: Non-Informative Priors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n27.1.1 Improper priors\nCan we go even further? We can think of the limiting case. Let’s think of Beta(0,0), what would that look like?\n\nf(\\theta) \\propto \\theta^{-1}(1-\\theta)^{-1}\n\nThis is not a proper density. If you integrate this over (0,1), you’ll get an infinite integral, so it’s not a true density in the sense of it not integrating to 1.\nThere’s no way to normalize it, since it has an infinite integral. This is what we refer to as an improper prior.\nIt’s improper in the sense that it doesn’t have a proper density. But it’s not necessarily improper in the sense that we can’t use it. If we collect data, we use this prior and as long as we observe one head and one tail, or at least one success and one failure. Then we can get a posterior\n\nf(\\theta\\mid y) \\propto \\theta^{y-1}(1-\\theta)^{n-y-1} \\sim Beta(y, n-y)\n\nWith a posterior mean of \\frac{y}{n} =\\hat{\\theta}, which you should recognize as the maximum likelihood estimate. So by using this improper prior, we get a posterior which gives us point estimates exactly the same as the frequentist approach.\nBut in this case, we can also think of having a full posterior. From this, we can make interval statements, and probability statements, and we can actually find an interval and say that there’s 95\\% probability that \\theta is in this interval. This is not something you can do under the frequentist approach even though we may get the same exact interval.\n\n\n27.1.2 Statements about improper priors\nImproper priors are okay as long as the posterior itself is proper. There may be some mathematical things that need to be checked and you may need to have certain restrictions on the data. In this case, we needed to make sure that we observed at least one head and one tail to get a proper posterior.\nBut as long as the posterior is proper, we can go forwards and do Bayesian inference even with an improper prior.\nThe second point is that for many problems there does exist a prior, typically an improper prior that will lead to the same point estimates as you would get under the frequentist paradigm. So we can get very similar results, results that are fully dependent on the data, under the Bayesian approach.\nBut in this case, we can also continue to have a posterior and make posterior interval estimates and talk about the posterior probabilities of the parameter.\n\n\n27.1.3 Normal Case\nAnother example is thinking about the normal case.\n\nY_i \\stackrel{iid}\\sim \\mathcal{N}(\\mu, \\sigma^2)\n\nLet’s start off by assuming that \\sigma^2 is known and we’ll just focus on the mean \\mu.\nWe can think about a vague prior like before and say that\n\n\\mu \\sim N(0, 1000000^2)\n\nThis would just spread things out across the real line. That would be a fairly non-informative prior covering a lot of possibilities. We can then think about taking the limit, what happens if we let the variance go to \\infty. In that case, we’re spreading out this distribution across the entire real number line. We can say that the density is just a constant across the whole real line.\n\nf(\\mu) \\propto 1\n\nThis is an improper prior because if you integrate the real line you get an infinite answer. However, if we go ahead and find the posterior\n\nf(\\mu \\mid y) \\propto f(y \\mid \\mu) f(\\mu) \\propto \\exp \\left (-\\frac{1}{2\\sigma^2}\\sum{(y_i - \\mu)^2} \\right ) (1)\n\n\nf(\\mu \\mid y) \\propto exp(-\\frac{1}{2\\sigma^2/n}(\\mu - \\bar{y})^2)\n\n\n\\mu \\mid y \\sim N(\\bar{y}, \\frac{\\sigma^2}{n})\n\nThis should look just like the maximum likelihood estimate.\n\n\n27.1.4 Normal with unknown Variance\nIn the case that \\sigma^2 is unknown, the standard non-informative prior is\n\nf(\\sigma^2) \\propto \\frac{1}{\\sigma^2}\n\n\n\\sigma^2 \\sim \\Gamma^{-1}(0,0)\n\nThis is an improper prior and it’s uniform on the log scale of \\sigma^2.\nIn this case, we’ll end up with a posterior for \\sigma^2\n\n\\sigma^2 \\mid y \\sim \\Gamma^{-1}\\left (\\frac{n-1}{2}, \\frac{1}{2}\\sum{(y_i - \\bar{y})^2}\\right)\n\nThis should also look reminiscent of the quantities we get as a frequentist. For example, the samples standard deviation",
    "crumbs": [
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>M4L11 - Non-Informative Priors</span>"
    ]
  },
  {
    "objectID": "C1-L11.html#sec-jeffreys-prior",
    "href": "C1-L11.html#sec-jeffreys-prior",
    "title": "27  M4L11 - Non-Informative Priors",
    "section": "27.2 Jeffrey’s Prior",
    "text": "27.2 Jeffrey’s Prior\n\n\n\n\n\n\n\nFigure 27.2: Jeffrey’s Prior\n\n\nChoosing a uniform prior depends upon the particular parameterization.\nSuppose I used a prior which is uniform on the log scale for \\sigma^2\n\nf(\\sigma^2) \\propto \\frac{1}{\\sigma^2}\n\nSuppose somebody else decides, that they just want to put a uniform prior on \\sigma^2 itself.\n\nf(\\sigma^2) \\propto 1\n\nThese are both uniform on certain scales or certain parameterizations, but they are different priors. So when we compute the posteriors, they will be different as well.\nThe key thing is that uniform priors are not invariant with respect to transformation. Depending on how you parameterize the problem, you can get different answers by using a uniform prior\nOne attempt to round this out is to use Jeffrey’s Prior\nJeffrey’s Prior is defined as the following\n\nf(\\theta) \\propto \\sqrt{\\mathcal{I(\\theta)}}\n\nWhere \\mathcal{I}(\\theta) is the fisher information of \\theta.\nIn most cases, this will be an improper prior.\n\n\n\n\nHarold Jeffreys\n\n\n\n\n\n\n\nTipHistorical Note on Sir Harold Jeffreys\n\n\n\nJeffreys’ Prior is due to Sir Harold Jeffreys (1891-1989) a British geophysicist who who used sophisticated mathematical models to study the Earth and solar system. His hypotheses were uncertain, requiring revision in the face of incoming results, Jeffreys tried to construct a formal theory of scientific reasoning based on Bayesian probability. He made significant contributions to mathematics and statistics. His book, Theory of Probability (Jeffreys 1983), first published in 1939, played an important role in the revival of the objective Bayesian view of probability.\nInductive and Reductive Inference\n“The fundamental problem of scientific progress, and a fundamental one of everyday life, is that of learning from experience. Knowledge obtained in this way is partly merely description of what we have already observed, but part consists of making inferences from past experience to predict future experience. This part may be called generalization or induction.”\nJEFFREYS’ RULES FOR A THEORY OF INDUCTIVE INFERENCE\n\nAll hypotheses used must be explicitly stated and the conclusions must follow from the hypotheses.\nA theory of induction must be self-consistent; that is, it must not be possible to derive contradictory conclusions from the postulates and any given set of observational data.\nAny rule given must be applicable in practice. A definition is useless unless the thing defined can be recognized in terms of the definition when it occurs. The existence of a thing or the estimate of a quantity must not involve an impossible experiment.\nA theory of induction must provide explicitly for the possibility that inferences made by it may turn out to be wrong.\nA theory of induction must not deny any empirical proposition a priori; any precisely stated empirical proposition must be formally capable of being accepted in the sense of the last rule, given a moderate amount of relevant evidence.\nThe number of postulates should be reduced to a minimum. (Occam’s Razor)\nAlthough we do not regard the human mind as a perfect reasoner, we must accept it as a useful one and the only one available. The theory need not represent actual thought processes in detail but should agree with them in outline.\nIn view of the greater complexity of induction, we cannot hope to develop it more thoroughly than deduction. We therefore take it as a rule that an objection carries no weight if an analogous objection invalidates part of generally accepted pure mathematics.\n\n\n\n\n27.2.1 Normal Data\nFor the example of Normal Data\n\nY_i \\sim N(\\mu, \\sigma^2)\n\n\nf(\\mu) \\propto 1\n\n\nf(\\sigma^2) \\propto \\frac{1}{\\sigma^2}\n\nWhere \\mu is uniform and \\sigma^2 is uniform on the log scale.\nThis prior will then be transformation invariant. We will end up putting the same information into the prior even if we use a different parameterization for the Normal.\n\n\n27.2.2 Binomial\n\nY_i \\sim B(\\theta)\n\n\nf(\\theta) \\propto \\theta^{-\\frac{1}{2}}(1-\\theta)^{-\\frac{1}{2}} \\sim \\mathrm{Beta}(\\frac{1}{2},\\frac{1}{2})\n\nThis is a rare example of where the Jeffrey’s prior turns out to be a proper prior.\nYou’ll note that this prior actually does have some information in it. It’s equivalent to an effective sample size of one data point. However, this information will be the same, not depending on the parameterization we use.\nIn this case, we have \\theta as a probability, but another alternative which is sometimes used is when we model things on a logistics scale.\nBy using the Jeffreys prior, we’ll maintain the exact same information.\n\n\n27.2.3 Closing information about priors\nOther possible approaches to objective Bayesian inference include priors such as reference priors and maximum entropy priors.\nA related concept to this is called empirical Bayesian analysis. The idea in empirical Bayes is that you use the data to help inform your prior; such as by using the mean of the data to set the mean of the prior distribution. This approach often leads to reasonable point estimates in your posterior. However, it’s sort of cheating since you’re using your data twice and as a result may lead to improper uncertainty estimates.",
    "crumbs": [
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>M4L11 - Non-Informative Priors</span>"
    ]
  },
  {
    "objectID": "C1-L11.html#sec-fisher-information",
    "href": "C1-L11.html#sec-fisher-information",
    "title": "27  M4L11 - Non-Informative Priors",
    "section": "27.3 Fisher Information",
    "text": "27.3 Fisher Information\nThe Fisher information (for one parameter) is defined as\n\n\\mathcal{I}(\\theta) = E\\left[\\left(\\frac{d}{d\\theta}log{(f(X \\mid \\theta))}\\right)^2\\right]\n\nWhere the expectation is taken with respect to X which has PDF f(X \\mid \\theta). This quantity is useful in obtaining estimators for \\theta with good properties, such as low variance. It is also the basis for Jeffrey’s prior.\n\n\n\n\n\n\nTipJeffreys prior violates the likelihood principle.\n\n\n\nUse of the Jeffreys prior violates the strong version of the likelihood principle. Which proposes that, given a statistical model, all the evidence in a sample relevant to model parameters is contained in the likelihood function. When using the Jeffreys prior, inferences about \\theta depend not just on the probability of the observed data as a function of \\theta, but also on the universe of all possible experimental outcomes, as determined by the experimental design, because the Fisher information is computed from an expectation over the chosen universe. Accordingly, the Jeffreys prior, and hence the inferences made using it, may be different for two experiments involving the same \\theta parameter even when the likelihood functions for the two experiments are the same a violation of the strong likelihood principle.\n\n\n\nExample 27.1 (Jeffreys prior) Let\n\nX \\mid \\theta \\sim N(\\theta, 1)\n\nThen we have\n\nf(x \\mid \\theta) = \\frac{1}{\\sqrt{2\\pi}}\\exp[-\\frac{1}{2}(x-\\theta)^2]\n\n\n\\log{(f(x \\mid \\theta))} = -\\frac{1}{2}\\log{(2\\pi)}-\\frac{1}{2}(x-\\theta)^2\n\n\n\\left ( \\frac{d}{d\\theta}log{(f(x \\mid \\theta))} \\right )^2 = (x-\\theta)^2\n\nand so\n\n\\mathcal{I}(\\theta) = \\mathbb{E}[(X - \\theta)^2] = \\mathbb{V}ar[X] = 1",
    "crumbs": [
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>M4L11 - Non-Informative Priors</span>"
    ]
  },
  {
    "objectID": "C1-L11.html#sensitivity-analysis-of-priors",
    "href": "C1-L11.html#sensitivity-analysis-of-priors",
    "title": "27  M4L11 - Non-Informative Priors",
    "section": "27.4 Sensitivity analysis of priors",
    "text": "27.4 Sensitivity analysis of priors\nThe general approach to using priors in models is to start with some justification for a prior, run the analysis, then come up with competing priors and reexamine the conclusions under the alternative priors. The results of the final model and the analysis of the sensitivity of the analysis to the choice of prior are written up as a package.\nFor a discussion of steps and methods to use in a sensitivity analysis, see: (Gelman et al. 2013, page: 38) which discusses two approaches:\nMany times we choose priors out of convenience. How to judge when assumptions of convenience can be made safely is a central task of Bayesian sensitivity analysis.\n\nAnalysis using different conjugate prior distributions.\n\n\nStarting with a uniform prior\nMore informative priors are tested and the 95% posterior CI is compared against the posterior mean and the prior mean.\nA table of prior mean, prior effective sample size , posterior mean and posterior 95 CI is created for the results\nWe are interested primarily to see how well the the posterior CI can excludes the prior mean even for priors with large effective sample size.\n\n\nAnalysis using a non-conjugate prior distribution follows the same approach but uses non conjugate prior. The comparisons described in 1. can be carried out using sampling.\n\n(Gelman et al. 2013, pages: 141)\n\n\n\n\n\n\nGelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. Bayesian Data Analysis, Third Edition. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis. https://books.google.co.il/books?id=ZXL6AQAAQBAJ.\n\n\nJeffreys, H. 1983. Theory of Probability. International Series of Monographs on Physics. Clarendon Press.",
    "crumbs": [
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>M4L11 - Non-Informative Priors</span>"
    ]
  },
  {
    "objectID": "C1-L11-Ex1.html",
    "href": "C1-L11-Ex1.html",
    "title": "28  Homework Alternative Priors",
    "section": "",
    "text": "Exercise 28.1 Suppose we flip a coin five times to estimate \\theta, the probability of obtaining heads. We use a Bernoulli likelihood for the data and a non-informative (and improper) Beta(0,0) prior for \\theta. We observe the following sequence: (H, H, H, T, H).\nBecause we observed at least one H and at least one T, the posterior is proper. What is the posterior distribution for \\theta\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nBeta(4,1)\nWe observed four “successes” and one “failure,” and these counts are the parameters of the posterior beta distribution.\n\n\n\n\nExercise 28.2 Continuing the previous question, what is the posterior mean for θ? Round your answer to one decimal place.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n${y} = 0.8 $\n\n\n\n\nExercise 28.3 Consider again the thermometer calibration problem from Lesson 10.\nAssume a normal likelihood with unknown mean θ and known variance \\sigma^2=0.25. Now use the non-informative (and improper) flat prior for \\theta across all real numbers. This is equivalent to a conjugate normal prior with variance equal to \\infty.\nYou collect the following n=5 measurements: (94.6, 95.4, 96.2, 94.9, 95.9). What is the posterior distribution for \\theta?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nRecall from the lesson that with a flat prior on θ, the posterior distribution is\n\n\\mathcal{N}(\\bar{y},\\frac{sigma^2}{n})=N(95.4,0.05)\n\n\n\n\n\nExercise 28.4 Which of the following graphs shows the Jeffreys prior for a Bernoulli/binomial success probability p?\nHint: The Jeffreys prior in this case is Beta(1/2, 1/2).\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nBeta(1/2, 1/2).\n\n\n\n\nExercise 28.5 Scientist A studies the probability of a certain outcome of an experiment and calls it θ. To be non-informative, he assumes a Uniform(0,1) prior for θ.\nScientist B studies the same outcome of the same experiment using the same data, but wishes to model the odds ϕ= \\frac{θ}{1−θ}. Scientist B places a uniform distribution on ϕ. If she reports her inferences in terms of the probability \\theta, will they be equivalent to the inferences made by Scientist A?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nNo, they did not use the Jeffreys prior.\nThe uniform prior on \\theta implies the following prior PDF for\n\nf(\\phi)= \\frac{1}{(1+\\phi)^2} I_{\\{\\phi≥0\\}}\n\n​which is not the uniform prior used by Scientist B.\nThey would obtain equivalent inferences if they both use the Jeffrey’s prior.",
    "crumbs": [
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Homework Alternative Priors</span>"
    ]
  },
  {
    "objectID": "C1-L12.html",
    "href": "C1-L12.html",
    "title": "29  M4L12 - Brief Review of Regression",
    "section": "",
    "text": "29.1 Conjugate Modeling\nRecall that linear regression is a model for predicting a response or dependent variable (Y, also called an output) from one or more covariates or independent variables (X, also called explanatory variables, inputs, or features). For a given value of a single x, the expected value of y is\n\\mathbb{E}[y] = \\beta_0 + \\beta_1x\nor we could say that\nY \\sim \\mathcal{N}(\\beta_0 + \\beta_1x, \\sigma^2)\nFor data (x_1, y_1), \\dots , (x_n, y_n), the fitted values for the coefficients, \\hat{\\beta_0} and \\hat{\\beta_1} are those that minimize the sum of squared errors \\sum_{i = 1}^n{(y_i - \\hat{y_i})^2}, where the predicted values for the response are \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x. We can get these values from R. These fitted coefficients give the least-squares line for the data.\nThis model extends to multiple covariates, with one \\beta_j for each k covariates\n\\mathbb{E}[y_i] = \\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_kx_{ik}\nOptionally, we can represent the multivariate case using vector-matrix notation.\nIn the Bayesian framework, we treat the \\beta parameters as unknown, put a prior on them, and then find the posterior. We might treat \\sigma^2 as fixed and known, or we might treat it as an unknown and also put a prior on it. Because the underlying assumption of a regression model is that the errors are independent and identically normally distributed with mean 0 and variance \\sigma^2, this defines a normal likelihood.",
    "crumbs": [
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>M4L12 - Brief Review of Regression</span>"
    ]
  },
  {
    "objectID": "C1-L12.html#conjugate-modeling",
    "href": "C1-L12.html#conjugate-modeling",
    "title": "29  M4L12 - Brief Review of Regression",
    "section": "",
    "text": "29.1.1 \\sigma^2 known\nSometimes we may know the value of the error variance \\sigma^2 . This simplifies calculations. The conjugate prior for the \\beta is a normal prior. In practice, people typically use a non-informative prior, i.e., the limit as the variance of the normal prior goes to infinity, which has the same mean as the standard least-squares estimates. If we are only estimating \\beta and treating \\sigma^2 as known, then the posterior for \\beta is a (multivariate) normal distribution. If we just have a single covariate, then the posterior for the slope is:\n\n\\beta_1 \\mid y \\sim N\\left(\\frac{\\sum_{i = 1}^n{(x_i-\\bar{x})(y_i - \\bar{y})}}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}, \\frac{\\sigma^2}{\\sum_{i=1}^n{(x_i - \\bar{x})^2}}\\right)\n\nIf we have multiple covariates, then using a matrix-vector notation, the posterior for the vector of coefficients is \n\\beta \\mid y \\sim N((X^tX)^{-1}X^ty, (X^tX)^{-1}\\sigma^2)\n\nwhere X denotes the design matrix and X^t is the transpose of X. The intercept is typically included in X as a column of 1’s. Using an improper prior requires us to have at least as many data points as we have parameters to ensure that the posterior is proper.\n\n\n29.1.2 \\sigma^2 Unknown\nIf we treat both \\beta and \\sigma^2 as unknown, the standard prior is the non-informative Jeffreys prior, f(\\beta, \\sigma^2) \\propto \\frac{1}{\\sigma^2} . Again, the posterior mean for \\beta will be the same as the standard least-squares estimates. The posterior for \\beta conditional on \\sigma^2 is the same normal distributions as when \\sigma^2 is known, but the marginal posterior distribution for \\beta, with \\sigma^2 integrated out is a t distribution, analogous to the t tests for significance in standard linear regression. The posterior t distribution has mean (X^tX)^{-1}X^ty and scale matrix (related to the variance matrix) s^2(X^tX)^{-1} , where s^2 = \\sum_{i = 1}^n{(y_i - \\hat{y_i})^2/(n - k - 1)} . The posterior distribution for \\sigma^2 is an inverse gamma distribution\n\n\\sigma^2 | y \\sim \\Gamma^{-1}(\\frac{n - k - 1}{2}, \\frac{n - k - 1}{2}s^2)\n\nIn the simple linear regression case (single variable), the marginal posterior for \\beta is a t distribution with mean \\frac{\\sum_{i = 1}^n{(x_i-\\bar{x})(y_i - \\bar{y})}}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}} and scale \\frac{s^2}{\\sum_{i=1}^n{(x_i - \\bar{x})^2}} . If we are trying to predict a new observation at a specified input x^* , that predicted value has a marginal posterior predictive distribution that is a t distribution, with mean \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x^* and scale se_r\\sqrt{1 + \\frac{1}{n} + \\frac{(x^* - \\bar{x})^2}{(n - 1)s_x^2}} . se_r is the residual standard error of the regression, which can be found easily in R. s_x^2 is the sample variance of x. Recall that the predictive distribution for a new observation has more variability than the posterior distribution for \\hat{y}, because individual observations are more variable than the mean.",
    "crumbs": [
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>M4L12 - Brief Review of Regression</span>"
    ]
  },
  {
    "objectID": "C1-L12.html#linear-regression",
    "href": "C1-L12.html#linear-regression",
    "title": "29  M4L12 - Brief Review of Regression",
    "section": "29.2 Linear Regression",
    "text": "29.2 Linear Regression\n\n29.2.1 Single Variable Regression\nWe’ll be looking at the Challenger dataset. It contains 23 past launches where it has the temperature at the day of launch and the O-ring damage index\nChallenger dataset\nRead in the data https://pdixon.stat.iastate.edu/stat511/datasets/challenger2.txt\n\n\nCode\noring=read.table(\"data/challanger.txt\", header=T)\n# Note that attaching this masks T which is originally TRUE\nattach(oring)\n\n\n\n\nCode\nhead(oring)\n\n\n   t  i\n1 53 11\n2 57  4\n3 58  4\n4 63  2\n5 66  0\n6 67  0\n\n\nNow we’ll see the plot\n\n\nCode\nplot(t,i)\n\n\n\n\n\n\n\n\n\nFit a linear model\n\n\nCode\noring.lm = lm(i ~ t)\nsummary(oring.lm)\n\n\n\nCall:\nlm(formula = i ~ t)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3025 -1.4507 -0.4928  0.7397  5.5337 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 18.36508    4.43859   4.138 0.000468 ***\nt           -0.24337    0.06349  -3.833 0.000968 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.102 on 21 degrees of freedom\nMultiple R-squared:  0.4116,    Adjusted R-squared:  0.3836 \nF-statistic: 14.69 on 1 and 21 DF,  p-value: 0.0009677\n\n\nAdd the fitted line into the scatter plot\n\n\nCode\nplot(t,i)\nlines(t,fitted(oring.lm))     \n\n\n\n\n\n\n\n\n\nCreate a 95% posterior interval for the slope\n\n\nCode\n-0.24337 - 0.06349*qt(.975,21)\n\n\n[1] -0.3754047\n\n\n\n\nCode\n-0.24337 + 0.06349*qt(.975,21)\n\n\n[1] -0.1113353\n\n\nNote: These are the same as the frequentist confidence intervals\nIf the challenger launch was at 31 degrees Fahrenheit, how much O-Ring damage would we predict?\n\n\nCode\ncoef(oring.lm)[1] + coef(oring.lm)[2]*31  \n\n\n(Intercept) \n   10.82052 \n\n\nCode\n# [1] 10.82052 \n\n\nLet’s make our posterior prediction interval\n\n\nCode\npredict(oring.lm,data.frame(t=31),interval=\"predict\")\n\n\n       fit      lwr      upr\n1 10.82052 4.048269 17.59276\n\n\nWe can calculate the lower bound through the following formula\n\n\nCode\n10.82052-2.102*qt(.975,21)*sqrt(1+1/23+((31-mean(T))^2/22/var(t)))\n\n\n[1] 4.850937\n\n\nWhat’s the posterior probability that the damage index is greater than zero?\n\n\nCode\n1-pt((0-10.82052)/(2.102*sqrt(1+1/23+((31-mean(T))^2/22/var(T)))),21)\n\n\n[1] NA\n\n\n\n\n29.2.2 Multivariate Regression\nWe’re looking at Galton’s seminal data predicting the height of children from the height of the parents.\n\n\n  Family Father Mother Gender Height Kids\n1      1   78.5   67.0      M   73.2    4\n2      1   78.5   67.0      F   69.2    4\n3      1   78.5   67.0      F   69.0    4\n4      1   78.5   67.0      F   69.0    4\n5      2   75.5   66.5      M   73.5    4\n6      2   75.5   66.5      M   72.5    4\n7      2   75.5   66.5      F   65.5    4\n8      2   75.5   66.5      F   65.5    4\n\n\nWhat are the columns in the dataset?\n\n\nCode\nnames(heights)\n\n\n[1] \"Family\" \"Father\" \"Mother\" \"Gender\" \"Height\" \"Kids\"  \n\n\nCode\n# [1] \"Family\" \"Father\" \"Mother\" \"Gender\" \"Height\" \"Kids\"  \n\n\nexplanation of the columns:\n\nFamily: the family the child is from\nFather: height of the father\nMother: height of the mother\nKids: count of children in the family\nGender: the gender of the child\nHeight: the height the child\n\nThe Height is out target variables.\nLet’s look at the relationship between the different variables\n\n\nCode\npairs(heights)\n\n\n\n\n\n\n\n\n\nPair plots are a great tool for doing EDA in R. You need to get used read them.\nWe care primarily about the Height so we can should first consider the row of the height. The other rows can inform us if there is a relation between other variables.\n\nthe Father and Mother are correlated with height.\nGender male children are generally taller.\nKids and Family don’t seem to have a clear pattern.\n\nFirst let’s start by creating a linear model taking all of the columns into account\n\n\nCode\nsummary(lm(Height~Father+Mother+Gender+Kids))\n\n\n\nCall:\nlm(formula = Height ~ Father + Mother + Gender + Kids)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.4748 -1.4500  0.0889  1.4716  9.1656 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.18771    2.79387   5.794 9.52e-09 ***\nFather       0.39831    0.02957  13.472  &lt; 2e-16 ***\nMother       0.32096    0.03126  10.269  &lt; 2e-16 ***\nGenderM      5.20995    0.14422  36.125  &lt; 2e-16 ***\nKids        -0.04382    0.02718  -1.612    0.107    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.152 on 893 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6391 \nF-statistic: 398.1 on 4 and 893 DF,  p-value: &lt; 2.2e-16\n\n\nAs you can see here, the Kids column is not statistically significant. Let’s look at a model with it removed.\n\n\nCode\nheights.lm=lm(Height~Father+Mother+Gender)\nsummary(heights.lm)\n\n\n\nCall:\nlm(formula = Height ~ Father + Mother + Gender)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.523 -1.440  0.117  1.473  9.114 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 15.34476    2.74696   5.586 3.08e-08 ***\nFather       0.40598    0.02921  13.900  &lt; 2e-16 ***\nMother       0.32150    0.03128  10.277  &lt; 2e-16 ***\nGenderM      5.22595    0.14401  36.289  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.154 on 894 degrees of freedom\nMultiple R-squared:  0.6397,    Adjusted R-squared:  0.6385 \nF-statistic:   529 on 3 and 894 DF,  p-value: &lt; 2.2e-16\n\n\nThis model looks good. We can tell from the summary that:\n\neach extra inch of the father’s height contributes an extra 0.4 inches height of the child.\neach extra inch of the mother’s height contributes an extra 0.3 inches height of the child.\nmale gender contributes 5.2 inches to the height of the child.\n\nLet’s create a 95% posterior interval for the difference in height by gender\n\n\nCode\n5.226 - 0.144 * qt(.975,894)\n\n\n[1] 4.943383\n\n\n\n\nCode\n5.226 + 0.144 * qt(.975,894)\n\n\n[1] 5.508617\n\n\nLet’s make a posterior prediction interval for a male and female with a father whose 68 inches and a mother whose 64 inches.\n\n\nCode\npredict(heights.lm,data.frame(Father=68,Mother=64,Gender=\"M\"), interval=\"predict\")\n\n\n       fit      lwr     upr\n1 68.75291 64.51971 72.9861\n\n\n\n\nCode\npredict(heights.lm,data.frame(Father=68,Mother=64,Gender=\"F\"), interval=\"predict\")\n\n\n       fit      lwr      upr\n1 63.52695 59.29329 67.76062",
    "crumbs": [
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>M4L12 - Brief Review of Regression</span>"
    ]
  },
  {
    "objectID": "C1-L12-Ex1.html",
    "href": "C1-L12-Ex1.html",
    "title": "30  —",
    "section": "",
    "text": "30.1 Homework On Regression\nFor Exercise 30.1–Exercise 30.6 consider the following:\nThe data found at pgalpga2008.dat consist of season statistics for individual golfers on the United States LPGA and PGA tours. The first column reports each player’s average driving distance in yards. The second column reports the percentage of the player’s drives that finish in the fairway, measuring their accuracy. The third and final column has a 1 to denote a female golfer (on the LPGA tour), and a 2 to denote a male golfer (on the PGA tour).\nLoad these data into R or Excel. In Excel, once you paste the data into a new worksheet, you may need to separate the data into columns using the “Text to Columns” feature under the “Data” menu.\nIf you wish to separate the LPGA and PGA data, one way in R is to use the subset function:\nwhere “dat” is the name of the original data set (replace “dat” with whatever you named this data set), “FM” is the name of the third column (replace “FM” with whatever you named this column), and select=1:2 means to include columns 1 and 2 in the new data set “datF”.\nCode\ndat=read.table(\"data/pgalpga2008.dat.txt\", header=T)\n# Note that attaching this masks T which is originally TRUE\nattach(dat)\ncolnames(dat) &lt;- c('distance','accuracy','gender')\nsummary(dat)\n\n\n    distance        accuracy         gender     \n Min.   :224.8   Min.   :49.00   Min.   :1.000  \n 1st Qu.:247.9   1st Qu.:61.10   1st Qu.:1.000  \n Median :276.7   Median :65.60   Median :2.000  \n Mean   :269.6   Mean   :65.23   Mean   :1.558  \n 3rd Qu.:287.7   3rd Qu.:69.50   3rd Qu.:2.000  \n Max.   :315.1   Max.   :80.40   Max.   :2.000  \n\n\nCode\ndatM &lt;- subset(dat, gender==2, select=1:2)\ndatF &lt;- subset(dat, gender==1, select=1:2)\n\nhead(datM)\n\n\n    distance accuracy\n157    290.3     59.5\n158    302.1     54.7\n159    287.1     62.4\n160    282.7     65.4\n161    299.1     52.8\n162    300.2     51.1\n\n\nCode\nsummary(datM)\n\n\n    distance        accuracy    \n Min.   :261.4   Min.   :49.00  \n 1st Qu.:282.0   1st Qu.:59.50  \n Median :287.0   Median :63.10  \n Mean   :287.6   Mean   :63.36  \n 3rd Qu.:293.3   3rd Qu.:66.90  \n Max.   :315.1   Max.   :80.40  \n\n\nCode\nhead(datF)\n\n\n  distance accuracy\n1    254.5     70.1\n2    253.1     59.3\n3    228.1     70.4\n4    240.8     69.5\n5    244.0     69.0\n6    257.9     66.3\n\n\nCode\nsummary(datF)\n\n\n    distance        accuracy    \n Min.   :224.8   Min.   :49.30  \n 1st Qu.:240.8   1st Qu.:64.45  \n Median :246.3   Median :68.35  \n Mean   :246.8   Mean   :67.59  \n 3rd Qu.:253.1   3rd Qu.:71.33  \n Max.   :269.5   Max.   :79.80",
    "crumbs": [
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>---</span>"
    ]
  },
  {
    "objectID": "C1-L12-Ex1.html#homework-on-regression",
    "href": "C1-L12-Ex1.html#homework-on-regression",
    "title": "30  —",
    "section": "",
    "text": "Exercise 30.1  Create two scatter plots with average drive distance on the x-axis and percent accuracy on the y-axis, one for female golfers and one for male golfers. What do you observe about the relationship between these two variables?Golf\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nplot(datM$distance, datM$accuracy, main=\"Scatterplot\", xlab=\"distance (yards)\", ylab=\"accuracy(pct)\", pch=19)\nabline(lm(datM$accuracy~datM$distance), col=\"red\") # regression line (y~x)\nlines(lowess(datM$accuracy,datM$distance), col=\"blue\") # lowess line (x,y)\n\n\n\n\n\n\n\n\n\nCode\nplot(datF$distance, datF$accuracy, main=\"Scatterplot\", xlab=\"distance (yards)\", ylab=\"accuracy(pct)\", pch=19)\nabline(lm(datF$accuracy~datF$distance), col=\"red\") # regression line (y~x)\nlines(lowess(datF$accuracy,datF$distance), col=\"blue\") # lowess line (x,y)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 30.2 Golf\nFit a linear regression model to the female golfer data only with drive distance as the explanatory variable x and accuracy as the response variable y. Use the standard reference (non-informative) prior.\nRecall that in a linear regression, we are modeling E(y)=b_0+b_1x\nIn this particular model, the intercept term is not interpretable, as we would not expect to see a 0-yard drive (but it is still necessary). Predictions should generally be made only within the range of the observed data.\nReport the posterior mean estimate of the slope parameter b relating drive distance to accuracy.\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nmod1 &lt;- lm(accuracy ~ distance, data=datF)\nsummary(mod1)\n\n\n\nCall:\nlm(formula = accuracy ~ distance, data = datF)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.6956  -2.6812   0.9755   3.6835  10.2227 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 130.9995    10.9663  11.946  &lt; 2e-16 ***\ndistance     -0.2569     0.0444  -5.786  3.9e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.262 on 154 degrees of freedom\nMultiple R-squared:  0.1786,    Adjusted R-squared:  0.1732 \nF-statistic: 33.48 on 1 and 154 DF,  p-value: 3.903e-08\n\n\n\n\n\n\n\nExercise 30.3 Golf\nThe posterior mean estimate of the slope from Exercise 30.2 is about five standard errors below 0. Hence, the posterior probability that this slope is negative is near 1.\nSuppose the estimate is b. How do we interpret this value?\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIf x is the driving distance, we expect the percentage accuracy to be 100bx.\nIf x is the driving distance, we expect the percentage accuracy to be bx.\nFor each additional yard of driving distance, we expect to see a decrease in percentage accuracy of ∣b∣.\nFor each additional yard of driving distance, we expect to see an increase in percentage accuracy of ∣b∣.\n\n\n\n\n\n\nExercise 30.4 Golf\nUse the posterior mean estimates of the model coefficients to obtain a posterior predictive mean estimate of driving accuracy for a new female golfer whose average driving distance is x=260 yards. Round your answer to one decimal place.\n\n\nCode\npredict.lm(mod1,data.frame(distance=260))\n\n\n       1 \n64.21029 \n\n\n\n\nExercise 30.5 Golf\nWhich of the following gives a 95% posterior predictive interval for the driving accuracy of a new female golfer whose average driving distance is x=260 yards?\nHint: Modify the code provided with this lesson under “prediction interval.”\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n#64.21029  -  0.03631 * qt(.975,195-2)\n#64.21029  +  0.03631 * qt(.975,195-2)\n#predict.lm(mod1,data.frame(distance=260),interval=\"confidence\", level=0.95)\npredict.lm(mod1,data.frame(distance=260),interval=\"prediction\", level=0.95)\n\n\n       fit      lwr     upr\n1 64.21029 53.71819 74.7024\n\n\n(53.7, 74.7)\nThis is\n\n\\hat{y}^* \\pm t_{n-2}^{-1}(0.975) \\cdot se_r \\cdot \\sqrt{1 + \\frac{1}{n} + \\frac{(260-\\bar{x})^2}{(n-1)s_x^2}}\n\nwhere:\n\n\\hat{y}^* is the prediction mean found in Exercise 30.4,\nt_{n-2}^{-1}(0.975) is the 0.975 quantile of a standard t distribution with n−2 degrees of freedom,\nn is the number of data points,\nse_r is the residual standard error (estimate of \\sigma)\n\\bar{x} is the sample mean of driving distance, and\n\ns_x^2 is the sample variance of driving distance.\n\n\n\n\n\n\nExercise 30.6 Golf\nWhat is the interpretation of the interval found in Exercise 30.5?\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIf we select a new female golfer who averages 260 yards per drive, we are 95% confident that the posterior mean for her accuracy would be in the interval.\nFor all female golfers who average 260 yards per drive, our probability is .95 that the mean of their driving accuracy is in the interval.\nIf we select a new female golfer who averages 260 yards per drive, our probability that her driving accuracy will be in the interval is .95.\nFor all female golfers who average 260 yards per drive, we are 95% confident that all their driving accuracies will be in the interval.\n\nWhy is this the correct answer:\n\nA Predictive interval does not predict a posterior mean.\nIt predicts a new observation.",
    "crumbs": [
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>---</span>"
    ]
  },
  {
    "objectID": "C1-L12-Ex2.html",
    "href": "C1-L12-Ex2.html",
    "title": "31  Honors Homework On Regression",
    "section": "",
    "text": "Exercise 31.1 Golf\nThe data are found at pgalpga2008.dat and consist of season statistics for individual golfers on the United States LPGA and PGA tours. The first column reports each player’s average driving distance in yards. The second column reports the percentage of the player’s drives that finish in the fairway, measuring their accuracy. The third and final column has a 1 to denote a female golfer (on the LPGA tour), and a 2 to denote male golfer (on the PGA tour).\nNow consider a multiple regression on the full data set, including both female and male golfers. Modify the third variable to be a 0 if the golfer is female and 1 if the golfer is male and fit the following regression:\n\n\\mathbb{E}[y] = b_0 + b_1x_1 + b_2x_2\n\nwhere\n\nx_1 is the average driving distance and\nx_2 is the indicator that the golfer is male.\n\nWhat is the posterior mean estimate of b_0 ? Round your answer to the nearest whole number.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndat=read.table(\"data/pgalpga2008.dat.txt\", header=T)\n# Note that attaching this masks T which is originally TRUE\nattach(dat)\ncolnames(dat) &lt;- c('distance','accuracy','gender')\n\ndat$gender = dat$gender -1\nmod2 &lt;- lm(accuracy ~ distance + gender, data=dat)\nsummary(mod2)\n\n\n\nCall:\nlm(formula = accuracy ~ distance + gender, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.0871  -2.8427   0.4869   3.3746  12.0241 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 147.3354     7.0460  20.911  &lt; 2e-16 ***\ndistance     -0.3231     0.0285 -11.334  &lt; 2e-16 ***\ngender        8.9468     1.2714   7.037 1.04e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.803 on 350 degrees of freedom\nMultiple R-squared:  0.359, Adjusted R-squared:  0.3553 \nF-statistic:    98 on 2 and 350 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nExercise 31.2  The posterior mean estimates of the other two coefficients are \\hat{b}_1=−0.323, and \\hat{b}_2=8.94. What is the interpretation of \\hat{b}_1?Golf\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nHolding all else constant, being male is associated with a 0.323 increase in drive accuracy percentage.\nHolding all else constant, each additional yard of distance is associated with a 0.323 increase in drive accuracy percentage.\nHolding all else constant, each additional yard of distance is associated with a 0.323 decrease in drive accuracy percentage.\nHolding all else constant, being male is associated with a 0.323 decrease in drive accuracy percentage.\n\n\n\n\n\nExercise 31.3 Golf\nThe standard error for b_1 (which we can think of as marginal posterior standard deviation in this case) is roughly 1/10 times the magnitude of the posterior mean estimate \\hat{b}_1=−0.323. In other words, the posterior mean is more than 10 posterior standard deviations from 0. What does this suggest?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe posterior probability that b_1&lt;0 is very low, suggesting a negative relationship between driving distance and accuracy.\nThe posterior probability that b_1&lt;0 is about 0.5, suggesting no evidence for an association between driving distance and accuracy.\nThe posterior probability that b_1&lt;0 is very high, suggesting a negative relationship between driving distance and accuracy.\n\n\n\n\n\nExercise 31.4 Golf\nThe estimated value of b_2 would typically be interpreted to mean that holding all else constant (for a fixed driving distance), golfers on the PGA tour are about 9% more accurate with their drives on average than golfers on the LPGA tour. However, if you explore the data, you will find that the PGA tour golfers’ average drives are 40+ yards longer than LPGA tour golfers’ average drives, and that the LPGA tour golfers are actually more accurate on average. Thus b_2 , while a vital component of the model, is actually a correction for the discrepancy in driving distances. Although model fitting can be easy (especially with software), interpreting the results requires a thoughtful approach.\nIt would also be prudent to check that the model fits the data well. One of the primary tools in regression analysis is the residual plot. Residuals are defined as the observed values y minus their predicted values \\hat{y} . Patterns in the plot of \\hat{y} versus residuals, for example, can indicate an inadequacy in the model. These plots are easy to produce.\n\n\nCode\nplot(fitted(mod2), residuals(mod2))\nabline(lm(residuals(mod2)~fitted(mod2)), col=\"red\") # regression line (y~x)\n\n\n\n\n\n\n\n\n\nwhere “mod” is the model object fitted with the lm() command.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe residuals appear to be random and lack any patterns or trends. There are no outliers (extreme observations).\nThe residuals appear to be random and lack any patterns or trends. However, there is at least one outlier (extreme observation) that we may want to investigate.\nThe residuals appear to be more spread apart for smaller predicted values \\hat{y} . There are no outliers (extreme observations).\nThe residuals appear to exhibit a curved trend. There is at least one outlier (extreme observation) that we may want to investigate.",
    "crumbs": [
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Honors Homework On Regression</span>"
    ]
  },
  {
    "objectID": "C2-L01.html",
    "href": "C2-L01.html",
    "title": "32  M1L1 - Statistical Modeling",
    "section": "",
    "text": "32.1 A Poll for a political candidate\nThis course is about statistical modelling which falls under the analyzing data objective.\nFor what kinds of problems might we use a statistical model?\nThe step is addressed in detail in most introductory statistics courses.\nGenerally, it is desirable to find a model where the parameters we estimate can be interpreted in the context of the original problem. You might also have to strike a balance between model complexity, and model generalizability. This is often referred to as the bias variance trade-off. Large complex models, might be able to fit your particular dataset very well. But may fail to generalize to future data.",
    "crumbs": [
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>M1L1 - Statistical Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L01.html#a-poll-for-a-political-candidate",
    "href": "C2-L01.html#a-poll-for-a-political-candidate",
    "title": "32  M1L1 - Statistical Modeling",
    "section": "",
    "text": "57% for a candidate\nthe 99% CI (51,63)\ndemographics:\n\n55% women\n63% men",
    "crumbs": [
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>M1L1 - Statistical Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L01.html#sec-modeling-process",
    "href": "C2-L01.html#sec-modeling-process",
    "title": "32  M1L1 - Statistical Modeling",
    "section": "32.2 Modeling Process (Video)",
    "text": "32.2 Modeling Process (Video)\n\n\n\n\n\n\n\nFigure 32.1: statistical modeling process\n\n\nBuilding statistical models is a process, and each step should be taken carefully. Here we outline the general process and offer some practical advice. We’ll call this the statistical modeling process.\n The first step in this process is to understand the problem. This may seem obvious, but understanding the problem and context is critical to success. A sophisticated model might be useless if it is applied inappropriately.understand the problem\n\nExample 32.1 (international stores) For example, suppose you have revenue data from several different locations of a store chain at unknown locations.\n\nIt seems reasonable to average these revenue numbers as a summary of how the store is doing.\nSuppose you discover that the stores are located in different countries and reported revenues in different currencies.\nNow that average doesn’t seem to have much meaning unless, of course, we get the revenue numbers converted to the same scale.\n\n\n The second step is to plan and properly collect relevant data. There may be multiple quantities that you could potentially measure to help answer your question. In this step, you decide what information will be most useful to solving your problem. How to collect the data and how many data points to collect. The quality of your data collection plan determines the value of your data.plan and collect data",
    "crumbs": [
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>M1L1 - Statistical Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L01.html#peer-review-survey",
    "href": "C2-L01.html#peer-review-survey",
    "title": "32  M1L1 - Statistical Modeling",
    "section": "32.3 peer review survey",
    "text": "32.3 peer review survey\nFor example, if you conduct a survey of peers in your workplace. Your results would likely not generalize to all workers in the company, especially if there are multiple work sites. If you want generalizable results, a better plan would be to select a random sample among all employees to participate in your survey.",
    "crumbs": [
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>M1L1 - Statistical Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L02.html",
    "href": "C2-L02.html",
    "title": "33  M1L2 - Bayesian Modeling",
    "section": "",
    "text": "33.1 Components of a Bayesian Model (Video)\nIn lesson one, we defined a statistical model as a mathematical structure used to imitate or approximate the data generating process. It incorporates uncertainty and variability using the theory of probability. A model could be very simple, involving only one variable.\nA model can be as simple as the one right here or as complicated and sophisticated as we need to capture the behavior of the data. So far, this model is the same for Frequentists and Bayesians.\nAs you may recall from the previous course. The frequentist approach to fitting this model right here would be to consider \\mu and \\sigma to be fixed but unknown constants, and then we would estimate them. To calculate our uncertainty in those estimates a frequentist approach would consider how much the estimates of \\mu and \\sigma might change if we were to repeat the sampling process and obtain another sample of 15 men, over, and over.\nThe Bayesian approach, the one we’re going to take in this class. Tackles our uncertainty in \\mu and \\sigma^2 with probability directly. By treating them as random variables with their own probability distributions. These are often called priors, and they complete a Bayesian model.\nIn the rest of this segment, we’re going to review three key components of Bayesian models. That were used extensively in the previous course The three primary components of Bayesian models that we often work with are the likelihood, the prior and the posterior.\n\\begin{aligned}\n\\mathbb{P}r(\\theta \\mid y) &= \\frac{\\mathbb{P}r(\\theta,y)}{\\mathbb{P}r(y)}\n\\\\ &= \\frac{\\mathbb{P}r(\\theta,y)}{\\int \\mathbb{P}r(\\theta,y)}\n\\\\ &= \\frac{\\mathbb{P}r(y \\mid \\theta)\\ \\mathbb{P}r(\\theta)}{\\int \\mathbb{P}r(y \\mid \\theta)\\ \\mathbb{P}r(\\theta)\\ d\\theta}\n\\end{aligned}\nWe start with the definition of conditional probability (1). The conditional distribution, \\mathbb{P}r(\\theta \\mid y) is the ratio of the joint distribution of \\theta and y, i.e. \\mathbb{P}r(\\theta,y); with the marginal distribution of y, \\mathbb{P}r(y).\nTo make this look like the Bayes theorem that we’re familiar with the joint distribution can be rewritten as the product of the prior and the likelihood. We start with the likelihood, because that’s how we usually write Bayes’ theorem. We have the same thing in the denominator here. But we’re going to integrate over the values of theta. These integrals are replaced by summations if we know that \\theta is a discrete random variable. The marginal distribution is another important piece which we may use when we more advanced Bayesian modeling.\nThe posterior distribution is our primary tool for achieving the statistical modeling objectives from lesson one.",
    "crumbs": [
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>M1L2 - Bayesian Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L02.html#sec-c2l02-components",
    "href": "C2-L02.html#sec-c2l02-components",
    "title": "33  M1L2 - Bayesian Modeling",
    "section": "",
    "text": "a Bayesian Model\n\n\n\nExample 33.1 (heights of men) Suppose our data consists of the heights of N=15 adult men. . Clearly it would be very expensive or even impossible to collect the genetic information that fully explains the variability in these men’s heights. We only have the height measurements available to us. To account for the variability, we might assume that the men’s heights follow a normal distribution.heights of N=15 men\nSo we could write the model like this:  where y_i will represent the height for person i, i will be our index. This will be equal to a constant, a number \\mu which will represents the mean for all men plus \\epsilon_i. the individual error term for individual i.y_i= \\mu + \\epsilon_i\n We’re going to assume that \\epsilon_i comes from a normal distribution with mean zero and variance \\sigma^2. We are also going to assume that these epsilons are independent and identically distributed from this normal distribution. This is also for i equal to 1 up to N which will be 15 in our case. Equivalently we could write this model directly for the y_i themselves.\\epsilon_i \\stackrel{iid}\\sim N(0,\\sigma^2) \\  i\\in 1 \\dots N\n So each y_i comes from a normal distribution independent and identically distributed with the normal distribution. With mean \\mu and variance \\sigma^2. This specifies a probability distribution and a model for the data.y_i \\stackrel{iid}\\sim N(\\mu,\\sigma^2) \\ i \\in 1 \\dots N\n\n\n\n\n\n\nNoteheights of men\n\n\n\n\n\\begin{aligned}\ny_i&= \\mu+\\epsilon_i,\n\\\\ \\epsilon_i &\\stackrel{iid}\\sim N(0,\\sigma^2)\n\\end{aligned}\n another way to write this:\n\n\\begin{aligned}\ny_i &\\stackrel{iid}\\sim N(\\mu,\\sigma^2)\n\\end{aligned}\n\n\n\nIf we know the values of \\mu and \\sigma. It also suggests how we might generate more fake data that behaves similarly to our original data set.\n\n\n\n\n\n\n\n\n\n\nFigure 33.1: Components of a Bayesian Model\n\n\n\n\n The likelihood is the probabilistic model for the data. It describes how, given the unknown parameters, the data might be generated. We’re going to call unknown parameter theta right here. Also, in this expression, you might recognize this from the previous class, as describing a probability distribution.\\mathbb{P}r(y\\mid \\theta)\\ \\text{(likelihood)}\n The prior, the next step, is the probability distribution that characterizes our uncertainty with the parameter theta. We’re going to write it as \\mathbb{P}r(\\theta). It’s not the same distribution as this one. We’re just using this notation p to represent the probability distribution of theta. By specifying a likelihood and a prior.\\mathbb{P}r(\\theta)\\ \\text{(prior)}\n We now have a joint probability model for both the knowns, the data, and the unknowns, the parameters. We can see this by using the chain rule of probability. If we wanted the joint distribution of both the data and the parameters theta. Using the chain rule of probability, we could start with the distribution of \\theta. And multiply that by the probability or the distribution of y given theta. That gives us an expression for the joint distribution. However if we’re going to make inferences about data and we already know the values of y, we don’t need the joint distribution, what we need is the posterior distribution.\\mathbb{P}r(y,\\theta) = \\mathbb{P}r(\\theta)\\mathbb{P}r(y\\mid\\theta) \\ \\text{(joint probability)}\n The posterior distribution is the distribution of \\mathbb{P}r(\\theta \\mid y), i.e. \\theta given y. We can obtain this expression using the laws of conditional probability and specifically using Bayes’ theorem.\\mathbb{P}r(\\theta \\mid y)\\ \\text{(posterior)}\n\n\n We start with the joint distribution like we have on top, and we integrate out or marginalize over the values of theta (2)How do we get the marginal distribution of y?\n\n\n\n\n\n\n\n\nNoteAnatomy of a posterior probability\n\n\n\n\n  \\begin{aligned}\n  &\\mathbb{P}r(y\\mid \\theta) && (likelihood)\n\\\\ &  \\mathbb{P}r(\\theta) && (prior)\n\\\\   \\mathbb{P}r(y,\\theta) &= \\mathbb{P}r(\\theta)\\mathbb{P}r(y|\\theta) &&(joint\\ distribution)\n\\\\   \\mathbb{P}r(\\theta \\mid y) &= \\frac{\\mathbb{P}r(\\theta,y)}{\\mathbb{P}r(y)} && (conditional\\ probability)\n\\\\ &= \\frac{\\mathbb{P}r(\\theta,y)}{\\int \\mathbb{P}r(\\theta,y)}\n\\\\ &= \\frac{\\mathbb{P}r(y \\mid \\theta)\\ \\mathbb{P}r(\\theta)}{\\int \\mathbb{P}r(y \\mid \\theta)\\ \\mathbb{P}r(\\theta)\\ d\\theta}\n\\end{aligned}\n\\tag{33.1}\n\n\n\nWhereas non-Bayesian approaches consider a probability model for the data only, the hallmark characteristic of Bayesian models is that they specify a joint probability distribution for both data and parameters. How does the Bayesian paradigm leverage this additional assumption?\n\n\n\nThis allows us to make probabilistic assessments about how likely our particular data outcome is under any parameter setting.\nThis allows us to select the most accurate prior distribution.\nThis allows us to make probabilistic assessments about hypothetical data outcomes given particular parameter values.\nThis allows us to use the laws of conditional probability to describe our updated information about parameters given the data.",
    "crumbs": [
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>M1L2 - Bayesian Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L02.html#sec-c2l02-model-specification",
    "href": "C2-L02.html#sec-c2l02-model-specification",
    "title": "33  M1L2 - Bayesian Modeling",
    "section": "33.2 Model Specification (Video)",
    "text": "33.2 Model Specification (Video)\n\n\n\n\nModel specification\n\nBefore fitting any model we first need to specify all of its components.\n\n\n\n\n\n\n\n\nFigure 33.2: The graphical model specification for the height model\n\n\n\n\n\n\n33.2.1 Hierarchical representation\nOne convenient way to do this is to write down the hierarchical form of the model. By hierarchy, we mean that the model is specified in steps or in layers. We usually start with the model for the data directly, or the likelihood. Let’s write, again, the model from the previous lesson.\nWe had the height for person i, given our parameters \\mu and \\sigma^2, so conditional on those parameters, y_i came from a normal distribution that was independent and identically distributed, where the normal distribution has mean \\mu and variance \\sigma^2, and we’re doing this for individuals 1 up to N, which was 15 in this example. y_i | \\mu,\\sigma^2 \\stackrel{iid}\\sim N(\\mu,\\sigma^2) \\ for\\ i \\in 1,\\dots,15\nThe next level that we need is the prior distribution from \\mu and \\sigma^2. For now we’re going to say that they’re independent priors. So that our prior from \\mu and \\sigma^2 is going to be able to factor Into the product of two independent priors.  We can assume independents in the prior and still get dependents in the posterior distribution.\\mathbb{P}r(\\mu,\\sigma^2)~=~\\mathbb{P}r(\\mu)\\mathbb{P}r(\\sigma^2)\\ (independence)\nIn the previous course we learned that the conjugate prior for \\mu, if we know the value of \\sigma^2, is a normal distribution, and that the conjugate prior for \\sigma^2 when \\mu is known is the inverse gamma distribution.\nLet’s suppose that our prior distribution for \\mu is a normal distribution where mean will be \\mu_0.  This is just some number that you’re going to fill in here when you decide what the prior should be. Mean \\mu_0, and less say \\sigma^2_0 would be the variance of that prior.\\mu \\sim N(\\mu_0,\\sigma^2_0)\nThe prior for \\sigma^2 will be inverse gamma  which has two parameters:\\sigma^2 \\sim IG(\\nu_0,\\beta_0)\n\nIt has a shape parameter, we’re going to call that \\nu_0, and\nIt has a scale parameter, we’ll call that \\beta_0.\n\nWe need to choose values for these hyper-parameters here. But we do now have a complete Bayesian model.\nWe now introduce some new ideas that were not presented in the previous course.\n\n\n\n\n\n\nNoteHierarchical representation\n\n\n\nBy hierarchy, we mean that the model is specified in steps or in layers.\n\nstart with the model for the data, or the likelihood.\nwrite the priors\nadd hyper-priors for the parameters of the priors.\n\nMore details can be seen on this wikipedia article and on this one\n\n\n\n\n33.2.2 Graphical representation\nAnother useful way to write out this model Is using what’s called a graphical representation. To write a graphical representation, we’re going to do the reverse order, we’ll start with the priors and finish with the likelihood.\nIn the graphical representation we draw what are called nodes so this would be a node for mu. The circle means that the this is a random variable that has its own distribution. So \\mu with its prior will be represented with that. And then we also have \\sigma^2. The next part of a graphical model is showing the dependence on other variables. Once we have the parameters, we can generate the data.\nFor example we have y_1, \\dots y_n. These are also random variables, so we’ll create these as nodes. And I’m going to double up the circle here to indicate that these nodes are observed, you see them in the data. So we’ll do this for all of the ys here. And to indicate the dependence of the distributions of the ys on \\mu and \\sigma^2, we’re going to draw arrows. So \\mu influences the distribution of y for each one of these ys. The same is true for sigma squared, the distribution of each y depends on the distribution of \\sigma^2. Again, these nodes right here, that are double-circled, mean that they’ve been observed. If they’re shaded, which is the usual case, that also means that they’re observed. The arrows indicate the dependence between the random variables and their distributions.\nNotice that in this hierarchical representation, I wrote the dependence of the distributions also. We can simplify the graphical model by writing exchangeable random variables and I’ll define exchangeable later.\nWe’re going to write this using a representative of the ys here on what’s called the plate. So I’m going to re draw this hierarchical structure, we have \\mu and \\sigma^2. And we don’t want to have to write all of these notes again. So I’m going to indicate that there are n of them, And I’m just going to draw one representative, y_i. And they depend on \\mu and \\sigma^2. To write a model like this, we must assume that the ys are exchangeable. That means that the distribution for the ys does not change if we were to switch the index label like the i on the y there. So, if for some reason, we knew that one of the ys was different from the other ys in its distribution, and if we also know which one it is, then we would need to write a separate node for it and not use a plate like we have here.\n\n\n\n\n\n\nNoteGraphical representation\n\n\n\n\n\n\n\n\n\n\n\nFigure 33.3: pgm-posterior\n\n\n\n\n\nIn the graphical representation we start at the top by drawing:\n\ncircle nodes for the hyperparameters.\narrows indicating that they determine the\nnodes for the priors.\nnodes for the RVs (doubled circles)\nplates (rectangles) indicating RVs that are exchangeable. We add an index to the corner of the plate to indicate the amount of replicated RVs\n\nMore details can be seen on this wikipedia article\n\n\nBoth the hierarchical and graphical representations show how you could hypothetically simulate data from this model. You start with the variables that don’t have any dependence on any other variables. You would simulate those, and then given those draws, you would simulate from the distributions for these other variables further down the chain.\nThis is also how you might simulate from a prior predictive distribution.",
    "crumbs": [
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>M1L2 - Bayesian Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L02.html#sec-c2l02-posterior-derivation",
    "href": "C2-L02.html#sec-c2l02-posterior-derivation",
    "title": "33  M1L2 - Bayesian Modeling",
    "section": "33.3 Posterior derivation (Video)",
    "text": "33.3 Posterior derivation (Video)\n\n\n\n\nPosterior derivation\n\nSo far, we’ve only drawn the model with two levels. But in reality, there’s nothing that will stop us from adding more layers.\nFor example, instead of fixing the values for the hyper parameters in the previous segment, those hyper parameters were the \\mu_0, the \\sigma_0, the \\nu_0 and the \\beta_0.\nWe could specify just fixed numeric values for those, or we could learn them from the data and model them using additional prior distributions for those variables to make this a hierarchical model.\nOne reason we might do this is if the data are hierarchically organized so that the observations are naturally grouped together. We will examine these types of hierarchical models in depth later in the course.\nAnother simple example of a hierarchical model is one you saw already in the previous course.\nLet’s write it as y_i \\mid \\mu,\\sigma^2, so this is just like the model from the previous lesson, will be independent and identically distributed normal with a mean \\mu and a variance, \\sigma^2. The next step, instead of doing independent priors for \\mu and \\sigma^2, we’re going to have the prior for \\mu depend on the value of \\sigma^2. That is given \\sigma^2, \\mu follows a normal distribution with mean \\mu naught, just some hyper parameter that you’re going to chose. And the variance of this prior will be \\sigma^2, this parameter, divided by omega naught. Another hyper parameter that will scale it.\nWe now have a joint distribution of y and \\mu given \\sigma^2 So finally, we need to complete the model with the prior for \\sigma^2. We’ll use our standard inverse gamma with the same hyper parameters as last time. This model has three layers. And \\mu depends on sigma right here. The graphical representation for this model looks like this. We start with the variables that don’t depend on anything else. So that would be \\sigma^2 and move down the chain.\nSo here, the next variable is \\mu which depends on \\sigma^2. And then dependent on both, we have the yi’s. We use a double circle because the yi’s are observed, their data, and we’re going to assume that they’re exchangeable. So let’s put them on a plate here for i in 1 to n The distribution of yi depends on both \\mu and \\sigma^2, so we’ll draw curves connecting those pieces there. To simulate hypothetical data from this model, we would have to first draw from the distribution of the prior for \\sigma^2. Then the distribution for mu which depends on \\sigma^2. And once we’ve drawn both of these, then we can draw random draws from the y’s, which of course depends on both of those. With multiple levels, this is an example of a hierarchical model. Once we have a model specification, we can write out what the full posterior distribution for all the parameters given the data looks like. Remember that the numerator in Bayes’ theorem is the joint distribution of all random quantities, all the nodes in this graphical representation over here from all of the layers. So for this model that we have right here, we have a joint distribution that’ll look like this. We’re going to write the joint distribution of everything y1 up to yn, \\mu and \\sigma^2, Using the chain rule of probability, we’re going to multiply all of the distributions in the hierarchy together. So let’s start with the likelihood piece. And we’ll multiply that by the next layer, the distribution of mu, given \\sigma^2. And finally, with the prior for sigma squared. So what do these expressions right here look like? The likelihood right here in this level because they’re all independent will be a product of normal densities. So we’re going to multiply the normal density for each yi, Given those parameters. This, again, is shorthand right here for the density of a normal distribution. So that represents this piece right here. The conditional prior of \\mu given sigma squared is also a normal. So we’re going to multiply this by a normal distribution of mu, where its parameters are \\mu naught and sigma squared over omega naught. And finally, we have the prior for sigma squared. We’ll multiply by the density of an inverse gamma for \\sigma^2 given the hyper parameters \\mu naught, sorry, that is given, the hyper parameters \\mu naught and and beta naught. What we have right here is the joint distribution of everything. It is the numerator in Bayes theorem. Let’s remind ourselves really fast what Bayes theorem looks like again. We have that the posterior distribution of the parameter given the data is equal to the likelihood, Times the prior. Over the same thing again. So this gives us in the numerator the joint distribution of everything which is what we’ve written right here.\nIn Bayes theorem, the numerator and the denominator are the exact same expression accept that we integrate or marginalize over all of the parameters.\nBecause the denominator is a function of the y’s only, which are known values, the denominator is just a constant number. So we can actually write the posterior distribution as being proportional to, this symbol right here represents proportional to. The joint distribution of the data and parameters, or the likelihood times the prior. The poster distribution is proportional to the joint distribution, or everything we have right here. In other words, what we have already written for this particular model is proportional to the posterior distribution of \\mu and \\sigma^2, given all of the data. The only thing missing in this expression right here is just some constant number that causes the expression to integrate to 1. If we can recognize this expression as being proportional to a common distribution, then our work is done, and we know what our posterior distribution is. This was the case for all models in the previous course. However, if we do not use conjugate priors or if the models are more complicated, then the posterior distribution will not have a standard form that we can recognize. We’re going to explore a couple of examples of this issue in the next segment.",
    "crumbs": [
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>M1L2 - Bayesian Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L02.html#sec-c2l02-non-conjugate-models",
    "href": "C2-L02.html#sec-c2l02-non-conjugate-models",
    "title": "33  M1L2 - Bayesian Modeling",
    "section": "33.4 Non-conjugate models (Video)",
    "text": "33.4 Non-conjugate models (Video)\n\n\n\n\nNon-conjugate models\n\nWe’ll first look at an example of a one parameter model that is not conjugate.\n\n\n33.4.0.1 Company Personnel\nSuppose we have values that represent the percentage change in total personnel from last year to this year for, we’ll say, ten companies. These companies come from a particular industry. We’re going to assume for now, that these are independent measurements from a normal distribution with a known variance equal to one, but an unknown mean.\nSo we’ll say the percentage change in the total personnel for company I, given the unknown mean \\mu will be distributed normally with mean \\mu, and we’re just going to use variance 1.\nIn this case, the unknown mean could represent growth for this particular industry.\nIt’s the average of the growth of all the different companies. The small variance between the companies and percentage growth might be appropriate if the industry is stable.\nWe know that the conjugate prior for \\mu in this location would be a normal distribution.\nBut suppose we decide that our prior believes about \\mu are better reflected using a standard t distribution with one degree of freedom. So we could write that as the prior for \\mu is a t distribution with a location parameter 0. That’s where the center of the distribution is. A scale parameter of 1 to make it the standard t-distribution similar to a standard normal, and 1 degree of freedom.\nThis particular prior distribution has heavier tails than the conjugate and normal distribution, which can more easily accommodate the possibility of extreme values for mu. It is centered on zero so, that apriori, there is a 50% chance that the growth is positive and a 50% chance that the growth is negative.\n\n\nRecall that the posterior distribution of \\mu is proportional to the likelihood times the prior. Let’s write the expression for that in this model. That is the posterior distribution for \\mu given the data y_1 \\dots y_n is going to be proportional to the likelihood.\nIt is a product from i equals 1 to n, in this case that’s 10.\nDensities from a normal distribution.\nLet’s write the density from this particular normal distribution.\nIs 1 over the square root of 2 pi.\nE to the negative one-half.\nYi minus the mean squared, this is the normal density for each individual Yi and we multiplied it for likelihood.\nThe density for this t prior looks like this.\nIt’s 1 over pi times 1 plus \\mu squared.\nThis is the likelihood times the prior.\nIf we do a little algebra here, first of all, we’re doing this up to proportionality.\nSo, constants being multiplied by this expression are not important.\nThe square root of 2 pi being multiplied n times, is just a constant number, and \\pi creates a constant number. So we will drop them in our next step.\nSo this is now proportional too, we’re removing this piece and now we’re going to use properties of exponents.\nThe product of exponents is the sum of the exponentiated pieces.\nSo we have the exponent of negative one-half times the sum from i equals 1 to n, of Yi minus \\mu squared.\nAnd then we’re dropping the pie over here, so times 1 plus \\mu squared.\nWe’re going to do a few more steps of algebra here to get a nicer expression for this piece.\nBut we’re going to skip ahead to that.\nWe’ve now added these last two expressions.\nTo arrive at this expression here for the posterior, or what’s proportional to the posterior distribution.\nThis expression right here is almost proportional to a normal distribution except we have this 1 plus \\mu squared term in the denominator.\nWe know the posterior distribution up to a constant but we don’t recognize its form as a standard distribution.\nThat we can integrate or simulate from, so we’ll have to do something else.\nLet’s move on to our second example. For a two parameter example, we’re going to return to the case where we have a normal likelihood.\nAnd we’re now going to estimate \\mu and \\sigma^2, because they’re both unknown.\nRecall that if \\sigma^2 were known, the conjugate prior from \\mu would be a normal distribution.\nAnd if \\mu were known, the conjugate prior we could choose for \\sigma^2 would be an inverse gamma.\nWe saw earlier that if you include \\sigma^2 in the prior for \\mu, and use the hierarchical model that we presented earlier, that model would be conjugate and have a closed form solution. However, in the more general case that we have right here, the posterior distribution does not appear as a distribution that we can simulate or integrate.\nChallenging posterior distributions like these ones and most others that we’ll encounter in this course kept Bayesian in methods from entering the main stream of statistics for many years. Since only the simplest problems were tractable. However, computational methods invented in the 1950’s, and implemented by statisticians decades later, revolutionized the field. We do have the ability to simulate from the posterior distributions in this lesson as well as for many other more complicated models.",
    "crumbs": [
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>M1L2 - Bayesian Modeling</span>"
    ]
  },
  {
    "objectID": "C2-L03.html",
    "href": "C2-L03.html",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "",
    "text": "34.1 Monte Carlo Integration (Video)\nBefore we learn how to simulate from complicated posterior distributions, let’s review some of the basics of Monte Carlo estimation.\nMonte Carlo estimation refers to simulating hypothetical draws from a probability distribution in order to calculate important quantities. By “important quantities,” we mean things like the mean, the variance, or the probability of some event or distributional property.\nAll of these calculations involve integration, which except for the simplest distributions, may range from very difficult to impossible :-) .\nSuppose we have a random variable \\theta that follows a \\Gamma distribution\n\\theta \\sim \\mathrm{Gamma}(a,b) \\qquad\n\\tag{34.1}\nLet’s say a=2 and b=\\frac{1}{3} , where a is the shape parameter and b is the rate parameter.\na=2 \\qquad b=1/3 \\qquad\n\\tag{34.2}\nTo calculate the mean of this distribution, we would need to compute the following integral. It is possible to compute this integral, and the answer is \\frac{a}{b} (6 in this case).\n\\mathbb{E}[\\theta] = \\int_0^\\infty \\theta f(\\theta) d\\theta = \\int_0^\\infty \\theta \\frac{b^a}{\\Gamma(a)}\\theta^{a-1}e^{-b\\theta} d\\theta = \\frac{a}{b} \\qquad\n\\tag{34.3}\nHowever, we could verify this answer through Monte Carlo estimation.\nTo do so, we would simulate a large number of draws (call them \\theta^∗_i \\quad (i=1,\\ldots ,m) ) from this gamma distribution and calculate their sample mean.\nWhy can we do this?\nRecall from the previous course that if we have a random sample from a distribution, the average of those samples converges in probability to the true mean of that distribution by the Law of Large Numbers.\nFurthermore, by the Central Limit Theorem (CLT), this sample mean \\bar{\\theta}^* = \\frac{1}{m}\\sum_{i=1}^m \\theta_i^* approximately follows a normal distribution with mean \\mathbb{E}[\\theta] and variance \\mathbb{V}ar[\\theta]/m .\nThe theoretical variance of \\theta is the following integral:\n\\text{Var}[\\theta] = \\int_0^\\infty (\\theta-\\mathbb{E}(\\theta))^2 f(\\theta) d\\theta \\qquad\n\\tag{34.4}\nJust like we did with the mean, we could approximate this variance with the sample variance\n\\text{Var}[\\theta^*] = \\frac{1}{m}\\sum_{i=1}^m (\\theta_i^* - \\bar{\\theta}^*)^2 \\qquad\n\\tag{34.5}",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#sec-monte-carlo-integration",
    "href": "C2-L03.html#sec-monte-carlo-integration",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "",
    "text": "Monte Carlo Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n34.1.1 Calculating probabilities\n\n\n\n\nMonte Carlo Integration\n\nThis method can be used to calculate many different integrals. Say h(\\theta) is any function and we want to calculate\n\n\\int h(\\theta) \\mathbb{P}r(\\theta) d\\theta = \\mathbb{E}(h(\\theta)) \\approx \\frac{1}{m}\\sum_{i=1}^m h(\\theta_i^*) \\qquad\n\\tag{34.6}\nwhere \\mathbb{P}r(\\theta) is the probability density function of \\theta and h(\\theta) is any function of \\theta.\nThis integral is precisely what is meant by \\mathbb{E}[h(\\theta)] , so we can conveniently approximate it by taking the sample mean of h(\\theta_i^*). That is, we apply the function h to each simulated sample from the distribution, and take the average of all the results.\nOne extremely useful example of an h function is is the indicator I_A(\\theta) where A is some logical condition about the value of \\theta. To demonstrate, suppose h(\\theta)=I_{[\\theta&lt;5]}(\\theta), which will give a 1 if \\theta &lt;5 and return a 0 otherwise.\nWhat is \\mathbb{E}(h(\\theta))?\nThis is the integral:\n\n\\begin{aligned}\n\\mathbb{E}[h(\\theta)] &= \\int_0^\\infty \\mathbb{I}_{[\\theta&lt;5]}(\\theta) \\mathbb{P}r(\\theta) d\\theta \\\\\n&= \\int_0^5 1 \\cdot \\mathbb{P}r(\\theta) d\\theta + \\int_5^\\infty 0 \\cdot \\mathbb{P}r(\\theta) d\\theta \\\\\n&= \\mathbb{P}r(\\theta &lt; 5) \\qquad\n\\end{aligned}\n\\tag{34.7}\nSo what does this mean?\nIt means we can approximate the probability that \\theta &lt; 5 by drawing many samples \\theta^∗_i , and approximating this integral with \\frac{1}{m} \\sum_{i=1}^m I_{\\theta^* &lt; 5} (\\theta_i^*). This expression is simply counting how many of those samples come out to be less than 5 , and dividing by the total number of simulated samples.\nThat’s convenient!\nLikewise, we can approximate quantiles of a distribution. If we are looking for the value z such that \\mathbb{P}r(\\theta &lt; z) = 0.9 , we simply arrange the samples \\theta^∗_i in ascending order and find the smallest drawn value that is greater than 90% of the others.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#monte-carlo-error-and-marginalization",
    "href": "C2-L03.html#monte-carlo-error-and-marginalization",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "34.2 Monte Carlo Error and Marginalization",
    "text": "34.2 Monte Carlo Error and Marginalization\n\n\n\n\nMonte Carlo Error and Marginalization\n\nHow good is an approximation by Monte Carlo sampling?\nAgain we can turn to the CLT, which tells us that the variance of our estimate is controlled in part by m. For a better estimate, we want larger m.\nFor example, if we seek \\mathbb{E}[\\theta] , then the sample mean \\bar\\theta^∗ approximately follows a normal distribution with mean \\mathbb{E}[\\theta] and variance Var[\\theta]/m .\nThe variance tells us how far our estimate might be from the true value.\nOne way to approximate Var[\\theta] is to replace it with the sample variance.\nThe standard deviation of our Monte Carlo estimate is the square root of that, or the sample standard deviation divided by \\sqrt{m} .\nIf m is large, it is reasonable to assume that the true value will likely be within about two standard deviations of your Monte Carlo estimate.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#marginalization",
    "href": "C2-L03.html#marginalization",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "34.3 Marginalization",
    "text": "34.3 Marginalization\nWe can also obtain Monte Carlo samples from hierarchical models.\nAs a simple example, let’s consider a binomial random variable where y \\mid \\phi \\sim \\mathrm{Bin}(10,\\phi) and further suppose \\phi is random (as if it had a prior) and is distributed beta \\phi \\sim \\mathrm{Beta}(2,2) .\nGiven any hierarchical model, we can always write the joint distribution of y and \\phi as \\mathbb{P}r(y,\\phi) = \\mathbb{P}r(y \\mid \\phi)\\mathbb{P}r(\\phi) using the chain rule of probability.\nTo simulate from this joint distribution, repeat these steps for a large number m :\n\nSimulate \\phi^∗_i from its Beta(2,2) distribution.\nGiven the drawn \\phi^∗_i , simulate y^∗_i from Bin(10,\\phi^*_i) .\n\nThis will produce m independent pairs of (y^∗,\\phi^∗)_i drawn from their joint distribution.\nOne major advantage of Monte Carlo simulation is that marginalizing is easy. Calculating the marginal distribution of y , \\mathbb{P}r(y)=\\int^1_0 \\mathbb{P}r(y,\\phi)d\\phi, might be challenging. But if we have draws from the joint distribution, we can just discard the \\phi^∗_i draws and use the y^∗_i as samples from their marginal distribution.\nThis is also called the prior predictive distribution introduced in the previous course.\nIn the next segment, we will demonstrate some of these principles.\nRemember, we do not yet know how to sample from the complicated posterior distributions introduced in the previous lesson.\nBut once we learn that, we will be able to use the principles from this lesson to make approximate inferences from those posterior distributions.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#computing-examples",
    "href": "C2-L03.html#computing-examples",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "34.4 Computing Examples",
    "text": "34.4 Computing Examples\nMonte Carlo simulation from the most common distributions is very straightforward in R.\nLet’s start with the example from the previous segment, where \\theta \\sim Gamma(a,b) with a=2, b=1/3 . This could represent the posterior distribution of \\theta if our data came from a Poisson distribution with mean \\theta and we had used a conjugate gamma prior. Let’s start with m=100 .\n\n\nCode\nset.seed(32) # Initializes the random number generator so we can replicate these results. To get different random numbers, change the seed. \nm = 100 \na = 2.0 \nb = 1.0 / 3.0 \n\n\nTo simulate m independent samples, use the rgamma function.\n\n\nCode\ntheta &lt;- rgamma(n=m, shape = a, rate=b) \n\n\nWe can plot a histogram of the generated data, and compare that to the true density.\n\n\nCode\nhist(theta, freq=FALSE) \ncurve(dgamma(x=x, shape=a, rate=b), col=\"blue\", add=TRUE)\n\n\n\n\n\n\n\n\nFigure 34.1: Histogram of simulated gamma samples with true density\n\n\n\n\n\nTo find our Monte Carlo approximation to \\mathbb{E}(\\theta) , let’s take the average of our sample (and compare it with the truth).\n\n\nCode\nsum(theta) / m # sample mean \n\n\n[1] 5.514068\n\n\n\n\nCode\nmean(theta) # sample mean \n\n\n[1] 5.514068\n\n\n\n\nCode\na / b # true expected value\n\n\n[1] 6\n\n\nNot bad, but we can do better if we increase m to say, 10,000.\n\n\nCode\nm = 1e4 \ntheta = rgamma(n=m, shape=a, rate=b) \nmean(theta)\n\n\n[1] 6.023273\n\n\nHow about the variance of \\theta ?\n\n\nCode\nvar(theta) # sample variance\n\n\n[1] 18.04318\n\n\n\n\nCode\na / b^2 # true variance of Gamma(a,b) \n\n\n[1] 18\n\n\nWe can also approximate the probability that \\theta &lt; 5 .\n\n\nCode\nind = theta &lt; 5.0 # set of indicators, TRUE if theta_i &lt; 5 \nmean(ind)         # automatically converts FALSE/TRUE to 0/1 \n\n\n[1] 0.497\n\n\n\n\nCode\npgamma(q=5.0, shape=a, rate=b) # true value of Pr( theta &lt; 5 )\n\n\n[1] 0.4963317\n\n\nWhat is the 0.9 quantile (90th percentile) of \\theta ? We can use the quantile function which will order the samples for us and find the appropriate sample quantile.\n\n\nCode\nquantile(x=theta, probs=0.9) \n\n\n     90% \n11.74338 \n\n\n\n\nCode\nqgamma(p=0.9, shape=a, rate=b) # true value of 0.9 quantile\n\n\n[1] 11.66916",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#monte-carlo-error",
    "href": "C2-L03.html#monte-carlo-error",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "34.5 Monte Carlo error",
    "text": "34.5 Monte Carlo error\nWe can use the CLT to approximate how accurate our Monte Carlo estimates are. For example, if we seek E(\\theta) , then the sample mean \\bar\\theta^∗ approximately follows a normal distribution with mean \\mathbb{E}(\\theta) and variance Var(\\theta)/m . We will use the sample standard deviation divided by the square root of m to approximate the Monte Carlo standard deviation.\n\n\nCode\nse = sd(theta) / sqrt(m) \n2.0 * se # we are reasonably confident that the Monte Carlo estimate is no more than this far from the truth\n\n\n[1] 0.08495454\n\n\nThese numbers give us a reasonable range for the quantity we are estimating with Monte Carlo. The same applies for other Monte Carlo estimates, like the probability that \\theta &lt; 5.\n\n\nCode\nind = theta &lt; 5.0 \nse = sd(ind) / sqrt(m)\n2.0 * se # we are reasonably confident that the Monte Carlo estimate is no more than this far from the truth \n\n\n[1] 0.01000032",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#marginalization-1",
    "href": "C2-L03.html#marginalization-1",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "34.6 Marginalization",
    "text": "34.6 Marginalization\nLet’s also do the second example of simulating a hierarchical model. In our example from the previous segment, we had a binomial random variable where y \\mid \\phi \\overset{\\text{iid}}{\\sim}\\text{Binomial}(10,\\phi), and \\phi \\sim Beta(2,2). To simulate from this joint distribution, repeat these steps for a large number m :\n\nSimulate \\phi_i from its Beta(2,2) distribution.\nGiven the drawn \\phi_i , simulate y_i from Bin(10,\\phi_i) .\n\n\n\nCode\nm = 10e4\n\ny = numeric(m) # create the vectors we will fill in with simulations \nphi = numeric(m)\n\nfor (i in 1:m) {\n  phi[i] = rbeta(n=1, shape1=2.0, shape2=2.0)\n  y[i] = rbinom(n=1, size=10, prob=phi[i]) \n} \n# which is equivalent to the following 'vectorized' code \nphi = rbeta(n=m, shape1=2.0, shape2=2.0) \ny = rbinom(n=m, size=10, prob=phi)\n\n\nIf we are interested only in the marginal distribution of y , we can just ignore the draws for \\phi and treat the draws of y as a sample from its marginal distribution.\n\n\nCode\nmean(y) \n\n\n[1] 5.00008\n\n\n\n\nCode\nplot(prop.table(table(y)), ylab=\"Pr(y)\", main=\"Marginal distribution of y\")\n\n\n\n\n\n\n\n\nFigure 34.2",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#definition",
    "href": "C2-L03.html#definition",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "35.1 Definition",
    "text": "35.1 Definition\nIf we have a sequence of random variables X_1,X_2,\\dots X_n where the indices 1,2,\\dots,n represent successive points in time, we can use the chain rule of probability to calculate the probability of the entire sequence:\n\n\\mathbb{P}r(X_1, X_2, \\ldots X_n) = \\mathbb{P}r(X_1) \\cdot \\mathbb{P}r(X_2 \\mid X_1) \\cdot \\mathbb{P}r(X_3 \\mid X_2, X_1) \\cdot \\ldots \\cdot \\mathbb{P}r(X_n \\mid X_{n-1}, X_{n-2}, \\ldots, X_2, X_1) \\qquad\n\\tag{35.1}\nMarkov chains simplify this expression by using the Markov assumption. The assumption is that given the entire past history, the probability distribution for the random variable at the next time step only depends on the current variable. Mathematically, the assumption is written like this:\n\n\\mathbb{P}r(X_{t+1} \\mid X_t, X_{t-1}, \\ldots, X_2, X_1 ) = \\mathbb{P}r(X_{t+1} \\mid X_t) \\qquad\n\\tag{35.2}\nfor all t=2,\\dots,n. Under this assumption, we can write the first expression as\n\n\\mathbb{P}r(X_1, X_2, \\ldots X_n) = \\mathbb{P}r(X_1) \\cdot \\mathbb{P}r(X_2 \\mid X_1) \\cdot \\mathbb{P}r(X_3 \\mid X_2) \\cdot \\mathbb{P}r(X_4 \\mid X_3) \\cdot \\ldots \\cdot \\mathbb{P}r(X_n \\mid X_{n-1}) \\qquad\n\\tag{35.3}\nwhich is much simpler than the original. It consists of an initial distribution for the first variable, \\mathbb{P}r(X_1), and n−1 transition probabilities. We usually make one more assumption: that the transition probabilities do not change with time. Hence, the transition from time t to time t+1 depends only on the value of Xt.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#examples-of-markov-chains",
    "href": "C2-L03.html#examples-of-markov-chains",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "35.2 Examples of Markov chains",
    "text": "35.2 Examples of Markov chains\n\n35.2.1 Discrete Markov chain\nSuppose you have a secret number (make it an integer) between 1 and 5. We will call it your initial number at step 1. Now for each time step, your secret number will change according to the following rules:\n\nFlip a coin.\n\nIf the coin turns up heads, then increase your secret number by one (5 increases to 1).\nIf the coin turns up tails, then decrease your secret number by one (1 decreases to 5).\n\nRepeat n times, and record the evolving history of your secret number.\n\nBefore the experiment, we can think of the sequence of secret numbers as a sequence of random variables, each taking on a value in \\{1,2,3,4,5\\}. Assume that the coin is fair, so that with each flip, the probability of heads and tails are both 0.5.\nDoes this game qualify as a true Markov chain? Suppose your secret number is currently 4 and that the history of your secret numbers is (2,1,2,3). What is the probability that on the next step, your secret number will be 5? What about the other four possibilities? Because of the rules of this game, the probability of the next transition will depend only on the fact that your current number is 4. The numbers further back in your history are irrelevant, so this is a Markov chain.\nThis is an example of a discrete Markov chain, where the possible values of the random variables come from a discrete set. Those possible values (secret numbers in this example) are called states of the chain. The states are usually numbers, as in this example, but they can represent anything. In one common example, the states describe the weather on a particular day, which could be labeled as 1-fair, 2-poor.\n\n\n35.2.2 Random walk (continuous)\nNow let’s look at a continuous example of a Markov chain. Say X_t=0 and we have the following transition model:\n\n\\mathbb{P}r(X_{t+1}\\mid X_t=x_t)=N(x_t,1) \\qquad\n\\tag{35.4}\nThat is, the probability distribution for the next state is Normal with variance 1 and mean equal to the current state. This is often referred to as a “random walk.” Clearly, it is a Markov chain because the transition to the next state Xt+1 only depends on the current state Xt.\nThis example is straightforward to code in R:\n\n\nCode\nset.seed(34)\n\nn = 100\nx = numeric(n)\n\nfor (i in 2:n) {\n  x[i] = rnorm(1, mean=x[i-1], sd=1.0)\n}\n\nplot.ts(x)",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#transition-matrix",
    "href": "C2-L03.html#transition-matrix",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "35.3 Transition matrix",
    "text": "35.3 Transition matrix\nLet’s return to our example of the discrete Markov chain. If we assume that transition probabilities do not change with time, then there are a total of 25 (52) potential transition probabilities. Potential transition probabilities would be from State 1 to State 2, State 1 to State 3, and so forth. These transition probabilities can be arranged into a matrix Q:\n\nQ =\n\\begin{pmatrix}\n0 & .5 & 0 & 0 & .5 \\\\\n.5 & 0 & .5 & 0 & 0 \\\\\n0 & .5 & 0 & .5 & 0 \\\\\n0 & 0 & .5 & 0 & .5 \\\\\n.5 & 0 & 0 & .5 & 0 \\\\\n\\end{pmatrix} \\qquad\n\\tag{35.5}\nwhere the transitions from State 1 are in the first row, the transitions from State 2 are in the second row, etc. For example, the probability \\mathbb{P}r(X_{t+1}=5\\mid X_t=4) can be found in the fourth row, fifth column.\nThe transition matrix is especially useful if we want to find the probabilities associated with multiple steps of the chain. For example, we might want to know \\mathbb{P}r(X_{t+2}=3 \\mid X_t=1), the probability of your secret number being 3 two steps from now, given that your number is currently 1. We can calculate this as \\sum_{k=15} \\mathbb{P}r(X_t+2=3 \\mid X_t+1=k) \\cdot \\mathbb{P}r(X_{t+1}=k \\mid X_t=1), which conveniently is found in the first row and third column of Q_2.\nWe can perform this matrix multiplication easily in R:\n\n\nCode\nQ = matrix(c(0.0, 0.5, 0.0, 0.0, 0.5,\n             0.5, 0.0, 0.5, 0.0, 0.0,\n             0.0, 0.5, 0.0, 0.5, 0.0,\n             0.0, 0.0, 0.5, 0.0, 0.5,\n             0.5, 0.0, 0.0, 0.5, 0.0), \n           nrow=5, byrow=TRUE)\n\nQ %*% Q # Matrix multiplication in R. This is Q^2.\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,] 0.50 0.00 0.25 0.25 0.00\n[2,] 0.00 0.50 0.00 0.25 0.25\n[3,] 0.25 0.00 0.50 0.00 0.25\n[4,] 0.25 0.25 0.00 0.50 0.00\n[5,] 0.00 0.25 0.25 0.00 0.50\n\n\n\n\nCode\n(Q %*% Q)[1,3]\n\n\n[1] 0.25\n\n\nTherefore, if your secret number is currently 1, the probability that the number will be 3 two steps from now is .25.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L03.html#stationary-distribution",
    "href": "C2-L03.html#stationary-distribution",
    "title": "34  M1L3 - Monte Carlo estimation",
    "section": "35.4 Stationary distribution",
    "text": "35.4 Stationary distribution\nSuppose we want to know the probability distribution of the your secret number in the distant future, say \\mathbb{P}r(X_{t+h} \\mid X_t) where h is a large number. Let’s calculate this for a few different values of h.\n\n\nCode\nQ5 = Q %*% Q %*% Q %*% Q %*% Q # h=5 steps in the future\nround(Q5, 3)\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 0.062 0.312 0.156 0.156 0.312\n[2,] 0.312 0.062 0.312 0.156 0.156\n[3,] 0.156 0.312 0.062 0.312 0.156\n[4,] 0.156 0.156 0.312 0.062 0.312\n[5,] 0.312 0.156 0.156 0.312 0.062\n\n\n\n\nCode\nQ10 = Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q # h=10 steps in the future\nround(Q10, 3)\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 0.248 0.161 0.215 0.215 0.161\n[2,] 0.161 0.248 0.161 0.215 0.215\n[3,] 0.215 0.161 0.248 0.161 0.215\n[4,] 0.215 0.215 0.161 0.248 0.161\n[5,] 0.161 0.215 0.215 0.161 0.248\n\n\n\n\nCode\nQ30 = Q\nfor (i in 2:30) {\n  Q30 = Q30 %*% Q\n}\nround(Q30, 3) # h=30 steps in the future\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 0.201 0.199 0.200 0.200 0.199\n[2,] 0.199 0.201 0.199 0.200 0.200\n[3,] 0.200 0.199 0.201 0.199 0.200\n[4,] 0.200 0.200 0.199 0.201 0.199\n[5,] 0.199 0.200 0.200 0.199 0.201\n\n\nNotice that as the future horizon gets more distant, the transition distributions appear to converge. The state you are currently in becomes less important in determining the more distant future. If we let h get really large, and take it to the limit, all the rows of the long-range transition matrix will become equal to (.2,.2,.2,.2,.2). That is, if you run the Markov chain for a very long time, the probability that you will end up in any particular state is 1/5=.2 for each of the five states. These long-range probabilities are equal to what is called the stationary distribution of the Markov chain.\nThe stationary distribution of a chain is the initial state distribution for which performing a transition will not change the probability of ending up in any given state. That is,\n\n\nCode\nc(0.2, 0.2, 0.2, 0.2, 0.2) %*% Q\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]  0.2  0.2  0.2  0.2  0.2\n\n\nOne consequence of this property is that once a chain reaches its stationary distribution, the stationary distribution will remain the distribution of the states thereafter.\nWe can also demonstrate the stationary distribution by simulating a long chain from this example.\n\n\nCode\nn = 5000\nx = numeric(n)\nx[1] = 1 # fix the state as 1 for time 1\nfor (i in 2:n) {\n  x[i] = sample.int(5, size=1, prob=Q[x[i-1],]) # draw the next state from the intergers 1 to 5 with probabilities from the transition matrix Q, based on the previous value of X.\n}\n\n\nNow that we have simulated the chain, let’s look at the distribution of visits to the five states.\n\nCode\ntable(x) / n\n\n\n\n\nTable 35.1\n\n\n\nx\n     1      2      3      4      5 \n0.1996 0.2020 0.1980 0.1994 0.2010 \n\n\n\n\nThe overall distribution of the visits to the states is approximately equal to the stationary distribution.\nAs we have just seen, if you simulate a Markov chain for many iterations, the samples can be used as a Monte Carlo sample from the stationary distribution. This is exactly how we are going to use Markov chains for Bayesian inference. In order to simulate from a complicated posterior distribution, we will set up and run a Markov chain whose stationary distribution is the posterior distribution.\nIt is important to note that the stationary distribution doesn’t always exist for any given Markov chain. The Markov chain must have certain properties, which we won’t discuss here. However, the Markov chain algorithms we’ll use in future lessons for Monte Carlo estimation are guaranteed to produce stationary distributions.\n\n35.4.1 Continuous example\nThe continuous random walk example we gave earlier does not have a stationary distribution. However, we can modify it so that it does have a stationary distribution.\nLet the transition distribution be \\mathbb{P}r(X_{t + 1}\\mid X_t = x_t)=N(\\phi x_t,1) where -1 &lt; \\phi &lt; 1. That is, the probability distribution for the next state is Normal with variance 1 and mean equal to ϕ times the current state. As long as \\phi is between −1 and 1, then the stationary distribution will exist for this model.\nLet’s simulate this chain for \\phi=−0.6.\n\n\nCode\nset.seed(38)\n\nn = 1500\nx = numeric(n)\nphi = -0.6\n\nfor (i in 2:n) {\n  x[i] = rnorm(1, mean=phi*x[i-1], sd=1.0)\n}\n\nplot.ts(x)\n\n\n\n\n\n\n\n\nFigure 35.1: Simulated AR(1) process with phi=-0.6\n\n\n\n\n\nThe theoretical stationary distribution for this chain is normal with mean 0 and variance 1/(1−\\phi^2), which in our example approximately equals 1.562. Let’s look at a histogram of our chain and compare that with the theoretical stationary distribution.\n\n\\text{Var}_{\\text{stationary}} = \\frac{1}{1-\\phi^2} \\qquad\n\\tag{35.6}\n\n\nCode\nhist(x, freq=FALSE)\ncurve(dnorm(x, mean=0.0, sd=sqrt(1.0/(1.0-phi^2))), col=\"red\", add=TRUE)\nlegend(\"topright\", legend=\"theoretical stationary\\ndistribution\", col=\"red\", lty=1, bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 35.2: Histogram of simulated AR(1) process with theoretical stationary distribution\n\n\n\n\n\nIt appears that the chain has reached the stationary distribution. Therefore, we could treat this simulation from the chain like a Monte Carlo sample from the stationary distribution, a normal with mean 0 and variance 1.562.\nBecause most posterior distributions we will look at are continuous, our Monte Carlo simulations with Markov chains will be similar to this example.",
    "crumbs": [
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>M1L3 - Monte Carlo estimation</span>"
    ]
  },
  {
    "objectID": "C2-L04.html",
    "href": "C2-L04.html",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "",
    "text": "35.1 Markov chain Monte Carlo (MCMC)\nMetropolis-Hastings (M-H) is an algorithm that allows us to sample from a generic probability distribution (which we will call the target distribution), even if we do not know the normalizing constant. To do this, we construct and sample from a Markov chain whose stationary distribution is the target distribution. It consists of picking an arbitrary starting value and iteratively accepting or rejecting candidate samples drawn from another distribution, one that is easy to sample.",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#sec-m2l4-metropolis-hastings",
    "href": "C2-L04.html#sec-m2l4-metropolis-hastings",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "",
    "text": "ImportantWhy use M-H or MCMC?\n\n\n\nWe will use M-H or other MCMC methods if there is no easy way to simulate independent draws from the target distribution. This can be due to non-conjugate priors, challenges in evaluating the normalizing constant or multiple explanatory variables.",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#sec-",
    "href": "C2-L04.html#sec-",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "35.2 The Metropolis-Hastings Algorithm (Video)",
    "text": "35.2 The Metropolis-Hastings Algorithm (Video)\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\n Let’s say we wish to produce samples from a target distribution \\mathbb{P}r(\\theta) \\propto g(\\theta), where we don’t know the normalizing constant (since \\int g(\\theta)d\\theta is hard or impossible to compute), so we only have g(\\theta), the unnormalized joint probability to work with. The Metropolis-Hastings algorithm proceeds as follows.\n\nSelect an initial value \\theta_0.\nFor i=1,\\dots,m repeat the following steps:\n\nDraw a candidate sample \\theta^∗ from a proposal distribution  q(\\theta^* \\mid \\theta_{i−1}) .\nCompute the ratio \\alpha = \\frac{g(\\theta^*) / q(\\theta^* \\mid \\theta_{i-1}) }{g(\\theta_{i-1}) / q(\\theta_{i-1} \\mid \\theta^*)} = \\frac{g(\\theta^*)q(\\theta_{i-1} \\mid \\theta^*)}{g(\\theta_{i-1})q(\\theta^* \\mid \\theta_{i-1})}\n\nIf \\alpha\\ge 1, then accept \\theta^∗ and set \\theta_i=\\theta^∗.\nIf 0&lt;\\alpha&lt;1:\n\naccept \\theta^∗ and set \\theta_i=\\theta^∗ with probability \\alpha,\nreject \\theta^∗ and set \\theta_i=\\theta_{i−1} with probability 1−\\alpha.\n\n\n\n\nproposal distribution q\n\n\n\n\n\nImportantCorrection to the proposal distribution\n\n\n\nSteps 2.b and 2.c act as a correction  since the proposal distribution is not the target distribution. At each step in the chain, we draw a random candidate value of the parameter and decide whether to “move” the chain there or remain where we are. If the proposed move to the candidate is “advantageous,” (\\alpha \\ge 1) we “move” there and if it is not “advantageous,” we still might move there, but only with probability \\alpha. Since our decision to “move” to the candidate only depends on where the chain currently is, this is a Markov chain.\n\n\ncorrection",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#proposal-distribution-q",
    "href": "C2-L04.html#proposal-distribution-q",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "35.3 Proposal distribution q",
    "text": "35.3 Proposal distribution q\nOne careful choice we must make is the candidate generating distribution q(\\theta^∗\\mid\\theta_{i−1}). It may or may not depend on the previous iteration’s value of \\theta.\n\n\n\n\n\n\nImportantIndependent Metropolis-Hastings\n\n\n\nThe simpler case is when the proposal distribution q does not depend on the previous value. We then write it as q(\\theta^∗). This arises if it is always the same distribution. We call this case independent Metropolis-Hastings. If we use independent M-H, q(\\theta) should be as similar as possible to \\mathbb{P}r(\\theta).\n\n\n\n\n\n\n\n\nImportantRandom-Walk Metropolis-Hastings\n\n\n\nIn the more general case, the proposal distribution takes the form q(\\theta^∗\\mid\\theta_{i−1}) with dependence on the previous iteration, is Random-Walk Metropolis-Hastings. Here, the proposal distribution is centered on \\theta_{i−1}.\nFor instance, it might be a Normal distribution with mean \\theta_{i−1}. Because the Normal distribution is symmetric, this example comes with another advantage: q(\\theta^* \\mid \\theta_{i−1})=q(\\theta_{i−1}∣\\theta^*) causing it to cancel out when we calculate \\alpha.\nThus, in Random-Walk M-H where the candidate is drawn from a Normal with mean \\theta_{i−1} and constant variance, the acceptance ratio is simply \\alpha=g(\\theta^∗)/g(\\theta_{i−1}).",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#acceptance-rate-α",
    "href": "C2-L04.html#acceptance-rate-α",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "35.4 Acceptance rate α",
    "text": "35.4 Acceptance rate α\nClearly, not all candidate draws are accepted, so our Markov chain sometimes “stays” where it is, possibly for many iterations. How often you want the chain to accept candidates depends on the type of algorithm you use. If you approximate \\mathbb{P}r(\\theta) with q(\\theta^∗) and always draw candidates from that, accepting candidates often is good; it means q(\\theta^∗) is approximating \\mathbb{P}r(\\theta) well. However, you still may want q to have a larger variance than p and see some rejection of candidates as an assurance that q is covering the space well.\nAs we will see in coming examples, a high acceptance rate for the Random-Walk Metropolis-Hastings sampler is not a good thing. If the random walk is taking too small of steps, it will accept often but will take a very long time to fully explore the posterior. If the random walk is taking too large of steps, many of its proposals will have a low probability and the acceptance rate will be low, wasting many draws. Ideally, a random walk sampler should accept somewhere between 23% and 50% of the candidates proposed.\nIn the next segment, we will see a demonstration of this algorithm used in a discrete case, where we can show mathematically that the Markov chain converges to the target distribution. In the following segment, we will demonstrate coding a Random-Walk Metropolis-Hastings algorithm in R to solve one of the problems from the end of Lesson 2.",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#demonstration-of-a-discrete-case",
    "href": "C2-L04.html#demonstration-of-a-discrete-case",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "35.5 Demonstration of a Discrete case",
    "text": "35.5 Demonstration of a Discrete case\n\n\n\n\nMCMC Coin Flip Example\n\nThe following segment is by Herbert Lee, a professor of statistics and applied mathematics at the University of California, Santa Cruz.\nThe following is a demonstration of using Markov chain Monte Carlo, used to estimate posterior probabilities in a simplified case, where we can actually work out the correct answer in closed form. We demonstrate that the Metropolis-Hastings algorithm is indeed working, and giving us the right answer.\nIf you recall from the previous course, the example where your brother or maybe your sister, has a loaded coin that you know will come up heads 70% of the time. But they come to you with some coin, you’re not sure if it’s the loaded coin or a fair coin, and they want to make a bet with you. And you have to figure out which coin this is.\nSuppose you have a prior probability that it’s a 60% probability, that they’ll bring a loaded coin to you. They let you flip it five times, and you get two heads and three tails.\nAnd then you need to figure out, what’s your posterior probability that this is a loaded coin.\nOur unknown parameter \\theta, can either take the values fair or loaded.\n\n\\theta = \\{\\text{fair, loaded} \\}\n\\tag{35.1}\nOur prior for \\theta is the probability of theta equals loaded, is 0.6.\n\n\\mathbb{P}r(\\theta=\\text{loaded})=0.6 \\qquad  \\text{(prior)}\n\\tag{35.2}\nOur likelihood will follow a Binomial distribution, depending upon the value of \\theta.\n\nf(x\\mid \\theta) = {5 \\choose x} \\frac{1}{2}^5\\mathbb{I}_{\\theta=\\text{fair}}+  {5 \\choose x} (.7)^x(.3)^{5-x}\\mathbb{I}_{\\theta=\\text{loaded}}  \\qquad  \\text{(likelihood)}\n\\tag{35.3}\nOur posterior then, we can look at posterior for theta, given that we saw x=2 equals two heads, posterior is the likelihood times the prior, divided by a normalizing constant.\n\n  \\begin{aligned}\n    f(\\theta \\mid X=2) &=\n      \\frac{ \\frac{1}{2}^5(0.4)\\mathbb{I}_{(\\theta=\\text{fair})} + (.7)^2(.3)^{3}(.6)\\mathbb{I}_{(\\theta=\\text{loaded})}}\n           { \\frac{1}{2}^5(0.4) + (.7)^2(.3)^{3}(.6)}  \n  \\\\&=\\frac{ 0.0125 \\mathbb{I}_{(\\theta=\\text{fair})} + 0.00794 \\mathbb{I}_{(\\theta=\\text{loaded})}}\n           { 0.0125 + 0.00794}\n  \\\\&= 0.612 \\mathbb{I}_{(\\theta=\\text{fair})} + 0.388 \\mathbb{I}_{(\\theta=\\text{loaded})}\n  \\qquad  \\text{(posterior) }\n  \\end{aligned}\n\\tag{35.4}\nIn this case, we can work out the binomial and our prior. And we see that we get these expressions at the end. We get posterior probability of \\theta is loaded given that we saw two heads, to be 0.388.\n\n\\therefore \\mathbb{P}r(\\theta=\\text{loaded}\\mid X=2) = 0.388 \\qquad  \\text{(posterior conditional probability ) }\n\\tag{35.5}\nThis is all review from the previous course so far.\nBut suppose we had a more complicated problem, where we couldn’t work this all out in closed form? We’ll know the likelihood and the prior, but we may not be able to get this normalizing constant. Can we instead do this by simulation? And indeed, yes we can.\nWe can do this with Markov chain Monte Carlo. In particular, using the Metropolis-Hastings algorithm. What we’ll do is, we’ll set up a Markov chain whose equilibrium distribution has this posterior distribution. So we’ll consider a Markov chain with two states, theta equals fair and theta equals loaded. And we’ll allow the chain to move between those two states, with certain transition probabilities. We set this up using this using the Metropolis-Hastings algorithm.\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\nSo under the Metropolis-Hastings algorithm, step one is we start at an arbitrary location. And in this case, we can\n\nstart at either \\theta \\ne \\text{fair}, or \\theta \\ne \\text{loaded}.\n\nIt does not really matter where we start, we’ll be moving back and forth and we’re going to look at the long-term running average, the long-term simulations.\nSo the key is we’ll be simulating.\n\nRun m simulations and in each iteration, we’ll propose a candidate and either accept it or reject it.\n\n\nSo the first part is we’re proposing a new candidate. We’ll call this candidate \\theta^*, and we’re going to propose it be the other state compared to where we are now. Where we are now is \\theta_{i-1}, and so we’ll propose to move to \\theta^*.\n\nIf our current state is fair, we’ll propose \\theta^*=\\text{loaded}.\nIf our current state is loaded, we’ll propose \\theta^*=\\text{fair}.\n\n\nwhat’s our acceptance probability alpha?\nThe general form for \\alpha is:\n\n\\begin {aligned}\n\\alpha &= {\n            { g(\\theta^*)     / q(\\theta^*     \\mid  \\theta_{i-1}) }\n      \\over {g(\\theta_{i-1}) / q(\\theta_{i-1} \\mid  \\theta^*)     }\n      }\n\\\\      &= {\n            { f(x=2 \\mid \\theta^*) f(\\theta^*)     / 1 }\n      \\over { f(x=2 \\mid \\theta_{i-1})f(\\theta_{i-1}) / 1    }\n} \\qquad \\text {(sub. g,q)}\n\\end{aligned}\n\\tag{35.6}\nIn this case,\n\ng() is our un-normalized likelihood times prior\nq(), the proposal distribution, is, in this case, since we always accept the opposite state deterministically i.e. \\theta^*=\\neg \\theta{i_1} with P=1\nIf \\theta^* = \\text{loaded} \\implies \\alpha = {0.00794 \\over 0.0125}=0.635\nIf \\theta^* = \\text{fair} \\implies \\alpha = { 0.0125 \\over 0.00794}=1.574\n\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\nGiven these probabilities, we then can do the acceptance or rejection step.\n\n\\begin{cases}\n\\text{ accept } \\theta^* \\text { and set } \\theta_i=\\text{fair} & \\text{If } \\theta^*=\\text{fair,  } \\alpha&gt;1\n\\\\ \\begin {cases}\n   \\text{ accept } \\theta^* \\text{  and set } \\theta_i=\\text{loaded} &  \\text{ With probability } 0.635\n\\\\ \\text{ reject } \\theta^* \\text{ and set } \\theta_i=\\text{fair}     &  \\text{ Otherwise }\n\\end{cases} & \\text{If } \\theta^*=\\text{loaded, } \\alpha=.635\n\\end{cases}\n\nIf the \\theta^*=\\text{loaded} \\implies \\alpha=0.635. So we accept theta star with probability 0.635. And if we accept it. Set \\theta_i=\\text{loaded} Otherwise, set \\theta_i = \\theta_{i- 1}, if we do not accept, it stays in that same old fair state.\nWe can draw this out as a Markov chain with two states, Fair and ‘loaded’. If it’s in the ‘loaded’ state, it will move with probability one to the fair state. If it’s in the fair state, it will move with a probability of 0.635 to the ‘loaded’ state. And with a probability of 0.365 it will stay in the fair state.\n\n\n\n\nstate diagram\n\nAnd so here’s a little diagram for this Markov chain with two states. In which case it will move back and forth with certain probabilities.\nThus, if we wanted to find our posterior probability , f(\\theta=\\text{loaded} \\mid x=2). We can simulate from this Markov chain using these transition probabilities. And observe the fraction of time that it spends in the state theta equals ‘loaded’. And this gives us a good estimate of the posterior probability that it’s the ‘loaded’ coin. In this particular case, we can also show that this gives us the theoretical right answer.\nIf you’ve seen a little bit of the theory of Markov chains. We can say that a Markov chain with transition probability capital P, has stationary distribution \\Pi.\n\n\\pi P = \\pi \\qquad \\text{(def. stationary distribution)}\n\\tag{35.7}\nHere we have a transition probability matrix P, where we can think about ‘fair’ and ‘loaded’. Moving from the ‘fair’ state, remaining in the ‘fair’ state happens with a probability of 0.365 and it moves from ‘fair’ to ‘loaded’, with a probability of 0.635. If it’s in the ‘loaded’ state, we’ll move to the ‘fair’ state with probability one, and it will stay in the ‘loaded’ state with probability 0.\n\nP=\\begin{bmatrix}\n   0.365 & 0.635\n\\\\ 1 & 0\n\\end{bmatrix}\n\nIn this case, we want our stationary distribution to be the posterior probabilities.\n\n\\Pi=\\begin{bmatrix}\n0.612 & 0.388 \\\\\n\\end{bmatrix}\n\nWhich you can recall are 0.612 of being ‘fair’ and 0.388 of being ‘loaded’. And so indeed, if you do just the minimal amount of matrix algebra, you can see that 0.612, 0.388 Multiplied by this matrix, 0.365, 0.635, 1, 0, does indeed give you 0.612 and 0.388, at least to within rounding error.\n\n\\begin{aligned}\n  \\Pi P &=\n  \\begin{bmatrix} 0.612 & 0.388 \\end{bmatrix}\n  \\begin{bmatrix} 0.365 & 0.635 \\\\ 1 & 0 \\end{bmatrix}\n  \\\\&= \\begin{bmatrix}0.612 & 0.388 \\end{bmatrix}\n  \\\\&= \\Pi\n\\end{aligned}\n\\tag{35.8}\nThus in this case we can see, that we do get the correct stationary distribution for the Markov chain using the Metropolis–Hastings algorithm. And that when we simulate it, we do get correct estimates then of the posterior probabilities.\nThis is a nice simple example where we can work out the posterior probabilities in closed form. We don’t need to run Markov chain Monte Carlo. But this method is very powerful because all we need is to be able to evaluate the likelihood and the prior, we don’t need to evaluate the full posterior and get that normalizing constant. And so this applies to a much broader range of more complicated problems. Where we can use Markov chain Monte Carlo to simulate, to be able to get these probabilities. We’ll make good use of this in the rest of this course.",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#random-walk-with-normal-likelihood-t-prior",
    "href": "C2-L04.html#random-walk-with-normal-likelihood-t-prior",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "35.6 Random walk with Normal likelihood, t prior",
    "text": "35.6 Random walk with Normal likelihood, t prior\nRecall the model from the last segment of Lesson 2 where the data are the percent change in total personnel from last year to this year for n=10 companies. We used a normal likelihood with known variance and t distribution for the prior on the unknown mean. Suppose the values are y=(1.2,1.4,−0.5,0.3,0.9,2.3,1.0,0.1,1.3,1.9). Because this model is not conjugate, the posterior distribution is not in a standard form that we can easily sample. To obtain posterior samples, we will set up a Markov chain whose stationary distribution is this posterior distribution.\nRecall that the posterior distribution is\n\n\\mathbb{P}r(\\mu \\mid y_1, \\ldots, y_n) \\propto \\frac{\\exp[ n ( \\bar{y} \\mu - \\mu^2/2)]}{1 + \\mu^2}\n\nThe posterior distribution on the left is our target distribution and the expression on the right is our g(\\mu).\nThe first thing we can do in R is write a function to evaluate g(\\mu). Because posterior distributions include likelihoods (the product of many numbers that are potentially small), g(\\mu) might evaluate to such a small number that to the computer, it is effectively zero. This will cause a problem when we evaluate the acceptance ratio \\alpha. To avoid this problem, we can work on the log scale, which will be more numerically stable. Thus, we will write a function to evaluate\n\n\\log(g(\\mu)) = n ( \\bar{y} \\mu - \\mu^2/2) - \\log(1 + \\mu^2)\n\nThis function will require three arguments, \\mu, \\bar{y}, and n.\n\n\nCode\nlg = function(mu, n, ybar) {\n  mu2 = mu^2\n  n * (ybar * mu - mu2 / 2.0) - log(1 + mu2)\n}\n\n\nNext, let’s write a function to execute the Random-Walk Metropolis-Hastings sampler with Normal proposals.\n\n\nCode\nmh = function(n, ybar, n_iter, mu_init, cand_sd) {\n  ## Random-Walk Metropolis-Hastings algorithm\n  \n  ## Step 1, initialize\n  mu_out = numeric(n_iter)\n  accpt = 0\n  mu_now = mu_init\n  lg_now = lg(mu=mu_now, n=n, ybar=ybar)\n  \n  ## Step 2, iterate\n  for (i in 1:n_iter) {\n    ## step 2a\n    mu_cand = rnorm(n=1, mean=mu_now, sd=cand_sd) # draw a candidate\n    \n    ## Step 2b\n    lg_cand = lg(mu=mu_cand, n=n, ybar=ybar) # evaluate log of g with the candidate\n    lalpha = lg_cand - lg_now # log of acceptance ratio\n    alpha = exp(lalpha)\n    \n    ## step 2c\n    u = runif(1) # draw a uniform variable which will be less than alpha with probability min(1, alpha)\n    if (u &lt; alpha) { # then accept the candidate\n      mu_now = mu_cand\n      accpt = accpt + 1 # to keep track of acceptance\n      lg_now = lg_cand\n    }\n    \n    ## collect results\n    mu_out[i] = mu_now # save this iteration's value of mu\n  }\n  \n  ## return a list of output\n  list(mu=mu_out, accpt=accpt/n_iter)\n}\n\n\nNow, let’s set up the problem.\n\n\nCode\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nybar = mean(y)\nn = length(y)\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nFinally, we’re ready to run the sampler! Let’s use m=1000 iterations and proposal standard deviation (which controls the proposal step size) 3.0, and initial value at the prior median 0.\n\n\nCode\nset.seed(43) # set the random seed for reproducibility\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=3.0)\nstr(post)\n\n\nList of 2\n $ mu   : num [1:1000] -0.113 1.507 1.507 1.507 1.507 ...\n $ accpt: num 0.122\n\n\n\n\nCode\nlibrary(\"coda\")\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nThis last plot is called a trace plot. It shows the history of the chain and provides basic feedback about whether the chain has reached its stationary distribution.\nIt appears our proposal step size was too large (acceptance rate below 23%). Let’s try another.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.05)\npost$accpt\n\n\n[1] 0.946\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nOops, the acceptance rate is too high (above 50%). Let’s try something in between.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.9)\npost$accpt\n\n\n[1] 0.38\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nWhich looks good. Just for fun, let’s see what happens if we initialize the chain at some far-off value.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=30.0, cand_sd=0.9)\npost$accpt\n\n\n[1] 0.387\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nIt took awhile to find the stationary distribution, but it looks like we succeeded! If we discard the first 100 or so values, it appears like the rest of the samples come from the stationary distribution, our posterior distribution! Let’s plot the posterior density against the prior to see how the data updated our belief about \\mu.\n\n\nCode\npost$mu_keep = post$mu[-c(1:100)] # discard the first 200 samples\nplot(density(post$mu_keep, adjust=2.0), main=\"\", xlim=c(-1.0, 3.0), xlab=expression(mu)) # plot density estimate of the posterior\ncurve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\npoints(ybar, 0, pch=19) # sample mean\n\ncurve(0.017*exp(lg(mu=x, n=n, ybar=ybar)), from=-1.0, to=3.0, add=TRUE, col=\"blue\") # approximation to the true posterior in blue\n\n\n\n\n\n\n\n\n\nThese results are encouraging, but they are preliminary. We still need to investigate more formally whether our Markov chain has converged to the stationary distribution. We will explore this in a future lesson.\nObtaining posterior samples using the Metropolis-Hastings algorithm can be time-consuming and require some fine-tuning, as we’ve just seen. The good news is that we can rely on software to do most of the work for us. In the next couple of videos, we’ll introduce a program that will make posterior sampling easy.",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#setup",
    "href": "C2-L04.html#setup",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "36.1 Setup",
    "text": "36.1 Setup\n\n36.1.1 Introduction to JAGS\nThere are several software packages available that will handle the details of MCMC for us. See the supplementary material for a brief overview of options.\nThe package we will use in this course is JAGS (Just Another Gibbs Sampler) by Martyn Plummer. The program is free, and runs on Mac OS, Windows, and Linux. Better yet, the program can be run using R with the rjags and R2jags packages.\nIn JAGS, we can specify models and run MCMC samplers in just a few lines of code; JAGS does the rest for us, so we can focus more on the statistical modeling aspect and less on the implementation. It makes powerful Bayesian machinery available to us as we can fit a wide variety of statistical models with relative ease.\n\n\n36.1.2 Installation and setup\nThe starting place for JAGS users is mcmc-jags.sourceforge.net. At this site, you can find news about the features of the latest release of JAGS, links to program documentation, as well as instructions for installation.\nThe documentation is particularly important. It is available under the files page link in the Manuals folder.\nAlso under the files page, you will find the JAGS folder where you can download and install the latest version of JAGS. Select the version and operating system, and follow the instructions for download and installation.\nOnce JAGS is installed, we can immediately run it from R using the rjags package. The next segment will show how this is done.",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04.html#modeling-in-jags",
    "href": "C2-L04.html#modeling-in-jags",
    "title": "35  M2L4 - Metropolis-Hastings",
    "section": "36.2 Modeling in JAGS",
    "text": "36.2 Modeling in JAGS\nThere are four steps to implementing a model in JAGS through R:\n\nSpecify the model.\nSet up the model.\nRun the MCMC sampler.\nPost-processing.\n\nWe will demonstrate these steps with our running example with the data are the percent change in total personnel from last year to this year for n=10 companies. We used a normal likelihood with known variance and t distribution for the prior on the unknown mean.\n\n36.2.1 1. Specify the model\nIn this step, we give JAGS the hierarchical structure of the model, assigning distributions to the data (the likelihood) and parameters (priors). The syntax for this step is very similar to R, but there are some key differences.\n\n\nCode\nlibrary(\"rjags\")\n\nmod_string = \" model {\n  for (i in 1:n) {\n    y[i] ~ dnorm(mu, 1.0/sig2)\n  }\n  mu ~ dt(0.0, 1.0/1.0, 1.0) # location, inverse scale, degrees of freedom\n  sig2 = 1.0\n} \"\n\n\nOne of the primary differences between the syntax of JAGS and R is how the distributions are parameterized. Note that the normal distribution uses the mean and precision (instead of variance). When specifying distributions in JAGS, it is always a good idea to check the JAGS user manual here in the chapter on Distributions.\n\n\n36.2.2 2. Set up the model\n\n\nCode\nset.seed(50)\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nn = length(y)\n\ndata_jags = list(y=y, n=n)\nparams = c(\"mu\")\n\ninits = function() {\n  inits = list(\"mu\"=0.0)\n} # optional (and fixed)\n\nmod = jags.model(textConnection(mod_string), data=data_jags, inits=inits)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 10\n   Unobserved stochastic nodes: 1\n   Total graph size: 15\n\nInitializing model\n\n\nThere are multiple ways to specify initial values here. They can be explicitly set, as we did here, or they can be random, i.e., list(\"mu\"=rnorm(1)). Also, we can omit the initial values, and JAGS will provide them.\n\n\n36.2.3 3. Run the MCMC sampler\n\n\nCode\nupdate(mod, 500) # burn-in\n\nmod_sim = coda.samples(model=mod, variable.names=params, n.iter=1000)\n\n\nWe will discuss more options to the coda.samples function in coming examples.\n\n\n36.2.4 4. Post-processing\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 1501:2500\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n       0.89477        0.32375        0.01024        0.01261 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n0.2710 0.6536 0.8878 1.1394 1.4989 \n\n\n\n\nCode\nlibrary(\"coda\")\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\nWe will discuss post processing further, including convergence diagnostics, in a coming lesson.",
    "crumbs": [
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>M2L4 - Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "C2-L04-Ex1.html",
    "href": "C2-L04-Ex1.html",
    "title": "36  Homework on the Metropolis-Hastings algorithm",
    "section": "",
    "text": "Exercise 36.1  In which situation would we choose to use a Metropolis-Hastings (or any MCMC) sampler rather than straightforward Monte Carlo sampling?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nMonte Carlo estimation is easier than calculating the integral required to obtain the mean of the target distribution.\nThe target distribution follows a Markov chain.\nThe data (likelihood) come from a Markov chain.\nThere is no easy way to simulate independent draws from the target distribution.\n\n\n\n\n\nExercise 36.2 Which of the following candidate-generating distributions would be best for an independent Metropolis-Hastings algorithm to sample the target distribution whose PDF is shown below?\nNote: In independent Metropolis-Hastings, the candidate-generating distribution q does not depend on the previous iteration of the chain.\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\n\n\n\n\nRecall, in independent M-H, the candidate-generating distribution q() should be similar to target distribution g().\n\n\n\n\nExercise 36.3  If we employed an independent Metropolis-Hastings algorithm (in which the candidate-generating distribution q does not depend on the previous iteration of the chain), what would happen if we skipped the acceptance ratio step and always accepted candidate draws?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe resulting sample would be a Monte Carlo simulation from q instead of from the target distribution.\nEach draw could be considered as a sample from the target distribution.\nThe chain would explore the posterior distribution very slowly, requiring more samples.\nThe sampler would become more efficient because we are no longer discarding draws.\n\nAccepting all candidates just means we are simulating from the candidate-generating distribution. The acceptance step in the algorithm acts as a correction, so that the samples reflect the target distribution more than the candidate-generating distribution.\n\n\n\n\nExercise 36.4 M-H\nIf the target distribution \\mathbb{P}r(θ)∝g(θ) is for a positive-valued random variable so that \\mathbb{P}r(θ) contains the indicator function I_{θ&gt;0}(θ), what would happen if a random walk Metropolis sampler proposed the candidate θ∗=−0.3?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe candidate would be accepted with probability 0.3 because g(\\theta^*) = \\lvert \\theta^* \\rvert , yielding an acceptance ratio \\alpha=0.3.\nThe candidate would be accepted with probability 1 because g(\\theta^∗)=0, yielding an acceptance ratio \\alpha=1.\nThe candidate would be accepted with probability 1 because g(\\theta^∗)=0, yielding an acceptance ratio \\alpha=\\infty.\nThe candidate would be rejected with probability 1 because g(\\theta^∗)=0, yielding an acceptance ratio \\alpha=0.\n\nThis strategy usually works, but sometimes runs into problems.\nAnother solution is to draw candidates for the logarithm of \\theta (which of course has a different target distribution that you must derive) using Normal proposals\n\n\n\n\nExercise 36.5  Suppose we use a random walk Metropolis sampler with normal proposals (centered on the current value of the chain) to sample from the target distribution whose PDF is shown below. The chain is currently at \\theta_i=15.0. Which of the other points, if used as a candidate θ^∗ for the next step, would yield the largest acceptance ratio \\alpha?M-H\n\n\n\nc2l05-ex5-01\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nA θ^∗=3.1\nB θ^∗=9.8\nC θ^∗=20.3\nD θ^∗=26.1\n\nB is the only point with a target density value (close to 0.09) higher than that of θi (close to 0.04).\nSince this is a random walk Metropolis sampler with symmetric proposal distribution, the expression for calculating the acceptance ratio for iteration i+1 is \\alpha=g(θ^∗)/g(θ_{i}). In this case α would be close to 2, whereas for A, C, and D, we have α&lt;1. If point B were proposed, it would be accepted in this case.\n\n\n\n\nExercise 36.6 M-H\nSuppose you are using a random walk Metropolis sampler with Normal proposals. After sampling the chain for 1000 iterations, you notice that the acceptance rate for the candidate draws is only 0.02. Which corrective action is most likely to help you approach a better acceptance rate (between 0.23 and 0.50)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nDecrease the variance of the normal proposal distribution q.\nIncrease the variance of the normal proposal distribution q.\nReplace the normal proposal distribution with a uniform proposal distribution centered on the previous value and variance equal to that of the old normal proposal distribution.\nFix the mean of the normal proposal distribution at the last accepted candidate’s value. Use the new mean for all future proposals.\n\nA low acceptance rate in a random walk Metropolis sampler usually indicates that the candidate-generating distribution is too wide and is proposing draws too far away from most of the target mass. Increasing the variance would likely make the problem worse, so we should decrease the variance.\n\n\n\n\nExercise 36.7 M-H\nSuppose we use a random walk Metropolis sampler to sample from the target distribution \\mathbb{P}r(\\theta)\\propto g(\\theta) and propose candidates \\theta^∗ using the \\text{Unif}(\\theta_{i−1}−\\epsilon,\\theta_{i−1}+\\epsilon) distribution where \\epsilon is some positive number and \\theta_{i−1} is the previous iteration’s value of the chain. What is the correct expression for calculating the acceptance ratio α in this scenario?\nHint: Notice that the \\text{Unif}(\\theta_{i−1}−\\epsilon,\\theta_{i−1}+\\epsilon) distribution is centered on the previous value and is symmetric (since the PDF is flat and extends the same distance \\epsilon on either side).\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\alpha = \\frac{ \\text{Unif}(\\theta^* \\mid \\theta_{i-1} - \\epsilon, \\, \\theta_{i-1} + \\epsilon) }{ \\text{Unif}(\\theta_{i-1} \\mid \\theta^* - \\epsilon, \\, \\theta^* + \\epsilon) } Where \\text{Unif}(\\theta | a,b) represents the PDF of a \\text{Unif}(a,b) evaluated at \\theta.\n\\alpha = \\frac{ g(\\theta_{i-1}) }{ g(\\theta^*) }\n\\alpha = \\frac{ \\text{Unif}(\\theta_{i-1} \\mid \\theta^* - \\epsilon, \\, \\theta^* + \\epsilon) }{ \\text{Unif}(\\theta^* \\mid \\theta_{i-1} - \\epsilon, \\, \\theta_{i-1} + \\epsilon) } Where \\text{Unif}(\\theta \\mid a,b) represents the PDF of a \\text{Unif}(a,b) evaluated at \\theta.\n\\alpha = \\frac{ g(\\theta^*) }{ g(\\theta_{i-1}) }\n\nSince the proposal distribution is centered on the previous value and is symmetric, evaluations of q drop from the calculation of \\alpha.\n\n\n\n\nExercise 36.8 M-H\nThe following code completes one iteration of an algorithm to simulate a chain whose stationary distribution is \\mathbb{P}r(\\theta) \\propto g(\\theta). Which algorithm is employed here?\n# draw candidate\n  theta_cand = rnorm(n=1, mean=0.0, sd=10.0)\n\n# evaluate log of g with the candidate\n  lg_cand = lg(theta=theta_cand)\n  \n# evaluate log of g at the current value\n  lg_now = lg(theta=theta_now)\n  \n# evaluate log of q at candidate\n  lq_cand = dnorm(theta_cand, mean=0.0, sd=10.0, log=TRUE)\n  \n# evaluate log of q at the current value\n  lq_now = dnorm(theta_now, mean=0.0, sd=10.0, log=TRUE)\n\n# calculate the acceptance ratio\n  lalpha = lg_cand + lq_now - lg_now - lq_cand \n  alpha = exp(lalpha)\n  \n# draw a uniform variable that will be less than alpha with probability min(1, alpha)\n  u = runif(1)\n  \n  if (u &lt; alpha) { # then accept the candidate\n    theta_now = theta_cand\n    accpt = accpt + 1 # to keep track of acceptance\n  }\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nRandom walk Metropolis with Normal proposal\nIndependent Metropolis-Hastings (q does not condition on the previous value of the chain) with Uniform proposal\nIndependent Metropolis-Hastings (q does not condition on the previous value of the chain) with Normal proposal\nRandom walk Metropolis with Uniform proposal\n\nNotice that candidates are always drawn from the same N(0,102) distribution, which is not centered on the previous iteration.",
    "crumbs": [
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Homework on the Metropolis-Hastings algorithm</span>"
    ]
  },
  {
    "objectID": "C2-L05.html",
    "href": "C2-L05.html",
    "title": "37  M2L5 - Gibbs sampling",
    "section": "",
    "text": "37.0.1 Multiple parameter sampling and full conditional distributions (Video)\nGibbs sampling is a Gibbs sampling is named after the physicist Josiah Willard Gibbs, in reference to an analogy between the sampling algorithm and statistical physics. The algorithm was described in (Geman and Geman 1984) by brothers Stuart and Donald Geman, and became popularized in the statistics community for calculating marginal probability distribution, especially the posterior distribution. Gibbs sampling is better suited for sampling from models with many variables by sampling them one at a time from a full conditional distribution.\nSo far, we have demonstrated MCMC for a single parameter.\nWhat if we seek the posterior distribution of multiple parameters, and that posterior distribution does not have a standard form?\nOne option is to perform Metropolis-Hastings (M-H) by sampling candidates for all parameters at once, and accepting or rejecting all of those candidates together. While this is possible, it can get complicated.\nAnother (simpler) option is to sample the parameters one at a time.\nAs a simple example, suppose we have a joint posterior distribution for two parameters \\theta and \\phi, written \\mathbb{P}r(\\theta, \\phi \\mid y) \\propto g(\\theta, \\phi). If we knew the value of \\phi, then we would just draw a candidate for \\theta and use g(\\theta, \\phi) to compute our Metropolis-Hastings ratio, and possibly accept the candidate. Before moving on to the next iteration, if we don’t know \\phi, then we can perform a similar update for it. Draw a candidate for \\phi using some proposal distribution and again use g(\\theta, \\phi) to compute our Metropolis-Hastings ratio. Here we pretend we know the value of \\theta by substituting its current iteration from the Markov chain. Once we’ve drawn for both \\theta and \\phi, that completes one iteration and we begin the next iteration by drawing a new \\theta. In other words, we’re just going back and forth, updating the parameters one at a time, plugging the current value of the other parameter into g(\\theta, \\phi).\nThis idea of one-at-a-time updates is used in what we call Gibbs sampling, which also produces a stationary Markov chain (whose stationary distribution is the posterior). If you recall, this is the namesake of JAGS, “just another Gibbs sampler.”",
    "crumbs": [
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>M2L5 - Gibbs sampling</span>"
    ]
  },
  {
    "objectID": "C2-L05.html#sec-conditionally-conjugate-prior-with-normal-likelihood",
    "href": "C2-L05.html#sec-conditionally-conjugate-prior-with-normal-likelihood",
    "title": "37  M2L5 - Gibbs sampling",
    "section": "37.1 Conditionally conjugate prior example with Normal likelihood (Video)",
    "text": "37.1 Conditionally conjugate prior example with Normal likelihood (Video)\n\n37.1.1 Normal likelihood, unknown mean and variance\n\n\n\n\nNormal likelihood, unknown mean and variance\n\n\n\n\nNormal likelihood conjugate prior\n\n\nLet’s return to the example at the end of Lesson 2 where we have normal likelihood with unknown mean and unknown variance. The model is:\n\n\\begin{aligned}\ny_i \\mid \\mu, \\sigma^2 &\\overset{\\text{iid}}{\\sim} \\mathcal{N} ( \\mu, \\sigma^2 ), \\quad i=1,\\ldots,n \\\\\n\\mu &\\sim \\mathcal{N}(\\mu_0, \\sigma_0^2) \\\\\n\\sigma^2 &\\sim \\mathcal{IG}(\\nu_0, \\beta_0)  \\, .\n\\end{aligned}\n\nWe chose a normal prior for \\mu because, in the case where \\sigma^2 is known, the normal is the conjugate prior for \\mu. Likewise, in the case where \\mu is known, the inverse-gamma is the conjugate prior for \\sigma^2. This will give us convenient full conditional distributions in a Gibbs sampler.\nLet’s first work out the form of the full posterior distribution. When we begin analyzing data, the JAGS software will complete this step for us. However, it is extremely valuable to see and understand how this works.\n\n\\begin{aligned}\n\\mathbb{P}r( \\mu, \\sigma^2 \\mid y_1, y_2, \\ldots, y_n ) &\\propto\n\\mathbb{P}r(y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma^2) \\mathbb{P}r(\\mu) \\mathbb{P}r(\\sigma^2)\n\\\\ &= \\prod_{i=1}^n \\mathcal{N} ( y_i \\mid \\mu, \\sigma^2 ) \\times \\mathcal{N}( \\mu \\mid \\mu_0, \\sigma_0^2) \\times \\mathcal{IG}(\\sigma^2 \\mid \\nu_0, \\beta_0)\n\\\\ &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp \\left[ -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right]\n\\\\ & \\qquad \\times\\frac{1}{\\sqrt{2\\pi\\sigma_0^2}} \\exp \\left[ -\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right]\n\\\\ & \\qquad \\times \\frac{\\beta_0^{\\nu_0}}{\\Gamma(\\nu_0)}(\\sigma^2)^{-(\\nu_0 + 1)} \\exp \\left[ -\\frac{\\beta_0}{\\sigma^2} \\right] \\mathbb{I}_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\\\ &\\propto (\\sigma^2)^{-n/2} \\exp \\left[ -\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} \\right]\n\\\\ & \\qquad \\times \\exp \\left[ -\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right] (\\sigma^2)^{-(\\nu_0 + 1)}\n\\\\ & \\qquad \\times \\exp \\left[ -\\frac{\\beta_0}{\\sigma^2} \\right] \\mathbb{I}_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\end{aligned}\n\nFrom here, it is easy to continue on to find the two full conditional distributions we need.\nFirst let’s look at \\mu, assuming \\sigma^2 is known (in which case it becomes a constant and is absorbed into the normalizing constant):\n\n\\begin{aligned}\n\\mathbb{P}r(\\mu \\mid \\sigma^2, y_1, \\ldots, y_n) &\\propto \\mathbb{P}r( \\mu, \\sigma^2 \\mid y_1, \\ldots, y_n )\n\\\\ &\\propto \\exp \\left[ -\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} \\right] \\exp \\left[ -\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right]\n\\\\ &\\propto \\exp \\left[ -\\frac{1}{2} \\left( \\frac{ \\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} + \\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2} \\right) \\right]\n\\\\ &\\propto \\text{N} \\left( \\mu \\mid \\frac{n\\bar{y}/\\sigma^2 + \\mu_0/\\sigma_0^2}{n/\\sigma^2 + 1/\\sigma_0^2} \\frac{1}{n/\\sigma^2 + 1/\\sigma_0^2} \\right)\n\\end {aligned}\n\\tag{37.1}\nwhich we derived in the supplementary material of the last course. So, given the data and \\sigma^2, \\mu follows this normal distribution.\nNow let’s look at \\sigma^2, assuming \\mu is known:\n\n\\begin{aligned}\n\\mathbb{P}r(\\sigma^2 \\mid \\mu, y_1, \\ldots, y_n) & \\propto \\mathbb{P}r( \\mu, \\sigma^2 \\mid y_1, \\ldots, y_n )\n\\\\ &\\propto (\\sigma^2)^{-n/2} \\exp \\left[ -\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2\\sigma^2} \\right] (\\sigma^2)^{-(\\nu_0 + 1)} \\exp \\left[ -\\frac{\\beta_0}{\\sigma^2} \\right] I_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\\\ &\\propto (\\sigma^2)^{-(\\nu_0 + n/2 + 1)} \\exp \\left[ -\\frac{1}{\\sigma^2} \\left( \\beta_0 + \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2} \\right) \\right] I_{\\sigma^2 &gt; 0}(\\sigma^2)\n\\\\ &\\propto \\text{IG}\\left( \\sigma^2 \\mid \\nu_0 + \\frac{n}{2}, \\, \\beta_0 + \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2} \\right)\n\\end{aligned}\n\\tag{37.2}\nThese two distributions provide the basis of a Gibbs sampler to simulate from a Markov chain whose stationary distribution is the full posterior of both \\mu and \\sigma^2. We simply alternate draws between these two parameters, using the most recent draw of one parameter to update the other.\nWe will do this in R in the next segment.",
    "crumbs": [
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>M2L5 - Gibbs sampling</span>"
    ]
  },
  {
    "objectID": "C2-L05.html#computing-example-with-normal-likelihood",
    "href": "C2-L05.html#computing-example-with-normal-likelihood",
    "title": "37  M2L5 - Gibbs sampling",
    "section": "37.2 Computing example with Normal likelihood",
    "text": "37.2 Computing example with Normal likelihood\nTo implement the Gibbs sampler we just described, let’s return to our running example where the data are the percent change in total personnel from last year to this year for n=10 companies.  We’ll still use a normal likelihood, but now we’ll relax the assumption that we know the variance of growth between companies, \\sigma^2, and estimate that variance. Instead of the t prior from earlier, we will use the conditionally conjugate priors, normal for \\mu and inverse-gamma for \\sigma^2.Company personnel\nThe first step will be to write functions to simulate from the full conditional distributions we derived in the previous segment. The full conditional for \\mu, given \\sigma^2 and data is\n\n37.2.1 Conditionally conjugate priors for the mean (Video)\n\n\\text{N} \\left( \\mu \\mid \\frac{n\\bar{y}/\\sigma^2 + \\mu_0/\\sigma_0^2}{n/\\sigma^2 + 1/\\sigma_0^2}, \\, \\frac{1}{n/\\sigma^2 + 1/\\sigma_0^2} \\right)\n\\tag{37.3}\n\n\nCode\n#' update_mu\n#'\n#' @param n - sample size\n#' @param ybar - sample mean\n#' @param sig2 - current sigma squared\n#' @param mu_0 - mean hyper-parameter\n#' @param sig2_0 - variance  hyper-parameter\n#' \n#' @output - updated  value for mu the mean\n1update_mu = function(n, ybar, sig2, mu_0, sig2_0) {\n2  sig2_1 = 1.0 / (n / sig2 + 1.0 / sig2_0)\n3  mu_1 = sig2_1 * (n * ybar / sig2 + mu_0 / sig2_0)\n4  rnorm(n=1, mean=mu_1, sd=sqrt(sig2_1))\n}\n\n\n\n1\n\nwe don’t need the data y\n\n2\n\nwhere:  sig2_1 is \\sigma^2_1 the right term in Equation 37.3  sig2 is the current \\sigma_2 which we update in update_sigma below using Equation 37.4  sig2_0 is the hyper parameter for \\sigma^2_0\n\n3\n\nmu_1 is \\sigma^2_1 the left term in Equation 37.3 which uses sig2_1 we just computed\n\n4\n\nwe now draw from the a N(\\mu_1,\\sigma_1^2) for update_sig2 and the trace.\n\n\n\n\n\n\n37.2.2 conditionally conjugate priors for the variance\nThe full conditional for \\sigma^2 given \\mu and data is\n\n\\text{IG}\\left( \\sigma^2 \\mid \\nu_0 + \\frac{n}{2}, \\, \\beta_0 + \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2} \\right)\n\\tag{37.4}\n\n\nCode\n#' update_sig2\n#'\n#' @param n - sample size\n#' @param y - the data\n#' @param nu_0 - nu hyper-parameter\n#' @param beta_0 - beta hyper-parameter\n#' \n#' @output - updated  value for sigma2 the variance\n1update_sig2 = function(n, y, mu, nu_0, beta_0) {\n2  nu_1 = nu_0 + n / 2.0\n3  sumsq = sum( (y - mu)^2 )\n4  beta_1 = beta_0 + sumsq / 2.0\n5  out_gamma = rgamma(n=1, shape=nu_1, rate=beta_1)\n6  1.0 / out_gamma\n}\n\n\n\n1\n\nwe need the data to update beta\n\n2\n\nnu_1 the left term in Equation 37.4\n\n3\n\nvectorized\n\n4\n\nbeta_1 the right term in Equation 37.4\n\n5\n\ndraw a gamma sample with updated rate for \\text{Gamma}() is shape for \\text{IG}() inv-gamma\n\n6\n\nsince there is no rinvgamma in R we use the reciprocal of a gamma random variable which is distributed inv-gamma\n\n\n\n\nWith functions for drawing from the full conditionals, we are ready to write a function to perform Gibbs sampling.\n\n\n37.2.3 Gibbs sampler in R\n\n\nCode\ngibbs = function(y, n_iter, init, prior) {\n  ybar = mean(y)\n  n = length(y)\n  \n  ## initialize\n  mu_out = numeric(n_iter)\n  sig2_out = numeric(n_iter)\n  \n  mu_now = init$mu\n  \n  ## Gibbs sampler\n  for (i in 1:n_iter) {\n    sig2_now = update_sig2(n=n, y=y, mu=mu_now, nu_0=prior$nu_0, beta_0=prior$beta_0)\n    mu_now = update_mu(n=n, ybar=ybar, sig2=sig2_now, mu_0=prior$mu_0, sig2_0=prior$sig2_0)\n    \n    sig2_out[i] = sig2_now\n    mu_out[i] = mu_now\n  }\n  \n1  cbind(mu=mu_out, sig2=sig2_out)\n}\n\n\n\n1\n\ncbind for column bind will take a lists of list and convert them into a matrix of collumns.\n\n\n\n\nNow we are ready to set up the problem in R.\n\n\\begin{aligned}\n  y_i \\mid \\mu, \\sigma &\\stackrel {iid} \\sim \\mathcal{N}(\\mu,\\sigma^2), \\quad i=1,\\ldots,n\n  \\\\ \\mu &\\sim \\mathcal{N}(\\mu_0,\\sigma^2_0)\n  \\\\ \\sigma^2 & \\sim \\mathcal{IG}(\\nu,\\beta_0)\n\\end{aligned}\n\\tag{37.5}\nWe also need to create the prior hyperparameters for \\sigma^2, \\nu_0 and \\beta_0. If we chose these hyperperameters carefully, they are interpretable as a prior guess for sigma squared, as well as a prior effective sample size to go with that guess.\nThe prior effective sample size. Which we’ll call n_0, is two times this \\nu_0 parameter. So in other words, the nu parameter will be the prior sample size Divided by 2. We’re also going to create an initial guess for sigma squared, let’s call it s^2_0. The relationship between \\beta_0 and these two numbers is the following: It is the prior sample size times the prior guess divided by 2.\nThis particular parameterization of the Inverse gamma distribution is called the Scaled Inverse Chi Square Distribution, where the two parameters are n_0 and s^2_0.\n\n\nCode\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nybar = mean(y)\nn = length(y)\n\n## prior\nprior = list()\nprior$mu_0 = 0.0\nprior$sig2_0 = 1.0\nprior$n_0 = 2.0 # prior effective sample size for sig2\nprior$s2_0 = 1.0 # prior point estimate for sig2\nprior$nu_0 = prior$n_0 / 2.0 # prior parameter for inverse-gamma\nprior$beta_0 = prior$n_0 * prior$s2_0 / 2.0 # prior parameter for inverse-gamma\n\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dnorm(x=x, mean = prior$mu_0, sd=sqrt(prior$sig2_0)), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nFinally, we can initialize and run the sampler!\n\n\nCode\nset.seed(53)\n\ninit = list()\ninit$mu = 0.0\n\npost = gibbs(y=y, n_iter=1e3, init=init, prior=prior)\n\n\n\n\nCode\nhead(post)\n\n\n            mu      sig2\n[1,] 0.3746992 1.5179144\n[2,] 0.4900277 0.8532821\n[3,] 0.2536817 1.4325174\n[4,] 1.1378504 1.2337821\n[5,] 1.0016641 0.8409815\n[6,] 1.1576873 0.7926196\n\n\n\n\nCode\nlibrary(\"coda\")\nplot(as.mcmc(post))\n\n\n\n\n\n\n\n\n\n\n\nCode\nsummary(as.mcmc(post))\n\n\n\nIterations = 1:1000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n       Mean     SD Naive SE Time-series SE\nmu   0.9051 0.2868  0.00907        0.00907\nsig2 0.9282 0.5177  0.01637        0.01810\n\n2. Quantiles for each variable:\n\n       2.5%    25%    50%   75% 97.5%\nmu   0.3024 0.7244 0.9089 1.090 1.481\nsig2 0.3577 0.6084 0.8188 1.094 2.141\n\n\nAs with the Metropolis-Hastings example, these chains appear to have converged. In the next lesson, we will discuss convergence in more detail.\n\n\n\n\n\n\nGeman, Stuart, and Donald Geman. 1984. “Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images.” IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI-6 (6): 721–41. https://doi.org/10.1109/tpami.1984.4767596.",
    "crumbs": [
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>M2L5 - Gibbs sampling</span>"
    ]
  },
  {
    "objectID": "C2-L05-Ex1.html",
    "href": "C2-L05-Ex1.html",
    "title": "38  HW - Gibbs-Sampling algorithm",
    "section": "",
    "text": "Exercise 38.1  Which of the following descriptions matches the process of Gibbs sampling for multiple random variables?Gibbs\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nCycle through the variables, drawing a sample from the full conditional distribution of each variable while substituting in the current values of all other variables. Repeat this cycle for many iterations.\nDraw candidates for all J variables simultaneously using a multivariate proposal distribution. For each variable, calculate the acceptance ratio αj using the joint (unnormalized) density. Accept each candidate with probability min\\{1,\\alpha_j\\} \\ for \\  j=1,\\ldots,J. Repeat this cycle for many iterations.\nCycle through the variables, drawing from a proposal distribution for each variable and accepting the candidate with probability equal to the ratio of the candidate draw to the old value of the variable. Repeat this cycle for many iterations.\nDraw candidates for all variables simultaneously using a multivariate proposal distribution. Calculate the acceptance ratio α using the joint (unnormalized) density. Accept the candidates with probability min\\{1,\\alpha\\}. Repeat this step for many iterations. Correct\n\nGibbs sampling allows us to perform the updates one-at-a-time using full conditional distributions.\n\n\n\n\nExercise 38.2  Suppose we have a joint probability distribution for four variables, \\mathbb{P}r(w,x,y,z) . Which of the following expresses the full conditional distribution for variable x?Gibbs\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\mathbb{P}r(x \\mid y)\n\\mathbb{P}r(x)\n\\mathbb{P}r(w,y,z \\mid x)\n\\mathbb{P}r(x \\mid w,y,z)\n\nIt is the distribution of x, conditional on all other variables. It is proportional to \\mathbb{P}r(w,x,y,z), where we consider w,y,z as constants.\n\n\n\n\nExercise 38.3  Suppose we have the following joint distribution for x,y, and z:Gibbs\n\n\\mathbb{P}r(x,y,z) = 5e^{-5z} I_{z\\ge0} \\frac{\\Gamma(z+3)}{\\Gamma(z) \\Gamma(3)} y^{z-1} (1-y)^{2} I_{0&lt;y&lt;1} { 10 \\choose x} y^x (1-y)^{10-x} I_{x\\in\\{1,\\ldots,10 \\}}\n\nThe density for the full conditional distribution of z is proportional to which of the following?\n\n\n\n\n\n\n\nImportant\n\n\n\nHint: The full conditional for z is proportional to the full joint distribution \\mathbb{P}r(x,y,z) where x and y are just constants.\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\mathbb{P}r(z \\mid x, y) \\propto 5e^{-5z} I_{z\\ge0}\n\\mathbb{P}r(z \\mid x, y) \\propto y^{z-1} (1-y)^{2} y^x (1-y)^{10-x} I_{0&lt;y&lt;1}\n\\mathbb{P}r(z \\mid x, y) \\propto e^{-5z} \\frac{\\Gamma(z+3)}{\\Gamma(z)} y^{z-1} I_{z\\ge0}\n\\mathbb{P}r(z \\mid x, y) \\propto { 10 \\choose x} y^x (1-y)^{10-x} I_{x\\in\\{1,\\ldots,10 \\}}\n\nThis could also be written as \\mathbb{P}r(z \\mid x, y) = C \\cdot e^{-5z} \\frac{\\Gamma(z+3)}{\\Gamma(z)} y^{z-1} I_{z\\ge0} where C is some constant number not involving z.\n\n\n\n\nExercise 38.4  The full conditional distribution in Question 3 is not a standard distribution that we can easily sample. Fortunately, it turns out that we can do a Metropolis-Hastings step inside our Gibbs sampler step for z.Gibbs\nIf we employ that strategy in a Gibbs sampler for y and z (always conditioning on x), then the algorithm would look like this:\nFor iteration i in 1 to m, repeat:\n\n  1. \n    a) Draw z* from a proposal distribution q.\n    b) Calculate the acceptance ratio (alpha) using the full\n        conditional distribution for z|x,y and the candidate distribution q, plugging in the previous iteration's value y_{i-1} for y.\n    c) Accept the candidate with probability min{1, alpha} and\n        set the value for z_i accordingly.\n\n  2. ___________________________.\nWhat would go in step 2 to complete the Gibbs sampler?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nDraw y_i from the marginal distribution r(y).\nDraw y_i from the full conditional \\mathbb{P}r(y \\mid x,z), plugging in the value z_i just drawn in step 1 for z.\nDraw y_i from the full conditional \\mathbb{P}r(y \\mid x,z), plugging in the previous iteration’s value z_{i−1} for z.\nDraw y_i from the full conditional \\mathbb{P}r(y \\mid x,z), plugging in the candidate z^∗ for z.\n\n\n\n\n\nExercise 38.5  Suppose we have a joint probability distribution for three variables: \\mathbb{P}r(x,y,z) . Identify the algorithm to perform Gibbs sampling for all three variables. 1 pointGibbs\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n[ ]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw candidates x*, y*, z* from a joint proposal\n      distribution q.\n\n  2. Calculate the acceptance ratio alpha using\n      $g(x,y,z) = \\mathbb{P}r(x|y,z)\\mathbb{P}r(y|x,z)\\mathbb{P}r(z|x,y) and q.\n\n  3. Accept the candidates with probability min{1,alpha}\n      and set x_i, y_i, z_i accordingly.\n\nend.\n\n[ ]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw x_i from the full conditional distribution for\n      x|y,z, plugging in the previous iteration's values\n      y_{i-1}, z_{i-1} for y and z.\n\n  2. Draw y_i from the full conditional distribution for\n      y|x,z, plugging in the previous iteration's values\n      x_{i-1}, z_{i-1} for x and z.\n\n  3. Draw z_i from the full conditional distribution for\n      z|x,y, plugging in the previous iteration's values\n      x_{i-1}, y_{i-1} for x and y.\n\nend.\n\n[ ]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw candidates x*, y*, z* from a joint proposal\n      distribution q.\n\n  2. a) i) Calculate the acceptance ratio alpha_x using\n            the full conditional \\mathbb{P}r(x|y,z) and q, plugging in the candidates y*, z* for y and z.\n\n        ii) Accept x* with probability min{1,alpha_x}\n            and set x_i accordingly.\n\n     b) i) Calculate the acceptance ratio alpha_y using\n            the full conditional \\mathbb{P}r(y|x,z) and q, plugging in x_i, z* for x and z.\n\n        ii) Accept y* with probability min{1,alpha_y}\n            and set y_i accordingly.\n\n     c) i) Calculate the acceptance ratio alpha_z using\n            the full conditional \\mathbb{P}r(z|x,y) and q, plugging in x_i, y_i for x and y.\n\n        ii) Accept z* with probability min{1,alpha_z}\n            and set z_i accordingly.\nend.\n\n[x]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw x_i from the full conditional distribution for\n      x|y,z, plugging in the previous iteration's values\n      y_{i-1}, z_{i-1} for y and z.\n\n  2. Draw y_i from the full conditional distribution for\n      y|x,z, plugging in the previous iteration's value\n      z_{i-1} for z and this iteration's value x_i for x.\n\n  3. Draw z_i from the full conditional distribution for\n      z|x,y, plugging in this iteration's values\n      x_i, y_i for x and y.\n\nend. \nThis is an extension of Gibbs sampling to three variables. The algorithm can be expanded to accommodate as many variables as you need.\n\n\n\nFor Questions 6 to 8, consider the example from the lesson where the data are percent change in total personnel since last year for n=10 companies.\n\nExercise 38.6  In our model with normal likelihood and unknown mean \\mu and unknown variance \\sigma^2 , we chose a normal prior for the mean and an inverse-gamma prior for the variance.Gibbs\nWhat was the major advantage of selecting these particular priors?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nBecause these priors are conjugate for their respective parameters, they guarantee the smallest possible Monte Carlo standard error for posterior mean estimates.\nBecause these priors are conjugate for their respective parameters, they guarantee the most accurate posterior distribution possible for the given likelihood.\nThese priors allowed us to bypass MCMC, providing a joint conjugate posterior for \\mu and \\sigma^2 .\nEach prior was conjugate in the case where the other parameter was known, causing the full conditional distributions to come from the same distribution families as the priors (and therefore easy to sample).\n\nIn hierarchical models, selecting conjugate priors at any level will result in a simple Gibbs update for the parameter involved. The other claims are false or exaggerations.\n\n\n\n\nExercise 38.7  Suppose we repeat the analysis for n=6 companies in another industry and the data are:Gibbs\nRe-run the Gibbs sampler in R for these new data (5000 iterations using the same priors and initial values as in the Lesson) and report the posterior mean for \\mu. Round your answer to two decimal places.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nlibrary(\"coda\")\nsummary(as.mcmc(post))\n\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nmu   -0.9976 0.6624 0.009368        0.01015\nsig2  4.5219 3.2775 0.046352        0.05135\n\n2. Quantiles for each variable:\n\n       2.5%    25%    50%     75%   97.5%\nmu   -2.218 -1.444 -1.042 -0.5762  0.4013\nsig2  1.419  2.506  3.596  5.4003 13.0080\n\n\n\n\nCode\n#' update_mu\n#'\n#' @param n - sample size\n#' @param ybar - sample mean\n#' @param sig2 - current sigma squared\n#' @param mu_0 - mean hyper-parameter\n#' @param sig2_0 - variance  hyper-parameter\n#' \n#' @output - updated  value for mu the mean\nupdate_mu = function(n, ybar, sig2, mu_0, sig2_0) {\n  sig2_1 = 1.0 / (n / sig2 + 1.0 / sig2_0)\n  mu_1 = sig2_1 * (n * ybar / sig2 + mu_0 / sig2_0)\n  rnorm(n=1, mean=mu_1, sd=sqrt(sig2_1))\n}\n\n#' update_sig2\n#'\n#' @param n - sample size\n#' @param y - the data\n#' @param nu_0 - nu hyper-parameter\n#' @param beta_0 - beta hyper-parameter\n#' \n#' @output - updated  value for sigma2 the variance\nupdate_sig2 = function(n, y, mu, nu_0, beta_0) {\n  nu_1 = nu_0 + n / 2.0\n  sumsq = sum( (y - mu)^2 )\n  beta_1 = beta_0 + sumsq / 2.0\n  out_gamma = rgamma(n=1, shape=nu_1, rate=beta_1)\n  1.0 / out_gamma\n}\n\ngibbs = function(y, n_iter, init, prior) {\n  ybar = mean(y)\n  n = length(y)\n  \n  ## initialize\n  mu_out = numeric(n_iter)\n  sig2_out = numeric(n_iter)\n  \n  mu_now = init$mu\n  \n  ## Gibbs sampler\n  for (i in 1:n_iter) {\n    sig2_now = update_sig2(n=n, y=y, mu=mu_now, nu_0=prior$nu_0, beta_0=prior$beta_0)\n    mu_now = update_mu(n=n, ybar=ybar, sig2=sig2_now, mu_0=prior$mu_0, sig2_0=prior$sig2_0)\n    \n    sig2_out[i] = sig2_now\n    mu_out[i] = mu_now\n  }\n  \n  cbind(mu=mu_out, sig2=sig2_out)\n}\n\ny = c(-0.2, -1.5, -5.3, 0.3, -0.8, -2.2)\nybar = mean(y)\nn = length(y)\n\n## prior\nprior = list()\nprior$mu_0 = 0.0\nprior$sig2_0 = 1.0\nprior$n_0 = 2.0 # prior effective sample size for sig2\nprior$s2_0 = 1.0 # prior point estimate for sig2\nprior$nu_0 = prior$n_0 / 2.0 # prior parameter for inverse-gamma\nprior$beta_0 = prior$n_0 * prior$s2_0 / 2.0 # prior parameter for inverse-gamma\n\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dnorm(x=x, mean = prior$mu_0, sd=sqrt(prior$sig2_0)), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nCode\nset.seed(53)\n\ninit = list()\ninit$mu = 0.0\n\npost = gibbs(y=y, n_iter=5e3, init=init, prior=prior)\n\n\n\n\n\n\nExercise 38.8 Gibbs\nAn industry expert is surprised by your results from Question 7 and insists that growth in this sector should be positive on average. To accommodate this expert’s prior beliefs, you adjust the prior for μ to be normal with a mean 1.0 and variance 1.0. This is a fairly informative and optimistic prior (the prior probability that \\mu &gt;0 is about 0.84).\nWhat happens to the posterior mean of μ? Re-run the analysis on the new data with this new prior. Again, use 5000 iterations and the same prior for σ2 and initial values as before).\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ny = c(-0.2, -1.5, -5.3, 0.3, -0.8, -2.2)\nybar = mean(y)\nn = length(y)\n\n## prior\nprior = list()\nprior$mu_0 = 1.0\nprior$sig2_0 = 1.0\nprior$n_0 = 2.0 # prior effective sample size for sig2\nprior$s2_0 = 1.0 # prior point estimate for sig2\nprior$nu_0 = prior$n_0 / 2.0 # prior parameter for inverse-gamma\nprior$beta_0 = prior$n_0 * prior$s2_0 / 2.0 # prior parameter for inverse-gamma\n\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dnorm(x=x, mean = prior$mu_0, sd=sqrt(prior$sig2_0)), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nCode\nset.seed(53)\n\ninit = list()\ninit$mu = 0.0\n\npost = gibbs(y=y, n_iter=5e3, init=init, prior=prior)\n\n\n\n\nCode\nlibrary(\"coda\")\nsummary(as.mcmc(post))\n\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nmu   -0.5071 0.7549  0.01068        0.01334\nsig2  5.4989 4.3818  0.06197        0.07592\n\n2. Quantiles for each variable:\n\n       2.5%    25%     50%      75%  97.5%\nmu   -1.828 -1.028 -0.5676 -0.03787  1.118\nsig2  1.536  2.870  4.2764  6.60483 17.002\n\n\n\nThe posterior mean for μ is less than −0.25, suggesting that despite the optimistic prior, the data strongly favor estimating growth to be negative in this industry.\nThe posterior mean for μ is between −0.25 and 0.25, suggesting that the data are not as optimistic about growth as the prior, but we are inconclusive about whether growth is positive or negative.\nThe posterior mean for μ is between 0.25 and 1.0, suggesting that the data are not informative enough to contradict this expert’s opinion.\nThe posterior mean for μ is above 1.0, suggesting that the optimistic prior was actually not optimistic enough.",
    "crumbs": [
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>HW - Gibbs-Sampling algorithm</span>"
    ]
  },
  {
    "objectID": "C2-L06.html",
    "href": "C2-L06.html",
    "title": "39  M2L5 - Assessing Convergence",
    "section": "",
    "text": "39.1 Convergence diagnostics\nIn the previous two lessons, we have demonstrated ways you can simulate a Markov chain whose stationary distribution is the target distribution (usually the posterior). Before using the simulated chain to obtain Monte Carlo estimates, we should first ask ourselves: Has our simulated Markov chain converged to its stationary distribution yet? Unfortunately, this is a difficult question to answer, but we can do several things to investigate.",
    "crumbs": [
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>M2L5 - Assessing Convergence</span>"
    ]
  },
  {
    "objectID": "C2-L06.html#sec-convergence-diagnostics",
    "href": "C2-L06.html#sec-convergence-diagnostics",
    "title": "39  M2L5 - Assessing Convergence",
    "section": "",
    "text": "39.1.1 Trace plots\nOur first visual tool for assessing chains is the trace plot. A trace plot shows the history of a parameter value across iterations of the chain. It shows you precisely where the chain has been exploring.\nFirst, let’s talk about what a chain should look like. Here is an example of a chain that has most likely converged.\n\n\nCode\nsource('mh.r')\n\n\nList of 2\n $ mu   : num [1:1000] 0 0 0.00586 0.00586 0.00586 ...\n $ accpt: num 0.119\n\n\nCode\nlibrary(\"coda\")\nset.seed(61)\npost0 = mh(n=n, ybar=ybar, n_iter=10e3, mu_init=0.0, cand_sd=0.9)\ncoda::traceplot(as.mcmc(post0$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf the chain is stationary, it should not be showing any long-term trends. The average value for the chain should be roughly flat. It should not be wandering as in this example:\n\n\nCode\nset.seed(61)\npost1 = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post1$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf this is the case, you need to run the chain many more iterations, as seen here:\n\n\nCode\nset.seed(61)\npost2 = mh(n=n, ybar=ybar, n_iter=100e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\nThe chain appears to have converged at this much larger time scale.\n\n\n39.1.2 Monte Carlo effective sample size\nOne major difference between the two chains we’ve looked at is the level of autocorrelation in each. Autocorrelation is a number between -1 and +1 which measures how linearly dependent the current value of the chain is on past values (called lags). We can see this with an autocorrelation plot:\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post0$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post1$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.diag(as.mcmc(post1$mu))\n\n\n            [,1]\nLag 0  1.0000000\nLag 1  0.9850078\nLag 5  0.9213126\nLag 10 0.8387333\nLag 50 0.3834563\n\n\nAutocorrelation is important because it tells us how much information is available in our Markov chain. Sampling 1000 iterations from a highly correlated Markov chain yields less information about the stationary distribution than we would obtain from 1000 samples independently drawn from the stationary distribution.\nAutocorrelation is a major component in calculating the Monte Carlo effective sample size of your chain. The Monte Carlo effective sample size is how many independent samples from the stationary distribution you would have to draw to have equivalent information in your Markov chain. Essentially it is the m (sample size) we chose in the lesson on Monte Carlo estimation.\n\n\nCode\nstr(post2) # contains 100,000 iterations\n\n\nList of 2\n $ mu   : num [1:100000] -0.0152 -0.1007 -0.0867 -0.1092 -0.0811 ...\n $ accpt: num 0.958\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post2$mu)) # effective sample size of ~350\n\n\n   var1 \n373.858 \n\n\n\n\nCode\n## thin out the samples until autocorrelation is essentially 0. This will leave you with approximately independent samples. The number of samples remaining is similar to the effective sample size.\ncoda::autocorr.plot(as.mcmc(post2$mu), lag.max=500)\n\n\n\n\n\n\n\n\n\n\n\nCode\nthin_interval = 400 # how far apart the iterations are for autocorrelation to be essentially 0.\nthin_indx = seq(from=thin_interval, to=length(post2$mu), by=thin_interval)\nhead(thin_indx)\n\n\n[1]  400  800 1200 1600 2000 2400\n\n\n\n\nCode\npost2mu_thin = post2$mu[thin_indx]\ntraceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ntraceplot(as.mcmc(post2mu_thin))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post2mu_thin), lag.max=10)\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(as.mcmc(post2mu_thin))\n\n\nvar1 \n 250 \n\n\n\n\nCode\nlength(post2mu_thin)\n\n\n[1] 250\n\n\n\n\nCode\nstr(post0) # contains 10,000 iterations\n\n\nList of 2\n $ mu   : num [1:10000] 0 0 0.315 0.315 0.949 ...\n $ accpt: num 0.382\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post0$mu)) # effective sample size of ~2,500\n\n\n    var1 \n2537.924 \n\n\n?effectiveSize\nThe chain from post0 has 10,000 iterations, but an effective sample size of about 2,500. That is, this chain essentially provides the equivalent of 2,500 independent Monte Carlo samples.\nNotice that the chain from post0 has 10 times fewer iterations than for post2, but its Monte Carlo effective sample size is about seven times greater than the longer (more correlated) chain. We would have to run the correlated chain for 700,000+ iterations to get the same amount of information from both chains.\nIt is usually a good idea to check the Monte Carlo effective sample size of your chain. If all you seek is a posterior mean estimate, then an effective sample size of a few hundred to a few thousand should be enough. However, if you want to create something like a 95% posterior interval, you may need many thousands of effective samples to produce a reliable estimate of the outer edges of the distribution. The number you need can be quickly calculated using the Raftery and Lewis diagnostic.\nraftery.diag(as.mcmc(post0$mu))\n\n\nCode\nraftery.diag(as.mcmc(post0$mu), q=0.005, r=0.001, s=0.95)\n\n\n\nQuantile (q) = 0.005\nAccuracy (r) = +/- 0.001\nProbability (s) = 0.95 \n\nYou need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n## \n## Quantile (q) = 0.005\n## Accuracy (r) = +/- 0.001\n## Probability (s) = 0.95 \n## \n## You need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n?raftery.diag\n\n\nIn the case of the first chain from post0, it looks like we would need about 3,700 effective samples to calculate reliable 95% intervals. With the autocorrelation in the chain, that requires about 13,200 total samples. If we wanted to create reliable 99% intervals, we would need at least 19,100 total samples.",
    "crumbs": [
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>M2L5 - Assessing Convergence</span>"
    ]
  },
  {
    "objectID": "C2-L06.html#burn-in",
    "href": "C2-L06.html#burn-in",
    "title": "39  M2L5 - Assessing Convergence",
    "section": "39.2 Burn-in",
    "text": "39.2 Burn-in\nWe have also seen how the initial value of the chain can affect how quickly the chain converges. If our initial value is far from the bulk of the posterior distribution, then it may take a while for the chain to travel there. We saw this in an earlier example.\n\n\nCode\nset.seed(62)\npost3 = mh(n=n, ybar=ybar, n_iter=500, mu_init=10.0, cand_sd=0.3)\ncoda::traceplot(as.mcmc(post3$mu))\n\n\n\n\n\n\n\n\n\nClearly, the first 100 or so iterations do not reflect draws from the stationary distribution, so they should be discarded before we use this chain for Monte Carlo estimates. This is called the “burn-in” period. You should always discard early iterations that do not appear to be coming from the stationary distribution. Even if the chain appears to have converged early on, it is safer practice to discard an initial burn-in.\n\n39.2.1 Multiple chains, Gelman-Rubin\nIf we want to be more confident that we have converged to the true stationary distribution, we can simulate multiple chains, each with a different starting value.\n\n\nCode\nset.seed(61)\n\nnsim = 500\npost1 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=15.0, cand_sd=0.4)\npost1$accpt\n\n\n[1] 0.616\n\n\n\n\nCode\npost2 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-5.0, cand_sd=0.4)\npost2$accpt\n\n\n[1] 0.612\n\n\n\n\nCode\npost3 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=7.0, cand_sd=0.1)\npost3$accpt\n\n\n[1] 0.844\n\n\n\n\nCode\npost4 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=23.0, cand_sd=0.5)\npost4$accpt\n\n\n[1] 0.53\n\n\n\n\nCode\npost5 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-17.0, cand_sd=0.4)\npost5$accpt\n\n\n[1] 0.618\n\n\n\n\nCode\npmc = mcmc.list(as.mcmc(post1$mu), as.mcmc(post2$mu), \n                as.mcmc(post3$mu), as.mcmc(post4$mu), as.mcmc(post5$mu))\nstr(pmc)\n\n\nList of 5\n $ : 'mcmc' num [1:500] 14.8 14 14 13.8 13.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -5 -5 -5 -5 -4.89 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 7 7 7 6.94 6.94 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 23 21.9 21.9 21.8 21.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -17 -17 -16.9 -16.2 -15.7 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n - attr(*, \"class\")= chr \"mcmc.list\"\n\n\n\n\nCode\ncoda::traceplot(pmc)\n\n\n\n\n\n\n\n\n\nIt appears that after about iteration 200, all chains are exploring the stationary (posterior) distribution. We can back up our visual results with the Gelman Rubin diagnostic. This diagnostic statistic calculates the variability within chains, comparing that to the variability between chains. If all chains have converged to the stationary distribution, the variability between chains should be relatively small, and the potential scale reduction factor, reported by the the diagnostic, should be close to one. If the values are much higher than one, then we would conclude that the chains have not yet converged.\n\n\nCode\ncoda::gelman.diag(pmc)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\n[1,]       1.01       1.02\n\n\n\n\nCode\ncoda::gelman.plot(pmc)\n\n\n\n\n\n\n\n\n\n\n\nCode\n?gelman.diag\n\n\n From the plot, we can see that if we only used the first 50 iterations, the potential scale reduction factor or “shrink factor” would be close to 10, indicating that the chains have not converged. But after about iteration 300, the “shrink factor” is essentially one, indicating that by then, we have probably reached convergence. Of course, we shouldn’t stop sampling as soon as we reach convergence. Instead, this is where we should begin saving our samples for Monte Carlo estimation.\n\n\n39.2.2 Monte Carlo estimation\nIf we are reasonably confident that our Markov chain has converged, then we can go ahead and treat it as a Monte Carlo sample from the posterior distribution. Thus, we can use the techniques from Lesson 3 to calculate posterior quantities like the posterior mean and posterior intervals from the samples directly.\n\n\nCode\nnburn = 1000 # remember to discard early iterations\npost0$mu_keep = post0$mu[-c(1:1000)]\nsummary(as.mcmc(post0$mu_keep))\n\n\n\nIterations = 1:9000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 9000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n      0.889449       0.304514       0.003210       0.006295 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n0.2915 0.6825 0.8924 1.0868 1.4890 \n\n\n\n\nCode\nmean(post0$mu_keep &gt; 1.0) # posterior probability that mu  &gt; 1.0\n\n\n[1] 0.3554444",
    "crumbs": [
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>M2L5 - Assessing Convergence</span>"
    ]
  },
  {
    "objectID": "C2-L06-Ex1.html",
    "href": "C2-L06-Ex1.html",
    "title": "40  Homework on the Gibbs-Sampling algorithm",
    "section": "",
    "text": "Exercise 40.1  Why is it important to check your MCMC output for convergence before using the samples for inference?convergence\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nConvergence diagnostics provide a guarantee that your inferences are accurate.\nYou can cut your Monte Carlo error by a factor of two if you strategically select which samples to retain.\nIf the chain has not reached its stationary distribution (the target/posterior), your samples will not reflect that distribution.\nPre-convergence MCMC samples are useless.\n\nMCMC is based on a process guaranteeing convergence to a stationary distribution.\n\n\n\n\nExercise 40.2  Which of the following trace plots illustrates a chain that appears to have converged?convergence\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\n\n\n\n\nA seems to switch between a -4 and 0 value states. B is clearly still moving down. C has long term dependence (auto-correlated) and is divergent. D looks like IID samples at -4.0 \\pm 1\n\n\n\n\nExercise 40.3  The trace plot below was generated by a random walk Metropolis sampler, where candidates were drawn from a normal proposal distribution with mean equal to the previous iteration’s value, and a fixed variance. Based on this result, what action would you recommend taking next?convergence\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe step size of the proposals is too small. Decrease the variance of the normal proposal distribution and re-run the chain.\nThe step size of the proposals is too small. Increase the variance of the normal proposal distribution and re-run the chain.\nThe step size of the proposals is too large. Increase the variance of the normal proposal distribution and re-run the chain.\nThe step size of the proposals is too large. Decrease the variance of the normal proposal distribution and re-run the chain.\n\nStep size for a parameter is not an implicit component of RW-MH alg we leaned so the question and answers are well posed. Also we are not told that this is the trace plot is for the mean, but It seems a safe assumption. Since the M-H algorithm uses the current and previous mean to accept/reject we can consider their difference as a step size. In the long run each step contributes little when updating the mean. What has greater influence on the step size then is the constant variance.\nWe did discuss this type of trace as having long term interdependence (clumping). It seems that we want to increase the step size by increasing the variance to make new samples less dependent on the previous value of the mean.\nIn other words, it takes too long for the chain to explore the posterior distribution. This is less of a problem if you run a very long chain, but it is best to use a more efficient proposal distribution if possible.\n\n\n\n\nExercise 40.4  Suppose you have multiple MCMC chains from multiple initial values and they appear to traverse the same general area back and forth, but struggle from moderate (or high) autocorrelation. Suppose also that adjusting the proposal distribution q is not an option. Which of the following strategies is likely to help increase confidence in your Monte Carlo estimates?convergence\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nDiscard fewer burn-in samples to increase your Monte Carlo effective sample size.\nRetain only the 80% of samples closest to the maximum likelihood estimate.\nRun the chains for many more iterations and check for convergence on the larger time scale.\nAdd more chains from more initial values to see if that reduces autocorrelation.\n\nProper MCMC algorithms come with a theoretical guarantee of eventual convergence to the target distribution. Chains with very high autocorrelation may require an impractical number of iterations, but it is worth checking to see if a longer chain yields acceptable results.\n\n\n\n\nExercise 40.5  Each of the following plots reports estimated autocorrelation from a MCMC chain with 10,000 iterations. Which will yield the lowest Monte Carlo effective sample size?convergence\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\n\n\n\n\nMCMC algs are based on a process guaranteeing convergence to a stationary distribution.\n\n\n\n\nExercise 40.6 convergence\nThe following trace plot shows four chains with distinct initial values. Of the choices given, what is the lowest number of samples you would comfortably recommend to discard as burn-in?\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nA: 50 iterations.\nB: 150 iterations.\nC: 400 iterations.\nD: 700 iterations.\n\nMCMC algs are based on a process guaranteeing convergence to a stationary distribution.\n\n\n\n\nExercise 40.7 convergence\nSuppose the Gelman and Rubin diagnostic computed from multiple chains reports a scale reduction factor much higher than 1.0, say 8.0. What is the recommended action?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThin the chain by discarding every eighth sample.\nContinue running the chain for many more iterations.\nDiscontinue use of the model, since there is little hope of reaching the stationary distribution.\nUse the samples for inference as this high scale reduction factor indicates convergence.\n\nMCMC algs are based on a process guaranteeing convergence to a stationary distribution.\n\n\n\n\nExercise 40.8  Which of the following Monte Carlo statistics would require the largest MCMC effective sample size to estimate reliably? Assume the target distribution is unimodal (has only one peak).convergence\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n97.5 percentile of the target distribution.\nMedian of the target distribution.\nMean of the target distribution.\n15 percentile of the target distribution.\n\nThe outer edges of the distribution are sampled less frequently and therefore susceptible to changes between simulations. The Raftery and Lewis diagnostic can help you decide how many iterations you need to reliably estimate outer quantiles of the target distribution..",
    "crumbs": [
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Homework on the Gibbs-Sampling algorithm</span>"
    ]
  },
  {
    "objectID": "C2-L06-Ex2.html",
    "href": "C2-L06-Ex2.html",
    "title": "41  Honnors Homework on M-H algorithm",
    "section": "",
    "text": "For Questions Exercise 41.1 through Exercise 41.3, consider the following model for data that take on values between 0 and 1:M-H\n\nx_i \\mid \\alpha, \\beta \\overset{\\text{iid}}{\\sim} \\text{Beta}(\\alpha, \\beta) \\, , \\quad i = 1, \\ldots, n\\, , \\\\ \\alpha \\sim \\text{Gamma}(a, b) \\, , \\\\ \\beta \\sim \\text{Gamma}(r, s)\n\nwhere α and β are independent a-priori.\n\nExercise 41.1  Which of the following gives the full conditional density for α up to proportionality?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\mathbb{P}r( \\alpha \\mid \\beta, x) \\propto \\frac{ \\Gamma(\\alpha + \\beta)^n }{ \\Gamma(\\alpha)^n } \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\alpha^{a-1} e^{-b\\alpha} I_{(0 &lt; \\alpha &lt; 1)}\n\\mathbb{P}r( \\alpha \\mid \\beta, x) \\propto \\frac{ \\Gamma(\\alpha + \\beta)^n }{ \\Gamma(\\alpha)^n } \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\alpha^{a-1} e^{-b\\alpha} I_{(\\alpha &gt; 0)}\n\\mathbb{P}r( \\alpha \\mid \\beta, x) \\propto \\frac{ \\Gamma(\\alpha + \\beta)^n }{ \\Gamma(\\alpha)^n \\Gamma(\\beta)^n } \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\left[ \\prod_{i=1}^n (1-x_i) \\right]^{\\beta - 1} \\alpha^{a-1} e^{-b\\alpha} \\beta^{r-1} e^{-s\\beta} I_{(0 &lt; \\alpha &lt; 1)} I_{(0 &lt; \\beta &lt; 1)}\n\\mathbb{P}r( \\alpha \\mid \\beta, x) \\propto \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\alpha^{a-1} e^{-b\\alpha} I_{(\\alpha &gt; 0)}\n\nWhen we treat the data x and β as known constants, the full joint distribution of all quantities x, α, and β is proportional to this expression when reinterpreted as a function of α.\nTo solve this one I had a couple of challenges:\n\nFirst I needed to understand what the full conditional means (I worked that out in the previous homework)\nNext that all the answers look like a likelihood times a prior\nNext I needed to remember that this requires reinterpreting the likelihood \\mathbb{P}r(x\\mid\\alpha,\\beta) as \\mathbb{P}r(\\alpha\\mid\\beta,x).\nFor the solution I multiplied the likelihood for \\text{Beta}(x|\\alpha,\\beta)^n with the prior \\text{Gamma}(\\alpha|a,b) then canceled any term in the product that did not have \\alpha. This was tricky since my reference for Gamma had x, \\alpha and \\beta and without substituting x=\\alpha, \\alpha=a and \\beta=b which is counter intuitive I got wrong answers.\nFinally I had to decide on two options for the indicator. The question talks about restricting the data to values from 0 to 1 but the Likelihood and prior allow values from \\mathbb{R}^+. I picked the latter since the restriction was for the data and not the parameters.\n\n\n\n\n\nExercise 41.2  Suppose we want posterior samples for α from the model in Exercise 41.1. What is our best option?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe full conditional for α is not proportional to any common probability distribution, and the marginal posterior for β is not any easier, so we will have to resort to a Metropolis-Hastings sampler.\nThe joint posterior for α and β is a common probability distribution which we can sample directly. Thus we can draw Monte Carlo samples for both parameters and keep the samples for α.\nThe full conditional for α is proportional to a common distribution which we can sample directly, so we can draw from that.\nThe full conditional for α is not a proper distribution (it doesn’t integrate to 1), so we cannot sample from it.\n\nAnother option is to approximate the posterior distribution for α by considering a set of discrete values such as 0.1,0.2, \\ldots, 0.9 etc. You could use a discrete uniform prior, or discrete prior probabilities proportional to the beta prior evaluated at these specific values. Either way, the full conditional distribution for α looks like the discrete version of Bayes’ theorem, which is easy to compute.\n\n\n\n\nExercise 41.3  If we elect to use a Metropolis-Hastings algorithm to draw posterior samples for α, the Metropolis-Hastings candidate acceptance ratio is computed using the full conditional for α asM-H\n\n\\frac{ \\Gamma(\\alpha)^n \\Gamma(\\alpha^*+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*} {\\alpha^*}^{a-1} e^{-b\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } {  \\Gamma(\\alpha^*)^n \\Gamma(\\alpha+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha} {\\alpha}^{a-1} e^{-b\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\nwhere α^∗ is a candidate value drawn from proposal distribution q(α^∗\\midα). Suppose that instead of the full conditional for α, we use the full joint posterior distribution of α and β and simply plug in the current (or known) value of β. What is the Metropolis-Hastings ratio in this case?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\frac{{\\alpha^*}^{a-1} e^{-b\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } { {\\alpha}^{a-1} e^{-b\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\\frac{ \\Gamma(\\alpha)^n \\Gamma(\\alpha^*+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*} {\\alpha^*}^{a-1} e^{-b\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } { \\Gamma(\\alpha^*)^n \\Gamma(\\alpha+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha} {\\alpha}^{a-1} e^{-b\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\\frac{ \\Gamma(\\alpha)^n \\Gamma(\\alpha^*+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } { \\Gamma(\\alpha^*)^n \\Gamma(\\alpha+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\\frac{ \\Gamma(\\alpha^* + \\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*- 1} \\left[ \\prod_{i=1}^n (1-x_i) \\right]^{\\beta - 1} {\\alpha^*}^{a-1} e^{-b\\alpha^*} \\beta^{r-1} e^{-s\\beta} q(\\alpha | \\alpha^*) I_{(0 &lt; \\alpha^*)} I_{(0 &lt; \\beta )} }{ \\Gamma(\\alpha^*)^n \\Gamma(\\beta)^n q(\\alpha^* | \\alpha) }\n\nAll of the terms involving only β are identical in the numerator and denominator, and thus cancel out. The acceptance ratio is the same whether we use the full joint posterior or the full conditional in a Gibbs sampler.\n\n\n\nFor Questions 4 and 5, re-run the Metropolis-Hastings algorithm from Lesson 4 to draw posterior samples from the model for mean company personnel growth for six new companies: (-0.2, -1.5, -5.3, 0.3, -0.8, -2.2). Use the same prior as in the lesson.\n\n\nCode\n{library(\"rjags\")}\nlibrary(\"coda\")\n\nlg = function(mu, n, ybar) {\n  mu2 = mu^2\n  n * (ybar * mu - mu2 / 2.0) - log(1 + mu2)\n}\n\nmh = function(n, ybar, n_iter, mu_init, cand_sd) {\n  ## Random-Walk Metropolis-Hastings algorithm\n  \n  ## step 1, initialize\n  mu_out = numeric(n_iter)\n  accpt = 0\n  mu_now = mu_init\n  lg_now = lg(mu=mu_now, n=n, ybar=ybar)\n  \n  ## step 2, iterate\n  for (i in 1:n_iter) {\n    ## step 2a\n    mu_cand = rnorm(n=1, mean=mu_now, sd=cand_sd) # draw a candidate\n    \n    ## step 2b\n    lg_cand = lg(mu=mu_cand, n=n, ybar=ybar) # evaluate log of g with the candidate\n    lalpha = lg_cand - lg_now # log of acceptance ratio\n    alpha = exp(lalpha)\n    \n    ## step 2c\n    u = runif(1) # draw a uniform variable which will be less than alpha with probability min(1, alpha)\n    if (u &lt; alpha) { # then accept the candidate\n      mu_now = mu_cand\n      accpt = accpt + 1 # to keep track of acceptance\n      lg_now = lg_cand\n    }\n    \n    ## collect results\n    mu_out[i] = mu_now # save this iteration's value of mu\n  }\n  \n  ## return a list of output\n  list(mu=mu_out, accpt=accpt/n_iter)\n}\n\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nybar = mean(y)\nn = length(y)\n#hist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\n#curve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\n#points(y, rep(0,n), pch=1) # individual data points\n#points(ybar, 0, pch=19) # sample mean\n#set.seed(43) # set the random seed for reproducibility\n\n\n\n\nCode\nsds = c(0.5,1.5,3.0,4.0)\ny = c(-0.2, -1.5, -5.3, 0.3, -0.8, -2.2)\nybar = mean(y)\nn = length(y)\n\nfor (sd in sds){\n  post = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=sd)\n  #str(post)\n  #traceplot(as.mcmc(post$mu))\n  print(c(sd,\":\",post$accpt,'mu',\":\",mean(post$mu)))\n}\n\n\n[1] \"0.5\"               \":\"                 \"0.637\"            \n[4] \"mu\"                \":\"                 \"-1.46236382073726\"\n[1] \"1.5\"               \":\"                 \"0.314\"            \n[4] \"mu\"                \":\"                 \"-1.45027695850878\"\n[1] \"3\"                 \":\"                 \"0.157\"            \n[4] \"mu\"                \":\"                 \"-1.44774621405117\"\n[1] \"4\"                 \":\"                 \"0.144\"            \n[4] \"mu\"                \":\"                 \"-1.42083746164812\"\n\n\n\nExercise 41.4  Below are four possible values for the standard deviation of the normal proposal distribution in the algorithm. Which one yields the best sampling results?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n0.5\n1.5\n3.0\n4.0\n\n\n\n\n\nExercise 41.5  Report the posterior mean point estimate for μ, the mean growth, using these six data points. Round your answer to two decimal places.M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n-1.46\n\nThe sample mean of the six points is -1.62. Clearly the prior has some influence on this estimate.",
    "crumbs": [
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Honnors Homework on M-H algorithm</span>"
    ]
  },
  {
    "objectID": "C2-L07.html",
    "href": "C2-L07.html",
    "title": "42  M3L7 - Linear regression",
    "section": "",
    "text": "42.1 Introduction to linear regression\nWe discussed linear regression briefly in the previous course. And we fit a few models with non-informative priors. Here, we’ll provide a brief review, demonstrate fitting linear regression models in JAGS And discuss a few practical skills that are helpful when fitting linear models in general.\nThis is not meant to be a comprehensive treatment of linear models, which you can find in numerous courses and textbooks.\nLinear regression is perhaps the simplest way to relate a continuous response variable to multiple explanatory variables.\nThis may arise from observing several variables together and investigating which variables correlate with the response variable. Or it could arise from conducting an experiment, where we carefully assign values of explanatory variables to randomly selected subjects. And try to establish a cause-and-effect relationship.\nA linear regression model has the following form:\ny_i=\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k + \\epsilon_i\n\\\\ \\epsilon_i \\stackrel {iid} \\sim N(0,\\sigma^2)\n\\tag{42.1}\nThis describes the mean, and then we would also add an error, individual term for each observation. We would assume that the errors are IID from a normal distribution means 0 variance \\sigma^2 for observations 1 \\ldots k.\nEquivalently we can write this model for y_i directly as y_i given all of the x_i values, betas and a constant variance \\sigma^2. Again, k is the number of predictor variables.\ny_i\\mid x_i,\\beta_i,\\sigma^2 \\sim N(\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k, \\sigma^2)\n\\\\ \\beta_i \\sim \\mathbb{P}r(\\beta_i)\n\\\\ \\sigma^2 \\sim \\mathbb{P}r(\\sigma^2)\n\\tag{42.2}\nThis yields the following graphical model structure.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeOneSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeTwoSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeThreeSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFourSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFiveSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmtt10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmb10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmss10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['DejaVu Sans Display'] not found. Falling back to DejaVu Sans.\n\n\n\n\n\n\n\n\nFigure 42.1: The graphical model for linear regression\nThe terms of a linear model are always linearly related because of the structure of the model.\nBut the model does not have to be linear necessarily in the xy relationship. For example, it may be that y is related linearly to x^2. Hence we could transform the x and y variables to get new x’s and new y’s but we would still have a linear model. However, in that case, if we transform the variables, we must be careful about how this changes the final interpretation of the results.",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-introduction-to-linear-regression",
    "href": "C2-L07.html#sec-introduction-to-linear-regression",
    "title": "42  M3L7 - Linear regression",
    "section": "",
    "text": "Introduction to linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantUnderstanding the Graphical Models\n\n\n\n\nThis graphical model uses plate notation\nWe’ll start with a plate for all of our different y variables,\n\nIt is repeated i = 1 \\ldots N times\n\ny_i, are random variable - (indicated by a circle)\n\nthey are observed - indicated by a filled shape.\n\nX_i variables.\n\nthey are drawn as squares around to indicate that they are constants and not random variables.\nWe’re always conditioning on the Xs. So they’ll just be constants.\nthey are observed, so they are filled in.\n\nThe y_i depend on the values of the x and the values of these parameters. So, we have \\beta_0, \\ldots, \\beta_k.\nSigma squared.\nSince the y_i depend on all of these, so this would be the graphical model representation.\n\n\n\n\n\n\n\n\n\n\n\nImportantInterpreting Coefficients\n\n\n\nThe basic interpretation of the \\beta_i coefficients is:\nWhile holding all other X variables constant, if we increases X_i by one then the mean of \\bar{y} is expected to increase by \\beta_i .\nThat is \\beta_i describes how the \\bar{y} changes with changes in X_i, while accounting for all the other X variables.\n\n\\beta \\approx  \\frac{\\partial \\bar{y} }{\\partial x_i}\n\\tag{42.3}\nThat’s true for all of the x variables.\n\n\n\n\n\n\n\n\nWarningRegression assumptions\n\n\n\nWe’re going to assume that\n\nThe ys are independent of each other, given the xs.\nThe y_is have the same variance.\nThe residuals are normally distributed with mean 0 and variance \\sigma^2.\n\nThese are actually strong assumptions that are not often not realistic in many situations.\nThere are many statistical models to address that.\nWe’ll look at some hierarchical methods in the coming lessons.\n\n\n\n42.1.1 Priors\nThe model is not complete until we add the prior distributions.\nSo we might say \\beta_0 comes from its prior.\n\\beta_1 would come from its prior, and so forth for all the \\betas. And sigma squared would come from its prior.\nThe most common choice for prior on the \\betas, is a Normal distribution. Or we can do a Multivariate normal for all of the betas at once.\nThis is conditionally conjugate and allows us to do Gibbs sampling.\nIf we want to be non-informative, we can choose Normal(0,\\sigma^2=1e6) priors with very large variance. Which are practically flat for realistic values of beta. The non-informative priors used in the last class are equivalent to using normal priors with infinite variance.\nWe can also use the conditionally conjugate InverseGamma() prior for \\sigma^2 that we’re familiar with.\nAnother common prior for the betas is Double exponential, or the Laplace prior, or Laplace distribution. \nThe Laplace prior has this density:\n\nf(x\\mid \\mu,\\beta)=\\frac{1}{2\\beta} e^{|\\frac{x-\\mu}{\\beta}|}\n\\tag{42.4}\nwhere:\n\n\\mu is the location parameter and\n\\beta is the scale parameter.\n\nThe case where \\mu = 0 and \\beta = 1 is called the standard double exponential distribution\n\nf(x)=\\frac{1}{2} e^{|x|}\n\\tag{42.5}\nAnd the density looks like this.\n\n\n\n\n\n\n\nFigure 42.2: The Double Exponential Distribution\n\n\n\n\n\n\n\n\n\n\nFigure 42.3: The Double Exponential Distribution\n\n\n\n\nRPython\n\n\n\n\nCode\n# Grid of X-axis values\nx &lt;- seq(-10, 10, 0.1)\nplot(x,  ddexp(x, 0, 2), type = \"l\", ylab = \"\", lwd = 2, col = \"red\")\nlines(x, ddexp(x, 0, 1.5), type = \"l\", ylab = \"\", lwd = 2, col = \"green\")\nlines(x, ddexp(x, 0, 1), type = \"l\", ylab = \"\", lwd = 2, col = \"blue\")\nlegend(\"topright\",\n       c(expression(paste(, beta)), \"1.5\",\"1\", \"2\"),\n       lty = c(0, 1, 1, 1),\n       col = c(\"red\",\"green\", \"blue\"), box.lty = 0, lwd = 2\n      )\n\n#x &lt;- rdexp(500, location = 2, scale = 1)\n#de_sample=ddexp(x, 2, 1)\n#CDF &lt;- ecdf(de_sample )\n#plot(CDF)\n\n\n\n\n\n\n\nCode\nloc, scale = 0., 1.\ns = np.random.laplace(loc, scale, 1000)\n\ncount, bins, ignored = plt.hist(s, 30, density=True)\nx = np.arange(-8., 8., .01)\npdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\nplt.plot(x, pdf);\n\ng = (1/(scale * np.sqrt(2 * np.pi)) *\n     np.exp(-(x - loc)**2 / (2 * scale**2)))\nplt.plot(x,g);\n\n\n\n\n\n\nIt’s called double exponential because it looks like the exponential distribution except it’s been reflected over the y axis. It has a sharp peak at x equals 0, or beta equals 0 in this case, which can be useful if we want to do variable selection among our x’s. Because it’ll favor values in your 0 for these betas.\nThis is related to the popular regression technique known as the LASSO. \nMore information is available from:\n\nNIST\nWikipedia",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#eda",
    "href": "C2-L07.html#eda",
    "title": "42  M3L7 - Linear regression",
    "section": "43.1 EDA",
    "text": "43.1 EDA\n\n\nCode\n1pairs(Leinhardt)\n\n\n\n1\n\nUsing pairs to investigate the marginal relationships between each of the four variables.\n\n\n\n\n\n\n\n\n\n\n\n\n43.1.0.1 Simple linear Model\nWe’ll start with a simple linear regression model that relates infant mortality to per capita income.\n\n\nCode\nplot(infant ~ income, data=Leinhardt)\n\n\n\n\n\n\n\n\n\n\n\nCode\nhist(Leinhardt$infant)\n\n\n\n\n\n\n\n\n\nthis is right-skewed (many small values and a number of much larger one)\n\n\nCode\nhist(Leinhardt$income)\n\n\n\n\n\n\n\n\n\nalso right-skewed.\nthis indicates that we may do better if we do a log transform on these two variables.\n\n\n43.1.0.2 Log-Log Linear Model\n\n\nCode\n1Leinhardt$loginfant = log(Leinhardt$infant)\n2Leinhardt$logincome = log(Leinhardt$income)\n\n\n3plot(loginfant ~ logincome,data=Leinhardt)\n\n\n\n1\n\nlog transform infant column.\n\n2\n\nlog transform income column.\n\n3\n\nscatter plot of the log log transformed data.\n\n\n\n\n\n\n\n\n\n\nFigure 43.1: log log transformed infant mortality vs income\n\n\n\n\n\nSince infant mortality and per capita income are positive and right-skewed quantities, we consider modeling them on the logarithmic scale. A linear model appears much more appropriate on this scale.\n\n\nCode\n1scatterplot(loginfant ~ logincome,data=Leinhardt)\n\n\n\n1\n\nscatterplot with a regression fit and uncertainty for the data\n\n\n\n\n\n\n\n\n\n\nFigure 43.2: log log transformed infant mortality vs income scatterplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n43.1.1 Modeling\nThe reference Bayesian analysis (with a non-informative prior) is available directly in R.\n\n\nCode\nlmod0 = lm(loginfant ~ logincome, data=Leinhardt)\nsummary(lmod0)\n\n\n\n\nregression output\nlm(formula = loginfant ~ logincome, data = Leinhardt)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.66694 -0.42779 -0.02649  0.30441  3.08415 \n\nCoefficients: \n            Estimate Std. Error t value Pr(&gt;|t|)    \n1(Intercept)  7.14582    0.31654  22.575   &lt;2e-16 ***\n2logincome   -0.51179    0.05122  -9.992   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n3Residual standard error: 0.6867 on 99 degrees of freedom\n4  (4 observations deleted due to missingness)\n5Multiple R-squared:  0.5021,    Adjusted R-squared:  0.4971\nF-statistic: 99.84 on 1 and 99 DF,  p-value: &lt; 2.2e-16\n\n\n\n1\n\nintercept is \\gg its error so it appears statistically significant (***)\n\n2\n\nposterior mean logincome too\n\n3\n\nResidual standard error gives us an estimate of the left over variance after fitting the model.\n\n4\n\n4 rows were dropped due to missing values\n\n5\n\nAdjusted R-squared is the explained variance adjusted for degrees of freedom",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-residual-checks",
    "href": "C2-L07.html#sec-residual-checks",
    "title": "42  M3L7 - Linear regression",
    "section": "45.1 Residual checks",
    "text": "45.1 Residual checks\n\n\n\n\n\n\nImportant\n\n\n\nAnalysis gets complicated quickly when we have multiple models. What we shall soon see is how to get residuals from the Bayesian model in Stan so we can compare it visually with the reference model we got using LM.\n\n\nChecking residuals (the difference between the response and the model’s prediction for that value) is important with linear models since residuals can reveal violations of the assumptions we made to specify the model. In particular, we are looking for any sign that the model is not linear, normally distributed, or that the observations are not independent (conditional on covariates).\nFirst, let’s look at what would have happened if we fit the reference linear model to the un-transformed variables.\n\n\nCode\nlmod0 = lm(infant ~ income, data=Leinhardt)\nplot(resid(lmod0)) # to check independence (looks okay)\n\n\n\n\n\n\n\n\n\nthere should not be a pattern - but we can see an increase. This is not an issue and due to the data being presorted.\n\n\nCode\nplot(predict(lmod0), resid(lmod0)) # to check for linearity, constant variance (looks bad)\n\n\n\n\n\n\n\n\n\nafter 80 the variance starts increasing\n\n\nCode\nqqnorm(resid(lmod0)) # to check Normality assumption (we want this to be a straight line)\n\n\n\n\n\n\n\n\n\nCode\n#?qqnorm\n\n\nThis looks good except for the last few points.\nNow let’s return to our model fit to the log-transformed variables. In a Bayesian model, we have distributions for residuals, but we’ll simplify and look only at the residuals evaluated at the posterior mean of the parameters.\n\n\nCode\nX = cbind(rep(1.0, data1_jags$n), data1_jags$log_income)\nhead(X)\n\n\n     [,1]     [,2]\n[1,]    1 8.139149\n[2,]    1 8.116716\n[3,]    1 8.115521\n[4,]    1 8.466110\n[5,]    1 8.522976\n[6,]    1 8.105308\n\n\n\n\nCode\n1(pm_params1 = colMeans(mod1_csim))\n\n\n\n1\n\nposterior mean - using (var = expr) forces R to return the value of var\n\n\n\n\n      b[1]       b[2]        sig \n 7.1377978 -0.5104394  0.9709716 \n\n\n\n\nCode\n1yhat1 = drop(X %*% pm_params1[1:2])\n2resid1 = data1_jags$y - yhat1\n3plot(resid1)\n\n\n\n1\n\nwe are evaluating \\\\hat{y} = b_0 \\times 1 + b_1 \\times x_1 via matrix multiplication of [1, data1_jags$log_income] *[b_0,b_1]\n\n2\n\nres_i = y_i- \\hat y = y_i - (b_0 \\times 1 + b_1 \\times x_{1,i})\n\n3\n\nplots the residual against the data index\n\n\n\n\n\n\n\n\n\n\n\nSo to get the residuals from Stan we extract the b parameter.\nAlthough we did not discuss it we could estimate \\hat y by drawing K predictions for each x_i and look at res_i=\\frac{1}{K}\\sum_k|y_i -\\hat y_{i,k}| and plot upper and fit a line as well as lower and upper bounds as well. Also I’m not sure but I guess we can also do with using the predictive posterior dist. Anyhow here is a link to something like this: Extracting and visualizing tidy residuals from Bayesian models -jk\n\n\nCode\nplot(yhat1, resid1) # against predicted values\n\n\n\n\n\n\n\n\n\n\n\nCode\nqqnorm(resid1) # checking normality of residuals\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(predict(lmod0), resid(mod1)) # to compare with reference linear model\n\n\n\n\n\n\n\n\n\n\n\nCode\nrownames(dat)[order(resid1, decreasing=TRUE)[1:5]] # which countries have the largest positive residuals?\n\n\n[1] \"Saudi.Arabia\" \"Libya\"        \"Zambia\"       \"Brazil\"       \"Afganistan\"  \n\n\nThe residuals look pretty good here (no patterns, shapes) except for two strong outliers, Saudi Arabia and Libya. When outliers appear, it is a good idea to double check that they are not just errors in data entry. If the values are correct, you may reconsider whether these data points really are representative of the data you are trying to model. If you conclude that they are not (for example, they were recorded on different years), you may be able to justify dropping these data points from the data set.\nIf you conclude that the outliers are part of data and should not be removed, we have several modeling options to accommodate them. We will address these in the next segment.",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-additional-covariates",
    "href": "C2-L07.html#sec-additional-covariates",
    "title": "42  M3L7 - Linear regression",
    "section": "46.1 Additional covariates",
    "text": "46.1 Additional covariates\nThe first approach is to look for additional covariates that may be able to explain the outliers. For example, there could be a number of variables that provide information about infant mortality above and beyond what income provides.\nLooking back at our data, there are two variables we haven’t used yet: region and oil. The oil variable indicates oil-exporting countries. Both Saudi Arabia and Libya are oil-exporting countries, so perhaps this might explain part of the anomaly.\n\n\nCode\nlibrary(\"rjags\")\n\nmod2_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[i], prec)\n1        mu[i] = b[1] + b[2]*log_income[i] + b[3]*is_oil[i]\n    }\n    \n2    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*10.0/2.0)\n    sig = sqrt( 1.0 / prec )\n} \"\n\n\nset.seed(73)\ndata2_jags = list(y=dat$loginfant, log_income=dat$logincome,\n3                  is_oil=as.numeric(dat$oil==\"yes\"))\ndata2_jags$is_oil\n\nparams2 = c(\"b\", \"sig\")\n\ninits2 = function() {\n4    inits = list(\"b\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod2 = jags.model(textConnection(mod2_string), data=data2_jags, inits=inits2, n.chains=3)\nupdate(mod2, 1e3) # burn-in\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params2,\n                        n.iter=5e3)\n\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim)) # combine multiple chains\n\n\n\n1\n\nwe add the is_oil indicator parameter\n\n2\n\nwe increment the number of parameters\n\n3\n\nencode the is_oil from text to be binary\n\n4\n\ndraw another var for b.\n\n\n\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 101\n   Unobserved stochastic nodes: 4\n   Total graph size: 507\n\nInitializing model\n\n\nAs usual, check the convergence diagnostics.\n\n\nCode\npar(mar = c(2., 1, 2., 1))\nplot(mod2_sim)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod2_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]          1       1.01\nb[2]          1       1.01\nb[3]          1       1.00\nsig           1       1.00\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod2_sim)\n\n\n             b[1]       b[2]          b[3]          sig\nLag 0  1.00000000 1.00000000  1.0000000000  1.000000000\nLag 1  0.94810120 0.94920630  0.0826130538  0.014810592\nLag 5  0.77186037 0.77285751  0.0063910311 -0.006334485\nLag 10 0.59723677 0.59848994 -0.0006977619 -0.004825090\nLag 50 0.06558183 0.06830724  0.0023020017 -0.004079886\n\n\n\n\nCode\n#autocorr.plot(mod2_sim,auto.layout=FALSE )\nautocorr.plot(mod2_csim,auto.layout=FALSE )\n\n\n\n\n\n\n\n\nFigure 46.1: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 46.2: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 46.3: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 46.4: auto-correlation plot\n\n\n\n\n\n\n\nCode\neffectiveSize(mod2_sim)\n\n\n      b[1]       b[2]       b[3]        sig \n  386.6284   390.8320 12711.2915 14692.8618 \n\n\nWe can get a posterior summary of the parameters in our model.\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nb[1]  7.1913 0.42208 0.0034462      0.0215666\nb[2] -0.5296 0.06826 0.0005573      0.0034603\nb[3]  0.7943 0.35278 0.0028804      0.0031299\nsig   0.9529 0.06674 0.0005449      0.0005509\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%     75%   97.5%\nb[1]  6.3590  6.9101  7.1903  7.4761  8.0084\nb[2] -0.6630 -0.5755 -0.5294 -0.4833 -0.3948\nb[3]  0.1125  0.5536  0.7923  1.0294  1.4940\nsig   0.8339  0.9067  0.9493  0.9950  1.0964\n\n\nIt looks like there is a positive relationship between oil-production and log-infant mortality. Because these data are merely observational, we cannot say that oil-production causes an increase in infant mortality (indeed that most certainly isn’t the case), but we can say that they are positively correlated.\nNow let’s check the residuals.\n\n\nCode\nX2 = cbind(rep(1.0, data1_jags$n), data2_jags$log_income, data2_jags$is_oil)\nhead(X2)\n\n\n     [,1]     [,2] [,3]\n[1,]    1 8.139149    0\n[2,]    1 8.116716    0\n[3,]    1 8.115521    0\n[4,]    1 8.466110    0\n[5,]    1 8.522976    0\n[6,]    1 8.105308    0\n\n\n\n\nCode\n(pm_params2 = colMeans(mod2_csim)) # posterior mean\n\n\n      b[1]       b[2]       b[3]        sig \n 7.1913377 -0.5295521  0.7943341  0.9528550 \n\n\n\n\nCode\nyhat2 = drop(X2 %*% pm_params2[1:3])\nresid2 = data2_jags$y - yhat2\nplot(resid2) # against data index\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(yhat2, resid2) # against predicted values\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(yhat1, resid1) # residuals from the first model\n\n\n\n\n\n\n\n\n\n\n\nCode\nsd(resid2) # standard deviation of residuals\n\n\n[1] 0.6489675\n\n\nThese look much better, although the residuals for Saudi Arabia and Libya are still more than three standard deviations away from the mean of the residuals. We might consider adding the other covariate region, but instead let’s look at another option when we are faced with strong outliers.\n\n46.1.1 Student-t likelihood\n\nLet’s consider changing the likelihood.\nThe normal likelihood has thin tails (almost all of the probability is concentrated within the first few standard deviations from the mean).\nThis does not accommodate outliers well.\nConsequently, models with the normal likelihood might be overly-influenced by outliers.\nRecall that the t distribution is similar to the normal distribution, but it has thicker tails which can accommodate outliers.\n\nThe t linear model might look something like this. Notice that the t distribution has three parameters, including a positive “degrees of freedom” parameter. The smaller the degrees of freedom, the heavier the tails of the distribution. We might fix the degrees of freedom to some number, or we can assign it a prior distribution.\n\n\nCode\ncurve(dnorm(x), from = -5, to = 5)\ncurve(dt(x,1), from = -5, to = 5,col=\"red\", add = TRUE)\n\n\n\n\n\n\nnormal and t distributions\n\n\n\n\n\nCode\nmod3_string = \" model {\n1    for (i in 1:length(y)) {\n        y[i] ~ dt( mu[i], tau, df )\n        mu[i] = b[1] + b[2]*log_income[i] + b[3]*is_oil[i]\n    }\n    \n    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n2    nu ~ dexp(1.0)\n3    df = nu + 2.0\n    \n4    tau ~ dgamma(5/2.0, 5*10.0/2.0)\n5    sig = sqrt( 1.0 / tau * df / (df - 2.0) )\n}\"\n\n\n\n1\n\nwe replaced normal likelihood with a student t likelihood which has thicker tails\n\n2\n\n\\nu nu is the degrees of freedom (dof) but the outcome can be 0 or 1\n\n3\n\nwe force the degrees of freedom dof&gt;2 to guarantee the existence of mean and variance in the t dist.\n\n4\n\n\\tau tau is the inverse scale is close to, but not equal to the precision from above so we use the same prior as we used for precision.\n\n5\n\n\\sigma sig standard deviation of errors is a deterministic function of tau, and df\n\n\n\n\nWe fit this model.\n\n\nCode\nset.seed(73)\ndata3_jags = list(y=dat$loginfant, log_income=dat$logincome,\n                  is_oil=as.numeric(dat$oil==\"yes\"))\n\nparams3 = c(\"b\", \"sig\")\n\ninits3 = function() {\n    inits = list(\"b\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, inits=inits3, n.chains=3)\nupdate(mod3, 1e3) # burn-in\n\nmod3_sim = coda.samples(model=mod3,\n                        variable.names=params3,\n                        n.iter=5e3)\n\nmod3_csim = as.mcmc(do.call(rbind, mod3_sim)) # combine multiple chains\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 101\n   Unobserved stochastic nodes: 5\n   Total graph size: 512\n\nInitializing model\n\n\ncheck MCMC convergence visually\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod3_sim)\n\n\n\n\n\n\n\n\n\ncheck MCMC convergence quantitatively using Rubin Gelman\n\n\nCode\ngelman.diag(mod3_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]       1.01       1.03\nb[2]       1.01       1.03\nb[3]       1.00       1.00\nsig        1.07       1.07\n\nMultivariate psrf\n\n1.01\n\n\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n     b[1]      b[2]      b[3]       sig \n 286.6588  280.1114 8598.8215 9587.5559",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-compare-models-using-deviance-information-criterion-dic",
    "href": "C2-L07.html#sec-compare-models-using-deviance-information-criterion-dic",
    "title": "42  M3L7 - Linear regression",
    "section": "46.2 Compare models using Deviance information criterion (DIC)",
    "text": "46.2 Compare models using Deviance information criterion (DIC)\n We have now proposed three different models. How do we compare their performance on our data? In the previous course, we discussed estimating parameters in models using the maximum likelihood method. Similarly, we can choose between competing models using the same idea.\nWe will use a quantity known as the deviance information criterion (DIC). It essentially calculates the posterior mean of the log-likelihood and adds a penalty for model complexity.\nLet’s calculate the DIC for our first two models:\nthe simple linear regression on log-income,\n\n\nCode\ndic.samples(mod1, n.iter=1e3)\n\n\nMean deviance:  231.4 \npenalty 2.961 \nPenalized deviance: 234.3 \n\n\nand the second model where we add oil production.\n\n\nCode\ndic.samples(mod2, n.iter=1e3)\n\n\nMean deviance:  225.2 \npenalty 3.729 \nPenalized deviance: 228.9 \n\n\nand the second model where we introduce the Student t likelihood.\n\n\nCode\ndic.samples(mod3, n.iter=1e3)\n\n\nMean deviance:  231.2 \npenalty 4.054 \nPenalized deviance: 235.2 \n\n\nThe first number is the Monte Carlo estimated posterior mean deviance, which equals -2 times the log-likelihood (plus a constant that will be irrelevant for comparing models). Because of that -2 factor, a smaller deviance means a higher likelihood.\nNext, we are given a penalty for the complexity of our model. This penalty is necessary because we can always increase the likelihood of the model by making it more complex to fit the data exactly. We don’t want to do this because over-fit models generalize poorly. This penalty is roughly equal to the effective number of parameters in your model. You can see this here. With the first model, we had a variance parameter and two betas, for a total of three parameters. In the second model, we added one more beta for the oil effect.\nWe add these two quantities to get the DIC (the last number). The better-fitting model has a lower DIC value. In this case, the gains we receive in deviance by adding the is_oil covariate outweigh the penalty for adding an extra parameter. The final DIC for the second model is lower than for the first, so we would prefer using the second model.\nWe encourage you to explore different model specifications and compare their fit to the data using DIC. Wikipedia provides a good introduction to DIC and we can find more details about the JAGS implementation through the rjags package documentation by entering ?dic.samples in the R console.\n\n\nCode\n#?dic.samples",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-regression-diagnostics",
    "href": "C2-L07.html#sec-regression-diagnostics",
    "title": "42  M3L7 - Linear regression",
    "section": "46.3 Regression Diagnostics",
    "text": "46.3 Regression Diagnostics\nIn production we want to flag regression issues in an automated fashion. However while we develop models we should try to examine these issues visually.\nRegression diagnostics help identify:\n\nshortcoming of our model and the preferred ways to improve them\n\ntransforms of variables\ndifferent likelihood\nadding missing covariate relations to remove patterns in the residuals\nincreasing interpretability by removing covariates that do not contribute to the fit.\n\nissues in the data\n\ntransformation\n\n\nwe should consider the following issues: 1. testing heteroscedasticity with the Breusch-Pagan test\nLet’s try to cover the diagnostic plots which help us validate a regression model.\n\n46.3.1 Residuals vs Fitted\n\nThe “residuals versus fits plot” is the most first diagnostic tool we\nshould look at to determine if the regression is valid. If the regression assumptions are violated we should be able to identify the issues and possibly correct them.\nIt is a scatter plot of residuals on the y axis and fitted values (estimated responses) on the x axis.\nThe plot can be used to detect:\n\nnon-linearity,\nunequal error variances, and\noutliers.\n\n\n\n\nCode\nplot(lmod0, 1)\n\n\n\n\n\nResiduals vs Fitted plot\n\n\n\n\nResiduals will enable us to assess visually whether an appropriate model has been fit to the data no matter how many predictor variables are used. We can checking the validity of a linear regression model by plotting residuals versus x and look for patterns. - Lack of a discernible pattern is indicative of a valid model. - A pattern is is indicative that a function or transformation of X is missing from the model.\n\n\n\n\n\n\nImportantWhat to look for\n\n\n\nLook for patterns that can indicate non-linearity,\n\nthat the residuals all are high in some areas and low in others. Change in variability as X changes - U shape missing quadratic term · we can get this plot as follows.\n\nThe blue line is there to aid the eye - it should ideally be relatively close to a straight line (in this case, it isn’t perfectly straight, which could indicate a mild non-linearity).\n\n\n\n\n46.3.2 QQ plot of the residuals\nThis plot shows if residuals are normally distributed. Do residuals follow a straight line well or do they deviate severely?\nThe regression is valid if the residuals are lined well on the straight dashed line.\nwe can get this plot as follows\n\n\nCode\nplot(lmod0, 2)\n\n\n\n\n\n\n\n\n\nnotice that the two outliers are labeled and should be reviewed for - removal - more robust likelihood\nfor more info see understanding QQ plots\n\n\n46.3.3 Scale Location plot\nThis plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance (homoscedasticity). It’s good if you see a horizontal line with equally (randomly) spread points.\n\n\nCode\nplot(lmod0, 3)\n\n\n\n\n\n\n\n\n\nin this case: - most of the points are to the right - the red line is almost flat which is good - there is increasing variance after 80\n\n\n46.3.4 Cook’s Distance\n\nOriginally introduced in (Cook 1977a) Cook’s Distance is an estimate of the influence of a data point.\nIt takes into account both the leverage and residual of each observation.\nCook’s Distance is a summary of how much a regression model changes when the ith observation is removed.\nWhen it comes to outliers we care about outliers that have a high Cook’s distance as they can have a large impact on the regression model. by shifting the sample fit from the population fit.\nAnother aspect of Cook’s distance is it can be used to identify regions of the design space where the model is poorly supported by the data - i.e. where the model is extrapolating and if we can get more data in that region we can improve the model.\n\n\n\nCode\nplot(lmod0, 4)\n\n\n\n\n\n\n\n\n\nUsed to detect highly influential outliers, i.e. points that can shift the sample fit from the population fit. For large sample sizes, a rough guideline is to consider values above 4/(n-p), where n is the sample size and p is the number of predictors including the intercept, to indicate highly influential points.\nsee Williams (1987)\n\n\n46.3.5 Residuals vs Leverage\n\n\nCode\nplot(lmod0, 5)\n\n\n\n\n\n\n\n\n\nCode\n#plot(mod3, 5)\n\n\nThis plot helps us to sort through the outliers, if there are any. Not all outliers are influential in linear regression analysis. Even though data have extreme values, they might not be influential to determine a regression line. i.e. the fit wouldn’t be much different if we choose to omit them from the analysis. If a point is able to exert a influence on the regression line we call it a high leverage point. Even in this case it might not alter the trend. So we want to identify high leverage points that are at a large distance from their predictor’s mean.\nUnlike the other plots, this time patterns are not relevant. We watch out for outlying values at the upper right corner or at the lower right corner. Those spots are the places where cases can be influential against a regression line. Look for cases outside of the dashed lines. When cases are outside of the dashed lines (meaning they have high “Cook’s distance” scores), the cases are influential to the regression results. The regression results will be altered if we exclude those cases.\nIn this case we see that the pints are within the cook’s distance contours so our outliers are not high leverage points.\n\n\n46.3.6 Cook’s Distance vs Leverage\n\n\nCode\nplot(lmod0, 6)\n\n\n\n\n\n\n\n\nFigure 46.5: Cooks distance v.s. Leverage\n\n\n\n\n\nCook’s distance and leverage are used to detect highly leverage points, i.e. data points that can shift the sample fit from the population fit.\nFor large sample sizes, a rough guideline is to consider Cook’s distance values above 1 to indicate highly influential points and leverage values greater than 2 times the number of predictors divided by the sample size to indicate high leverage observations. High leverage observations are ones which have predictor values very far from their averages, which can greatly influence the fitted model.\nThe contours in the scatterplot are standardized residuals labelled with their magnitudes\nsee Williams (1987)\n\n\n46.3.7 Python\n\nhttps://emredjan.xyz/blog/2017/07/11/emulating-r-plots-in-python/\nhttps://towardsdatascience.com/going-from-r-to-python-linear-regression-diagnostic-plots-144d1c4aa5a\nhttps://modernstatisticswithr.com/regression.html\n\n\n\n\n\n\n\nCook, R. Dennis. 1977b. “Detection of Influential Observation in Linear Regression.” Technometrics 19 (1): 15. https://doi.org/10.2307/1268249.\n\n\n———. 1977a. “Detection of Influential Observation in Linear Regression.” Technometrics 19 (1): 15. https://doi.org/10.2307/1268249.\n\n\nWilliams, D. A. 1987. “Generalized Linear Model Diagnostics Using the Deviance and Single Case Deletions.” Applied Statistics 36 (2): 181. https://doi.org/10.2307/2347550.",
    "crumbs": [
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>M3L7 - Linear regression</span>"
    ]
  },
  {
    "objectID": "C2-L07-Ex1.html",
    "href": "C2-L07-Ex1.html",
    "title": "43  HW on Linear Regression Model Part 1",
    "section": "",
    "text": "Exercise 43.1 Linear Regression\nIn a normal linear regression model with\n\nE(y_i)=\\beta_0+\\beta_1x_{1,i}+\\beta_2x_{2,i}+\\beta_3x_{3,i}\n\nwhich of the following gives the correct interpretation of \\beta_2?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWhile holding x_{2,i} constant, the expectation of y_{i} is \\beta_{2}.\nWhile holding x_{1,i} and x{3,i} constant, a one unit change in x_{2,i} results in a \\beta_2 change in y_i.\nWhile holding x_{1,i} and x_{3,i} constant, a one unit change in x_{2,i} results in a \\beta_2 change in the expectation of y_i.\nWhen x_{2,i}=0, a one unit change in x_{1,i} and x_{3,i} results in a \\beta_2 in y_i.\n\nThis is how much the expected response increases when we increase x2,i by 1.0 while controlling for the other predictors.\n\n\n\n\nExercise 43.2 Linear Regression\nWhich of the following model specifications for E(y_i) is not a valid linear model?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 ( x_{1,i} / x_{2,i} )\n\\beta_0 + \\beta_1 \\sin( 2 \\pi x_{1,i}) + \\beta_2 x_{2,i}\n\\beta_0 + \\beta_1 \\log (x_{1,i}) + \\beta_2 x_{2,i}^2\n\\beta_0 + \\exp(\\beta_1 x_{1,i} ) + \\beta_2 x_{2,i}^2\n\nThis model is not linear in the coefficients. We are free to transform the predictors and the response, but the model itself must be linear.\n\n\n\n\nExercise 43.3  Consider the Anscombe data set in R which can be accessed with the following code:Linear Regression\n\n\nCode\nlibrary(\"car\")  # load the 'car' package\n\n\nLoading required package: carData\n\n\nCode\ndata(\"Anscombe\")  # load the data set\n?Anscombe  # read a description of the data\n\n\n\n\nCode\nhead(Anscombe)  # look at the first few lines of the data\n\n\n   education income young urban\nME       189   2824 350.7   508\nNH       169   3259 345.9   564\nVT       230   3072 348.5   322\nMA       168   3835 335.3   846\nRI       180   3549 327.1   871\nCT       193   4256 341.0   774\n\n\n\n\nCode\npairs(Anscombe)  # scatter plots for each pair of variables\n\n\n\n\n\n\n\n\nFigure 43.1: Anscombe Pair plot\n\n\n\n\n\nSuppose we are interested in relating per-capita education expenditures to the other three variables. Which variable appears to have the strongest linear relationship with per-capita education expenditures?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nProportion of population that is urban\nNone of these variables appears to have a linear relationship with education expenditures.\nProportion of population under age 18\nPer-capita income\n\nIt appears that increases in income generally co-occur with increases in education expenditures.\n\n\n\n\nExercise 43.4 Linear Regression\nFit a reference (non-informative) Bayesian linear model to the Anscombe data with education expenditures as the response variable and include all three other variables as predictors. Use the lm function in R.\nWhat is the posterior mean estimate of the intercept in this model? Round your answer to one decimal place.\n\n\n\nCode\nmod_0=lm(data = Anscombe,formula = 'education ~ income + young + urban')\nsummary((mod_0))\n\n\n\nCall:\nlm(formula = \"education ~ income + young + urban\", data = Anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-60.240 -15.738  -1.156  15.883  51.380 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.868e+02  6.492e+01  -4.418 5.82e-05 ***\nincome       8.065e-02  9.299e-03   8.674 2.56e-11 ***\nyoung        8.173e-01  1.598e-01   5.115 5.69e-06 ***\nurban       -1.058e-01  3.428e-02  -3.086  0.00339 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.69 on 47 degrees of freedom\nMultiple R-squared:  0.6896,    Adjusted R-squared:  0.6698 \nF-statistic: 34.81 on 3 and 47 DF,  p-value: 5.337e-12\n\n\n\nCode\n## Allow room for printing model formula in outer margin:\npar( # mfrow = c(2, 3),\n    mar = c(3.5, 3.5, 2, 1),  oma = c(0, 0, 2, 0),  mgp = c(2.4, 0.8, 0)\n)\n# plot(mod_0,which=1:6,)\nfor (i in 1:6) {\n    plot(mod_0, which = i)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Residuals vs Fitted\n\n\n\n\n\n\n\n\n\n\n\n(b) Q-Q Residuals\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Scale-Location\n\n\n\n\n\n\n\n\n\n\n\n(d) Cook’s distance\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Residuals vs Leverage\n\n\n\n\n\n\n\n\n\n\n\n(f) Cook’s distance vs Leverage\n\n\n\n\n\n\n\nFigure 43.2: Diagnostic Charts\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n-286.84\n\nProper MCMC algorithms come with a theoretical guarantee of eventual convergence to the target distribution. Chains with very high autocorrelation may require an impractical number of iterations, but it is worth checking to see if a longer chain yields acceptable results.\n\n\n\n\nExercise 43.5  In our reference analysis of the Anscombe data, the intercept is estimated to be negative. Does this parameter have a meaningful interpretation?Linear Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nYes, it represents expected expenditures in a state with average income, average percent youth, and average percent urban.\nNo, there must be something wrong with the model because expenditures can never be negative.\nNo, this model should not have an intercept term at all.\nNo, it represents expected expenditures in a state with 0 average income, 0 % youth, and 0 % urban which doesn’t exist.\n\nAlthough this parameter is not very interpretable in this particular example, it is necessary to the model.\nOne strategy for making the intercept more interpretable would be to subtract the averages of the predictors from their values (i.e., x_{1,i}^∗=(x_{1,i}−\\bar{x}_1) ). Then the intercept would represent expected expenditures in a state with average income, average percent youth, and average percent urban.\n\n\n\n\nExercise 43.6 Linear Regression\nUse the code below to fit a linear regression model to the Anscombe data in JAGS. You will need to finish setting up and running the model.\n\n\nCode\nmod_csim = do.call(rbind, mod_sim) # combine multiple chains\n#autocorr.plot(mod_csim)\nnvar &lt;- ncol(as.matrix(mod_csim))\npar(mfrow = c(nvar, 1))\npar(oma = c(1, 1, 1, 1), mar = c(2, 2, 2, 1))  # tight margins\nautocorr.plot(mod_csim, ask = FALSE, auto.layout = FALSE)\n\n\n\n\n\n\n\n\nFigure 43.3\n\n\n\n\n\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\nFigure 43.4\n\n\n\n\n\n\n\nCode\neffectiveSize(mod_sim)\n\n\n       b[1]        b[2]        b[3]         sig \n  225.49203    74.43286   333.97046 11086.12740 \n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 10001:20000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean       SD  Naive SE Time-series SE\nb[1]  0.08032 0.009641 5.566e-05      0.0006432\nb[2]  0.79538 0.154644 8.928e-04      0.0180901\nb[3] -0.10578 0.035982 2.077e-04      0.0019607\nsig  27.41353 2.869888 1.657e-02      0.0274302\n\n2. Quantiles for each variable:\n\n         2.5%      25%      50%      75%    97.5%\nb[1]  0.06101  0.07384  0.08057  0.08695  0.09855\nb[2]  0.48053  0.68506  0.80857  0.90231  1.08664\nb[3] -0.17694 -0.13002 -0.10593 -0.08086 -0.03726\nsig  22.51701 25.39072 27.16787 29.14303 33.80592\n\n\n\n\nCode\nlibrary(\"rjags\")\n\nmod_string = \" model {\n    for (i in 1:length(education)) {\n1        education[i] ~ dnorm(mu[i], prec)\n        mu[i] = b0 + b[1] * income[i] + b[2] * young[i] + b[3] * urban[i] # &lt;2\n    }\n    \n3    b0 ~ dnorm(0.0, 1.0 / 1.0e6)\n    for (i in 1:3) {\n4        b[i] ~ dnorm(0.0, 1.0 / 1.0e6)\n    }\n    \n5    prec ~ dgamma(1.0 / 2.0, 1.0 * 1500.0 / 2.0)\n    sig2 = 1.0 / prec\n    sig = sqrt(sig2)\n} \"\n\ndata_jags = as.list(Anscombe)\nparams = c(\"b\", \"sig\")\ninits = function() {\n  #inits = list(\"b\"=rnorm(2,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n  inits = list(\"b\" = rnorm(2,0.0,1.0/1.0e6), \n               \"prec\" = rgamma(1, 0.5, 1.0*1500.0/2.0) )\n}\n\nset.seed(72)\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\nupdate(mod, 10000) # burn-in\n\nmod_sim = coda.samples(model=mod, variable.names=params,  n.iter=10000)\n\ngelman.diag(mod_sim)\n\n\nautocorr.diag(mod_sim)\n\n#autocorr.plot(mod_sim)\n# we should combine the chains before running this plot\n\n\n\n1\n\nthe likelihood, here perc is the variance of the normal distribution.\n\n3\n\nPrior for the intercept.\n\n4\n\nPriors for the coefficients.\n\n5\n\nInitial guess of variance based on overall variance of education variable. Uses low prior effective sample size. Technically, this is not a true ‘prior’, but it is not very informative.\n\n\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 51\n   Unobserved stochastic nodes: 5\n   Total graph size: 422\n\nInitializing model\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]       1.00       1.01\nb[2]       1.03       1.11\nb[3]       1.01       1.03\nsig        1.00       1.00\n\nMultivariate psrf\n\n1.04\n            b[1]      b[2]      b[3]         sig\nLag 0  1.0000000 1.0000000 1.0000000 1.000000000\nLag 1  0.9849030 0.9948252 0.9749923 0.069092686\nLag 5  0.9278101 0.9754330 0.8880344 0.037703448\nLag 10 0.8643188 0.9537919 0.7993668 0.038738747\nLag 50 0.5382206 0.8065007 0.4115589 0.009456393\n\n\nBefore proceeding to inference, we should check our model.\nThe first step is to check our MCMC chains. Do there appear to be any problems with the chains?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nYes, scale reduction factors are well above 1.0. The chains are not exploring the same distribution.\nYes, there is very high autocorrelation for sig. We should help the chain for sig by fixing the initial value.\nNo, a few thousand iterations will be sufficient for these chains.\nYes, there is very high autocorrelation among the coefficients. It would be good to run the chain for 100,000+ iterations to get reliable estimates.\n\nMCMC algorithms are based on a process guaranteeing convergence to a stationary distribution.\n\n\n\n\nExercise 43.7  Which of the following is not a condition we can check using a residual plot with predicted values on the x-axis and residuals on the y-axis?Linear Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nLinearity of the relationship between predictors and the response\nPresence of outliers\nConstant error variance\nIndependence of the observations\n\nOne way to check this assumption is by plotting predicted values against the data index. In the Anscombe data, we could check to see if residuals are more similar for states that are geographically close than for states that are not geographically close. If that is true, there may be spatial correlation in the data.\n\n\n\n\nExercise 43.8  Check the residual plot described in Question 7 for the Anscombe data. Since the estimates of the coefficients in the reference model are very close to those in the JAGS model, we will just look at the residuals of the reference model. This plot is the first that appears when you run the following code:Linear Regression\n\n\nCode\nplot(mod_0,which = 1)\n# here mod_lm is the object saved when you run lm()\n\n\n\n\n\n\n\n\nFigure 43.5: LM Residual Plot\n\n\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nYes, the observations appear not to be independent.\nYes, there is a curved pattern or shape to the residuals, indicating a nonlinear relationship between the variables.\nYes, the error variability appears to increase as predicted values increase.\nNo, this plot raises no concerns.\nYes, there are a few extreme outliers.\n\nThere is no obvious pattern to these points besides the variability of the residuals. There are alternative versions of linear models that address this issue, but we will not pursue them in this course.",
    "crumbs": [
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>HW on Linear Regression Model Part 1</span>"
    ]
  },
  {
    "objectID": "C2-L07-Ex2.html",
    "href": "C2-L07-Ex2.html",
    "title": "44  HW - Deviance information criterion (DIC)",
    "section": "",
    "text": "Exercise 44.1  What is the primary interpretation of the penalty term in the deviance information criterion (DIC)?DIC\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIt penalizes overly simple models.\nIt gives an effective number of parameters estimated in the model.\nIt estimates the optimal number of predictor variables (covariates) to include in the model.\nIt gives an estimate of how much your mean squared error would increase for each additional parameter estimated.\n\nIt penalizes overly complicated models which fit this particular data set well, but may fail to generalize. This penalty will be particularly useful for hierarchical models.\n\n\n\n\nExercise 44.2  DIC is a helpful tool for selecting among competing models. Which of the following changes to a linear model is not appropriate to evaluate with DIC?DIC\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nAdding or removing candidate covariates (predictors)\nChoice of distribution for the likelihood\nTransformation of covariates (predictors)\nMinor changes to the prior distributions\n\nIf we optimize the model with respect to the prior, we might as well have not used priors. This practice can lead to inflated confidence and misleading results.\nOne exception is if we use a completely different class of priors or prior structure that has a specific purpose, like variable selection. We will explore this in the next lesson.\n\n\n\n\nExercise 44.3  Although the residual analysis of the Anscombe data showed no major problem that we will pursue, it is still worthwhile to compare some competing models. First, calculate and report the DIC for the original model (that you fit for the previous quiz). Round your answer to the nearest whole number.DIC\n\n\nCode\nlibrary(\"rjags\")\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\nCode\nlibrary(\"car\")  # load the 'car' package\n\n\nLoading required package: carData\n\n\nCode\ndata(\"Anscombe\")  # load the data set\n#?Anscombe  # read a description of the data\n#head(Anscombe)  # look at the first few lines of the data\n#pairs(Anscombe)  # scatter plots for each pair of variables\nmod_0=lm(data = Anscombe,formula = 'education ~ income + young + urban')\n#summary((mod_0))\n#par(mar = c(2.5, 1, 2.5, 1))\n#plot(mod_0)\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(education)) {\n        education[i] ~ dnorm(mu[i], prec)\n        mu[i] = b0 + b[1]*income[i] + b[2]*young[i] + b[3]*urban[i]\n    }\n    \n    b0 ~ dnorm(0.0, 1.0/1.0e6)\n    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(1.0/2.0, 1.0*1500.0/2.0)\n        ## Initial guess of variance based on overall\n        ## variance of education variable. Uses low prior\n        ## effective sample size. Technically, this is not\n        ## a true 'prior', but it is not very informative.\n    sig2 = 1.0 / prec\n    sig = sqrt(sig2)\n} \"\n\ndata_jags = as.list(Anscombe)\nhead(data_jags)\n\n\n$education\n [1] 189 169 230 168 180 193 261 214 201 172 194 189 233 209 262 234 177 177 187\n[20] 148 196 248 247 246 180 149 155 149 156 191 140 137 112 130 134 162 135 155\n[39] 238 170 238 192 227 207 201 225 215 233 273 372 212\n\n$income\n [1] 2824 3259 3072 3835 3549 4256 4151 3954 3419 3509 3412 3981 3675 3363 3341\n[16] 3265 3257 2730 2876 3239 3303 3795 3742 4425 3068 2470 2664 2380 2781 3191\n[31] 2645 2579 2337 2081 2322 2634 2880 3029 2942 2668 3190 3340 2651 3027 2790\n[46] 3957 3688 3317 3968 4146 3513\n\n$young\n [1] 350.7 345.9 348.5 335.3 327.1 341.0 326.2 333.5 326.2 354.5 359.3 348.9\n[13] 369.2 360.7 365.4 343.8 336.1 369.1 368.7 349.9 339.9 375.9 364.1 352.1\n[25] 353.0 328.8 354.1 376.7 370.6 336.0 349.3 342.8 362.2 385.2 351.9 389.6\n[37] 329.8 369.4 368.9 367.7 365.6 358.1 421.5 387.5 412.4 385.1 341.3 332.7\n[49] 348.4 439.7 382.9\n\n$urban\n [1]  508  564  322  846  871  774  856  889  715  753  649  830  738  659  664\n[16]  572  701  443  446  615  661  722  766 1000  631  390  450  476  603  805\n[31]  523  588  584  445  500  661  680  797  534  541  605  785  698  796  804\n[46]  809  726  671  909  484  831\n\n\nCode\nparams_1 = c(\"b\", \"sig\")\ninits = function() {\n  #inits = list(\"b\"=rnorm(2,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n  inits = list(\"b\"=rnorm(3,0.0,1.0/1.0e6), \"prec\"=rgamma(1,0.5,1.0*1500.0/2.0))\n}\nset.seed(72)\nmod_1 = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 51\n   Unobserved stochastic nodes: 5\n   Total graph size: 422\n\nInitializing model\n\n\nCode\nupdate(mod_1, 1e3) # burn-in\n\nmod1_sim = coda.samples(model=mod_1,\n                        variable.names=params_1,\n                        n.iter=5e3)\n\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim))\n\nsummary(mod1_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean       SD  Naive SE Time-series SE\nb[1]  0.08078 0.009685 7.908e-05      0.0008967\nb[2]  0.79141 0.170465 1.392e-03      0.0302069\nb[3] -0.10555 0.036401 2.972e-04      0.0028678\nsig  27.45894 2.860295 2.335e-02      0.0477269\n\n2. Quantiles for each variable:\n\n         2.5%      25%      50%      75%    97.5%\nb[1]  0.06308  0.07366  0.08018  0.08765  0.10029\nb[2]  0.42558  0.68231  0.79451  0.90466  1.13561\nb[3] -0.17541 -0.13205 -0.10597 -0.07824 -0.03779\nsig  22.50373 25.45168 27.20017 29.20142 33.78349\n\n\n\n\nCode\nplot(mod1_sim)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmod_string_2 = \" model {\n    for (i in 1:length(education)) {\n        education[i] ~ dnorm(mu[i], prec)\n        mu[i] = b0 + b[1] * income[i] + b[2]* young[i]\n    }\n    \n    b0 ~ dnorm(0.0, 1.0/1.0e6)\n    for (i in 1:2) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(1.0/2.0, 1.0*1500.0/2.0)\n        ## Initial guess of variance based on overall\n        ## variance of education variable. Uses low prior\n        ## effective sample size. Technically, this is not\n        ## a true 'prior', but it is not very informative.\n    sig2 = 1.0 / prec\n    sig = sqrt(sig2)\n} \"\n\nparams_2 = c(\"b\", \"sig\")\ninits2 = function() {\n  inits = list(\"b\"=rnorm(2,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\nset.seed(72)\nmod_2 = jags.model(textConnection(mod_string_2), inits = inits2, data=data_jags, n.chains=3)\n\n\nWarning in jags.model(textConnection(mod_string_2), inits = inits2, data =\ndata_jags, : Unused variable \"urban\" in data\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 51\n   Unobserved stochastic nodes: 4\n   Total graph size: 320\n\nInitializing model\n\n\nCode\nupdate(mod_2, 1e3) # burn-in\n\nmod2_sim = coda.samples(model=mod_2,\n                        variable.names=params_2,\n                        n.iter=5e3)\n\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim))\n\nsummary(mod2_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean       SD  Naive SE Time-series SE\nb[1]  0.0600 0.007915 6.463e-05      0.0005425\nb[2]  0.7757 0.213091 1.740e-03      0.0319986\nsig  29.8375 3.124415 2.551e-02      0.0592148\n\n2. Quantiles for each variable:\n\n        2.5%      25%      50%      75%    97.5%\nb[1]  0.0427  0.05517  0.06065  0.06543  0.07414\nb[2]  0.3636  0.63407  0.76519  0.92604  1.18446\nsig  24.4897 27.64400 29.55814 31.74179 36.72129\n\n\n\n\nCode\nplot(mod2_sim)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmod_string_3 = \" model {\n    for (i in 1:length(education)) {\n        education[i] ~ dnorm(mu[i], prec)\n        mu[i] = b0 + b[1]*income[i] + b[2] * young[i] + b[3] * income[i]* young[i]\n    }\n    \n    b0 ~ dnorm(0.0, 1.0/1.0e6)\n    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(1.0/2.0, 1.0*1500.0/2.0)\n        ## Initial guess of variance based on overall\n        ## variance of education variable. Uses low prior\n        ## effective sample size. Technically, this is not\n        ## a true 'prior', but it is not very informative.\n    sig2 = 1.0 / prec\n    sig = sqrt(sig2)\n} \"\n\nparams_3 = c(\"b\", \"sig\")\ninits3 = function() {\n  inits = list(\"b\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\nset.seed(72)\nmod_3 = jags.model(textConnection(mod_string_3), inits = inits3, data=data_jags, n.chains=3)\n\n\nWarning in jags.model(textConnection(mod_string_3), inits = inits3, data =\ndata_jags, : Unused variable \"urban\" in data\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 51\n   Unobserved stochastic nodes: 5\n   Total graph size: 372\n\nInitializing model\n\n\nCode\nupdate(mod_3, 1e3) # burn-in\n\nmod3_sim = coda.samples(model=mod_3,\n                        variable.names=params_3,\n                        n.iter=5e3)\n\nmod3_csim = as.mcmc(do.call(rbind, mod3_sim))\n\nsummary(mod3_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean        SD  Naive SE Time-series SE\nb[1] -0.050986 3.525e-01 2.878e-03      0.0330066\nb[2] -0.363721 2.538e+00 2.072e-02      0.1776492\nb[3]  0.000307 9.869e-04 8.058e-06      0.0000953\nsig  38.460883 2.955e+01 2.413e-01      4.5359677\n\n2. Quantiles for each variable:\n\n          2.5%        25%        50%       75%     97.5%\nb[1] -0.690126 -0.3641313 -0.0241064  0.214157 6.245e-01\nb[2] -4.539447 -3.0828136 -0.0398603  2.237185 2.843e+00\nb[3] -0.001589 -0.0004111  0.0002291  0.001169 2.071e-03\nsig  24.961805 28.7555916 31.3234537 34.628716 1.453e+02\n\n\n\n\nCode\nplot(mod3_sim)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndic.samples(mod_1, n.iter=1e5)\n\n\nMean deviance:  480.8 \npenalty 5.125 \nPenalized deviance: 485.9 \n\n\nCode\ndic.samples(mod_2, n.iter=1e5)\n\n\nMean deviance:  489.2 \npenalty 4.174 \nPenalized deviance: 493.4 \n\n\nCode\ndic.samples(mod_3, n.iter=1e5)\n\n\nMean deviance:  487.3 \npenalty 5.452 \nPenalized deviance: 492.8 \n\n\n\n\nCode\n#mod3_sim\n\n#length(mod3_csim[mod3_csim[,1]&gt;=0,3])/dim(mod3_csim)[1]\nlength(mod1_csim[mod1_csim[,1]&gt;=0,3])/dim(mod1_csim)[1]\n\n\n[1] 1\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n486.4\nThis number by itself is not very useful. We now need to compare it to the DIC from other models and see which is lowest.\n\n\n\n\nExercise 44.4  We will consider two alternative models for the Anscombe data. Because income and urban may be more highly correlated with each other than with education, and since urban was less significant than income in our models so far, we’ll consider dropping it (we’ll discuss correlated covariates more in the next lesson).DIC\nThe two alternative models we will try are based on these adjustments:\n\nRemove the term in the linear model for urban.\nIn addition to dropping urban, add an interaction term β3×income×youth.\n\nFit both models in JAGS and calculate the DIC for each. If predictive performance is our criterion, which model would you conclude performs best?\n\n\n\nCode\nmod_0=lm(data = Anscombe,formula = 'education ~ income + young + urban')\n\nsummary((mod_0))\n\n\n\nCall:\nlm(formula = \"education ~ income + young + urban\", data = Anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-60.240 -15.738  -1.156  15.883  51.380 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.868e+02  6.492e+01  -4.418 5.82e-05 ***\nincome       8.065e-02  9.299e-03   8.674 2.56e-11 ***\nyoung        8.173e-01  1.598e-01   5.115 5.69e-06 ***\nurban       -1.058e-01  3.428e-02  -3.086  0.00339 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.69 on 47 degrees of freedom\nMultiple R-squared:  0.6896,    Adjusted R-squared:  0.6698 \nF-statistic: 34.81 on 3 and 47 DF,  p-value: 5.337e-12\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\n\nplot(mod_0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe DIC is lowest for the second model without the urban covariate. This is our preferred model.\nThe DIC is lowest for the original model with all covariates. This is our preferred model.\nThe DIC is lowest for the third model with the interaction term. This is our preferred model.\nThe DIC is indistinguishable among the three models. We cannot clearly identify a preferred model.\n\nWith DIC, a decrease of even a few points can indicate significant gains in model predictive performance.\n\n\n\n\nExercise 44.5  Using the model favored by the DIC, obtain a Monte Carlo estimate of the posterior probability that the coefficient for income is positive (greater than 0.0). Round your answer to two decimal places.DIC\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n1.00\nThere is strong evidence that increases in per-capita income are associated with increases in per-capita education expenditures. We cannot conclude that one causes the other since these data are merely observational, but we do know they are correlated.\n\n\n\n\nExercise 44.6  Which of the following accurately summarizes our conclusions based on the model favored by the DIC?convergence\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIncreases in per-capita income and percent youth are associated with decreases in mean per-capita education expenditures. Increases in percent urban are irrelevant.\nIncreases in per-capita income and percent youth are associated with decreases in mean per-capita education expenditures. Increases in percent urban are associated with increases in mean per-capita education expenditures.\nIncreases in per-capita income and percent urban are associated with increases in mean per-capita education expenditures. Increases in percent youth are associated with decreases in mean per-capita education expenditures.\nIncreases in per-capita income and percent youth are associated with increases in mean per-capita education expenditures. Increases in percent urban are associated with decreases in mean per-capita education expenditures.\n\n\n\nCode\nsummary(mod1_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean       SD  Naive SE Time-series SE\nb[1]  0.08078 0.009685 7.908e-05      0.0008967\nb[2]  0.79141 0.170465 1.392e-03      0.0302069\nb[3] -0.10555 0.036401 2.972e-04      0.0028678\nsig  27.45894 2.860295 2.335e-02      0.0477269\n\n2. Quantiles for each variable:\n\n         2.5%      25%      50%      75%    97.5%\nb[1]  0.06308  0.07366  0.08018  0.08765  0.10029\nb[2]  0.42558  0.68231  0.79451  0.90466  1.13561\nb[3] -0.17541 -0.13205 -0.10597 -0.07824 -0.03779\nsig  22.50373 25.45168 27.20017 29.20142 33.78349\n\n\nCode\n(pm_params1 = colMeans(mod1_csim))\n\n\n       b[1]        b[2]        b[3]         sig \n 0.08077524  0.79140906 -0.10555115 27.45893934 \n\n\nCheck the sign (positive or negative) of the coefficients in the model. A positive coefficient means that the variables (the covariate and response) increase or decrease together and a negative coefficient means that one increases when the other decreases.",
    "crumbs": [
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>HW - Deviance information criterion (DIC)</span>"
    ]
  },
  {
    "objectID": "C2-L08.html",
    "href": "C2-L08.html",
    "title": "45  M3L8 - ANOVA",
    "section": "",
    "text": "45.1 Introduction to ANOVA (Video)",
    "crumbs": [
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>M3L8 - ANOVA</span>"
    ]
  },
  {
    "objectID": "C2-L08.html#sec-intro-anova",
    "href": "C2-L08.html#sec-intro-anova",
    "title": "45  M3L8 - ANOVA",
    "section": "",
    "text": "Introduction to ANOVA",
    "crumbs": [
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>M3L8 - ANOVA</span>"
    ]
  },
  {
    "objectID": "C2-L08.html#one-way-anova-model-using-jags",
    "href": "C2-L08.html#one-way-anova-model-using-jags",
    "title": "45  M3L8 - ANOVA",
    "section": "45.2 One way ANOVA model using JAGS",
    "text": "45.2 One way ANOVA model using JAGS\n\n45.2.1 Data & EDA\nAs an example of a one-way ANOVA, we’ll look at the Plant Growth data in R.\n\n\n\n\nListing 45.1: Plant Growth Query\n\n\n\nCode\ndata(\"PlantGrowth\")\n#?PlantGrowth\nhead(PlantGrowth)\n\n\n\n\n\n  weight group\n1   4.17  ctrl\n2   5.58  ctrl\n3   5.18  ctrl\n4   6.11  ctrl\n5   4.50  ctrl\n6   4.61  ctrl\n\n\nWe first load the dataset (Listing 45.1)\nBecause the explanatory variable group is a factor and not continuous, we choose to visualize the data with box plots rather than scatter plots.\n\n\nCode\nboxplot(weight ~ group, data=PlantGrowth)\n\n\n\n\n\n\n\n\nFigure 45.1: PlantGrowth boxplot\n\n\n\n\n\nThe box plots summarize the distribution of the data for each of the three groups. It appears that treatment 2 has the highest mean yield. It might be questionable whether each group has the same variance, but we’ll assume that is the case.\n\n\n45.2.2 Modeling\nAgain, we can start with the reference analysis (with a noninformative prior) with a linear model in R.\n\n\nCode\nlmod = lm(weight ~ group, data=PlantGrowth)\nsummary(lmod)\n\n\n\nCall:\nlm(formula = weight ~ group, data = PlantGrowth)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4180 -0.0060  0.2627  1.3690 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.0320     0.1971  25.527   &lt;2e-16 ***\ngrouptrt1    -0.3710     0.2788  -1.331   0.1944    \ngrouptrt2     0.4940     0.2788   1.772   0.0877 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6234 on 27 degrees of freedom\nMultiple R-squared:  0.2641,    Adjusted R-squared:  0.2096 \nF-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\n\n\n\n\nCode\nanova(lmod)\n\n\nAnalysis of Variance Table\n\nResponse: weight\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \ngroup      2  3.7663  1.8832  4.8461 0.01591 *\nResiduals 27 10.4921  0.3886                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\nplot(lmod) # for graphical residual analysis\n\n\n\n\n\n\n\n\nFigure 45.2: Graphical residual analysis\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.3: Graphical residual analysis\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.4: Graphical residual analysis\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.5: Graphical residual analysis\n\n\n\n\n\nThe default model structure in R is the linear model with dummy indicator variables. Hence, the “intercept” in this model is the mean yield for the control group. The two other parameters are the estimated effects of treatments 1 and 2. To recover the mean yield in treatment group 1, you would add the intercept term and the treatment 1 effect. To see how R sets the model up, use the model.matrix(lmod) function to extract the X matrix.\nThe anova() function in R compares variability of observations between the treatment groups to variability within the treatment groups to test whether all means are equal or whether at least one is different. The small p-value here suggests that the means are not all equal.\nLet’s fit the cell means model in JAGS.\n\n\nCode\nlibrary(\"rjags\")\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[grp[i]], prec)\n    }\n    \n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*1.0/2.0)\n    sig = sqrt( 1.0 / prec )\n} \"\n\nset.seed(82)\nstr(PlantGrowth)\n\n\n'data.frame':   30 obs. of  2 variables:\n $ weight: num  4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ...\n $ group : Factor w/ 3 levels \"ctrl\",\"trt1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nCode\ndata_jags = list(y=PlantGrowth$weight, \n              grp=as.numeric(PlantGrowth$group))\n\nparams = c(\"mu\", \"sig\")\n\ninits = function() {\n    inits = list(\"mu\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 30\n   Unobserved stochastic nodes: 4\n   Total graph size: 74\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,\n                        variable.names=params,\n                        n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim)) # combined chains\n\n\n\n\n45.2.3 Model checking\nAs usual, we check for convergence of our MCMC.\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nmu[1]          1          1\nmu[2]          1          1\nmu[3]          1          1\nsig            1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n              mu[1]         mu[2]         mu[3]           sig\nLag 0   1.000000000  1.0000000000  1.0000000000  1.0000000000\nLag 1  -0.003062017  0.0052995606 -0.0067392672  0.0904768459\nLag 5   0.006381183 -0.0001238036  0.0105612662  0.0001888026\nLag 10 -0.010514728 -0.0026934221  0.0127967196  0.0035914877\nLag 50 -0.002692437  0.0146715566 -0.0007870658 -0.0139336028\n\n\nCode\neffectiveSize(mod_sim)\n\n\n   mu[1]    mu[2]    mu[3]      sig \n15000.00 14736.83 14417.96 12512.56 \n\n\n\n\n\n\n\n\nFigure 45.6: MCMC convergence diagnostics\n\n\n\n\n\nWe can also look at the residuals to see if there are any obvious problems with our model choice.\n\n\nCode\n(pm_params = colMeans(mod_csim))\n\n\n    mu[1]     mu[2]     mu[3]       sig \n5.0326202 4.6618837 5.5267184 0.7122639 \n\n\n\n\nCode\nyhat = pm_params[1:3][data_jags$grp]\nresid = data_jags$y - yhat\nplot(resid)\n\n\n\n\n\n\n\n\nFigure 45.7: Residuals vs Index\n\n\n\n\n\n\n\nCode\nplot(yhat, resid)\n\n\n\n\n\n\n\n\nFigure 45.8: Residuals vs Fitted values for PlantGrowth model\n\n\n\n\n\nAgain, it might be appropriate to have a separate variance for each group. We will have you do that as an exercise.\n\n\n45.2.4 Results\nLet’s look at the posterior summary of the parameters.\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nmu[1] 5.0326 0.22620 0.0018469      0.0018470\nmu[2] 4.6619 0.22465 0.0018343      0.0018516\nmu[3] 5.5267 0.22595 0.0018449      0.0018853\nsig   0.7123 0.09187 0.0007501      0.0008218\n\n2. Quantiles for each variable:\n\n        2.5%    25%    50%    75%  97.5%\nmu[1] 4.5876 4.8824 5.0331 5.1814 5.4727\nmu[2] 4.2210 4.5145 4.6621 4.8114 5.1034\nmu[3] 5.0771 5.3774 5.5271 5.6763 5.9668\nsig   0.5599 0.6478 0.7022 0.7667 0.9211\n\n\n\n\nCode\nHPDinterval(mod_csim)\n\n\n          lower     upper\nmu[1] 4.5773474 5.4604448\nmu[2] 4.2236860 5.1057507\nmu[3] 5.0868375 5.9743520\nsig   0.5412728 0.8922947\nattr(,\"Probability\")\n[1] 0.95\n\n\nThe HPDinterval() function in the coda package calculates intervals of highest posterior density for each parameter.\nWe are interested to know if one of the treatments increases mean yield. It is clear that treatment 1 does not. What about treatment 2?\n\n\nCode\nmean(mod_csim[,3] &gt; mod_csim[,1])\n\n\n[1] 0.9397333\n\n\nThere is a high posterior probability that the mean yield for treatment 2 is greater than the mean yield for the control group.\nIt may be the case that treatment 2 would be costly to put into production. Suppose that to be worthwhile, this treatment must increase mean yield by 10%. What is the posterior probability that the increase is at least that?\n\n\nCode\nmean(mod_csim[,3] &gt; 1.1*mod_csim[,1])\n\n\n[1] 0.4838667\n\n\nWe have about 50/50 odds that adopting treatment 2 would increase mean yield by at least 10%.",
    "crumbs": [
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>M3L8 - ANOVA</span>"
    ]
  },
  {
    "objectID": "C2-L08.html#two-factor-anova",
    "href": "C2-L08.html#two-factor-anova",
    "title": "45  M3L8 - ANOVA",
    "section": "45.3 Two Factor ANOVA",
    "text": "45.3 Two Factor ANOVA\n\n45.3.1 Data\nLet’s explore an example with two factors. We’ll use the Warpbreaks data set in R. Check the documentation for a description of the data by typing ?warpbreaks.\n\n\nCode\ndata(\"warpbreaks\")\n#?warpbreaks\nhead(warpbreaks)\n\n\n  breaks wool tension\n1     26    A       L\n2     30    A       L\n3     54    A       L\n4     25    A       L\n5     70    A       L\n6     52    A       L\n\n\n\nCode\n# This chunk is for displaying the output that was previously static.\n# If the static output below is preferred, this chunk can be removed \n# and the static output remains unlabelled as it's not a code cell.\n# For a labeled table, this chunk should generate it.\n# The original file had static output here:\n##   breaks wool tension\n## 1     26    A       L\n## 2     30    A       L\n## 3     54    A       L\n## 4     25    A       L\n## 5     70    A       L\n## 6     52    A       L\n# To make this a labeled table from code:\nhead(warpbreaks)\n\n\n\n\nTable 45.1: Preview of first few rows of warpbreaks data\n\n\n\n  breaks wool tension\n1     26    A       L\n2     30    A       L\n3     54    A       L\n4     25    A       L\n5     70    A       L\n6     52    A       L\n\n\n\n\n\nCode\ntable(warpbreaks$wool, warpbreaks$tension)\n\n\n\n\nTable 45.2: Contingency table of wool type vs tension level\n\n\n\n   \n    L M H\n  A 9 9 9\n  B 9 9 9\n\n\n\n\nAgain, we visualize the data with box plots.\n\n\nCode\nboxplot(breaks ~ wool + tension, data=warpbreaks)\n\n\n\n\n\n\n\n\nFigure 45.9: Warpbreaks boxplot\n\n\n\n\n\n\n\nCode\nboxplot(log(breaks) ~ wool + tension, data=warpbreaks)\n\n\n\n\n\n\n\n\nFigure 45.10: Warpbreaks boxplot with log-transformed breaks\n\n\n\n\n\nThe different groups have more similar variance if we use the logarithm of breaks. From this visualization, it looks like both factors may play a role in the number of breaks. It appears that there is a general decrease in breaks as we move from low to medium to high tension. Let’s start with a one-way model using tension only.\n\n\n45.3.2 One-way model\n\n\nCode\nmod1_string = \" model {\n    for( i in 1:length(y)) {\n        y[i] ~ dnorm(mu[tensGrp[i]], prec)\n    }\n    \n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*2.0/2.0)\n    sig = sqrt(1.0 / prec)\n} \"\n\nset.seed(83)\nstr(warpbreaks)\n\n\n'data.frame':   54 obs. of  3 variables:\n $ breaks : num  26 30 54 25 70 52 51 26 67 18 ...\n $ wool   : Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ tension: Factor w/ 3 levels \"L\",\"M\",\"H\": 1 1 1 1 1 1 1 1 1 2 ...\n\n\nCode\ndata1_jags = list(y=log(warpbreaks$breaks), tensGrp=as.numeric(warpbreaks$tension))\n\nparams1 = c(\"mu\", \"sig\")\n\nmod1 = jags.model(textConnection(mod1_string), data=data1_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 54\n   Unobserved stochastic nodes: 4\n   Total graph size: 123\n\nInitializing model\n\n\nCode\nupdate(mod1, 1e3)\n\nmod1_sim = coda.samples(model=mod1,\n                        variable.names=params1,\n                        n.iter=5e3)\n\n\n\n\nCode\n## convergence diagnostics\nplot(mod1_sim)\n\n\n\n\n\n\n\n\nFigure 45.11: MCMC convergence diagnostics for one-way tension model\n\n\n\n\n\n\n\nCode\ngelman.diag(mod1_sim)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nmu[1]          1          1\nmu[2]          1          1\nmu[3]          1          1\nsig            1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod1_sim)\n\n\n              mu[1]        mu[2]        mu[3]          sig\nLag 0   1.000000000  1.000000000  1.000000000  1.000000000\nLag 1  -0.007941346  0.010987010  0.011531633  0.058573549\nLag 5  -0.016863531 -0.001042528 -0.003001582 -0.007169178\nLag 10  0.004326670  0.003223160 -0.003412397 -0.007714962\nLag 50  0.004910054 -0.001144951 -0.011883866  0.009989784\n\n\nCode\neffectiveSize(mod1_sim)\n\n\n   mu[1]    mu[2]    mu[3]      sig \n15205.31 14581.29 14712.52 13120.27 \n\n\nThe 95% posterior interval for the mean of group 2 (medium tension) overlaps with both the low and high groups, but the intervals for low and high group only slightly overlap. That is a pretty strong indication that the means for low and high tension are different. Let’s collect the DIC for this model and move on to the two-way model.\n\n\nCode\ndic1 = dic.samples(mod1, n.iter=1e3)\n\n\n\n\n45.3.3 Two-way additive model\nWith two factors, one with two levels and the other with three, we have six treatment groups, which is the same situation we discussed when introducing multiple factor ANOVA. We will first fit the additive model which treats the two factors separately with no interaction. To get the X matrix (or design matrix) for this model, we can create it in R.\n\nCode\nX = model.matrix( ~ wool + tension, data=warpbreaks)\nhead(X)\n\n\n\n\nTable 45.3: Head of the design matrix for the additive model\n\n\n\n  (Intercept) woolB tensionM tensionH\n1           1     0        0        0\n2           1     0        0        0\n3           1     0        0        0\n4           1     0        0        0\n5           1     0        0        0\n6           1     0        0        0\n\n\n\n\n\nCode\ntail(X)\n\n\n\n\nTable 45.4: Tail of the design matrix for the additive model\n\n\n\n   (Intercept) woolB tensionM tensionH\n49           1     1        0        1\n50           1     1        0        1\n51           1     1        0        1\n52           1     1        0        1\n53           1     1        0        1\n54           1     1        0        1\n\n\n\n\nBy default, R has chosen the mean for wool A and low tension to be the intercept. Then, there is an effect for wool B, and effects for medium tension and high tension, each associated with dummy indicator variables.\n\n\nCode\nmod2_string = \" model {\n    for( i in 1:length(y)) {\n        y[i] ~ dnorm(mu[i], prec)\n        mu[i] = int + alpha*isWoolB[i] + beta[1]*isTensionM[i] + beta[2]*isTensionH[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1.0e6)\n    alpha ~ dnorm(0.0, 1.0/1.0e6)\n    for (j in 1:2) {\n        beta[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(3/2.0, 3*1.0/2.0)\n    sig = sqrt(1.0 / prec)\n} \"\n\ndata2_jags = list(y=log(warpbreaks$breaks), isWoolB=X[,\"woolB\"], isTensionM=X[,\"tensionM\"], isTensionH=X[,\"tensionH\"])\n\nparams2 = c(\"int\", \"alpha\", \"beta\", \"sig\")\n\nmod2 = jags.model(textConnection(mod2_string), data=data2_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 54\n   Unobserved stochastic nodes: 5\n   Total graph size: 243\n\nInitializing model\n\n\nCode\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params2,\n                        n.iter=5e3)\n\n\n\n\nCode\n## convergence diagnostics\nplot(mod2_sim)\n\ngelman.diag(mod2_sim)    # Corrected from mod1_sim\n\n\nPotential scale reduction factors:\n\n        Point est. Upper C.I.\nalpha            1          1\nbeta[1]          1          1\nbeta[2]          1          1\nint              1          1\nsig              1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod2_sim)  # Corrected from mod1_sim\n\n\n               alpha      beta[1]      beta[2]        int          sig\nLag 0   1.0000000000 1.0000000000  1.000000000  1.0000000  1.000000000\nLag 1   0.4968194670 0.5102656287  0.494872375  0.7515924  0.080609351\nLag 5   0.0343303202 0.0949971557  0.088713436  0.1761326 -0.009359506\nLag 10  0.0003601524 0.0201045340  0.001936419  0.0235889 -0.001810904\nLag 50 -0.0109121932 0.0004853135 -0.001072841 -0.0126650 -0.005312828\n\n\nCode\neffectiveSize(mod2_sim) # Corrected from mod1_sim\n\n\n    alpha   beta[1]   beta[2]       int       sig \n 5113.400  3780.126  4144.590  2394.872 12354.355 \n\n\n\n\n\n\n\n\nFigure 45.12: Convergence and diagnostics for the additive two-way ANOVA model\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.13: Convergence and diagnostics for the additive two-way ANOVA model\n\n\n\n\n\nLet’s summarize the results, collect the DIC for this model, and compare it to the first one-way model.\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean      SD  Naive SE Time-series SE\nalpha   -0.1522 0.12384 0.0010111       0.001733\nbeta[1] -0.2901 0.15282 0.0012478       0.002504\nbeta[2] -0.4912 0.15141 0.0012363       0.002376\nint      3.5781 0.12422 0.0010143       0.002553\nsig      0.4545 0.04535 0.0003703       0.000409\n\n2. Quantiles for each variable:\n\n           2.5%     25%     50%      75%     97.5%\nalpha   -0.3938 -0.2345 -0.1516 -0.07044  0.092157\nbeta[1] -0.5930 -0.3917 -0.2896 -0.18844  0.008243\nbeta[2] -0.7945 -0.5909 -0.4900 -0.38871 -0.196547\nint      3.3326  3.4953  3.5765  3.66136  3.821986\nsig      0.3768  0.4220  0.4509  0.48240  0.554006\n\n\n\n\nCode\n(dic2 = dic.samples(mod2, n.iter=1e3))\n\n\nMean deviance:  55.64 \npenalty 5.276 \nPenalized deviance: 60.92 \n\n\nCode\ndic1\n\n\nMean deviance:  66.55 \npenalty 4 \nPenalized deviance: 70.55 \n\n\nThis suggests there is much to be gained adding the wool factor to the model. Before we settle on this model however, we should consider whether there is an interaction. Let’s look again at the box plot with all six treatment groups.\n\n\nCode\nboxplot(log(breaks) ~ wool + tension, data=warpbreaks)\n\n\n\n\n\n\n\n\nFigure 45.14: Re-examining boxplot of log(breaks) by wool and tension for interaction effects\n\n\n\n\n\nOur two-way model has a single effect for wool B and the estimate is negative. If this is true, then we would expect wool B to be associated with fewer breaks than its wool A counterpart on average. This is true for low and high tension, but it appears that breaks are higher for wool B when there is medium tension. That is, the effect for wool B is not consistent across tension levels, so it may appropriate to add an interaction term. In R, this would look like:\n\n\nCode\nlmod2 = lm(log(breaks) ~ .^2, data=warpbreaks)\nsummary(lmod2)\n\n\n\nCall:\nlm(formula = log(breaks) ~ .^2, data = warpbreaks)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.81504 -0.27885  0.04042  0.27319  0.64358 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      3.7179     0.1247  29.824  &lt; 2e-16 ***\nwoolB           -0.4356     0.1763  -2.471  0.01709 *  \ntensionM        -0.6012     0.1763  -3.410  0.00133 ** \ntensionH        -0.6003     0.1763  -3.405  0.00134 ** \nwoolB:tensionM   0.6281     0.2493   2.519  0.01514 *  \nwoolB:tensionH   0.2221     0.2493   0.891  0.37749    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.374 on 48 degrees of freedom\nMultiple R-squared:  0.3363,    Adjusted R-squared:  0.2672 \nF-statistic: 4.864 on 5 and 48 DF,  p-value: 0.001116\n\n\nAdding the interaction, we get an effect for being in wool B and medium tension, as well as for being in wool B and high tension. There are now six parameters for the mean, one for each treatment group, so this model is equivalent to the full cell means model. Let’s use that.\n\n\n45.3.4 Two-way cell means model\nIn this new model, \\mu will be a matrix with six entries, each corresponding to a treatment group.\n\n\nCode\nmod3_string = \" model {\n    for( i in 1:length(y)) {\n        y[i] ~ dnorm(mu[woolGrp[i], tensGrp[i]], prec)\n    }\n    \n    for (j in 1:max(woolGrp)) {\n        for (k in 1:max(tensGrp)) {\n            mu[j,k] ~ dnorm(0.0, 1.0/1.0e6)\n        }\n    }\n    \n    prec ~ dgamma(3/2.0, 3*1.0/2.0)\n    sig = sqrt(1.0 / prec)\n} \"\n\nstr(warpbreaks)\n\n\n'data.frame':   54 obs. of  3 variables:\n $ breaks : num  26 30 54 25 70 52 51 26 67 18 ...\n $ wool   : Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ tension: Factor w/ 3 levels \"L\",\"M\",\"H\": 1 1 1 1 1 1 1 1 1 2 ...\n\n\nCode\ndata3_jags = list(y=log(warpbreaks$breaks), woolGrp=as.numeric(warpbreaks$wool), tensGrp=as.numeric(warpbreaks$tension))\n\nparams3 = c(\"mu\", \"sig\")\n\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 54\n   Unobserved stochastic nodes: 7\n   Total graph size: 179\n\nInitializing model\n\n\nCode\nupdate(mod3, 1e3)\n\nmod3_sim = coda.samples(model=mod3,\n                        variable.names=params3,\n                        n.iter=5e3)\nmod3_csim = as.mcmc(do.call(rbind, mod3_sim))\n\n\n\n\nCode\nplot(mod3_sim)\n\n\n\n\n\n\n\n\nFigure 45.15: Traceplots for the cell means model\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.16: Traceplots for the cell means model\n\n\n\n\n\n\n\nCode\n## convergence diagnostics\ngelman.diag(mod3_sim)\n\n\nPotential scale reduction factors:\n\n        Point est. Upper C.I.\nmu[1,1]          1          1\nmu[2,1]          1          1\nmu[1,2]          1          1\nmu[2,2]          1          1\nmu[1,3]          1          1\nmu[2,3]          1          1\nsig              1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod3_sim)\n\n\n             mu[1,1]       mu[2,1]      mu[1,2]     mu[2,2]      mu[1,3]\nLag 0   1.0000000000  1.0000000000  1.000000000 1.000000000  1.000000000\nLag 1  -0.0133848308  0.0002948518 -0.004139662 0.002587829 -0.002748009\nLag 5   0.0104327074 -0.0047827295 -0.017802457 0.004909324 -0.006741489\nLag 10 -0.0002999751  0.0010498602 -0.008027593 0.004243136  0.001301729\nLag 50  0.0097774801 -0.0156455425 -0.015883219 0.001079133  0.004678206\n             mu[2,3]          sig\nLag 0   1.0000000000  1.000000000\nLag 1   0.0005429844  0.100762949\nLag 5  -0.0008507273 -0.019476408\nLag 10  0.0049968697 -0.007446340\nLag 50 -0.0037544039 -0.003035055\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n mu[1,1]  mu[2,1]  mu[1,2]  mu[2,2]  mu[1,3]  mu[2,3]      sig \n15365.03 15000.00 16459.45 14709.36 15224.78 15000.00 12983.66 \n\n\nCode\nraftery.diag(mod3_sim)\n\n\n[[1]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                               \n         Burn-in  Total Lower bound  Dependence\n         (M)      (N)   (Nmin)       factor (I)\n mu[1,1] 2        3680  3746         0.982     \n mu[2,1] 2        3680  3746         0.982     \n mu[1,2] 2        3930  3746         1.050     \n mu[2,2] 2        3803  3746         1.020     \n mu[1,3] 2        3803  3746         1.020     \n mu[2,3] 2        3803  3746         1.020     \n sig     2        3741  3746         0.999     \n\n\n[[2]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                               \n         Burn-in  Total Lower bound  Dependence\n         (M)      (N)   (Nmin)       factor (I)\n mu[1,1] 2        3866  3746         1.030     \n mu[2,1] 2        3741  3746         0.999     \n mu[1,2] 2        3803  3746         1.020     \n mu[2,2] 2        3741  3746         0.999     \n mu[1,3] 2        3866  3746         1.030     \n mu[2,3] 2        3680  3746         0.982     \n sig     2        3866  3746         1.030     \n\n\n[[3]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                               \n         Burn-in  Total Lower bound  Dependence\n         (M)      (N)   (Nmin)       factor (I)\n mu[1,1] 2        3803  3746         1.020     \n mu[2,1] 3        4129  3746         1.100     \n mu[1,2] 2        3741  3746         0.999     \n mu[2,2] 2        3930  3746         1.050     \n mu[1,3] 2        3930  3746         1.050     \n mu[2,3] 2        3741  3746         0.999     \n sig     2        3803  3746         1.020     \n\n\nLet’s compute the DIC and compare with our previous models.\n\n\nCode\n(dic3 = dic.samples(mod3, n.iter=1e3))\n\n\nMean deviance:  52.04 \npenalty 7.256 \nPenalized deviance: 59.3 \n\n\nCode\ndic2\n\n\nMean deviance:  55.64 \npenalty 5.276 \nPenalized deviance: 60.92 \n\n\nCode\ndic1\n\n\nMean deviance:  66.55 \npenalty 4 \nPenalized deviance: 70.55 \n\n\nThis suggests that the full model with interaction between wool and tension (which is equivalent to the cell means model) is the best for explaining/predicting warp breaks.\n\n\n45.3.5 Results\n\n\nCode\nsummary(mod3_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean      SD  Naive SE Time-series SE\nmu[1,1] 3.717 0.14888 0.0012156      0.0012017\nmu[2,1] 3.283 0.14926 0.0012187      0.0012187\nmu[1,2] 3.115 0.14685 0.0011990      0.0011532\nmu[2,2] 3.309 0.14915 0.0012178      0.0012301\nmu[1,3] 3.117 0.14881 0.0012150      0.0012063\nmu[2,3] 2.906 0.14872 0.0012143      0.0012144\nsig     0.443 0.04481 0.0003659      0.0003953\n\n2. Quantiles for each variable:\n\n          2.5%    25%    50%    75% 97.5%\nmu[1,1] 3.4280 3.6178 3.7169 3.8161 4.010\nmu[2,1] 2.9870 3.1842 3.2822 3.3827 3.578\nmu[1,2] 2.8263 3.0168 3.1160 3.2140 3.403\nmu[2,2] 3.0118 3.2111 3.3096 3.4081 3.600\nmu[1,3] 2.8253 3.0187 3.1167 3.2165 3.417\nmu[2,3] 2.6156 2.8075 2.9056 3.0048 3.201\nsig     0.3658 0.4112 0.4395 0.4706 0.542\n\n\n\n\nCode\nHPDinterval(mod3_csim)\n\n\n            lower     upper\nmu[1,1] 3.4294925 4.0114002\nmu[2,1] 2.9831110 3.5727123\nmu[1,2] 2.8267999 3.4032513\nmu[2,2] 3.0177461 3.6046419\nmu[1,3] 2.8152699 3.4054009\nmu[2,3] 2.6129511 3.1973685\nsig     0.3605013 0.5345517\nattr(,\"Probability\")\n[1] 0.95\n\n\n\n\nCode\npar(mfrow=c(3,2)) # arrange frame for plots\ndensplot(mod3_csim[,1:6], xlim=c(2.0, 4.5))\n\n\n\n\n\n\n\n\nFigure 45.17: Posterior densities for cell means\n\n\n\n\n\nIt might be tempting to look at comparisons between each combination of treatments, but we warn that this could yield spurious results. When we discussed the statistical modeling cycle, we said it is best not to search your results for interesting hypotheses, because if there are many hypotheses, some will appear to show “effects” or “associations” simply due to chance. Results are most reliable when we determine a relatively small number of hypotheses we are interested in beforehand, collect the data, and statistically evaluate the evidence for them.\nOne question we might be interested in with these data is finding the treatment combination that produces the fewest breaks. To calculate this, we can go through our posterior samples and for each sample, find out which group has the smallest mean. These counts help us determine the posterior probability that each of the treatment groups has the smallest mean.\n\nCode\nprop.table( table( apply(mod3_csim[,1:6], 1, which.min) ) )\n\n\n\n\nTable 45.5: Posterior probabilities of each treatment group having the smallest mean break rate\n\n\n\n\n         2          3          4          5          6 \n0.01786667 0.11753333 0.01066667 0.11913333 0.73480000 \n\n\n\n\nThe evidence supports wool B with high tension as the treatment that produces the fewest breaks.",
    "crumbs": [
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>M3L8 - ANOVA</span>"
    ]
  },
  {
    "objectID": "C2-L08-Ex1.html",
    "href": "C2-L08-Ex1.html",
    "title": "46  HW on ANOVA",
    "section": "",
    "text": "Exercise 46.1  Which of the following variables qualifies as a “factor” variable?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWeight of a patient reported in kilograms\nPre-treatment temperature reported in degrees Celsius\nPatient age in years\nTreatment with either an experimental drug or a control placebo\n\nThis is a categorical predictor.\n\n\n\n\nExercise 46.2  In an ANOVA model for a single factor with four levels, there are multiple ways we can parameterize our model for E(y). These include the cell means model or a linear model with a baseline mean and adjustments for different levels. Regardless of the model chosen, what is the maximum number of parameters we use to relate this factor with E(y) in a linear model and still be able to uniquely identify the parameters?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n4\nIf we use any more than four parameters to describe E(y), there will be infinitely many values of the parameters that produce a given E(y) for a given set of predictor values.\n\n\n\nQuestion 3\nFor Questions Exercise 46.3, refer to the plant growth analysis from the lesson.\nRe-fit the JAGS model on plant growth from the lesson with a separate variance for each of the three groups. To do so, modify the model code to index the precision in the normal likelihood by group, just as we did with the mean. Use the same priors as the original model (except in this case it will be three independent priors for the variances).\n\nExercise 46.3  Compare the estimates between the original lesson model and this model with the summary function. Notice that the posterior means for the three μ parameters are essentially unchanged. However, the posterior variability for these parameters has changed. The posterior for which group’s mean was most affected by fitting separate group variances?ANOVA\n\n\nCode\nlibrary(\"rjags\")\n\n\n\n\nCode\ndata(\"PlantGrowth\")  # load the data set\n#?PlantGrowth\nmod1_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[grp[i]], prec)\n    }\n    \n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*1.0/2.0)\n    sig = sqrt( 1.0 / prec )\n} \"\n\nset.seed(82)\n#str(PlantGrowth)\ndata1_jags = list(y=PlantGrowth$weight, grp=as.numeric(PlantGrowth$group))\n\nparams = c(\"mu\", \"sig\")\n\ninits1 = function() {\n    inits = list(\"mu\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod1 = jags.model(textConnection(mod1_string), data=data1_jags, inits=inits1, n.chains=3)\nupdate(mod1, 1e3)\n\nmod1_sim = coda.samples(model=mod1, variable.names=params, n.iter=5e3)\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim)) # combined chains\n\n\n\n\nCode\ndata(\"PlantGrowth\")  # load the data set\n\nmod2_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[grp[i]], prec[grp[i]])\n    }\n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n        prec[j] ~ dgamma(5/2.0, 5*1.0/2.0)\n        sig[j] = sqrt( 1.0 / prec[j] )\n    }\n} \"\n\nset.seed(82)\ndata2_jags = list(y=PlantGrowth$weight, grp=as.numeric(PlantGrowth$group))\nparams = c(\"mu\", \"sig\")\ninits2 = function() {\n    inits = list(\"mu\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(3,1.0,1.0))\n}\n\nmod2 = jags.model(textConnection(mod2_string), data=data2_jags, inits=inits2, n.chains=3)\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2, variable.names=params, n.iter=5e3)\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim)) # combined chains\n\n\n\n\nCode\nsummary(mod1_csim)\n\n\n\nIterations = 1:15000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 15000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nmu[1] 5.0330 0.22729 0.0018558      0.0018826\nmu[2] 4.6646 0.22762 0.0018585      0.0018585\nmu[3] 5.5255 0.22723 0.0018553      0.0018795\nsig   0.7125 0.09192 0.0007505      0.0008251\n\n2. Quantiles for each variable:\n\n        2.5%    25%    50%    75%  97.5%\nmu[1] 4.5800 4.8837 5.0325 5.1823 5.4795\nmu[2] 4.2224 4.5138 4.6622 4.8129 5.1180\nmu[3] 5.0821 5.3760 5.5236 5.6736 5.9796\nsig   0.5599 0.6474 0.7032 0.7676 0.9215\n\n\nCode\nsummary(mod2_csim)\n\n\n\nIterations = 1:15000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 15000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean     SD Naive SE Time-series SE\nmu[1]  5.0339 0.2620 0.002140       0.002067\nmu[2]  4.6652 0.2972 0.002427       0.002427\nmu[3]  5.5283 0.2354 0.001922       0.001922\nsig[1] 0.8039 0.1666 0.001360       0.001469\nsig[2] 0.9238 0.1926 0.001573       0.001689\nsig[3] 0.7341 0.1517 0.001239       0.001362\n\n2. Quantiles for each variable:\n\n         2.5%    25%    50%    75% 97.5%\nmu[1]  4.5092 4.8666 5.0383 5.1995 5.553\nmu[2]  4.0811 4.4729 4.6612 4.8554 5.256\nmu[3]  5.0566 5.3778 5.5290 5.6755 5.995\nsig[1] 0.5535 0.6861 0.7790 0.8927 1.208\nsig[2] 0.6386 0.7886 0.8905 1.0272 1.392\nsig[3] 0.5079 0.6276 0.7104 0.8154 1.096\n\n\nCompare the estimates between the original lesson model and this model with the summary function. Notice that the posterior means for the three μ parameters are essentially unchanged. However, the posterior variability for these parameters has changed. The posterior for which group’s mean was most affected by fitting separate group variances??\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nGroup 1: control\nGroup 2: treatment 1.\nGroup 3: treatment 2\nThe effect on the marginal posterior was the same for all three groups.\n\nSD of group 2 mean increased from 0.23035 to 0.2988 that a 0.07 change\nGroup 2 has the highest variation in plant weight, which results in less confidence in our posterior mean estimate. The posterior standard deviation of μ has increased the most for this group.\n\n\n\n\nExercise 46.4  Compute the deviance information criterion (DIC) for each of the two models and save the results as objects dic1 (for the original model) and dic2 (for the new model). Wha is the difference: DIC1 - DIC2?.ANOVA\nHint: You can compute this directly with the following code: dic1−dic2.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n(dic1 = dic.samples(mod1,1e5))\n\n\nMean deviance:  58.99 \npenalty 4.095 \nPenalized deviance: 63.08 \n\n\nCode\n(dic2 = dic.samples(mod2,1e5))\n\n\nMean deviance:  61.21 \npenalty 5.735 \nPenalized deviance: 66.94 \n\n\nCode\ndic1-dic2\n\n\nDifference: -3.858163\nSample standard error: 1.641612\n\n\n-3.892918\n\n\n\n\nExercise 46.5  Based on the DIC calculations for these competing models, what should we conclude?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe DIC is higher for the new model, indicating preference for the model with separate variances across groups.\nThe DIC is lower for the original model, indicating preference for the model with one common variance across groups.\nThe DIC is higher for the original model, indicating preference for the model with one common variance across groups.\nThe DIC is lower for the new model, indicating preference for the model with separate variances across groups.\n\nThis suggests we should stay with the original model (if our objective is good prediction).\n\n\n\n\nExercise 46.6  Use the original model (single variance) to calculate a 95% interval of highest posterior density (HPD) for \\mu_3−\\mu_1. Which of the following is closest to this interval?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n1q5 = as.mcmc( cbind(mod1_csim,mudif=mod1_csim[,3]-mod1_csim[,1]) )\n2summary((q5))\n\n\n\n1\n\nadd a parameter called mudiff by calculate \\mu_3-\\mu_1 for each sample\n\n2\n\nuse the summary to get quantiles and read 2.5% and 97.5% for mudiff\n\n\n\n\n\nIterations = 1:15000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 15000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nmu[1] 5.0330 0.22729 0.0018558      0.0018826\nmu[2] 4.6646 0.22762 0.0018585      0.0018585\nmu[3] 5.5255 0.22723 0.0018553      0.0018795\nsig   0.7125 0.09192 0.0007505      0.0008251\nmudif 0.4925 0.32201 0.0026292      0.0026225\n\n2. Quantiles for each variable:\n\n         2.5%    25%    50%    75%  97.5%\nmu[1]  4.5800 4.8837 5.0325 5.1823 5.4795\nmu[2]  4.2224 4.5138 4.6622 4.8129 5.1180\nmu[3]  5.0821 5.3760 5.5236 5.6736 5.9796\nsig    0.5599 0.6474 0.7032 0.7676 0.9215\nmudif -0.1473 0.2828 0.4916 0.7038 1.1258\n\n\n\n(-0.20, 1.19)\n(-1.01, 0.25)\n(0.22, 1.49)\n(-0.14, 1.13)\n\nThe interval contains 0, indicating that the data lack strong (at least at the 95% level) evidence for \\mu_3\\ne\\mu_1. In the lesson, the posterior probability that \\mu_3&gt;\\mu_1 was 0.94.\n\n\n\n\nExercise 46.7  What is the correct interpretation of \\mu_3−\\mu_1 in the context of the plant growth analysis?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIt is the effect (change) of treatment 2 with respect to the control in mean plant weight.\nIt is the mean range of plant weight across the three treatment groups.\nIt is the difference in plant weight between treatment 2 and control.\nIt is the effect (change) of treatment 2 with respect to the control in plant weight.\n\nMCMC algs are based on a process guaranteeing convergence to a stationary distribution.\n\n\n\n\nExercise 46.8  The linear model with a baseline mean and group effects is the default in R. However, we can also fit the cell means model in R using the following code:ANOVA\n\n\nCode\nmod_cm = lm(weight ~ -1 + group, data=PlantGrowth)\nsummary(mod_cm)\n\n\n\nCall:\nlm(formula = weight ~ -1 + group, data = PlantGrowth)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4180 -0.0060  0.2627  1.3690 \n\nCoefficients:\n          Estimate Std. Error t value Pr(&gt;|t|)    \ngroupctrl   5.0320     0.1971   25.53   &lt;2e-16 ***\ngrouptrt1   4.6610     0.1971   23.64   &lt;2e-16 ***\ngrouptrt2   5.5260     0.1971   28.03   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6234 on 27 degrees of freedom\nMultiple R-squared:  0.9867,    Adjusted R-squared:  0.9852 \nF-statistic: 665.5 on 3 and 27 DF,  p-value: &lt; 2.2e-16\n\n\nwhere the −1 in the model formula tells R to drop the intercept. Because we used fairly noninformative priors for the μ parameters in the analysis with JAGS, the results are very similar.\nIn addition to allowing different prior specifications, what is one advantage of posterior sampling with JAGS over fitting the reference model in R?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWe can obtain posterior mode estimates for each mean (or coefficient).\nWe can obtain posterior standard deviations (standard errors) for each mean (or coefficient).\nWe can estimate the proportion of the variation in plant weight attributable to the treatment group assignment.\nWe can use the posterior samples to obtain simulated posterior distributions of any function of the parameters that may interest us (e.g., μ_3−μ_1).\n\nThe outer edges of the distribution are sampled less frequently and therefore susceptible to changes between simulations. The Raftery and Lewis diagnostic can help you decide how many iterations you need to reliably estimate outer quantiles of the target distribution..",
    "crumbs": [
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>HW on ANOVA</span>"
    ]
  },
  {
    "objectID": "C2-L08-Ex2.html",
    "href": "C2-L08-Ex2.html",
    "title": "47  HW+ - Multiple Factor ANOVA",
    "section": "",
    "text": "For Questions 1 and 2, consider the Anscombe data from the car package in R which we analyzed in the quizzes for Lesson 7.Laplace Prior\n\nExercise 47.1  In the original model, we used normal priors for the three regression coefficients. Here we will consider using Laplace priors centered on 0. The parameterization used in JAGS for the Laplace (double exponential) distribution has an inverse scale parameter τ. This is related to the variance v of the prior in the following way: v=2/τ2. Suppose we want the Laplace prior to have variance v=2. What value of τ should we use in the JAGS code?Laplace Prior\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n1.0\nAlternatively, we could place an informative prior on τ and learn it along with other parameters.\n\n\n\n\nExercise 47.2  When using an informative variable selection prior like the Laplace, we typically center and scale the data:Laplace Prior\n\n\nCode\nlibrary(\"rjags\")\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\nCode\nlibrary(\"car\")\n\n\nLoading required package: carData\n\n\nCode\ndata(\"Anscombe\")\nhead(Anscombe)\n\n\n   education income young urban\nME       189   2824 350.7   508\nNH       169   3259 345.9   564\nVT       230   3072 348.5   322\nMA       168   3835 335.3   846\nRI       180   3549 327.1   871\nCT       193   4256 341.0   774\n\n\nCode\n#?Anscombe\nXc = scale(Anscombe, center=TRUE, scale=TRUE)\nstr(Xc)\n\n\n num [1:51, 1:4] -0.157 -0.588 0.725 -0.609 -0.351 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:51] \"ME\" \"NH\" \"VT\" \"MA\" ...\n  ..$ : chr [1:4] \"education\" \"income\" \"young\" \"urban\"\n - attr(*, \"scaled:center\")= Named num [1:4] 196 3225 359 665\n  ..- attr(*, \"names\")= chr [1:4] \"education\" \"income\" \"young\" \"urban\"\n - attr(*, \"scaled:scale\")= Named num [1:4] 46.5 560 24 151.3\n  ..- attr(*, \"names\")= chr [1:4] \"education\" \"income\" \"young\" \"urban\"\n\n\n\n\nCode\ndata_jags = as.list(Anscombe)\n\nmod_string = \"model {\n    for (i in 1:length(education)) {\n        education[i] ~ dnorm(mu[i], prec)\n        mu[i] = b0 + b[1]*income[i] + b[2]*young[i] + b[3]*urban[i]\n    }\n    b0 ~ dnorm(0.0, 1.0/1.0e6)\n    for (j in 1:3) {\n        b[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    prec ~ dgamma(1.0/2.0, 1.0*1500.0/2.0)\n    sig2 = 1.0 / prec\n    sig = sqrt(sig2)\n} \"\nparams = c(\"b\",\"sig\")\nset.seed(72)\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 51\n   Unobserved stochastic nodes: 5\n   Total graph size: 422\n\nInitializing model\n\n\nCode\nupdate(mod, 1e4)\n\nmod_sim = coda.samples(model=mod, variable.names=params,  n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\ndic = dic.samples(mod, n.iter=1e3)\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata_jags = as.list(data.frame(Xc))\n\nmod2_string = \" model {\n    for (i in 1:length(education)) {\n        education[i] ~ dnorm(mu[i], prec)\n        mu[i] = b[1]*income[i] + b[2]*young[i] + b[3]*urban[i]\n    }\n    for (i in 1:3) {\n        b[i] ~ ddexp(0.0, 2)\n    }\n    prec ~ dgamma(0.5, 0.5)\n    sig2 = 1.0 / prec\n    sig = sqrt(sig2)\n} \"\n\nparams2 = c(\"b\",\"sig\")\n\nmod2 = jags.model(textConnection(mod2_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 51\n   Unobserved stochastic nodes: 4\n   Total graph size: 416\n\nInitializing model\n\n\nCode\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2, variable.names=params2,  n.iter=5e3)\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim))\n\ndic2 = dic.samples(mod2, n.iter=1e3)\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod2_sim)\n\n\n\n\n\n\n\n\n\nBecause we subtracted the mean from all (continuous) variables including the response, this is a rare case where we do not need an intercept. Fit the model in JAGS using the Laplace prior with variance 2 for each of the three coefficients, and an inverse gamma prior for the observation variance with effective sample size 1 and prior guess 1.\nHow do the inferences for the coefficients compare to the original model fit in the quiz for Lesson 7 (besides that their scale has changed due to scaling the data)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 10001:15000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean      SD  Naive SE Time-series SE\nb[1]  0.08218 0.01051 8.585e-05       0.001128\nb[2]  0.85744 0.16813 1.373e-03       0.030229\nb[3] -0.10908 0.03631 2.965e-04       0.002835\nsig  27.51444 2.88221 2.353e-02       0.040903\n\n2. Quantiles for each variable:\n\n         2.5%     25%     50%      75%   97.5%\nb[1]  0.06126  0.0755  0.0823  0.08947  0.1019\nb[2]  0.50802  0.7471  0.8762  0.98219  1.1358\nb[3] -0.18264 -0.1320 -0.1085 -0.08521 -0.0367\nsig  22.55702 25.4906 27.3144 29.28295 33.7263\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nb[1]  0.9236 0.11903 0.0009719      0.0020852\nb[2]  0.4060 0.08627 0.0007044      0.0009178\nb[3] -0.3005 0.11631 0.0009497      0.0020114\nsig   0.5920 0.06194 0.0005057      0.0005714\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%     75%   97.5%\nb[1]  0.6899  0.8463  0.9243  1.0037  1.1526\nb[2]  0.2356  0.3481  0.4071  0.4647  0.5728\nb[3] -0.5356 -0.3777 -0.2995 -0.2228 -0.0694\nsig   0.4862  0.5483  0.5865  0.6302  0.7266\n\n\n\nThe inferences are similar, with one exception. The first two coefficients (for income and percentage youth) are significantly positive and the percent urban coefficient’s posterior looks like the Laplace prior, with a spike near 0. This indicates that the percent urban “effect” is very weak.\nInexplicably, the signs of all coefficients have changed (from positive to negative and from negative to positive).\nThe inferences are essentially unchanged. The first two coefficients (for income and percentage youth) are significantly positive and the percent urban coefficient is still negative.\nThe inferences are vastly different. The marginal posterior for all three coefficients look like their Laplace priors, with a spike near 0. This indicates that the “effect” associated with each covariate is very weak.\n\nNotes: 1. There is a big change in sigma, it is much smaller in the second model indicating that the posterior is much narrower.\n2. Also we can see that the larget effect in the first model is b[2] and in the second ,odel it is b[1] 3. the 95% intervals in the first model are [0.06085,0.09832], [0.47245 1.09604] and [-0.17580,-0.04033] for the second they are [0.7001 ,1.15435] [0.2381 ,0.57309] [-0.5289 ,-0.07231] in both models they do not intersect - which is strong evidence for different means per each group. 4. picked that answer the strength of the coefficients has changed the margnials plots of the second model do not seem to be zero though b[3] is fairly close to zero\n\n\n\n\nExercise 47.3  Consider an ANOVA model for subjects’ responses to three experimental factor variables related to a proposed health supplement: dose, frequency, and physical activity. Dose has two levels: 100mg and 200mg. Frequency has three levels: “daily,” “twice-weekly,” and “weekly.” Physical activity has two levels: “low” and “high.” If these are the only covariates available and we assume that responses are iid normally distributed, what is the maximum number of parameters we could potentially use to uniquely describe the mean response?ANOVA\n\n\nCode\nlibrary(\"rjags\")\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n12\nThere are 2×3×2 total treatment combinations. If not every treatment combination is observed, then a model with fewer parameters would be necessary.\n\n\n\n\nExercise 47.4  If we have both categorical and continuous covariates, then it is common to use the linear model parameterization instead of the cell means model. If it is unclear how to set it up, you can use the model.matrix function in R as we have in the lessons.ANOVA\nSuppose that in addition to the experimental factors in the previous question, we have two continuous covariates: weight in kg and resting heart rate in beats per minute. If we use 100mg dose, daily frequency, and low physical activity as the baseline group, which of the following gives the linear model parameterization for an additive model with no interactions?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\text{E}(y_i) = \\beta_0 + \\beta_1 I_{{\\texttt dose}_i=100} + \\beta_2 I_{{\\texttt freq}_i={\\texttt daily}} + \\beta_3 I_{{\\texttt phys}_i={\\texttt low}} + \\ldots \\\\ \\qquad \\ldots + \\beta_4 {\\texttt weight}_i + \\beta_5 {\\texttt heart}_i\n\\text{E}(y_i) = \\mu_{g_i} + \\beta_1 {\\texttt weight}_i + \\beta_2 {\\texttt heart}_i\n\\text{E}(y_i) = \\mu_{g_i} + \\beta_1 {\\texttt weight}_i + \\beta_2 {\\texttt heart}_i\n\\text{E}(y_i) = \\beta_0 + \\beta_1 I_{{\\texttt dose}_i=200} + \\beta_2 I_{{\\texttt freq}_i={\\texttt twice\\ weekly}} + \\beta_3 I_{{\\texttt freq}_i={\\texttt weekly}} + \\ldots \\\\ \\qquad \\ldots + \\beta_4 I_{{\\texttt phys}_i={\\texttt high}} + \\beta_5 {\\texttt weight}_i + \\beta_6 {\\texttt heart}_i\n\n\n\n\n\nExercise 47.5  The reading in this honors section describes an analysis of the warp breaks data. Of the models fit, we concluded that the full cell means model was most appropriate. However, we did not assess whether constant observation variance across all groups was appropriate. Re-fit the model with a separate variance for each group. For each variance, use an Inverse-Gamma(1/2, 1/2) prior, corresponding to prior sample size 1 and prior guess 1 for each variance.ANOVA\nReport the DIC value for this model, rounded to the nearest whole number.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nX = model.matrix( ~ wool + tension, data=warpbreaks)\n#ead(X)\ndata(\"warpbreaks\")\n#?warpbreaks\n#head(warpbreaks)\nlibrary(\"rjags\")\nmod3_string = \" model {\n    for( i in 1:length(y)) {\n        y[i] ~ dnorm(mu[woolGrp[i], tensGrp[i]], prec[woolGrp[i], tensGrp[i]])\n    }\n    \n    for (j in 1:max(woolGrp)) {\n        for (k in 1:max(tensGrp)) {\n            mu[j,k] ~ dnorm(0.0, 1.0/1.0e6)\n            prec[j,k] ~ dgamma(0.5, 0.5)\n            sig[j,k] = sqrt(1.0 / prec[j,k])\n        }\n    }\n    \n} \"\n\nstr(warpbreaks)\n\n\n'data.frame':   54 obs. of  3 variables:\n $ breaks : num  26 30 54 25 70 52 51 26 67 18 ...\n $ wool   : Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ tension: Factor w/ 3 levels \"L\",\"M\",\"H\": 1 1 1 1 1 1 1 1 1 2 ...\n\n\nCode\ndata3_jags = list(y=log(warpbreaks$breaks), woolGrp=as.numeric(warpbreaks$wool), tensGrp=as.numeric(warpbreaks$tension))\n\nparams3 = c(\"mu\", \"sig\")\n\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 54\n   Unobserved stochastic nodes: 12\n   Total graph size: 191\n\nInitializing model\n\n\nCode\nupdate(mod3, 1e3)\n\nmod3_sim = coda.samples(model=mod3,\n                        variable.names=params3,\n                        n.iter=5e3)\nmod3_csim = as.mcmc(do.call(rbind, mod3_sim))\n\n#plot(mod3_sim, ask=TRUE)\n\n## convergence diagnostics\ngelman.diag(mod3_sim)\n\n\nPotential scale reduction factors:\n\n         Point est. Upper C.I.\nmu[1,1]           1       1.00\nmu[2,1]           1       1.00\nmu[1,2]           1       1.00\nmu[2,2]           1       1.00\nmu[1,3]           1       1.00\nmu[2,3]           1       1.00\nsig[1,1]          1       1.00\nsig[2,1]          1       1.00\nsig[1,2]          1       1.01\nsig[2,2]          1       1.00\nsig[1,3]          1       1.00\nsig[2,3]          1       1.00\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod3_sim)\n\n\n            mu[1,1]       mu[2,1]      mu[1,2]     mu[2,2]      mu[1,3]\nLag 0   1.000000000  1.0000000000  1.000000000 1.000000000  1.000000000\nLag 1  -0.014570917 -0.0024648496 -0.005972096 0.001473007 -0.008438936\nLag 5   0.012036893  0.0025289446  0.003349855 0.007763258 -0.002963054\nLag 10 -0.003465499  0.0057127595  0.003068672 0.007892690 -0.003335368\nLag 50 -0.005393425  0.0002250335 -0.006245108 0.010277522 -0.005550689\n             mu[2,3]    sig[1,1]     sig[2,1]      sig[1,2]     sig[2,2]\nLag 0   1.0000000000 1.000000000  1.000000000  1.0000000000  1.000000000\nLag 1   0.0063363768 0.129664352  0.102529950  0.1239463647  0.093515491\nLag 5   0.0063703285 0.005780222 -0.007318486  0.0091841603  0.015814855\nLag 10 -0.0042942688 0.004707227 -0.008437826  0.0038305338  0.002443544\nLag 50  0.0002515155 0.010159440 -0.020150847 -0.0008806229 -0.012370196\n           sig[1,3]     sig[2,3]\nLag 0   1.000000000  1.000000000\nLag 1   0.122927275  0.122708065\nLag 5   0.011110829 -0.001985284\nLag 10 -0.007095737  0.001061326\nLag 50 -0.017240964 -0.004011097\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n mu[1,1]  mu[2,1]  mu[1,2]  mu[2,2]  mu[1,3]  mu[2,3] sig[1,1] sig[2,1] \n15239.90 15093.36 15244.01 14511.81 15206.42 15000.00 11558.50 12046.09 \nsig[1,2] sig[2,2] sig[1,3] sig[2,3] \n11481.42 12065.88 11893.21 11718.97 \n\n\nCode\nraftery.diag(mod3_sim)\n\n\n[[1]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                                \n          Burn-in  Total Lower bound  Dependence\n          (M)      (N)   (Nmin)       factor (I)\n mu[1,1]  2        3803  3746         1.020     \n mu[2,1]  3        4129  3746         1.100     \n mu[1,2]  2        3741  3746         0.999     \n mu[2,2]  2        3995  3746         1.070     \n mu[1,3]  3        4198  3746         1.120     \n mu[2,3]  2        3805  3746         1.020     \n sig[1,1] 2        3680  3746         0.982     \n sig[2,1] 2        3620  3746         0.966     \n sig[1,2] 2        3866  3746         1.030     \n sig[2,2] 2        3681  3746         0.983     \n sig[1,3] 2        3866  3746         1.030     \n sig[2,3] 2        3741  3746         0.999     \n\n\n[[2]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                                \n          Burn-in  Total Lower bound  Dependence\n          (M)      (N)   (Nmin)       factor (I)\n mu[1,1]  3        4062  3746         1.080     \n mu[2,1]  2        3866  3746         1.030     \n mu[1,2]  3        4062  3746         1.080     \n mu[2,2]  2        3741  3746         0.999     \n mu[1,3]  2        3866  3746         1.030     \n mu[2,3]  3        4338  3746         1.160     \n sig[1,1] 2        3805  3746         1.020     \n sig[2,1] 2        3930  3746         1.050     \n sig[1,2] 2        3741  3746         0.999     \n sig[2,2] 2        3741  3746         0.999     \n sig[1,3] 2        3741  3746         0.999     \n sig[2,3] 2        3866  3746         1.030     \n\n\n[[3]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                                \n          Burn-in  Total Lower bound  Dependence\n          (M)      (N)   (Nmin)       factor (I)\n mu[1,1]  3        4267  3746         1.140     \n mu[2,1]  2        3995  3746         1.070     \n mu[1,2]  2        3930  3746         1.050     \n mu[2,2]  2        3995  3746         1.070     \n mu[1,3]  3        4198  3746         1.120     \n mu[2,3]  3        4484  3746         1.200     \n sig[1,1] 2        3930  3746         1.050     \n sig[2,1] 2        3803  3746         1.020     \n sig[1,2] 2        3741  3746         0.999     \n sig[2,2] 2        3866  3746         1.030     \n sig[1,3] 2        3741  3746         0.999     \n sig[2,3] 2        3866  3746         1.030     \n\n\nCode\n(dic3 = dic.samples(mod3, n.iter=1e3))\n\n\nMean deviance:  60.25 \npenalty 14.78 \nPenalized deviance: 75.03 \n\n\nThe DIC for this model is much higher than for the other models, suggesting that separate variances does not improve predictive accuracy in this model. However, the variance for the last group does appear to be smaller than the others, which may affect our inferences for the mean of the last group.",
    "crumbs": [
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>HW+ - Multiple Factor ANOVA</span>"
    ]
  },
  {
    "objectID": "C2-L09.html",
    "href": "C2-L09.html",
    "title": "48  M3L9 - Logistic regression",
    "section": "",
    "text": "48.1 Introduction to Logistic Regression (Video)\nLogistic regression is the preferred model when modelling a problem where the response variable is binary such as a classification or the outcome of a Bernoulli trial. In such the traditional least square fit suffers from a number of shortcomings. The main idea here is a log transform. However a naive approach this transform imposes issues with 0 valued inputs since log(0)=-\\infty",
    "crumbs": [
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>M3L9 - Logistic regression</span>"
    ]
  },
  {
    "objectID": "C2-L09.html#sec-intro-logistic-regression",
    "href": "C2-L09.html#sec-intro-logistic-regression",
    "title": "48  M3L9 - Logistic regression",
    "section": "",
    "text": "Figure 48.1: Introduction to logistic regression\n\n\n\n48.1.1 Data\n For an example of logistic regression , we’ll use the urine data set from the boot package in R. The response variable is r, which takes on values of 0 or 1. We will remove some rows from the data set which contain missing values.logistic regression\n\n\nCode\nlibrary(\"boot\")\ndata(\"urine\")\n?urine\nhead(urine)\n\n\n  r gravity   ph osmo cond urea calc\n1 0   1.021 4.91  725   NA  443 2.45\n2 0   1.017 5.74  577 20.0  296 4.49\n3 0   1.008 7.20  321 14.9  101 2.36\n4 0   1.011 5.51  408 12.6  224 2.15\n5 0   1.005 6.52  187  7.5   91 1.16\n6 0   1.020 5.27  668 25.3  252 3.34\n\n\n\n\nCode\n1dat = na.omit(urine)\n\n\n\n1\n\ndrop missing values\n\n\n\n\nLet’s look at pairwise scatter plots of the seven variables.\n\n\nCode\npairs(dat)\n\n\n\n\n\n\n\n\n\nOne thing that stands out is that several of these variables are strongly correlated with one another. For example gravity and osmo appear to have a very close linear relationship. Collinearity between x variables in linear regression models can cause trouble for statistical inference. Two correlated variables will compete for the ability to predict the response variable, leading to unstable estimates. This is not a problem for prediction of the response, if prediction is the end goal of the model. But if our objective is to discover how the variables relate to the response, we should avoid collinearity.\n\n\n\n\n\n\nImportantCollinearity and Multicollinearity\n\n\n\n When two covariates are highly correlated we call this relation collinearity. When one covariate in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy we call this relation multicollinearity. It is possible that no two pairs of a such a group of covariates are correlated.\nIn both cases this will lead to the design matrix being almost singular. Near singular matrices are a strong cause of instability in numerical calculations. Statistical this tends to lead to a model with inflated standard errors compared to models where we only keep the a subset where variables are neither collinear nor multicollinear. A consequence of this is that we will see a drop in statistical significance for these variables, which will make interpreting the model harder.\nWe have seen a few strategies ways to deal with these issues:\n\ninclude pair plot in the exploratory data analysis phase.\npicking subsets and checking DIC or,\nvariable selection using double exponential priors.\nPCA creates independent covariates with a lower dimension with a trade of losing interpretability. See (Johnson and Wichern 2001, 386) (Belsley, Kuh, and Welsch 1980, 85–191) (Härdle and Simar 2019)\nFeature elimination based on combination of Variance inflation factors (VIF) (Sheather 2009, 203)\n\n\n\nWe can more formally estimate the correlation among these variables using the corrplot package.\n\n\nCode\nlibrary(\"corrplot\")\nCor = cor(dat)\ncorrplot(Cor, type=\"upper\", method=\"ellipse\", tl.pos=\"d\")\ncorrplot(Cor, type=\"lower\", method=\"number\", col=\"black\", \n         add=TRUE, diag=FALSE, tl.pos=\"n\", cl.pos=\"n\")\n\n\n\n\n\n\n\n\n\n\n\n48.1.2 Variable selection\nOne primary goal of this analysis is to find out which variables are related to the presence of calcium oxalate crystals. This objective is often called “variable selection.” We have already seen one way to do this: fit several models that include different sets of variables and see which one has the best DIC. Another way to do this is to use a linear model where the priors for the \\beta coefficients favor values near 0 (indicating a weak relationship). This way, the burden of establishing association lies with the data. If there is not a strong signal, we assume it doesn’t exist.\nRather than tailoring a prior for each individual \\beta based on the scale its covariate takes values on, it is customary to subtract the mean and divide by the standard deviation for each variable.\n\n\nCode\nX = scale(dat[,-1], center=TRUE, scale=TRUE)\nhead(X[,\"gravity\"])\n\n\n         2          3          4          5          6          7 \n-0.1403037 -1.3710690 -0.9608139 -1.7813240  0.2699514 -0.8240622 \n\n\n\n\nCode\ncolMeans(X)\n\n\n      gravity            ph          osmo          cond          urea \n-9.861143e-15  8.511409e-17  1.515743e-16 -1.829852e-16  7.335402e-17 \n         calc \n-1.689666e-18 \n\n\n\n\nCode\napply(X, 2, sd)\n\n\ngravity      ph    osmo    cond    urea    calc \n      1       1       1       1       1       1 \n\n\n\n\n48.1.3 Model\nOur prior for the \\beta (which we’ll call b in the model) coefficients will be the double exponential (or Laplace) distribution, which as the name implies, is the exponential distribution with tails extending in the positive direction as well as the negative direction, with a sharp peak at 0. We can read more about it in the JAGS manual. The distribution looks like:\n\n\nCode\nddexp = function(x, mu, tau) {\n  0.5*tau*exp(-tau*abs(x-mu)) \n}\ncurve(ddexp(x, mu=0.0, tau=1.0), from=-5.0, to=5.0, ylab=\"density\", main=\"Double exponential\\ndistribution\") # double exponential distribution\ncurve(dnorm(x, mean=0.0, sd=1.0), from=-5.0, to=5.0, lty=2, add=TRUE) # normal distribution\nlegend(\"topright\", legend=c(\"double exponential\", \"normal\"), lty=c(1,2), bty=\"n\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(\"rjags\")\n\n\n\n\nCode\nmod1_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = int + b[1]*gravity[i] + b[2]*ph[i] + b[3]*osmo[i] + b[4]*cond[i] + b[5]*urea[i] + b[6]*calc[i]\n    }\n    int ~ dnorm(0.0, 1.0/25.0)\n    for (j in 1:6) {\n        b[j] ~ ddexp(0.0, sqrt(2.0)) # has variance 1.0\n    }\n} \"\n\nset.seed(92)\nhead(X)\n\n\n     gravity         ph       osmo       cond        urea        calc\n2 -0.1403037 -0.4163725 -0.1528785 -0.1130908  0.25747827  0.09997564\n3 -1.3710690  1.6055972 -1.2218894 -0.7502609 -1.23693077 -0.54608444\n4 -0.9608139 -0.7349020 -0.8585927 -1.0376121 -0.29430353 -0.60978050\n5 -1.7813240  0.6638579 -1.7814497 -1.6747822 -1.31356713 -0.91006194\n6  0.2699514 -1.0672806  0.2271214  0.5490664 -0.07972172 -0.24883614\n7 -0.8240622 -0.5825618 -0.6372741 -0.4379226 -0.51654898 -0.83726644\n\n\nCode\ndata_jags = list(y=dat$r, gravity=X[,\"gravity\"], ph=X[,\"ph\"], osmo=X[,\"osmo\"], cond=X[,\"cond\"], urea=X[,\"urea\"], calc=X[,\"calc\"])\n\nparams = c(\"int\", \"b\")\n\nmod1 = jags.model(textConnection(mod1_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 77\n   Unobserved stochastic nodes: 7\n   Total graph size: 1085\n\nInitializing model\n\n\nCode\nupdate(mod1, 1e3)\n\nmod1_sim = coda.samples(model=mod1,\n                        variable.names=params,\n                        n.iter=5e3)\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim))\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod1_sim, ask=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod1_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]          1       1.00\nb[2]          1       1.00\nb[3]          1       1.00\nb[4]          1       1.01\nb[5]          1       1.00\nb[6]          1       1.00\nint           1       1.00\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod1_sim)\n\n\n             b[1]         b[2]       b[3]       b[4]       b[5]         b[6]\nLag 0  1.00000000  1.000000000 1.00000000 1.00000000 1.00000000 1.0000000000\nLag 1  0.82455145  0.275126853 0.88415792 0.73813220 0.79047975 0.4900889290\nLag 5  0.38282625  0.024783761 0.54186932 0.30458860 0.34063895 0.0289921484\nLag 10 0.15623277  0.007830358 0.27598994 0.13981694 0.13659864 0.0006661123\nLag 50 0.01745844 -0.003605210 0.02771368 0.02391942 0.03779496 0.0191733095\n               int\nLag 0  1.000000000\nLag 1  0.280587632\nLag 5  0.019727112\nLag 10 0.024918124\nLag 50 0.006355973\n\n\nCode\nautocorr.plot(mod1_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod1_sim)\n\n\n     b[1]      b[2]      b[3]      b[4]      b[5]      b[6]       int \n1405.2325 8271.9006  922.2363 1717.9002 1553.5772 5140.3197 8106.0347 \n\n\nCode\n## calculate DIC\ndic1 = dic.samples(mod1, n.iter=1e3)\n\n\nLet’s look at the results.\n\n\nCode\nsummary(mod1_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nb[1]  1.6750 0.7355 0.006005       0.019654\nb[2] -0.1413 0.2859 0.002335       0.003146\nb[3] -0.3351 0.7609 0.006213       0.025145\nb[4] -0.7387 0.4898 0.003999       0.012074\nb[5] -0.6002 0.5796 0.004732       0.014837\nb[6]  1.6130 0.4833 0.003947       0.006771\nint  -0.1758 0.3015 0.002461       0.003351\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%      75%  97.5%\nb[1]  0.3903  1.1447  1.6251  2.14935 3.2313\nb[2] -0.7313 -0.3223 -0.1287  0.04632 0.4062\nb[3] -2.0128 -0.7892 -0.2416  0.14213 1.0840\nb[4] -1.7470 -1.0615 -0.7238 -0.39099 0.1457\nb[5] -1.8615 -0.9675 -0.5393 -0.18216 0.3898\nb[6]  0.7474  1.2766  1.5842  1.92495 2.6181\nint  -0.7665 -0.3789 -0.1777  0.02473 0.4293\n\n\n\n\nCode\n#par(mfrow=c(3,2))\npar(mar = c(2.5, 1, 2.5, 1))\n\ndensplot(mod1_csim[,1:6], xlim=c(-3.0, 3.0))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncolnames(X) # variable names\n\n\n[1] \"gravity\" \"ph\"      \"osmo\"    \"cond\"    \"urea\"    \"calc\"   \n\n\nIt is clear that the coefficients for variables gravity, cond (conductivity), and calc (calcium concentration) are not 0. The posterior distribution for the coefficient of osmo (osmolarity) looks like the prior, and is almost centered on 0 still, so we’ll conclude that osmo is not a strong predictor of calcium oxalate crystals. The same goes for ph.\nurea (urea concentration) appears to be a borderline case. However, if we refer back to our correlations among the variables, we see that urea is highly correlated with gravity, so we opt to remove it.\nOur second model looks like this:\n\n\nCode\nmod2_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = int + b[1]*gravity[i] + b[2]*cond[i] + b[3]*calc[i]\n    }\n    int ~ dnorm(0.0, 1.0/25.0)\n    for (j in 1:3) {\n        b[j] ~ dnorm(0.0, 1.0/25.0) # noninformative for logistic regression\n    }\n} \"\n\nmod2 = jags.model(textConnection(mod2_string), data=data_jags, n.chains=3)\n\n\nWarning in jags.model(textConnection(mod2_string), data = data_jags, n.chains =\n3): Unused variable \"ph\" in data\n\n\nWarning in jags.model(textConnection(mod2_string), data = data_jags, n.chains =\n3): Unused variable \"osmo\" in data\n\n\nWarning in jags.model(textConnection(mod2_string), data = data_jags, n.chains =\n3): Unused variable \"urea\" in data\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 77\n   Unobserved stochastic nodes: 4\n   Total graph size: 635\n\nInitializing model\n\n\n\n\nCode\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params,\n                        n.iter=5e3)\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim))\n\npar(mar = c(2.5, 1, 2.5, 1))\n#plot(mod2_sim, ask=TRUE)\nplot(mod2_sim)\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod2_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]          1          1\nb[2]          1          1\nb[3]          1          1\nint           1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod2_sim)\n\n\n             b[1]       b[2]       b[3]           int\nLag 0  1.00000000 1.00000000 1.00000000  1.0000000000\nLag 1  0.58128433 0.67350376 0.50743018  0.2872249841\nLag 5  0.11242736 0.16403208 0.05713961  0.0101213096\nLag 10 0.04561829 0.04332871 0.02999190  0.0007838081\nLag 50 0.01595758 0.02919047 0.01100776 -0.0031651856\n\n\nCode\nautocorr.plot(mod2_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod2_sim)\n\n\n    b[1]     b[2]     b[3]      int \n3443.873 2651.275 4476.259 8073.307 \n\n\nCode\ndic2 = dic.samples(mod2, n.iter=1e3)\n\n\n\n\n48.1.4 Results\n\n\nCode\ndic1\n\n\nMean deviance:  68.65 \npenalty 5.448 \nPenalized deviance: 74.1 \n\n\n\n\nCode\ndic2\n\n\nMean deviance:  70.99 \npenalty 3.816 \nPenalized deviance: 74.81 \n\n\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nb[1]  1.4223 0.5125 0.004184       0.008743\nb[2] -1.3550 0.4761 0.003888       0.009254\nb[3]  1.8755 0.5600 0.004573       0.008377\nint  -0.1528 0.3230 0.002637       0.003610\n\n2. Quantiles for each variable:\n\n        2.5%     25%    50%      75%   97.5%\nb[1]  0.4929  1.0686  1.401  1.74706  2.5016\nb[2] -2.3444 -1.6670 -1.337 -1.02664 -0.4878\nb[3]  0.8940  1.4857  1.837  2.22553  3.0748\nint  -0.7685 -0.3713 -0.159  0.05905  0.4990\n\n\n\n\nCode\nHPDinterval(mod2_csim)\n\n\n          lower      upper\nb[1]  0.4667769  2.4602958\nb[2] -2.2950147 -0.4479398\nb[3]  0.8596236  3.0278554\nint  -0.7707860  0.4938714\nattr(,\"Probability\")\n[1] 0.95\n\n\n\n\nCode\n#par(mfrow=c(3,1))\npar(mar = c(2.5, 1, 2.5, 1))\ndensplot(mod2_csim[,1:3], xlim=c(-3.0, 3.0))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncolnames(X)[c(1,4,6)] # variable names\n\n\n[1] \"gravity\" \"cond\"    \"calc\"   \n\n\nThe DIC is actually better for the first model. Note that we did change the prior between models, and generally we should not use the DIC to choose between priors. Hence comparing DIC between these two models may not be a fair comparison. Nevertheless, they both yield essentially the same conclusions. Higher values of gravity and calc (calcium concentration) are associated with higher probabilities of calcium oxalate crystals, while higher values of cond (conductivity) are associated with lower probabilities of calcium oxalate crystals.\nThere are more modeling options in this scenario, perhaps including transformations of variables, different priors, and interactions between the predictors, but we’ll leave it to you to see if you can improve the model.\n\n\n\n\n\n\nBelsley, David A., Edwin Kuh, and Roy E. Welsch. 1980. Regression Diagnostics. John Wiley & Sons, Inc. https://doi.org/10.1002/0471725153.\n\n\nHärdle, Wolfgang Karl, and Léopold Simar. 2019. Applied Multivariate Statistical Analysis. Springer International Publishing. https://doi.org/10.1007/978-3-030-26006-4.\n\n\nJohnson, R. A., and D. W. Wichern. 2001. Applied Multivariate Statistical Analysis. Pearson Modern Classics for Advanced Statistics Series. Prentice Hall. https://books.google.co.il/books?id=QBqlswEACAAJ.\n\n\nSheather, Simon. 2009. A Modern Approach to Regression with r. Springer New York. https://doi.org/10.1007/978-0-387-09608-7.",
    "crumbs": [
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>M3L9 - Logistic regression</span>"
    ]
  },
  {
    "objectID": "C2-L09-Ex1.html",
    "href": "C2-L09-Ex1.html",
    "title": "49  Homework on Logistic Regression",
    "section": "",
    "text": "Exercise 49.1  What is the advantage of using a link function such as the logit transform for logistic regression?Logistic Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIt ensures that the success probability (\\mathbb{E}[y] if y is Bernoulli) is between 0 and 1 without requiring any constraints on the x variables or the \\beta coefficients.\nIt ensures that \\beta_0+\\beta_1x_1+…+\\beta_kx_k is between 0 and 1 using log transformations of the coefficients.\nIt makes the \\beta coefficients interpretable directly as probabilities.\nIt ensures that the \\beta coefficients lie between 0 and 1 for all values of predictors x.\n\nThis is a categorical predictor.\n\n\n\n\nExercise 49.2  Logistic regression works with binomial likelihoods in addition to Bernoulli likelihoods. If the response y_i is a number of successes in n_i independent trials each with \\phi_i success probability, we can still model \\phi_i with a linear model using the logit transformation.Logistic Regression\nAs an example, consider the OME data in the MASS package in R. The data consist of experimental results from tests of auditory perception in children. Under varying conditions and for multiple trials under each condition, children either correctly or incorrectly identified the source of changing signals.\nAlthough the independence of the trails and results are questionable, we’ll try fitting a logistic regression to these data. First, we’ll explore the relationships briefly with the following code:\n\n\n\n\nListing 49.1: EDA of the OME dataset\n\n\n\nCode\nlibrary(\"MASS\")\ndata(\"OME\")\n?OME # background on the data\nhead(OME)\n\n\n\n\n\n  ID Age OME Loud      Noise Correct Trials\n1  1  30 low   35   coherent       1      4\n2  1  30 low   35 incoherent       4      5\n3  1  30 low   40   coherent       0      3\n4  1  30 low   40 incoherent       1      1\n5  1  30 low   45   coherent       2      4\n6  1  30 low   45 incoherent       2      2\n\n\n\n\nListing 49.2: EDA of the OME dataset\n\n\n\nCode\nany(is.na(OME)) # check for missing values\n\n\n\n\n\n[1] FALSE\n\n\n\n\nListing 49.3: EDA of the OME dataset\n\n\n\nCode\ndat = subset(OME, OME != \"N/A\") # manually remove OME missing values identified with \"N/A\"\ndat$OME = factor(dat$OME)\nstr(dat)\n\n\n\n\n\n'data.frame':   712 obs. of  7 variables:\n $ ID     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Age    : int  30 30 30 30 30 30 30 30 30 30 ...\n $ OME    : Factor w/ 2 levels \"high\",\"low\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Loud   : int  35 35 40 40 45 45 50 50 55 55 ...\n $ Noise  : Factor w/ 2 levels \"coherent\",\"incoherent\": 1 2 1 2 1 2 1 2 1 2 ...\n $ Correct: int  1 4 0 1 2 2 3 4 3 2 ...\n $ Trials : int  4 5 3 1 4 2 3 4 3 2 ...\n\n\n\n\nListing 49.4: EDA of the OME dataset\n\n\n\nCode\nplot(dat$Age, dat$Correct / dat$Trials )\nplot(dat$OME, dat$Correct / dat$Trials )\nplot(dat$Loud, dat$Correct / dat$Trials )\nplot(dat$Noise, dat$Correct / dat$Trials )\n\n\n\n\n\n\n\n\n\nage vs success\n\n\n\n\n\n\nOME vs success\n\n\n\n\n\n\nLoud vs success\n\n\n\n\n\n\nNoise vs success\n\n\n\n\n\nEDA of the OME dataset\n\nWe are interested how these variables relate to the probability of successfully identifying the source of changes in sound. Of these four variables, which appears to have the weakest association with the probability of success?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nAge in months\nOME: degree of otitis media with effusion (low or high)\nLoudness of stimulus in decibels\nNoise: stimulus type (coherent or incoherent)\n\nWith a Bernoulli likelihood, E(y) is the probability of success, which should be a proper probability. If the likelihood is Binomial, then the expected value of y is the the number of trials times the success probability. Here we would still use a logit likelihood on the success probability.\n\n\n\n\nExercise 49.3  Next, we’ll fit a reference logistic regression model with non-informative prior in R. We can do this with the glm function, providing the model formula as with the usual lm, except now the response is the observed proportion of correct responses. We must also indicate how many trials were run for each experiment using the weights argument.Logistic Regression\n\n\n\n\nListing 49.5: OME GLM\n\n\n\nCode\nmod_glm = glm(Correct/Trials ~ Age + OME + Loud + Noise, data=dat, weights=Trials, family=\"binomial\")\nsummary(mod_glm)\n\n\n\n\n\n\nCall:\nglm(formula = Correct/Trials ~ Age + OME + Loud + Noise, family = \"binomial\", \n    data = dat, weights = Trials)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -7.294441   0.434928 -16.772  &lt; 2e-16 ***\nAge              0.018896   0.003767   5.016 5.28e-07 ***\nOMElow          -0.237150   0.123257  -1.924   0.0544 .  \nLoud             0.171682   0.008880  19.333  &lt; 2e-16 ***\nNoiseincoherent  1.576304   0.115236  13.679  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1431.12  on 711  degrees of freedom\nResidual deviance:  732.38  on 707  degrees of freedom\nAIC: 1262.6\n\nNumber of Fisher Scoring iterations: 5\n\n\nTo get an idea of how the model fits, we can create residual (using a special type of residual for non-normal likelihoods) and in-sample prediction plots.\n\nCode\nplot(residuals(mod_glm, type=\"deviance\"))\nplot(fitted(mod_glm), dat$Correct/dat$Trials)\n\n\n\n\n\n\n\n\n\n\n\nFigure 49.1: residuals plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 49.2: in-sample prediction plots\n\n\n\n\n\nIt appears from the second plot that the model is not very precise (some model predictions were far from the observed proportion of correct responses). Nevertheless, it can be informative about the relationships among the variables.\nReport the posterior mode estimate of the coefficient for low OME.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n-0.24\n\n\n\n\nExercise 49.4  Next, we will fit a similar model in JAGS. To make the results comparable to those of the reference model, we will use the same configuration of covariates. We can extract this information from the reference model using model.matrix.Logistic Regression\n\n\nCode\nX = model.matrix(mod_glm)[,-1] # -1 removes the column of 1s for the intercept\nhead(X)\n\n\n  Age OMElow Loud Noiseincoherent\n1  30      1   35               0\n2  30      1   35               1\n3  30      1   40               0\n4  30      1   40               1\n5  30      1   45               0\n6  30      1   45               1\n\n\nThe data include categorical covariates which R codes as dummy variables (as with ANOVA). Hence we have an indicator variable for whether OME is at its low level and another indicating whether the Noise is incoherent. The intercept is then associated with this baseline group. Ignoring the continuous variables Age and Loud, what are the characteristics of this baseline group?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nChildren with low OME exposed to incoherent sound.\nChildren with high OME exposed to incoherent sound.\nChildren with low OME exposed to coherent sound.\nChildren with high OME exposed to coherent sound.\n\n\n\n\n\nExercise 49.5  Now complete the following code (as well as the code from previous questions) to fit the JAGS model with the fairly non-informative priors given. Use three chains with at least 5,000 iterations in each.Raftery and Lewis diagnostic\n\n\n\n\nListing 49.6: Jags logistic regression model\n\n\n\nCode\nmod1_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dbin(phi[i], n[i])\n        logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n    }\n    \n    b0 ~ dnorm(0.0, 1.0/5.0^2)\n    for (j in 1:4) {\n        b[j] ~ dnorm(0.0, 1.0/4.0^2)\n    }\n} \"\n\ndata_jags = as.list(as.data.frame(X))\n1data_jags$y = dat$Correct\ndata_jags$n = dat$Trials\n2str(data_jags)\n\nparams = c(\"b0\", \"b\")\n\nmod1 = jags.model(textConnection(mod1_string), data=data_jags, n.chains=3)\n3update(mod1, 1e3)\n\n4mod1_sim = coda.samples(model=mod1, variable.names=params,  n.iter=5e3)\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim))\n\n\n\n\n\n\n1\n\nthis will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.\n\n2\n\nensure all variables have the same number of observations (712).\n\n3\n\nburn in for 1k iterations\n\n4\n\nsim at least 5k iterations\n\n\n\n\nList of 6\n $ Age            : num [1:712] 30 30 30 30 30 30 30 30 30 30 ...\n $ OMElow         : num [1:712] 1 1 1 1 1 1 1 1 1 1 ...\n $ Loud           : num [1:712] 35 35 40 40 45 45 50 50 55 55 ...\n $ Noiseincoherent: num [1:712] 0 1 0 1 0 1 0 1 0 1 ...\n $ y              : int [1:712] 1 4 0 1 2 2 3 4 3 2 ...\n $ n              : int [1:712] 4 5 3 1 4 2 3 4 3 2 ...\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 712\n   Unobserved stochastic nodes: 5\n   Total graph size: 4377\n\nInitializing model\n\n\n\nCode\n## convergence diagnostics\nplot(mod1_sim,auto.layout = FALSE)\n\n\n\n\n\n\n\n\nb[1] trace - age\n\n\n\n\n\n\n\nb[1] density - age\n\n\n\n\n\n\n\n\n\nb[2] trace - OME\n\n\n\n\n\n\n\nb[2] density - OME\n\n\n\n\n\n\n\n\n\nb[3] trace - Loud\n\n\n\n\n\n\n\nb[3] density - Loud\n\n\n\n\n\n\n\n\n\nb[4] trace - incoherent\n\n\n\n\n\n\n\nb[4] density - incoherent\n\n\n\n\n\n\n\n\n\nb[0] trace - intercept\n\n\n\n\n\n\n\nb[0] density - intercept\n\n\n\n\n\n\nTrace plots\n\n\n\n\nCode\ngelman.diag(mod1_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]       1.00       1.01\nb[2]       1.00       1.00\nb[3]       1.03       1.06\nb[4]       1.00       1.00\nb0         1.03       1.05\n\nMultivariate psrf\n\n1.01\n\n\nCode\nautocorr.diag(mod1_sim)\n\n\n             b[1]         b[2]      b[3]       b[4]        b0\nLag 0  1.00000000  1.000000000 1.0000000 1.00000000 1.0000000\nLag 1  0.91025675  0.811156528 0.9826686 0.47753038 0.9870584\nLag 5  0.65090315  0.390115800 0.9215882 0.05882189 0.9356891\nLag 10 0.43901249  0.192422571 0.8532552 0.04455740 0.8760773\nLag 50 0.01764607 -0.002023693 0.4654191 0.03018729 0.4760548\n\n\n\nCode\nautocorr.plot(mod1_csim,auto.layout = FALSE)\n\n\n\n\n\n\n\n\nb[1] ac - age\n\n\n\n\n\n\n\nb[2] ac - OME\n\n\n\n\n\n\n\n\n\nb[3] ac - loud\n\n\n\n\n\n\n\nb[4] ac - incoherent\n\n\n\n\n\n\n\n\n\nb[0] ac - intercept\n\n\n\n\nMCMC auto-correlation\n\n\n\n\nCode\neffectiveSize(mod1_sim)\n#| label: 'lst-Logistic-Regression-5-5'\n1dic1 = dic.samples(mod1, n.iter=1e3)\n\n\n\n1\n\ncalculate DIC\n\n\n\n\n      b[1]       b[2]       b[3]       b[4]         b0 \n 618.09894 1420.13206  120.95215 3839.42600   99.65829 \n\n\nBecause there are many data points, the MCMC will take some time to run.\nBefore analyzing the results, perform some MCMC diagnostic checks. What does the Raftery and Lewis diagnostic (raftery.diag()) suggest about these chains?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nlibrary(\"coda\")\n(raftery.diag(mod1))\n\n\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n\nYou need a sample size of at least 3746 with these values of q, r and s\n\n\n\nThe dependence factor for many of the variables is large (&gt;5.0), indicating weak autocorrelation in the chains. We would not require a large number of iterations to reliably produce 95% probability intervals for the parameters.\nThe scale reduction factor for many variables is large (&gt;5.0), indicating that the different chains are exploring the same space. We have used a sufficient burn-in time.\nThe dependence factor for many of the variables is large (&gt;5.0), indicating strong autocorrelation in the chains. We would require a large number of iterations to reliably produce 95% probability intervals for the parameters.\nThe scale reduction factor for many variables is large (&gt;5.0), indicating that the different chains are not exploring the same space yet. We need to run a longer burn-in period.\n\nThe Raftery and Lewis diagnostic estimates how many iterations of the current chain would be required to reliably estimate the outer quantiles of the posterior.\n\n\n\n\nExercise 49.6  Although OMElow is the predictor with weakest statistical association to probability of correct responses, the posterior probability that its coefficient \\beta_2 is negative is still greater than 0.9. How do we interpret this (most likely) negative coefficient in the context of our model?Logistic Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWhile holding all other predictors constant, low OME is associated with a decrease of magnitude ∣\\beta_2∣ in the probability of correct responses while high OME is associated with an increase ∣\\beta_2∣.\nWhile holding all other predictors constant, low OME is associated with a higher probability of correct responses than high OME.\nWhile holding all other predictors constant, low OME is associated with a lower probability of correct responses than high OME.\nWhile holding all other predictors constant, low OME is associated with an increase of magnitude ∣\\beta_2∣ in the probability of correct responses while high OME is associated with a decrease of \\beta_2∣.\n\nSince low OME is coded with a one and has a negative coefficient, low OME is associated with lower log-odds and consequently lower probability.\nIt may also be interesting to try a model that includes interaction terms to see if, for example, the effect of low/high OME is different for different Age groups.\n\n\n\n\nExercise 49.7  Using the posterior mean estimates of the model coefficients, create a point estimate of the probability of correct responses for a child of age 60 months, with high OME, using a coherent stimulus of 50 decibels. Round your answer to two decimal places.Logistic Regression\n\n\n\n\n\n\nNoteHint:\n\n\n\nFirst calculate the linear part by multiplying the variables by the coefficients and adding them up (call this xb). Once you have that, apply the inverse of the link function to transform it into a probability estimate. Recall that the inverse of the logit transformation is \\phi=\\frac{1}{1+e^{−xb}}.\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n# logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n\n1A=X[,1]==60\n2B=X[,2]==0\n3C=X[,3]==50\n4D=X[,4]==0\n5ABCD = X[A & B & C & D, c(1,2,3,4)]\n6pm_coef = colMeans(mod1_csim)\n7pm_Xb = pm_coef[\"b0\"] + ABCD  %*% pm_coef[1:4]\n8phat = 1.0 / (1.0 + exp(-pm_Xb))\n9mean(phat)\n\n\n\n1\n\nchild of age 60 months\n\n2\n\nwith high OME,\n\n\n3\n\nusing a coherent\n\n4\n\nstimulus of 50 decibels\n\n5\n\ncombining\n\n6\n\ninfer mean for parameters from MCMC samples\n\n7\n\nmultiplying the variables by the coefficients\n\n8\n\ninverse of the link function to transform\n\n9\n\npoint estimate\n\n\n\n\n[1] 0.9180176\n\n\n\n\n\n\nExercise 49.8  Use the posterior mean estimates of the model coefficients to create point estimates of the probability of correct responses for each observation in the original data. To do this, follow the steps outlined in the lesson to create a vector of these probabilities called phat (using our notation from this quiz, it would be \\hat\\phi).Logistic Regression\nOnce you have phat, calculate the proportion of in-sample observations that are correctly classified according to the following criterion: the model prediction and observed correct response rate are either both higher than 0.7 or both lower than 0.7. Round your answer to two decimal places.\n\n\n\n\n\n\nNoteHint:\n\n\n\nUse the following code:\n\n\nCode\n# recall:   logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n\n(pm_coef = colMeans(mod1_csim))\n\n\n       b[1]        b[2]        b[3]        b[4]          b0 \n 0.01851805 -0.24664798  0.17009688  1.57064915 -7.20021444 \n\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\npm_Xb = pm_coef[\"b0\"] + X[,c(1,2,3,4)] %*% pm_coef[1:4]\nphat = 1.0 / (1.0 + exp(-pm_Xb))\nhead(phat)\n\n\n       [,1]\n1 0.2813186\n2 0.6531057\n3 0.4781525\n4 0.8150559\n5 0.6820131\n6 0.9116289\n\n\nCode\n(tab0.7 = table(phat &gt; 0.7, (dat$Correct / dat$Trials) &gt; 0.7))\n\n\n       \n        FALSE TRUE\n  FALSE   182   48\n  TRUE     63  419\n\n\nCode\nsum(diag(tab0.7)) / sum(tab0.7)\n\n\n[1] 0.8441011\n\n\n0.84\nIt appears that the accurate cases (high probability of correct responses) are well captured by the model.\nIn this exercise, we obtained a point estimate of the coefficients and used that to obtain a point estimate of the probabilities. If we want posterior distributions for the probabilities, we could apply the inverse link transformation to each iteration of the coefficients.",
    "crumbs": [
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Homework on Logistic Regression</span>"
    ]
  },
  {
    "objectID": "C2-L10.html",
    "href": "C2-L10.html",
    "title": "50  M4L10 - Poisson regression",
    "section": "",
    "text": "50.1 Introduction to Poisson regression\nPoisson regression is the preferred method to handle count data where the response is positive values but includes zeroes. The gist of this method is that We use a log transform link function on the regressors but not on the response which allows the response to be zero valued which correspond to zero counts. One limit of this approach mentioned below is that the Poisson takes one parameter \\lambda for both its expected value and its variance. We look give a deeper solution to this problem in the next course on mixture models, however in this course we will consider more restricted cases where we extend the Poisson regression with the Negative Binomial Distribution which allows us to model over-dispersed data.\nWe now have experience fitting regression models when the response is continuous, and when it is binary. What about when we have count data? We could fit a linear normal regression, but here we have a couple of drawbacks. First of all, counts usually aren’t negative. And the variances might not be constant. The Poisson distribution provides a natural likelihood for count data.\ny_i\\mid \\lambda+i \\stackrel {iid} \\sim \\mathrm{Pois}(\\lambda_i) \\qquad i=1, \\ldots, n\nHere, \\lambda conveniently represents the expected value of y \\mathbb{E}[y]. It turns out that \\lambda is also the variance of y \\mathbb{V}ar[y]. So if we expect a count to be higher, we also expect the variability in counts to go up.\nWe saw this earlier with the warp breaks data.\nIf we model the mean directly, like we did with linear regression. That is, we had the expected value yi was directly modeled with this linear form.\n\\mathbb{E}[y] = \\beta_0 + \\beta_1x_i \\qquad \\text{(linear regression)}\nWe would run into the same problem we did with logistic regression. The expected value has to be greater than zero in the Poisson distribution. To naturally deal with that restriction, we’re going to use the logarithmic link function.\nSo, the log link. That is, that the log of \\lambda_i is equal to this linear piece.\nlog link:\nlog(\\lambda_i) = \\beta_0+\\beta_1x_i \\qquad \\text{(log link)}\n\\tag{50.1}\n\\mathbb{E}[y]=\\beta_0+\\beta_1x_i \\qquad \\text{(linear regression)}\nFrom this, we can easily recover the expression for the mean itself. That is, we can invert this link function to get the expected value of y_i,\n\\implies \\mathbb{E}[y] = \\lambda_i = e^{\\left(\\beta_0+\\beta_1x_i \\right)}\n\\tag{50.2}\nIt might seem like this model is equivalent to fitting a normal linear regression to the log of y. But there are a few key differences. In the normal regression, we’re modeling the mean of the response directly. So we would be fitting a model to the \\log(y). Where we’re modeling the expected value of the \\log(y). This is different from what we’re modeling here, here we’re doing the log of the expected value of y.\n\\mathbb{E}[log(y)]\\ne log(\\mathbb{E}[y])\nThese are not equal, they’re usually similar, but they’re not the same. Another difference is that we have a separate independent parameter for the variants in a normal regression. In Poisson regression, the variance is automatically the same as \\lambda,which may not always be appropriate, as we’ll see in an upcoming example.\nAs usual, we can add more explanatory x variables to the Poisson regression framework. They can be continuous, categorical, or they could be counts themselves.\nIf we have three predictor variables x_i = ( x_{1,i}, x_{2,i}, x_{3,i} ), what would the likelihood part of the hierarchical representation of a Poisson regression with logarithmic link look like?\nHere we incorporated the (inverse) link function directly into the likelihood rather than writing it with two lines.",
    "crumbs": [
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>M4L10 - Poisson regression</span>"
    ]
  },
  {
    "objectID": "C2-L10.html#sec-introduction-to-poisson-regression",
    "href": "C2-L10.html#sec-introduction-to-poisson-regression",
    "title": "50  M4L10 - Poisson regression",
    "section": "",
    "text": "Figure 50.1: Introduction to Poisson regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left( e^{-(\\beta_0+\\beta_1 x_{1,i}+\\beta_2 x_{2,i}+\\beta_3 x_{3,i})}\\right)\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left(\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i} \\right)\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left(e^{\\beta_0 + \\beta_1 x_{1,i}+\\beta_2 x_{2,i}+\\beta_3 x_{3,i}}\\right)\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left( \\log[ \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i} ] \\right)",
    "crumbs": [
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>M4L10 - Poisson regression</span>"
    ]
  },
  {
    "objectID": "C2-L10.html#poisson-regression---jags-model",
    "href": "C2-L10.html#poisson-regression---jags-model",
    "title": "50  M4L10 - Poisson regression",
    "section": "50.2 Poisson regression - JAGS model",
    "text": "50.2 Poisson regression - JAGS model\n For an example of Poisson regression, we’ll use the badhealth data set from the COUNT package in R.doctor visits\n\n\nCode\nlibrary(\"COUNT\")\n\n\nLoading required package: msme\n\n\nLoading required package: MASS\n\n\nLoading required package: lattice\n\n\nLoading required package: sandwich\n\n\nCode\ndata(\"badhealth\")\n#?badhealth\nhead(badhealth)\n\n\n  numvisit badh age\n1       30    0  58\n2       20    0  54\n3       16    0  44\n4       20    0  57\n5       15    0  33\n6       15    0  28\n\n\naccording to the description:\n\n\n\n\n\n\nNoteData Card for badhealth\n\n\n\n1,127 observations from a 1998 German survey with 3 variables:\n\nnumvisit - number of visits to the doctor in 1998 (response)\nbadh - \\begin{cases} 1 \\qquad \\text{ patient claims to be in bad health} \\\\ 0 \\qquad \\text{ patient does not claim to be in bad health} \\end{cases}\nage - age of patient\n\n\n\n\n\nCode\nany(is.na(badhealth))\n\n\n[1] FALSE\n\n\n\nremove na\n\nAs usual, let’s visualize these data.\n\n\nCode\nhist(badhealth$numvisit, breaks=20)\n\n\n\n\n\n\n\n\nFigure 50.2: Histogram of number of doctor visits\n\n\n\n\n\n\n\nCode\nplot(jitter(log(numvisit)) ~ jitter(age), data=badhealth, subset=badh==0, xlab=\"age\", ylab=\"log(visits)\")\npoints(jitter(log(numvisit)) ~ jitter(age), data=badhealth, subset=badh==1, col=\"red\")\n\n\n\n\n\n\n\n\nFigure 50.3\n\n\n\n\n\n\n50.2.1 Doctor Visits Model\n It appears that both age and bad health are related to the number of doctor visits. We should include model terms for both variables. If we believe the age/visits relationship is different between healthy and non-healthy populations, we should also include an interaction term. We will fit the full model here and leave it to you to compare it with the simpler additive model.doctor visits\n\n\nCode\nlibrary(\"rjags\")\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/1e4)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n    b_intx ~ dnorm(0.0, 1.0/1e4)\n} \"\n\nset.seed(102)\n\ndata_jags = as.list(badhealth)\n\nparams = c(\"int\", \"b_badh\", \"b_age\", \"b_intx\")\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 4\n   Total graph size: 3665\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,  variable.names=params, n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nb_age        1.00       1.01\nb_badh       1.01       1.04\nb_intx       1.01       1.04\nint          1.00       1.01\n\nMultivariate psrf\n\n1.01\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n           b_age    b_badh    b_intx       int\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.9525175 0.9652643 0.9678261 0.9484847\nLag 5  0.8199741 0.8674916 0.8739739 0.8153412\nLag 10 0.6852371 0.7603195 0.7721200 0.6842460\nLag 50 0.2062104 0.2349866 0.2474145 0.1989648\n\n\nCode\nautocorr.plot(mod_csim)\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod_sim)\n\n\n   b_age   b_badh   b_intx      int \n281.1309 198.7581 186.1054 270.6465 \n\n\nCode\n## compute DIC\ndic = dic.samples(mod, n.iter=1e3)\n\n\n\n\n50.2.2 Model checking - Residuals\n\n“While inexact models may mislead, attempting to allow for every contingency a priori is impractical. Thus models must be built by an iterative feedback process in which an initial parsimonious model may be modified when diagnostic checks applied to residuals indicate the need.” —G. E. P. Box\n\nTo get a general idea of the model’s performance, we can look at predicted values and residuals as usual. Don’t forget that we must apply the inverse of the link function to get predictions for \\lambda .\n\n\nCode\n1X = as.matrix(badhealth[,-1])\n2X = cbind(X, with(badhealth, badh*age))\nhead(X)\n\n\n\n1\n\nwe drop the first column since it is the column for our y.\n\n2\n\nwe add a third column with \\mathbb{I}_{badh}\\times age\n\n\n\n\n     badh age  \n[1,]    0  58 0\n[2,]    0  54 0\n[3,]    0  44 0\n[4,]    0  57 0\n[5,]    0  33 0\n[6,]    0  28 0\n\n\n\n\nCode\n1(pmed_coef = apply(mod_csim, 2, median))\n\n\n\n1\n\nthis are the column medians of the coefficients.\n\n\n\n\n       b_age       b_badh       b_intx          int \n 0.008321089  1.557435148 -0.010663658  0.354097817 \n\n\n\n\nCode\n1llam_hat = pmed_coef[\"int\"] + X %*% pmed_coef[c(\"b_badh\", \"b_age\", \"b_intx\")]\n2lam_hat = exp(llam_hat)\n\nhist(lam_hat)\n\n\n\n1\n\nX \\cdot \\vec b_i gives the linear part.\n\n2\n\n\\hat\\lambda_i=e^{X \\cdot \\vec b_i} we need to apply the inverse link function\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nresid = badhealth$numvisit - lam_hat\nplot(resid) # the data were ordered\n\n\n\n\n\n\n\n\n\nthis plot looks bad, it might not be iid but we can ignore the issue since the data is presorted/\n\n\nCode\nplot(lam_hat, badhealth$numvisit)\nabline(0.0, 1.0)\n\n\n\n\n\n\n\n\nFigure 50.4\n\n\n\n\n\n\n\nCode\nplot(lam_hat[which(badhealth$badh==0)], resid[which(badhealth$badh==0)], xlim=c(0, 8), ylab=\"residuals\", xlab=expression(hat(lambda)), ylim=range(resid))\npoints(lam_hat[which(badhealth$badh==1)], resid[which(badhealth$badh==1)], col=\"red\")\n\n\n\n\n\n\n\n\nFigure 50.5\n\n\n\n\n\nIt is not surprising that the variability increases for values predicted at higher values since the mean is also the variance in the Poisson distribution. However, observations predicted to have about two visits should have variance about two, and observations predicted to have about six visits should have variance about six.\n\n\nCode\nvar(resid[which(badhealth$badh==0)])\n\n\n[1] 7.022625\n\n\n\n\nCode\nvar(resid[which(badhealth$badh==1)])\n\n\n[1] 41.19614\n\n\nFor this data the variance is much bigger this is not the case with these data. This indicates that either the model fits poorly (meaning the covariates don’t explain enough of the variability in the data), or the data are “overdispersed” for the Poisson likelihood we have chosen. This is a common issue with count data. If the data are more variable than the Poisson likelihood would suggest, a good alternative is the negative binomial distribution, which we will not pursue here.",
    "crumbs": [
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>M4L10 - Poisson regression</span>"
    ]
  },
  {
    "objectID": "C2-L10.html#sec-predictive-distributions",
    "href": "C2-L10.html#sec-predictive-distributions",
    "title": "50  M4L10 - Poisson regression",
    "section": "50.3 Predictive distributions",
    "text": "50.3 Predictive distributions\nAssuming the model fit is adequate, we can interpret the results.\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean       SD  Naive SE Time-series SE\nb_age   0.008293 0.001965 1.605e-05      0.0001175\nb_badh  1.554980 0.181697 1.484e-03      0.0129844\nb_intx -0.010596 0.004184 3.416e-05      0.0003086\nint     0.354297 0.076815 6.272e-04      0.0046752\n\n2. Quantiles for each variable:\n\n            2.5%       25%       50%       75%     97.5%\nb_age   0.004454  0.006946  0.008321  0.009599  0.012136\nb_badh  1.187085  1.435767  1.557435  1.679406  1.903495\nb_intx -0.018766 -0.013363 -0.010664 -0.007846 -0.002256\nint     0.203306  0.303189  0.354098  0.407729  0.502542\n\n\nThe intercept is not necessarily interpretable here because it corresponds to the number of doctor visits for a healthy 0-year-old. While the number of visits for a newborn baby sounds like interesting information, the youngest person in the data set is 20 years old. In such cases we should avoid making such projections and say that the intercept is an artifact of the model.\n\nFor healthy individuals, it appears that age is associated with an increase in the Expected number of doctor visits.\nBad health is associated with an increase in expected number of visits.\nThe interaction coefficient is interpreted as an adjustment to the age coefficient for people in bad health. Hence, for people with bad health, age is essentially unassociated with number of visits.\n\n\n50.3.1 Predictive distributions\nLet’s say we have two people aged 35, one in good health and the other in poor health. Q. What is the posterior probability that the individual with poor health will have more doctor visits?\nThis goes beyond the posterior probabilities we have calculated comparing expected responses in previous lessons. Here we will create Monte Carlo samples for the responses themselves. This is done by taking the Monte Carlo samples of the model parameters, and for each of those, drawing a sample from the likelihood.\nLet’s walk through this.\nFirst, we need the x values for each individual. We’ll say the healthy one is Person 1 and the unhealthy one is Person 2. Their x values are:\n\n\nCode\n1x1 = c(0, 35, 0)\n2x2 = c(1, 35, 35)\n\n\n\n1\n\ngood health person’s data (bad_health_indicator=0,age=35,age*indicator=0)\n\n2\n\nbad health person’s (bad_health_indicator=1,age=35,age*indicator=35)\n\n\n\n\nThe posterior samples of the model parameters are stored in mod_csim:\n\n\nCode\nhead(mod_csim)\n\n\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1 \nEnd = 7 \nThinning interval = 1 \n          b_age   b_badh       b_intx       int\n[1,] 0.01166850 1.671028 -0.013322077 0.2462753\n[2,] 0.01163804 1.669535 -0.013072131 0.2102952\n[3,] 0.01135825 1.642998 -0.012974285 0.2193505\n[4,] 0.01051171 1.622337 -0.010933384 0.2486904\n[5,] 0.01040266 1.526558 -0.008899249 0.2582633\n[6,] 0.01036078 1.445239 -0.008552249 0.2676151\n[7,] 0.01038651 1.443713 -0.007332383 0.2707102\n\n\nFirst, we’ll compute the linear part of the predictor:\n\n\nCode\nloglam1 = mod_csim[,\"int\"] + mod_csim[,c(2,1,3)] %*% x1\nloglam2 = mod_csim[,\"int\"] + mod_csim[,c(2,1,3)] %*% x2\n\n\nNext we’ll apply the inverse link:\n\n\nCode\nlam1 = exp(loglam1)\nlam2 = exp(loglam2)\n\n\nThe final step is to use these samples for the \\lambda parameter for each individual and simulate actual number of doctor visits using the likelihood:\n\n\nCode\n(n_sim = length(lam1))\n\n\n[1] 15000\n\n\nwe have distribution of 15000 samples of \\lambda for each person.\n\n\nCode\nplot(table(factor(y1, levels=0:18))/n_sim, pch=2, ylab=\"posterior prob.\", xlab=\"visits\")\npoints(table(y2+0.1)/n_sim, col=\"red\")\n\n\n\n\n\n\n\n\nFigure 50.6\n\n\n\n\n\n\n\nCode\ny1 = rpois(n=n_sim, lambda=lam1)\ny2 = rpois(n=n_sim, lambda=lam2)\n\nplot(table(factor(y1, levels=0:18))/n_sim, pch=2, ylab=\"posterior prob.\", xlab=\"visits\")\npoints(table(y2+0.1)/n_sim, col=\"red\")\n\n\n\n\n\n\n\n\n\nFinally, we can answer the original question: What is the probability that the person with poor health will have more doctor visits than the person with good health?\n\n\nCode\nmean(y2 &gt; y1)\n\n\n[1] 0.9202667\n\n\nBecause we used our posterior samples for the model parameters in our simulation (the loglam1 and loglam2 step above), this posterior predictive distribution on the number of visits for these two new individuals naturally account for our uncertainty in the model estimates. This is a more honest/realistic distribution than we would get if we had fixed the model parameters at their MLE or posterior means and simulated data for the new individuals.",
    "crumbs": [
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>M4L10 - Poisson regression</span>"
    ]
  },
  {
    "objectID": "C2-L10.html#sec-prior-sensitivity-analysis",
    "href": "C2-L10.html#sec-prior-sensitivity-analysis",
    "title": "50  M4L10 - Poisson regression",
    "section": "50.4 Prior sensitivity analysis",
    "text": "50.4 Prior sensitivity analysis\n  When communicating results from any analysis, a responsible statistician will report and justify modeling decisions, especially assumptions. In a Bayesian analysis, there is an additional assumption that is open to scrutiny: the choices of prior distributions. In the models considered so far in this course, there are an infinite number of prior distributions we could have chosen from. When communicating results from any analysis, a responsible statistician will report and justify modeling decisions, especially assumptions. In a Bayesian analysis, there is another assumption that is open to scrutiny: the choices of prior distributions. In the models considered so far in this course, there are an infinite number of prior distributions we could have chosen from.Q. How do you justify the model you choose?\n If they truly represent your beliefs about the parameters before analysis and the model is appropriate, then the posterior distribution truly represents your updated beliefs. If you don’t have any strong beliefs beforehand, there are often default, reference, or non-informative prior options, and you will have to select one. However, a collaborator or a boss (indeed, somebody somewhere) may not agree with your choice of prior. One way to increase the credibility of your results is to repeat the analysis under a variety of priors, and report how the results differ as a result. This process is called prior sensitivity analysis. Q. How do you justify the priors you choose?\nAt a minimum you should always report your choice of model and prior. If you include a sensitivity analysis, select one or more alternative priors and describe how the results of the analysis change. If they are sensitive to the choice of prior, you will likely have to explain both sets of results, or at least explain why you favor one prior over another. If the results are not sensitive to the choice of prior, this is evidence that the data are strongly driving the results. It suggests that different investigators coming from different backgrounds should come to the same conclusions.\nIf the purpose of your analysis is to establish a hypothesis, it is often prudent to include a “skeptical” prior which does not favor the hypothesis. Then, if the posterior distribution still favors the hypothesis despite the unfavorable prior, you will be able to say that the data substantially favor the hypothesis. This is the approach we will take in the following example, continued from the previous lesson.\n\n50.4.1 Poisson regression example\n Let’s return to the example of number of doctor visits. We concluded from our previous analysis of these data that both bad health and increased age are associated with more visits. Suppose the burden of proof that bad health is actually associated with more visits rests with us, and we need to convince a skeptic.doctor visits\nFirst, let’s re-run the original analysis and remind ourselves of the posterior distribution for the badh (bad health) indicator.\n\n\nCode\nlibrary(\"COUNT\")\nlibrary(\"rjags\")\n\ndata(\"badhealth\")\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/1e4)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n    b_intx ~ dnorm(0.0, 1.0/1e4)\n} \"\n\nset.seed(102)\n\ndata_jags = as.list(badhealth)\n\nparams = c(\"int\", \"b_badh\", \"b_age\", \"b_intx\")\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 4\n   Total graph size: 3665\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,\n                        variable.names=params,\n                        n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n\n\n\nCode\nplot(density(mod_csim[,\"b_badh\"]))\n\n\n\n\n\n\n\n\nFigure 50.7\n\n\n\n\n\nEssentially all of the posterior probability mass is above 0, suggesting that this coefficient is positive (and consequently that bad health is associated with more visits). We obtained this result using a relatively noninformative prior. What if we use a prior that strongly favors values near 0? Let’s repeat the analysis with a normal prior on the badh coefficient that has mean 0 and standard deviation 0.2, so that the prior probability that the coefficient is less than 0.6 is &gt;0.998 . We’ll also use a small variance on the prior for the interaction term involving badh (standard deviation 0.01 because this coefficient is on a much smaller scale).\n\n\nCode\nmod2_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/0.2^2)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n    b_intx ~ dnorm(0.0, 1.0/0.01^2)\n} \"\n\nmod2 = jags.model(textConnection(mod2_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 4\n   Total graph size: 3672\n\nInitializing model\n\n\nCode\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params,\n                        n.iter=5e3)\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim))\n\n\nHow did the posterior distribution for the coefficient of badh change?\n\n\nCode\ncurve(dnorm(x, mean=0.0, sd=sqrt(1e4)), from=-3.0, to=3.0, ylim=c(0.0, 3.0), lty=2,\n      main=\"b_badh\", ylab=\"density\", xlab=\"b_badh\")\ncurve(dnorm(x, mean=0.0, sd=0.2), from=-3.0, to=3.0, col=\"red\", lty=2, add=TRUE)\nlines(density(mod_csim[,\"b_badh\"]))\nlines(density(mod2_csim[,\"b_badh\"]), col=\"red\")\nlegend(\"topleft\", legend=c(\"noninformative prior\", \"posterior\", \"skeptical prior\", \"posterior\"),\n       lty=c(2,1,2,1), col=rep(c(\"black\", \"red\"), each=2), bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 50.8\n\n\n\n\n\nUnder the skeptical prior, our posterior distribution for b_badh has significantly dropped to between about 0.6 and 1.1. Although the strong prior influenced our inference on the magnitude of the bad health effect on visits, it did not change the fact that the coefficient is significantly above 0. In other words: even under the skeptical prior, bad health is associated with more visits, with posterior probability near 1.\nWe should also check the effect of our skeptical prior on the interaction term involving both age and health.\n\n\nCode\ncurve(dnorm(x, mean=0.0, sd=sqrt(1e4)), from=-0.05, to=0.05, ylim=c(0.0, 140.0), lty=2,\n      main=\"b_intx\", ylab=\"density\", xlab=\"b_intx\")\ncurve(dnorm(x, mean=0.0, sd=0.01), from=-0.05, to=0.05, col=\"red\", lty=2, add=TRUE)\nlines(density(mod_csim[,\"b_intx\"]))\nlines(density(mod2_csim[,\"b_intx\"]), col=\"red\")\nlegend(\"topleft\", legend=c(\"noninformative prior\", \"posterior\", \"skeptical prior\", \"posterior\"),\n       lty=c(2,1,2,1), col=rep(c(\"black\", \"red\"), each=2), bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 50.9\n\n\n\n\n\n\n\nCode\nmean(mod2_csim[,\"b_intx\"] &gt; 0) # posterior probability that b_intx is positive\n\n\n[1] 0.9510667\n\n\nThe result here is interesting. Our estimate for the interaction coefficient has gone from negative under the non-informative prior to positive under the skeptical prior, so the result is sensitive. In this case, because the skeptical prior shrinks away much of the bad health main effect, it is likely that this interaction effect attempts to restore some of the positive effect of bad health on visits. Thus, despite some observed prior sensitivity, our conclusion that bad health positively associates with more visits remains unchanged.",
    "crumbs": [
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>M4L10 - Poisson regression</span>"
    ]
  },
  {
    "objectID": "C2-L10.html#overdispersed-model",
    "href": "C2-L10.html#overdispersed-model",
    "title": "50  M4L10 - Poisson regression",
    "section": "50.5 Overdispersed model",
    "text": "50.5 Overdispersed model\nRecall that the Negative Binomial can be used to model overdispersed count data.\nstan has three parameterizations for the Negative Binomial.\nThe first looks like similar to a binomial parameterization:\n\n\\text{NegBinomial}(y~|~\\alpha,\\beta)  = \\binom{y +\n\\alpha - 1}{\\alpha - 1} \\, \\left( \\frac{\\beta}{\\beta+1}\n\\right)^{\\!\\alpha} \\, \\left( \\frac{1}{\\beta + 1} \\right)^{\\!y} \\!.\n\n\n\\mathbb{E}[y] = \\frac{\\alpha}{\\beta} \\ \\ \\text{ and } \\ \\ \\text{Var}[Y] = \\frac{\\alpha}{\\beta^2} (\\beta + 1).\n\nwe can sample from this using the following statement\nn ~ neg_binomial(alpha, beta)\nBut this parameterization if not a match to the Poisson model, so we move on\nThe second parametrization \\mu \\in \\mathbb{R}^+ and \\phi \\in \\mathbb{R}^+:\n\n\\mathrm{NegBinomial2}(n \\mid \\mu, \\phi)  = \\binom{n + \\phi - 1}{n} \\,\n\\left( \\frac{\\mu}{\\mu+\\phi} \\right)^{\\!n} \\, \\left(\n\\frac{\\phi}{\\mu+\\phi} \\right)^{\\!\\phi}\n\n\n\\mathbb{E}[n] = \\mu \\ \\ \\text{ and } \\ \\ \\ \\mathbb{V}\\text{ar}[n] = \\mu + \\frac{\\mu^2}{\\phi}\n\nwe can sample from this using the following statement\nn ~ neg_binomial_2(mu, phi)\nAnd there is a third parametrization\n\nNegBinomial2Log(y\\mid\\mu,\\phi) = NegBinomial2(y\\mid exp(\\eta),\\phi).\n\nwe can sample from this using the following statement:\ny \\~ **neg_binomial_2\\_log**(y\\|mu, phi)`\njags has just one parameterization:\n\nf(y \\mid r, p) = \\frac{\\Gamma(y+r)}{\\Gamma(r)\\Gamma(y+1)}p^r(1-p)^y\n\nWe think of the Negative Binomial Distribution as the probability of completing y successful trials allowing for r failures in a sequence of (y+r) Bernoulli trials where success is defined as drawing (with replacement) a white ball from an urn of white and black balls with a probability p of success.\n\n\\mathbb{E}[Y] = \\mu = { r(1-p) \\over p } \\qquad \\text{ and } \\qquad \\mathbb{V}\\text{ar}[Y] = \\mu + \\frac{\\mu^2}{r}\n\n\n50.5.1 Transformations:\nSince we want to have a model corresponding to a poisson regression we will transform the model as follows:\nIf we set p = {\\text{r} \\over {r} + \\lambda } then the mean becomes : \\lambda\nand if we also set r= {\\lambda^2 \\over \\omega} then the variance becomes a sum of \\lambda + \\omega where \\omega is our over dispersion term.\n\n\\omega = \\lambda^2 / r\n\n\n\\begin{aligned}\n\\mathbb{E}[Y] &= { r(1-p) \\over p }\n\\\\ &= rp^{-1} -r\n\\\\ & \\stackrel {sub\\ p} =  {\\cancel{r}(\\bcancel{r}+\\lambda) \\over \\cancel{r}} - \\bcancel{r}\n\\\\ &= \\lambda \\mathbb{V}\\text{ar}[Y]\n\\\\ &= { (1-p) r \\over p^2 }\n\\\\ & \\stackrel {sub \\ \\lambda } = {1 \\over p} \\lambda\n\\\\ & \\stackrel {sub p} = \\lambda { (r+ \\lambda) \\over r}\n\\\\ &=  {\\lambda r +  \\lambda^2 \\over r }\n\\\\ &= 1 \\lambda + {\\lambda^2 \\over r}\n\\\\ &\\stackrel { sub \\ \\omega}= \\lambda + \\omega\n\\end{aligned}\n\nWhere we interpret \\lambda as the mean and \\omega as the overdispersion \n\n\nCode\nlibrary(\"rjags\")\nlibrary(\"COUNT\")\ndata(\"badhealth\")\n\n\n\n\nCode\nmod3_string = \"\nmodel {\n    for (i in 1:length(numvisit)) { \n1        mu[i]       = b0 + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n2        lambda[i]   = exp(mu[i])\n3        p[i]        = r / (r + lambda[i])\n4        numvisit[i] ~ dnegbin(p[i], r)\n5        resid[i]       = numvisit[i] - p[i]\n    }\n    ## Priors\n6    b0        ~ dnorm(0.0, 1.0/1e6)\n7    b_badh    ~ dnorm(0.0, 1.0/0.2^2)\n8    b_age     ~ dnorm(0.0, 1.0/1e4)\n9    b_intx    ~ dnorm(0.0, 1.0/0.01^2)\n10    r ~ dunif(0,50)\n\n    ## extra deterministic parameters\n    omega      &lt;-  pow(mean(lambda),2)/2\n11    #theta      &lt;- pow(1/mean(p),2)\n12    #scale      &lt;- mean((1-p)/p)\n}\"\ndata3_jags = as.list(badhealth)\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, n.chains=3)\n13update(mod3, 1e3)\nparams3 = c(\"b_intx\", \"b_badh\", \"b_age\", 'over_disp', 'b0','omega','r')\n14mod3_sim = coda.samples(model=mod3,  variable.names=params3, n.iter=5e3)\n15mod3_csim = as.mcmc(do.call(rbind, mod3_sim))\n16(dic3 = dic.samples(mod3, n.iter=1e3))\n\n\n\n1\n\nthe linear part\n\n2\n\nlambda corresponds to the parameter used in the Poisson regression\n\n3\n\np is the success parameter\n\n4\n\nwe draw from the negative binomial distribution\n\n5\n\nsampling using the parametrization of the Negative Binomial distribution.\n\n6\n\nnormal prior for intercept b0\n\n7\n\nnormal prior for b_badh\n\n8\n\nnormal prior for b_age\n\n9\n\nnormal prior for b_intx\n\n10\n\nuniform prior for over_disp - at the upper limit of 50 NegBin converges to Poisson see (Jackman 2009, 280)\n\n11\n\ntheta param\n\n12\n\nscale param\n\n13\n\nburn in\n\n14\n\nsample\n\n15\n\nstack samples from the chains\n\n16\n\nestimate the DIC\n\n\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 5\n   Total graph size: 4204\n\nInitializing model\n\nMean deviance:  4478 \npenalty 4.072 \nPenalized deviance: 4482 \n\n\n\n\nCode\ngelman.diag(mod3_sim )\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nb0           1.01       1.03\nb_age        1.01       1.03\nb_badh       1.01       1.02\nb_intx       1.00       1.01\nomega        1.00       1.00\nr            1.00       1.00\n\nMultivariate psrf\n\n1.01\n\n\n\n\nCode\nraftery.diag(mod3_sim)\n\n\n[[1]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                              \n        Burn-in  Total Lower bound  Dependence\n        (M)      (N)   (Nmin)       factor (I)\n b0     48       48032 3746         12.800    \n b_age  27       29031 3746          7.750    \n b_badh 9        9308  3746          2.480    \n b_intx 8        8602  3746          2.300    \n omega  2        3741  3746          0.999    \n r      5        6185  3746          1.650    \n\n\n[[2]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                              \n        Burn-in  Total Lower bound  Dependence\n        (M)      (N)   (Nmin)       factor (I)\n b0     40       38235 3746         10.20     \n b_age  21       22956 3746          6.13     \n b_badh 16       14964 3746          3.99     \n b_intx 7        7675  3746          2.05     \n omega  3        4062  3746          1.08     \n r      5        6078  3746          1.62     \n\n\n[[3]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                              \n        Burn-in  Total Lower bound  Dependence\n        (M)      (N)   (Nmin)       factor (I)\n b0     33       36540 3746         9.75      \n b_age  28       27970 3746         7.47      \n b_badh 9        9497  3746         2.54      \n b_intx 10       11234 3746         3.00      \n omega  2        3803  3746         1.02      \n r      4        4955  3746         1.32      \n\n\n\n\nCode\nautocorr.diag(mod3_sim)\n\n\n              b0     b_age      b_badh      b_intx        omega           r\nLag 0  1.0000000 1.0000000  1.00000000  1.00000000  1.000000000 1.000000000\nLag 1  0.9353475 0.9388936  0.77623048  0.78475391  0.008166432 0.253348873\nLag 5  0.7525400 0.7549795  0.34558544  0.35362456 -0.003371287 0.003942014\nLag 10 0.5772155 0.5768298  0.12879323  0.13563268  0.010477006 0.001784702\nLag 50 0.0500231 0.0559672 -0.01879399 -0.01592171 -0.002914743 0.020807598\n\n\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n        b0      b_age     b_badh     b_intx      omega          r \n  416.6925   415.6010  1564.8925  1556.5188 16290.4982  8809.7537 \n\n\n\n\nCode\nsummary(mod3_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean       SD  Naive SE Time-series SE\nb0     0.477486 0.127084 1.038e-03      0.0062531\nb_age  0.005385 0.003300 2.695e-05      0.0001621\nb_badh 0.380941 0.166621 1.360e-03      0.0042089\nb_intx 0.014844 0.004324 3.531e-05      0.0001098\nomega  2.777912 0.217878 1.779e-03      0.0017088\nr      0.989728 0.069628 5.685e-04      0.0007429\n\n2. Quantiles for each variable:\n\n            2.5%      25%      50%      75%   97.5%\nb0      0.229533 0.390556 0.475626 0.564281 0.72471\nb_age  -0.001077 0.003151 0.005424 0.007588 0.01187\nb_badh  0.054162 0.268074 0.383434 0.495012 0.69961\nb_intx  0.006663 0.011850 0.014782 0.017772 0.02347\nomega   2.379396 2.627271 2.767154 2.918075 3.23263\nr       0.861347 0.942159 0.987243 1.034223 1.13210\n\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod3_sim, auto.layout = FALSE)\n\n\n\n\n\n\n\n\n\n\nFigure 50.10\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.11\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.12\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.13\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.14\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.15\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.16\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.17\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.18\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.19\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.20\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.21\n\n\n\n\n\n\n\nCode\nautocorr.plot(mod3_csim,auto.layout = FALSE)\n\n\n\n\n\n\n\n\n\n\nFigure 50.22\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.23\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.24\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.25\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.26\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.27\n\n\n\n\n\n\n\n\nCode\nX = as.matrix(badhealth[,-1])\nX = cbind(X, with(badhealth, badh*age))\n(pmed_coef = apply(mod3_csim, 2, median))\n\n\n         b0       b_age      b_badh      b_intx       omega           r \n0.475626057 0.005424455 0.383434113 0.014782455 2.767154337 0.987242999 \n\n\nCode\n(r = pmed_coef[\"r\"] )\n\n\n       r \n0.987243 \n\n\nCode\nmu_hat = pmed_coef[\"b0\"] + X %*% pmed_coef[c(\"b_badh\", \"b_age\", \"b_intx\")]\nlambda_hat = exp(mu_hat)\np_hat = r / (r + lambda_hat)\nhist(lambda_hat)\n\n\n\n\n\n\n\n\n\nCode\nhist(p_hat)\n\n\n\n\n\n\n\n\n\nresiduals\n\n\nCode\nresid = badhealth$numvisit - p_hat\nhead(resid)\n\n\n         [,1]\n[1,] 29.69063\n[2,] 19.68598\n[3,] 15.67418\n[4,] 19.68947\n[5,] 14.66094\n[6,] 14.65483\n\n\n\n\nCode\nplot(resid) # the data were ordered\n\n\n\n\n\n\n\n\nFigure 50.28: Plot of residuals\n\n\n\n\n\n\nCode\nhead(mod3_csim)\n\n\n\n\nTable 50.1: First few rows of mod3_csim\n\n\n\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1 \nEnd = 7 \nThinning interval = 1 \n            b0       b_age     b_badh     b_intx    omega         r\n[1,] 0.4750218 0.005754781 0.11911632 0.01899195 2.731221 0.9416937\n[2,] 0.4361648 0.005685571 0.24015770 0.01766072 2.586115 1.0204129\n[3,] 0.5495783 0.006180571 0.16148238 0.01898878 3.345023 0.9823598\n[4,] 0.5348564 0.003527329 0.06008378 0.02212811 2.693255 1.0079310\n[5,] 0.5629573 0.001806209 0.04938176 0.02633532 2.740525 1.0413283\n[6,] 0.5571392 0.003235151 0.10177277 0.02502712 3.018429 1.0583014\n[7,] 0.5398431 0.003661378 0.11241380 0.02423512 2.972390 1.0355894\n\n\n\n\n\n\nCode\nplot(p_hat, badhealth$numvisit)\nabline(0.0, 1.0)\n\n\n\n\n\n\n\n\nFigure 50.29: Plot of p_hat vs numvisit\n\n\n\n\n\n\n\nCode\nplot(p_hat[which(badhealth$badh==0)], resid[which(badhealth$badh==0)], xlim=range(p_hat), ylab=\"residuals\", xlab=expression(hat(p)), ylim=range(resid))\npoints(p_hat[which(badhealth$badh==1)], resid[which(badhealth$badh==1)], col=\"red\")\n\n\n\n\n\n\n\n\nFigure 50.30: Plot of p_hat vs residuals, colored by health status\n\n\n\n\n\n\n\nCode\nvar(resid[which(badhealth$badh==0)])\n\n\n[1] 7.061\n\n\nCode\nvar(resid[which(badhealth$badh==1)])\n\n\n[1] 41.21256\n\n\n\n\n\n\n\n\nJackman, Simon. 2009. “Bayesian Analysis for the Social Sciences.” Wiley Series in Probability and Statistics, October. https://doi.org/10.1002/9780470686621.",
    "crumbs": [
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>M4L10 - Poisson regression</span>"
    ]
  },
  {
    "objectID": "C2-L10-Ex1.html",
    "href": "C2-L10-Ex1.html",
    "title": "51  Homework on Poisson regression",
    "section": "",
    "text": "Exercise 51.1  With Poisson regression, we use the log link function so that \\log( \\mathbb{E}[y]) = \\log(\\lambda) = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_kPoisson Regression\nSuppose we have two covariate values x1,i=0.8 and x2,i=1.2 and we know the values of the coefficients: \\beta_0 = 1.5, \\beta_1 = -0.3 \\text{and} \\beta_2 = 1.0\nCalculate \\mathbb{E}[y] in this case. Round your answer to one decimal place\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nimport numpy as np\n\ndef E(x1,x2,b0,b1,b2):\n  return np.exp(b0+b1*x1+b2*x2)\n\nE(0.8,1.2,1.5,-0.3,1.0)\n\n\n11.704811539980856\n\n\nThis is just \\lambda_i=exp(\\beta_0+\\beta_1,x_{1,i}+\\beta_2x_{2,i})\n\n\n\n\nExercise 51.2  Re-run the JAGS model for the Poisson regression on doctor visits from the lesson. Calculate the DIC for the original model. Now remove the interaction term from the model and fit the simpler additive model. Again compute the DIC. If we use predictive performance as a criterion for selecting models, what do we conclude?Poisson Regression\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/1e4)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n    b_intx ~ dnorm(0.0, 1.0/1e4)\n} \"\n\nset.seed(102)\n\ndata_jags = as.list(badhealth)\n\nparams = c(\"int\", \"b_badh\", \"b_age\", \"b_intx\")\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 4\n   Total graph size: 3665\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,\n                        variable.names=params,\n                        n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nb_age        1.02       1.03\nb_badh       1.01       1.01\nb_intx       1.01       1.01\nint          1.01       1.03\n\nMultivariate psrf\n\n1.01\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n           b_age    b_badh    b_intx       int\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.9594745 0.9660418 0.9687087 0.9541685\nLag 5  0.8430960 0.8738199 0.8799248 0.8355823\nLag 10 0.7228425 0.7764740 0.7871004 0.7147377\nLag 50 0.1838640 0.3088212 0.3207056 0.1798588\n\n\nCode\nautocorr.plot(mod_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod_sim)\n\n\n   b_age   b_badh   b_intx      int \n255.5850 183.5962 169.8929 245.8203 \n\n\n\n\nCode\nmod1_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] \n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/1e4)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n} \"\n\nset.seed(102)\n\ndata1_jags = as.list(badhealth)\n\nparams1 = c(\"int\", \"b_badh\", \"b_age\")\n\nmod1 = jags.model(textConnection(mod1_string), data=data1_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 3\n   Total graph size: 3587\n\nInitializing model\n\n\nCode\nupdate(mod1, 1e3)\n\nmod1_sim = coda.samples(model=mod1, variable.names=params1,  n.iter=5e3)\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim))\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod1_sim)\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod1_sim)\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nb_age           1       1.01\nb_badh          1       1.00\nint             1       1.01\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod1_sim)\n\n\n            b_age       b_badh        int\nLag 0  1.00000000  1.000000000 1.00000000\nLag 1  0.94207406  0.472953685 0.93785274\nLag 5  0.76978088  0.060250383 0.76532447\nLag 10 0.59873458  0.031205380 0.59184498\nLag 50 0.07297796 -0.006773085 0.07817662\n\n\nCode\nautocorr.plot(mod1_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod1_sim)\n\n\n    b_age    b_badh       int \n 375.2170 4419.8134  384.3416 \n\n\nWe are interested how these variables relate to the probability of successfully identifying the source of changes in sound. Of these four variables, which appears to have the weakest association with the probability of success?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n## compute DIC\n(dic = dic.samples(mod, n.iter=1e3))\n\n\nMean deviance:  5630 \npenalty 4.686 \nPenalized deviance: 5635 \n\n\nCode\n(dic1 = dic.samples(mod1, n.iter=1e3))\n\n\nMean deviance:  5636 \npenalty 3.034 \nPenalized deviance: 5639 \n\n\n\nThe original model with interaction has a lower value of DIC than the simpler model, so we retain the simpler model.\nThe original model with interaction has a lower value of DIC than the simpler model, so we retain the original model.\nThe original model with interaction has a higher value of DIC than the simpler model, so we retain the original model.\nThe original model with interaction has a higher value of DIC than the simpler model, so we retain the simpler model.\n\nLower values of DIC indicate improved predictive performance.\n\n\n\n\nExercise 51.3  In the original model, the posterior mean estimate of the coefficient for badh (bad health) was 1.56. What is the correct interpretation of this coefficient if this were the true value?Poisson Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nBeing in bad health is associated with a 1.56 increase in the expected number of doctor visits.\nBeing in bad health is associated with a 1.56 decrease in the log of the expected number of doctor visits.\nBeing in bad health is associated with a 1.56 increase in the log of the expected number of doctor visits.\nBeing in bad health is associated with a 1.56 decrease in the log of the number of doctor visits.\n\nSince badh was an indicator (dummy) variable, the interpretation of the coefficient is simply the effect of this variable being “on.”\n\n\n\n\nExercise 51.4  In the previous course, we briefly discussed Poisson processes. The mean of a Poisson distribution can be thought of as a rate at which the events we count are occurring. Hence, it is natural to imagine that if we are observing for twice as long, we would expect to count about twice as many events (assuming the rate is steady). If t is the amount of time that we observe, and \\lambda is the rate of events per unit of time, then the expected number of events is t\\lambda and the distribution of the number of events in this time interval is Poisson(t\\lambda)Poisson Regression\nSuppose that a retail store receives an average of 15 customer calls per hour, and that the calls approximately follow a Poisson process. If we monitor calls for two hours, what is the probability that there will be fewer than 22 calls in this time period?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nppois(q=21,lambda = 2*15)\n\n\n[1] 0.0544434\n\n\nLet X be the number of calls in this interval. If we assume a Poisson process, then X \\sim Pois(2 \\cdot 15). The probability that X \\le 21 can be calculated in R using the ppois() function.\n\n\n\n\nExercise 51.5  On average, this retailer receives 0.01 calls per customer per day. They notice, however, that one particular group of customers tends to call more frequently.Raftery and Lewis diagnostic\nTo test this, they select 90 days to monitor 224 customers, 24 of which belong to this group (call it group 2). Not all customers had accounts for the full 90 day period, but we do know how many of the 90 days each was active. We also have the age of the customer, the group to which the customer belongs, and how many calls the customer placed during the period they were active. The data are attached as callers.csv.\nTry plotting some of the variables to understand some of the relationships. If one of the variables is categorical, a box plot is a good choice.\nWhich of the following plots would be most useful to the retailer to informally explore their hypothesis that customers from group 2 call at a higher rate than the other customers?\n\n\nCode\ncalls_dat = read.csv(file=\"data/callers.csv\", header=TRUE)\nhead(calls_dat)\n\n\n  calls days_active isgroup2 age\n1     2          32        0  27\n2     4          81        0  32\n3     0          41        0  22\n4     1          36        0  28\n5     0          55        0  31\n6     0          25        0  33\n\n\nCode\nboxplot(x=calls_dat$calls,y=calls_dat$isgroup2)\n\n\n\n\n\n\n\n\n\nCode\nboxplot(x=calls_dat$calls/calls_dat$days_active ,y=calls_dat$age)\n\n\n\n\n\n\n\n\n\nCode\nboxplot(x=calls_dat$calls/calls_dat$days_active ,y=calls_dat$isgroup2)\n\nboxplot(x=calls_dat$age,y=calls_dat$isgroup2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\ncalls vs. isgroup2\ncalls/days_active vs. age\ncalls/days_active vs. isgroup2\nage vs. isgroup2\n\nThis is the best choice.\nThe first variable is the observed call rate for the customer, which is better than using the total number of calls because that does not account for possible differences in how long the account was active.\nThe age vs. isgroup2 plot is also very important. If the customers in group 2 tend to be different in age than the other customers, then we will not be able to tell whether group membership or age (or another variable related to both) is driving the difference in call rates.\n\n\n\n\nExercise 51.6  Since we know how many days each customer was active and the data are counts, it seems reasonable to use a Poisson process model. We will assume that the customers’ calls are independent, and that the calling rate per day active for person i, λ_i is unique to each customer and does not change throughout the monitoring period.Poisson Regression\nIt makes sense to model λ_i using our two covariates, age and isgroup2. How would the likelihood specification for this model look in JAGS?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n[x]\n\n    for (i in 1:length(calls)) {\n        calls[i] ~ dpois( days_active[i] * lam[i] )\n        log(lam[i]) = b0 + b[1]*age[i] + b[2]*isgroup2[i]\n    }\n\n[ ]\n\n    for (i in 1:length(calls)) {\n        calls[i] ~ dpois( days_active[i] * lam[i] )\n        log(lam[i]) = b0 + b[1]*age[i] + b[2]*isgroup2[i]\n    }\n\n[ ]\n\n    for (i in 1:length(calls)) {\n        calls[i] ~ dpois( days_active[i] * lam[i] )\n        lam[i] = b0 + b[1]*age[i] + b[2]*isgroup2[i]\n    }\n\n[ ]\n\n    for (i in 1:length(calls)) {\n        calls[i] ~ dpois( lam[i] )\n        lam[i] = b0 + b[1]*age[i] + b[2]*isgroup2[i]\n    }\nThis is an fascinating modification of the model we saw in the class.\nThe Poisson process part comes in when we account for days_active, and the regression part comes in our model for \\lambda_i.\n\n\n\n\nExercise 51.7  Complete fit the model in JAGS using N(0,102) priors for the intercept and both coefficients. Be sure to check for MCMC convergence and look at the residuals (don’t forget to multiply lam_hat by days_active to obtain the model’s predicted mean number of calls).Poisson Regression\nWhat is the posterior probability that \\beta_2, the coefficient for the indicator \\text{isgroup2} &gt; 0?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ncalls_mod_string = \" model {\n    for (i in 1:length(calls)) {\n        calls[i] ~ dpois( days_active[i] * lam[i] )\n        log(lam[i]) = b0 + b[1]*age[i] + b[2]*isgroup2[i]\n    }\n\n  b0 ~ dnorm(0.0, 10.0^2)\n  for(j in 1:2){\n    b[j] ~ dnorm(0.0, 10.0^2)\n  }\n} \"\nset.seed(102)\ncalls_data_jags = as.list(calls_dat)\ncalls_params = c(\"b0\",'b')\ncalls_mod = jags.model(textConnection(calls_mod_string), data=calls_data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 224\n   Unobserved stochastic nodes: 3\n   Total graph size: 1218\n\nInitializing model\n\n\nCode\nupdate(calls_mod, 1e3)\ncalls_mod_sim = coda.samples(model=calls_mod, variable.names=calls_params,n.iter=5e3)\ncalls_mod_csim = as.mcmc(do.call(rbind, calls_mod_sim))\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(calls_mod_sim)\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(calls_mod_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]          1          1\nb[2]          1          1\nb0            1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(calls_mod_sim)\n\n\n              b[1]          b[2]          b0\nLag 0   1.00000000  1.000000e+00  1.00000000\nLag 1   0.72811897  2.456967e-01  0.72774532\nLag 5   0.25607973 -7.001852e-05  0.25475932\nLag 10  0.04443710 -5.000532e-03  0.04215230\nLag 50 -0.02057235 -1.065448e-02 -0.01783725\n\n\nCode\nautocorr.plot(calls_mod_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(calls_mod_sim)\n\n\n    b[1]     b[2]       b0 \n2119.399 9085.349 2084.881 \n\n\nCode\n## compute DIC\ndic = dic.samples(calls_mod, n.iter=1e3)\n\n\n\n\nCode\n#|llabel: q7s\n#calls_mod_csim\n#as.numeric(unlist(List))    \ndim(calls_mod_csim)\n\n\n[1] 15000     3\n\n\nCode\ncalls_csim=as.matrix(calls_mod_csim)\n\nlength(calls_csim[,c('b[2]')]&gt;0)/length(calls_csim[,'b[2]'])\n\n\n[1] 1\n\n\n\n\n\n\nExercise 51.8  What formal conclusions should be made about the retailer’s hypothesis?Poisson Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nprint(' E(Calls) ~ Pois(log(lam[i]) = b0 + b1*age[i] + b2*isgroup2[i])')\n\n\n[1] \" E(Calls) ~ Pois(log(lam[i]) = b0 + b1*age[i] + b2*isgroup2[i])\"\n\n\nCode\nsummary(calls_mod_csim)\n\n\n\nIterations = 1:15000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 15000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean       SD  Naive SE Time-series SE\nb[1] -0.1413 0.004361 3.561e-05      9.487e-05\nb[2]  0.3723 0.089581 7.314e-04      9.403e-04\nb0   -0.1248 0.096010 7.839e-04      2.089e-03\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%      75%    97.5%\nb[1] -0.1500 -0.1442 -0.1413 -0.13832 -0.13294\nb[2]  0.1955  0.3119  0.3717  0.43261  0.54807\nb0   -0.3104 -0.1901 -0.1255 -0.05966  0.06218\n\n\n\nThe data contain no evidence of association between call rates and group membership.\nWhile accounting for time active and age, customer membership in group 2 is associated with higher call rates than for customers not in group 2.\nWe are unable to conclude whether the calling rate discrepancy is due to group membership or age because members of group 2 are generally of different age than customers not in group 2.\nWhile accounting for time active and age, customer membership in group 2 is associated with lower call rates than for customers not in group 2.\n\nAge membership is not a concern here because a wide range of ages is represented in both groups. Otherwise, this would be a major issue.",
    "crumbs": [
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Homework on Poisson regression</span>"
    ]
  },
  {
    "objectID": "C2-L11.html",
    "href": "C2-L11.html",
    "title": "52  Hierarchical modeling",
    "section": "",
    "text": "52.1 Introduction to Hierarchical modeling",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#introduction-to-hierarchical-modeling",
    "href": "C2-L11.html#introduction-to-hierarchical-modeling",
    "title": "52  Hierarchical modeling",
    "section": "",
    "text": "Introduction to Hierarchical modeling",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#normal-hierarchical-model",
    "href": "C2-L11.html#normal-hierarchical-model",
    "title": "52  Hierarchical modeling",
    "section": "52.2 Normal hierarchical model",
    "text": "52.2 Normal hierarchical model\nHandout: Normal hierarchical model",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#applications-of-hierarchical-modeling",
    "href": "C2-L11.html#applications-of-hierarchical-modeling",
    "title": "52  Hierarchical modeling",
    "section": "52.3 Applications of hierarchical modeling",
    "text": "52.3 Applications of hierarchical modeling\nHandout: Common applications of Bayesian hierarchical models",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#prior-predictive-simulation",
    "href": "C2-L11.html#prior-predictive-simulation",
    "title": "52  Hierarchical modeling",
    "section": "52.4 Prior predictive simulation",
    "text": "52.4 Prior predictive simulation\n\n52.4.1 Data\nLet’s fit our hierarchical model for counts of chocolate chips. The data can be found in cookies.dat.\n\n\nCode\ndat = read.table(file=\"data/cookies.dat\", header=TRUE)\nhead(dat)\n\n\n  chips location\n1    12        1\n2    12        1\n3     6        1\n4    13        1\n5    12        1\n6    12        1\n\n\n\n\nCode\ntable(dat$location)\n\n\n\n 1  2  3  4  5 \n30 30 30 30 30 \n\n\nWe can also visualize the distribution of chips by location.\n\n\nCode\nhist(dat$chips)\n\n\n\n\n\n\n\n\n\n\n\nCode\nboxplot(chips ~ location, data=dat)\n\n\n\n\n\n\n\n\n\n\n\n52.4.2 Prior predictive checks\nBefore implementing the model, we need to select prior distributions for \\alpha and \\beta, the hyperparameters governing the gamma distribution for the \\lambda parameters. First, think about what the \\lambda’s represent. For location j, \\lambda_j is the expected number of chocolate chips per cookie. Hence, \\alpha and \\beta control the distribution of these means between locations. The mean of this gamma distribution will represent the overall mean of number of chips for all cookies. The variance of this gamma distribution controls the variability between locations. If this is high, the mean number of chips will vary widely from location to location. If it is small, the mean number of chips will be nearly the same from location to location.\nTo see the effects of different priors on the distribution of \\lambda’s, we can simulate. Suppose we try independent exponential priors for \\alpha and \\beta.\n\n\nCode\nset.seed(112)\nn_sim = 500\nalpha_pri = rexp(n_sim, rate=1.0/2.0)\nbeta_pri = rexp(n_sim, rate=5.0)\nmu_pri = alpha_pri/beta_pri\nsig_pri = sqrt(alpha_pri/beta_pri^2)\n\nsummary(mu_pri)\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n   0.0213    2.9829    9.8522   61.1271   29.9801 4858.7861 \n\n\n\n\nCode\nsummary(sig_pri)\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n   0.1834    3.3663    8.5488   41.8137   22.2219 2865.6461 \n\n\nAfter simulating from the priors for \\alpha and \\beta, we can use those samples to simulate further down the hierarchy:\n\n\nCode\nlam_pri = rgamma(n=n_sim, shape=alpha_pri, rate=beta_pri)\nsummary(lam_pri)\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n    0.000     1.171     7.668    83.062    28.621 11005.331 \n\n\nOr for a prior predictive reconstruction of the original data set:\n\n\nCode\n(lam_pri = rgamma(n=5, shape=alpha_pri[1:5], rate=beta_pri[1:5]))\n\n\n[1] 66.444084  9.946688  6.028319 15.922568 47.978587\n\n\n\n\nCode\n(y_pri = rpois(n=150, lambda=rep(lam_pri, each=30)))\n\n\n  [1] 63 58 64 63 70 62 61 48 71 73 70 77 66 60 72 77 69 62 66 71 49 80 66 75 74\n [26] 55 62 90 65 57 12  9  7 10 12 10 11  7 14 13  9  6  6 13  7 10 12  9  9 10\n [51]  7  8  6  9  7 10 13 13  8 12  6 10  3  6  7  4  6  7  5  5  4  3  6  2  8\n [76]  4  8  4  5  7  1  4  5  3  8  8  3  1  7  3 16 14 13 17 17 12 13 13 16 16\n[101] 15 14 11 10 13 17 16 19 16 17 15 16  7 17 21 16 12 15 14 13 52 44 51 46 39\n[126] 40 40 44 46 59 45 49 58 42 31 52 43 47 53 41 48 57 35 60 51 58 36 34 41 59\n\n\nBecause these priors have high variance and are somewhat noninformative, they produce unrealistic predictive distributions. Still, enough data would overwhelm the prior, resulting in useful posterior distributions. Alternatively, we could tweak and simulate from these prior distributions until they adequately represent our prior beliefs. Yet another approach would be to re-parameterize the gamma prior, which we’ll demonstrate as we fit the model.",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#jags-model",
    "href": "C2-L11.html#jags-model",
    "title": "52  Hierarchical modeling",
    "section": "52.5 JAGS Model",
    "text": "52.5 JAGS Model\n\n\nCode\nlibrary(\"rjags\")\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\n\n\nCode\nmod_string = \" model {\nfor (i in 1:length(chips)) {\n  chips[i] ~ dpois(lam[location[i]])\n}\n\nfor (j in 1:max(location)) {\n  lam[j] ~ dgamma(alpha, beta)\n}\n\nalpha = mu^2 / sig^2\nbeta = mu / sig^2\n\nmu ~ dgamma(2.0, 1.0/5.0)\nsig ~ dexp(1.0)\n\n} \"\n\nset.seed(113)\n\ndata_jags = as.list(dat)\n\nparams = c(\"lam\", \"mu\", \"sig\")\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 150\n   Unobserved stochastic nodes: 7\n   Total graph size: 315\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,\n                       variable.names=params,\n                       n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n\n\n\nCode\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nlam[1]          1          1\nlam[2]          1          1\nlam[3]          1          1\nlam[4]          1          1\nlam[5]          1          1\nmu              1          1\nsig             1          1\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n             lam[1]       lam[2]       lam[3]        lam[4]       lam[5]\nLag 0   1.000000000  1.000000000  1.000000000  1.0000000000  1.000000000\nLag 1   0.023102726  0.121228808  0.023030582  0.0073301419  0.068976208\nLag 5  -0.006962094  0.015652801  0.003340323 -0.0008886721 -0.017524919\nLag 10 -0.012926531  0.012968072 -0.001034433 -0.0041365120  0.003258073\nLag 50 -0.003595065 -0.002812131  0.002755635 -0.0004416327  0.011239581\n                  mu         sig\nLag 0   1.0000000000 1.000000000\nLag 1   0.3727235700 0.588331694\nLag 5   0.0076401113 0.103053539\nLag 10 -0.0008170542 0.009631030\nLag 50 -0.0023459791 0.008802601\n\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nautocorr.plot(mod_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod_sim)\n\n\n   lam[1]    lam[2]    lam[3]    lam[4]    lam[5]        mu       sig \n14175.213 10984.275 14445.876 15000.000 12438.401  6694.498  3635.713 \n\n\nCode\n## compute DIC\ndic = dic.samples(mod, n.iter=1e3)\n\n\n\n52.5.1 Model checking\nAfter assessing convergence, we can check the fit via residuals. With a hierarhcical model, there are now two levels of residuals: the observation level and the location mean level. To simplify, we’ll look at the residuals associated with the posterior means of the parameters.\nFirst, we have observation residuals, based on the estimates of location means.\n\n\nCode\n## observation level residuals\n(pm_params = colMeans(mod_csim))\n\n\n   lam[1]    lam[2]    lam[3]    lam[4]    lam[5]        mu       sig \n 9.279008  6.225160  9.519847  8.943737 11.759670  9.086336  2.083099 \n\n\n\n\nCode\nyhat = rep(pm_params[1:5], each=30)\nresid = dat$chips - yhat\nplot(resid)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(jitter(yhat), resid)\n\n\n\n\n\n\n\n\n\n\n\nCode\nvar(resid[yhat&lt;7])\n\n\n[1] 6.447126\n\n\n\n\nCode\nvar(resid[yhat&gt;11])\n\n\n[1] 13.72414\n\n\nAlso, we can look at how the location means differ from the overall mean \\mu.\n\n\nCode\n## location level residuals\nlam_resid = pm_params[1:5] - pm_params[\"mu\"]\nplot(lam_resid)\nabline(h=0, lty=2)\n\n\n\n\n\n\n\n\n\nWe don’t see any obvious violations of our model assumptions.\n\n\n52.5.2 Results\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean     SD Naive SE Time-series SE\nlam[1]  9.279 0.5348 0.004367       0.004495\nlam[2]  6.225 0.4631 0.003781       0.004433\nlam[3]  9.520 0.5448 0.004449       0.004535\nlam[4]  8.944 0.5264 0.004298       0.004298\nlam[5] 11.760 0.6206 0.005067       0.005565\nmu      9.086 0.9918 0.008098       0.012139\nsig     2.083 0.7187 0.005868       0.011963\n\n2. Quantiles for each variable:\n\n         2.5%    25%    50%    75%  97.5%\nlam[1]  8.248  8.918  9.265  9.637 10.351\nlam[2]  5.357  5.909  6.216  6.532  7.168\nlam[3]  8.492  9.143  9.512  9.882 10.616\nlam[4]  7.952  8.587  8.930  9.292 10.002\nlam[5] 10.582 11.333 11.744 12.161 13.020\nmu      7.154  8.465  9.059  9.669 11.132\nsig     1.091  1.585  1.952  2.423  3.885",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#posterior-predictive-simulation",
    "href": "C2-L11.html#posterior-predictive-simulation",
    "title": "52  Hierarchical modeling",
    "section": "52.6 Posterior predictive simulation",
    "text": "52.6 Posterior predictive simulation\nJust as we did with the prior distribution, we can use these posterior samples to get Monte Carlo estimates that interest us from the posterior predictive distribution.\nFor example, we can use draws from the posterior distribution of \\mu and \\sigma to simulate the posterior predictive distribution of the mean for a new location.\n\n\nCode\n(n_sim = nrow(mod_csim))\n\n\n[1] 15000\n\n\n\n\nCode\nlam_pred = rgamma(n=n_sim, shape=mod_csim[,\"mu\"]^2/mod_csim[,\"sig\"]^2, \n                  rate=mod_csim[,\"mu\"]/mod_csim[,\"sig\"]^2)\nhist(lam_pred)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmean(lam_pred &gt; 15)\n\n\n[1] 0.0168\n\n\nUsing these \\lambda draws, we can go to the observation level and simulate the number of chips per cookie, which takes into account the uncertainty in \\lambda:\n\n\nCode\ny_pred = rpois(n=n_sim, lambda=lam_pred)\nhist(y_pred)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmean(y_pred &gt; 15)\n\n\n[1] 0.0594\n\n\n\n\nCode\nhist(dat$chips)\n\n\n\n\n\n\n\n\n\nFinally, we could answer questions like: what is the posterior probability that the next cookie produced in Location 1 will have fewer than seven chips?\n\n\nCode\ny_pred1 = rpois(n=n_sim, lambda=mod_csim[,\"lam[1]\"])\nhist(y_pred1)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmean(y_pred1 &lt; 7)\n\n\n[1] 0.1915333",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#random-intercept-linear-model",
    "href": "C2-L11.html#random-intercept-linear-model",
    "title": "52  Hierarchical modeling",
    "section": "52.7 Random intercept linear model",
    "text": "52.7 Random intercept linear model\nWe can extend the linear model for the Leinhardt data on infant mortality by incorporating the region variable. We’ll do this with a hierarhcical model, where each region has its own intercept.\n\n\nCode\nlibrary(\"car\")\n\n\nLoading required package: carData\n\n\nCode\ndata(\"Leinhardt\")\n?Leinhardt\nstr(Leinhardt)\n\n\n'data.frame':   105 obs. of  4 variables:\n $ income: int  3426 3350 3346 4751 5029 3312 3403 5040 2009 2298 ...\n $ infant: num  26.7 23.7 17 16.8 13.5 10.1 12.9 20.4 17.8 25.7 ...\n $ region: Factor w/ 4 levels \"Africa\",\"Americas\",..: 3 4 4 2 4 4 4 4 4 4 ...\n $ oil   : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\nCode\npairs(Leinhardt)\n\n\n\n\n\n\n\n\n\n\n\nCode\nhead(Leinhardt)\n\n\n          income infant   region oil\nAustralia   3426   26.7     Asia  no\nAustria     3350   23.7   Europe  no\nBelgium     3346   17.0   Europe  no\nCanada      4751   16.8 Americas  no\nDenmark     5029   13.5   Europe  no\nFinland     3312   10.1   Europe  no\n\n\nPreviously, we worked with infant mortality and income on the logarithmic scale. Recall also that we had to remove some missing data.\n\n\nCode\ndat = na.omit(Leinhardt)\ndat$logincome = log(dat$income)\ndat$loginfant = log(dat$infant)\nstr(dat)\n\n\n'data.frame':   101 obs. of  6 variables:\n $ income   : int  3426 3350 3346 4751 5029 3312 3403 5040 2009 2298 ...\n $ infant   : num  26.7 23.7 17 16.8 13.5 10.1 12.9 20.4 17.8 25.7 ...\n $ region   : Factor w/ 4 levels \"Africa\",\"Americas\",..: 3 4 4 2 4 4 4 4 4 4 ...\n $ oil      : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ logincome: num  8.14 8.12 8.12 8.47 8.52 ...\n $ loginfant: num  3.28 3.17 2.83 2.82 2.6 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:4] 24 83 86 91\n  ..- attr(*, \"names\")= chr [1:4] \"Iran\" \"Haiti\" \"Laos\" \"Nepal\"\n\n\nNow we can fit the proposed model:\n\n\nCode\nlibrary(\"rjags\")\n\nmod_string = \" model {\n  for (i in 1:length(y)) {\n    y[i] ~ dnorm(mu[i], prec)\n    mu[i] = a[region[i]] + b[1]*log_income[i] + b[2]*is_oil[i]\n  }\n  \n  for (j in 1:max(region)) {\n    a[j] ~ dnorm(a0, prec_a)\n  }\n  \n  a0 ~ dnorm(0.0, 1.0/1.0e6)\n  prec_a ~ dgamma(1/2.0, 1*10.0/2.0)\n  tau = sqrt( 1.0 / prec_a )\n  \n  for (j in 1:2) {\n    b[j] ~ dnorm(0.0, 1.0/1.0e6)\n  }\n  \n  prec ~ dgamma(5/2.0, 5*10.0/2.0)\n  sig = sqrt( 1.0 / prec )\n} \"\n\nset.seed(116)\ndata_jags = list(y=dat$loginfant, log_income=dat$logincome,\n                  is_oil=as.numeric(dat$oil==\"yes\"), region=as.numeric(dat$region))\ndata_jags$is_oil\n\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n\nCode\ntable(data_jags$is_oil, data_jags$region)\n\n\n   \n     1  2  3  4\n  0 31 20 24 18\n  1  3  2  3  0\n\n\nCode\nparams = c(\"a0\", \"a\", \"b\", \"sig\", \"tau\")\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 101\n   Unobserved stochastic nodes: 9\n   Total graph size: 622\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3) # burn-in\n\nmod_sim = coda.samples(model=mod,\n                       variable.names=params,\n                       n.iter=5e3)\n\nmod_csim = as.mcmc(do.call(rbind, mod_sim)) # combine multiple chains\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\na[1]       1.05       1.16\na[2]       1.05       1.15\na[3]       1.05       1.15\na[4]       1.05       1.16\na0         1.01       1.03\nb[1]       1.05       1.17\nb[2]       1.00       1.01\nsig        1.00       1.00\ntau        1.00       1.00\n\nMultivariate psrf\n\n1.04\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n            a[1]      a[2]      a[3]      a[4]         a0      b[1]       b[2]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.00000000 1.0000000 1.00000000\nLag 1  0.9001760 0.8996483 0.8949744 0.9197659 0.19463182 0.9747301 0.12328271\nLag 5  0.8110994 0.8119318 0.8082661 0.8276882 0.16662405 0.8793248 0.01157785\nLag 10 0.7123125 0.7111090 0.7122514 0.7260531 0.15635165 0.7719519 0.03097500\nLag 50 0.2589712 0.2598085 0.2517056 0.2645886 0.05041769 0.2808998 0.01960443\n               sig          tau\nLag 0  1.000000000  1.000000000\nLag 1  0.054505385  0.289818936\nLag 5  0.002863801  0.007821327\nLag 10 0.002226746 -0.003215383\nLag 50 0.002465208 -0.006407903\n\n\nCode\nautocorr.plot(mod_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod_sim)\n\n\n      a[1]       a[2]       a[3]       a[4]         a0       b[1]       b[2] \n  218.8250   220.2598   212.6159   220.2453  1258.2932   191.9277  8793.7859 \n       sig        tau \n12943.3789  8114.3985 \n\n\n\n52.7.1 Results\nConvergence looks okay, so let’s compare this with the old model from Lesson 7 using DIC:\n\n\nCode\ndic.samples(mod, n.iter=1e3)\n\n\nMean deviance:  213.3 \npenalty 6.896 \nPenalized deviance: 220.2 \n\n\nCode\n### nonhierarchical model: 230.1\n\n\nIt appears that this model is an improvement over the non-hierarchical one we fit earlier. Notice that the penalty term, which can be interpreted as the “effective” number of parameters, is less than the actual number of parameters (nine). There are fewer “effective” parameters because they are “sharing” information or “borrowing strength” from each other in the hierarhical structure. If we had skipped the hierarchy and fit one intercept, there would have been four parameters. If we had fit separate, independent intercepts for each region, there would have been seven parameters (which is close to what we ended up with).\nFinally, let’s look at the posterior summary.\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\na[1]  6.5606 0.50516 0.0041246      0.0334076\na[2]  6.0186 0.63697 0.0052009      0.0422300\na[3]  5.8534 0.56169 0.0045862      0.0378524\na[4]  5.5454 0.77830 0.0063548      0.0513041\na0    5.9891 1.30609 0.0106642      0.0378597\nb[1] -0.3423 0.09529 0.0007780      0.0067047\nb[2]  0.6427 0.34575 0.0028231      0.0037354\nsig   0.9174 0.06547 0.0005346      0.0005756\ntau   2.0686 1.07186 0.0087517      0.0120144\n\n2. Quantiles for each variable:\n\n         2.5%     25%     50%     75%   97.5%\na[1]  5.58193  6.2140  6.5629  6.8892  7.5668\na[2]  4.78141  5.5853  6.0233  6.4366  7.2916\na[3]  4.76714  5.4748  5.8559  6.2223  6.9768\na[4]  4.04448  5.0214  5.5401  6.0609  7.0953\na0    3.43132  5.2361  6.0012  6.7499  8.4949\nb[1] -0.53249 -0.4047 -0.3432 -0.2774 -0.1586\nb[2] -0.04384  0.4114  0.6410  0.8763  1.3279\nsig   0.79952  0.8716  0.9140  0.9588  1.0562\ntau   0.98401  1.4164  1.8012  2.3780  4.7456\n\n\nIn this particular model, the intercepts do not have a real interpretation because they correspond to the mean response for a country that does not produce oil and has $0 log-income per capita (which is $1 income per capita). We can interpret a_0 as the overall mean intercept and \\tau as the standard deviation of intercepts across regions.\n\n\n52.7.2 Other models\nWe have not investigated adding interaction terms, which might be appropriate. We only considered adding hierarchy on the intercepts, but in reality nothing prevents us from doing the same for other terms in the model, such as the coefficients for income and oil. We could try any or all of these alternatives and see how the DIC changes for those models. This, together with other model checking techniques we have discussed could be used to identify your best model that you can use to make inferences and predictions.",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#mixture-models",
    "href": "C2-L11.html#mixture-models",
    "title": "52  Hierarchical modeling",
    "section": "52.8 Mixture models",
    "text": "52.8 Mixture models\nHistograms of data often reveal that they do not follow any standard probability distribution. Sometimes we have explanatory variables (or covariates) to account for the different values, and normally distributed errors are adequate, as in normal regression. However, if we only have the data values themselves and no covariates, we might have to fit a non-standard distribution to the data. One way to do this is by mixing standard distributions.\nMixture distributions are just a weighted combination of probability distributions. For example, we could take an exponential distribution with mean 1 and normal distribution with mean 3 and variance 1 (although typically the two mixture components would have the same support; here the exponential component has to be non-negative and the normal component can be positive or negative). Suppose we give them weights: 0.4 for the exponential distribution and 0.6 for the normal distribution. We could write the PDF for this distribution as\n\n\\mathbb{P}r(y) = 0.4 \\cdot \\exp(-y) \\cdot \\mathbb{I}_{(y \\ge 0)} + 0.6 \\cdot \\frac{1}{\\sqrt{2 \\pi}} \\exp\\left(- \\frac{1}{2} (y - 3)^2\\right)\n\nThe PDF of this mixture distribution would look like this:\n\n\nCode\ncurve( 0.4*dexp(x, 1.0) + 0.6*dnorm(x, 3.0, 1.0), from=-2.0, to=7.0, ylab=\"density\", xlab=\"y\", main=\"40/60 mixture of exponential and normal distributions\", lwd=2)\n\n\n\n\n\n\n\n\n\nWe could think of these two distributions as governing two distinct populations, one following the exponential distribution and the other following the normal distribution.\nLet’s draw the weighted PDFs for each population.\n\n\nCode\ncurve( 0.4*dexp(x, 1.0) + 0.6*dnorm(x, 3.0, 1.0), from=-2.0, to=7.0, ylab=\"density\", xlab=\"y\", main=\"40/60 mixture of exponential and normal distributions\", lwd=2)\ncurve( 0.4*dexp(x, 1.0), from=-2.0, to=7.0, col=\"red\", lty=2, add=TRUE)\ncurve( 0.6*dnorm(x, 3.0, 1.0), from=-2.0, to=7.0, col=\"blue\", lty=2, add=TRUE)\n\n\n\n\n\n\n\n\n\nThe general form for a discrete mixture of distributions is as follows:\n\n\\mathbb{P}r(y) = \\sum_{j=1}^J \\omega_j \\cdot f_j (y)\n\nwhere the \\omega’s are positive weights that add up to 1 (they are probabilities) and each of the J f_j(y) functions is a PDF for some distribution. In the example above, the weights were 0.4 and 0.6, f_1 was an exponential PDF and f_2 was a normal PDF.\nOne way to simulate from a mixture distribution is with a hierarchical model. We first simulate an indicator for which “population” the next observation will come from using the weights \\omega. Let’s call this z_i. In the example above, z_i would take the value 1 (indicating the exponential distribution) with probability 0.4 and 2 (indicating the normal distribution) with probability 0.6. Next, simulate the observation y_i from the distribution corresponding to z_i.\nLet’s simulate from our example mixture distribution.\n\n\nCode\nset.seed(117)\nn = 1000\nz = numeric(n)\ny = numeric(n)\nfor (i in 1:n) {\n  z[i] = sample.int(2, 1, prob=c(0.4, 0.6)) # returns a 1 with probability 0.4, or a 2 with probability 0.6\n  if (z[i] == 1) {\n    y[i] = rexp(1, rate=1.0)\n  } else if (z[i] == 2) {\n    y[i] = rnorm(1, mean=3.0, sd=1.0)\n  }\n}\nhist(y, breaks=30)\n\n\n\n\n\n\n\n\n\nIf we keep only the y values and throw away the z values, we have a sample from the mixture model above. To see that they are equivalent, we can marginalize the joint distribution of y and z:\n\n\\mathbb{P}r(y) = \\sum_{j=1}^2 \\mathbb{P}r(y, z=j) = \\sum_{j=1}^2 \\mathbb{P}r(z=j) \\cdot \\mathbb{P}r(y \\mid z=j) = \\sum_{j=1}^2 \\omega_j \\cdot f_j(y)\n\n\n52.8.1 Bayesian inference for mixture models\nWhen we fit a mixture model to data, we usually only have the y values and do not know which “population” they belong to. Because the z variables are unobserved, they are called latent variables. We can treat them as parameters in a hierarchical model and perform Bayesian inference for them. The hierarchial model might look like this:\n\n\\begin{aligned}\ny_i \\mid z_i, \\theta & \\overset{\\text{ind}}{\\sim} f_{z_i}(y \\mid \\theta) \\, , \\quad i = 1, \\ldots, n \\\\\n\\text{Pr}(z_i = j \\mid \\omega) &= \\omega_j \\, , \\quad j=1, \\ldots, J \\\\\n\\omega &\\sim \\mathbb{P}r(\\omega) \\\\\n\\theta &\\sim  \\mathbb{P}r(\\theta)\n\\end{aligned}\n\nwhere we might use a Dirichlet prior (see the review of distributions in the supplementary material) for the weight vector \\omega and conjugate priors for the population-specific parameters in \\theta. With this model, we could obtain posterior distributions for z (population membership of the observations), \\omega (population weights), and \\theta (population-specific parameters in f_j). Next, we will look at how to fit a mixture of two normal distributions in JAGS.",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11.html#example-with-jags",
    "href": "C2-L11.html#example-with-jags",
    "title": "52  Hierarchical modeling",
    "section": "52.9 Example with JAGS",
    "text": "52.9 Example with JAGS\n\n52.9.1 Data\nFor this example, we will use the data in the attached file mixture.csv.\n\n\nCode\ndat = read.csv(\"data/mixture.csv\", header=FALSE)\ny = dat$V1\n(n = length(y))\n\n\n[1] 200\n\n\nLet’s visualize these data.\n\n\nCode\nhist(y, breaks=20)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(density(y))\n\n\n\n\n\n\n\n\n\nIt appears that we have two populations, but we do not know which population each observation belongs to. We can learn this, along with the mixture weights and population-specific parameters with a Bayesian hierarchical model.\nWe will use a mixture of two normal distributions with variance 1 and different (and unknown) means.\n\n\n52.9.2 Model\n\n\nCode\nlibrary(\"rjags\")\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[z[i]], prec)\n      z[i] ~ dcat(omega)\n    }\n  \n  mu[1] ~ dnorm(-1.0, 1.0/100.0)\n    mu[2] ~ dnorm(1.0, 1.0/100.0) T(mu[1],) # ensures mu[1] &lt; mu[2]\n\n    prec ~ dgamma(1.0/2.0, 1.0*1.0/2.0)\n  sig = sqrt(1.0/prec)\n    \n    omega ~ ddirich(c(1.0, 1.0))\n} \"\n\nset.seed(11)\n\ndata_jags = list(y=y)\n\nparams = c(\"mu\", \"sig\", \"omega\", \"z[1]\", \"z[31]\", \"z[49]\", \"z[6]\") # Select some z's to monitor\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 200\n   Unobserved stochastic nodes: 204\n   Total graph size: 614\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,\n                        variable.names=params,\n                        n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n\n\n\nCode\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim, ask=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n              mu[1]        mu[2]    omega[1]    omega[2]          sig\nLag 0  1.0000000000  1.000000000 1.000000000 1.000000000  1.000000000\nLag 1  0.5568951389  0.349896710 0.310481173 0.310481173  0.410825416\nLag 5  0.0922654587  0.057187640 0.063596064 0.063596064  0.013829087\nLag 10 0.0190356548  0.008723446 0.018058181 0.018058181  0.001836680\nLag 50 0.0008341474 -0.012363626 0.004155637 0.004155637 -0.006028303\n               z[1]        z[31]        z[49] z[6]\nLag 0   1.000000000  1.000000000  1.000000000  NaN\nLag 1   0.010067842  0.039595219  0.031974687  NaN\nLag 5   0.011571414  0.020718847  0.013510490  NaN\nLag 10 -0.002757479 -0.001936273 -0.006995698  NaN\nLag 50 -0.002715105 -0.009872065 -0.007780321  NaN\n\n\nCode\neffectiveSize(mod_sim)\n\n\n    mu[1]     mu[2]  omega[1]  omega[2]       sig      z[1]     z[31]     z[49] \n 3847.426  5264.188  5497.829  5497.829  5906.891 13129.611 13071.418 13310.825 \n     z[6] \n    0.000 \n\n\n\n\n52.9.3 Results\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n            Mean      SD  Naive SE Time-series SE\nmu[1]    -2.1224 0.17015 0.0013893      0.0027450\nmu[2]     1.4872 0.12730 0.0010394      0.0017548\nomega[1]  0.3872 0.04092 0.0003341      0.0005535\nomega[2]  0.6128 0.04092 0.0003341      0.0005535\nsig       1.1380 0.07437 0.0006073      0.0009716\nz[1]      1.0098 0.09851 0.0008043      0.0008611\nz[31]     1.5721 0.49479 0.0040399      0.0043399\nz[49]     1.7955 0.40332 0.0032931      0.0035008\nz[6]      2.0000 0.00000 0.0000000      0.0000000\n\n2. Quantiles for each variable:\n\n            2.5%     25%     50%     75%   97.5%\nmu[1]    -2.4563 -2.2354 -2.1212 -2.0085 -1.7904\nmu[2]     1.2354  1.4046  1.4871  1.5725  1.7368\nomega[1]  0.3081  0.3596  0.3869  0.4141  0.4687\nomega[2]  0.5313  0.5859  0.6131  0.6404  0.6919\nsig       1.0062  1.0857  1.1323  1.1838  1.2996\nz[1]      1.0000  1.0000  1.0000  1.0000  1.0000\nz[31]     1.0000  1.0000  2.0000  2.0000  2.0000\nz[49]     1.0000  2.0000  2.0000  2.0000  2.0000\nz[6]      2.0000  2.0000  2.0000  2.0000  2.0000\n\n\n\n\nCode\n## for the population parameters and the mixing weights\n\npar(mar = c(2.5, 1, 2.5, 1))\npar(mfrow=c(3,2))\ndensplot(mod_csim[,c(\"mu[1]\", \"mu[2]\", \"omega[1]\", \"omega[2]\", \"sig\")])\n\n\n\n\n\n\n\n\n\n\n\nCode\n## for the z's\npar(mfrow=c(2,2))\npar(mar = c(2.5, 1, 2.5, 1))\ndensplot(mod_csim[,c(\"z[1]\", \"z[31]\", \"z[49]\", \"z[6]\")])\n\n\n\n\n\n\n\n\n\n\n\nCode\ntable(mod_csim[,\"z[1]\"]) / nrow(mod_csim) ## posterior probabilities for z[1], the membership of y[1]\n\n\n\n     1      2 \n0.9902 0.0098 \n\n\n\n\nCode\ntable(mod_csim[,\"z[31]\"]) / nrow(mod_csim) ## posterior probabilities for z[31], the membership of y[31]\n\n\n\n        1         2 \n0.4278667 0.5721333 \n\n\n\n\nCode\ntable(mod_csim[,\"z[49]\"]) / nrow(mod_csim) ## posterior probabilities for z[49], the membership of y[49]\n\n\n\n        1         2 \n0.2044667 0.7955333 \n\n\n\n\nCode\ntable(mod_csim[,\"z[6]\"]) / nrow(mod_csim) ## posterior probabilities for z[6], the membership of y[6]\n\n\n\n2 \n1 \n\n\n\n\nCode\ny[c(1, 31, 49, 6)]\n\n\n[1] -2.2661749 -0.3702666  0.0365564  3.7548080\n\n\nIf we look back to the y values associated with these z variables we monitored, we see that y_1 is clearly in Population 1’s territory, y_{31} is ambiguous, y_{49} is ambiguous but is closer to Population 2’s territory, and y_6 is clearly in Population 2’s territory. The posterior distributions for the z variables closely reflect our assessment.",
    "crumbs": [
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>M4L11 -Hierarchical modeling</span>"
    ]
  },
  {
    "objectID": "C2-L11-Ex1.html",
    "href": "C2-L11-Ex1.html",
    "title": "53  Homework on Hierarchical Models",
    "section": "",
    "text": "Exercise 53.1  Which of the following situations would call for a hierarchical model, due to the hierarchical structure of the data?Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nYou measure an individual’s mood with a questionnaire for ten consecutive days.\nYou survey a random sample of 100 individuals in your neighborhood who report their preferred produce market.\nYou run an internet connection speed test on your computer each Monday morning for ten consecutive weeks.\nYou take blood pressure measurements from each of five individuals on ten consecutive days.\n\nThe blood pressure measurements are grouped within (also called “nested” within) individuals. Hence, you would expect two measurements from person A to be more similar than a measurement from person A and another from person B.\n\n\n\n\nExercise 53.2  In hierarchical models, the observations are still conditionally independent, given their respective parameters. How then does such a model capture correlation among grouped observations?Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nObservation pairs from different groups require an extra parameter which induces negative correlation among them.\nGrouped observations share common parameters, which themselves share a common distribution across groups.\nGrouped observations require an extra parameter for each pair of observations which estimates the correlation among them.\nGrouped observations always exhibit correlation, even in an independent model.\n\nThe grouped observations are conditionally independent, given their common group parameters. However, if we integrate (marginalize) out this layer of group-specific parameters, leaving the hyperparameters and the observations only, the observations become dependent.\n\n\n\n\nExercise 53.3  In previous lessons, we fit models to data representing percent growth in personnel for companies in two industries. Below are attached additional data from the original two industries (with 10 and six companies respectively), as well as three additional industries. Percent growth is reported for a total of 53 companies.Hierarchical Model\nAs usual, you can read the data into R with\n\n\nCode\ndat = read.csv(file=\"data/pctgrowth.csv\", header=TRUE)\n\n\nRather than fit five separate models, one for each industry, we can fit a hierarchical model. As before, we assume a normal likelihood and common variance across all observations. Each industry will have it’s own mean growth, and each of these means will come from a common distribution, from which we will estimate the overall mean and variability across industries.\nLet i index the individual companies, and g_i indicate the industry (grp variable in pctgrowth.csv) for company i. Which of the following hierarchical models is the one described above?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\ny_i \\mid \\theta_{g_i}, \\sigma^2 \\overset{\\text{ind}}{\\sim} \\text{N} ( \\theta_{g_i}, \\sigma^2)\\, , \\quad i=1,\\ldots,53, \\quad g_i \\in \\{ 1, \\ldots, 5 \\}, \\\\ \\theta_g \\mid \\mu, \\tau^2 \\overset{\\text{iid}}{\\sim} \\text{N}(\\mu, \\tau^2)\\, , \\quad g = 1, \\ldots, 5, \\\\ \\mu \\sim \\text{N}(0, 1\\mathrm{e}{6})\\, , \\\\ \\tau^2 \\sim \\text{IG}(1/2,\\, 1\\cdot3/2) \\, , \\\\ \\sigma^2 \\sim \\text{IG}(2/2, \\, 2\\cdot1/2)\ny_i \\mid \\theta_{g_i}, \\sigma^2 \\overset{\\text{ind}}{\\sim} \\text{N} ( \\theta_{g_i}, \\sigma^2)\\, , \\quad i=1,\\ldots,53, \\quad g_i \\in \\{ 1, \\ldots, 5 \\}, \\\\ \\theta_g \\mid \\mu \\overset{\\text{iid}}{\\sim} \\text{N}(\\mu, 1)\\, , \\quad g = 1, \\ldots, 5, \\\\ \\mu \\sim \\text{N}(0, 1\\mathrm{e}{6})\\, , \\\\ \\sigma^2 \\sim \\text{IG}(2/2, \\, 2\\cdot1/2)\ny_i \\mid \\theta_{g_i}, \\sigma^2 \\overset{\\text{ind}}{\\sim} \\text{N} ( \\theta_{g_i}, \\sigma^2)\\, , \\quad i=1,\\ldots,53, \\quad g_i \\in \\{ 1, \\ldots, 5 \\}, \\\\ \\theta_g \\overset{\\text{iid}}{\\sim} \\text{N}(0, 1)\\, , \\quad g = 1, \\ldots, 5, \\\\ \\sigma^2 \\sim \\text{IG}(2/2, \\, 2\\cdot1/2)\ny_i \\mid \\theta_{g_i}, \\sigma^2 \\overset{\\text{ind}}{\\sim} \\text{N} ( \\theta_{g_i}, \\sigma^2)\\, , \\quad i=1,\\ldots,53, \\quad g_i \\in \\{ 1, \\ldots, 5 \\}, \\\\ \\theta_g \\mid \\tau^2 \\overset{\\text{iid}}{\\sim} \\text{N}(0, \\tau^2)\\, , \\quad g = 1, \\ldots, 5, \\\\ \\tau^2 \\sim \\text{IG}(1/2,\\, 1\\cdot3/2) \\, , \\\\ \\sigma^2 \\sim \\text{IG}(2/2, \\, 2\\cdot1/2)\n\nThis model allows us to explore each of:\n\nthe mean growth for each industry (\\theta)\nthe overall mean growth across industries (\\mu)\nthe overall variability in mean growth across industries (\\tau^2)\nthe variability of company growth between companies within industries (\\sigma^2).\n\nAll of these objectives are accomplished with a single model.\n\n\n\n\nExercise 53.4  Fit the hierarchical model from Question 3 in JAGS and obtain posterior mean estimates for each industry’s mean growth (posterior mean for each \\theta_g).Hierarchical Model\nWe are interested in comparing these estimates to those obtained from a model that assumes no hierarchy (the ANOVA cell means model). We can approximate the posterior estimates for the five industry means under a noninformative prior by simply calculating the sample mean growth for the five industries. You can do this in R with:\n\n\nCode\nmeans_anova = tapply(dat$y, INDEX=dat$grp, FUN=mean)\n## dat is the data read from pctgrowth.csv\n\n\nHow do these compare with the estimates from the hierarchical model?\nHint: It might help to plot them with:\n\n\nCode\nplot(means_anova)\n\n\n\n\n\n\n\n\n\nCode\n#points(means_theta, col=\"red\") ## where means_theta are the posterior point estimates for the industry means.\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n#: title s4 - compute new DIC\n#(dic = dic.samples(mod, n.iter=1e3))\n\n\n\nThe estimates from the hierarchical model have less variability than those from the ANOVA model, tending toward larger magnitudes.\nThe estimates from the hierarchical model have greater variability than those from the ANOVA model, tending toward smaller magnitudes.\nThe estimates from the hierarchical model have less variability than those from the ANOVA model, tending toward smaller magnitudes.\nThe estimates from the hierarchical model have greater variability than those from the ANOVA model, tending toward larger magnitudes. Correct\n\nThis is a typical feature of hierarchical models, where estimates tend to “shrink” toward their mean in the next step of the hierarchy (in this case \\mu).\n\n\n\n\nExercise 53.5  In our hierarchical model for personnel growth, we assumed that the variability between companies within an industry was constant across industries (\\sigma^2 was the same for all industries). Each of the following, except one, presents a reasonable approach to checking this model assumption. Which approach would be less informative than the others?Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nFit another model with separate \\sigma^2 parameters for each industry, and compare the DIC values between the new and old models.\nFit another model with separate \\sigma^2 parameters for each industry, and calculate the posterior probability that they differ from each other by some specified amount.\nCalculate the sample variance of growth within the industry for each of the five industries. Check if these variances are similar to each other.\nCalculate the posterior probability that {\\sigma^2\\over\\tau^2}&gt;1 in the original model. If this probability exceeds a pre-determined amount, use a model with separate variance parameters. Correct\n\nWhile it is true that wildly different variances across industries will inflate a common \\sigma^2, it is perfectly possible that the industry means are close to each other (low \\tau^2) while all industries exhibit similar variance among companies, each with large \\sigma^2.\n\n\n\n\nExercise 53.6  Which of the following would yield the correct calculation of the observation level residual for Company i in the hierarchical model for personnel growth?Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\ny_i−\\mu\ny_i−(\\theta_{g_i}−\\mu)\ny_i−\\theta_{g_i}\n\\theta_{g_i}−\\mu\n\nWe could obtain a distribution of the residual by calculating performing this calculation for each iteration of MCMC, or we could just get a posterior mean residual by using the posterior mean estimate of \\theta_{g_i}.\nWe can get an industry level residual by calculating \\theta_{g_i}−\\mu.\n\n\n\n\nExercise 53.7  Suppose we are interested in making a prediction for the growth of an 11th (new) company from Industry 1 (grp=1). Which of the following steps should we follow to simulate from the posterior predictive distribution for this new company’s growth? Call it y^∗.Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nFor each iteration of MCMC:\n\nDraw a sample y^∗ from a normal distribution with mean \\mu and variance \\tau2 using the current iteration of these parameters.\nDraw a sample \\theta_1^∗ from a normal distribution with mean \\mu and variance \\tau2. Then sample y^∗ from a normal distribution with mean \\theta_1^∗ and variance \\sigma^2 using the current iteration of all parameters.\nDraw a sample y^∗ from a normal distribution with mean \\mu and variance \\tau^2+\\sigma^2 using the current iteration of these parameters.\nDraw a sample y^∗ from a normal distribution with mean \\theta_1 and variance \\sigma^2 using the current iteration of these parameters.\n\nThis would produce a sample from the posterior predictive distribution of growth for a new company in a new industry. Because we know that this company is in Industry 1, we can use the existing posterior samples of \\theta_1.\n\n\n\n\nExercise 53.8  Suppose we are interested in making a prediction for the growth of a new company from a new industry which so far has not been observed. Which of the following steps should we follow to simulate from the posterior predictive distribution for this new company’s growth? Call it y^∗.Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nFor each iteration of MCMC: - [ ] Draw a sample y^∗ from a normal distribution with mean \\mu and variance \\tau^2 using the current iteration of these parameters. - [ ] Draw a sample y^∗ from a normal distribution with mean \\mu and variance \\sigma^2 using the current iteration of these parameters. - [ ] Draw a sample y^∗ from a normal distribution with mean \\theta_1 and variance \\sigma^2 using the current iteration of these parameters. - [x] Draw a sample \\theta^∗ from a normal distribution with mean \\mu and variance \\tau^2. Then sample y^∗ from a normal distribution with mean \\theta^∗ and variance \\sigma^2, using the current iteration of all parameters.\nThis would produce a draw from the posterior predictive distribution of industry means. It could be used as a step in the sample we are trying to produce, but this description is incomplete.",
    "crumbs": [
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Homework on Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "C2-L11-Ex2.html",
    "href": "C2-L11-Ex2.html",
    "title": "54  Homework on Non-Normal Hierarchical Models",
    "section": "",
    "text": "Exercise 54.1  We have seen an example of extending a normal linear model to a hierarchical model. We will now explore extending a non-normal linear model. Consider again the OME data in the MASS package in R, which we explored in the quiz from Lesson 9. The data consist of experimental results from tests of auditory perception in children. Under varying conditions and for multiple trials under each condition, children either correctly or incorrectly identified the source of changing signals.Hierarchical Model\nOne variable we did not use in the model was the child ID number. It turns out that there are multiple (ranging from eight to 20) observations for each child. For example, the first 20 rows of the data are all results from Child 1. Why is it reasonable to consider fitting a hierarchical model in this scenario?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nObservations are independent, within and between different children. Separate tests were conducted, so there’s no reason to believe the data are correlated.\nSome of the children in the study may be siblings, and their results may be more correlated than for unrelated children.\nObservations from a single child are likely correlated. For example, two results from one child are more likely to be similar than two results from two different children.\nThe children may be grouped in a hierarchical fashion, for example, classes in a school.\n\n\n\n\n\nExercise 54.2  Recall that the original model looked like this:Hierarchical Model\n\n\\begin{aligned}\ny_i \\mid \\phi_i  & \\overset{\\text{ind}}{\\sim} \\text{Binomial}(n_i, \\phi_i) \\, , \\quad i = 1,\\ldots,712 \\, ,\n\\\\ \\text{logit}(\\phi_i) &= \\beta_0 + \\beta_1 {\\texttt Age}_i + \\beta_2 I_{({\\texttt OME}_i = {\\texttt low})} + \\beta_3 {\\texttt Loud}_i + \\beta_4 I_{({\\texttt Noise}_i = {\\texttt incoherent})}\n\\\\ \\beta_0   & \\sim \\text{N}(0, 5^2)\n\\\\  \\beta_k  & \\overset{\\text{iid}}{\\sim} \\text{N}(0, 4^2) \\, , \\quad k = 1,2,3\n\\end{aligned}\n\nAs with other models, we will extend the intercept (and rename it) so that the linear part of the model looks like this:\n\n\\text{logit}(\\phi_i) = \\alpha_{{\\texttt ID}_i} + \\beta_1 {\\texttt Age}_i + \\beta_2 I_{({\\texttt OME}_i = {\\texttt low})} + \\beta_3 {\\texttt Loud}_i + \\beta_4 I_{({\\texttt Noise}_i = {\\texttt incoherent})}\n\nwhere {\\texttt ID}_i is an index identifying the child for observation i. The hierarchical prior for the intercepts would then look like this:\n\n\\alpha_j \\overset{\\text{iid}}{\\sim} \\text{N}(\\mu, \\tau^2) \\, , \\quad j = 1,\\ldots, 63\n\nfollowed by priors for \\mu and \\tau^2:\n\n\\mu \\sim \\text{N}(0, 10^2) \\\\ \\tau^2 \\sim \\text{IG}(1/2, 1/2)\n\nWhat does \\tau^2 indicate in the context of this model?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe variability in proportion of correct responses across tests for one child.\nThe variability in the number of correct responses across tests for one child.\nThe variability of the intercept across all observations in the data.\nThe variability of the intercept between children.\n\n\n\n\n\nExercise 54.3  Fit the hierarchical model proposed in Question 2 with JAGS by adjusting the code given in the quiz from Lesson 9 (below). The following R code will be necessary to reproduce the results.Hierarchical Model\n\n\nCode\nlibrary(\"MASS\")\ndata(\"OME\")\n\ndat = subset(OME, OME != \"N/A\")\ndat$OME = factor(dat$OME) # relabel OME\ndat$ID = as.numeric(factor(dat$ID)) # relabel ID so there are no gaps in numbers (they now go from 1 to 63)\n\n## Original reference model and covariate matrix\nmod_glm = glm(Correct/Trials ~ Age + OME + Loud + Noise, data=dat, weights=Trials, family=\"binomial\")\nX = model.matrix(mod_glm)[,-1]\n\n## Original model (that needs to be extended)\nmod_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dbin(phi[i], n[i])\n        #logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n    logit(phi[i]) = a[ID[i]] + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n    }\n    \n  for (k in 1:max(ID) ) {\n    a[k] ~ dnorm(a0, prec_a)\n    }\n    #a ~ dnorm(0.0, 1.0/5.0^2)\n  \n  a0 ~ dnorm(0,1.0/10.0^2)\n  prec_a ~ dgamma(0.5,0.5)\n  tau = sqrt(1/prec_a)\n\n    for (j in 1:4) {\n        b[j] ~ dnorm(0.0, 1.0/4.0^2)\n    }\n    \n} \"\n\ndata_jags = as.list(as.data.frame(X))\ndata_jags$y = dat$Correct\ndata_jags$n = dat$Trials\ndata_jags$ID = dat$ID\n\n\nset.seed(113)\nparams = c(\"b\",\"a\",\"a0\",\"tau\")\npar(mar = c(2.5, 1, 2.5, 1))\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 712\n   Unobserved stochastic nodes: 69\n   Total graph size: 6500\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\npar(mar = c(2.5, 1, 2.5, 1))\nmod_sim = coda.samples(model=mod, variable.names=params, n.iter=1e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n\nHow do the convergence diagnostics look?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\na[1]        1.48       2.24\na[2]        1.48       2.23\na[3]        1.43       2.11\na[4]        1.53       2.35\na[5]        1.46       2.19\na[6]        1.35       1.93\na[7]        1.49       2.26\na[8]        1.47       2.21\na[9]        1.36       1.94\na[10]       1.42       2.09\na[11]       1.48       2.24\na[12]       1.35       1.91\na[13]       1.41       2.08\na[14]       1.41       2.07\na[15]       1.47       2.21\na[16]       1.39       2.04\na[17]       1.40       2.04\na[18]       1.43       2.10\na[19]       1.37       1.98\na[20]       1.46       2.19\na[21]       1.38       2.01\na[22]       1.43       2.12\na[23]       1.31       1.84\na[24]       1.51       2.32\na[25]       1.46       2.20\na[26]       1.37       1.98\na[27]       1.39       2.03\na[28]       1.42       2.09\na[29]       1.38       2.00\na[30]       1.40       2.06\na[31]       1.41       2.06\na[32]       1.36       1.95\na[33]       1.40       2.06\na[34]       1.40       2.04\na[35]       1.37       1.97\na[36]       1.33       1.90\na[37]       1.42       2.10\na[38]       1.38       2.01\na[39]       1.40       2.05\na[40]       1.33       1.89\na[41]       1.33       1.89\na[42]       1.44       2.13\na[43]       1.41       2.07\na[44]       1.39       2.01\na[45]       1.40       2.04\na[46]       1.37       1.99\na[47]       1.41       2.07\na[48]       1.41       2.07\na[49]       1.36       1.96\na[50]       1.41       2.08\na[51]       1.38       2.01\na[52]       1.34       1.91\na[53]       1.40       2.04\na[54]       1.38       2.00\na[55]       1.29       1.79\na[56]       1.39       2.02\na[57]       1.45       2.16\na[58]       1.43       2.13\na[59]       1.41       2.06\na[60]       1.40       2.04\na[61]       1.37       1.98\na[62]       1.37       1.97\na[63]       1.44       2.15\na0          1.64       2.64\nb[1]        1.19       1.55\nb[2]        1.12       1.37\nb[3]        1.26       1.75\nb[4]        1.02       1.07\ntau         1.02       1.06\n\nMultivariate psrf\n\n1.4\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n            a[1]      a[2]      a[3]      a[4]      a[5]      a[6]      a[7]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.7384115 0.7589160 0.7477754 0.8130073 0.7828902 0.6552116 0.7612009\nLag 5  0.6320003 0.6733677 0.6283192 0.7157442 0.6741526 0.5464496 0.6628827\nLag 10 0.6011340 0.6246967 0.5918353 0.6812182 0.6483540 0.5043516 0.6072099\nLag 50 0.3782057 0.3794023 0.3893817 0.4321379 0.3989824 0.2986257 0.3953205\n            a[8]      a[9]     a[10]     a[11]     a[12]     a[13]     a[14]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.7480722 0.7067193 0.7389464 0.7588335 0.6635101 0.6657928 0.6735779\nLag 5  0.6392104 0.5711087 0.6293384 0.6761727 0.5083479 0.5466971 0.5604437\nLag 10 0.6157704 0.5317715 0.6053351 0.6246028 0.4844472 0.5159358 0.5225860\nLag 50 0.3820233 0.3323511 0.3643555 0.3981989 0.3346961 0.3237202 0.3548105\n           a[15]     a[16]     a[17]     a[18]     a[19]     a[20]     a[21]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.7317163 0.6820253 0.6716004 0.7421061 0.6988594 0.7671423 0.7089165\nLag 5  0.6069226 0.5747271 0.5230867 0.6224305 0.5491634 0.6813483 0.5869220\nLag 10 0.5878651 0.5388267 0.4861165 0.5651611 0.5325498 0.6480784 0.5715649\nLag 50 0.3700457 0.3360556 0.2875709 0.3601249 0.3180743 0.4043996 0.3801908\n           a[22]     a[23]     a[24]     a[25]     a[26]     a[27]     a[28]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.8037006 0.6584901 0.7917202 0.7084050 0.6751556 0.6826420 0.6988987\nLag 5  0.7082411 0.5299643 0.6807149 0.5972439 0.5572872 0.5703755 0.5915298\nLag 10 0.6491302 0.4851329 0.6583263 0.5536366 0.5235020 0.5238350 0.5708779\nLag 50 0.4121396 0.3146076 0.3983622 0.3800256 0.3558079 0.3464781 0.3559758\n           a[29]     a[30]     a[31]     a[32]     a[33]     a[34]     a[35]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.6554065 0.6893182 0.6809088 0.6751089 0.6582870 0.6828014 0.6847781\nLag 5  0.5431500 0.5538284 0.5618483 0.5380522 0.5537609 0.5638235 0.5561663\nLag 10 0.5044323 0.5209618 0.5612138 0.4942244 0.5133794 0.5413041 0.5182117\nLag 50 0.3178461 0.3385031 0.3438089 0.2864588 0.3398149 0.3553755 0.3083645\n           a[36]     a[37]     a[38]     a[39]     a[40]     a[41]     a[42]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.6559472 0.6612355 0.6946259 0.6600176 0.6280698 0.6322145 0.6871007\nLag 5  0.5474776 0.5496478 0.5820781 0.5282913 0.4933737 0.4864758 0.5933165\nLag 10 0.5028826 0.5276242 0.5412495 0.5142185 0.4725571 0.4322696 0.5434797\nLag 50 0.3258714 0.3180498 0.3267427 0.3404627 0.2962344 0.2767433 0.3538876\n           a[43]     a[44]     a[45]     a[46]     a[47]     a[48]     a[49]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.6682095 0.6802619 0.6684407 0.6752517 0.6600898 0.6842115 0.6686602\nLag 5  0.5352402 0.5502613 0.5612497 0.5632664 0.5365567 0.5179433 0.5475056\nLag 10 0.5215595 0.5107113 0.5147386 0.5105006 0.4635394 0.5146646 0.5163282\nLag 50 0.3332889 0.3084381 0.3394340 0.3141649 0.2865138 0.3099736 0.3087018\n           a[50]     a[51]     a[52]     a[53]     a[54]     a[55]     a[56]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.6881296 0.6635374 0.6426570 0.7067085 0.6712957 0.6358072 0.6842669\nLag 5  0.5539886 0.5716139 0.5277994 0.5702085 0.5264127 0.4845313 0.5588057\nLag 10 0.5322639 0.5280073 0.4801114 0.5563522 0.4984606 0.4592124 0.5164007\nLag 50 0.3432262 0.3306224 0.3108628 0.3630232 0.3269052 0.2901837 0.3323929\n           a[57]     a[58]     a[59]     a[60]     a[61]     a[62]     a[63]\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.7002908 0.7491153 0.6888401 0.7073981 0.6739860 0.6522490 0.6871424\nLag 5  0.6037649 0.6400560 0.5512992 0.5859669 0.5540001 0.5470158 0.5751582\nLag 10 0.5664133 0.5929086 0.5286043 0.5454899 0.5240993 0.5052415 0.5303184\nLag 50 0.3641708 0.3823791 0.3264806 0.3647112 0.3392222 0.3161184 0.3154212\n              a0      b[1]       b[2]      b[3]       b[4]          tau\nLag 0  1.0000000 1.0000000 1.00000000 1.0000000 1.00000000 1.0000000000\nLag 1  0.9804429 0.9454800 0.88868626 0.9707409 0.47560290 0.6867878779\nLag 5  0.9431717 0.7827141 0.56664884 0.8661804 0.04605940 0.2661491737\nLag 10 0.8951097 0.6358818 0.32463070 0.7465827 0.02341867 0.0594861522\nLag 50 0.5625958 0.2071369 0.02759236 0.2303559 0.02141137 0.0009459412\n\n\nCode\neffectiveSize(mod_sim)\n\n\n     a[1]      a[2]      a[3]      a[4]      a[5]      a[6]      a[7]      a[8] \n 32.48613  37.68245  41.79408  23.87680  31.59278  58.59754  42.22577  39.94962 \n     a[9]     a[10]     a[11]     a[12]     a[13]     a[14]     a[15]     a[16] \n 54.91486  35.74868  36.69694  51.50531  57.52082  62.60160  39.53437  43.72551 \n    a[17]     a[18]     a[19]     a[20]     a[21]     a[22]     a[23]     a[24] \n 60.99215  62.00972  56.10194  36.28346  37.72041  41.15899  72.20036  30.51418 \n    a[25]     a[26]     a[27]     a[28]     a[29]     a[30]     a[31]     a[32] \n 38.30646  55.95998  58.14786  35.42232  72.22349  55.34557  35.14419  55.55883 \n    a[33]     a[34]     a[35]     a[36]     a[37]     a[38]     a[39]     a[40] \n 45.79354  39.54010  38.97129  50.27835  53.39231  46.58026  60.38666  64.05775 \n    a[41]     a[42]     a[43]     a[44]     a[45]     a[46]     a[47]     a[48] \n 85.93085  58.56096  62.02050  65.22789  34.94011  57.87375  56.75564  48.69259 \n    a[49]     a[50]     a[51]     a[52]     a[53]     a[54]     a[55]     a[56] \n 58.69677  47.35716  38.38298  55.19775  40.37113  50.23325  72.85406  46.04376 \n    a[57]     a[58]     a[59]     a[60]     a[61]     a[62]     a[63]        a0 \n 44.67369  37.80013  53.91011  45.18546  45.03964  61.29044  46.98851  14.64713 \n     b[1]      b[2]      b[3]      b[4]       tau \n 77.16964 179.52186  44.54993 987.59389 423.75479 \n\n\n\n\nCode\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nautocorr.plot(mod_csim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe chains suddenly jump from exploring one space to exploring another, as though the parameters are switching labels. The parameters do not appear to be uniquely identified by the data.\nAutocorrelation is quite strong in the chains. This model would require a large number of MCMC iterations before we would use the results to make solid conclusions.\nDifferent chains from different initial values fail to explore the same space. Advanced MCMC techniques will be required to explore this multi-modal (many-peaked) posterior.\nConvergence diagnostics look great. There are no concerns\n\n\n\n\n\nExercise 54.4  The DIC value for the original model fit in the quiz for logistic regression is about 1264. Calculate a DIC value for this new hierarchical model. What do you conclude?Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n## s4 - compute new DIC\n(dic = dic.samples(mod, n.iter=1e3))\n\n\nMean deviance:  1240 \npenalty 28.05 \nPenalized deviance: 1268 \n\n\n\nThe DIC value for this new model is higher, indicating a preference for the new model.\nThe DIC value for this new model is higher, indicating a preference for the original model.\nThe DIC value for this new model is lower, indicating a preference for the new model.\nThe DIC value for this new model is lower, indicating a preference for the original model.\n\nIt turns out that in this case, the hierarchical model accounting for correlated tests with the same child does not help the model in terms of predictive accuracy. Theoretically, the hierarchical model is probably more justified because of the hierarchical structure of the data. However, the data appear to be essentially uncorrelated in practice\n\n\n\n\nExercise 54.5  The actual number of parameters in this hierarchical model is 69 (63 random intercepts, four regression coefficients, and two hyperparameters). What is the effective number of parameters? Round your answer to one decimal place.Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n27.51\nThis number is so much smaller than the actual number of parameters partially because the intercept parameters are very similar for many of the children.\n\n\n\n\nExercise 54.6 In the hierarchical model with random intercepts, we assumed that the common distribution for the intercepts is normal. What could we examine to assess whether this is a reasonable assumption?Hierarchical Model\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWe could look at the second-level residuals calculated from \\alpha_j − \\mu and evaluate how they are distributed.\nWe could look at the posterior distribution of \\mu.\nWe could look at the data-level residuals calculated from (y_i−\\phi_i) and evaluate how they are distributed.\nWe could look at the data-level residuals calculated from ({y_i \\over n_i}−\\phi_i) and evaluate how they are distributed.\n\nWe could perform the equivalent of a linear model residual analysis for this level of the model, using the estimates of the intercepts as the data.",
    "crumbs": [
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Homework on Non-Normal Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "C2-L12-Ex1.html",
    "href": "C2-L12-Ex1.html",
    "title": "56  Homework on Predictive distributions and mixture models",
    "section": "",
    "text": "Exercise 56.1  Consider the Poisson process model we fit in the quiz for Lesson 10 which estimates calling rates of a retailer’s customers. The data are attached below.Mixture Models\nRe-fit the model and use your posterior samples to simulate predictions of the number of calls by a new 29 year old customer from Group 2 whose account is active for 30 days. What is the probability that this new customer calls at least three times during this period? Round your answer to two decimal places.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nlibrary(\"rjags\")\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\nCode\ncalls_dat = read.csv(file=\"data/callers.csv\", header=TRUE)\nhead(calls_dat)\n\n\n  calls days_active isgroup2 age\n1     2          32        0  27\n2     4          81        0  32\n3     0          41        0  22\n4     1          36        0  28\n5     0          55        0  31\n6     0          25        0  33\n\n\nCode\ncalls_mod_string = \" model {\n    for (i in 1:length(calls)) {\n        calls[i] ~ dpois( days_active[i] * lam[i] )\n        log(lam[i]) = b0 + b[1]*age[i] + b[2]*isgroup2[i]\n    }\n\n  b0 ~ dnorm(0.0, 10.0^2)\n  for(j in 1:2){\n    b[j] ~ dnorm(0.0, 10.0^2)\n  }\n} \"\nset.seed(102)\ncalls_data_jags = as.list(calls_dat)\ncalls_params = c(\"b0\",'b')\ncalls_mod = jags.model(textConnection(calls_mod_string), data=calls_data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 224\n   Unobserved stochastic nodes: 3\n   Total graph size: 1218\n\nInitializing model\n\n\nCode\nupdate(calls_mod, 1e3)\ncalls_mod_sim = coda.samples(model=calls_mod, variable.names=calls_params,n.iter=5e3)\ncalls_mod_csim = as.mcmc(do.call(rbind, calls_mod_sim))\n\nx1 = c(29,1) # days active,isgroup2,age\n\nhead(calls_mod_csim)\n\n\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1 \nEnd = 7 \nThinning interval = 1 \n           b[1]      b[2]          b0\n[1,] -0.1371172 0.4340061 -0.15972214\n[2,] -0.1378026 0.3420005 -0.24826511\n[3,] -0.1356295 0.4789992 -0.19979551\n[4,] -0.1423094 0.3999796 -0.14418290\n[5,] -0.1422184 0.3359502 -0.06597418\n[6,] -0.1414895 0.3082942 -0.16756842\n[7,] -0.1380260 0.3546522 -0.23516074\n\n\nCode\nloglam1 = calls_mod_csim[,\"b0\"] + calls_mod_csim[,c(1,2)] %*% x1\nlam1 = exp(loglam1)\n(n_sim = length(lam1))\n\n\n[1] 15000\n\n\nCode\ny1 = rpois(n=n_sim, lambda=lam1*30) \nsum(y1 &gt;= 3)/length(y1)\n\n\n[1] 0.02853333\n\n\n0.03\n\n\n\n\nExercise 56.2  Suppose we fit a single component normal distribution to the data whose histogram is shown below.Mixture Models\n\nIf we use a noninformative prior for μ and σ^2 and plot the fit distribution evaluated at the posterior means (in blue), what would the fit look like? Is this model appropriate for these data?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n A single normal distribution does not allow bi-modality. Consequently, the fit places a lot of probability in a region with no data. It is not appropriate.\n The single normal fit nicely captures the features of the data. It is appropriate.\n The single normal fit accommodates the bi-modality in the dat, but fails to capture the imbalance in the two components. It is not appropriate.\n The single normal fit ignores the smaller component, fitting the cluster of points with most data. Consequently, the model places almost no probability in the region of the smaller component.\n\nWithout covariates, we would need a more flexible model to capture the bi-modality of these data. A two component mixture of normals would be appropriate.\n\n\n\n\nExercise 56.3  Which of the following histograms shows data that might require a mixture model to fit?Mixture Models\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\n\n\n\n\nThese data were actually drawn from a two component mixture of normal distributions, one with high variance.\n\n\n\n\nExercise 56.4 Mixture Models\nThe Dirichlet distribution with parameters \\alpha_1 = \\alpha_2 = \\ldots = \\alpha_K = 1 is uniform over its support, the values for which the random vector contains a valid set of probabilities. If \\theta contains five probabilities corresponding to five categories and has a \\text{Dirichlet}(1,1,1,1,1) prior, what is the effective sample size of this prior?\nHint: If \\theta has a \\text{Dirichlet}(\\alpha_1, \\alpha_2, \\ldots, \\alpha_K) prior, and the counts of multinomial data in each category are x_1, x_2, \\ldots, x_K, then the posterior of \\theta is \\text{Dirichlet}(\\alpha_1 + x_1, \\alpha_2 + x_2, \\ldots, \\alpha_K + x_K). The data sample size is clearly \\sum_{k=1}^K x_k.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nbased on the hint, what remains is \\sum_{k=1}^K \\alpha_k= 5\n\n\n\n\nExercise 56.5  Recall that in the Bayesian formulation of a mixture model, it is often convenient to introduce latent variables z_i which indicate “population” membership of y_i (the “population” may or may not have meaning in the context of the data). One possible hierarchical formulation is given by:Mixture Models\n\n\\begin{align}\n   y_i \\mid z_i, \\theta & \\overset{\\text{ind}}{\\sim} f_{z_i}(y \\mid \\theta) &i = 1, \\ldots, n\n\\\\ \\text{Pr}(z_i = j \\mid \\omega) &= \\omega_j &j=1, \\ldots, J\n\\\\ \\omega &\\sim Dirichlet(\\omega)\n\\\\ \\theta &\\sim  \\mathbb{P}r(\\theta)\n\\end{align}\n\nwhere f_{j} (y \\mid \\theta) is a probability density for y for mixture component j and w = (w_1, w_2, \\ldots, w_J) is a vector of prior probabilities of membership.\nWhat is the full conditional distribution for z_i?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\text{Pr}(z_i = j \\mid \\cdots ) = \\frac{ f_{j} (y_i \\mid \\theta)\\, w_j } { \\sum_{\\ell=1}^J f_{\\ell} (y_i \\mid \\theta)\\, w_\\ell }\\, , \\quad j=1, \\ldots, J\n\\text{Pr}(z_i = j \\mid \\cdots ) = \\frac{ w_j^{I_{(z_i=j))}} (1-w_j)^{1-I_{(z_i=j))}} } { \\sum_{\\ell=1}^J w_j^{I_{(z_i=j))}} (1-w_j)^{1-I_{(z_i=j))}} }\\, , \\quad j=1, \\ldots, J\n\\text{Pr}(z_i = j \\mid \\cdots ) = w_j \\, , \\quad j=1, \\ldots, J\n\\text{Pr}(z_i = j \\mid \\cdots ) = \\frac{ f_{j} (y_i \\mid \\theta) } { \\sum_{\\ell=1}^J f_{\\ell} (y_i \\mid \\theta) }\\, , \\quad j=1, \\ldots, J\n\nNotice the resemblance with this expression and the discrete version of Bayes’ theorem. This expression is often used in classification problems, where we need to infer membership of y_i to different candidate populations.",
    "crumbs": [
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Homework on Predictive distributions and mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html",
    "href": "C3-L01.html",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "",
    "text": "57.1 Basic Definitions (Video)\nHandout: Mixture model\nMixture models provide a flexible approach to modeling data and are useful in density estimation, clustering and classification problems:\nThe expectation of a mixture is straightforward to compute, as it is a weighted sum of the expectations of the components.\nthe moment generating function of a mixture is also straightforward to compute, as it is a weighted sum of the moment generating functions of the components.\nThe variance of a mixture is not as straightforward to compute, as it involves the second moment of the components and the square of the expectation. However there is a degenerate case where the variance of the mixture is equal to the weighted sum of the variances of the components.",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#sec-basic-definitions",
    "href": "C3-L01.html#sec-basic-definitions",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "",
    "text": "NoteTODO list\n\n\n\n\n\n\nfor each mixture add.\na formula and.\nan example why such a mixture is useful.\nin the graphs consider also plotting the the components in different color as well as the actual mixture.\nadd code for generating the mixtures in basic python.\nadd code for generating the mixtures in PYMC/bambi\nadd all images light box to a gallery - via a regex !?\nas needed extract from the lesson transcript some key points and add them to the notes - via the save note feature on Coursera.\nexplain the two forms of likelihoods.\n\n\n\n\n\n\n\nStandard families of probability distributions such as the Gaussian, exponential or Poisson are often too restrictive for modeling features of real data such as multimodality or zero inflation. Mixture models, which can be related to kernel density estimation procedures, address this issue in a way that allows for natural generalizations of well-known procedures.\nIn addition to providing flexible probability distributions, finite mixture models have a strong relationship with classical clustering and classification procedures such as K-mean clustering, as well as linear and quadratic discriminant analysis. More generally they provide a tool to understand and generalize these approaches, as well as to quantify the uncertainty associated with the estimates and predictions generated by them.",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#introduction-to-mixture-modeling",
    "href": "C3-L01.html#introduction-to-mixture-modeling",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "57.2 Introduction to Mixture modeling",
    "text": "57.2 Introduction to Mixture modeling\n\n57.2.1 Definition of a finite mixture model\n\n\n\n\n\n\n\nFigure 57.1: Mixtures definitions\n\n\n\nDefinition 57.1 Let \\omega_1 , \\ldots , \\omega_K be a collection of real numbers such that 0 \\le \\omega_k \\le 1 and \\sum^K_{k=1} \\omega_k = 1, and G_1, \\ldots, G_K be a collection of cumulative distribution functions. A random variable X with cumulative distribution function F(x) = Pr(X \\le x) of the form\n\nF(x) =\\sum^K_{k=1} \\underbrace{\\omega_k}_{weight}\\ \\cdot \\ \\underbrace{G_k(X)}_{component} \\qquad\n\\tag{57.1}\nis said to follow a finite mixture distribution with K components.\n\nf(x) =\\sum^K_{k=1} \\underbrace{\\omega_k}_{weight}\\ \\cdot \\ \\underbrace{g_k(X)}_{component} \\qquad\n\\tag{57.2}\nwhere g_k(x) is the density associated with G_k(x)\nThe values \\omega_1, \\ldots, \\omega_K are usually called the “weights” of the mixture, and the distributions G_1 , \\ldots, G_K are called the “components” of the mixture.\n\nEach component will typically belong to a parametric family that is indexed by its own parameter \\theta_k .\nWe will write G_k(x) = G_k (x \\mid \\theta_k ) whenever it is necessary to highlight the dependence on these parameters.\nIt is often the case that G_1, \\ldots, G_K all belong to the same family and differ only in the value parameters associated with each of the distributions, so that G_k (x \\mid \\theta_k ) = G(x \\mid \\theta_k ). In that case, the function G (and sometimes its density/probability mass function g) are called the “kernel” of the mixture.",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#three-component-exponential-mixture",
    "href": "C3-L01.html#three-component-exponential-mixture",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "57.3 Three component Exponential mixture",
    "text": "57.3 Three component Exponential mixture\nFor example, we could define a mixture with K = 3 components, with G(x \\mid \\theta_1 ), G(x \\mid \\theta_2 ) and G(x \\mid \\theta_3 ) all corresponding to exponential distributions with means \\theta_1 , \\theta_2 and \\theta_3 respectively.\nIn that case, the cumulative distribution function of the mixture is given by\n\nF(x) = \\left(\\omega_1 \\left[ 1 − e^ {x \\over \\theta_1}\\right] + \\omega_2\\left[ 1 − e^ {x \\over \\theta_2}\\right] + \\omega_3 \\left[ 1 − e^ {x \\over \\theta_3}\\right] \\right)\\mathbb{I}_{x\\ge0} \\qquad\n\\tag{57.3}\n\nf(x) = \\left({\\omega_1\\over \\theta_1} \\left[ 1 − e^ {x \\over \\theta_1}\\right] + {\\omega_2\\over \\theta_2}\\left[ 1 − e^ {x \\over \\theta_2}\\right] + {\\omega_3\\over \\theta_3} \\left[ 1 − e^ {x \\over \\theta_3}\\right] \\right)\\mathbb{I}_{x\\ge0} \\qquad\n\\tag{57.4}",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#sec-mixture-gaussians",
    "href": "C3-L01.html#sec-mixture-gaussians",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "57.4 Mixtures of Gaussians",
    "text": "57.4 Mixtures of Gaussians\nHere we will look at a few examples of mixtures of Gaussians which display different properties not available in a single Gaussian distribution.\n\n57.4.1 Example of a Bimodal mixture of Gaussians\n\nRpython\n\n\n\n\nCode\n# Mixture of univariate Gaussians, bimodal\nx = seq(-5, 12, length=100)\ny = 0.6*dnorm(x, 0, 1) + 0.4*dnorm(x, 5, 2)\n\n\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\n# set the title\ntitle(\"Bimodal Mixture of Gaussians\")\n\n\n\n\n\n\n\n\nFigure 57.8: Bimodal Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# title: Mixture of univariate Gaussians, bimodal\nfrom scipy.stats import norm\n\n# Values to sample\nx = np.linspace(-5, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nstd_1 = 1\nr_n1 = norm.pdf(x,loc = mu_1, scale = std_1)\n# Normal 2 Distribution\nmu_2 = 5\nstd_2 = 2\nr_n2 = norm.pdf(x, loc = mu_2, scale = std_2)\n\n### computing mixture model\nmixture_model = (0.6 * r_n1) + (0.4 * r_n2)\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=mixture_model)\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of two Gaussians')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 57.9: Bimodal Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()\n\n\n\n\n\n\n\n57.4.2 Example of a Uni-modal and skewed mixture of Gaussians\n\nf(x) = 0.55 \\times \\mathcal{N}(0, 2) + 0.45 \\times \\mathcal{N}(3, 4) \\qquad\n\\tag{57.7}\n\nRpython\n\n\n\n\nCode\nx = seq(-5, 12, length=100)\ny = 0.55*dnorm(x, 0, sqrt(2)) + 0.45*dnorm(x, 3, 4)\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\n\n\n\n\n\n\n\n\nFigure 57.10: Uni-modal Skewed Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# Values to sample\nx = np.linspace(-5, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nvar_1 = 2\nr_n1 = norm.pdf(loc = mu_1, scale = np.sqrt(var_1), x = x)\n# Normal 2 Distribution\nmu_2 = 3\nvar_2 = 16\nr_n2 = norm.pdf(loc = mu_2, scale = np.sqrt(var_2), x = x)\n\n### computing mixture model\nmixture_model = (0.55 * r_n1) + (0.45 * r_n2)\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=mixture_model)\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of two Gaussians Skewed')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 57.11: Uni-modal Skewed Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()\n\n\n\n\n\n\n\n57.4.3 Example of a Uni-modal, symmetric and heavy tailed mixture of Gaussians\n\nf(x) = 0.40 \\times \\mathcal{N}(0, 2) + 0.40 \\times \\mathcal{N}(0, 4) + 0.20 \\times \\mathcal{N}(0, 5) \\qquad\n\\tag{57.8}\n\nRpython\n\n\n\n\nCode\n# simulate Mixture of univariate Gaussians, unimodal heavy tail\n\nx = seq(-12, 12, length=100)\ny = 0.40 * dnorm(x, 0, sqrt(2)) + \n    0.40 * dnorm(x, 0, sqrt(16)) + \n    0.20 * dnorm(x, 0, sqrt(20))\nz = dnorm(x, 0, sqrt(0.4*2 + 0.4*16 + 0.2*20))\n\n\n\n\nCode\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\nlines(x, z, lty=2, lwd=2)\nlegend(2, 0.16, c(\"Mixture\",\"Gaussian\"), lty=c(1,2), bty=\"n\", cex=0.77, lwd=c(2,2))\n\n\n\n\n\n\n\n\nFigure 57.12: Unimodal Heavy Tailed Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# Values to sample\nx = np.linspace(-12.0, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nvar_1 = 2\nr_n1 = norm.pdf(loc = mu_1, scale = np.sqrt(var_1), x = x)\n# Normal 2 Distribution\nmu_2 = 0\nvar_2 = 16\nr_n2 = norm.pdf(loc = mu_2, scale = np.sqrt(var_2), x = x)\n# Normal 3 Distribution\nmu_3 = 0\nvar_3 = 20\nr_n3 = norm.pdf(loc = mu_3, scale = np.sqrt(var_3), x = x)\n\n### computing mixture model\ny = (0.4 * r_n1) + (0.4 * r_n2) + (0.2 * r_n3)\nz = norm.pdf(loc = 0, scale = np.sqrt(0.4 * 2 + 0.4 * 16 + 0.2 * 20), x = x)\n\n\n\n\nCode\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=y)\nax.plot(x, z, '--')\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of gaussians heavy tailed')\nplt.legend(['Mixture', 'Gaussian'])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 57.13: Unimodal Heavy Tailed Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#zero-inflated-mixtures",
    "href": "C3-L01.html#zero-inflated-mixtures",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "57.5 Zero Inflated Mixtures",
    "text": "57.5 Zero Inflated Mixtures\n\nZero inflated distributions are useful for modeling data with excess zeros (often in term of count data).\nWe learned in course 1 & 2 that the negative binomial or equivalent beta are zero inflated in comparison to the Poisson distribution.\nToday we see how we use mixture models by adding a point mass at zero to the distribution.\nExample from biology is the number of eggs in a nest.\nExample from insurance is the number of claims in a year.\nExample from survival analysis is the time to event data with a lot of censoring.\n\nNote there are two approaches to zero inflation:\n\none step models like the negative binomial.\nhurdle models - two step models where we first model the zero inflation and then the count data - This corresponds to the hierarchical representation of the mixture model.\n\n\n57.5.1 Example of a Zero-inflated log Gaussian distribution\nThis is a mixture of a point mass at zero and a log Gaussian distribution. This corresponds to the example where we have a light bulb factory and we want to model the time to failure of the light bulbs. We know that for the defective light bulbs, the time to failure is zero. For the non-defective light bulbs, the time to failure is log normally distributed with mean 1.5 and standard deviation 0.5\n\nf(x) = 0.3 \\times \\mathbb{I}_{x\\ge0} + 0.7 \\times \\mathcal{LN}(1.5, 0.5) \\qquad\n\\tag{57.9}\n\nRpython\n\n\n\n\nCode\n## The ZILN model \nx = seq(-2, 15, length=1000)\ny = plnorm(x, 1.5, 0.5)\nz = 0.3*as.numeric(x&gt;=0) + (1-0.3)*y\n\n\n\n\nCode\n## The plot\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", las=1, lty=2, xlab=\"x\", \n     ylab=\"Cumulative distribution Function\", lwd=2)\nlines(x, z, lty=1, lwd=2)\nlegend(4, 0.45, c(\"Zero infla. log Gaussian\",\"log Gaussian\"), \n     lty=c(1,2), bty=\"n\", lwd=c(2,2))\n\n\n\n\n\n\n\n\nFigure 57.14: Zero inflated log Gaussian\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import lognorm\n\n# Zero-inflated continuous distribution\n# Values to sample\nx = np.linspace(-2.0, 15.0, num = 200)\n# See for parameterization\ny = lognorm.pdf(loc = 0, scale = np.exp(1.5), s = 0.5, x = x)\n\n# Point mass vector\np_mass = np.zeros(len(x))\np_mass[x &gt;= 0] = 1\nz = 0.3 * p_mass + (1 - 0.3) * y\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nax.plot(x, y)\nax.plot(x, z, '--')\nplt.xlabel('X')\nplt.ylabel('Cumulative distribution function')\nplt.title('Zero-inflated continuous distribution')\nplt.legend(['Log gaussian', 'Zero infla. Log gaussian'])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 57.15: Zero inflated log Gaussian\n\n\n\n\n\n\n\n\n\n\n57.5.2 Example of a zero-inflated negative binomial distribution\n\nf(x) = 0.2 \\times \\mathbb{I}_{x=0} + 0.8 \\times NB(8, 0.6) \\qquad\n\\tag{57.10}\n\nRpython\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\nx = seq(0, 15)\ny = dnbinom(x, 8, 0.6)\nz = 0.2*c(1,rep(0,length(x)-1)) + (1-0.2)*y\npar(mfrow=c(2,1))\npar(mar=c(4,4,2,2)+0.1)\nbarplot(y, names.arg=x, las=1, xlab = \"x\", ylab=\"Probability\", \n        border=NA, main=\"Negative Binomial\")\npar(mar=c(4,4,1,1)+0.1)\nbarplot(z, names.arg=x, las=1, xlab = \"x\", ylab=\"Probability\", \n        border=NA, main=\"Zero-inflated Negative Binomial\")\n\n\n\n\n\n\n\n\nFigure 57.16: Zero inflated negative binomial\n\n\n\n\n\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\nfrom scipy.stats import nbinom\nimport seaborn as sns\n\n# Values to sample\nx = np.arange(0, 16)\ny = nbinom.pmf(x, n = 8, p = 0.6)\n\n# Plotting the negative binomial model\nfig, ax = plt.subplots(1, 1)\n\nsns.barplot(x=x, y=y, color = 'blue')\n\nplt.title('Negative Binomial')\nplt.xlabel('Count')\nplt.ylabel('PMF')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 57.17: Zero inflated negative binomial\n\n\n\n\n\nCode\n# Point mass vector\np_mass = np.zeros(len(x))\np_mass[0] = 1\nz = 0.2 * p_mass + (1 - 0.2) * y\n\n# Plotting the zero-inflated model\nfig, ax = plt.subplots(1, 1)\nsns.barplot(x=x, y=z, color = 'blue')\nplt.title('Zero-Inflated model')\nplt.xlabel('Count')\nplt.ylabel('PMF')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 57.18: Zero inflated negative binomial",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#hierarchical-representations",
    "href": "C3-L01.html#hierarchical-representations",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "57.6 Hierarchical representations",
    "text": "57.6 Hierarchical representations\n\n\n\n\n\n\n\nFigure 57.19: Hierarchical representation of a mixture\n\n\n\n\n\n\n\n\nFigure 57.20: simulation of a mixture\n\n\n\nRecall that the cumulative distribution function of a mixture takes the form Equation 57.1, where G_k(x) is the cumulative distribution function of the k-th component of the mixture.\nWe can use a RV for each component and introduce an indicator RV for the component selector C_i to select the component from which we will sample. This results in a hierarchical representation of the mixture model.\n\nX \\mid c \\sim g_c(x) \\qquad \\mathbb{P}r(c=k) = \\omega_k \\qquad\n\\tag{57.11}\nwhere C is a categorical random variable with K categories, and G_k(x \\mid C=k) is the cumulative distribution function of the k-th component of the mixture given that we have selected the k-th component.\nThis allows us to write the cumulative distribution function of the mixture as a weighted sum of the cumulative distribution functions of the components\n\n\\mathbb{P}r(x) = \\sum^K_{k=1} \\mathbb{P}r(x \\mid C=k) \\cdot \\mathbb{P}r(C=k) = \\sum^K_{k=1} g_k(x) \\cdot \\omega_k \\qquad\n\\tag{57.12}\nwhere g_k(x) is the cumulative distribution function of the k-th component of the mixture.\n\n57.6.1 Sample code for simulating from a Mixture Model\n\nRpython\n\n\n\n\nCode\n# Generate n observations from a mixture of two Gaussian distributions\nn     = 50           # required sample size\nw     = c(0.6, 0.4)  # mixture weights\nmu    = c(0, 5)      # list of means\nsigma = c(1, 2)      # list of sds\ncc    = sample(1:2, n, replace=T, prob=w) # sample for the component selector\nx     = rnorm(n, mu[cc], sigma[cc]) # sample the selected component\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = seq(-5, 12, length=200)\nyy = w[1] * dnorm(xx, mu[1], sigma[1]) + w[2] * dnorm(xx, mu[2], sigma[2])\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\npoints(x, y=rep(0,n), pch=1, col=cc)\n\n\n\n\n\n\n\n\nFigure 57.21: Mixture of two Gaussians\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom scipy.stats import norm\n\nn=50           # required sample size\nw=[0.6, 0.4]  # mixture weights\nmu=[0, 5]      # list of means\nsigma=[1, 2]  # list of sds\ncc = np.random.choice([0, 1], size=n, p=w) # sample for the component selector\n# sample the selected component\nx = np.array([np.random.normal(mu[i], sigma[i]) for i in cc])\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = np.linspace(-5, 12, num=200)\nyy = w[0]*norm.pdf(loc=mu[0], scale=sigma[0], x=xx) + \\\n     w[1]*norm.pdf(loc=mu[1], scale=sigma[1], x=xx)\nplt.plot(xx, yy, label='Mixture of Gaussians')\nplt.scatter(x, np.zeros(n), c=cc, label='Sampled data')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.title('Mixture of Gaussians')\nplt.legend()\nplt.show() \n\n\n\n\n\n\n\n\nFigure 57.22: Mixture of two Gaussians",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#the-likelihood-function",
    "href": "C3-L01.html#the-likelihood-function",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "57.7 The Likelihood function",
    "text": "57.7 The Likelihood function\n\n\n\n\n\n\n\nFigure 57.23: observed data likelihood\n\n\n\n\n\n\n\n\nFigure 57.24: complete data likelihood\n\n\n\n\nwe are now moving on to inferring the parameters of the mixture model from the observed data.\nwe can estimate these using the maximum likelihood estimation or with Bayesian estimation.\nin both cases we will need to compute the likelihood of the observed data.\nthere are two types of likelihoods:\n\nthe observed data likelihood is the probability of observing the data given the parameters of the model.\nthe complete data likelihood is the probability of observing the data and the latent variables given the parameters of the model.",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01.html#parameter-identifiability",
    "href": "C3-L01.html#parameter-identifiability",
    "title": "57  M1L1 - Definitions of Mixture Models",
    "section": "57.8 Parameter identifiability",
    "text": "57.8 Parameter identifiability\n\n\n\n\n\n\n\nFigure 57.25: Identifiability - Label switching\n\n\n\n\n\n\n\n\nFigure 57.26: identifiability - split weights\n\n\n\n\n\n\n\n\nFigure 57.27: identifiability - zero weights\n\n\n\n\nA probability model is identifiable if and only if different values of the parameters generate different probability distributions of the observable variables.\nOne challenge involved in working with mixture models is that they are not fully identifiable.\nThe problem is that different representations exists for the same mixture.\nQuestion: Is there a “Canonical representation” which fixes this, essentially a convention like:\n1. picking the representation with the least components (no zero weights)\n2. ordered with descending w_i\n\n57.8.1 Label switching\nThe labels used to distinguish the components in the mixture are not identifiable. The literature sometimes refers to this type of lack of identifiability as the label switching “problem”. Whether label switching is an actual problem or not depends on the computational algorithm being used to fit the model, and the task we are attempting to complete in any particular case. For example, label switching tends to not be an issue for the purpose of density estimation or classification problems, but it can lead to serious difficulties in clustering problems.",
    "crumbs": [
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>M1L1 - Definitions of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01-Ex1-Basic-Definitions.html",
    "href": "C3-L01-Ex1-Basic-Definitions.html",
    "title": "58  Basic Concepts of Mixture Models",
    "section": "",
    "text": "Exercise 58.1  \n\nWhich one of the following is not the density of a well defined mixture distribution with support on x \\ge 1 x\n\n\nf(x) = \\frac{1}{2}\\ e^{-x} + \\frac{1}{2} \\frac{1}{\\sqrt{2 \\pi}} \\exp^{-0.5x^2}\nf(x) = \\frac{1}{2}\\ e^{-x} + \\frac{1}{4}\\ e^{-x}\nf(x) = \\frac{1}{2}\\ e^{-x} + \\frac{1}{2}\\ e^{- 0.5 x}\n\nHint: the key here is to write the mixtures with the weights and the normalization constant clearly separated. This reveals that the last one is not a well defined mixture distribution because the weights do not sum to 1 while the the second answer is!\n\n\nExercise 58.2  \n\nWhat is the expected value of a random variable X whose distribution is a mixture of Poisson distributions of the form\n\n\nf(x) = 0.3 \\frac{2^x e^{-2}}{x!}  + 0.45 \\frac{2^x e^{-3}}{x!} + 0.25 \\frac{.5^x e^{-0.5}}{x!}\n\\tag{58.1}\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nE(X) = 0.3 \\cdot 2 + 0.45 \\cdot 3 + 0.25 \\cdot 0.5 = 2.075\n\n\n\n\n\n\nExercise 58.3  \n\nWhat is the variance of an RV X whose distribution is a mixture of Poisson distributions of the form Equation 58.1 ?\n\n\nE(X^2) = 0.3 \\cdot (2+2^2 ) + 0.45 \\cdot (3+3^2) + 0.25 \\cdot (0.5 + 0.5^2)= 7.3875\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nVar(X) = E(X^2) - E(X)^2 = 7.3875 - (2.075)^2 = 3.081875",
    "crumbs": [
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Basic Concepts of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L01-Ex2-Gaussian-mixtures.html",
    "href": "C3-L01-Ex2-Gaussian-mixtures.html",
    "title": "59  Mixtures of Gaussians",
    "section": "",
    "text": "Exercise 59.1 True or False? A scale mixture of normals with density \nf(x) = \\sum_{k=0}^{K} \\omega_k \\frac{1}{\\sqrt{2 \\pi}\\sigma_k} e^{-\\frac{x^2}{\\sigma_k^2}} \\qquad\n\\tag{59.1}\nis always unimodal?\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nTrue\nWe can see from the functional form that this is a sum of K Gaussian densities, with maximum at 0 and monotonically decreasing everywhere else.\n\n\n\n\n\nExercise 59.2 True or False? A scale mixture of normals with density as in Equation 59.1 is always symmetric?\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nTrue\nIf we inspect the functional form we can see that since x is squared in this function, it is symmetric around 0.",
    "crumbs": [
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Mixtures of Gaussians</span>"
    ]
  },
  {
    "objectID": "C3-L01-Ex3-Zero-Inflated-distribution.html",
    "href": "C3-L01-Ex3-Zero-Inflated-distribution.html",
    "title": "60  Zero inflated distributions",
    "section": "",
    "text": "Exercise 60.1 Consider a zero-inflated mixture that involves a point mass at 0 with weight 0.3 and an exponential distribution with mean 1 and weight 0.7. What is the mean of this mixture?\n\n1\n0.7\n0.5\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n0.7\n\n\n\n\n\nExercise 60.2 Consider a zero-inflated mixture that involves a point mass at 0 with weight 0.2 and an exponential distribution with mean 10000 and weight 0.8. If this mixture is used to represent the number of hours a light bulb works between the time it is installed and the time it fails, what is the probability that the bulb was defective when coming out of the factory and does not work when you install it?\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n0.2",
    "crumbs": [
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zero inflated distributions</span>"
    ]
  },
  {
    "objectID": "C3-L01-Ex4-Def-mixture-models.html",
    "href": "C3-L01-Ex4-Def-mixture-models.html",
    "title": "61  Definition of Mixture Models",
    "section": "",
    "text": "Exercise 61.1 Which one of the following is not the density of a well defined mixture distribution with support on the positive integers:\n\nf(x) = \\frac{1}{2} \\frac{e^{-1}}{x!} + \\frac{1}{2} \\frac{e^{-1}}{x!}\nf(x) = 0.5 \\times  \\frac{2^x e^{-2}}{x!} + 0.5 \\times  \\frac{3^x e^{-3}}{x!}\nf(x) = 0.45 \\times  \\frac{2^x e^{-1}}{x!} + 0.55 \\times  \\frac{3^x e^{-3}}{x!}\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\n\nPOISSON(\\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\n\n\\sum_{x=0}^{\\infty} \\frac{2^x e^{-1}}{x!} = e^{-1} \\sum_{x=0}^{\\infty} \\frac{2^x}{x!} = e^{-1} e^{2} = e^{1}\n\n\n\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nthe last one is not a well defined mixture distribution because exponent is has a lambda of 1 but should be 2 to be a poisson distribution.\nActually the answer is not 100% kosher as we have not demonstrated that it is not a well defined mixture distribution - we need to show it doesn’t sum to 1 or is not a valid distribution.\nI have given this fact in the hint above.\n\n\n\n\n\nExercise 61.2 Consider a zero-inflated mixture that involves a point mass at 0 with weight 0.2, a Gamma distribution with mean 1, variance 2 and weight 0.5, and another Gamma distribution with mean 2, variance 4 and weight 0.3. What is the mean of this mixture?\n\n2.5\n1.1\n1.6\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n\nE(X) = 0.2 \\cdot 0 + 0.5 \\cdot 1 + 0.3 \\cdot 2 = 1.1\n\n\n\n\n\n\nExercise 61.3 Consider a zero-inflated mixture that involves a point mass at 0 with weight 0.2, a Gamma distribution with mean 1, variance 2 and weight 0.5, and another Gamma distribution with mean 2, variance 4 and weight 0.3. What is the variance of this mixture?\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n\n\\begin{aligned}\nV[X] &= E[X^2] - E[X]^2\n\\\\ &= (\\sum_{i=1}^{n} w_i Var_{g_k}[X^2_i] + E_{g_k}[X]^2) - E[X]^2\n\\\\ E[X^2] &= 0.2 \\cdot 0^2 + 0.5 \\cdot (1 + 1^2) + 0.3 \\cdot (2 + 4) = 3.9\n\\\\ V[X] &= 3.9 - 1.1^2 = 2.69\n\\end{aligned}\n\n\n\n\n\n\nExercise 61.4 True or False: A mixture of Gaussians of the form\n\nf(x) = 0.3 \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} + 0.7 \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{(x-4)^2}{2}}\n\nhas a bimodal density.\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nAccording to the 68-95-99.7 rule, if two gaussian have means that are separated by distance greater than 1 sd apart, then the mixture should appear bimodal.\n\n\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nTrue. The two gaussians are separated by 4 standard deviations, so the mixture will be bimodal. We can verify this by plotting the density of the mixture.\n\n\nCode\nx = seq(-3, 7, length=100)\ny = 0.3*dnorm(x, 0, 1) + 0.7*dnorm(x, 4, 1)\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 61.5 True or False: Consider a location mixture of normals \nf(x) = \\sum_{k=1}^{K} \\omega_k \\frac{1}{\\sqrt{2 \\pi} \\sigma} e^{-\\frac{(x - \\mu_k)^2}{2 \\sigma^2}}\n\nThe following 3 constraints make all parameters fully identifiable:\n\nThe means \\mu_1,\\ldots,\\mu_k are all different.\nThe weights \\omega_1,\\ldots,\\omega_k are all &gt; 0\nThe components are ordered based on the values of their means, i.e., the component with the smallest \\mu_k is labeled component 1, the one with the second smallest \\mu_k is labeled component 2, etc.\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nTrue.\nThe first and second address the number of components, while the last deals with label switching.",
    "crumbs": [
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Definition of Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L02.html",
    "href": "C3-L02.html",
    "title": "62  M1L2 - Likelihood functions for Mixture Models",
    "section": "",
    "text": "62.1 Hierarchical representations (Video)\nRecall that the cumulative distribution function of a mixture takes the form Equation 57.1, where G_k(x) is the cumulative distribution function of the k-th component of the mixture.\nWe can use a RV for each component and introduce an indicator RV for the component selector C_i to select the component from which we will sample. This results in a hierarchical representation of the mixture model.\nX \\mid c \\sim g_c(x) \\qquad \\mathbb{P}r(c=k) = \\omega_k \\qquad\n\\tag{62.1}\nwhere C is a categorical random variable with K categories, and G_k(x \\mid C=k) is the cumulative distribution function of the k-th component of the mixture given that we have selected the k-th component.\nThis allows us to write the cumulative distribution function of the mixture as a weighted sum of the cumulative distribution functions of the components\n\\mathbb{P}r(x) = \\sum^K_{k=1} \\mathbb{P}r(x \\mid C=k) \\cdot \\mathbb{P}r(C=k) = \\sum^K_{k=1} g_k(x) \\cdot \\omega_k \\qquad\n\\tag{62.2}\nwhere g_k(x) is the cumulative distribution function of the k-th component of the mixture.",
    "crumbs": [
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>M1L2 - Likelihood functions for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L02.html#sec-hierarchical-representation",
    "href": "C3-L02.html#sec-hierarchical-representation",
    "title": "62  M1L2 - Likelihood functions for Mixture Models",
    "section": "",
    "text": "Figure 62.1: Hierarchical representation of a mixture\n\n\n\n\n\n\n\n\nFigure 62.2: simulation of a mixture\n\n\n\n\n\n\n\n\n\n\n\n62.1.1 Sample code for simulating from a Mixture Model\n\nRpython\n\n\n\n\nCode\n# Generate n observations from a mixture of two Gaussian distributions\nn     = 50           # required sample size\nw     = c(0.6, 0.4)  # mixture weights\nmu    = c(0, 5)      # list of means\nsigma = c(1, 2)      # list of sds\ncc    = sample(1:2, n, replace=T, prob=w) # sample for the component selector\nx     = rnorm(n, mu[cc], sigma[cc]) # sample the selected component\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = seq(-5, 12, length=200)\nyy = w[1] * dnorm(xx, mu[1], sigma[1]) + w[2] * dnorm(xx, mu[2], sigma[2])\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\npoints(x, y=rep(0,n), pch=1, col=cc)\n\n\n\n\n\n\n\n\nFigure 62.3: Mixture of two Gaussians\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom scipy.stats import norm\n\nn=50           # required sample size\nw=[0.6, 0.4]  # mixture weights\nmu=[0, 5]      # list of means\nsigma=[1, 2]  # list of sds\ncc = np.random.choice([0, 1], size=n, p=w) # sample for the component selector\n# sample the selected component\nx = np.array([np.random.normal(mu[i], sigma[i]) for i in cc])\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = np.linspace(-5, 12, num=200)\nyy = w[0]*norm.pdf(loc=mu[0], scale=sigma[0], x=xx) + \\\n     w[1]*norm.pdf(loc=mu[1], scale=sigma[1], x=xx)\nplt.plot(xx, yy, label='Mixture of Gaussians')\nplt.scatter(x, np.zeros(n), c=cc, label='Sampled data')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.title('Mixture of Gaussians')\nplt.legend()\nplt.show() \n\n\n\n\n\n\n\n\nFigure 62.4: Mixture of two Gaussians",
    "crumbs": [
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>M1L2 - Likelihood functions for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L02.html#the-likelihood-function",
    "href": "C3-L02.html#the-likelihood-function",
    "title": "62  M1L2 - Likelihood functions for Mixture Models",
    "section": "62.2 The Likelihood function",
    "text": "62.2 The Likelihood function\n\n\n\n\n\n\n\nFigure 62.5: observed data likelihood\n\n\n\n\n\n\n\n\nFigure 62.6: complete data likelihood\n\n\n\n\nwe are now moving on to inferring the parameters of the mixture model from the observed data.\nwe can estimate these using the maximum likelihood estimation or with Bayesian estimation.\nin both cases we will need to compute the likelihood of the observed data.\nthere are two types of likelihoods:\n\nthe observed data likelihood is the probability of observing the data given the parameters of the model.\nthe complete data likelihood is the probability of observing the data and the latent variables given the parameters of the model.",
    "crumbs": [
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>M1L2 - Likelihood functions for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L02.html#parameter-identifiability",
    "href": "C3-L02.html#parameter-identifiability",
    "title": "62  M1L2 - Likelihood functions for Mixture Models",
    "section": "62.3 Parameter identifiability",
    "text": "62.3 Parameter identifiability\n\n\n\n\n\n\n\nFigure 62.7: Identifiability - Label switching\n\n\n\n\n\n\n\n\nFigure 62.8: identifiability - split weights\n\n\n\n\n\n\n\n\nFigure 62.9: identifiability - zero weights\n\n\n\n\nA probability model is identifiable if and only if different values of the parameters generate different probability distributions of the observable variables.\nOne challenge involved in working with mixture models is that they are not fully identifiable.\nThe problem is that different representations exists for the same mixture.\nQuestion: Is there a “Canonical representation” which fixes this, essentially a convention like:\n1. picking the representation with the least components (no zero weights)\n2. ordered with descending w_i\n\n62.3.1 Label switching\nThe labels used to distinguish the components in the mixture are not identifiable. The literature sometimes refers to this type of lack of identifiability as the label switching “problem”. Whether label switching is an actual problem or not depends on the computational algorithm being used to fit the model, and the task we are attempting to complete in any particular case. For example, label switching tends to not be an issue for the purpose of density estimation or classification problems, but it can lead to serious difficulties in clustering problems.",
    "crumbs": [
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>M1L2 - Likelihood functions for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex1.html",
    "href": "C3-L02-Ex1.html",
    "title": "63  HW - The likelihood function",
    "section": "",
    "text": "Consider a random sample (3.5,9.7,8.2,6.4,7.1) composed of n=5 observations form the mixture with density:\nf(x)=w\\lambda_1 e^{-\\lambda_1 x} + (1-w)\\lambda_2 e^{-\\lambda_2 x}\n\nWhat is the complete-data likelihood associated with the indicator vector (1,1,2,1,2)\n\nw^{(1-w)^4} \\lambda_1 e^{-22.7 \\lambda_1} \\lambda_2^4 e^{-11.3\\lambda_2}\nw^3(1-w)^2 \\lambda_1^2 e^{-15.3\\lambda_1} \\lambda_2^3 e^{-19.6\\lambda_2}\nw^3(1-w)^2 \\lambda_1^3 e^{-19.6\\lambda_1} \\lambda_2^2 e^{-15.3\\lambda_2}\n\n\nConsider a random sample (3.5,9.7,7.1) composed of n=3 observations form the mixture with density: \nf(x)=w\\lambda_1 e^{-\\lambda_1 x} + (1-w)\\lambda_2 e^{-\\lambda_2 x}\n\n\nThe observed-data likelihood L_{O}(w,\\lambda_1,\\lambda_2;x) for this sample is given by the product\n\\begin{align*}\n& \\left\\{ w\\lambda_1 e^{-\\lambda_1 3.5} + (1-w)\\lambda_2 e^{-\\lambda_2 3.5} \\right\\} \\\\\n\\times &\\left\\{ w\\lambda_1 e^{-\\lambda_1 9.7} + (1-w)\\lambda_2 e^{-\\lambda_2 9.7} \\right\\} \\\\\n\\times &\\left\\{ w\\lambda_1 e^{-\\lambda_1 7.1} + (1-w)\\lambda_2 e^{-\\lambda_2 7.1} \\right\\}\n\\end{align*}\n\n\nyes\nno",
    "crumbs": [
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>HW - The likelihood function</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex2.html",
    "href": "C3-L02-Ex2.html",
    "title": "64  HW - Identifiability",
    "section": "",
    "text": "The number of components in a mixture model is an identifiable parameter\n\n\n[] yes\nno\n\n\nThe labels of the mixture components are identifiable parameters\n\n\nyes\n[x ] no",
    "crumbs": [
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>HW - Identifiability</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex3.html",
    "href": "C3-L02-Ex3.html",
    "title": "65  HW - The likelihood function",
    "section": "",
    "text": "Consider a random sample (−0.3,4.1,3.6,7.5,1.9,2.7) composed of n=6 observations form the mixture with density: \nf(x)=w_1 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{x^2}{2}\\right\\} + w_2 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{(x-2)^2}{2}\\right\\} + w_3 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{(x-4)^2}{2}\\right\\}\n 0 What is the complete-data likelihood associated with the indicator vector (1,2,2,3,1,2)\n\n\nw_1^2 w_2^2 w_3 \\exp\\{-11.705\\}\nw_1^3 w_2^1 w_3^2 \\exp\\{-11.705\\}\nw_1^2 w_2^3 w_3 \\exp\\{-23.41\\}\nw_1^3 w_2 w_3^2 \\exp\\{-23.41\\}\n\n\nTrue or False: Consider a location mixture of normals\n\n\nf(x)=\\sum_{k=1}^{K} \\omega_k \\frac{1}{\\sqrt{2\\pi}} \\sigma^{-1} \\exp\\left\\{-\\frac{(x-\\mu_k)^2}{2\\sigma^2}\\right\\}\n\nThe following 3 constraints make all parameters fully identifiable:\n\nThe means \\mu_1,\\ldots,\\mu_K should all be different.\nNo weight \\omega_k is allowed to be zero.\nThe component are ordered based on the values of their means, i.e., the component with the smallest \\mu_k is labeled component 1, the one with the second smallest \\mu_k is labeled component 2, etc.\n\n\nTrue\nFalse",
    "crumbs": [
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>HW - The likelihood function</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex4.html",
    "href": "C3-L02-Ex4.html",
    "title": "66  HW - Simulating from a Mixture Model",
    "section": "",
    "text": "66.1 HW - Simulation of Poisson mixture model\nCode\n# Generate n observations from a mixture of three poisson distributions\n1set.seed(452)\n2n = 200\n3w = c(0.7,0.2,0.1)\n4lambda = c(1,2,6)\n\n5ac = sample(1:3,n, replace=T, prob=w)\n6x = rpois(n,lambda=lambda[ac])\n\n\n\n1\n\nEnsure simulation is reproducible\n\n2\n\nSet sample size to 50\n\n3\n\nSet weights for the Poisson distributions\n\n4\n\nSet the means for the Poisson distributions\n\n5\n\nSample the active component for each observation in the sample\n\n6\n\nsimulate an ac mixture component n times\nCode\nempfreq = table(x)/n\npar(mar=c(4,4,1,1) + 0.1)\n#barplot(empfreq)\nbarplot(empfreq,xlab=\"counts\",ylab=\"probability\",main=\"Empirical distribution for Poisson mixture\")\n\n\n\n\n\n\n\n\nFigure 66.1: Empirical distribution for Poisson mixture",
    "crumbs": [
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>HW - Simulating from a Mixture Model</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex4.html#hw---simulation-of-poisson-mixture-model",
    "href": "C3-L02-Ex4.html#hw---simulation-of-poisson-mixture-model",
    "title": "66  HW - Simulating from a Mixture Model",
    "section": "",
    "text": "NoteInstructions\n\n\n\n# Generate n observations from a mixture of two Gaussian \n# distributions\nn     = 50           # Size of the sample to be generated\nw     = c(0.6, 0.4)  # Weights\nmu    = c(0, 5)      # Means\nsigma = c(1, 2)      # Standard deviations\ncc    = sample(1:2, n, replace=T, prob=w)\nx     = rnorm(n, mu[cc], sigma[cc])\n    \n# Plot f(x) along with the observations \n# just sampled\nxx = seq(-5, 12, length=200)\nyy = w[1]*dnorm(xx, mu[1], sigma[1]) + \n     w[2]*dnorm(xx, mu[2], sigma[2])\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\npoints(x, y=rep(0,n), pch=1)  \n\nModify the code above to sample 200 random numbers from a mixture of 3 Poisson distributions with means 1, 2 and 6 and weights 0.7, 0.2 and 0.1, respectively, and\ngenerate a barplot with the empirical frequencies of all the integers included in the sample.\n\n\n\n\nEnter code to sample 200 random numbers from a mixture of 3 Poisson distributions with means 1, 2 and 6 and weights 0.7, 0.2 and 0.1, respectively\n\n\n\nPlot the empirical distribution",
    "crumbs": [
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>HW - Simulating from a Mixture Model</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex5.html",
    "href": "C3-L02-Ex5.html",
    "title": "67  HW - Simulation of Poisson mixture model",
    "section": "",
    "text": "67.1 HW - Simulation of Poisson mixture model\nCode\n# Generate n observations from a mixture of three poisson distributions\nset.seed(452)\n\n\n# n     = 50\nn = 200                # sample size\n# w     = c(0.6, 0.4)  # Weights\nw = c(0.7,0.2,0.1)     # weights\n# mu    = c(0, 5)      # Means\n# sigma = c(1, 2)      # Standard deviations\nlambda = c(1,2,6)      # lambda params (mean,variation)\n\n\n\n#cc    = sample(1:2, n, replace=T, prob=w)\nac     = sample(1:length(w),n, replace=T, prob=w) # sample the active component\n#x     = rnorm(n, mu[cc], sigma[cc])\nx      = rpois(n,lambda=lambda[ac])                # simulate an ac mixture component n time\n\n\n#First converting the vector x into a factor while ensuring that any integer between 0 and the maximum in the sample are valid factors avoids the issue of ignoring zero counts or x=0.\n\n#empfreq = table(factor(x, levels=seq(0, max(x))))/n\nempirical_feqs = table(factor(x, levels=seq(0, max(x)))) # tabulate samples into a counts\nempirical_dist = empirical_feqs /n # convert frequencies to probabilities\nPlot the empirical distribution\nCode\npar(mar=c(4,4,1,1) + 0.1)\n#barplot(empfreq)\nbarplot(empirical_dist,xlab=\"counts\",ylab=\"probability\",main=\"Empirical distribution for Poisson mixture\")\n\n\n\n\n\n\n\n\nFigure 67.1: Empirical distribution for Poisson mixture\nCode\nempirical_feqs = table( factor(x, levels=seq(0, max(x)))) # tabulate samples into counts\nempirical_dist = empirical_feqs /n # convert frequencies to probabilities\n\nbarplot(empirical_dist,xlab=\"counts\",ylab=\"probability\",main=\"Empirical poisson mixture\")\n\n\n\n\n\n\n\n\nFigure 67.2",
    "crumbs": [
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>HW - Simulation of Poisson mixture model</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex5.html#hw---simulation-of-poisson-mixture-model",
    "href": "C3-L02-Ex5.html#hw---simulation-of-poisson-mixture-model",
    "title": "67  HW - Simulation of Poisson mixture model",
    "section": "",
    "text": "NoteInstructions\n\n\n\n# Generate n observations from a mixture of two Gaussian \n# distributions\nn     = 50           # Size of the sample to be generated\nw     = c(0.6, 0.4)  # Weights\nmu    = c(0, 5)      # Means\nsigma = c(1, 2)      # Standard deviations\ncc    = sample(1:2, n, replace=T, prob=w)\nx     = rnorm(n, mu[cc], sigma[cc])\n    \n# Plot f(x) along with the observations \n# just sampled\nxx = seq(-5, 12, length=200)\nyy = w[1]*dnorm(xx, mu[1], sigma[1]) + \n     w[2]*dnorm(xx, mu[2], sigma[2])\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\npoints(x, y=rep(0,n), pch=1)  \n\nModify the code above to sample 200 random numbers from a mixture of 3 Poisson distributions with means 1, 2 and 6 and weights 0.7, 0.2 and 0.1, respectively,\ngenerate a barplot with the empirical frequencies of all the integers included in the sample.",
    "crumbs": [
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>HW - Simulation of Poisson mixture model</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex6.html",
    "href": "C3-L02-Ex6.html",
    "title": "68  HW+ - Sim mixture of exponential distributions",
    "section": "",
    "text": "68.1 HW+ - Sim mixture of exponential distributions\nCode\nset.seed(238)                            # reproducibility\nn &lt;- 100                                  # the sample size\nw &lt;- c(0.3, 0.25, 0.25,  0.2)        # weights\nlambda &lt;- c(1, 4, 7 , 10)                 # means\nrates &lt;- 1 / lambda                       # inverses of the means\nac &lt;- sample (1:length(w), n, replace=T, prob =w) # smaple the active component\nx &lt;- rexp(n,rate = rates[ac])            # sample from the exponential distribution\nnext we use the samples to estimate the mean and variance of the mixture\nCode\n(sample_mean=mean(x))\n\n\n[1] 6.184079\n\n\nCode\n(sample_variance=var(x))\n\n\n[1] 77.21339",
    "crumbs": [
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>HW+ - Sim mixture of exponential distributions</span>"
    ]
  },
  {
    "objectID": "C3-L02-Ex6.html#hw---sim-mixture-of-exponential-distributions",
    "href": "C3-L02-Ex6.html#hw---sim-mixture-of-exponential-distributions",
    "title": "68  HW+ - Sim mixture of exponential distributions",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nModify code to Generate n observations from a mixture of two Gaussian # distributions into code to sample 100 random numbers from a mixture of 4 exponential distributions with means 1, 4, 7 and 10 and weights 0.3, 0.25, 0.25 and 0.2, respectively.\nUse these sample to approximate the mean and variance of the mixture.",
    "crumbs": [
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>HW+ - Sim mixture of exponential distributions</span>"
    ]
  },
  {
    "objectID": "C3-L03.html",
    "href": "C3-L03.html",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "",
    "text": "70 The EM algorithm for Mixture Models (Video)\nMaximum likelihood estimation is the most common approach to estimate the parameters of statistical models. However, attempting to obtain maximum likelihood estimates (MLEs) \\hat{\\omega} and \\hat{\\theta} by directly maximizing the observed-data likelihood\n\\mathcal{L}(\\omega,\\theta) = \\arg \\max_{\\omega,\\theta}\n\\prod_{i=1}^{n} \\sum_{k=1}^{K} \\omega_k g_k(x_i|\\theta_k)\nis not feasible, as it is a non-convex optimization problem.\nUsing numerical optimization methods, such as the Newton-Raphson algorithm, can be challenging due when there are many components in the mixture.\nIt worthwhile mentioning that MLE is more of a frequentist approach, as it provides point estimates of the parameters rather than a distributional view. In contrast, Bayesian methods we will consider later provide a full posterior distribution of the parameters, which is more informative and allows for uncertainty quantification.",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#em-algorithms-for-mixture-models",
    "href": "C3-L03.html#em-algorithms-for-mixture-models",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.1 EM algorithms for Mixture Models",
    "text": "70.1 EM algorithms for Mixture Models\n\n\n\n\nEM - Challenge\n\n\n\n\nEM - Steps\n\n\n\n\nEM - Deep Dive\n\n\n\nEM algorithm comes up a lot in NLP and other fields so it is worthwhile to understand it the way we will do so in the course.\nIt also important that the EM algorithm we use for mixture models is from the 1970s and is not the same as the general EM algorithm. c.f. (Dempster, Laird, and Rubin 1977)\nThe EM algorithm is iterative and consists of two steps: the E-step and the M-step. The E-step computes the expected value of the complete-data log-likelihood given the observed data and the current parameter estimates, while the M-step maximizes this expected log-likelihood with respect to the parameters. However before we start these steps we need to set initial values for the parameters.\nE step: Set\n\nQ(\\omega,\\theta \\mid \\omega^{(t)}, \\theta^{(t)},x) = E_{c \\mid \\omega^{(t)},\\theta^{(t)}, x} \\left[ \\log \\mathbb{P}r(x,c \\mid \\omega,\\theta) \\right]\n\\tag{70.1}\nWhere c is the latent variable indicating the component from which each observation was generated, \\omega are the weights, and \\theta are the parameters of the Gaussian components (means and standard deviations).\nM step: Set\n\n\\hat{\\omega}^{(t+1)},\\hat{\\theta}^{(t+1)} = \\arg \\max_{\\omega,\\theta} Q(\\omega,\\theta \\mid \\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)},y)\n\\tag{70.2}\nwhere \\hat{\\omega}^{(t)} and \\hat{\\theta}^{(t)} are the current estimates of the parameters, and y is the observed data.\nThese two steps are repeated until convergence, which is typically defined as the change in the full-data log-likelihood Q function being below a certain threshold.\nA key point is that if we condition each component independently on the \\omega, \\theta, x we can write\n\n\\mathbb{P}r(c_i=k \\mid \\omega, \\theta, x_i) = \\frac{\\omega_k g_k(x_i \\mid \\theta_k)}{\\sum_{j=1}^{K} \\omega_j g_j(x_i \\mid \\theta_j)}= v_{ik}(\\omega, \\theta)\n\nwhere the value of v_{ik} is interpreted as the probability that the i-th observation comes from the k-th component of the mixture assuming the population parameters \\omega and \\theta.",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#em-for-general-mixture",
    "href": "C3-L03.html#em-for-general-mixture",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.2 EM for general Mixture",
    "text": "70.2 EM for general Mixture",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#em-for-location-mixture-of-gaussians",
    "href": "C3-L03.html#em-for-location-mixture-of-gaussians",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.3 EM for location Mixture of Gaussians",
    "text": "70.3 EM for location Mixture of Gaussians\n\n\n\n\nthe responsibility\n\n\n\n\nthe derivative of Q wrt to w\n\n\n\n\nthe derivative of Q wrt to mu\n\n\n\n\nthe derivative of Q wrt to sigma",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#sec-em-example-1",
    "href": "C3-L03.html#sec-em-example-1",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.4 EM example 1",
    "text": "70.4 EM example 1\nThis video covers the code sample given in Listing 70.4 below. It is a simple implementation of the EM algorithm for fitting a 2-component Gaussian location mixture model to simulated data.\n\nThis code sample is both cool and awkward.\n\nIt is cool because it provides a step-by-step implementation of the EM algorithm, which is a fundamental concept in statistics and machine learning.\nIt is not broken in to functions lacks useful variables naming which would reduce the amounts of comments and cognitive load.\n\nHowever it does provide nice visualizations of the EM algorithm in action - particularly if run inside of RStudio IDE (as shown in the video).\nwould be interesting to make the number of components be drawn from a distribution rather than fixed at 2, then run the EM algorithm for multiple draws and pick the one with the best fit.\nLater on we learn about using BIC to select the number of components in a mixture model, which is a more principled approach than simply fixing the number of components at 2. However it stills seems that the number of components might be a RV even if it’s prior would be centred at the BIC estimate.",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#sec-em-code-example-1",
    "href": "C3-L03.html#sec-em-code-example-1",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.5 Sample code for EM example 1",
    "text": "70.5 Sample code for EM example 1\n\n\n\n\nListing 70.1: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\n\n## Step 0 - Generate data from a mixture with 2 components:\n\n## Ground Truth parameters initialization\nKK         = 2          # Number of components of the mixture\nw.true     = 0.6        # GT True weights associated with the components\nmu.true    = rep(0, KK) # initialize the true means list\nmu.true[1] = 0   # GT mean for the first component\nmu.true[2] = 5   # GT mean for the second component\nsigma.true = 1   # GT standard deviation of all components\n\nn  = 120         # Number of synthetic samples to generate\n\n# simulate the latent variables for the component indicator function\ncc = sample(1:KK, n, replace=T, prob=c(w.true,1-w.true))\nx  = rep(0, n)   # initialize the data vector x (or load data)\n\nfor(i in 1:n){ # for each observation\n  # sample from a distribution with mean selected by component indicator\n  # the SD is the same for all components as this is a location mixture\n  x[i] = rnorm(1, mu.true[cc[i]], sigma.true)\n}\n\n# Plot the true density\npar(mfrow=c(1,1))\nxx.true = seq(-8,11,length=200)\nyy.true = w.true*dnorm(xx.true, mu.true[1], sigma.true) + \n          (1-w.true)*dnorm(xx.true, mu.true[2], sigma.true) \nplot(xx.true, yy.true, type=\"l\", xlab=\"x\", ylab=\"True density\", lwd=2)\npoints(x, rep(0,n), col=cc)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 70.2: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\n## Run the actual EM algorithm\n## Initialize the parameters\nw     = 1/2                         #Assign equal weight to each component to start with\nmu    = rnorm(KK, mean(x), sd(x))   #Random cluster centers randomly spread over the support of the data\nsigma = sd(x)                       #Initial standard deviation\n\n# Plot the initial guess for the density\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(yy)), xlab=\"x\", ylab=\"Initial density\")\npoints(x, rep(0,n), col=cc)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 70.3: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\ns  = 0\nsw = FALSE\nQQ = -Inf\nQQ.out = NULL\nepsilon = 10^(-5)\n\n\n##Checking convergence of the algorithm\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  v[,1] = log(w) + dnorm(x, mu[1], sigma, log=TRUE)    #Compute the log of the weights\n  v[,2] = log(1-w) + dnorm(x, mu[2], sigma, log=TRUE)  #Compute the log of the weights\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  # Weights\n  w = mean(v[,1])\n  mu = rep(0, KK)\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Standard deviations\n  sigma = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n    }\n  }\n  sigma = sqrt(sigma/sum(v))\n  \n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    QQn = QQn + v[i,1]*(log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)) +\n                v[i,2]*(log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE))\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n  #Plot current estimate over data\n  layout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\n  par(mar=c(3.1,4.1,0.5,0.5))\n  plot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n  \n  par(mar=c(5,4,1.5,0.5))\n  xx = seq(-8,11,length=200)\n  yy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\n  plot(xx, yy, type=\"l\", ylim=c(0, max(c(yy,yy.true))), main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), lwd=2, col=\"red\", lty=2, xlab=\"x\", ylab=\"Density\")\n  lines(xx.true, yy.true, lwd=2)\n  points(x, rep(0,n), col=cc)\n  legend(6,0.22,c(\"Truth\",\"Estimate\"),col=c(\"black\",\"red\"), lty=c(1,2))\n}\n\n\n\n\n\n[1] \"1 -343.425690465737\"\n\n\n\n\n\n\n\n\n\n[1] \"2 -339.993932553505\"\n\n\n\n\n\n\n\n\n\n[1] \"3 -333.742916535535\"\n\n\n\n\n\n\n\n\n\n[1] \"4 -322.087405606262\"\n\n\n\n\n\n\n\n\n\n[1] \"5 -299.927704463736\"\n\n\n\n\n\n\n\n\n\n[1] \"6 -265.515667629269\"\n\n\n\n\n\n\n\n\n\n[1] \"7 -246.004047691222\"\n\n\n\n\n\n\n\n\n\n[1] \"8 -243.982291955643\"\n\n\n\n\n\n\n\n\n\n[1] \"9 -243.880207718536\"\n\n\n\n\n\n\n\n\n\n[1] \"10 -243.873888447856\"\n\n\n\n\n\n\n\n\n\n[1] \"11 -243.873372520873\"\n\n\n\n\n\n\n\n\n\n\n\nListing 70.4: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\n#Plot final estimate over data\nlayout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\npar(mar=c(3.1,4.1,0.5,0.5))\nplot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n\npar(mar=c(5,4,1.5,0.5))\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(c(yy,yy.true))), main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), lwd=2, col=\"red\", lty=2, xlab=\"x\", ylab=\"Density\")\nlines(xx.true, yy.true, lwd=2)\npoints(x, rep(0,n), col=cc)\nlegend(6,0.22,c(\"Truth\",\"Estimate\"),col=c(\"black\",\"red\"), lty=c(1,2), bty=\"n\")",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#em-example-2",
    "href": "C3-L03.html#em-example-2",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.6 EM example 2",
    "text": "70.6 EM example 2",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#sample-code-for-em-example-2",
    "href": "C3-L03.html#sample-code-for-em-example-2",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.7 Sample code for EM example 2",
    "text": "70.7 Sample code for EM example 2\nThis variant differs from the code sample above in that it uses the mvtnorm package to generate multivariate normal distributions. It also uses the ellipse package to plot the ellipses around the means of the components.\n\n\nCode\n#### Example of an EM algorithm for fitting a mixtures of K p-variate Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)    # Multivariate normals are not default in R\nlibrary(ellipse)    # Required for plotting\nset.seed(63252)     # For reproducibility\n\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nn  = 120\ncc = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc[i],], Sigma.true[cc[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc, type=\"n\", xlab=expression(x[1]), ylab=expression(x[2]))\ntext(x[,1], x[,2], seq(1,n), col=cc, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\n\n\n\n\n\n\n\n\n\nCode\n#title(main=\"Data + True Components\")\n\n\n### Run the EM algorithm\n## Initialize the parameters\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\ns       = 0\nsw      = FALSE\nQQ      = -Inf\nQQ.out  = NULL\nepsilon = 10^(-5)\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(k in 1:KK){\n    v[,k] = log(w[k]) + dmvnorm(x, mu[k,], Sigma[k,,],log=TRUE)  #Compute the log of the weights\n  }\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w     = apply(v,2,mean)\n  mu    = array(0, dim=c(KK, p))\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0, dim=c(KK, p, p))\n  for(k in 1:KK){\n    for(i in 1:n){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      QQn = QQn + v[i,k]*(log(w[k]) + dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n  #Plot current components over data\n  layout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\n  par(mar=c(3.1,4.1,0.5,0.5))\n  plot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\")\n  \n  par(mar=c(5,4,1,0.5))\n  plot(x[,1], x[,2], col=cc, main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), \n       xlab=expression(x[1]), ylab=expression(x[2]), lwd=2)\n  for(k in 1:KK){\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n  }\n}\n\n\n[1] \"1 -582.05125374123\"\n\n\n\n\n\n\n\n\n\n[1] \"2 -559.067366495985\"\n\n\n\n\n\n\n\n\n\n[1] \"3 -543.8803866857\"\n\n\n\n\n\n\n\n\n\n[1] \"4 -527.840823447868\"\n\n\n\n\n\n\n\n\n\n[1] \"5 -511.540892774085\"\n\n\n\n\n\n\n\n\n\n[1] \"6 -483.797796090743\"\n\n\n\n\n\n\n\n\n\n[1] \"7 -464.070439621255\"\n\n\n\n\n\n\n\n\n\n[1] \"8 -455.865736477295\"\n\n\n\n\n\n\n\n\n\n[1] \"9 -455.214732499627\"\n\n\n\n\n\n\n\n\n\n[1] \"10 -455.176042939796\"\n\n\n\n\n\n\n\n\n\n[1] \"11 -455.171446608628\"\n\n\n\n\n\n\n\n\n\n[1] \"12 -455.170550189128\"\n\n\n\n\n\n\n\n\n\nCode\n#Plot current components over data\nlayout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\npar(mar=c(3.1,4.1,0.5,0.5))\nplot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n\npar(mar=c(5,4,1,0.5))\nplot(x[,1], x[,2], col=cc, main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#sec-mixture-of-log-gaussians",
    "href": "C3-L03.html#sec-mixture-of-log-gaussians",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.8 Mixture of Log Gaussians",
    "text": "70.8 Mixture of Log Gaussians\n\n\n\n\n\n\nNotePrompt\n\n\n\n\n\nIf your data had support on the positive real numbers rather than the whole real line, how could you use the EM algorithm you just learned to instead fit a mixture of log-Gaussian distributions? Would you need to recode your algorithm?\n\nResponse\nUpdating the algorithm is nontrivial - it requires derivatives for each parameter. Depending on the distribution, we may need to add custom code to update each. We also need to update the distribution if these are changed.\nSo while the algorithm does not change, the code may change quite a bit.",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03.html#sec-advanced-em-algorithms",
    "href": "C3-L03.html#sec-advanced-em-algorithms",
    "title": "69  M2L3 - The EM algorithm for Mixture models",
    "section": "70.9 Advanced EM algorithms",
    "text": "70.9 Advanced EM algorithms\n\n70.9.1 HW: The EM for ZIP mixtures\nData on the lifetime (in years) of fuses produced by the ACME Corporation is available in the file fuses.csv:\nProvide the EM algorithm to fit the mixture model\n\n\n70.9.2 HW+: The EM for Mixture Models\n\n\n\n\n\n\nDempster, Arthur P, Nan M Laird, and Donald B Rubin. 1977. “Maximum Likelihood from Incomplete Data via the EM Algorithm.” Journal of the Royal Statistical Society: Series B (Methodological) 39 (1): 1–22.",
    "crumbs": [
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>M2L3 - The EM algorithm for Mixture models</span>"
    ]
  },
  {
    "objectID": "C3-L03-Ex1.html",
    "href": "C3-L03-Ex1.html",
    "title": "70  The EM algorithm for Zero-Inflated Mixtures",
    "section": "",
    "text": "70.1 HW - Simulation of Poisson mixture model\nIn the lessons we mentioned that Zero-Inflated Poisson (ZIP) models arises naturally in biology when analyzing nest size data since many birds fail to mate or lay eggs. As such they will have zero eggs in their nests. In this exercise, we will use the EM algorithm to fit a ZIP model to a dataset of nest sizes.\nCode\n# Load the nest size data\n\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\nnestsize &lt;- read.csv(\"data/nestsize.csv\",header=FALSE)\ncolnames(nestsize) &lt;- c(\"n\")\nx &lt;- nestsize$n\nn &lt;- length(x) # Number of observations\n# how many rows in the data\nnrow(nestsize)\n\n\n[1] 300\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 128\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, breaks=seq(0, max(x), by=1), freq=FALSE, xlab=\"Number of eggs\", ylab=\"Density\", main=\"Empirical distribution of nest sizes\")\nCode\n# EM algorithm for fitting a ZIP\n\n## Run the actual EM algorithm\n## Initialize the parameters\nKK         = 2                     # Number of components\nw     = 1/2                        # equal weights                     #Initial standard deviation\n\nlambda = mean(x) # initial guess for the mean\n\ns  = 0\nsw = FALSE\nQQ = -Inf\nQQ.out = NULL\nepsilon = 10^(-5)\n\nwhile(!sw){ ## run until convergence switch becomes TRUE\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(i in 1:n){\n    if (x[i] == 0){\n      # if the observation is zero it may be due to either component so we assign each a value based on the weights * pdf\n      v[i,1] = w * 1 # delta is 1 at zero\n      v[i,2] = (1-w) * dpois(x[i], lambda) # the weight for the second component\n      v[i,] = v[i,]/sum(v[i,]) # normalize \n    } else {\n      v[i,1] = 0\n      v[i,2] = 1\n      # normalized\n    }\n  }\n  \n  ## M step\n  # Weights\n  w = mean(v[,1]) \n  # parameters\n  lambda = sum(x)/sum(v[,2]) # normalize\n  \n  ##Check convergence\n  ## QQn is the new value of the Q function\n  ## QQ is the old value of the Q function\n  QQn = 0\n  for(i in 1:n){\n    if(x[i] == 0){\n      # log is used to avoid numerical underflow\n      QQn = QQn + v[i,1]*log(w) + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }else{\n      QQn = QQn + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n\n}\n\n\n[1] \"1 -576.591134395629\"\n[1] \"2 -560.13333821497\"\n[1] \"3 -555.36650787464\"\n[1] \"4 -554.153118451655\"\n[1] \"5 -553.854920699012\"\n[1] \"6 -553.78227912419\"\n[1] \"7 -553.764621578937\"\n[1] \"8 -553.760331674038\"\nCode\n# w\n# lambda\n\ncat(\"w = \", round(w, 2), \"\\n\")\n\n\nw =  0.4 \n\n\nCode\ncat(\"lambda = \", round(lambda, 2), \"\\n\")\n\n\nlambda =  3.07",
    "crumbs": [
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>The EM algorithm for Zero-Inflated Mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L03-Ex1.html#hw---simulation-of-poisson-mixture-model",
    "href": "C3-L03-Ex1.html#hw---simulation-of-poisson-mixture-model",
    "title": "70  The EM algorithm for Zero-Inflated Mixtures",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nA biologist is interest in characterizing the number of eggs laid by a particular bird species. To do this, they sample\nn=300n, nests on a site in Southern California. The observations are contained in the attached file data/nestsize.csv:\ngenerate a barplot with the empirical frequencies of all the integers included in the sample.\n\nAs you can see, the Poisson distribution underestimates the number of empty nests in the data, and overestimates the number of nests with either 1 or 2 eggs. To address this, you are asked to modify the implementation of the EM algorithm contained in the Reading “Sample code for EM example 1” so that you can fit a mixture between a point mass at zero and a Poisson distribution (we call this a “zero-inflated Poisson” distribution):\n\nf(x) = w \\delta_0(x) + (1-w) \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x \\in \\{0, 1, 2, \\ldots\\}\n\\tag{70.1}\nwhere w is the weight associated with the point mass at zero, \\lambda is the parameter of the Poisson distribution, and \\delta_0(x) represents the degenerate distribution placing all of its mass at zero.\n\nYou then should run your algorithm with the data contained in nestsize.csv and report the values of the estimates that you obtained, rounded to two decimal places. ​\n\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nThe code you generate should follow the same structure as “Sample code for EM example 1”. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect the fact that\n\nyou provided a reasonable initial point for you algorithm,\nthe observation-specific weights v_i,k are computed correctly (E step),\nthe formulas for the maximum of the Q functions are correct (M step),\nthe converge check is correct, and\nthe numerical values that you obtain are correct.\n\nTo simplify the peer-review process, assume that component 1 corresponds to the point mass at zero, while component 2 corresponds to the Poisson distribution.\nThere are two things that make this problem more challenging than the ones we have used for illustrations so far:\n\nthe two components in the mixture belong to different families, and\neach component has a very different support.\n\nkeep these two circumstances in mind when working on your answer.",
    "crumbs": [
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>The EM algorithm for Zero-Inflated Mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L03-Ex2.html",
    "href": "C3-L03-Ex2.html",
    "title": "71  The EM algorithm for Mixture Models",
    "section": "",
    "text": "71.1 Infer parameter of mixture of exponential and long normal for lifetime of fuses\nCode\n## Clear the environment and load required libraries\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\n# Load the data\nfuses &lt;- read.csv(\"data/fuses.csv\",header=FALSE)\nx &lt;- fuses$V1\nn &lt;- length(x) # Number of observations\n\n# how many rows in the data\nnrow(fuses)\n\n\n[1] 400\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 0\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, freq=FALSE, xlab=\"Fuses\", ylab=\"Density\", main=\"Empirical distribution of fuses failure times\")\nCode\nKK = 2                             # Number of components\nw     = 0.05                        # Assign equal weight to each component to start with\n#mu = rnorm(1,mean(log(x)), sd(log(x)))\nmu = mean(log(x))\ntau = sd(log(x))\nlambda = 20 / mean(x)\n\ns  = 0              # s_tep counter\nsw = FALSE          # sw_itch to stop the algorithm\nQQ = -Inf           # the Q function (log-likelihood function)\nQQ.out = NULL       # the Q function values\nepsilon = 10^(-5)   # the stopping criterion for the algorithm\n\ntrace &lt;- data.frame(iter=0, w=w, lambda=lambda, mu=mu, tau=tau)\n\nwhile(!sw){ ##Checking convergence\n\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(i in 1:n){\n    v[i,1] = log(w)   + dexp(x[i], rate=lambda, log=TRUE)\n    v[i,2] = log(1-w) + dlnorm(x[i], mu, tau, log=TRUE)    \n    v[i,]  = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,]))) \n  }\n\n  ## M step  \n  w      = mean(v[,1])  # Weights\n  lambda = sum(v[,1]) / sum(v[,1] * x)  # Lambda (rate)\n  mu     = sum(v[,2] * log(x)) / sum(v[,2]) # Mean\n  tau    = sqrt(sum(v[,2] * (log(x) - mu)^2) / sum(v[,2])) # Tau (standard deviation)\n  \n  # collect trace of parameters \n  trace  =  rbind(trace, data.frame(iter=s, w=w, lambda=lambda, mu=mu, tau=tau))\n\n  ## Check convergence\n  QQn = 0\n  #vectorized version\n  log_lik_mat = v[,1]*(log(w)   + dexp(x, lambda, log=TRUE)) +\n                v[,2]*(log(1-w) + dlnorm(x, mu, tau, log=TRUE))\n  QQn = sum(log_lik_mat)\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n}\n\n\n[1] \"1 -621.636631915928\"\n[1] \"2 -576.564676680329\"\n[1] \"3 -562.326030957339\"\n[1] \"4 -558.240693010161\"\n[1] \"5 -559.062812699431\"\n[1] \"6 -560.433982999852\"\n[1] \"7 -561.504096778213\"\n[1] \"8 -562.257984979008\"\n[1] \"9 -562.779349634224\"\n[1] \"10 -563.139561270939\"\n[1] \"11 -563.389080841182\"\n[1] \"12 -563.562415697134\"\n[1] \"13 -563.683109594057\"\n[1] \"14 -563.767298770739\"\n[1] \"15 -563.826100698272\"\n[1] \"16 -563.867209281663\"\n[1] \"17 -563.895967519019\"\n[1] \"18 -563.916095326952\"\n[1] \"19 -563.930187401928\"\n[1] \"20 -563.94005598844\"\n[1] \"21 -563.946968029888\"\n[1] \"22 -563.951809840896\"\nnext report the MLE parameters of the model.\nCode\n# Report the MLE parameters\ncat(\"w =\", round(w, 2), \"lambda =\", round(lambda, 2), \"mu =\", round(mu, 2),\"tau =\", round(tau, 2))\n\n\nw = 0.09 lambda = 3.05 mu = 0.78 tau = 0.38",
    "crumbs": [
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>The EM algorithm for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L03-Ex2.html#infer-parameter-of-mixture-of-exponential-and-long-normal-for-lifetime-of-fuses",
    "href": "C3-L03-Ex2.html#infer-parameter-of-mixture-of-exponential-and-long-normal-for-lifetime-of-fuses",
    "title": "71  The EM algorithm for Mixture Models",
    "section": "",
    "text": "NoteInstructions\n\n\n\nData on the lifetime (in years) of fuses produced by the ACME Corporation is available in the file fuses.csv:\nIn order to characterize the distribution of the lifetimes, it seems reasonable to fit to the data a two-component mixture of the form:\n\nf(x)=wλexp{−λx}+(1−w) \\frac{1}{\\sqrt{2\\pi}\\tau x} \\exp{− \\frac{(log(x)−μ)^{2}}{2τ^{2}}}, \\quad x &gt; 0.\n\\tag{71.1}\nwhere w is the weight associated with the exponential distribution, \\lambda is the rate of the exponential distribution, and \\text{LN}(\\mu, \\tau) is a log-normal distribution with mean \\mu and standard deviation \\tau.\n\nModify code to Generate n observations from a mixture of two Gaussian # distributions into code to sample 100 random numbers from a mixture of 4 exponential distributions with means 1, 4, 7 and 10 and weights 0.3, 0.25, 0.25 and 0.2, respectively.\nUse these sample to approximate the mean and variance of the mixture.",
    "crumbs": [
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>The EM algorithm for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html",
    "href": "C3-L04.html",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "",
    "text": "73 MCMC algorithm for Mixture Models\nMarkov chain Monte Carlo (MCMC) algorithm are typically used to perform Bayesian inference in complex models. In MCMC algorithms we repeatedly sample from the full conditional distributions of each block of parameters given fixed values for the rest. After an appropriate burn-in period, they generate samples that are dependent but identically distributed according to the posterior distribution of interest.",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#markov-chain-monte-carlo-algorithms-part-1",
    "href": "C3-L04.html#markov-chain-monte-carlo-algorithms-part-1",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.1 Markov Chain Monte Carlo algorithms part 1",
    "text": "73.1 Markov Chain Monte Carlo algorithms part 1\n\n\n\n\nMCMC - Priors of convenience\n\n\n\n\nMCMC - Complete data Likelihood\n\n\n\n\n\n\n\n\nTipNotation\n\n\n\n\nunder tildes signify a vector or collection.\n\\{i:c_i=l\\} mean the sum over the indices for a specific component k. We are regrouping the rows by their components\nThe double product mean we are iterating over the data rows times their likelihoods. (as usual)\nThe indicator in the exponent mean we are only taking one term per row which is picked using the component for which the latent indicator is true.\n\n\n\nThe model takes the form : \nf(x\\mid \\theta) = \\sum_{k=1}^K w_k g(x \\mid \\theta_k)\n\\tag{73.1}\nThe model is defined by the parameters \\theta = (\\theta_1, \\ldots, \\theta_K) and the weights w = (w_1, \\ldots, w_K).\nIn the Bayesian setting we also need priors for the weights and the parameters of each components.\n\n(w_1, \\ldots, w_K) \\sim Dirichlet(\\alpha_1, \\ldots, \\alpha_K) \\qquad \\mathbb{E}[w_k] = \\frac{\\alpha_k}{\\sum_{k=1}^K \\alpha_k}\n\\tag{73.2}\nalso if we use a_1 = a_2 = ... a_k=1 we end up with a uniform prior on the simplex.\n\n\\tilde{\\theta}_k if they admit a conjugate prior, we can use the conjugate prior for the parameters of the component k. Even though it won’t be conjugate for the whole model, it will be conjugate for the component k, at least given the sampling scheme outlined in Equation 73.4.\n\n\n\\mathbb{P}r(w) = \\frac{\\Gamma(\\sum_{k=1}^K \\alpha_k)}{\\prod_{k=1}^K \\Gamma(\\alpha_k)} \\prod_{k=1}^K w_k^{\\alpha_k - 1} \\qquad \\sum_{k=1}^K w_k = 1\n\\tag{73.3}\nTo develop a MCMC algorithm for mixture models we will use the hierarchical representation of the likelihood,\nComplete data likelihood:\n\n\\begin{aligned}\n\\mathbb{P}r(\\mathbf{x}, \\mathbf{c}, \\mid \\mathbf{\\omega}, \\mathbf{\\theta})  &= \\prod_{i=1}^n \\prod_{k=1}^K (\\omega_k\\ g_k(x_i \\mid \\theta_k))^{\\mathbb{1}(c_i = k)} &\n\\\\& = \\left[\\prod_{k=1}^K \\prod_{\\{i:c=k\\}}^n g_k(x_i \\mid \\theta_k)\\right] && \\left [\\prod_{k=1}^n \\omega_{k}^{\\sum \\mathbb{1}(c_i = k)}\\right ]\n\\\\& = \\mathbb{P}r(\\mathbf{x} \\mid \\mathbf{c}, \\mathbf{\\omega}, \\mathbf{\\theta}) && \\mathbb{P}r(\\mathbf{c} \\mid \\mathbf{\\omega}, \\mathbf{\\theta})\n\\\\& = \\mathbb{P}r(\\mathbf{x} \\mid \\mathbf{c}, \\mathbf{\\theta}) && \\mathbb{P}r(\\mathbf{c} \\mid \\mathbf{\\omega})\n\\end{aligned}\n\\tag{73.4}\nThe logic in this derivation is that we can rewrite the complete data likelihood as a product of two terms where we separate the weight from the other parameters.\n\n\n\n\n\n\nWarningUnclear !?\n\n\n\n\n\nI’m not sure this is 100% correct, we seem to be trying to write out the fact that each component is conditionally independent given the weights and the component parameters. This step from the first line to the second line is based on regrouping the terms in the product based on component k.\nAnother issue now that I’ve made an effort to clarify the notation is that the selection of the term in the product is based on picking the kernel from just one component. But it seems that we don’t know how to infer which component the data point belongs to.\n\n\n\nIn the third line we reinterpreting :\n\nthe left product in line 2 as a product of the likelihoods of the data if we know given their component, weights and parameters.\nthe right product in line 2 as the distribution of the indicators given the weights and parameters.\n\nIn the last line we remove \\omega on from the left term based on independence. And we remove \\theta from the right term based on independence.\n\n\n\n\n\n\nNoteVideo transcript\n\n\n\n\n\nIn previous lectures, we discussed the expectation maximization algorithm for fitting mixture models. In this lecture, we are going to discuss Markov Chain Monte Carlo for Bayesian inference in mixture models.\nSo we’re going to move from frequentist inference which we were interested only on finding the point estimate for the parameters in the model to a situation in which we are going to try to explore a full posterior distribution for those parameters. So recall that the mixture model we are working with is going to take the form or the density of that mixture model, is going to take the form of f of x is the sum over k components of weight multiplied by the components in the mixture. Those components are indexed by this parameter theta k, and we may have components that are all belong to the same family or that they belong to different families. If we are going to do Bayesian inference for this model, we need to compliment this density that is going to give us the likelihood with priors on the unknown parameters. In particular, we’re going to need priors for the weights, and we are going to need priors for the data suitcase. What is typically done in these situations is to use a priors of convenience.\nWhere are those players of convenience? Well, first for the weights remember that we have a constraint that the sum of the weights needs to be equal to one.\nObviously each one of them individually needs to be between zero and one. So a natural prior for that type of parameters is a Dirichlet prior and that is precisely what we are going to use. So we’re going to assume that the prior for the vector that includes all these weights just follows a Dirichlet distribution, with parameters a1 all the way to a_k. Just as a quick reminder they expected value of each one of these parameters individually is just given by the corresponding a divided by the sum of the a’s. So in other words, the values of the a’s just construals a prior what is the relative size of the different weights. In particular if you make them all the same, then you are saying that a prior you believe that all the weights are the same. We also know that as a special case if you make a1 equal to a2 all the way equal to ak and in particular equal to one then we just have the uniform distribution on the simplex.\nWhich is actually one of the typical choices used for the hyperparameters when fearing mixture models. Now, this is our priori of convenience for the omegas and we will see that in addition to having a very nice interpretation it will also allow us to do computation in a very straight forward manner. Now, the other set of priors that we need is the priors for the data case. What is typically done here is that if they admit a conjugate prior under gk then that prior is used.\nThe reason for that is that even though for the full mixture this conjugate prior on the g_k1 conjugate for the full model it will be conditionally conjugate under our sampling scheme that we will derive in a minute. So it will make computation for the parameters theta k much simpler if we can find that conjugate prior under theta k. After we have set up priors for the model the next thing that we need to do before deriving our Gibbs sampler is to write down the complete data likelihood in a slightly more convenient way. If you remember the complete data likelihood that we used extensively for deriving the EM Algorithm has the form of the distribution of the data in all those indicators CSU either just tells you which component you belong to conditional on the weight, and all the Thetas is just going to take the form of a double product. So the product over the observations followed by the product over the components of omega sub k g sub k of x sub y given Theta k raised to the indicator function of ci equals to k. In other words, rather than write the complete sum that we had before, we replaced that completes sum by a product where each one of the terms is now raised to this indicator function that just depends on whether the component was generated, the observation was generated by the k component in the mixture. This complete data likelihood that we use extensively can now be written in a couple of different ways, and one that is going to be particularly helpful for us involves breaking this expression into two pieces, one that has to do with their omega’s, and one that has to do with g’s. So let me start with a piece that starts with the g’s. The way in which I’m going to do it is first I’m going to reverse the order of this products. So I am going to consider first the product over the components. Next I’m going to consider the product over the observations. But before I write exploration explicitly, let me interpret this expression up here a little bit. So what we’re doing here with this double product or one way to think about what we’re doing with a double product is to think about computing a bunch of terms that are in here in particular in this piece, that can be positioned onto a matrix where one dimension corresponds to the index i, and the second dimension corresponds to the index k. The entries of this matrix are just g of x i given theta k. So different combinations of i and different combinations of k gives you the values that you are going to put into this matrix. Now, what is this important? Because if you think about what they indicator or function up here is doing is it’s telling you well you need to compute the whole matrix but you’re actually not going to use the full matrix, you are just going to pick a few elements of it, and in particular you are going to pick one element in each row according to what the value of ci case. So for example, if the first observation belongs to the second component you’d be picking this value, second observation the first component you will pick this value, third observation with third component here and so on. So the values of the ci can be interpreted as giving you a way to select elements in this matrix, and in particular one per row. So another way to write the product over all the observations is used to think about grouping rows together according to which column is being selected. In particular, for example, we could put all the observations that have the first column being selected together, then all the observations that have the second column being selected together and so on. One way to write that mathematically is to say that we’re going to do a product over the i’s but grouped together according to the value of k. Then we can get rid of the indicator and the numerator and write this as g sub k, xi given theta sub k. So this is one piece of this expression up here or one way to rewrite this expression up here or one piece of it that involves the g subcase. Of course we have a second piece that involves the omegas, that second piece that involves the omegas we can write as the product. Again, I’m going to consider the product over the case first. Then for a given k, omega k is exactly the same argument for all of them. So I can just write omega k and the product of omega k to the indicators just becomes omega k raised to the sum of the indicators.\nWell, once I have written the expression in this way, I can essentially think about this piece as being the distribution of the observations if I knew the indicators, the omegas, and the Thetas. It so happens that this expression in particular doesn’t depend on the omegas. So for this model this is the same as p of x given c and the theta. In this expression here you can interpret as the distribution of the c’s given the omegas and the theta’s. Again, in the particular structure of this model this happens to just depend on the weights omega. So we know that the product of these two quantities is just by the total law of probability the expression that we wanted in the beginning that is the distribution of the Theta and indicators together. So this particular form for the distribution is going to be particularly useful in terms of deriving the posterior distribution that we need for the Gibbs sampler. One last observation that I want to make that will be useful in the future is that if you think about what is the form of this piece down here the distribution or the Indicators even the weights, what you have is a form that resembles the kernel of multinomial distribution. So this is similar to the kernel of a multinomial.\nIn particular, it’s not only similar but it’s proportional to it. So it will be particularly useful in terms of deriving the algorithm using the fact that this looks like a multinomial distribution.",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#markov-chain-monte-carlo-algorithms-part-2",
    "href": "C3-L04.html#markov-chain-monte-carlo-algorithms-part-2",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.2 Markov Chain Monte Carlo algorithms part 2",
    "text": "73.2 Markov Chain Monte Carlo algorithms part 2\n\n\n\n\nposterior distribution - weights\n\n\n\n\nposterior distribution - components\n\n\n\n\nposterior distribution - parameters\n\n\n\nNow that we have a structure for the likelihood function that we and the prior distributions for all of our parameters, we can can derive the posterior distribution for our model.\nSo we want to write down the joint posterior distribution. In that joint posterior distribution includes, the weights and the parameters of the components, but it also involves the vector of indicators C, that we have introduced to simplify the structure of the likelihood, and by definition, this quantity is proportional to the distribution of the data, given all the parameters, multiplied by the distribution of the missing data parameters, given Omega and Theta, multiplied by the prior distribution on the parameters, multiplied by the prior distribution on the base.\n\n\\mathbb{P}r(c, \\theta, \\omega \\mid x) \\propto \\left \\{ \\prod_{i=1}^n \\mathbb{P}r(x | c, \\theta, \\omega) \\right \\} \\left \\{ \\prod_{i=1}^n\\prod_{k=1}^K \\mathbb{P}r(c \\mid \\omega, \\theta) \\right \\}\\ \\mathbb{P}r(\\omega)\\ \\mathbb{P}r(\\theta)\n\\tag{73.5}\nEach of the full conditional distributions can be derived from this joint posterior by retaining the terms that involve the parameter of interest, and recognizing the product of the selected terms as the kernel of a known family of distributions.\n\n\n\n\n\n\nNoteVideo transcript\n\n\n\n\n\nNow that we have a clear structure for the likelihood function that we will be using and we have prior distributions for all of our parameters, we can proceed to derive the posterior distribution that we will be working with.\nSo we want to write down the joint posterior distribution. In that joint posterior distribution includes, of course, the weights and the parameters of the components, but it also involves the vector of indicators C, that we have introduced to simplify the structure of the likelihood, and by definition, this quantity is proportional to the distribution of the data, given all the parameters, multiplied by the distribution of the missing data parameters, given Omega and Theta, multiplied by the prior distribution on the parameters, multiplied by the prior distribution on the base.\nSo this is the general expression, the general form, for that posterior distribution. Now, we have already seen what the form of the different terms is. In particular, this joint distribution of the data can be written as a double product. First-order components, and then over the groups of observations that belong to each one of those components of g_k x_i, given \\theta_k. So that is the first piece that we’re interested in. The second piece, we have already seen also how to write it down. This is going to be the product from k equals one, to capital k of Omega_k. Some of these indicators of C_i is equal to k from one to n. This is our second piece. Then we discussed using a Dirichlet distribution for this. So ignoring some proportionality constants, this becomes the product from k equals one to capital k of Omega_k raised to the a_k minus 1. That’s this piece. Then finally, we’re going to have another product. So typically, we use independent priors for each one of the data case. As I said, we’ll typically try to pick them so that they are conjugate to this kernel, g_k(), but for now, I’m going to write it in general form by writing this as p_k(\\theta_k), and that’s what the last term in the expression is. So we have written down a full expression for this. Now, it should be more or less clear how we need to proceed. So we need full conditionals for all the parameters in the model. In particular, we are going to need a full conditional for Omega, given all the other parameters, we’re going to need a full conditional for each one of the C_is given the rest of the parameters, and we’re going to need a full conditional for each one of the data case, given the rest of the parameters.\nSo to derive these full conditionals, what we will do is we will pick particular pieces from this expressions to retain and to construct this particular four conditionals. Let’s proceed now to derive each one of the four conditionals that we need to derive a Gibbs sampler or a Markov Chain Monte Carlo algorithm for this problem. Let’s just start with the full posterior distribution for the weights, and please note that we’re going to work with all the weights as a block, so we’re going to try to sample them all together, and rather than looking at each one of them at a time. o this full conditional distribution is made up of the terms in this full posterior distribution that involves Omega k, and if you look at this expression carefully, you will see that this piece doesn’t depend on Omega k anyway, and that this piece doesn’t depend on any of the Omega case either, so it’s just this two pieces in the middle that we need to consider. Furthermore, the two pieces are very similar, so both in both products over K of the weight raised to some power, so we can actually combine the two expressions together and just write them as the product from one to capital k of Omega _k raised to the sum of these indicator functions, plus a_k minus 1. This looks exactly like the prior that we used, except that now, we have updated parameters. So I could write this as the product of Omega_k raised to the a_k, call them stars, minus one, where a_k a star, is just the original a_k plus the sum from one to n of the indicators of C_i equals to k. So just doing this little change, makes it very clear that the form of the posterior is exactly the same form as the prior. In other words, this a conditionally conjugate prior for our problem, and that just means that Omega is going to be distributed as a Dirichlet, given all the other parameters, but with this updated parameters, a_1 star all the way to a_k star, and this is very interesting because essentially, a posteriori, we know that the expected value of Omega given all the other parameters, so this is the expected value of the full conditional. This is not expected value of the marginal posterior, but this is the expected value of the full conditional that is going to be a_k star divided by the sum from L equals one to k of a sub L, a star, but this is just a_k plus the sum from one to n of these indicators, c_i equals to k, divided by n plus the sum from L equals one to capital K of the a_l. N just comes from the fact that if I sum over all the components, then the sum of those values is going to be n.  So this is just the number of observations that are currently assigned to the case component, and if the values of a, k are small, then this is just roughly speaking. So approximately, the proportion of observations in component K. This has a very nice analogy with the computations that we did in the EM algorithm.\nIf you remember the way in which we computed the weights in that case, or the MLE for the weights, was by essentially computing a quantity that could also be interpreted as, roughly speaking, the proportion of observations in that step of the algorithm that were assigned to that component. So this provides a mirror image to what we did with the EM algorithm, but that has a Bayesian flavor rather than a frequentist flavor. Let’s continue now with the full conditional posterior distribution for the indicators, for the c_is. I’m interested in the probability that c_i is equal to K given the data. As before, this is going to be proportional to just the terms in this large product that depends on c_i, and if you look at it carefully, c_i only appears in this two terms of the product. These have nothing to do with c_i. In particular, it appears in a single term within this really large product and in a single term within this product. So the term that depends on C surviving equal to K in here is Omega_k. The term that depends on c_i equal to k in here, it’s just g_k of x_i given Theta, and this is true for every k from one to capital K. Remember that c_i is a discrete random variable, taking values between one and k because it indicates which component generated the observation. So if I want to get rid of the proportionality sign and actually being able to write what the probability is, I just need to normalize this by dividing over the sum of these quantities over k. So that means that p of c_i equals to k, given all the other parameters, is equal to Omega_k, g_k, x_i, given Theta_k, divided by the sum from l equals one to capital k of Omega l, g_l of x_i, given Theta_l. If you look at this expression carefully, you will realize that it is very similar to the expression that we used when computing in the EM algorithm, the weights associated which is one of the observations. In fact, it is the same expression, and this is just what we called in the EM algorithm, V_ik. Finally, let’s consider the full conditional posterior distribution for the data case. So we need p of Theta k given all the other parameters in the model. Again, we just pick from this whole product the terms that have to do with Theta k, in this case, it is the two in the middle that do not depend on it, and within this big expression, we just have a few terms that contain Theta k, and those correspond to the observations that are currently assigned to that particular component. So this expression is proportional to the product over the i’s that have been assigned to the kth component of g_k, x_i Theta k, and among this product, again, there is a single term that belongs to Theta k. So the form of the full conditional posterior distribution for the parameter Theta k is simply this. Now, without a specific choice of G and P, it is hard to further simplify this expression. But what I do want to note here is that if this prior p_k is conjugate to this kernel g_k, then we typically know what family this posterior distribution will belong to, and that will make computation much simpler because you will typically be able to sample from that full posterior conditional distribution in using a direct sampler. This will become a little bit more clear once we do an example with mixture models, which is what we’re going to do next.",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#mcmc-for-location-mixtures-of-normals-part-1",
    "href": "C3-L04.html#mcmc-for-location-mixtures-of-normals-part-1",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.3 MCMC for location mixtures of normals Part 1",
    "text": "73.3 MCMC for location mixtures of normals Part 1\n\n\n\n\nlocation mixture of Normals - priors\n\n\n\n\nlocation mixture of Normals - marginals\n\n\n\n\nlocation mixture of Normals weights\n\n\n\n\nlocation mixture of Normals - components\n\n\n\n\nlocation mixture of Normals - \\sigma^2\n\n\n\n\n\nas in the previous module we derive the full conditional distributions for the mixture of two univariate normals.\n\nf(x | ω, μ1, μ2, σ) = \\omega \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp\\left\\{-\\frac{(x - \\mu_1)^2}{2\\sigma^2}\\right\\} + (1- \\omega) \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp\\left\\{-\\frac{(x - \\mu_2)^2}{2\\sigma^2}\\right\\}\n\nwe use a beta distribution with a_1=1 and a_2=1 for \\omega which corresponds to a uniform distribution and is a special case of a Dirichlet for K=2.\n\\mu_k \\sim N(\\eta,\\tau^2)\ninverse gamma for ^2 with shape parameter a and scale parameter b.\nan empirical approach to priors:\nIn the absence of real prior information we typically employ the observed data to guide the selection of the hyperparameter η, τ^2, d and q, in an approach that is reminiscent of empirical Bayes. In particular, we attempt to make the means of the different component lie in the same support of the observed data, so we take η to be approximately equal the mean (or median) of the observations, and τ^2 to be roughly equal to their variance. Similarly, for the prior on the variance σ^2 we set d = 2 (which implies that E(σ^2) = q and an infinite prior variance) and q to be roughly equal to the variance of the observations. Posteriors are often not very sensitive to changes on the prior means that remain within an order of magnitude of the values suggested above.\n\n\n\n\n\n\nNoteOverthinking the priors\n\n\n\n\n\nIt seems that since this is a hierarchical model, we set the priors for different components from shared hyper-priors. This way the parameters can also be inferred and we can reduce the number of parameters we need to estimate !",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#mcmc-for-location-mixtures-of-normals-part-2",
    "href": "C3-L04.html#mcmc-for-location-mixtures-of-normals-part-2",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.4 MCMC for location mixtures of normals Part 2",
    "text": "73.4 MCMC for location mixtures of normals Part 2\n\n\n\n\nlocation mixture of Normals \\mu\n\n\n\n\nlocation mixture of Normals \\mu continued 1\n\n\n\n\nlocation mixture of Normals \\mu continued 2",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#mcmc-example-1",
    "href": "C3-L04.html#mcmc-example-1",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.5 MCMC Example 1",
    "text": "73.5 MCMC Example 1\n\n\nCode\n#### Example of an MCMC algorithm for fitting a location mixture of 2 Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(MCMCpack)\nset.seed(81196)  # So that results are reproducible\n\n\n\n\nCode\n## Generate data from a mixture with 2 components\nKK         = 2\nw.true     = 0.6  # True weights associated with the components\nmu.true    = rep(0, KK)\nmu.true[1] = 0   # True mean for the first component\nmu.true[2] = 5   # True mean for the second component\nsigma.true = 1   # True standard deviation of all components\nn          = 120         # Number of observations to be generated\ncc.true = sample(1:KK, n, replace=T, prob=c(w.true,1-w.true))\nx  = rep(0, n)\nfor(i in 1:n){\n  x[i] = rnorm(1, mu.true[cc.true[i]], sigma.true)\n}\n\n\n\n\nCode\n# Plot the true density\npar(mfrow=c(1,1))\nxx.true = seq(-8,11,length=200)\nyy.true = w.true*dnorm(xx.true, mu.true[1], sigma.true) + \n  (1-w.true)*dnorm(xx.true, mu.true[2], sigma.true) \nplot(xx.true, yy.true, type=\"l\", xlab=\"x\", ylab=\"True density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\nFigure 73.1: True density and data points\n\n\n\n\n\n\n\nCode\n## Initialize the parameters\nw     = 1/2                         #Assign equal weight to each component to start with\nmu    = rnorm(KK, mean(x), sd(x))   #Random cluster centers randomly spread over the support of the data\nsigma = sd(x)                       #Initial standard deviation\n\n# Plot the initial guess for the density\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(yy)), xlab=\"x\", \n     ylab=\"Initial density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\n\nCode\n## The actual MCMC algorithm starts here\n# Priors\naa  = rep(1,KK)  # Uniform prior on w\neta = 0          # Mean 0 for the prior on mu_k\ntau = 5          # Standard deviation 5 on the prior for mu_l\ndd  = 2\nqq  = 1\n\n# Number of iterations of the sampler\nrrr   = 6000\nburn  = 1000\n\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = rep(0, rrr)\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = rep(0, rrr)\nlogpost   = rep(0, rrr)\n\n# MCMC iterations\nfor(s in 1:rrr){\n  # Sample the indicators\n  cc = rep(0,n)\n  for(i in 1:n){\n    v = rep(0,KK)\n    v[1] = log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)  #Compute the log of the weights\n    v[2] = log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)  #Compute the log of the weights\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n\n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n\n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(rinvgamma(1, dd.star, qq.star))\n\n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s]     = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n\n\n  # Compute the log posterior\n  for(i in 1:n){\n    if(cc[i]==1){\n      logpost[s] = logpost[s] + log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)\n    }else{\n      logpost[s] = logpost[s] + log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)\n    }\n  }\n\n  logpost[s] = logpost[s] + dbeta(w, aa[1], aa[2],log = T)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log = T)\n  }\n\n  logpost[s] = logpost[s] + log(dinvgamma(sigma^2, dd, 1/qq))\n  \n  # print s every 500 iterations\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n\n\n\n\nCode\n## Plot the logposterior distribution for various samples\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\nxx = seq(-8,11,length=200)\ndensity.posterior = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  density.posterior[s,] = density.posterior[s,] + w.out[s+burn]*dnorm(xx,mu.out[s+burn,1],sigma.out[s+burn]) +\n                                                  (1-w.out[s+burn])*dnorm(xx,mu.out[s+burn,2],sigma.out[s+burn])\n}\n\n\n\n\n\n\n\n\nFigure 73.2: Log posterior distribution for various samples\n\n\n\n\n\n\n\nCode\n## report the posterior mean and 95% credible interval\ndensity.posterior.m = apply(density.posterior , 2, mean)\ndensity.posterior.lq = apply(density.posterior, 2, quantile, 0.025)\ndensity.posterior.uq = apply(density.posterior, 2, quantile, 0.975)\n\n## Plot the posterior density estimate\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.posterior.m, type=\"n\",ylim=c(0,max(density.posterior.uq)), xlab=\"x\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.posterior.lq, rev(density.posterior.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.posterior.m, lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\nFigure 73.3: Posterior density estimate",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#sample-code-for-mcmc-example-1",
    "href": "C3-L04.html#sample-code-for-mcmc-example-1",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.6 Sample code for MCMC example 1",
    "text": "73.6 Sample code for MCMC example 1",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#mcmc-example-2",
    "href": "C3-L04.html#mcmc-example-2",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.7 MCMC Example 2",
    "text": "73.7 MCMC Example 2",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#sample-code-for-mcmc-example-2",
    "href": "C3-L04.html#sample-code-for-mcmc-example-2",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.8 Sample code for MCMC example 2",
    "text": "73.8 Sample code for MCMC example 2\n\n\nCode\n#### Example of an MCMC algorithm for fitting a mixtures of K p-variate Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)\nlibrary(ellipse)\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\nlibrary(MCMCpack)\n\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nset.seed(63252)    #Keep seed the same so that we can reproduce results\nn  = 120\ncc.true = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc.true[i],], Sigma.true[cc.true[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]), type=\"n\")\ntext(x[,1], x[,2], seq(1,n), col=cc.true, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2)\n}\ntitle(main=\"Data + True Components\")\n\n\n\n\n\n\n\n\n\nCode\n## Initialize the parameters\nw          = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu         = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\ncc         = sample(1:KK, n, replace=TRUE, prob=w)\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\n# Priors\naa = rep(1, KK)\ndd = apply(x,2,mean)\nDD = 10*var(x)\nnu = p\nSS = var(x)/3\n\n# Number of iteration of the sampler\nrrr = 1000\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK, p))\nSigma.out = array(0, dim=c(rrr, KK, p, p))\nlogpost   = rep(0, rrr)\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + mvtnorm::dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc)))\n  \n  # Sample the means\n  DD.st = matrix(0, nrow=p, ncol=p)\n  for(k in 1:KK){\n    mk    = sum(cc==k)\n    xsumk = apply(x[cc==k,], 2, sum)\n    DD.st = solve(mk*solve(Sigma[k,,]) + solve(DD))\n    dd.st = DD.st%*%(solve(Sigma[k,,])%*%xsumk + solve(DD)%*%dd)\n    mu[k,] = as.vector(rmvnorm(1,dd.st,DD.st))\n  }\n  \n  # Sample the variances\n  xcensumk = array(0, dim=c(KK,p,p))\n  for(i in 1:n){\n    xcensumk[cc[i],,] = xcensumk[cc[i],,] + (x[i,] - mu[cc[i],])%*%t(x[i,] - mu[cc[i],])\n  }\n  for(k in 1:KK){\n    Sigma[k,,] = riwish(nu + sum(cc==k), SS + xcensumk[k,,])\n  }\n  \n  # Store samples\n  cc.out[s,]      = cc\n  w.out[s,]       = w\n  mu.out[s,,]     = mu\n  Sigma.out[s,,,] = Sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + mvtnorm::dmvnorm(x[i,], mu[cc[i],], Sigma[cc[i],,], log=TRUE)\n  }\n  logpost[s] = logpost[s] + ddirichlet(w, aa)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + mvtnorm::dmvnorm(mu[k,], dd, DD, log=TRUE)\n    logpost[s] = logpost[s] + log(diwish(Sigma[k,,], nu, SS))\n  }\n  \n  if(s/250==floor(s/250)){\n    print(paste(\"s = \", s))\n  }  \n}\n\n\n[1] \"s =  250\"\n[1] \"s =  500\"\n[1] \"s =  750\"\n[1] \"s =  1000\"\n\n\nCode\n## Plot the logposterior distribution for various samples\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\n\n\n\n\n\n\n\n\nCode\n## Plot the density estimate for the last iteration of the MCMC\npar(mfrow=c(1,1))\npar(mar=c(4,4,2,1)+0.1)\nplot(x[,1], x[,2], col=cc.true, main=paste(\"s =\",s,\"   logpost =\", round(logpost[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#practice-graded-assignment-the-mcmc-algorithm-for-zero-inflated-mixtures",
    "href": "C3-L04.html#practice-graded-assignment-the-mcmc-algorithm-for-zero-inflated-mixtures",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.9 Practice Graded Assignment: The MCMC algorithm for zero-inflated mixtures",
    "text": "73.9 Practice Graded Assignment: The MCMC algorithm for zero-inflated mixtures\n\n\nCode\nrm(list=ls())\nlibrary(MCMCpack)\nset.seed(81196)  # So that results are reproducible\n\n# Data loading\n\nx &lt;- read.csv(\"./data/nestsize.csv\")[[1]]\nn &lt;- length(x)\n\n# The actual MCMC algorithm starts here\n\n## MCMC iterations of the sampler\n\niterations &lt;- 6000\nburn &lt;- 1000\n\n## Initialize the parameters\n\ncc         = rep(2, n)\ncc[x == 0] = sample(1:2, sum(x == 0), replace = TRUE, prob = c(0.5, 0.5))\n\n## Priors\n\naa = c(1, 1)  # Uniform prior on w\nw     = 0.2 # fewer zeros\nlambda = mean(x[x &gt; 0])  # Initial lambda from nonzero data\n\n# Storing the samples\nw.out      = rep(0, iterations)\ncc.out     = array(0, dim=c(iterations, n))\nlambda.out = array(0, dim=c(iterations, n))\n\n# logpost    = rep(0, iterations)\n# MCMC iterations\n\nfor (s in 1:iterations) {\n\n  # Sample latent indicators c_i\n\n  cc = numeric(n)\n  for (i in 1:n) {\n    if (x[i] == 0) {\n      logp1 = log(w)\n      logp2 = log(1 - w) + dpois(0, lambda, log=TRUE)\n      probs = exp(c(logp1, logp2) - max(logp1, logp2))\n      probs = probs / sum(probs)\n      cc[i] = sample(1:2, 1, prob = probs)\n    } else {\n      cc[i] = 2\n    }\n  }\n\n  # Sample the weights\n\n  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n  lambda = rgamma(1, shape = 1 + sum(x[cc == 2]), rate = 1 + sum(cc == 2))\n\n  # Store samples\n\n  w.out[s] =  w\n  lambda.out[s]  = lambda\n  cc.out[s,] = cc\n\n}\n\n# Posterior summaries\n\nw.post = w.out[-(1:burn)]\nlambda.post = lambda.out[-(1:burn)]\ncat(\"Posterior mean of w:\", mean(w.post), \"\\n\")\n\n\nPosterior mean of w: 0.399678 \n\n\nCode\ncat(\"Posterior mean of lambda:\", mean(lambda.post), \"\\n\")\n\n\nPosterior mean of lambda: 0.008477621",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04.html#honors-peer-graded-assignment-markov-chain-monte-carlo-algorithms-for-mixture-models",
    "href": "C3-L04.html#honors-peer-graded-assignment-markov-chain-monte-carlo-algorithms-for-mixture-models",
    "title": "72  M4L1 - MCMC for Mixture Models",
    "section": "73.10 Honors Peer-graded Assignment: Markov chain Monte Carlo algorithms for Mixture Models",
    "text": "73.10 Honors Peer-graded Assignment: Markov chain Monte Carlo algorithms for Mixture Models",
    "crumbs": [
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>M4L1 - MCMC for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04-Ex1.html",
    "href": "C3-L04-Ex1.html",
    "title": "73  The MCMC algorithm for Zero-Inflated Mixtures",
    "section": "",
    "text": "73.1 HW - Simulation of Poisson mixture model\nIn the lessons we mentioned that Zero-Inflated Poisson (ZIP) models arises naturally in biology when analyzing nest size data since many birds fail to mate or lay eggs. As such they will have zero eggs in their nests.\nPoisson tends to underestimate the number of empty nests in the data, and overestimate the number of nests with either 1 or 2 eggs. Negative binomial can mitigate this problem by adding a tunable parameter to control for the dispersion of count data, however, it isn’t necessarily a good fix for zero-inflated data.\nIn this exercise, we will use the EM algorithm to fit a ZIP mixture model to a dataset of nest sizes.",
    "crumbs": [
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>The MCMC algorithm for Zero-Inflated Mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L04-Ex1.html#hw---simulation-of-poisson-mixture-model",
    "href": "C3-L04-Ex1.html#hw---simulation-of-poisson-mixture-model",
    "title": "73  The MCMC algorithm for Zero-Inflated Mixtures",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nA biologist is interest in characterizing the number of eggs laid by a particular bird species. To do this, they sample\nn=300n, nests on a site in Southern California. The observations are contained in the attached file data/nestsize.csv\nGenerate a barplot with the empirical frequencies of all the integers included in the sample.\n\nAs you can see, the Poisson distribution underestimates the number of empty nests in the data, and overestimates the number of nests with either 1 or 2 eggs. To address this, you are asked to modify the implementation of the EM algorithm contained in the Reading “Sample code for EM example 1” so that you can fit a mixture between a point mass at zero and a Poisson distribution (we call this a “Zero-Inflated Poisson” distribution)\n\nf(x) = w \\delta_0(x) + (1-w) \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x \\in \\{0, 1, 2, \\ldots\\}\n\\tag{73.1}\nwhere w is the weight associated with the point mass at zero, \\lambda is the parameter of the Poisson distribution, and \\delta_0(x) represents the degenerate distribution placing all of its mass at zero.\n\nYou then should run your algorithm with the data contained in nestsize.csv and report the values of the estimates that you obtained, rounded to two decimal places. ​\n\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nThe code you generate should follow the same structure as “Sample code for EM example 1”. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect the fact that\n\nyou provided a reasonable initial point for you algorithm,\nthe observation-specific weights v_i,k are computed correctly (E step),\nthe formulas for the maximum of the Q functions are correct (M step),\nthe converge check is correct, and\nthe numerical values that you obtain are correct.\n\nTo simplify the peer-review process, assume that component 1 corresponds to the point mass at zero, while component 2 corresponds to the Poisson distribution.\nThere are two things that make this problem more challenging than the ones we have used for illustrations so far:\n\nthe two components in the mixture belong to different families, and\neach component has a very different support.\n\nkeep these two circumstances in mind when working on your answer.",
    "crumbs": [
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>The MCMC algorithm for Zero-Inflated Mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L04-Ex1.html#full-conditional-distributions",
    "href": "C3-L04-Ex1.html#full-conditional-distributions",
    "title": "73  The MCMC algorithm for Zero-Inflated Mixtures",
    "section": "73.2 Full conditional distributions",
    "text": "73.2 Full conditional distributions\nThe full conditional distributions for the indicators of the ZIP model are given by:\n\n\\Pr(c_i = 1 \\mid \\cdots) \\propto \\begin{cases} w & x_i=0 \\\\ 0 & \\mbox{otherwise} \\end{cases}\n\\tag{73.2}\n\n\\Pr(c_i = 2 \\mid \\cdots) \\propto \\begin{cases} (1-w) \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} & x_i=0 \\\\ 1 & \\mbox{otherwise} \\end{cases}\n\\tag{73.3}\nwhere c_i is the latent indicator for observation i, and x_i is the observed data.\nThe full conditional distributions for the weights are given by: \n\\omega \\mid \\cdots \\sim \\mbox{Beta}\\left(m(\\mathbf{c})+1, n-m(\\mathbf{c})+1\\right)\n\\tag{73.4}\nwhere m(\\mathbf{c}) is the number of observations with c_i=1.\nIs the full conditional for the rate \\gamma\n\n\\lambda \\mid \\cdots \\sim \\mbox{Gamma}\\left( 1 + \\sum_{i : c_i = 2} x_i , 1 + n-m(\\mathbf{c}) \\right)\n\\tag{73.5}\nwhere m(\\mathbf{c}) is the number of observations with c_i=2.\n\n\n\n\n\n\nNoteSample code for MCMC example 1\n\n\n\n\n\n\n\nCode\n#### Example of an MCMC algorithm for fitting a location mixture of 2 Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\nset.seed(81196)  # So that results are reproducible\n\n## Generate data from a mixture with 2 components\nKK         = 2\nw.true     = 0.6  # True weights associated with the components\nmu.true    = rep(0, KK)\nmu.true[1] = 0   # True mean for the first component\nmu.true[2] = 5   # True mean for the second component\nsigma.true = 1   # True standard deviation of all components\nn          = 120         # Number of observations to be generated\ncc.true = sample(1:KK, n, replace=T, prob=c(w.true,1-w.true))\nx  = rep(0, n)\nfor(i in 1:n){\n  x[i] = rnorm(1, mu.true[cc.true[i]], sigma.true)\n}\n\n# Plot the true density\npar(mfrow=c(1,1))\nxx.true = seq(-8,11,length=200)\nyy.true = w.true*dnorm(xx.true, mu.true[1], sigma.true) + \n  (1-w.true)*dnorm(xx.true, mu.true[2], sigma.true) \nplot(xx.true, yy.true, type=\"l\", xlab=\"x\", ylab=\"True density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\n\nCode\n## Initialize the parameters\nw     = 1/2                         #Assign equal weight to each component to start with\nmu    = rnorm(KK, mean(x), sd(x))   #Random cluster centers randomly spread over the support of the data\nsigma = sd(x)                       #Initial standard deviation\n\n# Plot the initial guess for the density\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(yy)), xlab=\"x\", \n     ylab=\"Initial density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\n\nCode\n## The actual MCMC algorithm starts here\n# Priors\naa  = rep(1,KK)  # Uniform prior on w\neta = 0          # Mean 0 for the prior on mu_k\ntau = 5          # Standard deviation 5 on the prior for mu_l\ndd  = 2\nqq  = 1\n\n# Number of iterations of the sampler\nrrr   = 6000\nburn  = 1000\n\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = rep(0, rrr)\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = rep(0, rrr)\nlogpost   = rep(0, rrr)\n\n# MCMC iterations\nfor(s in 1:rrr){\n  # Sample the indicators\n  cc = rep(0,n)\n  for(i in 1:n){\n    v = rep(0,KK)\n    v[1] = log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)  #Compute the log of the weights\n    v[2] = log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)  #Compute the log of the weights\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n\n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n\n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(rinvgamma(1, dd.star, qq.star))\n\n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s]     = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    if(cc[i]==1){\n      logpost[s] = logpost[s] + log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)\n    }else{\n      logpost[s] = logpost[s] + log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)\n    }\n  }\n  logpost[s] = logpost[s] + dbeta(w, aa[1], aa[2],log = T)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log = T)\n  }\n  logpost[s] = logpost[s] + log(dinvgamma(sigma^2, dd, 1/qq))\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n\n\nCode\n## Plot the logposterior distribution for various samples\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\n\n\n\n\n\n\n\n\nCode\nxx = seq(-8,11,length=200)\ndensity.posterior = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  density.posterior[s,] = density.posterior[s,] + w.out[s+burn]*dnorm(xx,mu.out[s+burn,1],sigma.out[s+burn]) +\n                                                  (1-w.out[s+burn])*dnorm(xx,mu.out[s+burn,2],sigma.out[s+burn])\n}\ndensity.posterior.m = apply(density.posterior , 2, mean)\ndensity.posterior.lq = apply(density.posterior, 2, quantile, 0.025)\ndensity.posterior.uq = apply(density.posterior, 2, quantile, 0.975)\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.posterior.m, type=\"n\",ylim=c(0,max(density.posterior.uq)), xlab=\"x\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.posterior.lq, rev(density.posterior.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.posterior.m, lwd=2)\npoints(x, rep(0,n), col=cc.true)",
    "crumbs": [
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>The MCMC algorithm for Zero-Inflated Mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L04-Ex1.html#my-solution-code",
    "href": "C3-L04-Ex1.html#my-solution-code",
    "title": "73  The MCMC algorithm for Zero-Inflated Mixtures",
    "section": "73.3 My Solution code",
    "text": "73.3 My Solution code\n\n\nCode\n# Load the nest size data\n\nrm(list=ls())\nlibrary(MCMCpack)\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\nnestsize &lt;- read.csv(\"data/nestsize.csv\",header=FALSE)\ncolnames(nestsize) &lt;- c(\"n\")\nx &lt;- nestsize$n\nn &lt;- length(x) # Number of observations\n# how many rows in the data\nnrow(nestsize)\n\n\n[1] 300\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 128\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, breaks=seq(0, max(x), by=1), freq=FALSE, xlab=\"Number of eggs\", ylab=\"Density\", main=\"Empirical distribution of nest sizes\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# MCMC algorithm for fitting a ZIP\n# The actual MCMC algorithm starts here\n\n## MCMC iterations of the sampler\n\niterations &lt;- 6000\nburn       &lt;- 1000\n\n## Initialize the parameters\ncc         = rep(2, n)\ncc[x == 0] = sample(1:2, sum(x == 0), replace = TRUE, prob = c(0.5, 0.5))\ncc[x != 0] = 2\n\n## Priors\naa     = c(1, 1)        # Uniform prior on w\nalpha = 1\nbeta = 1\nlambda = mean(x[x &gt; 0]) # Initial lambda from nonzero data\n#lambda = mean(x) # Initial lambda from all data\nw      = 0.5            # fewer zeros\n\n# Storing the samples\nw.out      = numeric(iterations)\ncc.out     = array(0, dim=c(iterations, n))\nlambda.out = numeric(iterations)\n\n\n#logpost    = rep(0, iterations)\n\n# MCMC iterations\n\nfor (s in 1:iterations) {\n  # Sample latent indicators c_i\n  cc = numeric(n)\n  # Full conditional for cc\n  for(i in 1:n){\n    v = rep(0,2)\n    if(x[i]==0){\n      v[1] = log(w)\n      v[2] = log(1-w) + dpois(x[i], lambda, log=TRUE)\n      v    = exp(v - max(v))/sum(exp(v - max(v)))\n    }else{\n      v[1] = 0\n      v[2] = 1\n    }\n    cc[i] = sample(1:2, 1, replace=TRUE, prob=v)\n  }\n \n  # Sample the weights\n  # Full conditional for w\n  w = rbeta(1, 1+sum(cc==1), 1+n-sum(cc==1))  \n  lambda = rgamma(1, shape= sum(x[cc==2]) + 1, rate= sum(cc==2) + 1)\n  #lambda = rgamma(1, shape = 1 + sum(x[cc == 2]), rate = 1 + sum(cc == 2))\n\n  # Store samples\n  w.out[s] =  w\n  lambda.out[s]  = lambda\n  cc.out[s,] = cc\n}\n\n\n\n\nCode\n# Posterior summaries\nw.post = w.out[-(1:burn)]\nlambda.post = lambda.out[-(1:burn)]\n\ncat(\"Posterior mean of w:\", round(mean(w.post),2), \"\\n\")\n\n\nPosterior mean of w: 0.4 \n\n\nCode\ncat(\"Posterior mean of lambda:\", round(mean(lambda.post),2),\"\\n\")\n\n\nPosterior mean of lambda: 3.05",
    "crumbs": [
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>The MCMC algorithm for Zero-Inflated Mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L04-Ex2.html",
    "href": "C3-L04-Ex2.html",
    "title": "74  Markov chain Monte Carlo algorithms for Mixture Models",
    "section": "",
    "text": "74.1 HW - Simulation of Lifetime of Fuses\nfull conditional for w_i is given by\nw_i \\mid \\cdots \\sim Beta(1 + \\sum_{i=1}^n \\mathbb{I}(c_i=1), 1 + n - \\sum_{i=1}^n \\mathbb{I}(c_i=1))\nfull conditional for lambda_i is given by\n\\lambda_i \\mid \\cdots \\sim Gamma\\left(\\sum_{j=1}^n \\mathbb{I}(c_j=1), \\sum_{j=1}^n x_j \\mathbb{I}(c_j=1)\\right)\nFull conditional for \\mu\n\\mu \\mid \\cdots \\sim N\\left(\\frac{\\sum_{i:c_i=2} x_i}{{\\frac{m(c)}{τ^2}  + 1}} + 0, \\frac{1}{\\frac{m(c)}{τ^2}  + 1}\\right)\nFull conditional for \\tau\n\\tau^2 \\mid \\cdots \\sim IGam(2+n-m(c), 1+ \\frac{1}{2} \\sum_{i:c_i=2} (logx_i - μ)^2)\nCode\n# Load the nest size data\n\nrm(list=ls())\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\nfuses &lt;- read.csv(\"data/fuses.csv\",header=FALSE)\n#colnames(fuses) &lt;- c(\"n\")\nx &lt;- fuses$V1\nn &lt;- length(x) # Number of observations\n# how many rows in the data\nnrow(fuses)\n\n\n[1] 400\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 0\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, freq=FALSE, xlab=\"Fuses\", ylab=\"Density\", main=\"Empirical distribution of fuses failure times\")\n\n\n\n\n\n\n\n\nFigure 74.1: Histogram of the fuses failure times\nCode\n# MCMC algorithm for fitting a mixture of exponential and log-normal distributions\n# The actual MCMC algorithm starts here\n\n## MCMC iterations of the sampler\n\niterations &lt;- 11000\nburn       &lt;- 1000\n\n## Initialize the parameters, latent vars & Priors\nKK    = 2                # Number of components\nw     = 0.1              # fewer zeros\nw     = rbeta(1, 1, 9)     # Uniform prior on w\nalpha = 2\nbeta  = 1\n\nmu     = mean(log(x))\ntau    = sd(log(x))\nlambda = 20 / mean(x)\n\n\naa     =  c(1, 1)        # Uniform prior on w\nprob   = aa/sum(aa)\n# latent indicators\ncc     = sample(1:KK, n, replace = TRUE, prob = prob)\n# Storing the samples\ncc.out     = array(0, dim=c(iterations, n))\nw.out      = numeric(iterations)\nlambda.out = numeric(iterations)\ntau.out    = numeric(iterations)\n#mu.out     = array(0, dim=c(iterations, KK))\nmu.out    = numeric(iterations)\n\nlogpost    = rep(0, iterations)\n\n\n# MCMC iterations\n\nfor (s in 1:iterations) {      \n  # Full conditional for cc\n  v = rep(0,2)\n  for(i in 1:n){\n    v[1]  = log(w) + dexp(x[i], lambda, log=TRUE)\n    v[2]  = log(1-w) + dlnorm(x[i], mu, tau, log=TRUE)\n    v     = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:2, 1, replace=TRUE, prob=v)\n  }\n  #print(cc)\n \n  # Sample the weights\n  # Full conditional for w\n\n  w = rbeta(1, 1+sum(cc==1), 1+sum(cc==2))\n\n  # Full conditional for lambda\n  lambda = rgamma(1, 1 + sum(cc==1), 1 + sum(x[cc==1]))\n\n  # Full conditional for mu\n  mean.post = (sum(log(x[cc==2]))/tau^2 + 0)/(sum(cc==2)/tau^2 + 1)\n  std.post = sqrt(1/(sum(cc==2)/tau^2 + 1))\n  mu = rnorm(1, mean.post, std.post)\n\n  # Full conditional for tau\n  #tau = sqrt(1/rgamma(1, 2 + sum(cc==2)/2, 1 + 0.5*sum((log(x[cc==2]) - mu)^2)))\n  tau2 = 1/rgamma(1, 2 + sum(cc==2)/2, 1 + 0.5*sum((log(x[cc==2]) - mu)^2))\n  tau = sqrt(tau2)\n\n  # Store samples\n  cc.out[s,]     = cc\n  w.out[s]       =  w\n  lambda.out[s]  = lambda\n  mu.out[s]      = mu\n  tau.out[s]     = tau\n}\nThe posterior means, rounded to two decimal places, are E{w} \\approx 0.10, E{λ} \\approx 2.29, E{μ} \\approx 0.79 and E{τ} \\approx 0.38.\nCode\n# Posterior summaries\nw.post = w.out[-(1:burn)]\nlambda.post = lambda.out[-(1:burn)]\nmu.post = mu.out[-(1:burn)]\ntau.post = tau.out[-(1:burn)]\n\ncat(\"Posterior mean of w:\", round(mean(w.post),2), \"\\n\")\n\n\nPosterior mean of w: 0.1 \n\n\nCode\ncat(\"Posterior mean of lambda:\", round(mean(lambda.post),2),\"\\n\")\n\n\nPosterior mean of lambda: 2.43 \n\n\nCode\ncat(\"Posterior mean of mu:\", round(mean(mu.post),2),\"\\n\")\n\n\nPosterior mean of mu: 0.79 \n\n\nCode\ncat(\"Posterior mean of tau:\", round(mean(tau.post),2),\"\\n\")\n\n\nPosterior mean of tau: 0.38\nadd unit tests for the posterior means\nCode\nlibrary(testthat)\ntestthat::test_that(\"Posterior means are correct\", {\n  expect_equal(round(mean(w.post),2), 0.10)\n  expect_equal(round(mean(lambda.post),2), 2.29,tolerance = 0.15)\n  expect_equal(round(mean(mu.post),2), 0.79)\n  expect_equal(round(mean(tau.post),2), 0.38)\n})\n\n\nTest passed 🥇",
    "crumbs": [
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Markov chain Monte Carlo algorithms for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L04-Ex2.html#hw---simulation-of-lifetime-of-fuses",
    "href": "C3-L04-Ex2.html#hw---simulation-of-lifetime-of-fuses",
    "title": "74  Markov chain Monte Carlo algorithms for Mixture Models",
    "section": "",
    "text": "NoteInstructions\n\n\n\nData on the lifetime (in years) of fuses produced by the ACME Corporation is available in the file data/fuses.csv.\n\nf(x)=w \\lambda \\exp \\left\\{−λx\\right\\}+(1−w) \\frac{1}{\\sqrt{2\\pi}\\tau x} \\exp\\left\\{− \\frac{1}{2τ^{2}} (\\log(x)−μ)^{2} \\right\\}, \\quad x &gt; 0.\n\\tag{74.1}\nThe first component, which corresponds to an exponential distribution with rate \\lambda, is used to model low-quality components with a very short lifetime. The second component, which corresponds to a log-Gaussian distribution, is used to model normal, properly-functioning components.\nYou are asked to modify the implementation of the MCMC algorithm contained in the Reading “Sample code for MCMC example 1” so that you can fit this two-component mixture distributions instead. You then should run your algorithm for 10,000 iterations after a burn-in period of 1,000 iterations and report your estimates of the posterior means, rounded to two decimal places. Assume the following priors: w∼Uni[0,1], λ∼Exp(1), μ∼Normal(0,1) and τ^2∼IGam(2,1).\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nThe code you generate should follow the same structure as “Sample code for MCMC example 1”. In particular, focus on a Gibbs sampler that alternates between the full conditionals for \\omega, \\lambda,\\mu,\\tau^2 and the latent component indicators c_1,...,c_n\nPeer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect the fact that\n\nparameters have been initialized in a reasonable way,\neach of the two full conditional distributions associated with the sampler are correct, and\nthe numerical values that you obtain are correct. To simplify the peer-review process, assume that component 1 corresponds to the exponential distribution, while component 2 corresponds to the log-Gaussian distribution.",
    "crumbs": [
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Markov chain Monte Carlo algorithms for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L05.html",
    "href": "C3-L05.html",
    "title": "75  M4L5 - Density Estimation",
    "section": "",
    "text": "75.1 Density Estimation using Mixture Models (Video)",
    "crumbs": [
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>M4L5 - Density Estimation</span>"
    ]
  },
  {
    "objectID": "C3-L05.html#sec-density-estimation-using-mixture-models",
    "href": "C3-L05.html#sec-density-estimation-using-mixture-models",
    "title": "75  M4L5 - Density Estimation",
    "section": "",
    "text": "Density Estimation using Mixture Models\n\n\n75.1.1 KDE\n\nthe typical method for estimating the density of a random variable is to use a kernel density estimator (KDE)\nthe KDE is a non-parametric method that estimates the density of a random variable by averaging the contributions of a set of kernel functions centered at each data point\n\n\nX_1, \\ldots, X_n \\sim f(x)\n\n\n\\tilde{f}(x) = \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{h}  g \\left (\\frac{\\|X - X_i\\|}{h}\\right )\n\\tag{75.1}\n where h is the bandwidth of the kernel and g is a kernel function. The kernel function is a non-negative function that integrates to 1 and is symmetric around 0.\n For example, the Gaussian kernel is given by: \ng(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n\\tag{75.2}\ngiving us:\n\n\\tilde{f}(x) = \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{h}  \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{|X - X_i|^2}{2h^2}}\n\\tag{75.3}\n\n\n75.1.2 Mixture of K components\n\na mixture of K components is a parametric method that estimates the density of a random variable by averaging the contributions of K kernel functions, each centered at a different location and with a different scale\nthe mixture model is given by:\n\n\nX_1, \\ldots, X_n \\sim f(x) = \\sum_{k=1}^K w_k g(x \\mid \\hat{\\theta}_k)\n\\tag{75.4}\nwhere w_k is the weight of the k-th component, \\hat{\\theta}_k is the location and scale of the k-th component, and g(x \\mid \\hat{\\theta}_k) is the kernel function centered at \\hat{\\theta}_k. The weights are non-negative and sum to 1.\nExample: a location mixture of K Gaussian distributions is given by:\n\nX_1, \\ldots, X_n \\sim \\hat{f}(x) = \\sum_{k=1}^K \\hat{w}_k \\frac{1}{\\sqrt{2\\pi}\\hat{\\sigma}} \\exp^{-\\frac{(x - \\hat{\\mu}_k)^2}{2\\hat{\\sigma}^2}}\n\\tag{75.5}\nwhere \\hat{w}_k is the weight of the k-th component, \\hat{\\mu}_k is the mean of the k-th component, and \\hat{\\sigma} is the standard deviation of the k-th component.\nwe can see the the two methods are quite similar, but the mixture model is more flexible and can capture more complex shapes in the data.\n\nThe KDE is a special case of the mixture model where all the components have the same scale and location.\nKDE needs as many components as the number of data points, while the mixture model can have fewer components.\nKDE uses a fixed bandwidth,\nMDE can adaptively choose the bandwidth for each component. In fact we have a weight for each component and a scale parameter that controls the width of the kernel function.\nMDE tends to use less components and the weights tend to be 1/K\n\nThe above model can be improved by:\n\nusing a scale-location mixture model, where the scale and location of each component are estimated from the data.\n\n\n\n75.1.3 Density Estimation Example (Video)\n We use the galaxies dataset to illustrate the differences between the two methods.\nThe galaxies dataset contains the velocities of 82 galaxies in the Virgo cluster. The data is available in the MASS package.\n\n\n75.1.4 Sample code for Density Estimation Problem\n\n\nCode\n## Using mixture models for density estimation in the galaxies dataset\n## Compare kernel density estimation, and estimates from mixtures of KK=6\n## components obtained using both frequentist and Bayesian procedures\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(MCMCpack)\ndata(galaxies)\nKK = 6          # Based on the description of the dataset\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n### First, compute the \"Maximum Likelihood\" density estimate associated with a location mixture of 6 Gaussian distributions using the EM algorithm\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\n\nepsilon = 0.000001\ns       = 0\nsw      = FALSE\nKL      = -Inf\nKL.out  = NULL\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(k in 1:KK){\n    v[,k] = log(w[k]) + dnorm(x, mu[k], sigma,log=TRUE)  \n  }\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))\n  }\n  \n  ## M step\n  # Weights\n  w = apply(v,2,mean)\n  mu = rep(0, KK)\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Standard deviations\n  sigma = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n    }\n  }\n  sigma = sqrt(sigma/sum(v))\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -835.733942489325\"\n[1] \"2 -828.010809264972\"\n[1] \"3 -824.746233906969\"\n[1] \"4 -822.658999626022\"\n[1] \"5 -821.213895212478\"\n[1] \"6 -820.205593334589\"\n[1] \"7 -819.45255265569\"\n[1] \"8 -818.824551232431\"\n[1] \"9 -818.236534003549\"\n[1] \"10 -817.634208984436\"\n[1] \"11 -816.982967592922\"\n[1] \"12 -816.261886189958\"\n[1] \"13 -815.461265773593\"\n[1] \"14 -814.58192426664\"\n[1] \"15 -813.634925825188\"\n[1] \"16 -812.640825431584\"\n[1] \"17 -811.627832678685\"\n[1] \"18 -810.628730004626\"\n[1] \"19 -809.676914791807\"\n[1] \"20 -808.802324442178\"\n[1] \"21 -808.028006389222\"\n[1] \"22 -807.36782257363\"\n[1] \"23 -806.825578229162\"\n[1] \"24 -806.395771901538\"\n[1] \"25 -806.065864649222\"\n[1] \"26 -805.819434169721\"\n[1] \"27 -805.63925361852\"\n[1] \"28 -805.509531004204\"\n[1] \"29 -805.417065498588\"\n[1] \"30 -805.351515365637\"\n[1] \"31 -805.305136223748\"\n[1] \"32 -805.272302459567\"\n[1] \"33 -805.249006220074\"\n[1] \"34 -805.232424348309\"\n[1] \"35 -805.220578980422\"\n[1] \"36 -805.212086217934\"\n[1] \"37 -805.205976247832\"\n[1] \"38 -805.201567151818\"\n[1] \"39 -805.19837733157\"\n[1] \"40 -805.196065008484\"\n[1] \"41 -805.194386438224\"\n[1] \"42 -805.193166975027\"\n[1] \"43 -805.192280944541\"\n[1] \"44 -805.191637566216\"\n\n\nCode\nxx  = seq(5000,37000,length=300)\nnxx = length(xx)\ndensity.EM = rep(0, nxx)\nfor(s in 1:nxx){\n  for(k in 1:KK){\n    density.EM[s] = density.EM[s] + w[k]*dnorm(xx[s], mu[k], sigma)\n  }\n}\n\n### Get a \"Bayesian\" kernel density estimator based on the same location mixture of 6 normals\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(1,KK)  \neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/KK\n\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\ncc    = sample(1:KK, n, replace=T, prob=w)\n\n## Number of iterations of the sampler\nrrr   = 12000\nburn  = 2000\n\n## Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = rep(0, rrr)\nlogpost   = rep(0, rrr)\n\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  \n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n  \n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(1/rgamma(1, dd.star, qq.star))\n  \n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s,]    = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dnorm(x[i], mu[cc[i]], sigma, log=TRUE)\n  }\n  logpost[s] = logpost[s] + log(ddirichlet(w, aa))\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log=TRUE)\n  }\n  logpost[s] = logpost[s] + dgamma(1/sigma^2, dd, qq, log=TRUE) - 4*log(sigma)\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n\n\nCode\n## Compute the samples of the density over a dense grid\ndensity.mcmc = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n    for(k in 1:KK){\n        density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn])\n    }\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\n## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate and frequentist point estimate\ncolscale = c(\"black\", \"blue\", \"red\")\nyy = density(x)\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Velocity\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=colscale[1], lwd=2)\nlines(xx, density.EM, col=colscale[2], lty=2, lwd=2)\nlines(yy, col=colscale[3], lty=3, lwd=2)\npoints(x, rep(0,n))\nlegend(27000, 0.00017, c(\"KDE\",\"EM\",\"MCMC\"), col=colscale[c(3,2,1)], lty=c(3,2,1), lwd=2, bty=\"n\")",
    "crumbs": [
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>M4L5 - Density Estimation</span>"
    ]
  },
  {
    "objectID": "C3-L06.html",
    "href": "C3-L06.html",
    "title": "76  M4L6 - Clustering",
    "section": "",
    "text": "76.1 Clustering",
    "crumbs": [
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>M4L6 - Clustering</span>"
    ]
  },
  {
    "objectID": "C3-L06.html#clustering",
    "href": "C3-L06.html#clustering",
    "title": "76  M4L6 - Clustering",
    "section": "",
    "text": "76.1.1 Mixture Models for Clustering\n\n\n76.1.2 Clustering example\n\n\nCode\n## Using mixture models for clustering in the iris dataset\n## Compare k-means clustering and a location and scale mixture model with K normals\n\n### Loading data and setting up global variables\nrm(list=ls())\nlibrary(mclust)\n\n\nPackage 'mclust' version 6.1.1\nType 'citation(\"mclust\")' for citing this R package in publications.\n\n\nCode\nlibrary(mvtnorm)\n\n\n\nAttaching package: 'mvtnorm'\n\n\nThe following object is masked from 'package:mclust':\n\n    dmvnorm\n\n\nCode\n### Defining a custom function to create pair plots\n### This is an alternative to the R function pairs() that allows for \n### more flexibility. In particular, it allows us to use text to label \n### the points\npairs2 = function(x, col=\"black\", pch=16, labels=NULL, names = colnames(x)){\n  n = dim(x)[1]\n  p = dim(x)[2]\n  par(mfrow=c(p,p))\n  for(k in 1:p){\n    for(l in 1:p){\n      if(k!=l){\n        par(mar=c(3,3,1,1)+0.1)\n        plot(x[,k], x[,l], type=\"n\", xlab=\"\", ylab=\"\")\n        if(is.null(labels)){\n          points(x[,k], x[,l], pch=pch, col=col)\n        }else{\n          text(x[,k], x[,l], labels=labels, col=col)\n        }\n      }else{\n        plot(seq(0,5), seq(0,5), type=\"n\", xlab=\"\", ylab=\"\", axes=FALSE)\n        text(2.5,2.5,names[k], cex=1.2)\n      }\n    }\n  }\n}\n\n## Setup data\ndata(iris)\nx       = as.matrix(iris[,-5])\nn       = dim(x)[1]\np       = dim(x)[2]       # Number of features\nKK      = 3\nepsilon = 0.0000001\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1))\ncolscale = c(\"black\",\"blue\",\"red\")\nshortnam  = c(\"s\",\"c\",\"g\")\npairs2(x, col=colscale[iris[,5]], labels=shortnam[as.numeric(iris[,5])])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nnumruns = 15\nv.sum   = array(0, dim=c(numruns, n, KK))\nQQ.sum  = rep(0, numruns)\n\nfor(ss in 1:numruns){\n  w   = rep(1,KK)/KK  #Assign equal weight to each component to start with\n  mu  = rmvnorm(KK, apply(x,2,mean), 3*var(x))   #Cluster centers randomly spread over the support of the data\n  Sigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\n  Sigma[1,,] = var(x)\n  Sigma[2,,] = var(x)\n  Sigma[3,,] = var(x)\n  \n  sw     = FALSE\n  QQ     = -Inf\n  QQ.out = NULL\n  s      = 0\n  \n  while(!sw){\n    ## E step\n    v = array(0, dim=c(n,KK))\n    for(k in 1:KK){  #Compute the log of the weights\n      v[,k] = log(w[k]) + mvtnorm::dmvnorm(x, mu[k,], Sigma[k,,], log=TRUE) \n    }\n    for(i in 1:n){\n      v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n    }\n    \n    ## M step\n    w = apply(v,2,mean)\n    mu = matrix(0, nrow=KK, ncol=p)\n    for(k in 1:KK){\n      for(i in 1:n){\n        mu[k,]    = mu[k,] + v[i,k]*x[i,]\n      }\n      mu[k,] = mu[k,]/sum(v[,k])\n    }\n    Sigma = array(0,dim=c(KK, p, p))\n    for(k in 1:KK){\n      for(i in 1:n){\n        Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n      }\n      Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n    }\n    \n    ##Check convergence\n    QQn = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        QQn = QQn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n      }\n    }\n    if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n      sw=TRUE\n    }\n    QQ = QQn\n    QQ.out = c(QQ.out, QQ)\n    s = s + 1\n  }\n  \n  v.sum[ss,,] = v\n  QQ.sum[ss]  = QQ.out[s]\n  print(paste(\"ss =\", ss))\n}\n\n\n[1] \"ss = 1\"\n[1] \"ss = 2\"\n[1] \"ss = 3\"\n[1] \"ss = 4\"\n[1] \"ss = 5\"\n[1] \"ss = 6\"\n[1] \"ss = 7\"\n[1] \"ss = 8\"\n[1] \"ss = 9\"\n[1] \"ss = 10\"\n[1] \"ss = 11\"\n[1] \"ss = 12\"\n[1] \"ss = 13\"\n[1] \"ss = 14\"\n[1] \"ss = 15\"\n\n\nCode\n## Cluster reconstruction under the mixture model\ncc = apply(v.sum[which.max(QQ.sum),,], 1 ,which.max)\ncolscale = c(\"black\",\"blue\",\"red\")\npairs2(x, col=colscale[cc], labels=cc)\n\n\n\n\n\n\n\n\n\nCode\nARImle = adjustedRandIndex(cc, as.numeric(iris[,5]))  # Higher values indicate larger agreement\n\n## Cluster reconstruction under the K-means algorithm\nirisCluster &lt;- kmeans(x, 3, nstart = numruns)\ncolscale = c(\"black\",\"blue\",\"red\")\npairs2(x, col=colscale[irisCluster$cluster], labels=irisCluster$cluster)\n\n\n\n\n\n\n\n\n\nCode\nARIkmeans = adjustedRandIndex(irisCluster$cluster, as.numeric(iris[,5]))",
    "crumbs": [
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>M4L6 - Clustering</span>"
    ]
  },
  {
    "objectID": "C3-L07.html",
    "href": "C3-L07.html",
    "title": "77  M4L7 -Classification",
    "section": "",
    "text": "77.1 Classification\nClassification is a supervised learning problem where we want to predict the class of a new observation based on its features.\nAccording to the instructor the main difference from clustering is that in classification we have a training set. I would think the main difference is that we have labels for some of the data, while in clustering we do not have labels at all.\nThe fact that we have labels and a training set means we should know how many classes we have and we can use these labels to train a model and use it to predict the class of a new observation.\nThe instructor mentions Support Vector Machines (SVM), logistic regression and linear discriminant analysis (LDA) as familiar examples of classification methods. These and a number of others are covered in (James et al. 2013). We will focus on Naive Bayes classifiers as it is the most similar to mixture models and the EM algorithm which we have seen earlier",
    "crumbs": [
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>M4L7 -Classification</span>"
    ]
  },
  {
    "objectID": "C3-L07.html#classification",
    "href": "C3-L07.html#classification",
    "title": "77  M4L7 -Classification",
    "section": "",
    "text": "77.1.1 Mixture Models and naive Bayes classifiers\n\n\n\n\nK-means clustering\n\n\n\n\nK-means clustering\n\n\n\n\nMixture Models for Clustering\n\n\n\n\n77.1.1.1 Naive Bayes classifiers\nThe idea of Naive Bayes classifiers is that we want to know what is the probability that observation i belongs to class k and we can obtain this using Bayes’ theorem by computing the prior probability that an observation is in that class. This is just the frequency of the class multiplied by the density of that class and divided by the sum over the classes of the same expression.\n\n\\mathbb{P}r(x_i \\in \\text{class}_k) = \\frac{w_k \\cdot g_k(x_i|\\theta_k)}{\\sum_{j=1}^K w_j \\cdot g_j(x_i|\\theta_j)}\n\\tag{77.1}\nwhere w_k is the prior probability of class k, g_k(x_i|\\theta_k) is the density of class k, and \\theta_k is the parameter of class k.\nwith\n\n\\tilde{c}_i = \\arg \\max_k \\mathbb{P}r(x_i \\in \\text{class}_k)\\ for \\; i=n+1,\\ldots,n+m\n\nThe naive Bayes classifier assumes that the features are conditionally independent given the class. This means that the density of class k can be written as the product of the densities of each feature given the class: \ng_k(x_i|\\theta_k) = \\prod_{l=1}^p g_{kl}(x_{il}|\\theta_{kl})\n\nwhere g_{kl}(x_{il}|\\theta_{kl}) is the density of feature l given class k and \\theta_{kl} is the parameter of feature l given class k. This means that we can estimate the density of each feature separately and then multiply them together to get the density of the class.\nThis is a very strong assumption and is not true in general. However, it works well in practice and is often used in text classification problems where the features are the words in the text.\nThe naive Bayes classifier is a special case of the mixture model where the components are the classes and the densities are the product of the densities of each feature given the class. This means that we can use the EM algorithm to estimate the parameters of the model in the same way as we did for the mixture model. The only difference is that we need to estimate the densities of each feature separately and then multiply them together to get the density of the class.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nThe last class of problems for which mixture models are very useful is classification problems. If you come from the machine learning literature, you will call this supervised classification to contrast, again, unsupervised classification that I called clustering before. The goal in supervised classification is to start with a training set and use the information in a training set to determine the classes or the labels of a second group of observations that you call the test set. So you start with a training set that contains known labels classes. You also have a test set that has unknown labels, and you want to use this information to make predictions about the test set labels. For example, you may want to decide whether a person suffers from a disease or not based on a set of medical tests, maybe P medical tests, and you have gone out and measured those tests in a number of individuals. So you know those individuals whether they are sick or they are not sick. Based on that training set that is labeled where you know what the real quality of the individuals is, then you go out and you are going to pick just a random person that comes into your medical appointment, and based on the results of the test, now you want to decide if that individual suffers from the disease or not. So the presence of the training set is really what distinguishes clustering problems from classification problems. In clustering problems, we don’t have a training set. We don’t have anything that gives us a hint about how the classes look like. We’re trying to do the process of dividing the observations into groups in some sense blindly. That’s why it’s sometimes called unsupervised classification because you can think that the training set provides supervision in how you do the classification. In typical supervised classification problems on the other hand, you do have that training set. You do have that group of labeled observations that can help you make decisions about how the new groups will look like. So in some sense, supervised classification is a simpler problem than unsupervised classification because of the presence of the training set. Now, there are a number of classification procedures out there. This is a fairly common problem in the literature. You may be familiar with things like support vector machines or logistic regression for classification. I want to discuss today the similarities between using mixture models for classification and some techniques such as linear discriminant analysis, and in particular with Naive Bayes classifiers. The idea of Naive Bayes classifiers is very simple. So if you want to know what is the probability that observation i belongs to class k, you can typically obtain that by just using Bayes’ theorem by computing the prior probability that an observation is in that class. That is typically just the frequency of the class multiplied by the density of that class and divided by the sum over the classes of the same expression. Now, again, this should be very familiar. This quantity here is essentially what we used both in the EM algorithm to compute the [inaudible] case and in the MCMC algorithm if you are fitting a mixture model from a Bayesian perspective to sample the class labels C sub x. So in other words, it’s clear just from writing the expression from Naive Bayes that there should be a very close relationship between doing Naive Bayes and doing mixture models. In fact, you can cast Naive Bayes classifiers as just as a special case of mixture models. Let’s discuss Naive Bayes classifiers where we use Gaussian kernels for the classification. Let’s enter this a little bit of notation. So remember that we have both a test set and a training set. So let’s call X_1 up to X_n my training set, and let’s call X_n plus 1 up to X_n plus m the test set. In other words, we have n observations in the training set, we have m observations in the test set and we just group the observations together so that the first n in the sample are the training and last m are the test. In addition to this, because the training set is labeled, we’re going to have C_1 up to C_n are known, but C_1 or C_n plus 1 up to C_m plus n are unknown and we want to protect them. Let’s write a Naive Bayes classifier that uses Gaussian kernels, and we’re going to use the more general Gaussian kernels that we can. So in that case, the probability that observation i belongs to class k, it’s going to be equal to Omega_k 1 over the square root 2 Pi to the p. Remember that we’re working with P variate normal. So we can have P features for each individual, determinant of Sigma_k to the minus one 1/2 X of minus one 1/2 X_i minus Mu k transpose sigma sub k inverse X_i minus Mu k, divided by the sum over the components of exactly the same expression. This has to be l, minus Mu sub l transpose sigma l inverse X_i minus Mu l. So this is just Bayes theorem as we have written multiple times in this course. So what you do is, you need this expression only for the training set because for the test set you already know what class you are in. So what you typically do is a two-step process in which you get Mu k hat and Sigma hat sub k are estimated from the training set. You could do different things, but it’s very fairly common to just fit a multivariate Gaussian to each one of the components. So your Cs, your labels divide your training set into groups. For each one of those groups, you fit one different normal and that gives you Sigma and Mu. Similarly, for Omega k, you want to get an estimate for Omega k, and the natural thing to do is to just use the frequency, the fraction of the observations in the training set that belong to each one of the classes. Once you have those, then you classify new observations as by letting C_i be equal to the org max of that probability. Where the probabilities are computed by plugging in these maximum likelihood estimators in this formula up here. As I said, this is done for n plus 1 all the way to n plus m. So you don’t need to do this for the training set, the training set you know the labels and you use those labels to compute the MLEs that get plugged into this. Now, with additional observations in those MLEs, you can decide what are the classes for them. So this is what a naive Bayes classifier based on Gaussian distributions for each one of the classes would look like. Now, this is exactly the same as the EM algorithm that we have discussed in the past for mixture models, if we make a couple of assumptions or if we incorporate a couple of assumptions into the algorithm. So let’s write down that next. We can recast the algorithms that we just saw for naive Bayes classifier based on Gaussian kernels in the context of the EM algorithm that we have been discussing for mixtures. That is very easy, we’re going to think, again, about an E-step and an M-step, and we’re going to add an additional post-processing step, if you will. In our E-step, if you remember, what we did in the past was to compute the indicators for the variables. So that is our variables V_i,k that corresponds to the weights that are associated with each one of the components. What we’re going to do in this case is we’re going to define the V_i,k in a very simple fashion rather than doing it using Bayes theorem. Because we actually know what observations or what components are generating each of the observations in the training set, we can call V_i,k just one or zero if C_i is equal to k and zero otherwise, for all the observations that go from one to n. In other words, this is for the training set. Once we have defined our E-step in this way, we’re going to have an M-step where we compute Mu sub k and Omega sub k. To put it in the same way that we did with the EM algorithm, this is going to have a very particular shape. It’s going to have the sum from one to n of V_i,k X_i divided by the sum from one to n of V_i,k. In a similar expression for my matrix Sigma, Sigma is going to be Sigma sub k, it’s going to be one over the sum of the V_i,k from one to n, sum from one to n of V_i,k X_i minus Mu k, X_i minus Mu k transpose. These are expressions that we have seen in the past when filling mixtures of multivariate Gaussians to data. This is just a fancy way, so casting it in terms of the E-step and the M-step, it’s just a fancy way to say, I know what my assignments are, for sure, because this is a training set. So this is just computing the average of the observations that are in category K because, in this case, these are either zeros or ones. Similarly, here, this is just the variance covariance matrix of the observations that are in component K, but it’s written in a fancy way using this V_i,k as indicators. Then, we have a post-processing. It’s in the post-processing step where the test set comes into play. So for now, we have only used the training set for our calculations. In the post-processing step, what we do is we allocate C_i based on the arc max over K of the posterior distribution of the class allocations. So that is probability that X_i belongs to class K. So this is just another way to write the algorithms as we had before, that is very simple in the context of [inaudible]. So why did I go through the trouble of expressing this in this complicated manner when I had a very simple description before? Well, because now you can try to generalize this from this supervised setting where you completely break apart the estimation of the parameters that only uses the training set and the classification that only uses the test set. You can actually try to combine information from both, and it should be clear that if you have training sets that are just very small compared to the test set, the estimates that you get for Mu and Sigma will be very bad because they will be based on very few observations, very few data points. So if you could somehow use some of the information that you are recovering by doing the classification to help you estimate what Mu and Sigma are, they’ll probably give you more robust, stronger algorithm. How to do that should be relatively straightforward once you think about it in this context. For the observations to the training set, we have the value of the V_i,k, but we could add an estimate of the value of the V_i,k for the observations in the test set to this calculation. We already know how to do that. So we’re going to turn the algorithm iterative now. So these guys are always going to be defined in this way because I know the C’s, but these guys are refined at every iteration of the algorithm. I’ll just make this essentially equal to the probability that X_i belongs to class K given the current parameters of the model, so given the current Omegas, the current Mus, and the current Sigmas. Then, I can extend my sums to m down here and down here. Now, what I’m doing is, for the observations that I know what class they are in, these weights are either zeros or ones. For the ones that I don’t know but I’m trying to classify, they will be some number between zero and one, and I’m just going to do a weighted average so you can think about this, again, as a weighted average of the information that I know for sure, and the information that I’m recovering about Mu and Sigma from the classification. So again, this now becomes an iterative algorithm, so I need to think about t plus 1, t plus 1, t plus 1, t plus 1, t plus 1, t plus 1, and t plus 1. So I have turned what was just a two-step algorithm that doesn’t require any iteration, I turned it into an iterative algorithm that uses the whole sample to estimate the parameters of the classes. This is sometimes called a semi-supervised; I don’t necessarily like the term very much. But this is sometimes called a semi-supervised algorithm, in the sense that it’s not completely supervised because of the addition of this information and the fact that now, the sums go up to m. But it’s also not fully unsupervised because I’m using the information, I’m using this piece up here that has information where I know their true labels. Once the algorithm converges, I’m still going to do the post-processing step that is to go from this V_i,k’s that I computed here for the test set to generate what are the labels for those observations.\n\n\n\n\n\n\n77.1.2 LDA and the EM algorithm\n\n\n\n\nLDA\n\n\n\n\nLDA\n\n\nIt is important to understand the connection between using mixture models for classification and other procedures that are commonly used out there for classification. One example of those procedures that has a strong connection is linear discriminant analysis and also to quadratic discriminant analysis.\nTo illustrate that connection, we start with a very simple mixture model.\nSo let’s start with a mixture model of the form,\n\nf(x) = \\sum_{k=1}^2 \\omega_k \\frac{1}{\\sqrt{2\\pi}} \\frac{1}{\\sqrt{\\text{det}(\\Sigma)}} e^{-\\frac{1}{2}(x - \\mu_k)^T \\Sigma^{-1} (x - \\mu_k)}.\n\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nIt is important to understand the connection between using mixture models for classification and other procedures that are commonly used out there for classification. One example of those procedures that has a strong connection is linear discriminant analysis. And also, by the way, quadratic discriminant analysis. But let’s start with linear discriminant analysis.\nAnd to illustrate that connection, let’s start with a very simple mixture model.\nSo let’s start with a mixture model of the form, f(x) = the sum from 1 to 2. So I’m going to be working only with two components of omega k, 1 over the square root 2pi to the p determinant of sigma to the -1 half, x- 1 half, x, mu sub k, transpose sigma inverse, x- mu sub k. So this is two-component mixture with locations bearing with a component, but the same variance-covariance matrix for the two components that I have in the mixture.\nAnd let’s think about how the procedure would look like if we were to do Naive Bayes classification using this mixture. If I follow the unsupervised example that I have discussed before, the probability that I put observation i in class, 1, say, I only have two classes.\nSo as you see again, consider one of them and the other one is just 1- the numbers that I get here. It’s going to be equal.\nAnd I’m going to expand this in all its glory. It’s going to be a little bit long. So it’s going to be omega 1, 1 over the square root 2pi to the p determinant of sigma to the- 1 half, x of- 1 half, x- mu k transpose sigma inverse x- mu k. And in the denominator, we’re going to have the same expression first. And then we’re going to have omega 2, that is just 1- omega 1 but 2pi to the p determinant of sigma to the- 1 half x- 1 half x- mu 2, sigma inverse x- mu 2. Okay, and we know that the probability that xi belongs to class 1 is exactly the same expression but replacing mu, 1 which is what should be up here, replacing mu1 with mu2.\nSo, in the post processing step, we are going to assign C sub i = 1 if and only if the probability that xi belongs to class 1 is greater than the probability that xi belongs to class 2. And because the two expressions are the same in the denominator, the only thing that changes is the numerator, then this happens if and only if omega 1, 1 over the square root 2pi to the p determinant sigma to the- 1 half x- 1 half, X- mu1 transpose sigma inverse x- mu1, Is greater than omega 2, 1 over the square root 2pi to the p determinant of sigma to the- 1 half x of- 1 half x- mu2, sigma inverse x- mu2. So probability of class 1 greater than probability of class 2 only if this quantity is greater than the same thing but evaluated for the second component in the mixture. So let’s do a little bit of algebra and let’s try to simplify this expression a little bit and we will see that that simplification leads to a very nice expression that matches exactly what you get out of linear discriminant analysis. So now we want to simplify this expression that corresponds to the situation where we’re going to label an observation coming from class 1, and we want to make it much more compact. So a few things that we can observe. So one of them is we have 1 over square root 2pi to the p on both sides, so we can cancel that. The other thing that we observe is that we have the determinant of the variance-covariance matrix on both sides. And because we’re assuming that the two components have the same variance- covariance matrix, we can again just simplify both terms on either side. And the next thing that I’m going to do is I’m going to move all the omegas to one side and bring all the terms with the exponentials to the other side. If I do that, I’m going to end up on the left hand side with the exponent of- 1 half, X- mu1 transpose sigma inverse x- mu1. And then this term came to the other side in the denominator, but that just means that when it goes into the exponential, I need to change all to reverse signs. So it’s going to be- x- mu2 transpose sigma inverse x- mu2. So that’s the expression once you move this to the denominator and combine the two exponentials. And this needs to be greater than omega 2 divided by omega 1. Now, some further simplifications. I can take the logarithm on both sides and I can multiply by -2 on both sides, and I end up with an expression that looks like x- mu 1 transpose sigma inverse x- mu1- x- mu 2 transpose sigma inverse x- mu 2 has to be less than, because I’m going to end up multiplying by a -2. So less than -2 log of omega 2 divided by omega 1. So now we have this difference of two quadratic forms needs to be less than a certain constant that depends on what are my prior weights for each one of the two components. Now, to finish simplifying this, we need to expand these two squares, which is pretty straightforward. So first we’re going to have x sigma inverse x transpose sigma inverse x. This is just a square. So it’s going to be 2 times x transpose sigma inverse mu1. And finally, \\mu_1 transpose sigma inverse \\mu_1. And then we need to subtract a similar expression but using mu2 for it turns. So it’s going to be x transpose sigma inverse x. It’s going to be +, in this case, 2x transpose sigma inverse mu2. And finally, again,- mu2 transpose sigma inverse mu2, and all of these needs to be less than -2 log of omega 2, Divided by omega 1. So you can see that the expressions are relatively straightforward.\nAnd one of the things that is very nice, and it’s a consequence of having the same variance-covariance matrix for each one of the components, is that now this quadratic term of the data is going to cancel out. And so, we can just basically learn together a couple of terms. So we can write, 2 times, X transpose sigma inverse multiplied by mu2- mu1. So I’m taking this term and combining it with this term. So, the term here and the term here.\nAnd then I’m going to say that this has to be less than -2 times log of omega 2 divided by omega 1, and I’m going to move this two terms to the right. So,+ mu2 transpose sigma inverse mu2- mu1 transpose sigma inverse mu1. So this is actually quite a bit of simplification and it’s a very interesting one. Because you can think about this, Thing on the right hand side, just call this T for threshold. So this is your sum threshold and that threshold is basically computed based on the training data. So if I know the classes of some observations, I can get what the means for each one of the classes are, I can estimate the common sigma, and I can estimate the relative frequencies. And with that, I can obtain a stress score from the training set. And I can think about this matrix product as sum vector a. The form of this simplified expression is very interesting. You can see that the right-hand side, all this expression in the box, it’s just a threshold that can be easily computed from the training set. We can estimate the weight and we can estimate the mean and the covariance of the two components. And then, this product of the variance-covariance or the inverse of the variance-covariance matrix times the difference of the means corresponds to a vector a that can also be computed from the training set. So essentially, the decision of whether we classify an observation in class 1 or class 2 is going to depend on whether a linear combination, and that’s what x transpose times a is, is just a linear combination of the values of x. So whether this linear combination of the values of x is greater than a given threshold or not. In other words, what we’re doing, In a setting where we only have two variables, for example, x1 and x2, the linear combination of the entries is just a line on the plane. So this product just corresponds to a line. And by deciding whether we are above the line or below the line, we’re just saying that one of the regions corresponds to class, 2, and the other region corresponds to class 1. So this is the reason why the procedure is called linear discriminant analysis because it uses a straight line to decide whether observations should be classified in class 1 and class 2. Now, there are some more interesting things that you can do. For example, you don’t have to assume that the sigmas are the same, you could assume that the sigmas are different. If you were to do that, then you’d be in a situation that is analogous to this one with the main difference being that now these terms here wouldn’t necessarily simplify. But then, you can rearrange terms in such a way that now, you’re going to have a quadratic form of x being less than a certain threshold. And in that case, you’re separating hyperplane. Instead of being a hyperplane or line, it’s going to be a quadratic form. And that is the reason why when you’re doing Naive Bayes and you’re working with kernels that are Gaussian and have different variance-covariance matrices, you call the procedure quadratic discriminant analysis. Because it uses a quadratic form, a parabola or something like that to separate the two classes that you’re working with. The nice thing about thinking about this classification procedures in the context of mixture models is again, thinking about ways in which you can generalize and address the shortcomings of the procedure. It’s clear that the main issue with classification procedures based on Gaussians is that data in the real world sometimes doesn’t look like multivariate Gaussian distributions. So one possible extension is to instead of considering the density, this ps here to be a single Gaussian, you can kind of use mixtures a second time and borrow some ideas from when we did density estimation. And say well, I’m going to have a mixture and each component of that mixture is in turn a second mixture that may have a few components. And that may allow for the shape of the clusters to be much more general, and that’s what we call mixture discriminant analysis. As before, if you instead of doing the Algorithm and the simple maximum likelihood estimation that I described before, you instead use Bayesian estimators for your process, then you will have Bayesian equivalent of linear discriminant analysis and quadratic discriminant analysis. So it is very useful to think about your statistical methods in the context of mixture models for the purpose of both generalizing and understanding the shortcomings of what you’re doing.\n\n\n\n\n\n77.1.3 Linear and quadratic discriminant analysis in the context of Mixture Models\n\n\n77.1.4 Classification example\nThis video discusses the code in the next section.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nI’m going to illustrate now to use of mixture models for classification using the wind dataset. Unlike the previous datasets that we work with, this one is not included in R by default. So the two files that you need wind training and wind tests are available on the website, make sure that you download them and that you have them in the right directory for R to read them. And in this case, I made sure that I change the directory where I’m looking at before I start working with this, and that I put my files in there.\nOkay, so the wind dataset is an interesting one, it’s a series of measurements for different varieties of wine. They come from three different cultivars, and for each particular variety of wine. They did a chemical analysis and measure 13 different variables that have to do with different chemical components present in the world. So we have a label set where we know which samples from which of the three cultivars. And now we want to use the information that we clean out of that to classify to decide a series of new wines to assign them to the cultivar that we think they come from. We actually do know the truth for the test set, so we will actually first do the predictions we’ll act as if we don’t know what the cultivar of the test set is. And then we will compare the predictions that we’re making against the truth, as a way to tell how well the algorithm is to it, okay. So the first thing that we need to do is load our dataset as I said, you need to make sure that the two files are in the directory where you’re working. So make sure of that, remember that we called n the sample size of the training set and m the training size the size of the test set. So I’m just calling the variables that way, and I’m going to use mixture of normals mixture of multivariate normals by location and scale. So I’m going to use a method that is essentially equivalent to doing quadratic discriminant analysis. And, I want to run the Algorithm that I discussed on the board, but in a situation which we assume that we’re going to work with semi-supervised learning. In other words, I went around the Version of the algorithm in which we’re going to use all the observation both in the training and the test set, to learn the parameters of the classes. So it’s going to be an iterative algorithm. So we know in advance as we have three classes because we have three cultivars. B in this case is going to be 13 because there are 13 features that were measured on each wine. So if you come down here, you can see that B 13, we can try to do a graph of the data. In this case the graph is not going to be terribly readable because there are so many variables, but it may still provide a little bit of intuition. So the variables that are measured things like alcohol, the ash, the alkalinity, the level of magnesium, the hue that has to do with how dark the wine is, proline. So you can see here where the variables are there are measured, and even though the graph is not very readable at least you can see that the classes do not fully overlap. So we do have some hope that we may be able to do classification in the problem. That’s pretty much the main thing that you can say out of this graph here, okay. So, as I said before mixture of models with different components, different variances and different means for each component its normal component in the mixture. Same type of standard initialization that we have done before. And we’re going to do the E and the M step here, remember that for the observations in the training set. We know the class, so the value of B are either 0 or 1, and because we do the calculation first in the log scale, then we do either 0 or minus infinity. So 0 corresponds to probability of 1 and minus infinity corresponds to a probability of 0 in the log scale. And then for the observations in the test set, we have just a regular way in which we compute the probability that the observation comes from each class. And once we have done this then we subtract, we do as we have always done subtract maximums and then re-standardize. So this is how the ES step gets adapted in the case of semisupervised classification. And then the structure of the m-step is exactly the same structure of the regular Algorithm. So we compute means and variances for each one of the components as weighted averages of the different quantities. We check conversions in the standard way, in which we have been checking convergence. And finally once everything is done, we will get a classification, so let’s run it for this dataset. It runs actually quite quickly, we have only 12 iterations and we have converged. Now what the Algorithm gives gave us is just the B values, that is the probability that an observation comes from a given class. Now, we typically are going to want to convert those peas into Cs and as we saw on the board, that is done by just selecting the class that has the highest probability.\nSo if we do that for our training set in this case, and if you look at the indexes here, they run from n + 1 to n + m, which means that we’re looking at test set. If we just get what is the maximum we can see that the first block of observations is assigned to component two. Most of this block is assigned to component two except for this guy here, and then the the remaining block of observation is assigned to components three. So now how does that compare with the truth? So we can actually go into winder test, and the first column of that file contains the true labels, and we can say that it matches actually pretty well. So the ones all match, the twos match except for one guy, the one we had kind of identified before, and the threes all match together. And we can actually if you just want to have a summary of how many errors you make. You can do a little comparison like this, and you can find that there is only a single error in the classification that the algorithm does.\nNow let’s compare that with just using quadratic discriminant analysis and linear discriminant analysis. The way they are implemented in R, so QDA and LDA are the two functions that you will need, they are part of the mass package. So, We first feed the QDA model and then we that fitted model to predict the classes. And now if we see what the regular QDA does is it’s going to give me this long list of probabilities for the test set. And we can turn those into labels and in particular we can see how many errors we’re making in the prediction. And you can see that we make a single mistake, which is actually not the mistake that we had made before. So if we just look at this one here and we compare it against the, Classification that our algorithm did, and we compared it against the truth.\nWe see that our algorithm makes a mistake in this observation and QDA does not, and instead the error is somewhere else in this sample. It’s basically here, so you can see that the QDA classifies this as two, when the reality is that it’s a three. So our results are not identical to QDA even though our method is asymptotically going to be equivalent to QDA but they don’t give us exactly the same result, but they give us very similar accuracy. Interestingly if you run LDA and you try to look at how many errors you have in that case, you will see that LDA in this case has no errors, even though it’s a simpler more restrictive classification procedure. So this can happen, so it’s a relatively large sample, so a single a difference in a single error is not a very large difference. So, hopefully this illustrates how classification or how measurements can be used for classification in a real life setting.\n\n\n\n\n\n77.1.5 Sample EM algorithm for classification problems\n\n\nCode\n## Using mixture models for classification in the wine dataset\n## Compare linear and quadratic discriminant analysis and a \n##   (semi-supervised) location and scale mixture model with K normals\n## Comparing only against the EM algorithm\n\n# Semi-supervised, quadratic discriminant analysis \n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(mvtnorm)\nwine.training = read.table(\"data/wine_training.txt\", sep=\",\", header=TRUE)\nwine.test = read.table(\"data/wine_test.txt\", sep=\",\", header=TRUE)\nn = dim(wine.training)[1]  # Size of the training set\nm = dim(wine.test)[1]      # Size of the test set\nx = rbind(as.matrix(wine.training[,-1]), as.matrix(wine.test[,-1]))   # Create dataset of observations, first n belong to the training set, and the rest belong to the test set\np       = dim(x)[2]              # Number of features\nKK      = 3\nepsilon = 0.00001\n\npar(mfrow=c(1,1))\npar(mar=c(2,2,2,2)+0.1)\ncolscale = c(\"black\",\"red\",\"blue\")\npairs(wine.training[,-1], col=colscale[wine.training[,1]], pch=wine.training[,1])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #Cluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\nsw     = FALSE\nKL     = -Inf\nKL.out = NULL\ns      = 0\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n+m,KK))\n  for(k in 1:KK){  #Compute the log of the weights\n    v[1:n,k] = ifelse(wine.training[,1]==k,0,-Inf)  # Training set\n    v[(n+1):(n+m),k] = log(w[k]) + mvtnorm::dmvnorm(x[(n+1):(n+m),], mu[k,], Sigma[k,,],log=TRUE)  # Test set\n  }\n  for(i in 1:(n+m)){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w = apply(v,2,mean)\n  mu = matrix(0, nrow=KK, ncol=p)\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0,dim=c(KK,p,p))\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:(n+m)){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -3146.58419305226\"\n[1] \"2 -2942.48222029706\"\n[1] \"3 -2873.76499310479\"\n[1] \"4 -2852.76768638231\"\n[1] \"5 -2796.247735428\"\n[1] \"6 -2791.29098585679\"\n[1] \"7 -2791.23059641487\"\n[1] \"8 -2791.14094416728\"\n[1] \"9 -2791.05612416221\"\n[1] \"10 -2790.99254414223\"\n[1] \"11 -2790.95228067601\"\n[1] \"12 -2790.92945838389\"\n\n\nCode\n## Predicted labels\napply(v, 1, which.max)[(n+1):(n+m)]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## True labels\nwine.test[,1]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## Comparison\napply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1]\n\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nCode\nsum(!(apply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# Using the qda and lda functions in R\n# qda\nmodqda = qda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredqda = predict(modqda,newdata=wine.test[,-1])\nsum(!(ccpredqda$class == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# lda\nmodlda = lda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredlda = predict(modlda,newdata=wine.test[,-1])\nsum(!(ccpredlda$class == wine.test[,1])) # No errors!!!\n\n\n[1] 0",
    "crumbs": [
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>M4L7 -Classification</span>"
    ]
  },
  {
    "objectID": "C3-L07.html#advanced-density-estimation-and-classification",
    "href": "C3-L07.html#advanced-density-estimation-and-classification",
    "title": "77  M4L7 -Classification",
    "section": "77.2 Advanced Density Estimation and Classification",
    "text": "77.2 Advanced Density Estimation and Classification\n\n77.2.1 Practice Graded Assignment: The EM algorithm and density estimation\n\n\n77.2.2 Honors Peer-graded Assignment: MCMC algorithms and density estimation\n\n\n77.2.3 Honors Peer-graded Assignment: MCMC algorithms and density estimation\n\n\n77.2.4 Honors Peer-graded Assignment: Classification\n\n\n\n\n\n\nJames, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. An Introduction to Statistical Learning: With Applications in r. Springer Texts in Statistics. Springer New York. https://books.google.co.il/books?id=qcI_AAAAQBAJ.",
    "crumbs": [
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>M4L7 -Classification</span>"
    ]
  },
  {
    "objectID": "C3-L07-Ex1.html",
    "href": "C3-L07-Ex1.html",
    "title": "78  Old Faithful eruptions density estimation with the EM algorithm",
    "section": "",
    "text": "78.1 HW - The EM algorithm and density estimation\nIn this exercise, we implement the EM algorithm to fit a location-and-scale mixture of 2 univariate Gaussian distributions to the duration of eruptions of the Old Faithful geyser. We will then use the fitted model to generate a density estimate of the marginal distribution of the duration of the eruptions.\nCode\n###### Setup data\nx = faithful$eruptions\nn = length(x)\n\n###### EM algorithm to fit the location-and-scale mixture of 2 Gaussians\nw      = 0.5          \nmu     = c(mean(x)-sd(x), mean(x)+sd(x))\nsigma  = rep(sd(x)/4,2)\n\ns  = 0\nsw = FALSE\nQQ = -Inf\nQQ.out = NULL\nepsilon = 10^(-5)\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,2))\n  for(i in 1:n){\n    v[i,1] = log(w) + dnorm(x[i], mu[1], sigma[1], log=T)\n    v[i,2] = log(1-w) + dnorm(x[i], mu[2], sigma[2], log=T)\n    v[i,]  = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,]))) \n  }\n\n  ## M step\n  # Weights\n  w  = mean(v[,1])\n  # Means\n  mu = rep(0, 2)\n  for(k in 1:2){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Variances\n  sigma = rep(0,2)\n  for(k in 1:2){\n    for(i in 1:n){\n      sigma[k] = sigma[k] + v[i,k]*(x[i] - mu[k])^2\n    }\n    sigma[k] = sqrt(sigma[k]/sum(v[,k]))\n  }\n  ## Check convergence\n  QQn = 0\n  for(i in 1:n){\n    QQn = QQn + v[i,1]*(log(w) + dnorm(x[i],mu[1],sigma[1],log=TRUE)) +\n                v[i,2]*(log(1-w) + dnorm(x[i],mu[2],sigma[2],log=TRUE))\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n}\n\n\n[1] \"1 -309.450737493483\"\n[1] \"2 -292.32994157869\"\n[1] \"3 -280.279590400843\"\n[1] \"4 -278.882852059725\"\n[1] \"5 -278.687833281763\"\n[1] \"6 -278.515594042029\"\n[1] \"7 -278.371067671734\"\n[1] \"8 -278.269313940617\"\n[1] \"9 -278.20429223392\"\n[1] \"10 -278.164685957935\"\n[1] \"11 -278.141072956464\"\n[1] \"12 -278.127115849347\"\n[1] \"13 -278.118891261794\"\n[1] \"14 -278.114049071933\"\n[1] \"15 -278.111198729535\"\n[1] \"16 -278.109520815145\"\nCode\nxx  = seq(0,7,length=150)\nnxx = length(xx)\ndensity.EM = rep(0, nxx)\nfor(s in 1:nxx){\n  density.EM[s] = density.EM[s] + w*dnorm(xx[s], mu[1], sigma[1]) + \n                                  (1-w)*dnorm(xx[s], mu[2], sigma[2])\n}\nCode\nplot(xx, density.EM, col=\"red\", lwd=2, type=\"l\", xlab=\"Eruptions\")\npoints(x,rep(0,n))\ntitle(main=\"Mixture of 2 Gaussians\")\n\n\n\n\n\n\n\n\nFigure 78.1: Density estimate of the duration of the eruptions using a location-and-scale mixture of 2 univariate Gaussian distributions",
    "crumbs": [
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Old Faithful eruptions density estimation with the EM algorithm</span>"
    ]
  },
  {
    "objectID": "C3-L07-Ex1.html#hw---the-em-algorithm-and-density-estimation",
    "href": "C3-L07-Ex1.html#hw---the-em-algorithm-and-density-estimation",
    "title": "78  Old Faithful eruptions density estimation with the EM algorithm",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nThe R dataset faithful contains data on waiting time between eruptions (the column named waiting) and the duration of the eruption (the column named eruptions) for the famous Old Faithful geyser in Yellowstone National Park, Wyoming, USA.\nYou are asked to modify the EM algorithm provided in “Sample code for density estimation problems” to provide a density estimate the marginal distribution of the duration of the eruptions using a location-and-scale mixture of 2 univariate Gaussian distributions (as opposed to the location mixture of 6 univariate Gaussian distributions that we used for the galaxies dataset).\n\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nReviewers will check whether the code has been modified correctly, and whether the density estimate you generate appears correct. Please remember that you are being asked to use a location-and-scale mixture to generate the density estimate, so the “Sample code for density estimation problems” cannot be used directly and requires some modification. Before submitting your answer, it might be useful to compare the density estimate generated by your algorithm against a kernel density estimate generated by the R function density(). While they should not be identical, they should be similar.",
    "crumbs": [
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Old Faithful eruptions density estimation with the EM algorithm</span>"
    ]
  },
  {
    "objectID": "C3-L07-Ex2.html",
    "href": "C3-L07-Ex2.html",
    "title": "79  Old Faithful eruptions density estimation with the MCMC algorithms",
    "section": "",
    "text": "79.1 HW - Old Faithful eruptions density estimation with the MCMC algorithms\nIn this exercise, we implement the MCMC algorithm to fit a location-and-scale mixture of 2 univariate Gaussian distributions to the duration of eruptions of the Old Faithful geyser. We will then use the fitted model to generate a density estimate of the marginal distribution of the duration of the eruptions.\nthe full conditional for the c_i scale-location mixture of 2 Gaussians is given by:\nPr(c_i=1 \\mid x_i, \\theta) = \\frac{w_1 \\cdot \\phi(x_i \\mid \\mu_1, \\sigma^2_1)}{w_1 \\cdot \\phi(x_i \\mid \\mu_1, \\sigma^2_1) + w_2 \\cdot \\phi(x_i \\mid \\mu_2, \\sigma^2_2)}\n\\tag{79.1}\nwhere is the density of the normal distribution with mean \\mu_k and variance \\sigma^2_k, given by:\n\\phi(x_i \\mid \\mu_k, \\sigma^2_k) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_k}} \\cdot \\exp\\left(-\\frac{(x_i - \\mu_k)^2}{2\\sigma^2_k}\\right)\n\\tag{79.2}\nThe full conditional of \\omega is given by:\n\\omega \\mid c, x, = Beta(a_1 + \\sum_{i=1}^n \\mathbb{1}_{(c_i=1)},\\ a_2 + \\sum_{i=1}^n \\mathbb{1}_{(c_i=2)})\n\\tag{79.3}\nwhere a_1 and a_2 are the parameters of the Beta distribution, and \\mathbb{1}_{(c_i=k)} is an indicator function that is equal to 1 if c_i=k and 0 otherwise. The full conditional of \\mu_k is given by:\n\\mu_k \\mid c, x, \\sigma^2_k = \\mbox{Normal}\\left( \\left[ \\frac{n_k}{\\sigma_k^2} + \\frac{1}{\\tau^2} \\right]^{-1}\\left[ \\frac{\\sum_{i:c_i=k} x_i}{\\sigma_k^2} + \\frac{\\eta}{\\tau^2} \\right], \\left[ \\frac{n_k}{\\sigma_k^2} + \\frac{1}{\\tau^2} \\right]^{-1}\\right)\n\\tag{79.4}\nwhere n_k is the number of observations assigned to component k, \\eta is the mean of the data, and \\tau^2 is the variance of the data.\nThe full conditional of \\sigma^2_k is given by:\n1/\\sigma^2_k \\mid c, x, \\mu_k = \\mbox{Gamma}\\left( d + \\frac{n_k}{2} , q + \\frac{1}{2} \\sum_{i:c_k=k} (x_i - \\mu_k)^2 \\right)\n\\tag{79.5}\nwhere d is the degrees of freedom and q is the scale parameter.\nchanges:\nCode\n###### Setup data\nrm(list=ls())\nset.seed(81196)  # So that results are reproducible\nlibrary(MASS)\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\ndata(faithful)\n#KK = 6          # Based on the description of the dataset\nKK     = 2                          # Number of components\n#x  = galaxies\nx = faithful$eruptions\n#n  = length(x)\nn = length(x)\n\nset.seed(781209)\n\n\n## Empirical Bayes approach to select the hyperparameters\n\neta = mean(x)          # Mean of the data\ntau2 = var(x)          # Variance of the data\ndd = 2                 # Degrees of freedom for the Gamma distribution\nqq = var(x)/KK         # Scale parameter for the Gamma distribution\n\n# Priors\naa = rep(1,KK)          \n\n# Initial values\nw     = rep(1,KK)/KK                # Use equal weight for each component\nmu    = rnorm(KK, mean(x), sd(x))   # Random cluster centers\nsigma2 = rep(var(x),KK)             # Random cluster scales\nsigma = sqrt(sigma2)   \n\n#d     = 2                          # Degrees of freedom for the Gamma distribution\n#q     = 1                          # Scale parameter for the Gamma distribution\n\ncc = sample(1:KK, n, replace=TRUE,prob=w)  # Random initial cluster assignments\n\n\n# MCMC settings\niterations  = 12000\nburn = 2000\n\n# Storage\ncc.out    = array(0, dim=c(iterations, n))\nw.out     = array(0, dim=c(iterations, KK))\nmu.out    = array(0, dim=c(iterations, KK))\nsigma.out = array(0, dim=c(iterations, KK))\n\nfor(s in 1:iterations){\n  # Sample latent indicators\n  for(i in 1:n){\n    # This form is easier to extend to n components\n    v = sapply(1:KK, function(k) log(w[k]) + dnorm(x[i], mu[k], sqrt(sigma2[k]), log=TRUE))\n    # than\n    #    v    = rep(0,2)\n    #v[1] = log(w) + dnorm(x[i], mu[1], sigma[1], log=TRUE)  #Compute the log of the weights\n    #v[2] = log(1-w) + dnorm(x[i], mu[2], sigma[2], log=TRUE)  #Compute the log of the weights\n    v = exp(v - max(v))   # stabilize the computation\n    v = v / sum(v)        # Normalize\n    #cc[i] = sample(1:KK, size=1, prob=v)\n    cc[i] = sample(1:KK, size=1, replace = TRUE, prob=v)\n  }\n  \n  # Sample weights\n  #w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n  # this is equivalent to the more general\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  # and both give a uniform distribution for the weights\n\n  # Sample means and variances\n  for(k in 1:KK){\n    nk = sum(cc==k)\n    xk = x[cc==k]\n    # Mean\n    tau2_hat = 1/(nk/sigma2[k] + 1/tau2)\n    mu_hat = tau2_hat * (sum(xk)/sigma2[k] + eta/tau2)\n    mu[k] = rnorm(1, mu_hat, sqrt(tau2_hat))\n    # Variance\n    dd_star = dd + nk/2\n    qq_star = qq + sum((xk - mu[k])^2)/2\n    sigma2[k] = 1/rgamma(1, dd_star, qq_star)\n  }\n  sigma = sqrt(sigma2)\n  \n  # Store samples\n  cc.out[s,]    = cc\n  w.out[s,]     = w\n  mu.out[s,]    = mu\n  sigma.out[s,] = sigma\n  if(s %% 1000 == 0) cat(\"Iteration\", s, \"\\n\")\n}\n\n\nIteration 1000 \nIteration 2000 \nIteration 3000 \nIteration 4000 \nIteration 5000 \nIteration 6000 \nIteration 7000 \nIteration 8000 \nIteration 9000 \nIteration 10000 \nIteration 11000 \nIteration 12000\nProvide code to generate the density estimate on a grid consisting of 150 points in the interval\nCode\nxx  = seq(min(x), max(x), length=150)\nnxx = length(xx)\ndensity.mcmc = array(0, dim=c(iterations-burn, nxx))\n\nfor(s in 1:(iterations-burn)){\n  for(k in 1:KK){\n    density.mcmc[s,] = density.mcmc[s,] +\n      w.out[s+burn, k] * dnorm(xx, mu.out[s+burn, k], sigma.out[s+burn, k])\n  }\n}\ndensity.mcmc.m = colMeans(density.mcmc)\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\n\n# Kernel density estimate\nyy = density(x)\nProvide the a graph of the density estimate on the interval [0,7]\nCode\nplot(xx, density.mcmc.m, type=\"n\", ylim=c(0, max(density.mcmc.uq)), xlim=c(0, 7),\n     xlab=\"Eruption duration (min)\", ylab=\"Density\")\npolygon(c(xx, rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=NA)\nlines(xx, density.mcmc.m, col=\"black\", lwd=2)\nlines(yy, col=\"red\", lwd=2, lty=2)\npoints(x, rep(0, n), pch=16, cex=0.5)\nlegend(\"topright\", c(\"MCMC mean\", \"95% band\", \"KDE\"),\n       col=c(\"black\", \"grey\", \"red\"), lty=c(1, NA, 2), lwd=2, pch=c(NA, 15, NA), pt.cex=2, bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 79.1: Density estimate of the eruption duration using MCMC algorithm",
    "crumbs": [
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Old Faithful eruptions density estimation with the MCMC algorithms</span>"
    ]
  },
  {
    "objectID": "C3-L07-Ex2.html#hw---old-faithful-eruptions-density-estimation-with-the-mcmc-algorithms",
    "href": "C3-L07-Ex2.html#hw---old-faithful-eruptions-density-estimation-with-the-mcmc-algorithms",
    "title": "79  Old Faithful eruptions density estimation with the MCMC algorithms",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nThe R dataset faithful contains data on waiting time between eruptions (the column named waiting) and the duration of the eruption (the column named eruptions) for the famous Old Faithful geyser in Yellowstone National Park, Wyoming, USA.\nIn this case, we are asked to modify the MCMC algorithm provided in “Sample code for density estimation problems” (as opposed to the EM algorithm we used in the previous peer assignment) to provide a (Bayesian) density estimate the marginal distribution of the duration of the eruptions using a location-and-scale mixture of 2 univariate Gaussian distributions (as opposed to the location mixture of 6 univariate Gaussian distributions that we used for the galaxies dataset).\n\nAssume that the priors are w \\sim Beta(1,1), μ_k \\sim Normal(η,τ^2) and 1/σ^2_k \\sim Gamma(d,q), where η is the mean of the data, τ^2 is the variance of the data, d is the degrees of freedom and q is the scale parameter.\nThe hyperparameters η, τ^2, d and q are selected using an empirical Bayes approach similar to the one we used in “Sample code for density estimation problems”.\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nReviewers will check whether the code has been modified correctly, and whether the density estimate you generate appears correct. Please remember that you are being asked to use a location-and-scale mixture to generate the density estimate, so the “Sample code for density estimation problems” cannot be used directly and requires some modification. Before submitting your answer, it might be useful to compare the density estimate generated by your algorithm against a kernel density estimate generated by the R function density(). While they should not be identical, they should be similar.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthe number of components from 6 to 2\nthe data from galaxies to faithful$eruptions\nthe prior for the weights from w \\sim Beta(1,1) to w \\sim Beta(1,1)\nthe prior for the means from μ_k \\sim Normal(η,τ^2) to μ_k \\sim Normal(η,τ^2)\nthe prior for the variances from 1/σ^2_k \\sim Gamma(d,q) to 1/σ^2_k \\sim Gamma(d,q)\nthe full conditional for the c_i from c_i \\sim \\mathcal{N}(μ_k,σ^2_k) to c_i \\sim \\mathcal{N}(μ_k,σ^2_k) - only this one changes\nthe hyperparameters from η, τ^2, d and q to η, τ^2, d and q\nThe complete conditional as outlined above in Equation 79.1, Equation 79.2, Equation 79.3, Equation 79.4 and Equation 79.5.\nuse the empirical Bayes approach to select the hyperparameters η, τ^2, d and q - this is more or less what we have been doing all along, but now we are justifying it with the empirical Bayes approach.\n\n\n\n\n\n\n\n\n\n\n\n\nNotesolution code from the course\n\n\n\n\n\n\n\nCode\nx = faithful$eruptions\nn = length(x)\nplot(density(x))\npoints(x,rep(0,n))\n\n\n\n\n\n\n\n\n\nCode\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(1,2)  \neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/2\n\n## Initialize the parameters\nw     = 1/2\nmu    = rnorm(2, mean(x), sd(x))\nsigma = rep(sd(x)/2,2)\ncc    = sample(1:2, n, replace=T, prob=c(1/2,1/2))\n\n## Number of iterations of the sampler\niterations   = 12000\nburn  = 2000\n\n## Storing the samples\ncc.out    = array(0, dim=c(iterations, n))\nw.out     = rep(0, iterations)\nmu.out    = array(0, dim=c(iterations, 2))\nsigma.out = array(0, dim=c(iterations, 2))\nlogpost   = rep(0, iterations)\n\nfor(s in 1:iterations){\n  # Sample the indicators\n  for(i in 1:n){\n    v    = rep(0,2)\n    v[1] = log(w) + dnorm(x[i], mu[1], sigma[1], log=TRUE)  #Compute the log of the weights\n    v[2] = log(1-w) + dnorm(x[i], mu[2], sigma[2], log=TRUE)  #Compute the log of the weights\n    v    = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:2, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n  \n  # Sample the parameters of the components\n  for(k in 1:2){\n    \n    # Sample the means\n    nk    = sum(cc==k)    # how many points assigned to component k\n    xsumk = sum(x[cc==k]) # sum of the points assigned to component k\n    tau2.hat = 1/(nk/sigma[k]^2 + 1/tau^2) # tau star squared\n    mu.hat  = tau2.hat*(xsumk/sigma[k]^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n    \n    # Sample the variances\n    dd.star = dd + nk/2\n    qq.star = qq + sum((x[cc==k] - mu[k])^2)/2\n    sigma[k] = sqrt(1/rgamma(1, dd.star, qq.star))\n  }\n  \n  # Store samples\n  cc.out[s,]    = cc\n  w.out[s]     = w\n  mu.out[s,]    = mu\n  sigma.out[s,] = sigma\n  logpost[s] = 0\n\n  ## Compute the log-posterior\n  for(i in 1:n){\n    if(cc[i] == 1){\n      logpost[s] = logpost[s] + log(w) + dnorm(x[i], mu[1], sigma[1], log=TRUE)\n    }else{\n      logpost[s] = logpost[s] + log(1-w) + dnorm(x[i], mu[2], sigma[2], log=TRUE)\n    }\n  }\n  logpost[s] = logpost[s] + dbeta(w, aa[1], aa[2], log=TRUE)\n  for(k in 1:2){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log = T) + dgamma(1/sigma[k]^2, dd, qq)/sigma[k]^4\n  }\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n\n\nCode\n## Compute the samples of the density over a dense grid\nxx  = seq(0,7,length=150)\ndensity.mcmc = array(0, dim=c(iterations-burn,length(xx)))\nfor(s in 1:(iterations-burn)){\n  density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn]*dnorm(xx,mu.out[s+burn,1],sigma.out[s+burn,1]) + \n                               (1-w.out[s+burn])*dnorm(xx,mu.out[s+burn,2],sigma.out[s+burn,2])\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\n## Plot Bayesian estimate with pointwise credible bands\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Eruptions\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=\"black\", lwd=2)\npoints(x, rep(0,n))",
    "crumbs": [
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Old Faithful eruptions density estimation with the MCMC algorithms</span>"
    ]
  },
  {
    "objectID": "C3-L07-Ex3.html",
    "href": "C3-L07-Ex3.html",
    "title": "80  Bayesian Mixture Models for Classification of Banknotes",
    "section": "",
    "text": "80.1 HHW - banknote classification the MCMC algorithms\nThe data set banknote contains six measurements (length of bill, width of left edge, width of right edge, bottom margin width, top margin width, and length of diagonal, all in mm) made on 100 genuine and 100 counterfeit old-Swiss 1000-franc bank notes",
    "crumbs": [
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Bayesian Mixture Models for Classification of Banknotes</span>"
    ]
  },
  {
    "objectID": "C3-L07-Ex3.html#hhw---banknote-classification-the-mcmc-algorithms",
    "href": "C3-L07-Ex3.html#hhw---banknote-classification-the-mcmc-algorithms",
    "title": "80  Bayesian Mixture Models for Classification of Banknotes",
    "section": "",
    "text": "NoteInstructions\n\n\n\nTo load the dataset in R, use the command load(“banknoteclassification.Rdata”), but first make sure that your working directory is set to the directory containing the file. You should see four objects:\n\nbanknote.training contains the characteristics for 30 notes (15 genuine and 15 counterfeit) in the training set.\nbanknote.training.labels contains the labels (“genuine” or “counterfeit”) for the 30 notes in the training set\nbanknote.test contains the characteristics for 170 notes (85 genuine and 85 counterfeit) in the test set.\nbanknote.test.labels contains the labels (“genuine” or “counterfeit”) for the 170 notes in the test set. These are provided only for validation purposes.\n\nYou are asked to modify the MCMC algorithm in “Sample code for MCMC example 2” to create an algorithm for semi-supervised classification that is the Bayesian equivalent of that provided under “Sample EM algorithm for classification problems” and apply it to classify the observations contained in the test set. You are then asked to compare your results against those generated by the qda function in R.\nAs your priors, use distributions in the same families as in “Sample code for MCMC example 2”. In particular, use a uniform distribution for the weights, multivariate normal distributions for the means of the components, and inverse Wishart priors for the variance-covariance matrices of the components. The parameters of the priors should be set using the same empirical Bayes approach used in that example.\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nReviewers will check that the code has been properly adapted, and whether the classification results you provide are correct.\n\n\n\n\n\n\n\n\nNoteSample code for MCMC example 2\n\n\n\n\n\n\n\nCode\n#### Example of an MCMC algorithm for fitting a mixtures of K p-variate Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)\nlibrary(ellipse)\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nset.seed(63252)    #Keep seed the same so that we can reproduce results\nn  = 120\ncc.true = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc.true[i],], Sigma.true[cc.true[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]), type=\"n\")\ntext(x[,1], x[,2], seq(1,n), col=cc.true, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2)\n}\ntitle(main=\"Data + True Components\")\n\n\n\n\n\n\n\n\n\nCode\n## Initialize the parameters\nw          = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu         = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\ncc         = sample(1:KK, n, replace=TRUE, prob=w)\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\n# Priors\naa = rep(1, KK)\ndd = apply(x,2,mean)\nDD = 10*var(x)\nnu = p\nSS = var(x)/3\n\n# Number of iteration of the sampler\nrrr = 1000\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK, p))\nSigma.out = array(0, dim=c(rrr, KK, p, p))\nlogpost   = rep(0, rrr)\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + mvtnorm::dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc)))\n  \n  # Sample the means\n  DD.st = matrix(0, nrow=p, ncol=p)\n  for(k in 1:KK){\n    mk    = sum(cc==k)\n    xsumk = apply(x[cc==k,], 2, sum)\n    DD.st = solve(mk*solve(Sigma[k,,]) + solve(DD))\n    dd.st = DD.st%*%(solve(Sigma[k,,])%*%xsumk + solve(DD)%*%dd)\n    mu[k,] = as.vector(rmvnorm(1,dd.st,DD.st))\n  }\n  \n  # Sample the variances\n  xcensumk = array(0, dim=c(KK,p,p))\n  for(i in 1:n){\n    xcensumk[cc[i],,] = xcensumk[cc[i],,] + (x[i,] - mu[cc[i],])%*%t(x[i,] - mu[cc[i],])\n  }\n  for(k in 1:KK){\n    Sigma[k,,] = riwish(nu + sum(cc==k), SS + xcensumk[k,,])\n  }\n  \n  # Store samples\n  cc.out[s,]      = cc\n  w.out[s,]       = w\n  mu.out[s,,]     = mu\n  Sigma.out[s,,,] = Sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + mvtnorm::dmvnorm(x[i,], mu[cc[i],], Sigma[cc[i],,], log=TRUE)\n  }\n  logpost[s] = logpost[s] + ddirichlet(w, aa)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + mvtnorm::dmvnorm(mu[k,], dd, DD, log=TRUE)\n    logpost[s] = logpost[s] + log(diwish(Sigma[k,,], nu, SS))\n  }\n  \n  if(s/250==floor(s/250)){\n    print(paste(\"s = \", s))\n  }\n  \n}\n\n\n[1] \"s =  250\"\n[1] \"s =  500\"\n[1] \"s =  750\"\n[1] \"s =  1000\"\n\n\nCode\n## Plot the logposterior distribution for various samples\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\n\n\n\n\n\n\n\n\nCode\n## Plot the density estimate for the last iteration of the MCMC\npar(mfrow=c(1,1))\npar(mar=c(4,4,2,1)+0.1)\nplot(x[,1], x[,2], col=cc.true, main=paste(\"s =\",s,\"   logpost =\", round(logpost[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\n\n\n\n\n\n\n\n\n\nsample code for classification of the wine dataset using a mixture model with EM algorithm\n\n\nCode\n## Using mixture models for classification in the wine dataset\n## Compare linear and quadratic discriminant analysis and a \n##   (semi-supervised) location and scale mixture model with K normals\n## Comparing only against the EM algorithm\n\n# Semi-supervised, quadratic discriminant analysis\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(mvtnorm)\nwine.training = read.table(\"data/wine_training.txt\", sep=\",\", header=TRUE)\nwine.test = read.table(\"data/wine_test.txt\", sep=\",\", header=TRUE)\nn = dim(wine.training)[1]  # Size of the training set\nm = dim(wine.test)[1]      # Size of the test set\nx = rbind(as.matrix(wine.training[,-1]), as.matrix(wine.test[,-1]))   # Create dataset of observations, first n belong to the training set, and the rest belong to the test set\np       = dim(x)[2]              # Number of features\nKK      = 3\nepsilon = 0.00001\n\npar(mfrow=c(1,1))\npar(mar=c(2,2,2,2)+0.1)\ncolscale = c(\"black\",\"red\",\"blue\")\npairs(wine.training[,-1], col=colscale[wine.training[,1]], pch=wine.training[,1])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #Cluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\nsw     = FALSE\nKL     = -Inf\nKL.out = NULL\ns      = 0\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n+m,KK))\n  for(k in 1:KK){  #Compute the log of the weights\n    v[1:n,k] = ifelse(wine.training[,1]==k,0,-Inf)  # Training set\n    v[(n+1):(n+m),k] = log(w[k]) + mvtnorm::dmvnorm(x[(n+1):(n+m),], mu[k,], Sigma[k,,],log=TRUE)  # Test set\n  }\n  for(i in 1:(n+m)){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w = apply(v,2,mean)\n  mu = matrix(0, nrow=KK, ncol=p)\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0,dim=c(KK,p,p))\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:(n+m)){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -3146.58419305226\"\n[1] \"2 -2942.48222029706\"\n[1] \"3 -2873.76499310479\"\n[1] \"4 -2852.76768638231\"\n[1] \"5 -2796.247735428\"\n[1] \"6 -2791.29098585679\"\n[1] \"7 -2791.23059641487\"\n[1] \"8 -2791.14094416728\"\n[1] \"9 -2791.05612416221\"\n[1] \"10 -2790.99254414223\"\n[1] \"11 -2790.95228067601\"\n[1] \"12 -2790.92945838389\"\n\n\nCode\n## Predicted labels\napply(v, 1, which.max)[(n+1):(n+m)]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## True labels\nwine.test[,1]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## Comparison\napply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1]\n\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nCode\nsum(!(apply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# Using the qda and lda functions in R\n# qda\nmodqda = qda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredqda = predict(modqda,newdata=wine.test[,-1])\nsum(!(ccpredqda$class == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# lda\nmodlda = lda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredlda = predict(modlda,newdata=wine.test[,-1])\nsum(!(ccpredlda$class == wine.test[,1])) # No errors!!!\n\n\n[1] 0",
    "crumbs": [
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Bayesian Mixture Models for Classification of Banknotes</span>"
    ]
  },
  {
    "objectID": "C3-L07-Ex3.html#solution",
    "href": "C3-L07-Ex3.html#solution",
    "title": "80  Bayesian Mixture Models for Classification of Banknotes",
    "section": "80.2 Solution",
    "text": "80.2 Solution\n\n\nCode\nlibrary(MASS)\nlibrary(mvtnorm)\nlibrary(MCMCpack)\n\nload(\"data/banknoteclassification.Rdata\")\n\n\nProvide an MCMC algorithm to fit a semisupervised Bayesian quadratic discriminant model to the banknote data.\n\n\nCode\n# Combine data for semi-supervised setup\nn = nrow(banknote.training)\nm = nrow(banknote.test)\nx = rbind(banknote.training, banknote.test)\np = ncol(banknote.training)\nK = 2  # Two classes: genuine/counterfeit\n\n# Convert labels to numeric (1/2)\nlabel_map = setNames(1:2, c(\"genuine\", \"counterfeit\"))\ntrain_labels = label_map[banknote.training.labels]\ntest_labels  = label_map[banknote.test.labels]\n\n# Priors from empirical Bayes\naa = rep(1, K)\ndd = colMeans(x)\nDD = 10 * var(x)\nnu = p\nSS = var(x) / 3\n\n# Initial values\nw    = rep(1, K) / K\nmu   = rmvnorm(K, dd, var(x))\nSigma = array(0, dim=c(K, p, p))\nfor (k in 1:K) Sigma[k,,] = var(x) / K\ncc = c(train_labels, sample(1:K, m, replace=TRUE))\n\n# MCMC settings\niters = 1000\nburn  = 500\n\ncc.out = array(0, dim=c(iters, n+m))\nfor (s in 1:iters) {\n  # 1. Sample class indicators (cc)\n  # - Fixed for training set, update for test set\n  for (i in (n+1):(n+m)) {\n    logp = sapply(1:K, function(k)\n      log(w[k]) + dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE))\n    p_i = exp(logp - max(logp)); p_i = p_i / sum(p_i)\n    cc[i] = sample(1:K, 1, prob=p_i)\n  }\n  # 2. Update weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=K)))\n  # 3. Update means\n  for (k in 1:K) {\n    idx = which(cc == k)\n    mk = length(idx)\n    DD_st = solve(mk * solve(Sigma[k,,]) + solve(DD))\n    dd_st = DD_st %*% (solve(Sigma[k,,]) %*% colSums(x[idx,,drop=FALSE]) + solve(DD) %*% dd)\n    mu[k,] = as.vector(rmvnorm(1, dd_st, DD_st))\n  }\n  # 4. Update covariances\n  for (k in 1:K) {\n    idx = which(cc == k)\n    mk = length(idx)\n    xcensumk = matrix(0, p, p)\n    for (i in idx) {\n      d = x[i,] - mu[k,]\n      xcensumk = xcensumk + d %*% t(d)\n    }\n    Sigma[k,,] = riwish(nu + mk, SS + xcensumk)\n  }\n  cc.out[s,] = cc\n}\n\n\nWhat is the classification error for the test set?\n\n[] Is the classification error for the “genuine” class generated by the algorithm correct? should be 0\n[] Is the classification error for the “counterfeit” class generated by the algorithm correct? should be 0\n\n\n\nCode\n# Posterior prediction: for each test sample, majority vote of assignments\ncc.test.posterior = cc.out[burn:iters, (n+1):(n+m), drop=FALSE]\ncc.test.pred = apply(cc.test.posterior, 2, function(z) as.integer(names(which.max(table(z)))))\n\nclassification_error = mean(cc.test.pred != test_labels)\ncat(\"MCMC Test Classification Error:\", classification_error, \"\\n\")\n\n\nMCMC Test Classification Error: 0 \n\n\n\n[] Is the R function qda (which implements classical quadratic discriminant analysis) is used to classify the observations in the test set, what is the classification error?\n[] Is the classification error for the “genuine” class generated by the algorithm correct? should be 0 out of 85\n[] Is the classification error for the “counterfeit” class generated by the algorithm correct? should be 3 out of 85 i.e. 3.52%\n\n\n\nCode\nmod_qda = qda(x=banknote.training, grouping=banknote.training.labels, method=\"mle\")\nqda_pred = predict(mod_qda, banknote.test)$class\n\nqda_error = mean(qda_pred != banknote.test.labels)\ncat(\"QDA Test Classification Error:\", qda_error, \"\\n\")\n\n\nQDA Test Classification Error: 0.01764706 \n\n\n\n\n\n\n\n\nNoteSolution code\n\n\n\n\n\n\n\nCode\n#### Semisupervised classification for the banknote dataset\nrm(list=ls())\nlibrary(mvtnorm)\nlibrary(MCMCpack)\n\n## Load data\nload(\"data/banknoteclassification.Rdata\")\n#load(\"banknoteclassification.Rdata\")\nx = rbind(banknote.training,banknote.test)\n\n## Generate data from a mixture with 3 components\nKK      = length(unique(banknote.training.labels))\np       = dim(banknote.training)[2]\nn       = dim(banknote.training)[1]\nm       = dim(unique(banknote.test))[1]\n\n## Initialize the parameters\nw          = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu         = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\ncc         = c(as.numeric(banknote.training.labels), sample(1:KK, m, replace=TRUE, prob=w))\n\n# Priors\naa = rep(1, KK)\ndd = apply(x,2,mean)\nDD = 10*var(x)\nnu = p+1\nSS = var(x)/3\n\n# Number of iteration of the sampler\nrrr  = 11000\nburn = 1000\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n+m))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK, p))\nSigma.out = array(0, dim=c(rrr, KK, p, p))\nlogpost   = rep(0, rrr)\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in (n+1):(n+m)){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc)))\n  \n  # Sample the means\n  DD.st = matrix(0, nrow=p, ncol=p)\n  for(k in 1:KK){\n    mk    = sum(cc==k)\n    xsumk = apply(x[cc==k,], 2, sum)\n    DD.st = solve(mk*solve(Sigma[k,,]) + solve(DD))\n    dd.st = DD.st%*%(solve(Sigma[k,,])%*%xsumk + solve(DD)%*%dd)\n    mu[k,] = as.vector(rmvnorm(1,dd.st,DD.st))\n  }\n  \n  # Sample the variances\n  xcensumk = array(0, dim=c(KK,p,p))\n  for(i in 1:(n+m)){\n    xcensumk[cc[i],,] = xcensumk[cc[i],,] + (x[i,] - mu[cc[i],])%*%t(x[i,] - mu[cc[i],])\n  }\n  for(k in 1:KK){\n    Sigma[k,,] = riwish(nu + sum(cc==k), SS + xcensumk[k,,])\n  }\n  \n  # Store samples\n  cc.out[s,]      = cc\n  w.out[s,]       = w\n  mu.out[s,,]     = mu\n  Sigma.out[s,,,] = Sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dmvnorm(x[i,], mu[cc[i],], Sigma[cc[i],,], log=TRUE)\n  }\n  logpost[s] = logpost[s] + ddirichlet(w, aa)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dmvnorm(mu[k,], dd, DD)\n    logpost[s] = logpost[s] + diwish(Sigma[k,,], nu, SS)\n  }\n  \n  if(s/250==floor(s/250)){\n    print(paste(\"s = \", s))\n  }\n}\n\n\n[1] \"s =  250\"\n[1] \"s =  500\"\n[1] \"s =  750\"\n[1] \"s =  1000\"\n[1] \"s =  1250\"\n[1] \"s =  1500\"\n[1] \"s =  1750\"\n[1] \"s =  2000\"\n[1] \"s =  2250\"\n[1] \"s =  2500\"\n[1] \"s =  2750\"\n[1] \"s =  3000\"\n[1] \"s =  3250\"\n[1] \"s =  3500\"\n[1] \"s =  3750\"\n[1] \"s =  4000\"\n[1] \"s =  4250\"\n[1] \"s =  4500\"\n[1] \"s =  4750\"\n[1] \"s =  5000\"\n[1] \"s =  5250\"\n[1] \"s =  5500\"\n[1] \"s =  5750\"\n[1] \"s =  6000\"\n[1] \"s =  6250\"\n[1] \"s =  6500\"\n[1] \"s =  6750\"\n[1] \"s =  7000\"\n[1] \"s =  7250\"\n[1] \"s =  7500\"\n[1] \"s =  7750\"\n[1] \"s =  8000\"\n[1] \"s =  8250\"\n[1] \"s =  8500\"\n[1] \"s =  8750\"\n[1] \"s =  9000\"\n[1] \"s =  9250\"\n[1] \"s =  9500\"\n[1] \"s =  9750\"\n[1] \"s =  10000\"\n[1] \"s =  10250\"\n[1] \"s =  10500\"\n[1] \"s =  10750\"\n[1] \"s =  11000\"\n\n\n\n\nCode\nprobgenuine = rep(NA, m)\nfor(i in 1:m){\n  probgenuine[i] = sum(cc.out[-seq(1,burn),n+i]==2)/(rrr-burn)\n}\n\n\n\nprobcounterfeit = rep(NA, m)\nfor(i in 1:m){\n   probcounterfeit[i] = sum(cc.out[-seq(1,burn),n+i]==1)/(rrr-burn)\n} \n\n# Confusion matrix using threshold 0.5\npredicted_class &lt;- ifelse(probcounterfeit &gt; 0.5, 1, 2)  # 1 = counterfeit, 2 = genuine\n\n# Compare with true labels (already converted to numeric in your setup)\ntable(True = banknote.test.labels, Pred = predicted_class)\n\n\n             Pred\nTrue           1  2\n  counterfeit 85  0\n  genuine      0 85\n\n\nclassification_error_genuine = 0 classification_error_counterfit = 0\nfor (i in 1:m){ if (banknote.test.labels[i] == “genuine” && probgenuine[i] &lt; 0.5) { classification_error_genuine = classification_error_genuine + 1 } if (banknote.test.labels[i] == “counterfeit” && probcounterfeit[i] &lt; 0.5) { classification_error_counterfit = classification_error_counterfit + 1 } }\nclassification_error = (classification_error_genuine + classification_error_counterfit) / m\nprint(paste(“Genuine error count:”, classification_error_genuine)) print(paste(“Genuine error rate:”, classification_error_genuine/m)) print(c(“Counterfeit error count:”, classification_error_counterfit)) print(paste(“Counterfeit error rate:”, classification_error_counterfit/n)) print(paste(“Overall classification error”,classification_error))\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbanknote.qda = qda(x=banknote.training, grouping=banknote.training.labels, method=\"mle\")\nqda_preds = predict(banknote.qda, banknote.test)$class\n\ntable(True = banknote.test.labels, Pred = qda_preds)\n\n             Pred\nTrue          counterfeit genuine\n  counterfeit          82       3\n  genuine               0      85\n\n\n\n\nqda_classification_error_genuine = 0 qda_classification_error_counterfit = 0\nfor (i in 1:m){ if (banknote.test.labels[i] == “genuine” && qda_preds[i] == “counterfeit”) { qda_classification_error_genuine = qda_classification_error_genuine + 1 } if (banknote.test.labels[i] == “counterfeit” && qda_preds[i] == “genuine”) { qda_classification_error_counterfit = qda_classification_error_counterfit + 1 } }\nprint(paste(“QDA genuine error count:”, qda_classification_error_genuine)) print(paste(“QDA genuine error rate:”,qda_classification_error_genuine/m)) print(paste(“QDA counterfeit error count:”, qda_classification_error_counterfit)) print(paste(“QDA counterfeit error rate:”, qda_classification_error_counterfit/m))\n\n\nCode\nprobgenuine = rep(NA, m)\n\nfor(i in 1:m){\n  probgenuine[i] = sum(cc.out[-seq(1,burn),n+i]==2)/(rrr-burn)\n}\n\npredicted_class &lt;- ifelse(probgenuine &gt; 0.5, 2, 1)  # 1 = counterfeit, 2 = genuine\nlabmap &lt;- c(\"counterfeit\", \"genuine\")\npredicted_labels &lt;- labmap[predicted_class]\n\ntab_mcmc &lt;- table(True = banknote.test.labels, Pred = predicted_labels)\n\n# Per-class error rates\ngenuine_error     &lt;- 1 - tab_mcmc[\"genuine\", \"genuine\"] / sum(tab_mcmc[\"genuine\", ])\ncounterfeit_error &lt;- 1 - tab_mcmc[\"counterfeit\", \"counterfeit\"] / sum(tab_mcmc[\"counterfeit\", ])\n\nprint(paste(\"genuine: \", round(100 * genuine_error,2)))\n\n\n[1] \"genuine:  0\"\n\n\nCode\nprint(paste(\"counterfeit: \", round(100 * counterfeit_error, 2)))\n\n\n[1] \"counterfeit:  0\"\n\n\nbanknote.qda = qda(x=banknote.training, grouping=banknote.training.labels, method=“mle”) qda_preds = predict(banknote.qda, banknote.test)$class tab_qda &lt;- table(True = banknote.test.labels, Pred = qda_preds) # Per-class error rates genuine_error &lt;- 1 - tab_qda[“genuine”, “genuine”] / sum(tab_qda[“genuine”, ]) counterfeit_error &lt;- 1 - tab_qda[“counterfeit”, “counterfeit”] / sum(tab_qda[“counterfeit”, ]) print(paste(“genuine:”, round(100 * genuine_error,2))) print(paste(“counterfeit:”, round(100 * counterfeit_error, 2)))",
    "crumbs": [
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Bayesian Mixture Models for Classification of Banknotes</span>"
    ]
  },
  {
    "objectID": "C3-L08.html",
    "href": "C3-L08.html",
    "title": "81  M5L8 - Computational Considerations",
    "section": "",
    "text": "81.1 Computational Considerations (Video)",
    "crumbs": [
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>M5L8 - Computational Considerations</span>"
    ]
  },
  {
    "objectID": "C3-L08.html#computational-considerations-video",
    "href": "C3-L08.html#computational-considerations-video",
    "title": "81  M5L8 - Computational Considerations",
    "section": "",
    "text": "Computational Considerations\n\n\n81.1.1 Numerical stability\nThe issue is in how the computer represents numbers. The computer uses a finite number of bits to represent numbers, which can lead to numerical instability when performing calculations that involve very large or very small numbers. This can result in loss of precision and incorrect results.\nThe solution is to use logarithmic transformations to avoid numerical instability. By taking the logarithm of the numbers, we can work with smaller and more manageable values, which reduces the risk of numerical instability.\n\n\n81.1.2 Sample code to illustrate numerical stability issues (Reading)\n\n\nCode\n## Consider a mixture of two normal distributions with equal weights (w1 = w2 = 1/2)\n## Component 1 has mean 0 and standard deviation 1\n## Component 2 has mean 1 and standard deviation 1\n## The observation is x = 50\n## What is Pr(c = 1 | x)?\ndnorm(50, 0, 1)\n\n\n[1] 0\n\n\nCode\ndnorm(50, 1, 1)\n\n\n[1] 0\n\n\nCode\ndnorm(50, 0, 1)/(dnorm(50, 0, 1) + dnorm(50, 1, 1))\n\n\n[1] NaN\n\n\nCode\n## What if x=3?  Two ways to do the calculation\n## One way:  Direct calculation\nz1 = dnorm(3, 0, 1)\nz2 = dnorm(3, 1, 1)\nz1/(z1+z2)\n\n\n[1] 0.07585818\n\n\nCode\n## A second way:  Compute in the logarithm scale, add b \n## to all values, and then exponentiate before standardizing\nlz1 = dnorm(3, 0, 1, log=T)\nlz2 = dnorm(3, 1, 1, log=T)\nb = 3\nexp(lz1+b)/(exp(lz1+b) + exp(lz2+b))\n\n\n[1] 0.07585818\n\n\nCode\n## Going back to the case x - 50:\n## Wrong\nlz1 = log(dnorm(50, 0, 1))\nlz2 = log(dnorm(50, 1, 1))\nb = max(lz1, lz2)\nexp(lz1-b)/(exp(lz1-b) + exp(lz2-b))\n\n\n[1] NaN\n\n\nCode\n## Wrong\nlz1 = log(exp(-0.5*50^2)/sqrt(2*pi))\nlz2 = log(exp(-0.5*49^2)/sqrt(2*pi))\nb = max(lz1, lz2)\nexp(lz1-b)/(exp(lz1-b) + exp(lz2-b))\n\n\n[1] NaN\n\n\nCode\n## Right\nlz1 = dnorm(50, 0, 1, log=TRUE)\nlz2 = dnorm(50, 1, 1, log=TRUE)\nb = max(lz1, lz2)\nexp(lz1-b)/(exp(lz1-b) + exp(lz2-b))\n\n\n[1] 3.179971e-22\n\n\nCode\n## Also right (just more cumbersome)\nlz1 = -0.5*log(2*pi) - 0.5*50^2\nlz2 = -0.5*log(2*pi) - 0.5*49^2\nb = max(lz1, lz2)\nexp(lz1-b)/(exp(lz1-b) + exp(lz2-b))\n\n\n[1] 3.179971e-22\n\n\n\n\n81.1.3 Computational issues associated with multimodality (Video)\n\n\n\n\nmultimodality issues\n\n\n\n81.1.4 Sample code to illustrate multimodality issues 1 (Reading)\n\n\nCode\n## Illustrating the fact that the likelihood for a mixture model is multimodal\n\n### Loading data and setting up global variables\nrm(list=ls())\nlibrary(mclust)\n\n\nPackage 'mclust' version 6.1.1\nType 'citation(\"mclust\")' for citing this R package in publications.\n\n\nCode\nlibrary(mvtnorm)\n\n\n\nAttaching package: 'mvtnorm'\n\n\nThe following object is masked from 'package:mclust':\n\n    dmvnorm\n\n\nCode\n### Defining a custom function to create pair plots\n### This is an alternative to the R function pairs() that allows for \n### more flexibility. In particular, it allows us to use text to label \n### the points\npairs2 = function(x, col=\"black\", pch=16, labels=NULL, names = colnames(x)){\n  n = dim(x)[1]\n  p = dim(x)[2]\n  par(mfrow=c(p,p))\n  for(k in 1:p){\n    for(l in 1:p){\n      if(k!=l){\n        par(mar=c(3,3,1,1)+0.1)\n        plot(x[,k], x[,l], type=\"n\", xlab=\"\", ylab=\"\")\n        if(is.null(labels)){\n          points(x[,k], x[,l], pch=pch, col=col)\n        }else{\n          text(x[,k], x[,l], labels=labels, col=col)\n        }\n      }else{\n        plot(seq(0,5), seq(0,5), type=\"n\", xlab=\"\", ylab=\"\", axes=FALSE)\n        text(2.5,2.5,names[k], cex=1.2)\n      }\n    }\n  }\n}\n\n\n## Setup data\ndata(iris)\nx       = as.matrix(iris[,-5])\nn       = dim(x)[1]\np       = dim(x)[2]       # Number of features\nKK      = 3\nepsilon = 0.0000001\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1))\ncolscale = c(\"black\",\"blue\",\"red\")\nshortnam  = c(\"s\",\"c\",\"g\")\n\n# Initialize the parameters of the algorithm\nset.seed(63252)\n\nnumruns = 15\nv.sum   = array(0, dim=c(numruns, n, KK))\nQQ.sum  = rep(0, numruns)\n\nfor(ss in 1:numruns){\n  w   = rep(1,KK)/KK  #Assign equal weight to each component to start with\n  #mu  = as.matrix(aggregate(x, list(iris[,5]), mean)[,2:5])  # Initialize in the true values\n  #Sigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\n  #Sigma[1,,] = var(x[iris[,5]==\"setosa\",])\n  #Sigma[2,,] = var(x[iris[,5]==\"versicolor\",])\n  #Sigma[3,,] = var(x[iris[,5]==\"virginica\",])\n  mu  = rmvnorm(KK, apply(x,2,mean), 3*var(x))   #Cluster centers randomly spread over the support of the data\n  Sigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\n  Sigma[1,,] = var(x)\n  Sigma[2,,] = var(x)\n  Sigma[3,,] = var(x)\n  \n  sw     = FALSE\n  QQ     = -Inf\n  QQ.out = NULL\n  s      = 0\n  \n  while(!sw){\n    ## E step\n    v = array(0, dim=c(n,KK))\n    for(k in 1:KK){  #Compute the log of the weights\n      v[,k] = log(w[k]) + dmvnorm(x, mu[k,], Sigma[k,,], log=TRUE) \n    }\n    for(i in 1:n){\n      v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n    }\n    \n    ## M step\n    w = apply(v,2,mean)\n    mu = matrix(0, nrow=KK, ncol=p)\n    for(k in 1:KK){\n      for(i in 1:n){\n        mu[k,]    = mu[k,] + v[i,k]*x[i,]\n      }\n      mu[k,] = mu[k,]/sum(v[,k])\n    }\n    Sigma = array(0,dim=c(KK, p, p))\n    for(k in 1:KK){\n      for(i in 1:n){\n        Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n      }\n      Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n    }\n    \n    ##Check convergence\n    QQn = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        QQn = QQn + v[i,k]*(log(w[k]) + dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n      }\n    }\n    if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n      sw=TRUE\n    }\n    QQ = QQn\n    QQ.out = c(QQ.out, QQ)\n    s = s + 1\n  }\n  \n  v.sum[ss,,] = v\n  QQ.sum[ss]  = QQ.out[s]\n  print(paste(\"ss =\", ss))\n}\n\n\n[1] \"ss = 1\"\n[1] \"ss = 2\"\n[1] \"ss = 3\"\n[1] \"ss = 4\"\n[1] \"ss = 5\"\n[1] \"ss = 6\"\n[1] \"ss = 7\"\n[1] \"ss = 8\"\n[1] \"ss = 9\"\n[1] \"ss = 10\"\n[1] \"ss = 11\"\n[1] \"ss = 12\"\n[1] \"ss = 13\"\n[1] \"ss = 14\"\n[1] \"ss = 15\"\n\n\nCode\n## Boxplot of final values of the Q function for all runs of the algorithm\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1))\nboxplot(QQ.out, ylab=\"Q\", xlab=\"Iterations\",las=2)\n\n\n\n\n\n\n\n\n\nCode\n## Graphical representation of the best solution \ncc = apply(v.sum[which.max(QQ.sum),,], 1 ,which.max)\ncolscale = c(\"black\",\"blue\",\"red\")\n#pairs(x, col=colscale[cc], pch=cc)\npairs2(x, col=colscale[cc], labels=cc)\n\n\n\n\n\n\n\n\n\nCode\n## Graphical representation of the worst solution\ncc = apply(v.sum[which.min(QQ.sum),,], 1 ,which.max)\ncolscale = c(\"black\",\"blue\",\"red\")\n#pairs(x, col=colscale[cc], pch=cc)\npairs2(x, col=colscale[cc], labels=cc)\n\n\n\n\n\n\n\n\n\n\n\n81.1.5 Sample code to illustrate multimodality issues 2 (Reading)\nThis code fails to converge because the algorithm is stuck in a local maximum of the likelihood function. The problem is that one of the components is “numerically empty” (i.e., it has no data points assigned to it). This can happen when the initial values for the means are too far apart or when the data is not well-separated.\n\n\nCode\n## Illustrating that the EM might fail for numerical reasons if a component is “numerically empty”\n\n### Loading data and setting up global variables\nrm(list=ls())\nlibrary(mclust)\nlibrary(mvtnorm)\nlibrary(ellipse)\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\n## Setup data\ndata(iris)\nx       = as.matrix(iris[,-5])\nn       = dim(x)[1]\np       = dim(x)[2]       # Number of features\nKK      = 3\nepsilon = 0.00000001\n\n# Initialize the parameters of the algorithm\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = matrix(0, KK, p)  # Initialize in the true values\nmu[1,] = apply(x, 2, mean)\nmu[2,] = apply(x, 2, mean) + c(2.2, 2.2, 2.2, 2.2)\nmu[3,] = apply(x, 2, mean) + c(-2.2, -2.2, -2.2, -2.2)\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/3\nSigma[2,,] = var(x)/3\nSigma[3,,] = var(x)/3\n\n# Plot the data along with the estimates of the components\ncolscale = c(\"black\",\"blue\",\"red\")\npar(mfrow=c(p,p))\nfor(k in 1:p){\n  for(l in 1:p){\n    if(k!=l){\n      par(mar=c(3,3,1,1)+0.1)\n      plot(x[,k], x[,l], type=\"n\", xlab=\"\", ylab=\"\", xlim=c(min(c(x[,k], mu[,k])),max(c(x[,k], mu[,k]))), ylim=c(min(c(x[,l], mu[,l])),max(c(x[,l], mu[,l]))))\n      for(r in 1:KK){\n        lines(ellipse(x=Sigma[r,c(k,l),c(k,l)], centre=mu[r,c(k,l)], level=0.50), col=\"gold1\", lty=1, lwd=1)\n        lines(ellipse(x=Sigma[r,c(k,l),c(k,l)], centre=mu[r,c(k,l)], level=0.82), col=\"gold1\", lty=1, lwd=1)\n        lines(ellipse(x=Sigma[r,c(k,l),c(k,l)], centre=mu[r,c(k,l)], level=0.95), col=\"gold1\", lty=1, lwd=1)\n      }\n      text(x[,k], x[,l], labels=as.numeric(iris[,5]), col=colscale[iris[,5]])\n      points(mu[,k], mu[,l], pch=19, col=\"gold1\", cex=2)\n    }else{\n      plot(seq(0,5), seq(0,5), type=\"n\", xlab=\"\", ylab=\"\", axes=FALSE)\n      text(2.5,2.5,colnames(x)[k], cex=1.5)\n    }\n  }\n}\n\n\n\n\n\n\n\n\n\nCode\n## Run the EM algorithm.  It will fail in the first iteration\nsw     = FALSE\nQQ     = -Inf\nQQ.out = NULL\ns      = 0\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(k in 1:KK){  #Compute the log of the weights\n    v[,k] = log(w[k]) + dmvnorm(x, mu[k,], Sigma[k,,], log=TRUE) \n  }\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w = apply(v,2,mean)\n  mu = matrix(0, nrow=KK, ncol=p)\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0,dim=c(KK, p, p))\n  for(k in 1:KK){\n    for(i in 1:n){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      QQn = QQn + v[i,k]*(log(w[k]) + dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n}\n\n\nError in if (abs(QQn - QQ)/abs(QQn) &lt; epsilon) {: missing value where TRUE/FALSE needed\n\n\nCode\nQQn\n\n\n[1] NaN",
    "crumbs": [
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>M5L8 - Computational Considerations</span>"
    ]
  },
  {
    "objectID": "C3-L08-Ex1.html",
    "href": "C3-L08-Ex1.html",
    "title": "82  Computational considerations for Mixture Models",
    "section": "",
    "text": "82.1 HW - Computational considerations for Mixture Models\n\\begin{aligned}\n\\mu_1 &= (0,0)' \\\\\n\\mu_2 &= (1/3,1/3)' \\\\\n\\mu_3 &= (-2/3,1/3)'\n\\end{aligned}\n For an observation x_i = (31,−23)' what is the value of v_{i,2}, the probability of the observation being generated by the second component (rounded to three decimal places)?",
    "crumbs": [
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Computational considerations for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L08-Ex1.html#hw---computational-considerations-for-mixture-models",
    "href": "C3-L08-Ex1.html#hw---computational-considerations-for-mixture-models",
    "title": "82  Computational considerations for Mixture Models",
    "section": "",
    "text": "Consider a mixture of three Gaussian distribution with common identity covariance matrix and means\n\n\n\n0.928\n1.000\n0.072\n\n\nTrue or False: The starting value for the parameters of the mixture model in the EM algorithm could have an impact on the solution you obtain.\n\n\nTrue\nFalse\n\n\nTrue or False: Consider a Bayesian formulation of a Mixture Model that uses informative priors for all the parameters. A Markov chain Monte Carlo (MCMC) algorithm for fitting such model will fail to work if no observations are allocated to a component of the mixture.\n\n\nTrue\nFalse",
    "crumbs": [
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Computational considerations for Mixture Models</span>"
    ]
  },
  {
    "objectID": "C3-L09.html",
    "href": "C3-L09.html",
    "title": "83  M5L9 - Determining the number of components",
    "section": "",
    "text": "83.1 Bayesian Information Criteria - BIC (Video)\nSo far we considered the number of components in the mixture model as a known and fixed parameter. However, in practice, the number of components is often unknown and needs to be estimated from the data. We will cover two approaches to estimate the number of components in a mixture model:\nWe can consider the choice of the number of components in a mixture model as a model selection problem. In this context, we have a collection of J models, each with a different number of components. The goal is to select the model that best fits with the evidence/data while avoiding overfitting.\nA common approach to model selection that is useful for mixture models is the Bayesian Information Criteria (BIC). Given a collection of J models to be compared, the BIC for model j is given by the formula: \nBIC_k = - 2\\log L_j(\\hat{\\eta}) - r_k \\log (n) \\qquad\n\\tag{83.1}\nwhere L_j is the likelihood of the model, \\hat{\\eta} is the maximum likelihood estimate of the parameters, r_j is the number of effective (independent) parameters in model j, and n is the number of observations. The model with the lowest BIC value is considered the best model.\nWe can interpret the first term in Equation 83.1 as a measure of the goodness of fit of the model, while the second term penalizes the model for its complexity. The BIC is a trade-off between the goodness of fit and the complexity of the model.\nIn the case of mixture models, j corresponds to the number of components K in the model. and \\eta_k corresponds to the parameters of the model, which include the weights and parameters of the of the component distributions i.e. \\eta_k = (w_1,\\ldots,w_k, \\theta_1, \\ldots \\theta_K) . The number of effective parameters in a mixture model with K components is given by: \nL_k(\\hat{w}_1,...\\hat{w}_K, \\hat{\\theta}_1,...,\\hat{\\theta_K}) = \\prod_{i=1}^n \\sum_{k=1}^K \\hat{w}_k g(x_i|\\hat{\\theta}_k)\nfurthermore, the number of effective parameters is given by:\nr_k = K - 1 + \\sum_{k=1}^K \\dim(\\theta_k)\n### HW Bayesian Information Criteria (BIC)",
    "crumbs": [
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>M5L9 - Determining the number of components</span>"
    ]
  },
  {
    "objectID": "C3-L09.html#sec-BIC",
    "href": "C3-L09.html#sec-BIC",
    "title": "83  M5L9 - Determining the number of components",
    "section": "",
    "text": "BIC\n\n\n\n\nBIC\n\n\n\n\n\n\n\n\n\n\n\n83.1.1 Bayesian Information Criteria Example (Video)\nThis is a walkthrough of the code in the next section.\n\n\n83.1.2 Sample code: Bayesian Information Criteria (Reading)\n\n\nCode\n## Illustrating the use of BIC to estimate the number of components of a Mixture Model\n## using the galaxies dataset\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\ndata(galaxies)\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\nKKmax = 20\nBIC   = rep(0, KKmax-1)\n\nw.sum  = vector(\"list\", KKmax-1)\nmu.sum = vector(\"list\", KKmax-1)\nsigma.sum = rep(0, KKmax-1)\n\nfor(KK in 2:KKmax){\n  ### First, compute the \"Maximum Likelihood\" density estimate \n  ### associated with a location mixture of 6 Gaussian distributions \n  ### using the EM algorithm\n  ## Initialize the parameters\n  w     = rep(1,KK)/KK\n  mu    = rnorm(KK, mean(x), sd(x))\n  sigma = sd(x)/KK\n  \n  epsilon = 0.000001\n  s       = 0\n  sw      = FALSE\n  KL      = -Inf\n  KL.out  = NULL\n  \n  while(!sw){\n    ## E step\n    v = array(0, dim=c(n,KK))\n    for(k in 1:KK){\n      v[,k] = log(w[k]) + dnorm(x, mu[k], sigma,log=TRUE)  \n    }\n    for(i in 1:n){\n      v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))\n    }\n    \n    ## M step\n    # Weights\n    w = apply(v,2,mean)\n    mu = rep(0, KK)\n    for(k in 1:KK){\n      for(i in 1:n){\n        mu[k]    = mu[k] + v[i,k]*x[i]\n      }\n      mu[k] = mu[k]/sum(v[,k])\n    }\n    # Standard deviations\n    sigma = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n      }\n    }\n    sigma = sqrt(sigma/sum(v))\n    \n    ##Check convergence\n    KLn = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        KLn = KLn + v[i,k]*(log(w[k]) + \n                        dnorm(x[i], mu[k], sigma, log=TRUE))\n      }\n    }\n    if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n      sw=TRUE\n    }\n    KL = KLn\n    KL.out = c(KL.out, KL)\n    s = s + 1\n    if(s/20==floor(s/20)){      \n      print(paste(s, KLn))\n    }\n  }\n  \n  w.sum[[KK-1]]  = w\n  mu.sum[[KK-1]] = mu\n  sigma.sum[KK-1] = sigma\n  \n  \n  ## Computing BIC\n  for(i in 1:n){\n    BIC[KK-1] = BIC[KK-1] - 2*log(sum(w*dnorm(x[i], mu, sigma)))\n  }\n  BIC[KK-1] = BIC[KK-1] + ((KK-1) + 1 + KK)*log(n)  ### KK-1 independent weights, one variance, and KK means\n}\n\n\n[1] \"20 -861.300160340851\"\n[1] \"40 -861.845102704334\"\n[1] \"60 -862.021825056483\"\n[1] \"80 -862.107312512661\"\n[1] \"100 -862.156909986849\"\n[1] \"120 -862.188905642997\"\n[1] \"140 -862.211044984583\"\n[1] \"20 -892.435584724028\"\n[1] \"40 -893.104888016642\"\n[1] \"60 -893.40498202712\"\n[1] \"80 -893.591204291568\"\n[1] \"100 -893.723710425507\"\n[1] \"120 -893.825831831938\"\n[1] \"140 -893.908860452777\"\n[1] \"160 -893.979019408269\"\n[1] \"180 -894.040054525798\"\n[1] \"200 -894.094370451017\"\n[1] \"220 -894.143587647454\"\n[1] \"240 -894.188838741371\"\n[1] \"260 -894.230936144577\"\n[1] \"280 -894.27047113134\"\n[1] \"300 -894.307873877557\"\n[1] \"320 -894.343449688044\"\n[1] \"340 -894.37739943714\"\n[1] \"360 -894.40982826946\"\n[1] \"380 -894.440744086025\"\n[1] \"400 -894.470045342745\"\n[1] \"420 -894.497495562189\"\n[1] \"440 -894.522679009391\"\n[1] \"460 -894.544927117938\"\n[1] \"20 -833.432143007169\"\n[1] \"40 -818.168044247337\"\n[1] \"20 -826.416964018383\"\n[1] \"40 -770.789119074513\"\n[1] \"20 -828.321379092958\"\n[1] \"40 -795.942449657444\"\n[1] \"20 -794.662374351299\"\n[1] \"20 -809.439563423673\"\n[1] \"40 -808.663042378389\"\n[1] \"20 -801.80909130307\"\n[1] \"40 -799.673095387316\"\n[1] \"60 -795.809414492802\"\n[1] \"80 -796.314077121678\"\n[1] \"100 -796.933079286827\"\n[1] \"120 -797.365852316129\"\n[1] \"140 -797.658242104202\"\n[1] \"160 -797.855651509745\"\n[1] \"180 -797.990205412934\"\n[1] \"200 -798.083160070137\"\n[1] \"220 -798.148337498443\"\n[1] \"240 -798.194729342538\"\n[1] \"260 -798.228231798405\"\n[1] \"280 -798.252756139525\"\n[1] \"300 -798.270931855528\"\n[1] \"20 -798.319463648812\"\n[1] \"40 -794.845009758997\"\n[1] \"20 -826.983331709186\"\n[1] \"40 -821.239623208658\"\n[1] \"60 -819.799267130562\"\n[1] \"20 -816.295987712457\"\n[1] \"40 -806.709549732948\"\n[1] \"60 -799.9518751137\"\n[1] \"80 -799.129266973443\"\n[1] \"100 -799.002745451039\"\n[1] \"120 -798.945377403758\"\n[1] \"140 -798.91051104072\"\n[1] \"160 -798.887897813767\"\n[1] \"20 -815.12255712431\"\n[1] \"40 -815.861463325247\"\n[1] \"60 -816.65277780204\"\n[1] \"80 -817.367420905963\"\n[1] \"100 -817.981695199728\"\n[1] \"120 -818.482121987687\"\n[1] \"140 -818.87830886769\"\n[1] \"160 -819.188917828566\"\n[1] \"180 -819.43207261762\"\n[1] \"200 -819.622680437914\"\n[1] \"220 -819.772400789357\"\n[1] \"240 -819.890235329328\"\n[1] \"260 -819.983130882009\"\n[1] \"280 -820.05646679529\"\n[1] \"300 -820.114425855522\"\n[1] \"320 -820.160272929299\"\n[1] \"340 -820.196564739275\"\n[1] \"360 -820.225308853616\"\n[1] \"380 -820.248085081872\"\n[1] \"20 -851.834637132759\"\n[1] \"40 -846.408634750858\"\n[1] \"60 -845.373438543406\"\n[1] \"80 -845.241334679279\"\n[1] \"100 -845.152403322103\"\n[1] \"120 -844.93698044634\"\n[1] \"140 -844.478918069205\"\n[1] \"160 -843.859272082294\"\n[1] \"180 -843.396830866521\"\n[1] \"200 -843.157791850473\"\n[1] \"220 -842.987198075861\"\n[1] \"240 -842.746387043908\"\n[1] \"260 -842.311020162512\"\n[1] \"280 -841.525460525532\"\n[1] \"300 -840.13307886189\"\n[1] \"320 -837.637646283637\"\n[1] \"340 -834.447395567086\"\n[1] \"360 -833.024355453823\"\n[1] \"380 -832.778629503937\"\n[1] \"20 -830.712619627954\"\n[1] \"40 -831.59431933264\"\n[1] \"60 -831.760529398233\"\n[1] \"20 -839.780784325688\"\n[1] \"40 -831.549890278729\"\n[1] \"60 -799.604532650141\"\n[1] \"80 -798.987352669928\"\n[1] \"100 -794.989269879538\"\n[1] \"120 -789.077330165171\"\n[1] \"140 -782.992659155106\"\n[1] \"160 -779.078509255756\"\n[1] \"180 -777.844806633688\"\n[1] \"200 -777.752544725934\"\n[1] \"20 -833.977026832454\"\n[1] \"40 -829.411289375974\"\n[1] \"60 -807.265963558671\"\n[1] \"80 -801.845362767957\"\n[1] \"100 -796.131513754935\"\n[1] \"120 -795.383807283214\"\n[1] \"140 -793.411136510273\"\n[1] \"160 -790.669333999831\"\n[1] \"180 -787.910419504715\"\n[1] \"200 -786.399810943812\"\n[1] \"220 -785.118217074068\"\n[1] \"240 -784.899208579399\"\n[1] \"20 -833.733328938719\"\n[1] \"40 -812.315430568933\"\n[1] \"60 -808.877039049294\"\n[1] \"80 -799.484504043974\"\n[1] \"100 -781.392623208429\"\n[1] \"120 -779.207456613408\"\n[1] \"140 -778.924812359465\"\n\n\nCode\n## Plot of BIC as a function of K\npar(mar=c(4,4,1,1) + 0.1)\nplot(seq(2,KKmax), BIC, type=\"l\", xlab=\"K\", ylab=\"BIC\", lwd=2)\nabline(v=6, lty=3)\n\n\n\n\n\n\n\n\n\nCode\n## Computing density estimates for various values of K\ndensity.est = function(xx, w, mu, sigma){\n  KK  = length(w)\n  nxx = length(xx)\n  density.EM = rep(0, nxx)\n  for(s in 1:nxx){\n    for(k in 1:KK){\n      density.EM[s] = density.EM[s] + w[k]*dnorm(xx[s], mu[k], sigma)\n    }\n  }\n  return(density.EM)\n}\n\nxx  = seq(5000,37000,length=300)\nKK = 8\nmdeKK8 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 7\nmdeKK7 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 6\nmdeKK6 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 5\nmdeKK5 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 4\nmdeKK4 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\n\n## Comparing density estimates for K=4, 5 and 6\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, mdeKK6, type=\"n\",ylim=c(0,max(c(mdeKK4,mdeKK5,mdeKK6,mdeKK7))), \n     xlab=\"Velocity\", ylab=\"Density\")\nlines(xx, mdeKK6, col=\"black\", lty=1, lwd=2)\nlines(xx, mdeKK5, col=\"red\", lty=2, lwd=2)\nlines(xx, mdeKK4, col=\"blue\", lty=3, lwd=2)\npoints(x, rep(0,n))\nlegend(26000, 0.00022, c(\"K = 6\",\"K = 5\",\"K = 4\"), \n       lty=c(1,2,3), col=c(\"black\",\"red\",\"blue\"), bty=\"n\")\n\n\n\n\n\n\n\n\n\nCode\n## Comparing density estimates for K=6, 7 and 8\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, mdeKK6, type=\"n\",ylim=c(0,max(c(mdeKK6,mdeKK7,mdeKK8))), \n     xlab=\"Velocity\", ylab=\"Density\")\nlines(xx, mdeKK6, col=\"black\", lty=1, lwd=2)\nlines(xx, mdeKK7, col=\"red\", lty=2, lwd=2)\nlines(xx, mdeKK8, col=\"blue\", lty=3, lwd=2)\npoints(x, rep(0,n))\nlegend(26000, 0.00022, c(\"K = 6\",\"K = 7\",\"K = 8\"), \n       lty=c(1,2,3), col=c(\"black\",\"red\",\"blue\"), bty=\"n\")\n\n\n\n\n\n\n\n\n\nCode\n## What happens with the variance (bandwidth) as K increases\npar(mar=c(4,4,1,1) + 0.1)\nplot(seq(2,KKmax), sigma.sum, type=\"l\", xlab=\"K\", \n     ylab=expression(hat(sigma)), lwd=2)\nabline(v=6, lty=3)\n\n\n\n\n\n\n\n\n\n\n\n83.1.3 Estimating the number of components in Bayesian settings (Video)\nThe BIC has the term Bayesian in its name, but it is not a Bayesian method. It is a frequentist method that uses the likelihood of the model and the number of parameters to estimate the number of components. In contrast, Bayesian methods use the posterior distribution of the model parameters to estimate the number of components.\nSo what we want is to have a posterior estimate of the number of components. We can do this by using a Dirichlet process prior on the weights of the mixture model. The Dirichlet process is a nonparametric prior that allows for an infinite number of components, but only a finite number of them will be used in the posterior distribution.\n\n\n83.1.4 Bayesian Information Criteria (BIC) for Mixture Models\n\n\n\n\nEstimating the number of components\n\n\n\n\nEstimating the number of components\n\n\n\nK= maximum number of components\nK* = number of components that really generated the model\n\n\nK&lt;&lt;K*$\n\nso far we used\n\n\\tilde{w} \\sim Dir(1, \\ldots ,1) = U(0,1)\n\\tag{83.2}\nbut this won’t work because the number of weights in the prior increases with K and has increasing influence on the posterior. We need to use a prior that reduces the influence on the posterior as K increase like: \n\\tilde{w} \\sim Dir(\\alpha/K, \\ldots, \\alpha/K)\n\\tag{83.3}\nwhere \\alpha is a hyperparameter that controls the strength of the prior. The larger the value of \\alpha, the more influence the prior has on the posterior distribution.\nif (w_1,…,w_K)∼Dir(α/K,…,α/K), then the expected number of occupied components is given by:\n\n\\begin{aligned}\n\\lim_{K \\to \\infty} \\mathbb{E}[K^*] &= \\sum_{i=0}^n \\frac{\\alpha}{\\alpha+i-1}\n\\\\ & \\approx \\int_0^1 \\frac{\\alpha}{\\alpha +x-1} dx \\qquad \\text{(Riemann sum approximation)}\n\\\\ & = \\alpha \\log\\left(\\frac{n+\\alpha-1}{\\alpha}\\right)\n\\end{aligned} \\qquad\n\\tag{83.4}\n\n\\mathbb{E}[K^*] \\approx \\alpha \\log\\left(\\frac{n+\\alpha-1}{\\alpha}\\right)\n\\tag{83.5}\nleaving us with just a single parameter \\alpha to tune. This is a very useful result because it allows us to estimate the number of components in a mixture model without having to specify the number of components in advance.\n\n\n83.1.5 Sample code for estimating the number of components and the partition structure in Bayesian models (Reading)\n\n\nCode\n## Full Bayesian estimation of a mixture model for density estimation in the galaxies dataset\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\ndata(galaxies)\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n### Fitting a Bayesian mixture model with \nKK = 30   ## In this formulation, it should be interpreted as the \n          ## maximum number of components allowed\n\n## Finding the value of alpha consistent with 6 expected components a priori\nff = function(alpha)  alpha*log((82+alpha-1)/alpha) - 6\nalph = uniroot(ff, c(0.01, 20))\nalph$root  # 1.496393\n\n\n[1] 1.496393\n\n\nCode\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(1.5/KK,KK)  # We approximate 1.496393 by 1.5\neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/KK\n\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\ncc    = sample(1:KK, n, replace=T, prob=w)\n\n## Number of iterations of the sampler\nrrr   = 25000\nburn  = 5000\n\n## Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = array(0, dim=c(rrr, KK))\nlogpost   = rep(0, rrr)\n\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  \n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n  \n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(1/rgamma(1, dd.star, qq.star))\n  \n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s,]    = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dnorm(x[i], mu[cc[i]], sigma, log=TRUE)\n  }\n  logpost[s] = logpost[s] + log(ddirichlet(w, aa))\n  for(k in 1:KK){\n      logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log=TRUE)\n  }\n  logpost[s] = logpost[s] + dgamma(1/sigma^2, dd, qq, log=TRUE) - 4*log(sigma)\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n[1] \"s = 12500\"\n[1] \"s = 13000\"\n[1] \"s = 13500\"\n[1] \"s = 14000\"\n[1] \"s = 14500\"\n[1] \"s = 15000\"\n[1] \"s = 15500\"\n[1] \"s = 16000\"\n[1] \"s = 16500\"\n[1] \"s = 17000\"\n[1] \"s = 17500\"\n[1] \"s = 18000\"\n[1] \"s = 18500\"\n[1] \"s = 19000\"\n[1] \"s = 19500\"\n[1] \"s = 20000\"\n[1] \"s = 20500\"\n[1] \"s = 21000\"\n[1] \"s = 21500\"\n[1] \"s = 22000\"\n[1] \"s = 22500\"\n[1] \"s = 23000\"\n[1] \"s = 23500\"\n[1] \"s = 24000\"\n[1] \"s = 24500\"\n[1] \"s = 25000\"\n\n\nCode\nnunique = function(x)   length(unique(x))\nKstar = apply(cc.out[-seq(1,burn),],1,nunique)\npar(mar=c(4,4,1,1) + 0.1)\nbarplot(table(Kstar)/sum(table(Kstar)), xlab=expression(K^\"*\"), ylab=\"Frequency\")\n\n\n\n\n\n\n\n\n\nCode\n#dev.print(file=\"postKstaralpha2.pdf\", dev=pdf)\n\n\n## Construct pairwise co-clustering matrix for this dataset\npairwise = matrix(0, nrow=n, ncol=n)\nfor(s in 1:(rrr-burn)){\n  for(i in 1:n){\n    for(j in i:n){\n      pairwise[i,j] = pairwise[i,j] + as.numeric(cc.out[s+burn,i]==cc.out[s+burn,j])\n      pairwise[j,i] = pairwise[i,j]\n    }\n  }  \n}\nDD = pairwise/max(pairwise)\n\nheatmapplot = function(DD, alab, subsetaxis, llc=FALSE){\n  n = dim(DD)[1]\n  #colorscale = rev(gray(0:100 / 100))\n  colorscale = c(\"white\", rev(heat.colors(100)))\n  nf = layout(matrix(c(1,2),nrow=1,ncol=2), c(7,1), TRUE)\n  par(mar=c(4,3,1,0.5))\n  \n  ###Display heat-map\n  image(seq(1,n), seq(1,n), DD, axes=F, xlab=\"\", ylab=\"\", \n        col=colorscale[seq(floor(min(100*DD)), floor(max(100*DD))) + 1])\n  axis(1,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  axis(2,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  box()\n  abline(v = llc+0.5)\n  abline(h = llc+0.5)\n  \n  ###Display color scale\n  par(mar=c(3,0,0,0))\n  plot(1:100,1:100,xlim=c(0,2),ylim=c(0,100),type=\"n\",axes=F,xlab =\"\",ylab =\"\")\n  yposr = 1:100\n  rect(0, yposr-.5, 0.5, yposr+.5,col = colorscale, border=F)\n  rect(0, .5, 0.5, 100.5,col = \"transparent\")\n  text(0.42,c(yposr[1],yposr[25],yposr[50],yposr[75],yposr[100]),c(\"0.00\",\"0.25\",\"0.50\",\"0.75\",\"1.00\"),pos=4,cex=1.1)\n}\nheatmapplot(DD, seq(1,n), seq(1,n,by=3))\n\n\n\n\n\n\n\n\n\nCode\n## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate and frequentist point estimate\n## Compute the samples of the density over a dense grid\nxx  = seq(5000,37000,length=300)\ndensity.mcmc = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  for(k in 1:KK){\n    density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn])\n  }\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\nyy = density(x)\ncolscale = c(\"black\", \"red\")\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Velocity\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=colscale[1], lwd=2)\nlines(yy, col=colscale[2], lty=2, lwd=2)\npoints(x, rep(0,n))\nlegend(27000, 0.00017, c(\"MCMC\",\"KDE\"), col=colscale[c(1,2)], lty=c(1,2), lwd=2, bty=\"n\")\n\n\n\n\n\n\n\n\n\nCode\n##### Finding optimal partition according to Binder's loss function\n##\n## Function that computes the loss at a particular configuration\nLstst = function(cch, DD, Dbar){\n  z = 0\n  for(i in 1:(n-1)){\n    for(j in (i+1):n){\n      if(cch[i]==cch[j]){\n        z = z + (DD[i,j]-Dbar)\n      }\n    }\n  }\n  return(z)\n}\n\n## Initial value of the algorithm is the last iteration of the sampler\n## Using as.numeric(factor()) is a cheap way to force the cluster labels \n## to be sequential starting at 1\ncch = as.numeric(factor(cc))\n\n## Setup parameters for the recursive alorithm\nDbar = 0.50\noptLstst.old  = -Inf\noptLstst.new = Lstst(cch, DD, Dbar=Dbar)\nmaxiter = 50\nniter   = 1\nwhile((optLstst.old!=optLstst.new)&(niter&lt;=maxiter)){\n  for(i in 1:n){\n    nq   = max(cch) + 1\n    q    = rep(0, nq)\n    for(s in 1:nq){\n      ccht    = cch\n      ccht[i] = s\n      q[s] = Lstst(ccht, DD, Dbar=Dbar)\n    }\n    cch[i] = which.max(q)\n    cch = as.numeric(factor(cch))\n  }\n  optLstst.old = optLstst.new\n  optLstst.new = Lstst(cch, DD, Dbar=Dbar)\n  niter = niter+1\n}\n#print(nunique(cch))\n\n## Create another heatmap plot of the co-clustering matrix in which the \n## optimal clusters are represented.\ncchlo    = as.numeric(as.character(factor(cch, labels=order(unique(cch)))))\ncchlotab = table(cchlo)\nllc      = cumsum(cchlotab[-length(cchlotab)])\nheatmapplot(DD, seq(1,n), seq(1,n,by=3), llc=llc)\n\n\n\n\n\n\n\n\n\nCode\n#dev.print(file=\"galaxiesheatmap50.pdf\", dev=pdf)",
    "crumbs": [
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>M5L9 - Determining the number of components</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex1.html",
    "href": "C3-L09-Ex1.html",
    "title": "84  M5HW2 - Bayesian Information Criteria (BIC)",
    "section": "",
    "text": "Exercise 84.1 Consider a K-component mixture of D-dimensional Multinomial distributions,\n\nf(x) = \\sum_{k=1}^K w_k \\left( \\frac{x_1 + x_2 + \\cdots + x_D}{x_1 \\, x_2 \\cdots x_D} \\right) \\prod_{d=1}^D \\theta_{d,k}^{x_d}\n\nwhere x = (x_1, \\ldots, x_D) and \\sum_{d=1}^D \\theta_{d,k} = 1 for all k = 1, \\ldots, K. For the purpose of computing the BIC, what is the effective number of parameters in the model?\n\n(K−1)+K×D\nK+K×(D−1)\n(K−1)+K×(D−1)\n(K−1)×(D−1)\n\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nThe effective number of parameters can be computed as follows:\n\nThe mixture weights w_k contribute K - 1 parameters (since they must sum to 1).\nEach component k has D-1 independent parameters \\theta_{d,k} for d = 1, \\ldots, D. the last is determined by the constraint \\sum_{d=1}^D \\theta_{d,k} = 1. Thus, each component contributes D parameters.\n\nThus, the total number of parameters is:\n\n\\text{Total parameters} = (K - 1) + K \\cdot (D - 1)",
    "crumbs": [
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>M5HW2 - Bayesian Information Criteria (BIC)</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex2.html",
    "href": "C3-L09-Ex2.html",
    "title": "85  M5HW2 - Estimating the number of components in Bayesian settings",
    "section": "",
    "text": "Exercise 85.1 Let K^∗ be the prior expected number of occupied components in a mixture model with K components where the weights are given a Dirichlet prior (w_1, \\ldots, w_K) \\sim \\text{Dir}(2K, \\ldots, 2K). If you have n = 400 observations, what is the expected number of occupied components, E(K^∗) according to the exact formula we discussed in the lecture? Round your answer to one decimal place.\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nTo compute the expected number of occupied components, we can use the formula:\n\nE(K^*) = \\sum_{i=0}^n \\frac{\\alpha}{\\alpha+i-1}\n Thus, the expected number of occupied components is given by:\n\n\nCode\nE.Kstar = 0\nfor (i in 1:400){\n  E.Kstar = E.Kstar +  2/(2+i-1)\n}\nround(E.Kstar,1)\n\n\n[1] 11.1\n\n\n11.1\n\n\n\n\nExercise 85.2 Consider the same setup as the previous question, what is the expected number of occupied components, E(K^∗) according to the exact formula we discussed in the lecture if n = 100 instead? Round your answer to one decimal place.\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n\n\nCode\nn      = 100\nalpha  = 2\n\nEKstar = 0\nfor(i in 1:n){\n  EKstar = EKstar + alpha/(alpha + i -1)\n}\nprint(EKstar)\n\n\n[1] 8.394557\n\n\n8.4\n\n\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nWhat would be the answer to the previous question if you used the approximate formula instead of the exact formula? Remember to round your answer to one decimal place.\n\n\n\n\nExercise 85.3  \n\n\nCode\nalpha = 2\nn = 100\nKstar = alpha*log((n+alpha-1)/alpha)\nround( Kstar,1)\n\n\n[1] 7.8\n\n\n7.8\n\n\nExercise 85.4 If you have n = 200 observations and a priori expect the mixture will have about 2 occupied components (i.e., E(K^∗) \\approx 2 a priori), what value of \\alpha should you use for the prior (w_1, \\ldots, w_K) \\sim \\text{Dir}(\\alpha K, \\ldots, \\alpha K). Use the approximation E(K^∗) \\approx \\alpha \\log\\left(\\frac{n + \\alpha - 1}{\\alpha}\\right) to provide an answer, which should be rounded to two decimal\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n\n\nCode\nn      = 200\nalpha  = 2\nalpha*log((n+alpha-1)/alpha)\n\n\n[1] 9.220315\n\n\n0.31",
    "crumbs": [
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>M5HW2 - Estimating the number of components in Bayesian settings</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex3.html",
    "href": "C3-L09-Ex3.html",
    "title": "86  M5HW3 - Estimating the partition structure in Bayesian models",
    "section": "",
    "text": "86.1 HW - Estimating the partition structure in Bayesian models\nCode\n## Full Bayesian estimation of a mixture model for density estimation in the galaxies dataset\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)      ## for the dataset\nlibrary(MCMCpack)  ## for the rWishart() in the full conditionals\n\n\nLoading required package: coda\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\ndata(galaxies)\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n### Fitting a Bayesian mixture model with \nKK = 30   ## the maximum number of components allowed\n\n## Finding the value of alpha consistent with 6 expected components a priori\nff = function(alpha)  alpha*log((82+alpha-1)/alpha) - 6\nalph = uniroot(ff, c(0.01, 20)) #solve nonlinear equation ff in range [0.01, 20]\nalph$root  # 1.496393\n\n\n[1] 1.496393\n\n\nCode\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(1.5/KK,KK)  # We approximate 1.496393 by 1.5\neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/KK\n\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\ncc    = sample(1:KK, n, replace=T, prob=w)\n\n## Number of iterations of the sampler\nrrr   = 25000\nburn  = 5000\n\n## Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = array(0, dim=c(rrr, KK))\nlogpost   = rep(0, rrr)\n\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  \n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n  \n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(1/rgamma(1, dd.star, qq.star))\n  \n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s,]    = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dnorm(x[i], mu[cc[i]], sigma, log=TRUE)\n  }\n  logpost[s] = logpost[s] + log(ddirichlet(w, aa))\n  for(k in 1:KK){\n      logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log=TRUE)\n  }\n  logpost[s] = logpost[s] + dgamma(1/sigma^2, dd, qq, log=TRUE) - 4*log(sigma)\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n[1] \"s = 12500\"\n[1] \"s = 13000\"\n[1] \"s = 13500\"\n[1] \"s = 14000\"\n[1] \"s = 14500\"\n[1] \"s = 15000\"\n[1] \"s = 15500\"\n[1] \"s = 16000\"\n[1] \"s = 16500\"\n[1] \"s = 17000\"\n[1] \"s = 17500\"\n[1] \"s = 18000\"\n[1] \"s = 18500\"\n[1] \"s = 19000\"\n[1] \"s = 19500\"\n[1] \"s = 20000\"\n[1] \"s = 20500\"\n[1] \"s = 21000\"\n[1] \"s = 21500\"\n[1] \"s = 22000\"\n[1] \"s = 22500\"\n[1] \"s = 23000\"\n[1] \"s = 23500\"\n[1] \"s = 24000\"\n[1] \"s = 24500\"\n[1] \"s = 25000\"\nCode\nnunique = function(x)   length(unique(x))\nKstar = apply(cc.out[-seq(1,burn),],1,nunique)\npar(mar=c(4,4,1,1) + 0.1)\nbarplot(table(Kstar)/sum(table(Kstar)), xlab=expression(K^\"*\"), ylab=\"Frequency\")\n#dev.print(file=\"postKstaralpha2.pdf\", dev=pdf)\n\n\n\n\n\n\n\n\nFigure 86.1: Posterior distribution of the number of components in the galaxies dataset using a Dirichlet prior with alpha = 1.5/K.\nthe pairwise probability matrix\nCode\n## Construct pairwise co-clustering matrix for this dataset\npairwise = matrix(0, nrow=n, ncol=n)\nfor(s in 1:(rrr-burn)){\n  for(i in 1:n){\n    for(j in i:n){\n      pairwise[i,j] = pairwise[i,j] + as.numeric(cc.out[s+burn,i]==cc.out[s+burn,j])\n      pairwise[j,i] = pairwise[i,j]\n    }\n  }  \n}\nDD = pairwise/max(pairwise)\n#DD\nheatmap plot function\nCode\nheatmapplot = function(DD, alab, subsetaxis, llc=FALSE){\n  n = dim(DD)[1]\n  #colorscale = rev(gray(0:100 / 100))\n  colorscale = c(\"white\", rev(heat.colors(100)))\n  nf = layout(matrix(c(1,2),nrow=1,ncol=2), c(7,1), TRUE)\n  par(mar=c(4,3,1,0.5))\n  \n  ###Display heat-map\n  image(seq(1,n), seq(1,n), DD, axes=F, xlab=\"\", ylab=\"\", \n        col=colorscale[seq(floor(min(100*DD)), floor(max(100*DD))) + 1])\n  axis(1,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  axis(2,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  box()\n  abline(v = llc+0.5)\n  abline(h = llc+0.5)\n  \n  ###Display color scale\n  par(mar=c(3,0,0,0))\n  plot(1:100,1:100,xlim=c(0,2),ylim=c(0,100),type=\"n\",axes=F,xlab =\"\",ylab =\"\")\n  yposr = 1:100\n  rect(0, yposr-.5, 0.5, yposr+.5,col = colorscale, border=F)\n  rect(0, .5, 0.5, 100.5,col = \"transparent\")\n  text(0.42,c(yposr[1],yposr[25],yposr[50],yposr[75],yposr[100]),c(\"0.00\",\"0.25\",\"0.50\",\"0.75\",\"1.00\"),pos=4,cex=1.1)\n}\n\nheatmapplot(DD, seq(1,n), seq(1,n,by=3))\n\n\n\n\n\n\n\n\nFigure 86.2: Heatmap of the pairwise co-clustering matrix for the galaxies dataset using a Dirichlet prior with alpha = 1.5/K.\nCode\n## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate and frequentist point estimate\n## Compute the samples of the density over a dense grid\nxx  = seq(5000,37000,length=300)\ndensity.mcmc = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  for(k in 1:KK){\n    density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn])\n  }\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\nyy = density(x)\ncolscale = c(\"black\", \"red\")\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Velocity\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=colscale[1], lwd=2)\nlines(yy, col=colscale[2], lty=2, lwd=2)\npoints(x, rep(0,n))\nlegend(27000, 0.00017, c(\"MCMC\",\"KDE\"), col=colscale[c(1,2)], lty=c(1,2), lwd=2, bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 86.3: Posterior distribution of the number of components in the galaxies dataset using a Dirichlet prior with alpha = 1.5/K.\nwe want a point estimate for the number of components in the optimal partition according to Binder’s loss function with \\gamma_1 = 3 and \\gamma_2 = 1.\nCode\n##### Finding optimal partition according to Binder's loss function\n##\n## Function that computes the loss at a particular configuration\nLstst = function(cch, DD, Dbar){\n  z = 0\n  for(i in 1:(n-1)){\n    for(j in (i+1):n){\n      if(cch[i]==cch[j]){\n        z = z + (DD[i,j]-Dbar)\n      }\n    }\n  }\n  return(z)\n}\n\n## Initial value of the algorithm is the last iteration of the sampler\n## Using as.numeric(factor()) is a cheap way to force the cluster labels \n## to be sequential starting at 1\ncch = as.numeric(factor(cc))\n\n\n\n## Setup parameters for the recursive alorithm\n#Dbar = 0.50   # the same penalty for fp and fn errors\ngamma_1 = 3\ngamma_2 = 1\nDbar = gamma_2 / (gamma_1 + gamma_2) \nDbar # 0.25\n\n\n[1] 0.25\n\n\nCode\noptLstst.old  = -Inf\noptLstst.new = Lstst(cch, DD, Dbar=Dbar)\nmaxiter = 50\nniter   = 1\nwhile((optLstst.old!=optLstst.new)&(niter&lt;=maxiter)){\n  for(i in 1:n){\n    nq   = max(cch) + 1\n    q    = rep(0, nq)\n    for(s in 1:nq){\n      ccht    = cch\n      ccht[i] = s\n      q[s] = Lstst(ccht, DD, Dbar=Dbar)\n    }\n    cch[i] = which.max(q)\n    cch = as.numeric(factor(cch))\n  }\n  optLstst.old = optLstst.new\n  optLstst.new = Lstst(cch, DD, Dbar=Dbar)\n  niter = niter+1\n}\n\nprint(nunique(cch))\n\n\n[1] 6\nCode\n## Create another heatmap plot of the co-clustering matrix in which the \n## optimal clusters are represented.\ncchlo    = as.numeric(as.character(factor(cch, labels=order(unique(cch)))))\ncchlotab = table(cchlo)\nllc      = cumsum(cchlotab[-length(cchlotab)])\nheatmapplot(DD, seq(1,n), seq(1,n,by=3), llc=llc)\n#dev.print(file=\"galaxiesheatmap50.pdf\", dev=pdf)\n\n\n\n\n\n\n\n\nFigure 86.4: Heatmap of the pairwise co-clustering matrix for the galaxies dataset using a Dirichlet prior with alpha = 1.5/K.\nCode\n## Full Bayesian estimation of a mixture model for density estimation in the galaxies dataset\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(MCMCpack)\ndata(galaxies)\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n### Fitting a Bayesian mixture model with \nKK = 30   ## In this formulation, it should be interpreted as the \n          ## maximum number of components allowed\n\n## Finding the value of alpha consistent with 6 expected components a priori\nff = function(alpha)  alpha*log((82+alpha-1)/alpha) - 6\nalph = uniroot(ff, c(0.01, 20))\nalph$root  # 1.496393\n\n\n[1] 1.496393\n\n\nCode\nalph$root = 0.2\n\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(1.5/KK,KK)  # We approximate 1.496393 by 1.5\neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/KK\n\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\ncc    = sample(1:KK, n, replace=T, prob=w)\n\n## Number of iterations of the sampler\nrrr   = 25000\nburn  = 5000\n\n## Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = array(0, dim=c(rrr, KK))\nlogpost   = rep(0, rrr)\n\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  \n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n  \n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(1/rgamma(1, dd.star, qq.star))\n  \n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s,]    = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dnorm(x[i], mu[cc[i]], sigma, log=TRUE)\n  }\n  logpost[s] = logpost[s] + log(ddirichlet(w, aa))\n  for(k in 1:KK){\n      logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log=TRUE)\n  }\n  logpost[s] = logpost[s] + dgamma(1/sigma^2, dd, qq, log=TRUE) - 4*log(sigma)\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n[1] \"s = 12500\"\n[1] \"s = 13000\"\n[1] \"s = 13500\"\n[1] \"s = 14000\"\n[1] \"s = 14500\"\n[1] \"s = 15000\"\n[1] \"s = 15500\"\n[1] \"s = 16000\"\n[1] \"s = 16500\"\n[1] \"s = 17000\"\n[1] \"s = 17500\"\n[1] \"s = 18000\"\n[1] \"s = 18500\"\n[1] \"s = 19000\"\n[1] \"s = 19500\"\n[1] \"s = 20000\"\n[1] \"s = 20500\"\n[1] \"s = 21000\"\n[1] \"s = 21500\"\n[1] \"s = 22000\"\n[1] \"s = 22500\"\n[1] \"s = 23000\"\n[1] \"s = 23500\"\n[1] \"s = 24000\"\n[1] \"s = 24500\"\n[1] \"s = 25000\"\n\n\nCode\n## ----- galaxiesbaysian2 \nnunique = function(x)   length(unique(x))\nKstar = apply(cc.out[-seq(1,burn),],1,nunique)\npar(mar=c(4,4,1,1) + 0.1)\nbarplot(table(Kstar)/sum(table(Kstar)), xlab=expression(K^\"*\"), ylab=\"Frequency\")\n\n\n\n\n\n\n\n\n\nCode\n#dev.print(file=\"postKstaralpha2.pdf\", dev=pdf)\n\n## ----- galaxiesbaysian3\n## Construct pairwise co-clustering matrix for this dataset\npairwise = matrix(0, nrow=n, ncol=n)\nfor(s in 1:(rrr-burn)){\n  for(i in 1:n){\n    for(j in i:n){\n      pairwise[i,j] = pairwise[i,j] + as.numeric(cc.out[s+burn,i]==cc.out[s+burn,j])\n      pairwise[j,i] = pairwise[i,j]\n    }\n  }  \n}\nDD = pairwise/max(pairwise)\n\nheatmapplot = function(DD, alab, subsetaxis, llc=FALSE){\n  n = dim(DD)[1]\n  #colorscale = rev(gray(0:100 / 100))\n  colorscale = c(\"white\", rev(heat.colors(100)))\n  nf = layout(matrix(c(1,2),nrow=1,ncol=2), c(7,1), TRUE)\n  par(mar=c(4,3,1,0.5))\n  \n  ###Display heat-map\n  image(seq(1,n), seq(1,n), DD, axes=F, xlab=\"\", ylab=\"\", \n        col=colorscale[seq(floor(min(100*DD)), floor(max(100*DD))) + 1])\n  axis(1,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  axis(2,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  box()\n  abline(v = llc+0.5)\n  abline(h = llc+0.5)\n  \n  ###Display color scale\n  par(mar=c(3,0,0,0))\n  plot(1:100,1:100,xlim=c(0,2),ylim=c(0,100),type=\"n\",axes=F,xlab =\"\",ylab =\"\")\n  yposr = 1:100\n  rect(0, yposr-.5, 0.5, yposr+.5,col = colorscale, border=F)\n  rect(0, .5, 0.5, 100.5,col = \"transparent\")\n  text(0.42,c(yposr[1],yposr[25],yposr[50],yposr[75],yposr[100]),c(\"0.00\",\"0.25\",\"0.50\",\"0.75\",\"1.00\"),pos=4,cex=1.1)\n}\nheatmapplot(DD, seq(1,n), seq(1,n,by=3))\n\n\n\n\n\n\n\n\n\nCode\n## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate and frequentist point estimate\n## Compute the samples of the density over a dense grid\nxx  = seq(5000,37000,length=300)\ndensity.mcmc = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  for(k in 1:KK){\n    density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn])\n  }\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\nyy = density(x)\ncolscale = c(\"black\", \"red\")\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Velocity\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=colscale[1], lwd=2)\nlines(yy, col=colscale[2], lty=2, lwd=2)\npoints(x, rep(0,n))\nlegend(27000, 0.00017, c(\"MCMC\",\"KDE\"), col=colscale[c(1,2)], lty=c(1,2), lwd=2, bty=\"n\")\n\n\n\n\n\n\n\n\n\nCode\n##### Finding optimal partition according to Binder's loss function\n##\n## Function that computes the loss at a particular configuration\nLstst = function(cch, DD, Dbar){\n  z = 0\n  for(i in 1:(n-1)){\n    for(j in (i+1):n){\n      if(cch[i]==cch[j]){\n        z = z + (DD[i,j]-Dbar)\n      }\n    }\n  }\n  return(z)\n}\n\n## Initial value of the algorithm is the last iteration of the sampler\n## Using as.numeric(factor()) is a cheap way to force the cluster labels \n## to be sequential starting at 1\ncch = as.numeric(factor(cc))\n\n## Setup parameters for the recursive alorithm\nDbar = 0.50\noptLstst.old  = -Inf\noptLstst.new = Lstst(cch, DD, Dbar=Dbar)\nmaxiter = 50\nniter   = 1\nwhile((optLstst.old!=optLstst.new)&(niter&lt;=maxiter)){\n  for(i in 1:n){\n    nq   = max(cch) + 1\n    q    = rep(0, nq)\n    for(s in 1:nq){\n      ccht    = cch\n      ccht[i] = s\n      q[s] = Lstst(ccht, DD, Dbar=Dbar)\n    }\n    cch[i] = which.max(q)\n    cch = as.numeric(factor(cch))\n  }\n  optLstst.old = optLstst.new\n  optLstst.new = Lstst(cch, DD, Dbar=Dbar)\n  niter = niter+1\n}\n#print(nunique(cch))\n\n## Create another heatmap plot of the co-clustering matrix in which the \n## optimal clusters are represented.\ncchlo    = as.numeric(as.character(factor(cch, labels=order(unique(cch)))))\ncchlotab = table(cchlo)\nllc      = cumsum(cchlotab[-length(cchlotab)])\nheatmapplot(DD, seq(1,n), seq(1,n,by=3), llc=llc)\n\n\n\n\n\n\n\n\n\nCode\n#dev.print(file=\"galaxiesheatmap50.pdf\", dev=pdf)\nCode\n## Full Bayesian estimation of a mixture model for density estimation in the galaxies dataset\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(MCMCpack)\ndata(galaxies)\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n### Fitting a Bayesian mixture model with \nKK = 30   ## In this formulation, it should be interpreted as the \n          ## maximum number of components allowed\n\n## Finding the value of alpha consistent with 6 expected components a priori\nff = function(alpha)  alpha*log((82+alpha-1)/alpha) - 6\nalph = uniroot(ff, c(0.01, 20))\nalph$root  # 1.496393\n\n\n[1] 1.496393\n\n\nCode\nalph$root = 0.2\n\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(0.2/KK,KK)  # We approximate 1.496393 by 1.5\neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/KK\n\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\ncc    = sample(1:KK, n, replace=T, prob=w)\n\n## Number of iterations of the sampler\nrrr   = 25000\nburn  = 5000\n\n## Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = array(0, dim=c(rrr, KK))\nlogpost   = rep(0, rrr)\n\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  \n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n  \n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(1/rgamma(1, dd.star, qq.star))\n  \n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s,]    = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dnorm(x[i], mu[cc[i]], sigma, log=TRUE)\n  }\n  logpost[s] = logpost[s] + log(ddirichlet(w, aa))\n  for(k in 1:KK){\n      logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log=TRUE)\n  }\n  logpost[s] = logpost[s] + dgamma(1/sigma^2, dd, qq, log=TRUE) - 4*log(sigma)\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n[1] \"s = 12500\"\n[1] \"s = 13000\"\n[1] \"s = 13500\"\n[1] \"s = 14000\"\n[1] \"s = 14500\"\n[1] \"s = 15000\"\n[1] \"s = 15500\"\n[1] \"s = 16000\"\n[1] \"s = 16500\"\n[1] \"s = 17000\"\n[1] \"s = 17500\"\n[1] \"s = 18000\"\n[1] \"s = 18500\"\n[1] \"s = 19000\"\n[1] \"s = 19500\"\n[1] \"s = 20000\"\n[1] \"s = 20500\"\n[1] \"s = 21000\"\n[1] \"s = 21500\"\n[1] \"s = 22000\"\n[1] \"s = 22500\"\n[1] \"s = 23000\"\n[1] \"s = 23500\"\n[1] \"s = 24000\"\n[1] \"s = 24500\"\n[1] \"s = 25000\"\n\n\nCode\n## ----- galaxiesbaysian2 \nnunique = function(x)   length(unique(x))\nKstar = apply(cc.out[-seq(1,burn),],1,nunique)\npar(mar=c(4,4,1,1) + 0.1)\nbarplot(table(Kstar)/sum(table(Kstar)), xlab=expression(K^\"*\"), ylab=\"Frequency\")\n\n\n\n\n\n\n\n\n\nCode\n#dev.print(file=\"postKstaralpha2.pdf\", dev=pdf)\n\n## ----- galaxiesbaysian3\n## Construct pairwise co-clustering matrix for this dataset\npairwise = matrix(0, nrow=n, ncol=n)\nfor(s in 1:(rrr-burn)){\n  for(i in 1:n){\n    for(j in i:n){\n      pairwise[i,j] = pairwise[i,j] + as.numeric(cc.out[s+burn,i]==cc.out[s+burn,j])\n      pairwise[j,i] = pairwise[i,j]\n    }\n  }  \n}\nDD = pairwise/max(pairwise)\n\nheatmapplot = function(DD, alab, subsetaxis, llc=FALSE){\n  n = dim(DD)[1]\n  #colorscale = rev(gray(0:100 / 100))\n  colorscale = c(\"white\", rev(heat.colors(100)))\n  nf = layout(matrix(c(1,2),nrow=1,ncol=2), c(7,1), TRUE)\n  par(mar=c(4,3,1,0.5))\n  \n  ###Display heat-map\n  image(seq(1,n), seq(1,n), DD, axes=F, xlab=\"\", ylab=\"\", \n        col=colorscale[seq(floor(min(100*DD)), floor(max(100*DD))) + 1])\n  axis(1,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  axis(2,at=subsetaxis,labels=alab[subsetaxis],las=2,cex.axis=1)\n  box()\n  abline(v = llc+0.5)\n  abline(h = llc+0.5)\n  \n  ###Display color scale\n  par(mar=c(3,0,0,0))\n  plot(1:100,1:100,xlim=c(0,2),ylim=c(0,100),type=\"n\",axes=F,xlab =\"\",ylab =\"\")\n  yposr = 1:100\n  rect(0, yposr-.5, 0.5, yposr+.5,col = colorscale, border=F)\n  rect(0, .5, 0.5, 100.5,col = \"transparent\")\n  text(0.42,c(yposr[1],yposr[25],yposr[50],yposr[75],yposr[100]),c(\"0.00\",\"0.25\",\"0.50\",\"0.75\",\"1.00\"),pos=4,cex=1.1)\n}\nheatmapplot(DD, seq(1,n), seq(1,n,by=3))\n\n\n\n\n\n\n\n\n\nCode\n## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate and frequentist point estimate\n## Compute the samples of the density over a dense grid\nxx  = seq(5000,37000,length=300)\ndensity.mcmc = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  for(k in 1:KK){\n    density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn])\n  }\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\nyy = density(x)\ncolscale = c(\"black\", \"red\")\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Velocity\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=colscale[1], lwd=2)\nlines(yy, col=colscale[2], lty=2, lwd=2)\npoints(x, rep(0,n))\nlegend(27000, 0.00017, c(\"MCMC\",\"KDE\"), col=colscale[c(1,2)], lty=c(1,2), lwd=2, bty=\"n\")\n\n\n\n\n\n\n\n\n\nCode\n##### Finding optimal partition according to Binder's loss function\n##\n## Function that computes the loss at a particular configuration\nLstst = function(cch, DD, Dbar){\n  z = 0\n  for(i in 1:(n-1)){\n    for(j in (i+1):n){\n      if(cch[i]==cch[j]){\n        z = z + (DD[i,j]-Dbar)\n      }\n    }\n  }\n  return(z)\n}\n\n## Initial value of the algorithm is the last iteration of the sampler\n## Using as.numeric(factor()) is a cheap way to force the cluster labels \n## to be sequential starting at 1\ncch = as.numeric(factor(cc))\n\n## Setup parameters for the recursive alorithm\nDbar = 1/ (1 + 1) \n\noptLstst.old  = -Inf\noptLstst.new = Lstst(cch, DD, Dbar=Dbar)\nmaxiter = 50\nniter   = 1\nwhile((optLstst.old!=optLstst.new)&(niter&lt;=maxiter)){\n  for(i in 1:n){\n    nq   = max(cch) + 1\n    q    = rep(0, nq)\n    for(s in 1:nq){\n      ccht    = cch\n      ccht[i] = s\n      q[s] = Lstst(ccht, DD, Dbar=Dbar)\n    }\n    cch[i] = which.max(q)\n    cch = as.numeric(factor(cch))\n  }\n  optLstst.old = optLstst.new\n  optLstst.new = Lstst(cch, DD, Dbar=Dbar)\n  niter = niter+1\n}\n#print(nunique(cch))\n\n## Create another heatmap plot of the co-clustering matrix in which the \n## optimal clusters are represented.\ncchlo    = as.numeric(as.character(factor(cch, labels=order(unique(cch)))))\ncchlotab = table(cchlo)\nllc      = cumsum(cchlotab[-length(cchlotab)])\nheatmapplot(DD, seq(1,n), seq(1,n,by=3), llc=llc)\n\n\n\n\n\n\n\n\n\nCode\n#dev.print(file=\"galaxiesheatmap50.pdf\", dev=pdf)",
    "crumbs": [
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>M5HW3 - Estimating the partition structure in Bayesian models</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex3.html#hw---estimating-the-partition-structure-in-bayesian-models",
    "href": "C3-L09-Ex3.html#hw---estimating-the-partition-structure-in-bayesian-models",
    "title": "86  M5HW3 - Estimating the partition structure in Bayesian models",
    "section": "",
    "text": "Binder’s loss function is invariant to label switching\n\n\nYes\nNo\n\n\nUse the implementation of the MCMC algorithm for fitting a mixture model to the galaxies dataset contained in the lesson “Sample code for estimating the number of components and the partition structure in Bayesian models” to estimate the number of component associated with the optimal partition obtained using Binder’s loss function with γ_1 = 3 and γ_2 = 1. What is the number of components in the optimal partition?\n\n\n\n\n\n\n\n\n\n\n\n\nRerun the algorithm contained in “Sample code for estimating the number of components and the partition structure in Bayesian models” using a prior for the weights (w_1,…,w_K)\\sim Dir(\\frac{0.2}{K},…,\\frac{0.2}{K}). What is the mode for the posterior distribution on K^*, the number of occupied clusters?\n\n\n\nUnder the new prior (w_1,…,w_K)\\sim Dir(0.2K,…,0.2K), what is the number of components in the optimal partitions according to Binder’s loss function with \\gamma_1 = 3 and \\gamma_2 = 1?",
    "crumbs": [
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>M5HW3 - Estimating the partition structure in Bayesian models</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex4.html",
    "href": "C3-L09-Ex4.html",
    "title": "87  M5HW4 - BIC for zero-inflated mixtures",
    "section": "",
    "text": "87.1 HW - Simulation of Poisson mixture model\nIn the lessons we mentioned that Zero-Inflated Poisson (ZIP) models arises naturally in biology when analyzing nest size data since many birds fail to mate or lay eggs. As such they will have zero eggs in their nests.\nPoisson tends to underestimate the number of empty nests in the data, and overestimate the number of nests with either 1 or 2 eggs. Negative binomial can mitigate this problem by adding a tunable parameter to control for the dispersion of count data, however, it isn’t necessarily a good fix for zero-inflated data.\nIn this exercise, we will use the EM algorithm to fit a ZIP mixture model to a dataset of nest sizes.",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>M5HW4 - BIC for zero-inflated mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex4.html#hw---simulation-of-poisson-mixture-model",
    "href": "C3-L09-Ex4.html#hw---simulation-of-poisson-mixture-model",
    "title": "87  M5HW4 - BIC for zero-inflated mixtures",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nIn week 2, you considered the problem faced by a biologist is interest in characterizing the number of eggs laid by a particular bird species. The data consisted of a sample n=300 nests on a site in Southern California, which were contained in the file nestsize.csv: data/nestsize.csv\n\nAt the time we visually compared the empirical distribution of the data against a Poison distribution whose parameter has been set to its maximum likelihood estimator as a justification for using a mixture model of the form\n\nf(x) = w \\delta_0(x) + (1-w) \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x \\in \\{0, 1, 2, \\ldots\\}\n\\tag{87.1}\nwhere w is the weight associated with the point mass at zero, \\lambda is the parameter of the Poisson distribution, and \\delta_0(x) represents the degenerate distribution placing all of its mass at zero.\n\nYou are asked to build on the EM algorithm you constructed in week 2 to compute the BIC associated with this model and contrast it against the BIC for the simpler Poisson model.",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>M5HW4 - BIC for zero-inflated mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex4.html#full-conditional-distributions",
    "href": "C3-L09-Ex4.html#full-conditional-distributions",
    "title": "87  M5HW4 - BIC for zero-inflated mixtures",
    "section": "87.2 Full conditional distributions",
    "text": "87.2 Full conditional distributions\nThe full conditional distributions for the indicators of the ZIP model are given by:\n\n\\Pr(c_i = 1 \\mid \\cdots) \\propto \\begin{cases} w & x_i=0 \\\\ 0 & \\mbox{otherwise} \\end{cases}\n\\tag{87.2}\n\n\\Pr(c_i = 2 \\mid \\cdots) \\propto \\begin{cases} (1-w) \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} & x_i=0 \\\\ 1 & \\mbox{otherwise} \\end{cases}\n\\tag{87.3}\nwhere c_i is the latent indicator for observation i, and x_i is the observed data.\nThe full conditional distributions for the weights are given by: \n\\omega \\mid \\cdots \\sim \\mbox{Beta}\\left(m(\\mathbf{c})+1, n-m(\\mathbf{c})+1\\right)\n\\tag{87.4}\nwhere m(\\mathbf{c}) is the number of observations with c_i=1.\nIs the full conditional for the rate \\gamma\n\n\\lambda \\mid \\cdots \\sim \\mbox{Gamma}\\left( 1 + \\sum_{i : c_i = 2} x_i , 1 + n-m(\\mathbf{c}) \\right)\n\\tag{87.5}\nwhere m(\\mathbf{c}) is the number of observations with c_i=2.",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>M5HW4 - BIC for zero-inflated mixtures</span>"
    ]
  },
  {
    "objectID": "C3-L09-Ex4.html#my-solution-code",
    "href": "C3-L09-Ex4.html#my-solution-code",
    "title": "87  M5HW4 - BIC for zero-inflated mixtures",
    "section": "87.3 My Solution code",
    "text": "87.3 My Solution code\nDerive the formula for the BIC associated with the the Poisson model\n\nf(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x \\in \\{0, 1, 2, \\ldots\\}\n\\tag{87.6}\n(Note that you can think about this model as a mixture with a single component).\nThen, provide code to compute the BIC and use it to evaluate it for the dataset nestsize.csv:\n\n\nCode\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\nnestsize &lt;- read.csv(\"data/nestsize.csv\",header=FALSE)\ncolnames(nestsize) &lt;- c(\"n\")\nx &lt;- nestsize$n\nn &lt;- length(x) # Number of observations\nlambdahat = mean(x)\nn = length(x)\ntwicenegloglik = -2*sum(dpois(x,lambdahat,log=TRUE))\nBIC1 = twicenegloglik + log(n) \nBIC1 # 1272.175\n\n\n[1] 1272.175\n\n\n\nL(\\lambda) = \\prod_{i=0}^n \\sum_{k=0}^K \\frac{e^{-\\lambda} \\times \\lambda^x}{x!}\n\n\n\nCode\n## L(\\lambda) = \\prod_{i=0}^n \\sum_{k=0}^K \\frac{e^{-\\lambda} \\times \\lambda^x}{x!}\n\n## Setup controls for the algorithm\ns  = 0\nsw = FALSE\nQQ = -Inf\nQQ.out = NULL\nepsilon = 10^(-5)\n\n## Initiatlize parameters\nw      = 0.1          #Assign equal weight to each component to start with\nlambda = mean(x)      #Random cluster centers randomly spread over the support of the data\n\n## Repeat E and M steps until convergence\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,2))\n  for(i in 1:n){\n    if(x[i]==0){\n      v[i,1] = log(w)    \n      v[i,2] = log(1-w) + dpois(x[i], lambda, log=TRUE)  \n      v[i,]  = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,]))) \n    }else{\n      v[i,1] = 0\n      v[i,2] = 1\n    }\n  }\n  ## M step\n  # Weights\n  w = mean(v[,1])\n  lambda = sum(x)/sum(v[,2])\n\n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    if(x[i]==0){\n      QQn = QQn + v[i,1]*log(w) + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }else{\n      QQn = QQn + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n}\n\n\n[1] \"1 -665.770652745491\"\n[1] \"2 -627.28059416914\"\n[1] \"3 -583.751999411541\"\n[1] \"4 -562.533341454046\"\n[1] \"5 -556.003801253986\"\n[1] \"6 -554.31143569587\"\n[1] \"7 -553.893589555972\"\n[1] \"8 -553.791684738297\"\n[1] \"9 -553.766907034284\"\n[1] \"10 -553.760886876408\"\n[1] \"11 -553.75942443985\"\n\n\nCode\nprint(paste(\"lambda: \",lambda)) #3.07\n\n\n[1] \"lambda:  3.06513670302051\"\n\n\nCode\nprint(paste(\"w: \",w)) #.40\n\n\n[1] \"w:  0.398613010794319\"\n\n\nCode\nprint(paste(\"1-w: \",1-w))\n\n\n[1] \"1-w:  0.601386989205681\"\n\n\nCode\n## Compute twice the negative log-likelihood for the model\ntwicenegloglik = 0\nfor(i in 1:n){\n  if(x[i]==0){\n    twicenegloglik = twicenegloglik - 2*log(w + (1-w)*dpois(x[i], lambda)) # why no log=True here\n    # dpois = e^(-lambda)*  lambda for x =0\n    # log=True would give would be 0 -lambda * log(e) + log(lambda) = log(lambda) - lambda\n\n\n  }else{\n    twicenegloglik = twicenegloglik - 2*( log(1-w) +  dpois(x[i], lambda, log=TRUE))\n  }\n}\n\nBIC2 = twicenegloglik + 2*log(n)\nBIC2 # 1056.85\n\n\n[1] 1056.845\n\n\n\n\nCode\nlibrary(testthat)\ntestthat::test_that(\"Posterior means are correct\", {\n  expect_equal(round(mean(w),2), 0.40)\n  expect_equal(round(mean(lambda),2), 3.07)\n  expect_equal(round(mean(BIC1),2), 1272.18,tolerance = 0.01)\n  expect_equal(round(mean(BIC2),2), 1056.85,tolerance = 0.01)\n  expect_equal(round(mean(BIC1),3), 1272.175)\n  expect_equal(round(mean(BIC2),3), 1056.845)\n})\n\n\nTest passed 🌈",
    "crumbs": [
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>M5HW4 - BIC for zero-inflated mixtures</span>"
    ]
  },
  {
    "objectID": "C4-L00.html",
    "href": "C4-L00.html",
    "title": "88  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "",
    "text": "88.1 Course Card\nI decided to migrate some material that is auxiliary to the course:",
    "crumbs": [
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#course-card",
    "href": "C4-L00.html#course-card",
    "title": "88  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "",
    "text": "Course: Bayesian Statistics: Time Series\nOffered by: University of California, Santa Cruz\nInstructor: Raquel Prado\nCertificate: Yes\nLevel: Graduate\nCommitment: 4 weeks of study, 3-4 hours/week",
    "crumbs": [
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#overview-of-the-course",
    "href": "C4-L00.html#overview-of-the-course",
    "title": "88  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "88.2 Overview of the course",
    "text": "88.2 Overview of the course\nThis course seems very similar to classic basic time series course without the Bayesian part. (AR, MA, ARMA, ARIMA, SARIMA, DLM etc.)\nOne of the questions I had when I started this course was what is the difference between a Bayesian approach to time series analysis and a classical approach. The following is a summary of what I found:\n\n\n\n\n\n\nImportantAre we Being Bayesian ?\n\n\n\nThe Bayesian approach presents primarily in:\n\nSections on Bayesian inference where we do inference on the parameters of the models.\nBayesian prediction unlike an MLE prediction is a distribution of predictions not just a point estimate, and therefore is useful for quantifying uncertainty.\nWe also cover some material on model selection - this again is where the Bayesian approach to optimization presents more powerful tools than the classical approach.\nWhen we want to quantify the uncertainty in our model we have four sources of uncertainty:\n\nUncertainty due to using the correct model (structure).\n\nI consider this is an epistemic uncertainty -\nOne could reduce it by collecting more data, then applying the Bayesian model selection to choose the best model.\n\nUncertainty due to the estimation of the model parameters. This is an epistemic uncertainty - we can reduce it by collecting more data reducing the plausible intervals for these parameters under the bayesian approach.\nUncertainty due to random shocks \\epsilon_t. for the period being predicted. This is an aleatory uncertainty.\nUncertainty in the forecasted values X_{t+h} Items 2-3 can be quantified using a plausible interval in the Bayesian approach and as we predict further into the future the interval will grow.\n\nModel selection is a big part of the Bayesian approach. We can use the DIC, WAIC, and LOO to compare models.\n\n\n\n\nThe book by Professor Prado is very comprehensive and covers plenty of additional models and references lots of recent research. These including VAR, VARMA models, Kalman filters, SMC/Particle filters, etc. These are useful for the continuous control flavours of RL. But you will need to learn it on your own.\nIn the capstone project that is the next course in the specialization the teacher adds another layer of sophistication by introducing mixtures of TS models.\nHowever unlike some courses I took we dive deep enough and get sufficient examples to understand how to put all the bits together into more sophisticated time series models.\n\n\n88.2.1 Mathematical Review\n\nThere is a issues with mathematics most of the results and techniques are so rarely useful that students will soon forget most but a few very useful results. Having a good memory is a great asset in mathematics but is rarely enough. I like to review some mathematical results from my undergraduate days every five years or so. This helps me keep many of the results fresh in my mind and also makes reading new mathematics easier. Fundamentals in mathematics can fo a very long way. This is material from topology, determinants and solving linear equations, numerical methods for decomposing matrices, and so on. Definitions of certain groups.\nOne reason this and other Bayesian courses and books can be challenging and even overwhelming is that they can use lots of mathematics. This can range from high school material like complex numbers and quadratics formulas to intermediate results like finding root of characteristic polynomials, eigenvalues, Topelitz matrices, jordan forms, and advanced topics like the Durbin-Levinson recursion and certain results from functional analysis theory.\n\nNote that I have not even touched on probability and statistics in that list.\nRather than complain I see this as an opportunity to review/learn some mathematics and statistics that can be useful to a data scientist. During my last sting in Data science I often was able to write formulas but more often then not felt that I lacked sufficient mathematical tools to manipulate them to get the kind of results I wanted. Rather then learning lots of mathematics I wanted to find the most practical and useful results for wrangling maths. When I was a physics undergraduate these might be trigonometric identities, completing the square, being familiar with many integrals and Taylor or Maclaurin series approximations and a few useful inequalities occasionally we use l’Hopital’s rule. Familiarity with some ODEs was also greatly beneficial as these come up in many physical models. Later on hermitian and unitary matrices, fourier expansions, spectral theory, and some results from functional analysis were useful.\nFor statistics we have the variants of the law of large numbers and the central limit theorem, convergence theorems, manipulations of the normal distribution, linear properties of expectation can get you along way. But you have to remember lots of definitions and there are lots of results and theorems that seem to be stepping stones to other results rather than any practical use.\nOn the other hand conjugacy of certain distributions as demonstrated by Herbert Lee and other instructors in this specialization are often very challenging. Charts of Convergence of distributions to other distributions under certain conditions are neat but. There is Hoeffding’s inequality and the Markov’s inequality which can be useful but like most results in mathematics I never had a where they might be used. Then there are certain results - convergence of Markov chains, doubly stochastic matrices. De Finetti’s theorem in statistics.\nI have found that the more I learn the more I can understand and appreciate the material.\n\nThe autoregressive process gives rise to Toeplitz matrices which can be solved using the Durbin-Levinson recursion mentioned many times in the course.\nDurbin-Levinson recursion - is an advanced topic not covered in Numerical Analysis courses or Algebra courses I took.\nTo use it with time series we also need to understand the Yule-Walker equations.\nar(p) require some linear algebra concepts like eigenvalues and Eigenvectors, and characteristic polynomials.\nThe AR(p) the Wold decomposition theorem to get to the infinite order moving average representation and this is not a result I recall learning in my functional analysis course. We also use some complex numbers and Fourier analysis and spectral density functions.\n\nSummarize some of the extra curricular material I found useful in the course.\n\nComplex numbers\nEigenvalues, Eigenvectors and characteristic polynomials\nDurbin-Levinson recursion\nYule-Walker equations\nWiener process (Random walk)\nBrownian motion (Continuous Random walk with drift)\nMarkov Chains ()\nMartingales ()\nStopping theorem\nKalman filter\nWold’s theorem\nDe Finetti’s theorem\nCholesky decomposition\n\n\n\n88.2.2 Complex Numbers (Review)\nWhen we wish to find the roots of real valued polynomials we will often encounter complex numbers. In this course such polynomials arise naturally in the characteristic polynomials of AR(p) processes.\nWe will need the polar form of complex numbers to represent some variants of AR(p) process.\nThe numbers in the Complex field z \\in \\mathbb{C} numbers are numbers that can be expressed in the form z = a + bi, where a,b\\in\\mathbb{R} and i is the imaginary unit. The imaginary unit i is defined as the square root of -1. Complex numbers can be added, subtracted, multiplied, and divided just like real numbers.\nThe complex conjugate  of a complex number z = a + bi is denoted by \\bar{z} = a - bi. The magnitude of a complex number z = a + bi is denoted by |z| = \\sqrt{a^2 + b^2}. This is sometimes called the modulus of the complex number in this course. The argument of a complex number z = a + bi is denoted by \\text{arg}(z) = \\tan^{-1}(b/a). The polar form of a complex number is given by z = r e^{i \\theta}, where r = |z| and \\theta = \\text{arg}(z).complex conjugate\nThe polar form of a complex number is given by:\n\n\\begin{aligned}\nz &= \\mid z\\mid e^{i \\theta} \\\\\n  &= r (\\cos(\\theta) + i \\sin(\\theta))\n\\end{aligned}\n\\tag{88.1}\nwhere:\n\n|z| is the magnitude of the complex number, i.e. the distance from the origin to the point in the complex plane.\n\\theta is the angle of the complex number.\n\nI think we will also need the unit roots.\n\n\n88.2.3 Eigenvalues, Eigenvectors the characteristic polynomials and Unit roots\nThe Eigenvalues of a matrix are the roots of the characteristic polynomial of the matrix. The characteristic polynomial of a matrix A is defined as:\n\n\\begin{aligned}\n\\text{det}(A - \\lambda I) = 0\n\\end{aligned}\n\nwhere \\lambda is the Eigenvalue and I is the identity matrix. The eigenvectors of a matrix are the vectors that satisfy the equation:\n\n\\begin{aligned}\nA v = \\lambda v\n\\end{aligned}\n\nwhere v is the eigenvector and \\lambda is the eigenvalue. The eigenvalues and eigenvectors of a matrix are used in many applications in mathematics and physics, including the diagonalization of matrices, the solution of differential equations, and the analysis of dynamical systems.\n\n88.2.3.1 Unit Roots\nA unit root is a root of the characteristic polynomial of an autoregressive model that is equal to 1. The presence of a unit root in an autoregressive model indicates that the model is not stationary. The unit root test is a statistical test that is used to determine whether a time series is stationary or non-stationary. The unit root test is based on the null hypothesis that the time series has a unit root, and the alternative hypothesis that the time series is stationary. The unit root test is used to determine whether a time series is stationary or non-stationary, and is an important tool in time series analysis.\n\n\n\n88.2.4 Spectral analysis (1898)\nThe power spectrum of a signal is the squared absolute value of its Fourier transform. If it is estimated from the discrete Fourier transform it is also called periodogram. Usually estimated using the a fast Fourier transform (FFT) algorithm.\n\n\n88.2.5 Yule-Walker Equations (1932)\n\n\n88.2.6 Durbin-Levinson recursion (Off-Course Reading)\nLike me, you might be curious about the Durbin-Levinson recursion mentioned above. This is not covered in the course, and turned out to be an enigma wrapped in a mystery.\nI present my finding in the note below - much of it is due to (Wikipedia contributors 2024b) and (Wikipedia contributors 2024a)\nIn (Yule 1927) and (Walker 1931), Yule and Walker proposed a method for estimating the parameters of an autoregressive model. The method is based on the Yule-Walker equations which are a set of linear equations that can be used to estimate the parameters of an autoregressive model.\nDue to the autoregressive nature of the model, the equations are take a special form called a Toeplitz matrix. However at the time they probably had to use the numerically unstable Gauss-Jordan elimination to solve these equations which is O(n^3) in time complexity.\nA decade or two later in (Levinson 1946) and (Durbin 1960) the authors came up for with a weakly stable yet more efficient algorithm for solving these autocorrelated system of equations which requires only O(n^2) in time complexity. Later their work was further refined in (Trench 1964) and (Zohar 1969) to just 3\\times n^2 multiplication. A cursory search reveals that Toeplitz matrix inversion is still an area of active research with papers covering parallel algorithms and stability studies. Not surprising as man of the more interesting deep learning models, including LLMs are autoregressive.\nSo the Durbin-Levinson recursion is just an elegant bit of linear algebra for solving the Yule-Walker equations more efficiently.\nHere is what I dug up:\n\n\n88.2.7 Durbin-Levinson and the Yule-Walker equations (Off-Course Reading)\nThe Durbin-Levinson recursion is a method in linear algebra for computing the solution to an equation involving a Toeplitz matrix AKA a diagonal-constant matrix where descending diagonals are constant. The recursion runs in O(n^2) time rather then O(n^3) time required by Gauss-Jordan elimination.\nThe recursion can be used to compute the coefficients of the autoregressive model of a stationary time series. It is based on the Yule-Walker equations and is used to compute the PACF of a time series.\nThe Yule-Walker equations can be stated as follows for an AR(p) process:\n\n\\gamma_m = \\sum_{k=1}^p \\phi_k \\gamma_{m-k} + \\sigma_\\epsilon^2\\delta_{m,0} \\qquad \\text{(Yule-Walker equations)}\n\\tag{88.2}\nwhere:\n\n\\gamma_m is the autocovariance function of the time series,\n\\phi_k are the AR coefficients,\n\\sigma_\\epsilon^2 is the variance of the white noise process, and\n\\delta_{m,0} is the Kronecker delta function.\n\nwhen m=0 the equation simplifies to:\n\n\\gamma_0 = \\sum_{k=1}^p \\phi_k \\gamma_{-k} + \\sigma_\\epsilon^2 \\qquad \\text{(Yule-Walker equations for m=0)}\n\\tag{88.3}\nfor m &gt; 0 the equation simplifies to:\n \\begin{bmatrix}\n    \\gamma_1 \\newline\n    \\gamma_2 \\newline\n    \\gamma_3 \\newline\n    \\vdots \\newline\n    \\gamma_p \\newline\n\\end{bmatrix} =  \\begin{bmatrix}\n    \\gamma_0     & \\gamma_{-1}  & \\gamma_{-2}  & \\cdots \\newline\n    \\gamma_1     & \\gamma_0     & \\gamma_{-1}  & \\cdots \\newline\n    \\gamma_2     & \\gamma_1     & \\gamma_0     & \\cdots \\newline\n    \\vdots       & \\vdots       & \\vdots       & \\ddots \\newline\n    \\gamma_{p-1} & \\gamma_{p-2} & \\gamma_{p-3} & \\cdots \\newline\n\\end{bmatrix}  \\begin{bmatrix}\n    \\phi_{1} \\newline\n    \\phi_{2} \\newline\n    \\phi_{3} \\newline\n    \\vdots \\newline\n    \\phi_{p} \\newline\n\\end{bmatrix}\n\nand since this matrix is Toeplitz, we can use Durbin-Levinson recursion to efficiently solve the system for \\phi_k \\forall k.\nOnce \\{\\phi_m ; m=1,2, \\dots ,p \\} are known, we can consider m=0 and solved for \\sigma_\\epsilon^2 by substituting the \\phi_k into Equation 88.3 Yule-Walker equations.\nOf course the Durbin-Levinson recursion is not the last word on solving this system of equations. There are today numerous improvements which are both faster and more numerically stable.\nThe Yule-Walker equations are a set of p linear equations in the p unknowns \\phi_1, \\phi_2, \\ldots, \\phi_p that can be used to estimate the parameters of an autoregressive model of order p. The Yule-Walker equations are derived by setting the sample autocorrelation function equal to the theoretical autocorrelation function of an AR(p) model and then solving for the unknown parameters. The Yule-Walker equations are given by:\n\n\\begin{aligned}\n\\gamma(0) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(2) + \\ldots + \\phi_p \\gamma(p) \\\\\n\\gamma(1) & = \\phi_1 \\gamma(0) + \\phi_2 \\gamma(1) + \\ldots + \\phi_p \\gamma(p-1) \\\\\n\\gamma(2) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(0) + \\ldots + \\phi_p \\gamma(p-2) \\\\\n\\vdots \\\\\n\\gamma(p) & = \\phi_1 \\gamma(p-1) + \\phi_2 \\gamma(p-2) + \\ldots + \\phi_p \\gamma(0) \\\\\n\\end{aligned}\n\nwhere \\gamma(k) is the sample autocorrelation function at lag k. The Yule-Walker equations can be solved using matrix algebra to obtain the estimates of the AR parameters \\phi_1, \\phi_2, \\ldots, \\phi_p.\n\n\n88.2.8 Wold’s theorem - (extra curricular) circa 1939\nIn the 1920 Yule and Eugen Slutsky were researching time series and they came up with two different ways to represent a time series.\n\nYule’s researches led to the notion of the autoregressive scheme. \n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t}\n\\end{aligned}\n\\tag{88.4}\nSlutsky’s researches led to the notion of a moving average scheme. \n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{88.5}\n\nwe can use the two schemes together and get the ARMA(p,q) model:\n\n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t} + \\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{88.6}\nwhere:\nThe following is extracted from: the wikipedia at https://en.wikipedia.org/wiki/Wold%27s_theorem\nWold’s decomposition AKA called the Wold representation theorem states that:\n\nEvery covariance-stationary time series Y_{t} can be written as the sum of two time series, one deterministic and one stochastic.\n\nFormally:\n\n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{\\infty }  \\underbrace{b_{j}\\epsilon _{t-j}}_{\\text{stochastic}} + \\underbrace{\\eta _{t}}_{\\text{deterministic}} \\\\\n&= \\sum _{j=0}^{\\infty } b_{j}\\epsilon _{t-j} + \\phi_{j} y_{t-j}\n\\end{aligned}\n\nwhere:\n\n{Y_{t}} is the time series being considered,\n{\\epsilon _{t}} is an white noise sequence called innovation process that acts as an input to the linear filter {\\{b_{j}\\}}.\n{b} is the possibly infinite vector of moving average weights (coefficients or parameters)\n{\\eta _{t}} is a “deterministic” time series, in the sense that it is completely determined as a linear combination of its past values It may include “deterministic terms” like sine/cosine waves of {t}, but it is a stochastic process and it is also covariance-stationary, it cannot be an arbitrary deterministic process that violates stationarity.\n\nThe moving average coefficients have these properties:\n\nStable, that is, square summable \\sum _{j=1}^{\\infty } \\mid b_{j}|^{2} &lt; \\infty\nCausal (i.e. there are no terms with j &lt; 0)\nMinimum delay\nConstant (b_j independent of t)\nIt is conventional to define b_0=1\n\nAny stationary process has this seemingly special representation. Not only is the existence of such a simple linear and exact representation remarkable, but even more so is the special nature of the moving average model.\nThis result is used without stating its name in the course when we are show the AR(p) representation in terms of moving averages.",
    "crumbs": [
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#kalman-filter-1960",
    "href": "C4-L00.html#kalman-filter-1960",
    "title": "88  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "88.3 Kalman Filter (1960)",
    "text": "88.3 Kalman Filter (1960)\n\n\\begin{aligned}\nx_{t} & = F_{t} x_{t-1} + G_{t} u_{t} + w_{t} && \\text{(transition equation)} \\\\\ny_{t} & = H_{t} x_{t} + v_{t} && \\text{(observation equation)}\n\\end{aligned}\n\\tag{88.7}\nwhere:\n\nx_{t} is the state vector at time t,\nF_{t} is the state transition matrix,\nG_{t} is the control input matrix,\nu_{t} is the control vector,\nw_{t} is the process noise vector,\ny_{t} is the observation vector at time t,\nH_{t} is the observation matrix,\nv_{t} is the observation noise vector.\n\nThe Kalman filter is a recursive algorithm that estimates the state of a linear dynamic system from a series of noisy observations. The Kalman filter is based on a linear dynamical system model that is defined by two equations: the state transition equation and the observation equation. The state transition equation describes how the state of the system evolves over time, while the observation equation describes how the observations are generated from the state of the system. The Kalman filter uses these two equations to estimate the state of the system at each time step, based on the observations received up to that time step. This could be implemented in real time in the 1960s and was used in the Apollo missions.\nThe Extended Kalman Filter (EKF) is an extension of the Kalman filter that can be used to estimate the state of a nonlinear dynamic system. The EKF linearizes the nonlinear system model at each time step and then applies the Kalman filter to the linearized system. The EKF is an approximation to the true nonlinear system, and its accuracy depends on how well the linearized system approximates the true system.\n\n88.3.1 Box Jenkins Method (1970)\nsee Box Jenkins Method\nA five step process for identifying, selecting and assessing ARMA (and similar) models.\n\nThere are three courses on Stochastic Processes on MIT OCW that I found useful:\n\nIntroduction to Stochastic Processes\nDiscrete Stochastic Processes\nhas lecture videos and notes\npoisson processes\nAdvanced Stochastic Processes\nmartingales\nito calculus",
    "crumbs": [
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#bayesian-time-series-bibliography",
    "href": "C4-L00.html#bayesian-time-series-bibliography",
    "title": "88  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "88.4 Bayesian Time Series Bibliography",
    "text": "88.4 Bayesian Time Series Bibliography\nWe start with some books from the course, I collected here both the recommended books and some others that I found useful.\n\n88.4.1 Time Series: Modeling, Computation, and Inference\nc.f. (Prado, Ferreira, and West 2023)\n\n\n\n\nTime Series: Modeling, Computation, and Inference\n\n\nTitle:Time Series: Modeling, Computation, and Inference\nISBN:9781032040042, 1032040041\nPage count:452\nPublished:September 2023\nFormat:Paperback\nPublisher:CRC Press\nAuthors: Raquel Prado, Marco A. R. Ferreira, Mike West\n\n(Prado, Ferreira, and West 2023) “Time Series: Modeling, Computation, and Inference” by course instructor Raquel Prado. This book, now in its second edition is a comprehensive introduction to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nWhile learning this course I found some of the material harder to follow than I expected. The books helped to clarify definitions and so on however the book is\nrather comprehensive and mathematically advanced unlike some other books on statistics.\nThe teacher frequently point out that many aspects of Times series and are beyond the scope of the course. Yet this book covers much more ground like unequally spaced time series and vector valued time series.\nFor example we look at EKG data which the authors have been working on for years. However we look at it in this course in terms of a univariate time series while in reality EKG is usually sampled at 12 sites simultaneously yielding a multi-variate time series.\nOnce this course is done I will probably want to dive deeper into the subject and try to devote more time to other models in the book.\n\n\n\n88.4.2 Bayesian Forecasting and Dynamic Models\nc.f. (West and Harrison 2013)\n\n\n\n\nBayesian Forecasting and Dynamic Models\n\n\nTitle:Bayesian Forecasting and Dynamic Models\nISBN:9781475770971, 1475770979\nPage count:682\nPublished:March 17, 2013\nFormat:Paperback\nPublisher:Springer New York\nAuthor:Mike West, Jeff Harrison\n\n(West and Harrison 2013) “Bayesian Forecasting and Dynamic Models” by Mike West and Jeff Harrison. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian forecasting and dynamic models. The following is the description from the publisher:\n\nThe use of dynamic models in the forecasting of time series data has a long history, with the development of autoregressive integrated moving average (ARIMA) models and state space models. However, the use of Bayesian methods in the development of dynamic models is a relatively recent development. This book provides a comprehensive introduction to the use of Bayesian methods in the development of dynamic models for forecasting time series data. The book covers a wide range of topics, including the use of dynamic models in the analysis of time series data, the use of Bayesian methods in the development of dynamic models, and the use of dynamic models in the forecasting of time series data.\n\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n\n\n\n88.4.3 Practical Time Series Analysis\nc.f. (Nielsen 2019)\n\n\n\n\nPractical Times Series Analysis\n\n\nTitle:Practical Time Series Analysis: Prediction with Statistics and Machine Learning\nISBN:1492041602, 9781492041603\nPage count:504\nPublished:2019\nFormat:Paperback\nPublisher:O’Reilly Media, Inc.\n(Nielsen 2019) “Practical Time Series Analysis: Prediction with Statistics and Machine Learning” by Aileen Nielsen. Is a good resource for parctionars getting started with time series analysis. I also recommend any videos by Aileen Nielsen on the subject.\n\n\nPractical Times Series Analysis by Aileen Nielsen is a good book for beginners. It is a practical guide to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for beginners in statistics, computer science, and related fields.\nTime series data analysis is increasingly important due to the massive production of such data through the internet of things, the digitalization of healthcare, and the rise of smart cities. As continuous monitoring and data collection become more common, the need for competent time series analysis with both statistical and machine learning techniques will increase.\nCovering innovations in time series data analysis and use cases from the real world, this practical guide will help you solve the most common data engineering and analysis challenges in time series, using both traditional statistical and modern machine learning techniques. Author Aileen Nielsen offers an accessible, well-rounded introduction to time series in both R and Python that will have data scientists, software engineers, and researchers up and running quickly.\nYou’ll get the guidance you need to confidently:\n\nFind and wrangle time series data\nUndertake exploratory time series data analysis\nStore temporal data\nSimulate time series data\nGenerate and select features for a time series\nMeasure error\nForecast and classify time series with machine or deep learning\nEvaluate accuracy and performance\n\n\n\n\n88.4.3.1 “Machine Learning: A Bayesian and Optimization Perspective” by Sergios Theodoridis.\nc.f. (Theodoridis 2015)\n\n\n\n\nMachine Learning: A Bayesian and Optimization Perspective\n\n\nTitle:Machine Learning: A Bayesian and Optimization Perspective\nISBN:0128015225, 9780128015223\nPage count:1062\nPublished:2015\nFormat:Hardcover\nPublisher:Academic Press\nAuthors: Sergios Theodoridis\n\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks like a good book on machine learning. The following is the description from the publisher:\n\nThis tutorial text gives a unifying perspective on machine learning by covering both probabilistic and deterministic approaches -which are based on optimization techniques - together with the Bayesian inference approach, whose essence lies in the use of a hierarchy of probabilistic models. The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts.\nThe book builds carefully from the basic classical methods to the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models.\n\nAll major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods.\nThe latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling.\nCase studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied.\nMATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code.\n\n\n\n\n\n88.4.3.2 Statistical Analysis in Climate Research\nc.f.(Storch and Zwiers 2002)\n\n\n\n\nStatistical Analysis in Climate Research\n\n\nTitle:Statistical Analysis in Climate Research\nISBN:1139425099, 9781139425094\nPage count:484\nPublished:2002\nFormat:Paperback\nPublisher:Cambridge University Press\nAuthors: Hans von Storch, Francis W. Zwiers\n\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks promising. Here is the description from the publisher:\n\nClimatology is, to a large degree, the study of the statistics of our climate. The powerful tools of mathematical statistics therefore find wide application in climatological research. The purpose of this book is to help the climatologist understand the basic precepts of the statistician’s art and to provide some of the background needed to apply statistical methodology correctly and usefully. The book is self contained: introductory material, standard advanced techniques, and the specialised techniques used specifically by climatologists are all contained within this one source. There are a wealth of real-world examples drawn from the climate literature to demonstrate the need, power and pitfalls of statistical analysis in climate research. Suitable for graduate courses on statistics for climatic, atmospheric and oceanic science, this book will also be valuable as a reference source for researchers in climatology, meteorology, atmospheric science, and oceanography.\n\nHans von Storch is Director of the Institute of Hydrophysics of the GKSS Research Centre in Geesthacht, Germany and a Professor at the Meteorological Institute of the University of Hamburg.\nFrancis W. Zwiers is Chief of the Canadian Centre for Climate Modelling and Analysis, Atmospheric Environment Service, Victoria, Canada, and an Adjunct Professor at the Department of Mathematicw and Statistics of the University of Victoria.\n\n\n\n\n\n\n88.4.4 Bayesian Modeling and Computation in Python\nc.f. (Martin, Kumar, and Lao 2021)\n\n\n\n\nBayesian Modeling and Computation in Python\n\nThis is a great resource for translating what we learned to Python. The book is available at Bayesian Modeling and Computation in Python\nI found the chapter on state space modeling and the Kalman filter particularly useful. The book is a great resource for translating what we learned in the course to Python. The book is suitable for undergraduate students in statistics, computer science, and related fields.\n\n\n\n88.4.5 Bayesian Data Analysis\nc.f. (Gelman et al. 2013)\n\n\n\n\nBayesian Data Analysis\n\n\nTitle:Bayesian Data Analysis\nISBN:1439840954, 9781439840955\nPage count:675\nPublished:2013\nFormat:Hardcover\nPublisher:Chapman and Hall/CRC\nAuthors: Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, Donald B. Rubin\n\n(Gelman et al. 2013) “Bayesian Data Analysis” is probably the most famous book on Bayesian statistics. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian data analysis. Although this is not a time series book, the authors have been intersted in the domain of political election prediction and have used time series data in their research and some of that is covered in the book’s examples.\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nAn electronic version of the third eddition book is available at Bayesian Data Analysis\n\n\n\n\n88.4.6 Introductory Time Series with R c.f. (Cowpertwait and Metcalfe 2009)\n\n\n\n\nIntroductory Time Series with R\n\n(Cowpertwait and Metcalfe 2009) “Introductory Time Series with R” by Cowpertwait and Metcalfe, and the second is\n\nYearly global mean temperature and ocean levels, daily share prices, and the signals transmitted back to Earth by the Voyager space craft are all examples of sequential observations over time known as time series. This book gives you a step-by-step introduction to analysing time series using the open source software R. Each time series model is motivated with practical applications, and is defined in mathematical notation. Once the model has been introduced it is used to generate synthetic data, using R code, and these generated data are then used to estimate its parameters. This sequence enhances understanding of both the time series model and the R function used to fit the model to data. Finally, the model is used to analyse observed data taken from a practical application. By using R, the whole procedure can be reproduced by the reader.\nAll the data sets used in the book are available on the website at datasets\nThe book is written for undergraduate students of mathematics, economics, business and finance, geography, engineering and related disciplines, and postgraduate students who may need to analyse time series as part of their taught programme or their research.\n\nPaul Cowpertwait is an associate professor in mathematical sciences (analytics) at Auckland University of Technology with a substantial research record in both the theory and applications of time series and stochastic models.\nAndrew Metcalfe is an associate professor in the School of Mathematical Sciences at the University of Adelaide, and an author of six statistics text books and numerous research papers. Both authors have extensive experience of teaching time series to students at all levels.\n\n\n\n\n\n88.4.7 Analysis of Integrated and Cointegrated Time Series with R c.f.\n\n\n\n\nAnalysis of Integrated and Cointegrated Time Series with R\n\n(Pfaff 2008) “Analysis of Integrated and Cointegrated Time Series with R” by Bernhard Pfaff. Its been a long time since I read this book and rather than do it an injustice I direct you to the review by Dirk Eddelbuettel in the Journal of Statistical Software is avaoilable at review. Or the book’s website at Analysis of Integrated and Cointegrated Time Series with R.\n\nThe analysis of integrated and co-integrated time series can be considered as the main methodology employed in applied econometrics. This book not only introduces the reader to this topic but enables him to conduct the various unit root tests and co-integration methods on his own by utilizing the free statistical programming environment R. The book encompasses seasonal unit roots, fractional integration, coping with structural breaks, and multivariate time series models. The book is enriched by numerous programming examples to artificial and real data so that it is ideally suited as an accompanying text book to computer lab classes.\nThe second edition adds a discussion of vector auto-regressive, structural vector auto-regressive, and structural vector error-correction models.\n\n\n\n88.4.8 Bayesian Analysis of Time Series by Lyle D. Broemeling\n(Broemeling 2019)\n\ncovers pretty much the material in the course.\nuses winbugs and R\nmodels considered include\n\nwhite noise\nWiener process (random walk)\nAR(p)\nARMA(p,q)\nARIMA\nRegression\nRegression with MA and Seasonal effects\nDLM\nTAR\n\n\n\n\n88.4.9 Bayesian Inference for Stochastic Processes by Lyle D. Broemeling\n\n\n\n\nBayesian Inference for Stochastic Processes by Lyle D. Broemeling\n\n\nThe code for R and WinBUGS is available at code\nIT is based on WinBUGS which is a bit dated but still useful.\nThis books seems a bit dated but it covers a lot of the material in the course.\n\n\n\n88.4.10 Dynamic Time Series Models using R-INLA: An Applied Perspective\n(Ravishanker, Raman, and Soyer 2022) is a new book that covers the use of the R-INLA package for fitting dynamic time series models. The book is available online gitbook\n\n\n\n\nDynamic Time Series Models using R-INLA: An Applied Perspective\n\nThis is a very interesting book which covers a new approach to fitting time series models using the R-INLA package. INLA stands for Integrated Nested Laplace Approximation and is a method for fitting Bayesian models that is faster than MCMC. The book covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n88.4.11 Statistics for Spatio-Temporal Data\n\n\n\n\nStatistics for Spatio-Temporal Data\n\n(Cressie and Wikle 2011) is a book I came across when I tried to understand the NDLM model. NLDMs have a two level hierarcial form and it seems possible to extend this formulation will non-normaly distributed shocks and possibly non linear relation. In this book the authors take an interesting approch of not only looking at NDLM as a heirarchical model but they also extend the time series model into a spatio-temporal model.\nThis book is a comprehensive introduction to the analysis of spatio-temporal data and covers a wide range of topics in spatio-temporal statistics. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.",
    "crumbs": [
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L00.html#bayesian-analysis-of-stochastic-process-models",
    "href": "C4-L00.html#bayesian-analysis-of-stochastic-process-models",
    "title": "88  Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "88.5 Bayesian Analysis of Stochastic Process Models",
    "text": "88.5 Bayesian Analysis of Stochastic Process Models\nc.f. (Rios Insua, Ruggeri, and Wiper 2012)\n\n\n\n\nBayesian Analysis of Stochastic Process Models\n\nDavid Rios Insua, Fabrizio Ruggeri, Michael P. Wiper\nThis book is a comprehensive introduction to the analysis of stochastic process models using Bayesian methods. The book covers a wide range of topics in stochastic process modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nThere are also a number of books on NDLM that I’ve come accross:\n\nDynamic linear model tutorial matlab\nForecasting, structural time series and the Kalman filter by Andrew C. Harvey\nDynamic Linear Models with R by Giovanni Petris Sonia Petrone Patrizia Campagnoli\nTime Series Analysis by State Space Methods by J. Durbin and S.J. Koopman\n\n\n\n\n\n\n\nBroemeling, Lyle D. 2019. Bayesian Analysis of Time Series. CRC Press.\n\n\nCowpertwait, P. S. P., and A. V. Metcalfe. 2009. Introductory Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=QFiZGQmvRUQC.\n\n\nCressie, N., and C. K. Wikle. 2011. Statistics for Spatio-Temporal Data. CourseSmart Series. Wiley. https://books.google.co.il/books?id=-kOC6D0DiNYC.\n\n\nDurbin, J. 1960. “The Fitting of Time-Series Models.” Revue de l’Institut International de Statistique / Review of the International Statistical Institute 28 (3): 233–44. http://www.jstor.org/stable/1401322.\n\n\nGelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. Bayesian Data Analysis, Third Edition. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis. https://books.google.co.il/books?id=ZXL6AQAAQBAJ.\n\n\nLevinson, Norman. 1946. “The Wiener (Root Mean Square) Error Criterion in Filter Design and Prediction.” Journal of Mathematics and Physics 25 (1-4): 261–78. https://doi.org/https://doi.org/10.1002/sapm1946251261.\n\n\nMartin, Osvaldo A., Ravin Kumar, and Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. Boca Raton.\n\n\nNielsen, A. 2019. Practical Time Series Analysis: Prediction with Statistics and Machine Learning. O’Reilly Media. https://books.google.co.il/books?id=xNOwDwAAQBAJ.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=ca5MkRbF3fYC.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nRavishanker, N., B. Raman, and R. Soyer. 2022. Dynamic Time Series Models Using r-INLA: An Applied Perspective. CRC Press. https://books.google.co.il/books?id=e6h6EAAAQBAJ.\n\n\nRios Insua, David, Fabrizio Ruggeri, and Michael P Wiper. 2012. Bayesian Analysis of Stochastic Process Models. John Wiley & Sons.\n\n\nStorch, H. von, and F. W. Zwiers. 2002. Statistical Analysis in Climate Research. Cambridge University Press. https://books.google.co.il/books?id=bs8hAwAAQBAJ.\n\n\nTheodoridis, S. 2015. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science. https://books.google.co.il/books?id=hxQRogEACAAJ.\n\n\nTrench, William F. 1964. “An Algorithm for the Inversion of Finite Toeplitz Matrices.” Journal of the Society for Industrial and Applied Mathematics 12 (3): 515–22. http://ramanujan.math.trinity.edu/wtrench/research/papers/TRENCH_RP_6.PDF.\n\n\nWalker, Gilbert Thomas. 1931. “On Periodicity in Series of Related Terms.” Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character 131 (818): 518–32. https://doi.org/10.1098/rspa.1931.0069.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.\n\n\nWikipedia contributors. 2024a. “Autoregressive Model — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Autoregressive_model&oldid=1233171855#Estimation_of_AR_parameters.\n\n\n———. 2024b. “Levinson Recursion — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Levinson_recursion&oldid=1229942891.\n\n\nYule, George Udny. 1927. “VII. On a Method of Investigating Periodicities Disturbed Series, with Special Reference to Wolfer’s Sunspot Numbers.” Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character 226 (636-646): 267–98. https://doi.org/10.1098/rsta.1927.0007.\n\n\nZohar, Shalhav. 1969. “Toeplitz Matrix Inversion: The Algorithm of w. F. Trench.” J. ACM 16: 592–601. https://api.semanticscholar.org/CorpusID:3115290.",
    "crumbs": [
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Week 0: Introductions to time series analysis and the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html",
    "href": "C4-L01.html",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "",
    "text": "90 Week 1: Introduction to Time Series and the AR(1) process",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#introduction",
    "href": "C4-L01.html#introduction",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "90.1 Introduction",
    "text": "90.1 Introduction\n\n90.1.1 Welcome to Bayesian Statistics: Time Series\n\nObligatory introduction to the course and the instructors.\nRaquel Prado is a professor of statistics in the Baskin School of Engineering at the University of California, Santa Cruz. She was the recipient 2022 Zellner Medal, see Weckerle (2022).\n\n\n\n90.1.2 Introduction to R\n\nIntroduction to R",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#stationarity-the-acf-and-the-pacf",
    "href": "C4-L01.html#stationarity-the-acf-and-the-pacf",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "90.2 Stationarity the ACF and the PACF",
    "text": "90.2 Stationarity the ACF and the PACF\nBefore diving into the material here is a brief overview of the notations for timer series.\n\n\n\n\n\n\nTip 90.1: Notation\n\n\n\n\n\\{y_t\\} - the time series process, where each y_t is a univariate random variable and t are the time points that are equally spaced.\ny_{1:T} or y_1, y_2, \\ldots, y_T - the observed data.\nYou will see the use of ’ to denote the transpose of a matrix,\nand the use of \\sim to denote a distribution.\nunder tildes \\utilde{y} are used to denote estimates of the true values y.\nE matrix of eigenvalues\n\\Lambda = diagonal(\\alpha_1, \\alpha_2, \\ldots , \\alpha_p) is a diagonal matrix with the eigenvalues of \\Sigma on the diagonal.\nJ_p(1) = a p by p Jordan form matrix with 1 on the super-diagonal\n\nalso see (Prado, Ferreira, and West 2023, 2–3)\n\n\n\n90.2.1 Stationarity (video)\n\n\n\n\nstrong and weak stationarity\n\nStationarity c.f. (Prado, Ferreira, and West 2023, sec. 1.2) is a fundamental concept in time series analysis.\n\n\n\n\n\n\nImportantTL;DR – Stationarity\n\n\n\n\nStationarity\n\n\n\n\nA time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.\n\n\n\nWe make this definition more formal in the definitions of strong and weak stationarity below.\n\n\n\nStationarityStationarity is a key concept in time series analysis. A time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.\n\nDefinition 90.1 (Strong Stationarity)  Let y_t be a time series. We say that y_t is stationary if the following conditions hold:Strong Stationarity\nLet \\{y_t\\} \\quad \\forall n&gt;0 be a time series and h &gt; 0 be a lag. If for any subsequence the distribution of y_t, y_{t+1}, \\ldots, y_{t+n} is the same as the distribution of y_{t+h}, y_{t+h+1}, \\ldots, y_{t+h+n} we call the series strongly stationary.\n\nAs it’s difficult to verify strong stationarity in practice, we will often use the following weaker notion of stationarity.\n\nDefinition 90.2 (Weak Stationarity)   The mean, variance, and auto-covariance are constant over time.Weak StationaritySecond-order Stationarity\n\n\\begin{aligned}\n\\mathbb{E}[y_t] &= \\mu \\quad \\forall t \\\\\n\\mathbb{V}ar[y_t] &= \\nu =\\sigma^2 \\quad \\forall t \\\\\n\\mathbb{C}ov[y_t , y_s ] &= γ(t − s)\n\\end{aligned}\n\\tag{90.1}\n\n\nStrong stationarity \\implies Weak stationarity, but\nThe converse is not true.\nIn this course when we deal with a Gaussian process, our typical use case, they are equivalent!\n\n\n\n\n\n\n\nCautionCheck your understanding\n\n\n\nQ. Can you explain with an example when a time series is weakly stationary but not strongly stationary?\n\n\n\n\n90.2.2 The auto-correlation function ACF (video)\n\n\n\n\nThe auto-correlation function ACF\n\nThe autocorrelation is simply how correlated a time series is with itself at different lags.\n\nCorrelation in general is defined in terms of covariance of two variables.\nThe covariance is a measure of the joint variability of two random variables.\n\n\n\n\n\n\n\nImportant\n\n\n\nRecall that the Covariance between two random variables y_t and y_s is defined as:\n\n\\begin{aligned}\n\\mathbb{C}ov[y_t, y_s] &= \\mathbb{E}[(y_t-\\mathbb{E}[y_t])(y_s-\\mathbb{E}[y_s])] \\\\\n              &= \\mathbb{E}[(y_t-\\mu_t)(y_s-\\mu_s)] \\\\\n              &= E[y_t y_s] - \\mu_t \\times \\mu_s\n\\end{aligned} \\qquad\n\\tag{90.2}\nWe get the second line by substituting \\mu_t = \\mathbb{E}(y_t) and \\mu_s = \\mathbb{E}(y_s) using the definition of the mean of a RV. the third line is by multiplying out and using the linearity of the expectation operator.\n\n\n\n\n\n\n\n\nTip 90.2: AFC notation\n\n\n\nWe will frequently use the notation \\gamma(h) to denote the autocovariance for a lag h i.e. between y_t and y_{t+h}\n\n\\gamma(h) = \\mathbb{C}ov[y_t, y_{t+h}] \\qquad\n\\tag{90.3}\n\n\nWhen the time series is stationary, then the covariance only depends on the lag h = |t-s| and we can write the covariance as \\gamma(h).\nLet \\{y_t\\} be a time series. Recall that the covariance between two random variables y_t and y_s is defined as:\n\n\\gamma(t,s)=\\mathbb{C}ov[y_t, y_s] = \\mathbb{E}[(y_t-\\mu_t)(y_s-\\mu_s)] \\qquad\n\\tag{90.4}\nwhere \\mu_t = \\mathbb{E}(y_t) and \\mu_s = \\mathbb{E}(y_s) are the means of y_t and y_s respectively.\n\n\\mu_t = \\mathbb{E}(y_t) \\qquad \\mu_s = \\mathbb{E}(y_s)\n\\tag{90.5}\n\n\\text{Stationarity} \\implies \\mathbb{E}[y_t] = \\mu \\quad \\forall t \\qquad \\therefore \\quad \\gamma(t,s)=\\gamma(|t-s|)\n\nIf h&gt;0 \\qquad \\gamma(h)=\\mathbb{C}ov[y_t,y_{t-h}]\n\n\n\n\n\n\nImportantAutocorrelation Function (AFC)\n\n\n\n\n\n\\rho(t,s) = \\frac{\\gamma(t,s)}{\\sqrt{\\gamma(t,t)\\gamma(s,s)}}\n\\tag{90.6}\n\n\nauto-correlation AFC\n\\text{Stationarity} \\implies \\rho(h)=\\frac{\\gamma(h)}{\\gamma(o)} \\qquad \\gamma(0)=Var(y_t)\n\n\n\n\n\nslide 2\n\n\ny_{1:T}\n\\tag{90.7}\n\n\n\n\n\n\nImportantThe sample AFC\n\n\n\n\n\\hat\\gamma(h)= \\frac{1}{T} \\sum_{t=1}^{T-h}(y_{t+h}-\\bar y )(y_t-\\hat y)\n\\tag{90.8}\nwhere \\bar y is the sample mean of the time series y_{1:T}, and \\hat y is the sample mean of the time series y_{1:T-h}.\n\n\n\n\\bar y = \\frac{1}{T} \\sum_{t=1}^{T}y_t\n\\tag{90.9}\n\n\\hat \\rho = \\frac{\\hat\\gamma(h)}{\\hat\\gamma(o)}\n\\tag{90.10}\n\n\n90.2.3 The partial auto-correlation function PACF (Reading)\n\nDefinition 90.3 (Partial Auto-correlation Function (PAFC)) Let {y_t} be a zero-mean stationary process, and let\n\n\\hat{y}_t^{h-1} = \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + \\ldots + \\beta_{h-1} y_{t-(h-1)}\n\\tag{90.11}\nbe the best linear predictor of y_t based on the previous h − 1 values \\{y_{t−1}, \\ldots , y_{t−h+1}\\}. The best linear predictor of y_t based on the previous h − 1 values of the process is the linear predictor that minimizes\n\nE[(y_t − \\hat{y}_y^{h-1})^2]\n\\tag{90.12}\nThe partial autocorrelation of this process at lag h, denoted by \\phi(h, h) is defined as: partial auto-correlation PAFC\n\n\\phi(h, h) = Corr(y_{t+h} − \\hat{y}_{t+h}^{h-1}, y_t − \\hat{y}_t^{h-1})\n\\tag{90.13}\nfor h \\ge 2 and \\phi(1, 1) = Corr(y_{t+1}, y_{t}) = \\rho(1).\n\nThe partial autocorrelation function can also be computed via the Durbin-Levinson recursion for stationary processes as \\phi(0, 0) = 0,\n\n\\phi(n, n) = \\frac{\\rho(n) − \\sum_{h=1}^{n-1} \\phi(n − 1, h)\\rho(n − h)}{1- \\sum_{h=1}^{n-1}\\phi(n − 1, h)\\rho(h)}\n\\tag{90.14}\nfor n \\ge 1, and\n\n\\phi(n, h) = \\phi(n − 1, h) − \\phi(n, n)\\phi(n − 1, n − h),\n\\tag{90.15}\nfor n \\ge 2, and h = 1, \\ldots , (n − 1).\nNote that the sample PACF can be obtained by substituting the sample autocorrelations and the sample auto-covariances in the Durbin-Levinson recursion.\n\n\n90.2.4 Differencing and smoothing (Reading)\nDifferencing and smoothing are techniques used to remove trends and seasonality in time series data. They are covered in the (Prado, Ferreira, and West 2023, sec. 1.4).\nMany synthetic time series models are built under the assumption of stationarity. However, in the real world time series data often present non-stationary features such as trends or seasonality. These features render such a time series non-stationary, and therefore, not suitable for analysis using the tools and methods we have discussed so far. However practitioners can use techniques for detrending, deseasonalizing and smoothing that when applied to such observed data transforms it into a new time series that is consistent with the stationarity assumption.\nWe briefly discuss two methods that are commonly used in practice for detrending and smoothing.\n\n90.2.4.1 Differencing\nDifferencing, is a method which removes the trend from a time series data. The first difference of a time series is defined in terms of the difference operator, denoted as D, that produces the transformation differencing operator D\n\nDy_t \\doteqdot y_t - y_{t-1}.\n\\tag{90.16}\nHigher order differences are obtained by successively applying the operator D. For example,\n\nD^2y_t = D(Dy_t) = D(y_t - y_{t-1}) = y_t - 2y_{t-1} + y_{t-2}.\n\\tag{90.17}\nDifferencing can also be written in terms of the so called back-shift operator B, with back-shift operator B\n\nBy_t \\doteqdot y_{t-1},\n\\tag{90.18}\nso that\n\nDy_t \\doteqdot (1 - B) y_t\n\\tag{90.19}\nand\n\nD^dy_t \\doteqdot (1 - B)^d y_t.\n\\tag{90.20}\nthis notation lets us write the differences in by referencing items backwards in time, which is often more intuitive and also useful, for example, when we will want to write the differencing operator in terms of a polynomial.\n\n\n90.2.4.2 Smoothing\nMoving averages, which is commonly used to “smooth” a time series by removing certain features (e.g., seasonality) to highlight other features (e.g., trends).\nA moving average is a weighted average of the time series around a particular time t. In general, if we have data y_{1:T}, we could obtain a new time series such that moving average\n\nz_t = \\sum_{j=-q}^{p} w_j y_{t+j} \\qquad\n\\tag{90.21}\nfor t = (q + 1) : (T − p), with weights w_j \\ge 0 and \\sum^p_{j=−q} w_j = 1\nWe will frequently work with moving averages for which\n\np = q \\qquad \\text{(centered)}\n\nand\n\nw_j = w_{−j} \\forall j  \\text{(symmetric)}\n\nAssume we have periodic data with period d. Then, symmetric and centered moving averages can be used to remove such periodicity as follows:\n\nIf d = 2q :\n\n\nz_t =  \\frac{1}{d} \\left(\\frac{1}{2} y_{t−q} + y_{t−q+1} + \\ldots + y_{t+q−1} + \\frac{1}{2} y_{t+q}\\right )\n\\tag{90.22}\n\nif d = 2q + 1 :\n\n\nz_t = \\frac{1}{d} \\left( y_{t−q} + y_{t−q+1} + \\ldots + y_{t+q−1} + y_{t+q}\\right )\n\\tag{90.23}\n\nExample 90.1 (Seasonal Moving Average) To remove seasonality in monthly data (i.e., seasonality with a period of d = 12 months), we use a moving average with p = q = 6, a_6 = a_{−6} = 1/24, and a_j = a_{−j} = 1/12 for j = 0, \\ldots , 5 , resulting in:\n\nz_t = \\frac{1}{24} y_{t−6} + \\frac{1}{12}y_{t−5} + \\ldots + \\frac{1}{12}y_{t+5} + \\frac{1}{24}y_{t+6}\n\\tag{90.24}\n\n\n\n\n90.2.5 ACF PACF Differencing and Smoothing Examples (Video)\nThis video walks us through the code snippets in ?lst-moving-averages-and-differencing and Listing 90.1 below and provides examples of how to compute the ACF and PACF of a time series, how to use differencing to remove trends, and how to use moving averages to remove seasonality.\n\nOutline:\n\nWe begin by simulating data using the code in Section 90.2.7\nWe simulates white noise data using the rnorm(1:2000,mean=0,sd=1) function in R\nWe plot the white noise data which we can see lacks a temporal structure.\nWe plot the ACF using the acf function in R:\n\nwe specify the number of lags using the lag.max=20\nwe shows a confidence interval for the ACF values\n\nWe plot the PACF using the pacf function in R\nNext we define some time series objects in R using the ts function\n\nwe define and plot monthly data starting in January 1960\nwe define and plot yearly data with one observation per year starting in 1960\nwe define and plot yearly data with four observations per year starting in 1960\n\nWe move on to smoothing and differencing in Section 90.2.6\nWe load the CO2 dataset in R and plot it\nwe plot the ACF and PACF of the CO2 dataset\nwe use the filter function in R to remove the seasonal component of the CO2 dataset we plot the resulting time series highlighting the trend.\nTo remove the trend we use the diff function in R to take the first and second differences of the CO2 dataset\n\nthe diff function takes a parameter differences which specifies the number of differences to take\n\nwe plot the resulting time series after taking the first and second differences\nthe ACF and PACF of the resulting time series are plotted, they look different, in that they no longer have the slow decay characteristic of time series with a trend.\n\n\nThe r-code for the examples is provided below.\n\n\n90.2.6 R code for Differencing and filtering via moving averages (reading)\n\n\nCode\n# Load the CO2 dataset in R\ndata(co2) \n\n# Take first differences to remove the trend \nco2_1stdiff=diff(co2,differences=1)\n\n# Filter via moving averages to remove the seasonality \nco2_ma=filter(co2,filter=c(1/24,rep(1/12,11),1/24),sides=2)\n\npar(mfrow=c(3,1),mar = c(3, 4, 2, 1), cex.lab=1.2,cex.main=1.2)\nplot(co2) # plot the original data \nplot(co2_1stdiff) # plot the first differences (removes trend, highlights seasonality)\nplot(co2_ma) # plot the filtered series via moving averages (removes the seasonality, highlights the trend)\n\n\n\n\n\n\n\n\nFigure 90.1: R code: for Differencing and filtering via moving averages\n\n\n\n\n\n\n\n90.2.7 R Code: Simulate data from a white noise process (reading)\n\n\n\n\nListing 90.1: R Code: Simulate data from a white noise process\n\n\n\nCode\n#\n# Simulate data with no temporal structure (white noise)\n#\nset.seed(2021)\nT=200\nt =1:T\ny_white_noise=rnorm(T, mean=0, sd=1)\n#\n# Define a time series object in R: \n# Assume the data correspond to annual observations starting in January 1960 \n#\nyt=ts(y_white_noise, start=c(1960), frequency=1)\n#\n# plot the simulated time series, their sample ACF and their sample PACF\n#\npar(mfrow = c(1, 3),mar = c(3, 4, 2, 1), cex.lab = 1.3, cex.main = 1.3)\nyt=ts(y_white_noise, start=c(1960), frequency=1)\nplot(yt, type = 'l', col='red', xlab = 'time (t)', ylab = \"Y(t)\")\nacf(yt, lag.max = 20, xlab = \"lag\",\n    ylab = \"Sample ACF\",ylim=c(-1,1),main=\"\")\npacf(yt, lag.max = 20,xlab = \"lag\",\n     ylab = \"Sample PACF\",ylim=c(-1,1),main=\"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n90.2.8 Quiz 1: Stationarity, ACF, PACF, Differencing, and Smoothing\nomitted per coursera requirements",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#the-ar1-process-definition-and-properties",
    "href": "C4-L01.html#the-ar1-process-definition-and-properties",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "90.3 The AR(1) process: Definition and properties",
    "text": "90.3 The AR(1) process: Definition and properties\nWe will next introduce the autoregressive process of order one, or AR(1) process, which is a fundamental model in time series analysis. We will discuss the definition of the AR(1) process, its properties, and how to simulate data from an AR(1) process.\n\n90.3.1 The AR(1) process (video)\n\n\n\n\nAR(1)\n\n\n\n\nAR(1) properties\n\n\n\n\n90.3.2 The PACF of the AR(1) process (reading)\nIt is possible to show that the PACF of an autoregressive process of order one is zero after the first lag. We can use the Durbin-Levinson recursion to show this.\nFor lag n = 0 we have \\phi(0, 0) = 0\nFor lag n = 1 we have:\n\n\\phi(1, 1) =  \\rho(1) = \\phi\n\nFor lag n = 2 we compute \\phi(2, 2) as:\n\n\\phi(2, 2) = \\frac{(\\rho(2) − \\phi(1, 1)\\rho(1))}{ (1 − \\phi(1, 1)\\rho(1))} = \\frac{\\phi^2-\\phi^2}{1- \\phi^2}=0\n\nand we also obtain\n\n\\phi(2, 1) = \\phi(1, 1) − \\phi(2, 2)\\phi(1, 1) = \\phi.\n\nFor lag n = 3 we compute \\phi(3, 3) as\n\n\\begin{aligned}\n\\phi(3, 3) &= \\frac{(\\rho(3) − \\sum_{h=1}^2 \\phi(2, h)\\rho(3 − h))}{1 − \\sum_{h=1}^2 \\phi(2, h)\\rho(h)} \\newline\n&= \\frac{\\phi^3 - \\phi(2,1) \\rho(2) - \\phi(2,2) \\rho(1)}{1 - \\phi(2,1)\\rho(1) - \\phi(2,2)\\rho(2)} \\newline\n&= \\frac{\\phi^3 - \\phi^3 - 0}{1 - \\phi^2 } \\newline\n&= 0\n\\end{aligned}\n\nand we also obtain\n\n\\phi(3, 1) = \\phi(2, 1) − \\phi(3, 3)\\phi(2, 2) = \\phi\n\n\n\\phi(3, 2) = \\phi(2, 2) − \\phi(3, 3)\\phi(2, 1) = 0\n\nWe can prove by induction that in the case of an AR(1), for any lag n,\n\\phi(n, h) = 0, \\phi(n, 1) = \\phi and \\phi(n, h) = 0 for h \\ge 2 and n \\ge 2.\nThen, the PACF of an AR(1) is zero for any lag above 1 and the PACF coefficient at lag 1 is equal to the AR coefficient \\phi\n\n\n90.3.3 Simulate data from an AR(1) process (video)\nThis video walks through the code snippet below and provides examples of how to sample data from an AR(1) process and plot the ACF and PACF functions of the resulting time series.\n\n\n90.3.4 R code: Sample data from AR(1) processes (Reading)\n\n\nCode\n# sample data from 2 ar(1) processes and plot their ACF and PACF functions\n#\nset.seed(2021)\nT=500 # number of time points\n#\n# sample data from an ar(1) with ar coefficient phi = 0.9 and variance 1\n#\nv=1.0 # innovation variance\nsd=sqrt(v) #innovation stantard deviation\nphi1=0.9 # ar coefficient\nyt1=arima.sim(n = T, model = list(ar = phi1), sd = sd)\n#\n# sample data from an ar(1) with ar coefficient phi = -0.9 and variance 1\n#\nphi2=-0.9 # ar coefficient\nyt2=arima.sim(n = T, model = list(ar = phi2), sd = sd)\n\npar(mfrow = c(2, 1),mar = c(3, 4, 2, 1), cex.lab = 1.3)\nplot(yt1,main=expression(phi==0.9))\nplot(yt2,main=expression(phi==-0.9))\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(3, 2),mar = c(3, 4, 2, 1), cex.lab = 1.3)\nlag.max=50 # max lag\n#\n## plot true ACFs for both processes\n#\ncov_0=sd^2/(1-phi1^2) # compute auto-covariance at h=0\ncov_h=phi1^(0:lag.max)*cov_0 # compute auto-covariance at h\nplot(0:lag.max, cov_h/cov_0, pch = 1, type = 'h', col = 'red',\n     ylab = \"true ACF\", xlab = \"Lag\",ylim=c(-1,1), main=expression(phi==0.9))\n\ncov_0=sd^2/(1-phi2^2) # compute auto-covariance at h=0\ncov_h=phi2^(0:lag.max)*cov_0 # compute auto-covariance at h\n# Plot autocorrelation function (ACF)\nplot(0:lag.max, cov_h/cov_0, pch = 1, type = 'h', col = 'red',\n     ylab = \"true ACF\", xlab = \"Lag\",ylim=c(-1,1),main=expression(phi==-0.9))\n\n## plot sample ACFs for both processes\n#\nacf(yt1, lag.max = lag.max, type = \"correlation\", ylab = \"sample ACF\",\n    lty = 1, ylim = c(-1, 1), main = \" \")\nacf(yt2, lag.max = lag.max, type = \"correlation\", ylab = \"sample ACF\",\n    lty = 1, ylim = c(-1, 1), main = \" \")\n## plot sample PACFs for both processes\n#\npacf(yt1, lag.ma = lag.max, ylab = \"sample PACF\", ylim=c(-1,1),main=\"\")\npacf(yt2, lag.ma = lag.max, ylab = \"sample PACF\", ylim=c(-1,1),main=\"\")\n\n\n\n\n\n\n\n\n\n\n\n90.3.5 Quiz 2: The AR(1) definition and properties\nOmitted per Coursera honor code requirements.",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#review-of-maximum-likelihood-and-bayesian-inference-in-regression",
    "href": "C4-L01.html#review-of-maximum-likelihood-and-bayesian-inference-in-regression",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.1 Review of maximum likelihood and Bayesian inference in regression",
    "text": "91.1 Review of maximum likelihood and Bayesian inference in regression\n\n91.1.1 Regression Models: Maximum Likelihood Estimation\nAssume a regression model with the following structure: \ny_i = \\beta_1x_{i,1} + \\ldots + \\beta_kx_{i,k} + \\epsilon_i,\n\nfor i = 1, \\ldots, n and \\epsilon_i independent random variables with \\epsilon_i \\sim N(0, v) \\forall i. This model can be written in matrix form as:\n\ny = X \\beta + \\epsilon, \\epsilon \\sim N (0, vI), \\qquad\n\nwhere:\n\ny = (y_1, \\ldots, y_n)′ is an n-dimensional vector of responses,\nX is an n × k matrix containing the explanatory variables,\n\\beta = (\\beta_1, \\ldots, \\beta_k)′ is the k-dimensional vector of regression coefficients,\n\\epsilon = (\\epsilon_1, \\ldots, \\epsilon_n)′ is the n-dimensional vector of errors,\nI is an n × n identity matrix.\n\nIf X is a full rank matrix with rank k the maximum likelihood estimator for \\beta, denoted as \\hat\\beta_{MLE} is given by:\n\n\\hat\\beta_{MLE} = (X′X)^{−1}X′y,\n\nand the MLE for v is given by\n\n\\hat v_{MLE} = \\frac{1}{n} (y − X \\hat\\beta_{MLE})′(y − X \\hat\\beta_{MLE})\n\n\\hat v_{MLE} is not an unbiased estimator of v, therefore, the following unbiased estimator of v is typically used:\n\ns^2 = \\frac{1}{n-k}(y − X \\hat\\beta_{MLE} )′(y − X \\hat\\beta_{MLE} )\n\n\n\n91.1.2 Regression Models: Bayesian Inference\nAssume once again we have a model with the structure in (1), which results in a likelihood of the form\n\n\\mathbb{P}r(y \\mid \\beta , v) = \\frac{1}{(2\\pi v)^{n/2}}\\exp \\left\\{ -\\frac{1}{2} (y − X\\beta)′(y − X\\beta) \\right\\}\n\nIf a prior of the form\n\n\\mathbb{P}r(\\beta, v) \\propto \\frac{1}{v}\n\nis used, we obtain that the posterior distribution is given by\n\n\\mathbb{P}r(\\beta,v \\mid y) \\propto \\frac{1}{v^{n/2+1}}\\exp \\left\\{ -\\frac{1}{2v} (y − X\\beta)′(y − X\\beta) \\right\\}\n\nIn addition it can be shown that\n\n(\\beta\\mid v, y) \\sim N (\\hat \\beta_{MLE} , v(X′X)−1)\n(v\\mid y) \\sim \\text{IG}((n − k)/2, d/2) with\n\n\nd = (y − X \\hat \\beta_{MLE} )′(y − \\hat \\beta_{MLE} )\n\nwith k = dim(\\beta).\nGiven that \\mathbb{P}r(\\beta, v \\mid y) = \\mathbb{P}r(\\beta \\mid v, y)p(v \\mid y) the equations above provide a way to directly sample from the posterior distribution of \\beta and v by first sampling v from the inverse-gamma distribution above and then conditioning on this sampled value of v, sampling \\beta from the normal distribution above.",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#maximum-likelihood-estimation-in-the-ar1-video",
    "href": "C4-L01.html#maximum-likelihood-estimation-in-the-ar1-video",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.2 Maximum likelihood estimation in the AR(1) (video)",
    "text": "91.2 Maximum likelihood estimation in the AR(1) (video)\n\n\n\n\nslide 1\n\n\n\n\nslide 2\n\n\n\n\nslide 3",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#r-code-mle-for-the-ar1-examples-reading",
    "href": "C4-L01.html#r-code-mle-for-the-ar1-examples-reading",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.3 R code: MLE for the AR(1), examples (reading)",
    "text": "91.3 R code: MLE for the AR(1), examples (reading)\nThe following code allows you to compute the MLE of the AR coefficient \\psi, the unbiased estimator of v, s^2 , and the MLE of v based on a dataset simulated from an AR(1) process and using the conditional likelihood.\n\n\nCode\nset.seed(2021)\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n## Case 1: Conditional likelihood\ny=as.matrix(yt[2:T]) # response\nX=as.matrix(yt[1:(T-1)]) # design matrix\nphi_MLE=as.numeric((t(X)%*%y)/sum(X^2)) # MLE for phi\ns2=sum((y - phi_MLE*X)^2)/(length(y) - 1) # Unbiased estimate for v \nv_MLE=s2*(length(y)-1)/(length(y)) # MLE for v\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_MLE, \"\\n\",\n    \"MLE for the variance v: \", v_MLE, \"\\n\", \n    \"Estimate s2 for the variance v: \", s2, \"\\n\")\n\n\n\n MLE of conditional likelihood for phi:  0.9261423 \n MLE for the variance v:  1.048 \n Estimate s2 for the variance v:  1.050104 \n\n\nThis code allows you to compute estimates of the AR(1) coefficient and the variance using the arima function in R. The first case uses the conditional sum of squares, the second and third cases use the full likelihood with different starting points for the numerical optimization required to compute the MLE with the full likelihood.\n\n\nCode\n# Obtaining parameter estimates using the arima function in R\nset.seed(2021)\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n#Using conditional sum of squares, equivalent to conditional likelihood \narima_CSS=arima(yt,order=c(1,0,0),method=\"CSS\",n.cond=1,include.mean=FALSE)\ncat(\"AR estimates with conditional sum of squares (CSS) for phi and v:\", arima_CSS$coef,arima_CSS$sigma2,\n\"\\n\")\n\n\nAR estimates with conditional sum of squares (CSS) for phi and v: 0.9261423 1.048 \n\n\nCode\n#Uses ML with full likelihood \narima_ML=arima(yt,order=c(1,0,0),method=\"ML\",include.mean=FALSE)\ncat(\"AR estimates with full likelihood for phi and v:\", arima_ML$coef,arima_ML$sigma2,\n\"\\n\")\n\n\nAR estimates with full likelihood for phi and v: 0.9265251 1.048434 \n\n\nCode\n#Default: uses conditional sum of squares to find the starting point for ML and \n#         then uses ML \narima_CSS_ML=arima(yt,order=c(1,0,0),method=\"CSS-ML\",n.cond=1,include.mean=FALSE)\ncat(\"AR estimates with CSS to find starting point for ML for phi and v:\", \narima_CSS_ML$coef,arima_CSS_ML$sigma2,\"\\n\")\n\n\nAR estimates with CSS to find starting point for ML for phi and v: 0.9265252 1.048434 \n\n\nThis code shows you how to compute the MLE for \\psi using the full likelihood and the function optimize in R.\n\n\nCode\nset.seed(2021)\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n## MLE, full likelihood AR(1) with v=1 assumed known \n# log likelihood function\nlog_p &lt;- function(phi, yt){\n  0.5*(log(1-phi^2) - sum((yt[2:T] - phi*yt[1:(T-1)])^2) - yt[1]^2*(1-phi^2))\n}\n\n# Use a built-in optimization method to obtain maximum likelihood estimates\nresult =optimize(log_p, c(-1, 1), tol = 0.0001, maximum = TRUE, yt = yt)\ncat(\"\\n MLE of full likelihood for phi: \", result$maximum)\n\n\n\n MLE of full likelihood for phi:  0.9265928",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#bayesian-inference-in-the-ar1",
    "href": "C4-L01.html#bayesian-inference-in-the-ar1",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.4 Bayesian inference in the AR(1)",
    "text": "91.4 Bayesian inference in the AR(1)\n\n\n\n\nslide 1",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#bayesian-inference-in-the-ar1-conditional-likelihood-example-video",
    "href": "C4-L01.html#bayesian-inference-in-the-ar1-conditional-likelihood-example-video",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.5 Bayesian inference in the AR(1): Conditional likelihood example (video)",
    "text": "91.5 Bayesian inference in the AR(1): Conditional likelihood example (video)\nThis video walks through the code snippet below and provides examples of how to sample from the posterior distribution of the AR coefficient \\psi and the variance v using the conditional likelihood and a reference prior.",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#r-code-ar1-bayesian-inference-conditional-likelihood-example-reading",
    "href": "C4-L01.html#r-code-ar1-bayesian-inference-conditional-likelihood-example-reading",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.6 R Code: AR(1) Bayesian inference, conditional likelihood example (reading)",
    "text": "91.6 R Code: AR(1) Bayesian inference, conditional likelihood example (reading)\n\n\nCode\n####################################################\n#####             MLE for AR(1)               ######\n####################################################\nset.seed(2021)\nphi=0.9 # ar coefficient\nsd=1 # innovation standard deviation\nT=200 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) # sample stationary AR(1) process\n\ny=as.matrix(yt[2:T]) # response\nX=as.matrix(yt[1:(T-1)]) # design matrix\nphi_MLE=as.numeric((t(X)%*%y)/sum(X^2)) # MLE for phi\ns2=sum((y - phi_MLE*X)^2)/(length(y) - 1) # Unbiased estimate for v\nv_MLE=s2*(length(y)-1)/(length(y)) # MLE for v \n\nprint(c(phi_MLE,s2))\n\n\n[1] 0.9178472 1.0491054\n\n\nCode\n#######################################################\n######     Posterior inference, AR(1)               ###\n######     Conditional Likelihood + Reference Prior ###\n######     Direct sampling                          ###\n#######################################################\n\nn_sample=3000   # posterior sample size\n\n## step 1: sample posterior distribution of v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2)/2, sum((yt[2:T] - phi_MLE*yt[1:(T-1)])^2)/2)\n\n## step 2: sample posterior distribution of phi from normal distribution\nphi_sample=rep(0,n_sample)\nfor (i in 1:n_sample){\nphi_sample[i]=rnorm(1, mean = phi_MLE, sd=sqrt(v_sample[i]/sum(yt[1:(T-1)]^2)))}\n\n## plot histogram of posterior samples of phi and v\npar(mfrow = c(1, 2),mar = c(3, 4, 2, 1), cex.lab = 1.3)\nhist(phi_sample, xlab = bquote(phi), \n     main = bquote(\"Posterior for \"~phi),xlim=c(0.75,1.05), col='lightblue')\nabline(v = phi, col = 'red')\nhist(v_sample, xlab = bquote(v), col='lightblue', main = bquote(\"Posterior for \"~v))\nabline(v = sd, col = 'red')",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#quizz---mle-and-bayesian-inference-in-the-ar1",
    "href": "C4-L01.html#quizz---mle-and-bayesian-inference-in-the-ar1",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.7 Quizz - MLE and Bayesian inference in the AR(1)",
    "text": "91.7 Quizz - MLE and Bayesian inference in the AR(1)\nOmitted per Coursera honor code",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L01.html#practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1",
    "href": "C4-L01.html#practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1",
    "title": "89  Introductions to Time Series analysis & the AR(1) process",
    "section": "91.8 Practice Graded Assignment: MLE and Bayesian inference in the AR(1)",
    "text": "91.8 Practice Graded Assignment: MLE and Bayesian inference in the AR(1)\nThis peer-reviewed activity is highly recommended. It does not figure into your grade for this course, but it does provide you with the opportunity to apply what you’ve learned in R and prepare you for your data analysis project in week 5.\n\nConsider the R code below: MLE for the AR(1)\n\n\n\n\n\nListing 91.1: R Code: MLE for the AR(1) process, conditional likelihood example\n\n\n\nCode\n####################################################\n#####             MLE for AR(1)               ######\n####################################################\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n## Case 1: Conditional likelihood\ny=as.matrix(yt[2:T]) # response\nX=as.matrix(yt[1:(T-1)]) # design matrix\nphi_MLE=as.numeric((t(X)%*%y)/sum(X^2)) # MLE for phi\ns2=sum((y - phi_MLE*X)^2)/(length(y) - 1) # Unbiased estimate for v \nv_MLE=s2*(length(y)-1)/(length(y)) # MLE for v\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_MLE, \"\\n\",\n    \"MLE for the variance v: \", v_MLE, \"\\n\", \n    \"Estimate s2 for the variance v: \", s2, \"\\n\")\n\n\n\n\n\n\n MLE of conditional likelihood for phi:  0.9048951 \n MLE for the variance v:  1.084559 \n Estimate s2 for the variance v:  1.086737 \n\n\nModify the code above to sample 800 observations from an AR(1) with AR coefficient \\psi = -0.8 and variance v = 2. Plot your simulated data. Obtain the MLE for \\psi based on the conditional likelihood and the unbiased estimate s^2 for the variance v.\n\nConsider the R code below: AR(1) Bayesian inference, conditional likelihood\n\n\n\n\n\nListing 91.2: R Code: AR(1) Bayesian inference, conditional likelihood example\n\n\n\nCode\n#######################################################\n######     Posterior inference, AR(1)               ###\n######     Conditional Likelihood + Reference Prior ###\n######     Direct sampling                          ###\n#######################################################\n\nn_sample=3000   # posterior sample size\n\n## step 1: sample posterior distribution of v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2)/2, sum((yt[2:T] - phi_MLE*yt[1:(T-1)])^2)/2)\n\n## step 2: sample posterior distribution of phi from normal distribution\nphi_sample=rep(0,n_sample)\nfor (i in 1:n_sample){\nphi_sample[i]=rnorm(1, mean = phi_MLE, sd=sqrt(v_sample[i]/sum(yt[1:(T-1)]^2)))}\n\n## plot histogram of posterior samples of phi and v\npar(mfrow = c(1, 2), mar = c(3, 4, 2, 1), cex.lab = 1.3)\nhist(phi_sample, xlab = bquote(phi), \n     main = bquote(\"Posterior for \"~phi),xlim=c(0.75,1.05), col='lightblue')\nabline(v = phi, col = 'red')\nhist(v_sample, xlab = bquote(v), col='lightblue', main = bquote(\"Posterior for \"~v))\nabline(v = sd, col = 'red')\n\n\n\n\n\n\n\n\n\n\n\n\nUsing your simulated data from part 1 modify the code above to summarize your posterior inference for \\psi and v based on 5000 samples from the joint posterior distribution of \\psi and v.\n\n\n\n\n\n\nTipGrading Criteria\n\n\n\nThe responses should follow the same template as the sample code provided above but you will submit your code lines in plain text. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect that :\n\nyou generate 800 time points from the AR(1) rather than 500 and plot your simulated data.\nyour simulated data is from an AR(1) with AR cofficient \\psi = -0.8 and variance v = 2 rather than AR(1) with AR coefficient \\psi = 0.9 and variance v = 1 and\nyou obtain 5000 rather than 3000 samples from the posterior distribution from the new simulated process.\n\n\n\n\n91.8.1 Bayesian Inference in the AR(1), : full likelihood example (reading)\nWe consider a prior distribution that assumes that \\phi and v are independent:\n\n\\mathbb{P}r(v) \\propto \\frac{1}{v},\n\n\n\\mathbb{P}r(\\phi) = \\frac{1}{2}, \\quad \\text{for } \\phi \\in (-1, 1),\n\ni.e., we assume a Uniform prior for \\phi \\in (-1, 1). Combining this prior with the full likelihood in the AR(1) case, we obtain the following posterior density:\n\n\\mathbb{P}r(\\phi, v \\mid y_{1:T}) \\propto \\frac{(1 - \\phi^2)^{1/2} }{v^{T/2 + 1}} \\exp\\left(-\\frac{Q^*(\\phi)}{2v}\\right), \\quad -1 &lt; \\phi &lt; 1,\n\nwith\n\nQ^*(\\phi) = y_1^2(1 - \\phi^2) + \\sum_{t=2}^{T} (y_t - \\phi y_{t-1})^2.\n\nIt is not possible to get a closed-form expression for this posterior or to perform direct simulation. Therefore, we use simulation-based Markov Chain Monte Carlo (MCMC) methods to obtain samples from the posterior distribution.\n\n\n91.8.2 Transformation of \\phi\nWe first consider the following transformation on \\phi:\n\n\\eta = \\log\\left(\\frac{1 - \\phi}{\\phi + 1}\\right),\n\nso that \\eta \\in (-\\infty, \\infty). The inverse transformation on \\eta is:\n\n\\phi = \\frac{1 - \\exp(\\eta)}{1 + \\exp(\\eta)}.\n\nWriting down the posterior density for \\eta and v, we obtain\n\n\\mathbb{P}r(\\eta, v \\mid y_{1:T}) \\propto\\frac{ (1 - \\phi^2)^{1/2} }{v^{T/2 + 1}} \\exp\\left(-\\frac{Q^*(\\phi)}{2v}\\right) \\cdot \\frac{2 \\exp(\\eta)}{(1 + \\exp(\\eta))^2},\n\nwith \\phi written as a function of \\eta. We proceed to obtain samples from this posterior distribution using the MCMC algorithm outlined below. Once we have obtained M samples from \\eta and v after convergence, we can use the inverse transformation above to obtain posterior samples for \\phi.\n\n\n91.8.3 MCMC Algorithm: Bayesian Inference for AR(1), Full Likelihood\nAlgorithm:\n\nInitialize \\eta^{(0)} and \\beta^{(0)}.\nFor m in 1:M do:\n\nSample v^{(m)} \\sim \\text{IG}\\left(\\frac{T}{2}, \\frac{Q^*(\\phi^{(m-1)})}{2}\\right).\nSample \\eta^{(m)} using Metropolis-Hastings:\n\nSample \\eta^* \\sim N(\\eta^{(m-1)}, c), where c is a tuning parameter.\nCompute the importance ratio:\n\n\n\n\n        r = \\frac{p(\\eta^*, v^{(m)} \\mid y_{1:T})}{p(\\eta^{(m-1)}, v^{(m)} \\mid y_{1:T})}.\n\n\nSet:\n\n\n        \\eta^{(m)} =\n        \\begin{cases}\n        \\eta^* & \\text{with probability } \\min(r, 1), \\\\\n        \\eta^{(m-1)} & \\text{otherwise}.\n        \\end{cases}\n\n\n\n\n\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nWeckerle, Melissa. 2022. “Statistics professor wins prestigious professional statistics society award  Baskin School of Engineering.” https://engineering.ucsc.edu/news/statistics-professor-wins-zellner-medal.",
    "crumbs": [
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Introductions to Time Series analysis & the AR(1) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html",
    "href": "C4-L02.html",
    "title": "90  The AR(p) process",
    "section": "",
    "text": "91 The general AR(p) process (video)",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#definition-and-state-space-representation-video",
    "href": "C4-L02.html#definition-and-state-space-representation-video",
    "title": "90  The AR(p) process",
    "section": "91.1 Definition and state-space representation (video)",
    "text": "91.1 Definition and state-space representation (video)\n\n\n\n\nAR(p) process, characteristic polynomial, stability, stationarity and MA representation\n\nAR(P), shorthand for autoregressive process of order p which generalizes the AR(1) process by defining the current time step in terms of the previous p time steps. Thus the number of parameter p, required is the order  of the autoregressive process. It tells us how many lags we will be considering. On the other hand, the AR(1) process is a special case of the AR(p) process with p=1.order\nAR(P)\nWe will assume AR(P) has the following structure:\n\n\\textcolor{red}{y_t} = \\textcolor{blue}{\\phi_1} \\textcolor{red}{y_{t-1}} + \\textcolor{blue}{\\phi_2} \\textcolor{red}{y_{t-2}} + \\ldots + \\textcolor{blue}{\\phi_p} \\textcolor{red}{y_{t-p}} + \\textcolor{grey}{\\epsilon_t} \\qquad\n\\tag{91.1}\nwhere:\n\n\\textcolor{red}{y_t} is the value of the time series at time t\n\\textcolor{blue}{\\phi_{1:p}} are the AR coefficients\n\\textcolor{grey}{\\epsilon_t} \\overset{\\text{iid}}{\\sim} \\text{N}(0,v) \\quad \\forall t is a white noise process.\nThe number of parameters has increased from one coefficient in AR(1) to p coefficients for AR(P).\n\nA central outcome of the autoregressive nature of the AR(p) is due to the properties the AR characteristic polynomial \\Phi.  This is defined as :\\Phi AR characteristic polynomial\nrecall the backshift operator B is defined as B y_t = y_{t-1}, so that B^j y_t = y_{t-j}.\n\n\\begin{aligned}\n       y_t &= \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\ldots + \\phi_p y_{t-p} + \\epsilon_t  && \\text{(Ar(p) defn.)} \\newline\n       y_t &= \\phi_1 By_{t} + \\phi_2 B^2y_{t} + \\ldots + \\phi_p B^p y_{t} + \\epsilon_t && \\text{(B defn.)} \\newline\n\\epsilon_t &= y_t - \\phi_1 B y_t + \\phi_2 B^2 y_t + \\ldots + \\phi_p B^p y_t    && \\text{(rearranging)} \\newline\n\\epsilon_t  &= (1- \\phi_1 B + \\phi_2 B^2 + \\ldots + \\phi_p B^p) y_t            && \\text{(factoring out $y_t$)}\n\\end{aligned}\n \n\\Phi(z) = 1 - \\phi_1 z - \\phi_2 z^2 - \\ldots - \\phi_p z^p \\qquad \\text{(Characteristic polynomial)}\n\\tag{91.2}\nwhere:\n\nz \\in \\mathbb{C} i.e. complex-valued.\n\nwe can also rewrite the characteristic polynomial in terms of the reciprocal roots of the polynomial.\nThe zeros of the characteristic polynomial are the roots of the AR(p) process.\n\n\\Phi(z) = \\prod_{j=1}^{p} (1 - \\alpha_j z) = 0  \\implies z = \\frac{1}{ \\alpha_j} \\qquad \\text{(reciprocal roots)}\n\nwhere:\n\n\\alpha_j are the reciprocal roots of the characteristic polynomial.\n\n\nWhy are we interested in this autoregresive lag polynomial?\n\n\nThis polynomial and its roots tells us a lot about the process and its properties.\nOne of the main characteristics is it allows us to think about things like quasi-periodic behavior, whether it’s present or not in a particular AR(p) process.\nIt allows us to think about whether a process is stationary or not, depending on some properties related to this polynomial.\nIn particular, we are going to say that the process is stable if all the roots of the characteristic polynomial have a modulus greater than one.  \n\\Phi(z) = 0 \\iff |z| &gt; 1  \\qquad \\text{(stability condition)}\n\\tag{91.3}\nFor any of the roots, it has to be the case that the modulus of that root, they have to be all outside the unit circle.\nIf a process is stable, it will also be stationary.\n\nstability conditionWe can show this as follows:\n\nOnce the process is stationary, and if all the roots of the characteristic polynomial are outside the unit circle, then we will be able to write this process in terms of an infinite order moving average process. In this case, if the process is stable, then we are going to be able to write it like this.\n\n\ny_t = \\Psi(B) \\epsilon_t = \\sum_{j=0}^{\\infty} \\psi_j \\epsilon_{t-j} \\ \\text {with} \\ \\psi_0 = 1 \\text{ and } \\sum_{j=0}^{\\infty} |\\psi_j| &lt; \\infty\n\\tag{91.4}\nwhere:\n\n\\epsilon_t is a white noise process with zero mean and constant variance v.\nB is the lag operator AKA the backshift operator defined by B \\varepsilon_t = \\varepsilon_{t-1}. This need to be applied to a time series \\epsilon_t to get the lagged values.\n\\Psi(B) is the infinite order polynomial in B that representing a linear filter applied to the noise process.​\n\\psi_t = 1 is the weight for the white noise at time t.\nthe constraint \\psi_0 = 1 ensures that the current shock contributes directly to y_t\nthe constraint on the weights \\sum_{j=0}^{\\infty} |\\psi_j| &lt; \\infty ensures that the weights decay sufficiently fast, so that the process does not explode i.e. it is stable and thus stationary.\n\nthe notation with \\psi a functional of operator B and \\psi_i as constants is confusing in both the reuse if the symbol and the complexity.\nHere, U is any complex valued number.\n\nI am going to have an infinite order polynomial here on B, the backshift operator that I can write down just as the sum, j goes from zero to infinity.\n\n\nHere \\psi_0=1. Then there is another condition on the Psi’s for this to happen. We have to have finite sum of these on these coefficients. Once again, if the process is stable, then it would be stationary and we will be able to write down the AR as an infinite order moving average process here. If you recall, B is the backshift operator. Again, if I apply this to y_t, I’m just going to get y_t-j. I can write down Psi of B, as 1 + \\psi_1 B, B squared, and so on. It’s an infinite order process.\n\n\nThe AR characteristic polynomial can also be written in terms of the reciprocal roots of the polynomial. So instead of considering the roots, we can consider the reciprocal roots. In that case, let’s say the $phi$ of u for Alpha 1, Alpha 2, and so on. The reciprocal roots.\n\n\nWhy do we care about all these roots? Why do we care about this structure? Again, we will be able to understand some properties of the process based on these roots as we will see.\n\n\n\n\n\nA state space representation of Ar(p)\n\nWe will now discuss another important representation of the AR(P) process, one that is based on a state-space representation of the process. Again, we care about this type of representations because they allow us to study some important properties of the process. In this case, our state-space or dynamic linear model representation, we will make some connections with these representations later when we talk about dynamic linear models, is given as follows for an AR(P). I have my y_t. I can write it as F transpose and then another vector x_t here. Then we’re going to have x_t is going to be a function of x_t minus 1. That vector there is going to be an F and a G. I will describe what those are in a second. Then I’m going to have another vector here with some distribution. In our case, we are going to have a normal distribution also for that one. In the case of the AR(P), we’re going to have x_t to be y_t, y_t minus 1.\n\nIt’s a vector that has all these values of the y_t process. Then F is going to be a vector. It has to match the dimension of this vector. The first entry is going to be a one, and then I’m going to have zeros everywhere else. The w here is going to be a vector as well.\nThe first component is going to be the Epsilon t. That we defined for the ARP process. Then every other entry is going to be a zero here. Again, the dimensions are going to match so that I get the right equations here. Then finally, my G matrix in this representation is going to be a very important matrix, the first row is going to contain the AR parameters, the AR coefficients. We have p of those. That’s my first row. In this block, I’m going to have an identity matrix. It’s going to have ones in the diagonal and zeros everywhere else. I’m going to have a one here, and then I want to have zeros everywhere else. In this portion, I’m going to have column vector here of zeros. This is my G matrix. Why is this G matrix important? This G matrix is going to be related to the characteristic polynomial, in particular, is going to be related to the reciprocal roots of the characteristic polynomial that we discussed before. The eigenvalues of this matrix correspond precisely to the reciprocal roots of the characteristic polynomial. We will think about that and write down another representation related to this process. But before we go there, I just want you to look at this equation and see that if you do the matrix operations that are described these two equations, you get back the form of your autoregressive process. The other thing is, again, this is called a state-space representation because you have two equations here. One, you can call it the observational level equation where you are relating your observed y’s with some other model information here. Then there is another equation that has a Markovian structure here, where x_t is a function of x_t minus 1. This is why this is a state-space representation. One of the nice things about working with this representation is we can use some definitions that apply to dynamic linear models or state-space models, and one of those definitions is the so-called forecast function. The forecast function, we can define it in terms of, I’m going to use here the notation f_t h to denote that is a function f that depends on the time t that you’re considering, and then you’re looking at forecasting h steps ahead in your time series. If you have observations up to today and you want to look at what is the forecast function five days later, you will have h equals 5 there. It’s just the expected value. We are going to think of this as the expected value of y_t plus h. Conditional on all the observations or all the information you have received up to time t. I’m going to write it just like this. Using the state-space representation, you can see that if I use the first equation and I think about the expected value of y_t plus h is going to be F transpose, and then I have the expected value of the vector x_t plus h in that case. I can think of just applying this, then I would have expected value of x_t plus h given y_1 up to t. But now when I look at the structure of x_t plus h, if I go to my second equation here, I can see that x_t plus h is going to be dependent on x_t plus h minus 1, and there is a G matrix here. I can write this in terms of the expected value of x_t plus h, which is just G, expected value of x_t plus h minus 1, and then I also have plus expected value of the w_t’s. But because of the structure of the AR process that we defined, we said that all the Epsilon T’s are independent normally distributed random variables center at zero. In this case, those are going to be all zero. I can write down this as F transpose G, and then I have the expected value of x_t plus h minus 1 given y_1 up to t. If I continue with this process all the way until I get to time t, I’m going to get a product of all these G matrices here, and because we are starting with this lag h, I’m going to have the product of that G matrix h times. I can write this down as F transpose G to the power of h, and then I’m going to have the expected value of, finally, I get up to here.\nThis is simply is going to be just my x_t vector. I can write this down as F transpose G^h, and then I have just my x_t. Again, why do we care? Now we are going to make that connection with this matrix and the eigenstructure of this matrix. I said before, one of the features of this matrix is that the eigenstructure is related to the reciprocal roots of the characteristic polynomial. In particular, the eigenvalues of this matrix correspond to the reciprocal roots of the characteristic polynomial. If we are working with the case in which we have exactly p different roots. We have as many different roots as the order of the AR process. Let’s say, p distinct. We can write down then G in terms of its eigendecomposition. I can write this down as E, a matrix Lambda here, E inverse.\nHere, Lambda is going to be a diagonal matrix, you just put the reciprocal roots, I’m going to call those Alpha 1 up to Alpha p. They are all different. You just put them in the diagonal and you can use any order you want. But the eigendecomposition, the eigenvectors, have to follow the order that you choose for the eigenvalues. Then what happens is, regardless of that, you’re going to have a unique G. But here, the E is a matrix of eigenvectors.\n\n\nAgain, why do we care? Well, if you look at what we have here, we have the power G to the power of h. Using that eigendecomposition, we can get to write this in this form. Whatever elements you have in the matrix of eigenvectors, they are now going to be functions of the reciprocal roots. The power that appears here, which is the number of steps ahead that you want to forecast in your time series for prediction, I’m just going to have the Alphas to the power of h. When I do this calculation, I can end up writing the forecast function just by doing that calculation as a sum from j equals 1 up to p of some constants. Those constants are going to be related to those E matrices but the important point is that what appears here is my Alpha to the power of h. What this means is I’m breaking this expected value of what I’m going to see in the future in terms of a function of the reciprocal roots of the characteristic polynomial. You can see that if the process is stable, is going to be stationary, all the moduli of my reciprocal roots are going to be below one. This is going to decay exponentially as a function of h. You’re going to have something that decays exponentially. Depending on whether those reciprocal roots are real-valued or complex-valued, you’re going to have behavior here that may be quasiperiodic for complex-valued roots or just non-quasiperiodic for the real valued roots. The other thing that matters is, if you’re working with a stable process, are going to have moduli smaller than one. The contribution of each of the roots to these forecasts function is going to be dependent on how close that modulus of that reciprocal root is to one or minus one. For roots that have relatively large values of the modulus, then they are going to have more contribution in terms of what’s going to happen in the future. This provides a way to interpret the AR process.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#examples-video",
    "href": "C4-L02.html#examples-video",
    "title": "90  The AR(p) process",
    "section": "91.2 Examples (video)",
    "text": "91.2 Examples (video)\n\n\n\n\nAR(1)\n\n\n\n\nAR(2) two positive roots\n\n\n\n\nAR(2) complex roots\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.\nEtiam maximus accumsan gravida. Maecenas at nunc dignissim, euismod enim ac, bibendum ipsum. Maecenas vehicula velit in nisl aliquet ultricies. Nam eget massa interdum, maximus arcu vel, pretium erat. Maecenas sit amet tempor purus, vitae aliquet nunc. Vivamus cursus urna velit, eleifend dictum magna laoreet ut. Duis eu erat mollis, blandit magna id, tincidunt ipsum. Integer massa nibh, commodo eu ex vel, venenatis efficitur ligula. Integer convallis lacus elit, maximus eleifend lacus ornare ac. Vestibulum scelerisque viverra urna id lacinia. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget enim at diam bibendum tincidunt eu non purus. Nullam id magna ultrices, sodales metus viverra, tempus turpis.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#acf-of-the-arp-video",
    "href": "C4-L02.html#acf-of-the-arp-video",
    "title": "90  The AR(p) process",
    "section": "91.3 ACF of the AR(p) (video)",
    "text": "91.3 ACF of the AR(p) (video)\n\n\n\n\nACF of the AR(p)\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#simulating-data-from-an-arp-video",
    "href": "C4-L02.html#simulating-data-from-an-arp-video",
    "title": "90  The AR(p) process",
    "section": "91.4 Simulating data from an AR(p) (video)",
    "text": "91.4 Simulating data from an AR(p) (video)\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#computing-the-roots-of-the-ar-polynomial-reading",
    "href": "C4-L02.html#computing-the-roots-of-the-ar-polynomial-reading",
    "title": "90  The AR(p) process",
    "section": "91.5 Computing the roots of the AR polynomial (reading)",
    "text": "91.5 Computing the roots of the AR polynomial (reading)\nCompute AR reciprocal roots given the AR coefficients\n\n\nCode\n# Assume the folloing AR coefficients for an AR(8)\nphi=c(0.27, 0.07, -0.13, -0.15, -0.11, -0.15, -0.23, -0.14)\nroots=1/polyroot(c(1, -phi)) # compute reciprocal characteristic roots\nr=Mod(roots) # compute moduli of reciprocal roots\nlambda=2*pi/Arg(roots) # compute periods of reciprocal roots\n\n# print results modulus and frequency by decreasing order\nprint(cbind(r, abs(lambda))[order(r, decreasing=TRUE), ][c(2,4,6,8),]) \n\n\n             r          \n[1,] 0.9722428 12.731401\n[2,] 0.8094950  5.103178\n[3,] 0.7196221  2.987712\n[4,] 0.6606487  2.232193",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#simulating-data-from-an-arp-reading",
    "href": "C4-L02.html#simulating-data-from-an-arp-reading",
    "title": "90  The AR(p) process",
    "section": "91.6 Simulating data from an AR(p) (reading)",
    "text": "91.6 Simulating data from an AR(p) (reading)\n\nRcode to simulate data from an AR(2) with one pair of complex-valued reciprocal roots and plot the corresponding sample ACF and sample PACF\n\n\n\nCode\n## simulate data from an AR(2)\nset.seed(2021)\n## AR(2) with a pair of complex-valued roots with modulus 0.95 and period 12 \nr=0.95\nlambda=12 \nphi=numeric(2) \nphi[1]&lt;- 2*r*cos(2*pi/lambda) \nphi[2] &lt;- -r^2\nphi\n\n\n[1]  1.645448 -0.902500\n\n\nCode\nT=300 # number of time points\nsd=1 # innovation standard deviation\nyt=arima.sim(n=T, model = list(ar = phi), sd=sd)\n\npar(mfrow = c(3, 1), mar = c(3, 4, 2, 1), cex.lab = 1.5)\n## plot simulated data\nts.plot(yt)\n## draw sample autocorrelation function\nacf(yt, lag.max = 50,\n    type = \"correlation\", ylab = \"sample ACF\", \n    lty = 1, ylim = c(-1, 1), main = \" \")\n\n## draw sample partial autocorrelation function\npacf(yt, lag.ma = 50, main = \"sample PACF\")\n\n\n\n\n\n\n\n\n\n\nR=code to simulate data from an AR(2) with two different real-valued reciprocal roots and plot the corresponding sample ACF and sample PACF\n\n\n\nCode\n### Simulate from AR(2) with two real reciprocal roots (e.g., 0.95 and 0.5)\nset.seed(2021)\nrecip_roots=c(0.95, 0.5) ## two different real reciprocal roots\nphi=c(sum(recip_roots), -prod(recip_roots)) ## compute ar coefficients\nphi\n\n\n[1]  1.450 -0.475\n\n\nCode\nT=300 ## set up number of time points\nsd=1 ## set up standard deviation\nyt=arima.sim(n=T,model = list(ar=phi),sd=sd) # generate ar(2)\n\npar(mfrow = c(3, 1), mar = c(3, 4, 2, 1),  cex.lab = 1.5, cex.main = 1.5)\n### plot simulated data \nts.plot(yt)\n### plot sample ACF\nacf(yt, lag.max = 50, type = \"correlation\",  main = \"sample ACF\")\n### plot sample PACF\npacf(yt, lag.max = 50, main = \"sample PACF\")\n\n\n\n\n\n\n\n\n\n\nRcode to simulate data from an AR(3) with one real reciprocal root and a pair of complex-valued reciprocal roots and plot the corresponding sample ACF and sample PACF\n\n\n\nCode\n### Simulate from AR(3) with one real root \n### and a pair of complex roots (e.g., r=0.95 and lambda = 12 and real root with\n### 0.8 modulus)\nset.seed(2021)\nr= c(0.95, 0.95, 0.8) ## modulus\nlambda=c(-12, 12) ## lambda\nrecip_roots=c(r[1:2]*exp(2*pi/lambda*1i), r[3]) ## reciprocal roots\nphi &lt;- numeric(3) # placeholder for phi\nphi[1]=Re(sum(recip_roots)) # ar coefficients at lag 1\nphi[2]=-Re(recip_roots[1]*recip_roots[2] + recip_roots[1]*recip_roots[3] + recip_roots[2]*recip_roots[3]) # ar coefficients at lag 2\nphi[3]=Re(prod(recip_roots))\nphi\n\n\n[1]  2.445448 -2.218859  0.722000\n\n\nCode\nT=300 # number of time points\nsd=1 # standard deviation\nyt=arima.sim(n=T,model = list(ar=phi), sd = sd) # generate ar(3)\n\npar(mfrow = c(3,1),  mar = c(3, 4, 2, 1), cex.lab = 1.5, cex.main = 1.5)\n### plot simulated data \nts.plot(yt)\n### plot sample ACF\nacf(yt, lag.max = 50, type = \"correlation\",  main = \"sample ACF\")\n### plot sample PACF\npacf(yt, lag.max = 50, main = \"sample PACF\")",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#the-arp-review-reading",
    "href": "C4-L02.html#the-arp-review-reading",
    "title": "90  The AR(p) process",
    "section": "91.7 The AR(p): Review (Reading)",
    "text": "91.7 The AR(p): Review (Reading)\n\n91.7.1 AR(p): Definition, stability, and stationarity\n\n\n91.7.2 AR(p)\nA time series follows a zero-mean autoregressive process of order p, of AR(p), if:\n\ny_t = \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\ldots + \\phi_p y_{t-p} + \\epsilon_t \\qquad\n\\tag{91.5}\nwhere \\phi_1, \\ldots, \\phi_p are the AR coefficients and \\epsilon_t is a white noise process\nwith \\epsilon_t \\sim \\text{i.i.d. } N(0, v), for all t.\n\nThe AR characteristic polynomial is given by\n\n\\Phi(u) = 1 - \\phi_1 u - \\phi_2 u^2 - \\ldots - \\phi_p u^p,\n\nwith u complex-valued.\nThe AR(p) process is stable if \\Phi(u) = 0 only when |u| &gt; 1. In this case, the process is also stationary and can be written as\n\ny_t = \\psi(B) \\epsilon_t = \\sum_{j=0}^{\\infty} \\psi_j \\epsilon_{t-j},\n\nwith \\psi_0 = 1 and \\sum_{j=0}^{\\infty} |\\psi_j| &lt; \\infty. Here B denotes the backshift operator, so B^j \\epsilon_t = \\epsilon_{t-j} and\n\n\\psi(B) = 1 + \\psi_1 B + \\psi_2 B^2 + \\ldots + \\psi_j B^j + \\ldots\n\nThe AR polynomial can also be written as\n\n\\Phi(u) = \\prod_{j=1}^{p} (1 - \\alpha_j u),\n\nwith \\alpha_j being the reciprocal roots of the characteristic polynomial. For the process to be stable (and consequently stationary), |\\alpha_j| &lt; 1 for all j = 1, \\ldots, p.\n\n91.7.2.1 AR(p): State-space representation\nAn AR(p) can also be represented using the following state-space or dynamic linear (DLM) model representation:\n\ny_t = F' x_t,\n\n\nx_t = G x_{t-1} + \\omega_t,\n\nwith x_t = (y_t, y_{t-1}, \\dots, y_{t-p+1})', F = (1, 0, \\dots, 0)', \\omega_t = (\\epsilon_t, 0, \\dots, 0)', and\n\nG = \\begin{pmatrix}\n\\phi_1 & \\phi_2 & \\phi_3 & \\dots & \\phi_{p-1} & \\phi_p \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & & \\vdots \\\\\n0 & 0 & 0 & \\dots & 1 & 0\n\\end{pmatrix}.\n\nUsing this representation, the expected behavior of the process in the future can be exhibited via the forecast function:\n\nf_t(h) = E(y_{t+h} | y_{1:t}) = F' G^h x_t, \\quad h &gt; 0,\n\nfor any t \\ge p. The eigenvalues of the matrix G are the reciprocal roots of the characteristic polynomial.\n\n\n\n\n\n\nNoteEigenvalues\n\n\n\n\nThe eigenvalues can be real-valued or complex-valued.\nIf they are Complex-valued the eigenvalues/reciprocal roots appear in conjugate pairs.\n\n\n\nAssuming the matrix G has p distinct eigenvalues, we can decompose G into G = E \\Lambda E^{-1}, with\n\n\\Lambda = \\text{diag}(\\alpha_1, \\dots, \\alpha_p),\n\nfor a matrix of corresponding eigenvectors E. Then, G^h = E \\Lambda^h E^{-1} and we have:\n\nf_t(h) = \\sum_{j=1}^{p} c_{tj} \\alpha_j^h.\n\n\n\n91.7.2.2 ACF of AR(p)\nFor a general AR(p), the ACF is given in terms of the homogeneous difference equation:\n\n\\rho(h) - \\phi_1 \\rho(h-1) - \\ldots - \\phi_p \\rho(h-p) = 0, \\quad h &gt; 0.\n\nAssuming that \\alpha_1, \\dots, \\alpha_r denotes the characteristic reciprocal roots each with multiplicity m_1, \\ldots, m_r, respectively, with \\sum_{i=1}^{r} m_i = p. Then, the general solution is\n\n\\rho(h) = \\alpha_1^h p_1(h) + \\ldots + \\alpha_r^h p_r(h),\n\nwith p_j(h) being a polynomial of degree m_j - 1.\n\n91.7.2.2.1 Example: AR(1)\nWe already know that for h \\ge 0, \\rho(h) = \\phi^h. Using the result above, we have\n\n\\rho(h) = a \\phi^h,\n\nand so to find a, we take \\rho(0) = 1 = a \\phi^0, hence a = 1.\n\n\n91.7.2.2.2 Example: AR(2)\nSimilarly, using the result above in the case of two complex-valued reciprocal roots, we have\n\n\\rho(h) = a \\alpha_1^h + b \\alpha_2^h = c r^h \\cos(\\omega h + d).\n\n\n\n\n91.7.2.3 PACF of AR(p)\nWe can use the Durbin-Levinson recursion to obtain the PACF of an AR(p).\nUsing the same representation but substituting the true autocovariances and autocorrelations with their sampled versions, we can also obtain the sample PACF.\nIt is possible to show that the PACF of an AR(p) is equal to zero for h &gt; p.\n\n\n91.7.3 Quiz: The AR(p) process (Quiz)\nOmitted due to Coursera’s Honor Code",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#bayesian-inference-in-the-arp-reference-prior-conditional-likelihood-video",
    "href": "C4-L02.html#bayesian-inference-in-the-arp-reference-prior-conditional-likelihood-video",
    "title": "90  The AR(p) process",
    "section": "92.1 Bayesian inference in the AR(p): Reference prior, conditional likelihood (video)",
    "text": "92.1 Bayesian inference in the AR(p): Reference prior, conditional likelihood (video)\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#rcode-maximum-likelihood-estimation-arp-conditional-likelihood-reading",
    "href": "C4-L02.html#rcode-maximum-likelihood-estimation-arp-conditional-likelihood-reading",
    "title": "90  The AR(p) process",
    "section": "92.2 Rcode: Maximum likelihood estimation, AR(p), conditional likelihood (Reading)",
    "text": "92.2 Rcode: Maximum likelihood estimation, AR(p), conditional likelihood (Reading)\n\n\nCode\n  set.seed(2021)\n# Simulate 300 observations from an AR(2) with one pair of complex-valued reciprocal roots \nr=0.95\nlambda=12 \nphi=numeric(2) \nphi[1]=2*r*cos(2*pi/lambda) \nphi[2]=-r^2\nsd=1 # innovation standard deviation\nT=300 # number of time points\n# generate stationary AR(2) process\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n## Compute the MLE for phi and the unbiased estimator for v using the conditional likelihood\np=2\ny=rev(yt[(p+1):T]) # response\nX=t(matrix(yt[rev(rep((1:p),T-p)+rep((0:(T-p-1)),rep(p,T-p)))],p,T-p));\nXtX=t(X)%*%X\nXtX_inv=solve(XtX)\nphi_MLE=XtX_inv%*%t(X)%*%y # MLE for phi\ns2=sum((y - X%*%phi_MLE)^2)/(length(y) - p) #unbiased estimate for v\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_MLE, \"\\n\",\n    \"Estimate for v: \", s2, \"\\n\")\n\n\n\n MLE of conditional likelihood for phi:  1.65272 -0.9189823 \n Estimate for v:  0.9901292",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#model-order-selection-video",
    "href": "C4-L02.html#model-order-selection-video",
    "title": "90  The AR(p) process",
    "section": "92.3 Model order selection (video)",
    "text": "92.3 Model order selection (video)\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#example-bayesian-inference-in-the-arp-conditional-likelihood-video",
    "href": "C4-L02.html#example-bayesian-inference-in-the-arp-conditional-likelihood-video",
    "title": "90  The AR(p) process",
    "section": "92.4 Example: Bayesian inference in the AR(p), conditional likelihood (Video)",
    "text": "92.4 Example: Bayesian inference in the AR(p), conditional likelihood (Video)\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#rcode-bayesian-inference-arp-conditional-likelihood-reading",
    "href": "C4-L02.html#rcode-bayesian-inference-arp-conditional-likelihood-reading",
    "title": "90  The AR(p) process",
    "section": "92.5 Rcode: Bayesian inference, AR(p), conditional likelihood (Reading)",
    "text": "92.5 Rcode: Bayesian inference, AR(p), conditional likelihood (Reading)\n\n\nCode\n# Simulate 300 observations from an AR(2) with one pair of complex-valued roots \nset.seed(2021)\nr=0.95\nlambda=12 \nphi=numeric(2) \nphi[1]=2*r*cos(2*pi/lambda) \nphi[2]=-r^2\nsd=1 # innovation standard deviation\nT=300 # number of time points\n# generate stationary AR(2) process\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \npar(mfrow=c(1,1), mar = c(3, 4, 2, 1) )\nplot(yt)\n\n\n\n\n\n\n\n\n\nCode\n## Compute the MLE of phi and the unbiased estimator of v using the conditional likelihood\np=2\ny=rev(yt[(p+1):T]) # response\nX=t(matrix(yt[rev(rep((1:p),T-p)+rep((0:(T-p-1)),rep(p,T-p)))],p,T-p));\nXtX=t(X)%*%X\nXtX_inv=solve(XtX)\nphi_MLE=XtX_inv%*%t(X)%*%y # MLE for phi\ns2=sum((y - X%*%phi_MLE)^2)/(length(y) - p) #unbiased estimate for v\n\n#####################################################################################\n### Posterior inference, conditional likelihood + reference prior via \n### direct sampling                 \n#####################################################################################\n\nn_sample=1000 # posterior sample size\nlibrary(MASS)\n\n## step 1: sample v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2*p)/2, sum((y-X%*%phi_MLE)^2)/2)\n\n## step 2: sample phi conditional on v from normal distribution\nphi_sample=matrix(0, nrow = n_sample, ncol = p)\nfor(i in 1:n_sample){\n  phi_sample[i, ]=mvrnorm(1,phi_MLE,Sigma=v_sample[i]*XtX_inv)\n}\n\npar(mfrow = c(2, 3), mar = c(3, 4, 2, 1),  cex.lab = 1.3)\n## plot histogram of posterior samples of phi and v\n\nfor(i in 1:2){\n  hist(phi_sample[, i], xlab = bquote(phi), \n       main = bquote(\"Histogram of \"~phi[.(i)]),col='lightblue')\n  abline(v = phi[i], col = 'red')\n}\n\nhist(v_sample, xlab = bquote(nu), main = bquote(\"Histogram of \"~v),col='lightblue')\nabline(v = sd, col = 'red')\n\n#####################################################\n# Graph posterior for modulus and period \n#####################################################\nr_sample=sqrt(-phi_sample[,2])\nlambda_sample=2*pi/acos(phi_sample[,1]/(2*r_sample))\nhist(r_sample,xlab=\"modulus\",main=\"\",col='lightblue')\nabline(v=0.95,col='red')\nhist(lambda_sample,xlab=\"period\",main=\"\",col='lightblue')\nabline(v=12,col='red')\n\n\n\n\n\n\n\n\n\n\n92.5.1 Rcode: Model order selection (Reading)\n\n\nCode\n###################################################\n# Simulate data from an AR(2)\n###################################################\nset.seed(2021)\nr=0.95\nlambda=12 \nphi=numeric(2) \nphi[1]=2*r*cos(2*pi/lambda) \nphi[2]=-r^2\nsd=1 # innovation standard deviation\nT=300 # number of time points\n# generate stationary AR(2) process\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n#############################################################################\n######   compute AIC and BIC for different AR(p)s based on simulated data ###\n#############################################################################\npmax=10 # the maximum of model order\nXall=t(matrix(yt[rev(rep((1:pmax),T-pmax)+rep((0:(T-pmax-1)),\n              rep(pmax,T-pmax)))], pmax, T-pmax));\ny=rev(yt[(pmax+1):T])\nn_cond=length(y) # (number of total time points - the maximum of model order)\n\n## compute MLE\nmy_MLE &lt;- function(y, Xall, p){\n  n=length(y)\n  x=Xall[,1:p]\n  a=solve(t(x) %*%x)\n  a=(a + t(a))/2 # for numerical stability \n  b=a%*%t(x)%*%y # mle for ar coefficients\n  r=y - x%*%b # residuals \n  nu=n - p # degrees freedom\n  R=sum(r*r) # SSE\n  s=R/nu #MSE\n  return(list(b = b, s = s, R = R, nu = nu))\n}\n\n\n## function for AIC and BIC computation \nAIC_BIC &lt;- function(y, Xall, p){\n  ## number of time points\n  n &lt;- length(y)\n  \n  ## compute MLE\n  tmp=my_MLE(y, Xall, p)\n  \n  ## retrieve results\n  R=tmp$R\n  \n  ## compute likelihood\n  likl= n*log(R)\n  \n  ## compute AIC and BIC\n  aic =likl + 2*(p)\n  bic =likl + log(n)*(p)\n  return(list(aic = aic, bic = bic))\n}\n# Compute AIC, BIC \naic =numeric(pmax)\nbic =numeric(pmax)\n\nfor(p in 1:pmax){\n  tmp =AIC_BIC(y,Xall, p)\n  aic[p] =tmp$aic\n  bic[p] =tmp$bic\n  print(c(p, aic[p], bic[p])) # print AIC and BIC by model order\n}\n\n\n[1]    1.000 2166.793 2170.463\n[1]    2.000 1635.816 1643.156\n[1]    3.000 1637.527 1648.536\n[1]    4.000 1639.059 1653.738\n[1]    5.000 1640.743 1659.093\n[1]    6.000 1641.472 1663.491\n[1]    7.000 1643.457 1669.147\n[1]    8.000 1645.370 1674.729\n[1]    9.000 1646.261 1679.290\n[1]   10.000 1647.915 1684.614\n\n\nCode\n## compute difference between the value and its minimum\naic =aic-min(aic) \nbic =bic-min(bic) \n\n## draw plot of AIC, BIC, and the marginal likelihood\npar(mfrow = c(1, 1), mar = c(3, 4, 2, 1) )\nmatplot(1:pmax,matrix(c(aic,bic),pmax,2),ylab='value',\n        xlab='AR order p',pch=\"ab\", col = 'black', main = \"AIC and BIC\")\n# highlight the model order selected by AIC\ntext(which.min(aic), aic[which.min(aic)], \"a\", col = 'red') \n# highlight the model order selected by BIC\ntext(which.min(bic), bic[which.min(bic)], \"b\", col = 'red') \n\n\n\n\n\n\n\n\n\nCode\n########################################################\np &lt;- which.min(bic) # We set up the moder order\nprint(paste0(\"The chosen model order by BIC: \", p))\n\n\n[1] \"The chosen model order by BIC: 2\"\n\n\n\n\n92.5.2 Spectral representation of the AR(p) (video)\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.\n\n\n92.5.3 Spectral representation of the AR(p): Example (video)\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.\n\n\n92.5.4 Rcode: Spectral density of AR(p) (Reading)\n\n\nCode\n### Simulate 300 observations from an AR(2) prcess with a pair of complex-valued roots \nset.seed(2021)\nr=0.95\nlambda=12 \nphi=numeric(2) \nphi[1]&lt;- 2*r*cos(2*pi/lambda) \nphi[2] &lt;- -r^2\nsd=1 # innovation standard deviation\nT=300 # number of time points\n# sample from the AR(2) process\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n# Compute the MLE of phi and the unbiased estimator of v using the conditional likelihood \np=2\ny=rev(yt[(p+1):T])\nX=t(matrix(yt[rev(rep((1:p),T-p)+rep((0:(T-p-1)),rep(p,T-p)))],p,T-p));\nXtX=t(X)%*%X\nXtX_inv=solve(XtX)\nphi_MLE=XtX_inv%*%t(X)%*%y # MLE for phi\ns2=sum((y - X%*%phi_MLE)^2)/(length(y) - p) #unbiased estimate for v\n\n# Obtain 200 samples from the posterior distribution under the conditional likelihood and the reference prior \nn_sample=200 # posterior sample size\nlibrary(MASS)\n\n## step 1: sample v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2*p)/2, sum((y-X%*%phi_MLE)^2)/2)\n\n## step 2: sample phi conditional on v from normal distribution\nphi_sample=matrix(0, nrow = n_sample, ncol = p)\nfor(i in 1:n_sample){\n  phi_sample[i,]=mvrnorm(1,phi_MLE,Sigma=v_sample[i]*XtX_inv)\n}\n\n\n### using spec.ar to draw spectral density based on the data assuming an AR(2)\nspec.ar(yt, order = 2, main = \"yt\")\n\n\n\n\n\n\n\n\n\nCode\n### using arma.spec from astsa package to draw spectral density\nlibrary(\"astsa\")\n\n## plot spectral density of simulated data with posterior sampled \n## ar coefficients and innvovation variance\npar(mfrow = c(1, 1), mar = c(3, 4, 2, 1) )\n#result_MLE=arma.spec(ar=phi_MLE, var.noise = s2, log='yes',main = '')\nresult_MLE=arma.spec(ar=phi_MLE, var.noise = s2, main = '')\n\n\n\n\n\n\n\n\n\nCode\nfreq=result_MLE$freq\n  \nspec=matrix(0,nrow=n_sample,ncol=length(freq))\n\nfor (i in 1:n_sample){\nresult=arma.spec(ar=phi_sample[i,], var.noise = v_sample[i],# log='yes',\n                 main = '',plot=FALSE)\nspec[i,]=result$spec\n}\n\nplot(2*pi*freq,log(spec[1,]),type='l',ylim=c(-3,12),ylab=\"log spectra\",\n     xlab=\"frequency\",col=0)\n#for (i in 1:n_sample){\nfor (i in 1:2){\nlines(2*pi*freq,log(spec[i,]),col='darkgray')\n}\nlines(2*pi*freq,log(result_MLE$spec))\nabline(v=2*pi/12,lty=2,col='red')\n\n\n\n\n\n\n\n\n\n\n\n92.5.5 Quiz: Spectral representation of the AR(p)\nOmitted due to Coursera’s Honor Code\n\n\n92.5.6 Graded Assignment: Bayesian analysis of an EEG dataset using an AR(p)\nThe dataset below corresponds to a portion of an electroencephalogram (EEG) recorded in a particular location on the scalp of an individual. The original EEG dataset was originally recorded at 256Hz but was then subsampled every sixth observations, so the resulting sampling rate is about 42.7 observations per second. The dataset below has 400 observations corresponding approximately to 9.36 seconds.\nYou will use an AR(8) to model this dataset and obtain maximum likelihood estimation and Bayesian inference for the parameters of the model. For this you will need to do the following:\n\nDownload the dataset, and plot it in R. Upload a picture of your graph displaying the data and comment on the features of the data. Does it present any trends or quasi-periodic behavior?\nModify the code below to obtain the maximum likelihood estimators (MLEs) for the AR coefficients under the conditional likelihood. For this you will assume an autoregressive model of order p=8. The parameters of the model are \\phi=(\\phi_1, \\ldots \\phi_8)' snf v. You will compute the MLE of \\phi denoted as \\hat\\phi. ​\nObtain an unbiased estimator for the observational variance of the AR(8). You will compute the unbiased estimator for v denoted as s^2.\nModify the code below to obtain 500 samples from the posterior distribution of the parameters \\phi=(\\phi_1, \\ldots \\phi_8)' and v under the conditional likelihood and the reference prior. You will assume an autoregressive model of order v. Once you obtain samples from the posterior distribution you will compute the posterior means of \\phi and v, denoted as \\hat\\phi. and \\hat v, respectively.\n\nModify the code below to use the function polyroot and obtain the moduli and periods of the reciprocal roots of the AR polynomial evaluated at the posterior mean \\hat\\phi.\n\n\nCode\nset.seed(2021)\nr=0.95\nlambda=12 \nphi=numeric(2) \nphi[1]=2*r*cos(2*pi/lambda) \nphi[2]=-r^2\nsd=1 # innovation standard deviation\nT=300 # number of time points\n# generate stationary AR(2) process\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \npar(mfrow=c(1,1), mar = c(3, 4, 2, 1) )\nplot(yt)\n\n\n\n\n\n\n\n\n\nCode\n## Case 1: Conditional likelihood\np=2\ny=rev(yt[(p+1):T]) # response\nX=t(matrix(yt[rev(rep((1:p),T-p)+rep((0:(T-p-1)),rep(p,T-p)))],p,T-p));\nXtX=t(X)%*%X\nXtX_inv=solve(XtX)\nphi_MLE=XtX_inv%*%t(X)%*%y # MLE for phi\ns2=sum((y - X%*%phi_MLE)^2)/(length(y) - p) #unbiased estimate for v\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_MLE, \"\\n\",\n    \"Estimate for v: \", s2, \"\\n\")\n\n\n\n MLE of conditional likelihood for phi:  1.65272 -0.9189823 \n Estimate for v:  0.9901292 \n\n\nCode\n#####################################################################################\n##  AR(2) case \n### Posterior inference, conditional likelihood + reference prior via \n### direct sampling                 \n#####################################################################################\n\nn_sample=1000 # posterior sample size\nlibrary(MASS)\n\n## step 1: sample v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2*p)/2, sum((y-X%*%phi_MLE)^2)/2)\n\n## step 2: sample phi conditional on v from normal distribution\nphi_sample=matrix(0, nrow = n_sample, ncol = p)\nfor(i in 1:n_sample){\n  phi_sample[i, ]=mvrnorm(1,phi_MLE,Sigma=v_sample[i]*XtX_inv)\n}\n\n## plot histogram of posterior samples of phi and nu\npar(mfrow = c(1, 3),  mar = c(3, 4, 2, 1), cex.lab = 1.3)\nfor(i in 1:2){\n  hist(phi_sample[, i], xlab = bquote(phi), \n       main = bquote(\"Histogram of \"~phi[.(i)]))\n  abline(v = phi[i], col = 'red')\n}\n\nhist(v_sample, xlab = bquote(nu), main = bquote(\"Histogram of \"~v))\nabline(v = sd, col = 'red')",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L02.html#arima-processes-reading",
    "href": "C4-L02.html#arima-processes-reading",
    "title": "90  The AR(p) process",
    "section": "92.6 ARIMA processes (Reading)",
    "text": "92.6 ARIMA processes (Reading)\n\n\n\n\n\n\nNoteARMA Model Definition\n\n\n\nA time series process is a zero-mean autoregressive moving average process if it is given by\n\ny_t = \\textcolor{red}\n                {\\underbrace{\\sum_{i=1}^{p} \\phi_i y_{t-i}}_{AR(P)}}\n      +\n      \\textcolor{blue}{\\underbrace{\\sum_{j=1}^{q} \\theta_j \\epsilon_{t-j}}_{MA(Q)}} + \\epsilon_t \\qquad \\text{(ARMA(p, q))}\n\\tag{92.1}\nwith \\epsilon_t \\sim N(0, v).\n\nFor q = 0, we get an AR(p) process.\nFor p = 0, we get a MA(q) i.e. moving average process of order q.\n\n\n\nNext we will define the notions of stability and invertibility of an ARMA process.\n\n92.6.0.1 Stability Definition\nAn ARMA process is stable if the roots of the AR characteristic polynomial stable\n\n\\Phi(u) = 1 - \\phi_1 u - \\phi_2 u^2 - \\ldots - \\phi_p u^p\n\nlie outside the unit circle, i.e., for all u such that \\Phi(u) = 0, |u| &gt; 1.\nEquivalently, this happens when the reciprocal roots of the AR polynomial have moduli smaller than 1.\nThis condition implies stationarity.\n\n\n92.6.0.2 Invertible ARMA Definition\nAn ARMA process is invertible if the roots of the MA characteristic polynomial given by invertible\n\n\\Theta(u) = 1 + \\theta_1 u + \\ldots + \\theta_q u^q,\n\\tag{92.2}\nlie outside the unit circle.\n\nNote that \\Phi(B) y_t = \\Theta(B) \\epsilon_t.\n\nWhen an ARMA process is stable, it can be written as an infinite order moving average process.\nWhen an ARMA process is invertible, it can be written as an infinite order autoregressive process.\n\n\n92.6.0.3 ARIMA Processes\nAn autoregressive integrated moving average process with orders p, d, and q is a process that can be written as\n\n(1 - B)^d y_t = \\sum_{i=1}^{p} \\phi_i y_{t-i} + \\sum_{j=1}^{q} \\theta_j \\epsilon_{t-j} + \\epsilon_t,\n\\tag{92.3}\nwhere B is the backshift operator, d is the order of integration, and \\epsilon_t \\sim N(0, v).\nin other words, y_t follows an ARIMA(p, d, q) if the d difference of y_t follows an ARMA(p, q).\n\nEstimation in ARIMA processes can be done via least squares, maximum likelihood, and also in a Bayesian way. We will not discuss Bayesian estimation of ARIMA processes in this course.\n\n92.6.1 Spectral Density of ARMA Processes\nFor a given AR(p) process with AR coefficients \\phi_1, \\dots, \\phi_p and variance v, we can obtain its spectral density as\n\nf(\\omega) = \\frac{v}{2\\pi |\\Phi(e^{-i\\omega})|^2} = \\frac{v}{2\\pi |1 - \\phi_1 e^{-i\\omega} - \\ldots - \\phi_p e^{-ip\\omega}|^2},\n\\tag{92.4}\nwith \\omega a frequency in (0, \\pi).\nThe spectral density provides a frequency-domain representation of the process that is appealing because of its interpretability.\nFor instance, an AR(2) process that has one pair of complex-valued reciprocal roots with modulus 0.7 and a period of \\lambda = 12, will show a mode in the spectral density located at a frequency of 2\\pi/12. If we keep the period of the process at the same value of 12 but increase its modulus to 0.95, the spectral density will continue to show a mode at 2\\pi/12, but the value of f(2\\pi/12) will be higher, indicating a more persistent quasi-periodic behavior.\nSimilarly, we can obtain the spectral density of an ARMA process with AR characteristic polynomial \\Phi(u) = 1 - \\phi_1 u - \\ldots - \\phi_p u^p and MA characteristic polynomial \\Theta(u) = 1 + \\theta_1 u + \\ldots + \\theta_q u^q, and variance v as\n\nf(\\omega) = \\frac{v}{2\\pi} \\frac{|\\Theta(e^{-i\\omega})|^2}{|\\Phi(e^{-i\\omega})|^2}.\n\\tag{92.5}\nNote that if we have posterior estimates or posterior samples of the AR/ARMA coefficients and the variance v, we can obtain samples from the spectral density of AR/ARMA processes using the equations above.",
    "crumbs": [
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>The AR(p) process</span>"
    ]
  },
  {
    "objectID": "C4-L03.html",
    "href": "C4-L03.html",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "",
    "text": "92 The Normal Dynamic Linear Model: Definition, Model classes & The Superposition Principle\nNormal Dynamic Linear Models (NDLMs) are defined and illustrated in this module using several examples Model building based on the forecast function via the superposition principle is explained. Methods for Bayesian filtering, smoothing and forecasting for NDLMs in the case of known observational variances and known system covariance matrices are discussed and illustrated..\nThe Normal Dynamic Linear Model (DLM) is covered (R. Prado, Ferreira, and West 2023, 117–44)\nDynamic Linear Models (DLMs) extend classical linear regression to time-indexed data, introducing dependencies between observations through latent evolving parameters. A Normal DLM (NDLM) assumes Gaussian noise at both observation and system levels, enabling tractable Bayesian inference through the Kalman filter.\nWhile superficially complex, NDLMs are conceptually close to linear regression. Instead of I.I.D. observations indexed by i, we index data by time t and allow parameters to evolve with time, resulting in a two-level hierarchical model. At the top level is the observation equation. Below this there is the evolution equation(s) that can be understood as a latent state transition model that can capture trends, periodicity, and regression. The evolution equations can have more than one level however we will see that with some work these are summarized into a matrix form.\nTo make things simpler this is demonstrated using a white noise process and then a random walk model. What makes the NDLM somewhat different is that that there are two variance elements at two levels, necessitating learning more parameters. Once we cover these to models the instructor walks us though all the bits and pieces of the notation. Later we will see that we can add trends, periodicity, regression components in a more or less systematic way. However we need to pick and choose these components to get a suitable forecast function. This approach require an intimate familiarity with the data generating process to model.\nThis approach is Bayesian in that we draw our parameters from a multivariate normal and use updating to improve this initial estimate by incorporating the data and we end up with a posterior i.e. we have distributional view of the time series incorporating uncertainties. Additionally we have a number of Bayesian quantities that can be derived from the model, such as\nHowever the DLM framework is quite flexible and once you understand it it can ve adapted to support features like seasonality using the superposition principle. NDLMs don’t need to be non-stationary time series.\nAs far as I cen tell NDLMs are just DLM with their errors distributed normally at the different levels.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#ndlm-definition-video",
    "href": "C4-L03.html#ndlm-definition-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.1 NDLM Definition (Video)",
    "text": "92.1 NDLM Definition (Video)\n\n\n\n\nNDLM Motivation\n\n\n\n\nNDLM general form\n\n\n\n\nthe forecast function\n\n\n\n\nIn this module, we will motivate and develop a class of models suitable for for analyzing and forecasting non-stationary time series called normal dynamic linear models . We will talk about Bayesian inference and forecasting within this class of models and describe model building as well.\n\n92.1.1 White Noise - A motivating example\nLet’s begin with a very simple model that has no temporal structure, just a mean value with some variation that is:\n\ny_t = \\mu + v_t \\qquad v_t \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, \\nu) \\qquad  \\text{(white noise model)}\n\\tag{92.1}\nwhere:\n\ny_t is the observed time series at time t,\n\\mu is the expected value of y_t this is characteristic we are interested in,\n\\nu_t is a white noise process as usual iid standard normal N(0,1).\n\nIf we plot this model we might see the following graph:\n\n\nCode\nset.seed(123)\nn &lt;- 100\nV &lt;- 1\nmu &lt;- 0\ny &lt;- mu + rnorm(n, 0, V)\nplot(y, type = \"l\", col = \"blue\", lwd = 2, xlab = \"Time\", ylab = \"y\", main = \"Model with no temporal structure\")\n\n\n\n\n\n\n\n\nFigure 92.1\n\n\n\n\n\nFor this model the mean of the time series is \\mu will be the the expected value of y_t, which is \\mu. And the variance of y_t is \\nu.\n\n\\mathbb{E}[y_t] = \\mu \\qquad \\text{and} \\qquad \\mathbb{V}ar[y_t] = \\nu \\qquad\n\\tag{92.2}\n\n\n92.1.2 A Random walk model with a slowly changing mean\nNext we incorporate some temporal structure, we allow the expected value of the time series, to change over time. To can achieve this, by update the model definition with a \\mu_t where the index indicates that it can change at every time step. And let us keep the noise unchanged. i.e. we set it to \\mu_t \\in N(0,\\nu).\nWe get the following model:\n\ny_t = \\mu_t + \\nu_t \\quad \\nu_t \\overset{\\text{iid}}{\\sim} N(0, V) \\qquad \\text{(radom walk model)}\n\\tag{92.3}\nTo complete this we need to also decide how to incorporate the the changes over time in the parameter \\mu_t. We might consider different options but we should pick the simplest possible to start with. One option is to assume that the expected value of \\mu_t is just the expected value of \\mu_{t-1} plus some noise.\nWe now have that random walk type of structure where \\mu_t can be written in terms of \\mu(t-1). The expected value of \\mu_t, we can think of it as \\mu_{t-1} + \\text{some noise}. This error is once again, assumed to be normally distributed random variable centered at zero and with variance W. Another assumption that we have made here is that the \\nu_t and \\omega_t, are also independent of each other.\nputting this together we get:\n\n\\begin{aligned}\ny_t &= \\mu_t + \\nu_t & \\nu_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, V)  & \\text{(Observation eq.)} \\\\\n\\mu_t &= \\mu_{t-1} + \\omega_t  & \\omega_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, W) & \\text{(System/evolution eq.)}\n\\end{aligned}\n\\tag{92.4}\nWith this model, what we are assuming is that the mean level of the series is changing over time. Note that this is an example of a Gaussian or Normal dynamic linear model.\nNDLMs are a two level hierarchical models where :\n\nAt the top is an observation level equation relating observations y at time t to some time dependent, (hidden) state parameters and some observation level iid distributed error.\nThe system evolution level equation describes the dynamics of parameters over time and incorporates some system iid distributed error.\nThese equations have a linear structure, in the sense that the expected value of y at time t is a linear function of the parameters.\nWe have the assumption of normality for the noise terms in both these equations as well as independence within and between levels.\n\nThis is our first example. Next we will be discuss the general class of models. Later we will consider how to incorporate different structures into the model, and how to perform Bayesian inference for filtering smoothing and forecasting.\n\n\n92.1.3 General form of the NDLM\nThe general class of dynamic linear models can be written as follows:\nWe are going to have two equations. One is the so-called observation equation that relates the observations to the parameters in the model, and the notation we are going to use is as follows.\n\\begin{aligned}\ny_t &= \\vec{F}_t' \\vec{\\theta}_t   + \\nu_t && \\nu_t \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, V_t) && \\text{(obs)} \\\\\n\\vec{\\theta}_t &= G_t \\vec{\\theta}_{t-1} + \\vec{\\omega}_t && \\vec{\\omega}_t \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, W_t) && \\text{(system)}\n\\end{aligned}\n\\tag{92.5}\nWhere:\n\ny_t a univariate observation at time t.\n\\vec{\\theta}_t the state vector is a k-dimensional vector of unknown parameters at time t.\n\\vec{F_t} the observation operator a k*1-dimensional vector at time t that transforms the state parameters into observations.\n\\nu_t is the observation noise at time t from a Normal distribution with variance V_t.\nG_t the state evolution operator is a k \\times k matrix (known)\n\\omega_t the innovation or state evolution noise at time t distributed as N(0,W_t)(known)\nthe noise at the observation level and the system level are each iid and mutually iid.\n\nWe also have the prior distribution for the state vector at time 0:\n\n\\vec{\\theta}_0 \\sim N(\\vec{m}_0,c_0) a prior k-dimensional Normal distribution.\n\nm_0 the mean in the prior is a k-dimensional vector of means. (known)\nc_0 is the covariance matrix k by k. (known)\n\n\n\n\n\n\n\n\nNoteSome Thoughts on NDLM the definition\n\n\n\n\n\nQ. Why are F_t and G_t a vector and a matrix respectively?\n\nIt may helps to think about F and G as follows:\nF_t' acts as a linear transformation that maps the latent state \\vec{\\theta}_t into the observation space, of y.\nG_t is a linear transformation that describes how the state vector evolves over time. I like to think about it as a Hidden Markov state transition matrix.\nIn other words, F_t takes the current hidden state \\theta_t and produces an observation y_t, while G_t takes the current state and produces the next state.\n\nQ. Why is this called a linear model?\n\nThis is because both the observation equation is a linear equation that relates the observations to the parameters in the model and the system equation is a linear equation that tells us how the time-varying parameter is going to be changing over time. This is why we call this a linear model.\n\nQ. Why are the noise terms \\nu_t and \\omega_t assumed to be normally distributed?\n\nThis is a common assumption in time series analysis. It is a convenient assumption that allows us to perform Bayesian inference and forecasting in a very simple way. And this is why we call this a normal dynamic linear model.\n\nQ. Isn’t this just a hierarchical model?\n\nIndeed, this is a hierarchical model. We have a model for the observations and a model for the system level. The system level is changing over time and the observations are related to the system level through the observation equation. And so it is possible to extend this model to more complex structures if we wish to do so by adding another level, etc… However adding more levels leads to extra dynamics that are captured in G without changing the overall framework!\n\n\n\n\n\n\n92.1.4 Inference in the NDLM\nIn terms of the inference, there are a few different kinds of densities and quantities that we are interested in:\n One of the distributions that we are interested in finding is the so-called filtering distribution. We may be interested here in finding what is the density of \\theta_t given all the observations that we have up to time t.Filtering distribution\n\n\\mathcal{D}_t= \\{\\mathcal{D}_0, y_{1:T}\\}\n\\tag{92.6}\nWe will denote information as \\mathcal{D}_t. Usually, it is all the information we have at time zero (i.e. our prior), coupled with all the data points I have up to time t.\nHere we conditioning on all the observed quantities and the prior information up to time t, and I may be interested in just finding what is the distribution for \\theta_t. This is called filtering.\n\n\\mathbb{P}r(\\theta_t \\mid \\mathcal{D}_t) \\qquad \\text{filtering distribution}\n\\tag{92.7}\nforecasting distribution\nAnother distribution that is very important in time series analysis is the forecasting distribution. We may be interested in the distribution of y{t+h}? where we consider h lags into the future and we have all the information \\mathcal{D}_t, up to time t. We want to do a predictions here\n\n\\mathbb{P}r(y_{t+h} \\mid \\mathcal{D}_t) \\qquad \\text{forecasting distribution}\n\\tag{92.8}\n Another important quantity or an important set of distributions is what we call the smoothing distribution. Usually, you have a time series, when you get your data, you observe, I don’t know, 300 data points. As you go with the filtering, you are going to start from zero all the way to 300 and you’re going to update these filtering distributions as you go and move forward. We may want instead to revisit the parameter at time 10, for example, given that you now have observed all these 300 observations. In that case, you’re interested in densities that are of the form. Let’s say that you observe capital T in your process and now you are going to revisit that density for \\theta_t. This is now in the past. Here we assume that t&lt;T. This is called smoothing.Smoothing Distribution\nSo you have more observation once you have seen the data. We will talk about how to perform Bayesian inference to obtain all these distributions under this model setting.\n\n\\mathbb{P}r(\\theta_t \\mid \\mathcal{D}_T)  \\qquad t &lt; T \\qquad \\text{smoothing distribution}\n\\tag{92.9}\n\n\n92.1.5 The forecast function for the NDLM\nIn addition to all the structure that we described before and all the densities that we are interested in finding, we also have as usual, the so-called forecast function, which instead of being the density is just \\mathbb{E}[y(t+h)\\mid \\mathcal{D}_t] i.e. expected value of y at time t given all the information we have before time t.\n\n\\mathbb{E}[y(t+h)\\mid \\mathcal(D_t)] = F'_{t+h} G_{t+h} \\ldots G_{t+1} \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t]\n\\tag{92.10}\nThis is the form of the forecast function.\nThere are particular cases and particular models that we will be discussing in which the F_t=F, i.e. constant and also G_t = G is also constant for all t. In these cases, the forecast function can be simplified and written as:\n\nf_t(h) = \\mathbb{E}(y_{t+h} \\mid D_t) = F'G^h \\mathbb{E}(\\theta_t \\mid \\mathcal{D}_t)\n\\tag{92.11}\nOne thing that we will learn is that the eigen-structure of this matrix is very important to define the form of the forecast function, and it’s very important for model building and for adding components into your model.\n\n\n92.1.6 NDLM short form notation\nFinally, just in terms of short notation, we can always write down when we’re working with normal dynamic linear models, we may be referring to the model instead of writing the two equations, the system and the observation equation. I can just write all the components that define my model. \n\\{F_t, G_t, v_t, W_t\\}\n\\tag{92.12}\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nIn this part of the course, I will discuss the class of normal dynamic linear models for analyzing and forecasting non-stationary time series. We will talk about Bayesian inference and forecasting within this class of models and describe model building as well.\n\n92.1.7 Motivating example\nI want to begin first with a motivating example. Suppose you have a model that is very simple and has no temporal structure here, just a model that looks like this. You have your time series y_t. Then you’re interested in just thinking about what is the mean level of that time series. That mean level, I’m going to call it \\mu and then I have some noise and the noise is normally distributed. They are all independent, identically distributed normal random variables \\Normal(0,v). Again, I can think of my time series. Suppose that I have my time series here, and then I’m plotting y_t. Then I have something that looks like this. In this model that \\mu is going to try to get the mean of that time series, this expected value of y_t, which is \\mu. The variance here of y_t is v under this model. What may happen in practice again, this model has no temporal structure, I may want to incorporate some temporal structure that says, well, I think that the level of this, the expected value of this time series, should be changing over time. If you were to do that, you will write down a model where the mu changes over time, so it’s indexed in time. Then you have still your same noise here. Let’s again assume \\Normal(0,v). I have now to make a decision on how I’m going to incorporate temporal structure by modeling the changes over time in this parameter \\mu_t. You could consider different options.\nThe simplest possible, probably that you can consider is something that looks like this. You have that random walk type of structure where \\mu_t is now going to be written as \\mu_{t-1}. The expected value of \\mu_t, you’ll think of it as \\mu_{t-1} plus some noise. That error here is going to be again, assume normally distributed random variable centered at zero and with variance w. There is another assumption that we can make here and is that the nu t and omega t here, are also independent of each other. When I have this model, what am assuming here is that the mean level of the series is changing over time.\nThese type of models have a few characteristics. This is an example of a normal dynamic linear model, as we will see later. In this models, we usually have a few things.\nThe first thing is we have two equations. One is the so-called observation equation that is relating your y_t, your observed process to some parameters in the model that are changing over time. The next equation is the so-called system level equation or evolution equation that tells me how that time varying parameter is going to be changing over time. The other thing you may notice is that we have a linear structure both in the observational level and in the system level. The linear structure, in the sense of the expected value of y_t is just a linear function of that \\mu_t. It happens to be \\mu_t in this particular case. In the second level, I can think of the expected value of \\mu_t as a linear function given \\mu_{t-1}, so it’s a function that is linear on \\mu_{t-1}. There is that linear structure. The other thing that we have here is at both levels, we have the assumption of normality for the noise terms in those equations. This is an example of a Gaussian or normal dynamic. These are time-varying parameters linear model. We will be discussing the general class of models. This is just an example. We will also discuss how to build different structures into the model, as well as how to perform Bayesian inference and forecasting.\n\n\n92.1.8 General form of the model\nThe general class of dynamic linear models can be written as follows. Again, we are going to have two equations. One is the so-called observation equation that relates the observations to the parameters in the model, and the notation we are going to use is as follows. Here, my observations are univariate. We are discussing models for univariate time series. I have that related to a vector of parameters, Theta_t plus some noise here. This is the noise. The noise are assumed to be independent, identically distributed normal random variables, 0, V_t. Then I have another equation which is a system equation that has this form. There is a general G_t matrix. This is going to be depending on \\theta_{t-1}. This is a vector, and then I have again, these are iid multivariate \\Normal(0, W_t). This is the observation equation. This is the system equation or evolution equation. This defines a normal dynamic linear model. Here, we are going to say that F_t is a vector. The dimension of the vector is going to be the same as the number of parameters in the model. Let’s say we have k. This is a vector of known values. For each t, we are going to assume that we know what that vector is. Then we have the vector of parameters here is also of dimension k of parameters. The G is the next thing we need to define is a known matrix. That one is also assumed to be known, and then I have V_t is variance at the observational level. The W_t we are going to assume at the beginning that these two quantities are also known for all the values t. This is the variance-covariance matrix at the system level. Again, if we think about these two equations, we have the model defined in this way.\nThere is a next piece that we need to consider if we are going to perform based in inference for the model parameters. The next piece that we need to consider to just fully specify the model is what is the prior distribution. In a normal dynamic linear model, the prior distribution is assumed to be conjugate here. In the case again in which V_t and W_t are known, we are going to be assuming that, say that zero, the parameter vector before observing any data is going to be normally distributed Multivariate normal with M_0 and C_0. The mean is a vector, again of the same dimension as \\theta_0. Then I have k by k covariance matrix there as well. These are assumed to be also given to move forward with the model.\n\n\n92.1.9 Inference, forcasting, smoothing, and filtering.\nIn terms of the inference, there are different kinds of densities and quantities that we are interested in. One distribution that we are interested in finding is the so-called filtering distribution. We may be interested here in finding what is the density of \\theta_{t} given all the observations that we have up to time t. I’m going to call and all the information that I have up to time t. I’m going to call that D_t . It can also be, in some cases, I will just write down. So D_t, you can view with all the info up to time t. Usually, it is all the information I have at time zero. Then coupled, if there is no additional information that’s going to be coupled with all the data points I have up to that time. Here I’m conditioning on all the observed quantities and the prior information up to time t, and I may be interested in just finding what is the distribution for \\theta_{t}.\nThis is called filtering. Another quantity that is very important in time series analysis is forecasting.\nI may be interested in just what is the density, the distribution of y_{t+h} ? Again, the number of steps ahead here, here I’m thinking of h, given that I have all this information up to time t. I’m interested in predictions here. We will be talking about forecasting. Then another important quantity or an important set of distributions is what we call the smoothing distribution. Usually, you have a time series, when you get your data, you observe, I don’t know, 300 data points. As you go with the filtering, you are going to start from zero all the way to 300 and you’re going to update these filtering distributions as you go and move forward. But then you may want to revisit your parameter at time 10, for example, given that you now have observed all these 300 observations. In that case, you’re interested in densities that are of the form. Let’s say that you observe capital T in your process and now you are going to revisit that density for \\theta_t. This is now in the past. Here we assume that t is smaller than capital T. This is called smoothing. So you have more observation once you have seen the data. We will talk about how to perform Bayesian inference to obtain all these distributions under this model setting.\n\n\n92.1.10 The forecast function\nIn addition to all the structure that we described before and all the densities that we are interested in finding, we also have as usual, the so-called forecast function, which is just instead of being the density is just expected value of y(t+h) given all the information I have up to time t. In the case of a general normal dynamic linear model, we have the structure for these just using the equations, the observation and the system of equations.\nWe’re going to have here G_{t+h}. We multiply all these all the way to G_(t+1), and then we have the \\mathbb{E}[\\theta_{t}\\mid D_t]. This is the form of the forecast function. There are particular cases and particular models that we will be discussing in which the F_t is equal to F, so is constant for all t and G_t is also constant for all t. In those cases, the forecast function can be simplified and written as F'G^h expected value. One thing that we will learn is that the eigen-structure of this matrix is very important to define the form of the forecast function, and it’s very important for model building and for adding components into your model.\n\n\n92.1.11 Short-form notation\nFinally, just in terms of short notation, we can always write down when we’re working with normal dynamic linear models, we may be referring to the model instead of writing the two equations, the system and the observation equation. I can just write all the components that define my model. This fully specifies the model in terms of the two equations. If I know what Ft is, what Gt is, what Vt is, and the covariance at the system level. I sometimes will be just talking about a short notation like this for defining the model.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#polynomial-trend-models-video",
    "href": "C4-L03.html#polynomial-trend-models-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.2 Polynomial Trend Models (Video)",
    "text": "92.2 Polynomial Trend Models (Video)\n\n\n\n\nfirst and second order polynomial model\n\n\n\n\np-order polynomial model\n\n\nWhile we haven’t talked about the superposition principle yet we start at looking at adding different components to the DLM.\nWe might :\n\nsetting a baseline mean and variance\nadding a random walk with its variance\nadd a trend\nadd a regression\nadd seasonality\n\nNext we want to extend the random walk model to include different types of trends and this will be covered by the polynomial trend models. These are models that are useful to model linear trends or polynomial trends in your time series. So if you have a data set, where you have an increasing trend, or a decreasing trend, you would use one of those components in your model. Also\n\n92.2.1 First order polynomial model\nThe first order model is developed at great detail in chapter In (West and Harrison 2013 ch. 2). I don’t know what to make of it, isn’t this a trivial white noise model?\nThe math for Bayesian updating is fairly straight forward and must be much more complex with more sophisticated dynamics. So this is used by the authors to introduce their DLM and an 30 pages of the book is dedicated to in depth analysis and Bayesian development of this specific model and different distribution of interests as well as including comparison to other models and a look at the signal to noise ratio in the model.\nIt is worthwhile pointing out that these models get their name from their forecast function which will takes the general form Equation 92.22\nThe first order polynomial model is a model that is useful to describe linear trends in your time series. If you have a data set where you have an increasing trend or a decreasing trend, you would use one of those components in your model.\nSo the all those can be incorporated using the general p-order polynomial model, so I will just describe the form of this model.\nA first order polynomial is of the form Ax+B where A is the slope and B is the intercept. This is the same random walk model we saw above.\n\n\\begin{aligned}\ny_t &= \\theta_t + \\nu_t, \\qquad & \\nu_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, V_t) \\\\\n\\theta_t &= \\theta_{t-1} + \\omega_t, \\qquad & \\omega_t & \\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, W_t) \\\\\n&\\{1,1,v_t,W_t\\} && \\text{(short form)}\\\\\nf_t(h) &= \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t] && \\text{(forecast fn)}\\\\\n\\end{aligned}\n\\tag{92.13}\nIn the observation equation, \\theta_{t} is the level of the series at time t and \\nu_t is the observation error. In the evolution equation we see the mean for this parameter changing over time as a random walk or a local constant mean with evolution noise \\omega_t.\n(West and Harrison 2013, sec. 2.1) gives the following representation of the model:\nIt is useful to think of \\theta_t as a smooth function of time \\theta(t) with an associated Taylor series representation\n\n\\theta(t + \\delta t) = \\theta(t) + \\text{higher-order terms}\n\\tag{92.14}\nwhere the higher-order terms are assumed to be zero-mean noise. This is a very important point, because it means that we are not trying to model the higher-order terms explicitly, but rather we are assuming that they are just noise.\nwith the model simply describing the higher-order terms as zero-mean noise.\nThis is the genesis of the first-order polynomial DLM: the level model is a locally constant (first-order polynomial) proxy for the underlying evolution.·\nWe can write it down in short form with the following quadruple/\n\n\\{1, 1, V_t, W_t\\} \\qquad f_t(h) = \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t] = k_t \\ \\forall   h&gt;0\n\\tag{92.15}\nNext we can write the forecast function f_t(h) of this model using the representation we gave in Equation 92.15.\nAgain, we’re going to have something of the form F transposed G to the power of h and then the expected value of that \\theta_t given \\mathcal{D}_t. F is 1, G is 1, therefore I’m going to end up having just expected value of \\theta_t given \\mathcal{D}_t.\nWhich depending on the data that you have is you’re just going to have something that is a value that depends on t and it doesn’t depend on h. What this model is telling you is that the forecast function, how you expect to see future values of the series h steps ahead is something that looks like the level that you estimated at time t.\n\n\n92.2.2 Second order Polynomial model AKA Linear Growth model\n(West and Harrison 2013, secs. 7.1–7.2) gives a detailed analysis of this model.\nNow we want to create a model in which captures things that has a linear trend either increasing or decreasing. To do thus we need to have two components in our parameter vector of the state vector. For this we will need two components in our parameter vector of the state vector1.\nSo we have again something that looks like in my observation equation. I’m going to have, I’m going to call it say \\theta_{t,1} \\sim  \\mathcal{N}(v_t), and then I’m going to have say \\theta_{t,1} is going to be of the form to \\theta_{t-1,1} and there is another component here. The other component enters this equation plus let’s call this \\theta_{t-1,2}. And then I have finally also I need an evolution for the second component of the process which is going to be again having a random walk type of behavior.\n\\begin{aligned}\n  y_t &= \\theta_{t,1} + \\nu_t \\quad &\\nu_t &\\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, v_t) \\\\\n  \\theta_{t,1} &= \\theta_{t-1,1} + \\theta_{t-1,2} + \\omega_{t,1} \\qquad &\\omega_{t,1} &\\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, w_{t,11}) \\\\\n  \\theta_{t,2} &= \\theta_{t-1,2} + \\omega_{t,2} \\qquad &\\omega_{t,2} &\\overset{\\text{iid}}{\\sim}  \\mathcal{N}(0, w_{t,22})\n\\end{aligned}\n\\tag{92.16}\nSo there are different ways in which you can interpret this two parameters but essentially:\n\n\\theta_{t-1,1} is related to the baseline level of the series\n\\theta_{t-1,2} is related to the rate of change of the of the series.\n\n\n\n\n\n\n\nTipShort form DLM notation\n\n\n\n\n\n\nHaving the short form notation makes the model easier to understand in relation to other DLM models.\nIt will soon be instrumental in communicating the model structure with different software packages.\n\n\n\n\nNext we should summarize this model using the familiar short form DLM representation, which requires a bit of creative algebra.\n\n\\mathbf{\\theta}_t = (\\theta_{t,1}, \\theta_{t,2}) \\qquad \\{\\mathbf{F}, \\mathbf{G}, V_t, \\mathbf{W}_t\\}\n\nFirst we collect the two variances for the evolution two components into the vector \\utilde{w}_t and then assume that this w_t is Normal. Now this is a bi-variate normal.\n\n\\utilde{\\omega}_t = (\\omega_{t,1},\\omega_{t,2})' \\qquad \\utilde{\\omega}_t \\sim  \\mathcal{N}(0,W_t)\n\nSo what would be my F and my G in this model? So again my theta vector has two components, thus my G, so my F is going to be a two dimensional. We can write down F transposed as the only component that appears at this level is the first component of the vector. I’m going to have 1 and then a zero for F transposed. c.f. Equation 92.17 And then my G here if you think about writing down \\theta_t times G say the t-1 + \\omega_t. Then you have that you’re G is going to have this form.\n\n\\begin{aligned}\n\\mathbf{F} &= (1,0)' & V_t &= v_t \\\\\n\\mathbf{G} &= \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n& \\mathbf{W}_t &= \\begin{pmatrix} w_{t,11} & 0 \\\\ 0 & w_{t,22} \\end{pmatrix}\n\\end{aligned}\n\\tag{92.17}\nthis is the form from the video \n\\begin{aligned}\n\\mathbf{F} &= (1,0)' & V_t &= v_t \\\\\n\\mathbf{G} &= \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n& \\mathbf{W}_t &= \\begin{pmatrix} w_{t,11} & w_{t,12} \\\\ w_{t,21} & w_{t,22} \\end{pmatrix}\n\\end{aligned}\n\\tag{92.18}\nthis is the more general form from the handout. Note that in this case we have w_{t,12}=w_{t,21} so there is just one extra parameter.\nThe lesson videos and the handouts differ in the form \\mathbf{W}_t. In the lecture we assumed zero covariance but in the handout the covariance was snuck in. This gives us a slightly more general model. The covariance though is symmetric so we get an extra parameter we need to infer and include in the prior. Anyhow I kept the more general form, though in most cases we will keep the off diagonal terms at zero.\nSo for the first component, I have past values of both components. That’s why I have a 1 and 1 here for the second component I only have the past value of the second component. So there is a zero and a 1. So this tells me what is the structure of this second order polynomial. If I think about how to obtain the forecast function for this second order polynomial is going to be very similar to what we did before. So you can write it down as F transposed G to the power of h, expected value of theta t given Dt. Now the expected value is going to be vector also with two components because theta_t is a two dimensional vector. The structure here if you look at what G is G to the power of h going to be a matrix, that is going to look like 1, h, 0 1. When you multiply that matrix time this times this F what you’re going to end up having is something that looks like 1 h times this expected value of theta t given Dt. So I can think of two components here, so this gives you a constant on h, this part is not going to depend on h. So I can write this down as k t 11 component multiplied by 1 and then I have another constant, multiplied by h. So you can see what happens now is that your forecast function has the form of a linear polynomial. So it’s just a linear function on the number of steps ahead. The slope and the intercept related to that linear function are going to depend on the expected value of, theta_t given the all the information I have up to time t. But essentially is a way to model linear trends. So this is what happens with the second order polynomial model.\nAs we included linear trends and constant values in the forecast function, we may want to also incorporate other kinds of trends, polynomial trends in the model. So you may want to have a quadratic form, the forecast function or a cubic forecast function as a function of h.\n\n\\theta_t = (\\theta_{t,1}, \\theta_{t,2})' \\qquad \\mathbf{G} = \\mathbf{J}_2(1) \\qquad \\mathbf{E}_2 = (1, 0)'\n\n\n\\mathbf{G^h} = \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n\n\n\\begin{aligned}\nf_t(h) &= F' G^h \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t] \\\\\n&= (1,h) \\mathbb{E}[\\theta_{t}\\mid D_t] \\\\\n&= (1,h)(K_{t,0}, K_{t,1})' \\\\\n&= (K_{t,0} + K_{t,1} h)\n\\end{aligned}\n\\tag{92.19}\n\n\\begin{aligned}\n\\mathbf{G^h} &= \\begin{pmatrix} 1 & h \\\\ 0 & 1 \\end{pmatrix}\n\\end{aligned}\n\\tag{92.20}\n\n\n92.2.3 General p-th order polynomial model\nWe can consider a so called p-th order polynomial model. This model will have a state-space vector of dimension p and a polynomial of order p − 1 forecast function on h. The model can be written as\n\n\\{E_p, J_p(1), v_t, W_t\\}\n\nwith F_t = E_p = (1, 0, \\ldots, 0)′ and G_t = J_p(1), with\n\nJ_p(1) = \\begin{pmatrix}\n1 & 1 & 0 & \\cdots & 0 & 0  \\\\\n0 & 1 & 1 & \\cdots & 0 & 0  \\\\\n0 & 0 & 1 & \\cdots & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 1 & 1 \\\\\n0 & 0 & 0 & \\cdots & 0 & 1\n\\end{pmatrix}\n\\tag{92.21}\nThe forecast function is given by \nf_t(k) = a_{t_0} +  a_{t_1}k + \\ldots + a_{t_{n-1}} k^{n-1} \\qquad k \\in \\mathbb{N}\n\\tag{92.22}\nwhere a_{t_i} are the coefficients of the polynomial and k is the number of steps ahead we need in our forecast. There is also an alternative parameterization of this model that leads to the same algebraic form of the forecast function given by \\{Ep, Lp, vt, W t\\}, with\n\nL_p = \\begin{pmatrix}\n1 & 1 & 1 & \\cdots & 1 & 1  \\\\\n0 & 1 & 1 & \\cdots & 1 & 1   \\\\\n0 & 0 & 1 & \\cdots & 1 & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 1 & 1 \\\\\n0 & 0 & 0 & \\cdots & 0 & 1\n\\end{pmatrix}\n\\tag{92.23}\nAnd in this type of model, the forecast function is going to have order p-1. So the parameter vector is going to have dimension p. So you’re going to have \\theta_t =  \\theta_{t1:p}.\nThe observation operator F is just a constant and if we write it as a row vector we get F' as a p-dimensional vector with the one in the first entry and zeros everywhere else.\nThe dynamics matrix G may be written using either a J Jordan form Equation 92.21 or as a triangular form Equation 92.23. These result in different parameterization of this model and we will talk a little bit about this.\nIn the Equation 92.21 we have a matrix with ones on the diagonal and the super diagonal, the matrix is needs to be p \\times p i.e. with dimension p to be compatible with the dimension of the hidden state vector \\theta. So this matrix G is what we call a Jordan block of dimension p of 1. So here 1 is the number that appears in the diagonal. And then I have a p I_p matrix, I have ones in the upper diagonal part. So this is the form of the model, so once again I have the F the G, and the W_t. I have my model.\nThe forecast function in this case again can be written as F' G^h \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_t]. And when you simplify times expected value of \\theta_t, given D_t. Once you simplify those functions you get something that is a polynomial of order p-1 in h. So I just can write this down as k_t + k_{t,1} h + k_{t, p-1} h^{p-1}, so that’s my forecast function.\nThere is an alternative parameterization of this model that has the same F and the same algebraic form of the forecast function, the same form of the forecast function. But instead of using Equation 92.21 form of the G matrix, it has a Equation 92.23 form that has ones in the diagonal and ones everywhere above the diagonal. So it’s an upper triangular matrix with ones in the diagonal and above the diagonal. That’s a different parameterization of the same model but it leads to the same general form of the forecast function just with a different parameterization.\nSo again, we can consider the way you think about these models?\n\nWhat is you think what kind of forecast function makes sense here ?\nWhat is the type of predictions that I expect to have in my model?\nIf they look like a linear trend, I use a second order polynomial.\nIf it looks like a quadratic trend in the forecast then I would use 3rd order polynomial model representation.\n\nNote that the third order polynomial model is covered in\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\n92.2.4 First order Polynomial Models\nI will begin describing the structure of a particular class of models now, the polynomial trend models. These are models that are useful to describe linear trends or polynomial trends in your time series. So if you have a data set, where you have an increasing trend, or a decreasing trend, you would use one of those components in your model.\nWe will begin with the first order polynomial model, which we have already described. It’s the one that has y_t is a single parameter, I’m going to call it just \\theta_t + \\nu_t. And then a random walk evolution for that single parameter, so that’s the mean level of the series. And then we assume that it changes as a random walk, so this is the first order polynomial model.\nSo in general, I’m going to begin with the first order polynomial model, which we have already described. It’s the one that has y_t is a single parameter, I’m going to call it just \\theta_t + \\nu_t. And then a random walk evolution for that single parameters, so that’s the mean level of the series. And then we assume that it changes As a random walk, so this is the first order polynomial model. In this model if I want to write it down in short form I would have a quadruple that looks like this. So the F here that goes F transposed times the parameter vector in this case we have a scalar vector, scalar parameter. It’s going to be 1 my G that goes next to the state of t-1 is going to also be 1. And then I have vt and Wt here. So this fully defines my model if I think about the forecast function of this model using the representation we had before. Again, we’re going to have something of the form F'G^h and then the expected value of that \\theta_t | \\mathcal{D}_t. F is 1, G is 1, therefore I’m going to end up having just expected value of \\theta_t | \\mathcal{D}_t. Which depending on the data that you have is you’re just going to have something that is a value that depends on t and it doesn’t depend on h.\nWhat this model is telling you is that the forecast function, how you expect to see future values of the series h steps ahead is something that looks like the level that you estimated at time t.\nSo that’s the forecast function, you is a first order is a zero order polynomial is a constant on h and it’s called the first order polynomial model.\n\n\n92.2.5 Second order Polynomial Models\nIn the case of a second order polynomial We are going to now think about about a model in which we want to capture things that are not a constant over time but may have an increasing or decreasing linear trend. In this case we’re going to need two components in your parameter vector in the state vector.\nSo we have again something that looks like in my observation equation. I’m going to have, I’m going to call it say theta{t,1} Normal vt, and then I’m going to have say theta_{t,1} is going to be of the form to theta_{t-1,1} and there is another component here. The other component enters this equation plus let’s call this And then I have finally also I need an evolution for the second component of the process which is going to be again having a random walk type of behavior. So there is different ways in which you can interpret this two parameters but essentially one of them is related to the baseline level of the series the other one is related to the rate of change of the of the series. So if you think about the dlm representation again, these two components, I can collect into the vector wt. and then assume that this wt Is normal. Now this is a bivariate normal. So what would be my F and my G in this model? So again my theta vector has two components My G, so my F is going to be a two dimensional vectors. So I can write down F transposed as the only component that appears at this level is the first component of the vector. I’m going to have 1 and then a zero for F transposed. And then my G here if you think about writing down theta t times G say the t -1 +wt. Then you have that you’re G is going to have this form. So for the first component, I have past values of both components. That’s why I have a 1 and 1 here for the second component I only have the past value of the second component. So there is a zero and a 1. So this tells me what is the structure of this second order polynomial. If I think about how to obtain the forecast function for this second order polynomial is going to be very similar to what we did before. So you can write it down as F transposed G to the power of h, expected value of theta t given Dt. Now the expected value is going to be vector also with two components because theta_t is a two dimensional vector. The structure here if you look at what G is G to the power of h going to be a matrix, that is going to look like 1, h, 0 1. When you multiply that matrix time this times this F what you’re going to end up having is something that looks like 1 h times this expected value of theta t given Dt. So I can think of two components here, so this gives you a constant on h, this part is not going to depend on h. So I can write this down as k t 11 component multiplied by 1 and then I have another constant, multiplied by h. So you can see what happens now is that your forecast function has the form of a linear polynomial. So it’s just a linear function on the number of steps ahead. The slope and the intercept related to that linear function are going to depend on the expected value of, theta_t given the all the information I have up to time t. But essentially is a way to model linear trends. So this is what happens with the second order polynomial model.\n\n\n92.2.6 P-th Order Polynomial Models\nAs we included linear trends and constant values in the forecast function, we may want to also incorporate other kinds of trends, polynomial trends in the model. So you may want to have a quadratic form, the forecast function or a cubic forecast function as a function of h. So the all those can be incorporated using the general p-order polynomial model, so I will just describe the form of this model. And in this type of model, the forecast function is going to have order p-1. So your parameter vector is going to have dimension p. So you’re going to have theta_t theta t1 to tp. Your F matrix is going to be constant if I write it as a row vector. F transpose is going to be a p dimensional vector with the one in the first entry and zeros everywhere else. My G matrix is going to have this form and there is different parameterizations of this model and I will talk a little bit about this. But one way to parameterize the model is something that looks like this. So you have ones in the diagonal of the matrix, the matrix is going to be a p by p has to be the dimension of the p compatible with the dimension of the state vector. And then you have zeros’s below the diagonal above that set of ones that are also ones above the diagonal. So this matrix G is what we call a Jordan block of dimension p of 1. So here 1 is the number that appears in the diagonal. And then I have a p Ip matrix, I have ones in the upper diagonal part. So this is the form of the model, so once again I have the F the G, and the wt. I have my model. The forecast function in this case again can be written as F transposed G to the power of h. And when you simplify times expected value of theta_t, given Dt. Once you simplify those functions you get something that is a polynomial of order p-1 in h. So I just can write this down as kt constant.Plus kt1 h + kt p- 1, h to the p -1, so that’s my forecast function. There is an alternative parameterization of this model that has the same F and the same algebraic form of the forecast function, the same form of the forecast function. But instead of having this G matrix, it has a matrix that has ones in the diagonal and ones everywhere above the diagonal. So it’s an upper triangular matrix with ones in the diagonal and above the diagonal. That’s a different parameterization of the same model is going to have the same general form of the forecast function is a different parameterization. So again, you can consider the way you think about these models is you think what kind of forecast function I want to have for my future? What is the type of predictions that I expect to have in my model? And if they look like a linear trend, I use a second order polynomial. If it looks like a quadratic trend in the forecast then I would use 3rd order polynomial model representation.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-polynomial-trend-models-reading",
    "href": "C4-L03.html#summary-of-polynomial-trend-models-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.3 Summary of polynomial trend models (Reading)",
    "text": "92.3 Summary of polynomial trend models (Reading)\n\n92.3.1 Polynomial Trend Models\n\n92.3.1.1 First-Order Polynomial\n\n\\begin{aligned}\ny_t &= \\mu_t + \\nu_t, \\qquad & \\nu_t &\\sim  \\mathcal{N}(0, v_t) \\\\\n\\mu_t &= \\mu_{t-1} + \\omega_t, \\qquad & \\omega_t &\\sim  \\mathcal{N}(0, w_t)\n\\end{aligned}\n\nIn this case, we have:\n\\theta_t = \\mu_t \\quad \\forall t\n\nF_t = 1 \\quad \\forall t \\qquad G_t = 1 \\quad \\forall t\n\nresulting in:\n\n\\{1, 1, v_t, w_t\\} \\qquad \\text{(short notation)}\n\nThe forecast function is:\n\nf_t(h) = E(\\mu_t \\mid \\mathcal{D}_t) = k_t, \\quad \\forall h &gt; 0.\n\n\n\n92.3.1.2 Second-Order Polynomial\n\\begin{aligned}\n  y_t &= \\theta_{t,1} + \\nu_t, \\quad &\\nu_t &\\sim  \\mathcal{N}(0, v_t) \\\\\n  \\theta_{t,1} &= \\theta_{t-1,1} + \\theta_{t-1,2} + \\omega_{t,1}, \\qquad &\\omega_{t,1} &\\sim  \\mathcal{N}(0, w_{t,11}) \\\\\n  \\theta_{t,2} &= \\theta_{t-1,2} + \\omega_{t,2}, \\qquad &\\omega_{t,2} &\\sim  \\mathcal{N}(0, w_{t,22}),\n\\end{aligned}\n\nwhere we can also have:\n\n\\text{Cov}(\\theta_{t,1}, \\theta_{t,2} ) = w_{t,12} = w_{t,21}\n\nThis can be written as a DLM with the state-space vector \\theta_t = (\\theta_{t,1}, \\theta_{t,2})', and\n\n\\{\\mathbf{F}, \\mathbf{G}, v_t, \\mathbf{W}_t\\}  \\qquad \\text{(short notation)}\n\nwith \\mathbf{F} = (1, 0)' and\n\n\\mathbf{G} =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}, \\quad \\mathbf{W}_t =\n\\begin{pmatrix}\nw_{t,11} & w_{t,12} \\\\\nw_{t,21} & w_{t,22}\n\\end{pmatrix}.\n\nNote that\n\n\\mathbf{G}^2 =\n\\begin{pmatrix}\n1 & 2 \\\\\n0 & 1\n\\end{pmatrix}, \\quad \\mathbf{G}^h =\n\\begin{pmatrix}\n1 & h \\\\\n0 & 1\n\\end{pmatrix},\n\nand so:\n\nf_t(h) = (1, h) E(\\mathbf{\\theta}_t \\mid \\mathcal{D}_t) = (1, h) (k_{t,0}, k_{t,1})' = (k_{t,0} + h k_{t,1}).\n\nHere \\mathbf{G} = \\mathbf{J}_2(1) (see below).\nAlso, we denote \\mathbf{E}_2 = (1, 0)', and so the short notation for this model is\n\n\\{E_2, J_2(1), \\cdot, \\cdot\\}\n\n\n\n92.3.1.3 General p-th Order Polynomial Model\nWe can consider a p-th order polynomial model. This model will have a state-space vector of dimension p and a polynomial of order p-1 forecast function on h. The model can be written as\n\\{E_p, J_p(1), v_t, W_t\\}  \\qquad \\text{(short notation)}\n\nwith \\mathbf{F}_t = \\mathbf{E}_p = (1, 0, \\dots, 0)' and \\mathbf{G}_t = \\mathbf{J}_p(1), with\n\n\\mathbf{J}_p(1) =\n\\begin{pmatrix}\n1 & 1 & 0 & \\cdots & 0 & 0 & 0 \\\\\n0 & 1 & 1 & \\cdots & 0 & 0 & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 0 & 1 & 1 \\\\\n0 & 0 & 0 & \\cdots & 0 & 0 & 1\n\\end{pmatrix}.\n\nThe forecast function is given by\n\nf_t(h) = k_{t,0} + k_{t,1} h + \\dots + k_{t,p-1} h^{p-1}.\n\nThere is also an alternative parameterization of this model that leads to the same algebraic form of the forecast function, given by \\{E_p, L_p, v_t, W_t\\}, with\n\nL_p =\n\\begin{pmatrix}\n1 & 1 & 1 & \\cdots & 1 \\\\\n0 & 1 & 1 & \\cdots & 1 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 1\n\\end{pmatrix}.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#regression-models-video",
    "href": "C4-L03.html#regression-models-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.4 Regression models (Video)",
    "text": "92.4 Regression models (Video)\n\n\n\n\nRegression models\n\n\n92.4.1 Simple dynamic regression\n\n\\begin{aligned}\ny_t &= \\beta_{t,0} + \\beta_{t,1}x_t + ν_t \\\\\n\\beta_{t,0} &= \\beta_{t−1,0} + \\omega_{t,0} \\\\\n\\beta_{t,1} &= \\beta_{t−1,1} + \\omega_{t,1}\n\\end{aligned}\n\\tag{92.24}\nand so \\theta_t = (\\beta_t,0, \\beta_{t,1})′, F_t = (1, x_t)′ and G = I_2.\nThis results in a forecast function of the form\n\nf_t(h) = k_{t,0} + k_{t,1}x_{t+h}\n\\tag{92.25}\nwhere k_{t,0} = \\mathbb{E}[\\beta_{t,0} \\mid \\mathcal{D}_t] and k_{t,1} = \\mathbb{E}[\\beta_{t,1} \\mid \\mathcal{D}_t].\n\n\n92.4.2 General dynamic regression\n\n\\begin{aligned}\ny_t &= \\beta_{t,0} + \\beta_{t,1}x_{t,1} + \\ldots \\beta_{t,M} x_{t,M} + ν_t \\\\\n\\beta_{t,m} &= \\beta_{t−1,m} + \\omega_{t,m,} & m = 0 : M.\n\\end{aligned}\n\\tag{92.26}\nThen, \\theta = (\\beta_t,0, \\ldots , \\beta_{t,M} )′, F_t = (1, x_{t,1}, \\ldots , x_{t,M} )′ and G = I_M . The forecast function is given by\n\nf_t(h) = k_{t,0} + k_{t,1}x_{t+h,1} + \\ldots + k_{t+h,M}x_{t+h,M}\n\\tag{92.27}\nA particular case is of dynamic regressions is the case of time-varying auto-regressions (TVAR) with\n\n\\begin{aligned}\ny_t &= \\varphi_{t,1}y_{t−1} + \\varphi_{t,2}y_{t−2} + \\ldots + \\varphi_{t,p} y_{t−p} + ν_t,\\\\\n\\varphi_{t,m} &= \\varphi_{t−1,m} + \\omega_{t,m,} & m = 1 : p\n\\end{aligned}\n\\tag{92.28}\nThere is a paper (Raquel Prado, Huerta, and West 2000) on TVAR models that is a good reference for this model.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\n92.4.3 Regression Models\nIn regression models, we may also have additional covariates that are also measured sequentially over time. We may want to regress the y_t time series and see what relationships they have with other covariates that are also measured over time. The simplest possible case is the dynamic simple regression model. In this case, I can write down. I have a single covariate, that covariate is X_t that is observed here, and then I have the usual. In this case, I have an intercept and a slope, and this is representing my simple linear regression. It’s just the regression where both the intercept and the slope are time-varying. I can define the variation. I need to specify what’s the evolution of the two components, and we are going to use this random walk. We could use other structures, but again, in the normal linear case, we are going to be using these evolution equations. Then I collect here my W’s as a single vector. The \\omega_t is going to have the two components in here. These are normally distributed zero and variance covariance matrix W_t, that is a two-by-two matrix. This is the case of the simple regression model. In the case of this model, we have F now is time-varying. This is going to change depending on the value of X_t. I can write Ft transpose as one and X_t. My Theta vector. Again, if I think about what it is, is just Beta t, 0 Beta t, 1. I have those two components.\nThe G matrix is going to be the identity, and you can see that essentially the first component is related to the first component in t minus one, and the second component at time t is related to the second component at time t minus 1. So the identity matrix will be the G. Therefore, if I think about my forecast function in the simple linear regression case, this is going to be my F transpose, which is 1 xt times the G, the G is the identity, times the expected value of Theta t, given Dt. For the expected value of Theta t given Dt, This is a two-dimensional vector, so I’m going to have components in there. I can write this down as K_t0 plus K_t1 Xt. We can see that the forecast function is again has that form that depends on that covariate at the time. This should be t plus h because we are evaluating this at t plus h. You need to have the covariate evaluated at t plus h here.\n\n\n92.4.4 General Dynamic Regression Model\nIn the case of general dynamic regression model, we’re going to have a set of covariates. We can have, let’s say k of those covariates or p of those covariates, X_t1. This is my observation equation. Instead of having a single covariate, now I’m going to have p of them. I’m going to have coefficients that go with each of those and I may have the Beta t0 coefficient. My G matrix now, if I think about my parameter vector is just p plus 1 dimensional, p plus 1. Yeah, so that I have the 0 and then the p values, so is a p plus 1 vector. Then my G is the identity. My F_t is going to be a vector, is also p plus 1 dimension. The first entry is one, the second is X_t1 X_tp. My forecast function is going to be similar to this, but now we are going to have more than one covariate, so we end up with a forecast function that has this form, p. This is the case for the dynamic regression.\n\n\n92.4.5 TVAR\nOne particular example of dynamic regression model is the case of a time-varying autoregressive process. This brings us back to those autoregressive processes that we were discussing earlier in the course. When you you’re regressing each of the X’s correspond to pass values, you have a regression model that we call a time-varying ARP. In this case, your observation equation is going to have the AR coefficients, but the AR coefficients are going to be varying over time. If we assume that we put all the coefficients together and have a random walk evolution equation for those. If I said, I call Phi_t the vector that contains all the components with all the coefficients from one to p, then I can now define this evolution equation. Then my Omega_t here is a p-dimensional vector, and I have Omega t, normal zero, WT, and my epsilon t normal 0 vt.\nThis defines a time-varying AR. It’s the same structure that we had before. The only difference is my covariates are just past values of the time series. Therefore my forecast function for the time-varying AR is going to have this form where every_thing is going to depend on past values of the time series. We will study this model in particular and make connections with the AR that we studied earlier in the class.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-regression-models-reading",
    "href": "C4-L03.html#summary-of-regression-models-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.5 Summary of Regression Models (Reading)",
    "text": "92.5 Summary of Regression Models (Reading)\n\n92.5.1 Dynamic Regression Models\n\n92.5.1.1 Simple Dynamic Regression\n\n\\begin{aligned}\n  y_t &= \\beta_{t,0} + \\beta_{t,1} x_t + \\nu_t \\\\\n  \\beta_{t,0} &= \\beta_{t-1,0} + \\omega_{t,0} \\\\\n  \\beta_{t,1} &= \\beta_{t-1,1} + \\omega_{t,1}\n\\end{aligned}\n\nThus:\n\n\\theta_t = (\\beta_{t,0}, \\beta_{t,1})'\n\n\nF_t = (1, x_t)'\n\nand\n\nG = I_2\n\nThis results in a forecast function of the form\n\nf_t(h) = k_{t,0} + k_{t,1} x_{t+h}.\n\n\n\n92.5.1.2 General Dynamic Regression\n\n\\begin{aligned}\ny_t &= \\beta_{t,0} + \\beta_{t,1} x_{t,1} + \\dots + \\beta_{t,M} x_{t,M} + \\nu_t \\\\\n\\beta_{t,m} &= \\beta_{t-1,m} + \\omega_{t,m}, \\quad &m = 0:M.\n\\end{aligned}\n\\tag{92.29}\nThen,\n\\theta_t = (\\beta_{t,0}, \\dots, \\beta_{t,M})',\n\\mathbf{F}_t = (1, x_{t,1}, \\dots, x_{t,M})' and\n\\mathbf{G} = \\mathbf{I}_M.\nThe forecast function is given by:\n\nf_t(h) = k_{t,0} + k_{t,1} x_{t+h,1} + \\dots + k_{t,M} x_{t+h,M}.\n\\tag{92.30}\nA particular case of dynamic regressions is the case of time-varying autoregressive (TVAR) with time-varying autoregressive (TVAR)\n\n\\begin{aligned}\n  y_t &= \\phi_{t,1} y_{t-1} + \\phi_{t,2} y_{t-2} + \\dots + \\phi_{t,p} y_{t-p} + \\nu_t \\\\\n  \\phi_{t,m} &= \\phi_{t-1,m} + \\omega_{t,m}, \\quad m = 1:p.\n\\end{aligned}",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#the-superposition-principle-video",
    "href": "C4-L03.html#the-superposition-principle-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.6 The superposition principle (Video)",
    "text": "92.6 The superposition principle (Video)\n\n\n\n\nThe superposition principle\n\nWe can use the superposition principle to build models that have different kinds of components. The main idea is to think about what is the general structure we want for the forecast function and then isolate the different components of the forecast function and think about the classes of dynamic linear models that are represented in each of those components. Each of those components has a class and then we can build the general dynamic linear model with all those pieces together using this principle.\nTwo references for the Superposition principle are\n\n(West and Harrison 2013, sec. 3.1 p. 98)\n(R. Prado, Ferreira, and West 2023, sec. 4.2.1 p. 136)\n\n\n\n\n\n\n\nImportant 92.1: Superposition Principle\n\n\n\nIn the first the author state:\n\nConditional independence also features strongly in initial model building and in choosing an appropriate parametrization. For example, the linear superposition principle states that any linear combination of deterministic linear models is a linear model. This extends to a normal linear superposition principle:\nAny linear combination of independent normal DLMs is a normal DLM. - &gt; – (West and Harrison 2013, sec. 3.1 p. 98)\n\n\n\nWe will illustrate how to do that with an example:\nLet’s say that we want to create a model here with a forecast function that has a linear trend component. Let’s say we have a linear function as a function of the number of steps ahead that you want to consider. Then suppose you also have a covariate here that you want to include in your model as a regression component. \nf_t(h) = \\underbrace{(k_{t,0} + k_{t,1}\\; h)}_{\\text{linear trend component}} + \\underbrace{(k_{t,2}\\; x_{t+h})}_{\\text{regression component}}\n\\tag{92.31}\nwhere:\n\nf_t(h) is our forecast function.\nk_{t,0}, k_{t,1} and k_{t,2} are just constants (that we index using time t and a second subscript).\nx_{t+h} is a time dependent regression covariate.\n\nWhen we look at the forecast function, we can isolate a linear trend and a regression components as indicated. Each of these can be set in terms of two forecast functions]{.mark}. I’m going to call the forecast function f_{1,t}(h), this is just the first piece.\n\n\\begin{aligned}\nf_t(h) &= f_{1,t}(h) + f_{2,t}(h) \\\\\nf_{1,t}(h) &= k_{t,0} + k_{t,1} & \\text{(linear trend component)} \\\\\nf_{2,t}(h) &= k_{t,2}x_{t+h} & \\text{(regression component)}\n\\end{aligned}\n\\tag{92.32}\nWe know how to represent forecast function f_{1,t} and f_{2,t} in terms of dynamic linear models.\nFor the linear trend component, f_{1,t}(h) , we have a 2-dimensional state vector, \\theta_t = (\\theta_{t,1}, \\theta_{t,2})', which yields the following DLM shortform:\n\n\\{F_1, G_1, \\cdot, \\cdot\\}  \\qquad \\text{(short notation)}\n\\tag{92.33}\n\nWhere we don’t explicitly specify the observational and system variances, V and W\nThe important bit are F and G. The forecast function is given by:\n\n\nF_{1} = E_2 = (1, 0)'\n\\tag{92.34}\n\nG_{1} =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}\n\\tag{92.35}\nfor the regression component f_{2,t}(h) we have the following DLM representation:\n\n\\{F_2,t, G_2, \\cdot, \\cdot\\}  \\qquad \\text{(short notation)}\n\\tag{92.36}\nwhere we have F_{2t} is X_t and my G is simply going to be 1. This is a one-dimensional vector in terms of the state parameter vector.\n\nF_{2,t} = x_{t+h}\n\\tag{92.37}\n\nG_{2} = 1\n\\tag{92.38}\nOnce we have these, we can assemble them into our final model. \\{F_t, G, \\cdot, \\cdot\\}\nWe care more about F, G, and less about the observational variance and some covariance also for the system where the\nF is going to be an F that has, you just concatenate the two Fs. You’re going to get 1, 0 and then you’re going to put the next component here. Again, this one is dependent on time because this component is time dependent and\nThe model with forecast function f_t(h) above is a model with a 3-dimensional state vector with\n\nF_t = (F_1', F_{2,t})' = (1, 0, x_t)'\n\nThen the G, you can create it just taking a block diagonal structure by concatenating G_1 and G_2. though formally there must be a better term for this operation.\n\nG = \\text{blockdiag}[G_1, G_2] =\n\\begin{pmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}.\n\nThis gives us the full G dynamics matrix for the model. A model with this F_t and this G that is constant over time will give us this particular forecast function Equation 92.31 we started with.\nWe used the superposition principle to build this model. If we need additional components, we will learn how to incorporate seasonal components, regression components, trend components. One can build a fairly sophisticated model with different structures into this particular model using the superposition principle.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\n92.6.1 The superposition principle\nWe can use the superposition principle to build models that have different kinds of components. The main idea is to think about what is the general structure we want for the forecast function and then isolate the different components of the forecast function and think about the classes of dynamic linear models that are represented in each of those components. Each of those components has a class and then we can build the general dynamic linear model with all those pieces together using this principle. I will illustrate how to do that with an example. Let’s say that you want to create a model here with a forecast function that has a linear trend component. Let’s say we have a linear function as a function of the number of steps ahead that you want to consider. Then suppose you also have a covariate here that you want to include in your model as a regression component. Let’s say we have a K_t2 and then we have X_t plus h, this is my covariate. Again, the k’s here are just constants, as of constants in terms of h, they are dependent on time here. This is the general structure we want to have for the forecast function. Now you can see that when I look at the forecast function, I can isolate here and separate these two components. I have a component that looks like a linear trend and then I have a component that is a regression component. Each of this can be set in terms of two forecast functions. I’m going to call the forecast function F_1t h, this is just the first piece. Then I have my second piece here. I’m going to call it F_2t, is just this piece here with the regression component. We know how to represent this forecast function in terms of a dynamic linear model. I can write down a model that has an F, G, and some V, and some W that I’m going to just leave here and not specify them explicitly because the important components for the structure of the model are the F and the G. If you’ll recall the F in the case of a forecast function with a linear trend like this, is just my E_2 vector, which is a two-dimensional vector. The first entry is one, and the second one is a zero. Then the G in this case is just this upper triangular matrix that has 1, 1 in the first row and 0, 1 in the second one. Remember, in this case we have a two-dimensional state vector where one of the components in the vector is telling me information about the level of the time series, the other component is telling me about the rate of change in that level. This is a representation that corresponds to this forecast function. For this other forecast function, we have a single covariate, it’s just a regression and I can represent these in terms of an F_2, G_2, and then some observational variance and some system variance here in the case of a single covariate and this one depends on t. We have F_2t is X_t and my G here is simply going to be one. This is a one-dimensional vector in terms of the state parameter vector. We have a single state vector and it’s just going to tell me about the changes, the coefficient that goes with the X_t covariate. Once I have these, I can create my final model and I’m going to just say that my final model is F, G, and then I have some observational variance and some covariance also for the system where the F is going to be an F that has, you just concatenate the two Fs. You’re going to get 1, 0 and then you’re going to put the next component here. Again, this one is dependent on time because this component is time dependent and then the G, you can create it just taking a block diagonal structure, G_1 and G_2. You just put together, the first one is 1, 1, 0, 1 and then I concatenate this one as a block diagonal. This should be one. This gives me the full G function for the model. Now a model with this F_t and this G that is constant over time will give me this particular forecast function. I’m using the superposition principle to build this model. If you want additional components, we will learn how to incorporate seasonal components, regression components, trend components. You can build a fairly sophisticated model with different structures into this particular model using the superposition principle.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#superposition-principle-general-case-reading",
    "href": "C4-L03.html#superposition-principle-general-case-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.7 Superposition principle: General case (Reading)",
    "text": "92.7 Superposition principle: General case (Reading)\nYou can build dynamic models with different components, for example, a trend component plus a regression component, by using the principle of superposition. The idea is to think about the general form of the forecast function you want to have for prediction. You then write that forecast function as a sum of different components where each component corresponds to a class of DLM with its own state-space representation. The final DLM can then be written by combining the pieces of the different components.\nFor example, suppose you are interested in a model with a forecast function that includes a linear polynomial trend and a single covariate x_t, i.e.,\n\nf_t(h) = k_{t,0} + k_{t,1}h + k_{t,3}x_{t+h}.\n\nThis forecast function can be written as f_t(h) = f_{1,t}(h) + f_{2,t}(h), with\n\nf_{1,t}(h) = (k_{t,0} + k_{t,1}h), \\quad f_{2,t}(h) = k_{t,3}x_{t+h}.\n\nThe first component in the forecast function corresponds to a model with a 2-dimensional state vector, F_{1,t} = F_1 = (1, 0)',\n\nG_{1,t} = G_1 =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}.\n\nThe second component corresponds to a model with a 1-dimensional state vector, F_{2,t} = x_t, G_{2,t} = G_2 = 1.\nThe model with forecast function f_t(h) above is a model with a 3-dimensional state vector with F_t = (F_1', F_{2,t})' = (1, 0, x_t)' and\n\nG_t = \\text{blockdiag}[G_1, G_2] =\n\\begin{pmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}.\n\n\n92.7.1 General Case\nThe general case wasn’t covered in the video and we didn’t have a proper statement of the superposition principle. However, in Important 92.1 I extracted the statement of the principle above. This statement clarifies that the principle arises via conditional independence, a tool we also used extensively in the previous course on mixture models. Now let us consider the general case from the handout.\nAssume that you have a time series process y_t with a forecast function\n\nf_t(h) = \\sum_{i=1}^{m} f_{i,t}(h),\n\nwhere each f_{i,t}(h) is the forecast function of a DLM with representation \\{F_{i,t}, G_{i,t}, v_{i,t}, W_{i,t}\\}.\nThen, f_t(h) has a DLM representation \\{F_t, G_t, v_t, W_t\\} with\n\nF_t = (F_{1,t}', F_{2,t}', \\dots, F_{m,t}')',\n\n\nG_t = \\text{blockdiag}[G_{1,t}, \\dots, G_{m,t}],\n\n\nv_t = \\sum_{i=1}^{m} v_{i,t},\n\nand\n\nW_t = \\text{blockdiag}[W_{1,t}, \\dots, W_{m,t}].",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#quiz-the-normal-dynamic-linear-model",
    "href": "C4-L03.html#quiz-the-normal-dynamic-linear-model",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "92.8 Quiz: The Normal Dynamic Linear Model",
    "text": "92.8 Quiz: The Normal Dynamic Linear Model\nOmitted due to Coursera honor code",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#filtering-video",
    "href": "C4-L03.html#filtering-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.1 Filtering (Video)",
    "text": "93.1 Filtering (Video)\n\n\n\n\nDerivation for the Prior and Forecast at Time t\n\n\n\n\nDerivation of the Posterior at Time t\n\n\nRecall we are working in a Bayesian setting where a NDLM model with a normal prior would like this:\n\n\\begin{aligned}\n  y_t &= F_t' \\theta_t + \\nu_t & \\nu_t &\\sim \\mathcal{N}(0, v_t) & \\text{(observation)}\\\\\n  \\theta_t &= G_t \\theta_{t-1} + \\omega_t & \\omega_t &\\sim  \\mathcal{N}(0, W_t) & \\text{(evolution)} \\\\\n  & &(\\theta_0 \\mid \\mathcal{D}_0) & \\sim  \\mathcal{N}(m_0, C_0) & \\text{(prior)}\n\\end{aligned}\n\\tag{93.1}\n\nIn the prior \\mathcal{D}_0 stands for the information that we have before collecting any data and\nWe are assuming \\theta_0 follows a normal distribution with\nm_0 mean\nC_0 variance covariance matrix.\n\nSince we are doing filtering which is a retrospective analysis, of past states we assume that we know m_0, C_0, \\nu_t, \\omega_t, F_t, G_t \\qquad \\forall t.\nHowever, there is often great interest in looking back in time in order to get a clearer picture of what happened.\nWe are interested in performing Bayesian inference in this setting and we talked about different kinds of distributions.\n\nOne is the filtering distribution that allows us to update the distribution of \\theta_t as we receive observations and information over time.\nThe other one is smoothing equations that allows us to just revisit the past once we have observed a chunk of data.\n\nIn a Bayesian setting, you have to set a prior distribution. We will work with the prior distribution that is conjugate.\nIn this case we have to begin with a distribution at time zero for \\theta_0. So before we have seen any data at all, I have this prior distribution.\nWe also assume a prior distribution of the form:\n\n(\\theta_{t} \\mid \\mathcal{D}_{t-1}) \\sim \\mathcal{N}(m_{t-1}, C_{t-1}).\n\\tag{93.2}\nWe assume that this the filtering distribution follows this normal distribution based on\n\nthe prior in Equation 93.9 being conjugate of the normal and\n\nthe linearity of the model in Equation 93.9.\n\nThese result in updates to the model parameters and uncertainty, at each time step, preserving the normal structure from the prior.\nThen, we can obtain the following distributions:\n\nPrior at Time t\n\n\n  (\\theta_t \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(a_t, R_t) \\qquad \\text{(prior at time t)} \\qquad\n   \\tag{93.3}\nwith\n \\begin{aligned}\n  a_t \\doteq& \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_{t-1}] =& G_t  \\mathbb{E}[G_t \\theta_{t-1} \\mid \\mathcal{D}_{t-1} ] =& G_t m_{t-1} \\\\\n  R_t \\doteq& \\mathbb{V}ar[\\theta_t \\mid \\mathcal{D}_{t-1}] =& G_t \\mathbb{V}ar[\\theta_t \\mid \\mathcal{D}_{t-1}] =& G_t C_{t-1} G_t' + W_t.\n  \\end{aligned}\n   \\tag{93.4}\nWhere we simply took the first and second moments of the system equation from Equation 93.9 conditioned on our information set \\mathcal{D}_{t-1}\n\nOne-Step Forecast\n\n\n  (y_t \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(f_t, q_t) \\qquad \\text{(one step forecast fn)} \\qquad\n   \\tag{93.5}\nwith\n\\begin{aligned}\n  f_t\n     & \\doteq \\mathbb{E}[ y_t \\mid \\mathcal{D}_{t-1} ]\n     & = F_t' \\mathbb{E}[ y_t \\mid \\mathcal{D}_{t-1} ]\n     & = F_t' a_t \\\\\n  q_t\n     & \\doteq \\mathbb{V}ar[y_t \\mid \\mathcal{D}_{t-1}]\n     & = F_t' \\mathbb{V}ar[y_t \\mid \\mathcal{D}_{t-1}]  \n     & = F_t' R_t F_t + v_t\n  \\end{aligned}\n   \\tag{93.6}\nWhere we took the first moments on the observation equation conditioned on the information set \\mathcal{D}_t and substituted Equation 93.5\n\nPosterior at Time t\n\n\n  (\\theta_t \\mid \\mathcal{D}_t) \\sim  \\mathcal{N}(m_t, C_t)\n  \nwith\n\\begin{aligned}\n  m_t &= a_t + R_t F_t q_t^{-1} (y_t - f_t), \\\\\n  C_t &= R_t - R_t F_t q_t^{-1} F_t' R_t.\n  \\end{aligned}\n   \\tag{93.7}\nThese can be derived via Normal theory or via the Multivariate Bayes’ theorem. The background for both seems to be provided in (West and Harrison 2013, secs. 17.2.3 p.639)\nNow, denoting e_t = (y_t - f_t) and A_t = R_t F_t q_t^{-1}, we can rewrite the equations above as:\nIt follows that\n\n\\begin{pmatrix}Y \\\\ \\theta\\end{pmatrix} \\sim \\mathcal{N}\n\\left(\n  \\begin{pmatrix}F'a \\\\ a \\end{pmatrix},\n  \\begin{pmatrix} F'RF + V & F'R \\\\ RF & R \\end{pmatrix}\n\\right)\n\nTherefore, identifying Y with X_1 and \\theta with X_2 in the partition of X in 17.2.2, we have RF R )]\nTherefore, identifying Y with X1 and θ with X2 in the partition of X in 17.2.2, we have \nY \\sim \\mathcal{N}[F'a, F'RF + V]\n\n\n(\\theta \\mid Y) \\sim \\mathcal{N}[m, C],\n\nwhere\n\nm = a + RF[F′RF + V]−1[Y − F′a]\n\nand \nC = R − RF[F′RF + V]−1F′R.\n\n\n  \\begin{aligned}\n  \\theta \\mid \\mathcal{D}_t &\\sim \\mathcal{N}(m_t,C_t)\\\\\n  m_t &\\doteq a_t + A_t e_t, \\\\\n  C_t &\\doteq R_t - A_t q_t A_t'\n  \\end{aligned}\n\\tag{93.8}\nEquation 93.4 , Equation 93.6 and Equation 93.8 are often referred to as the Kalman filtering equations.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nI will now discuss Bayesian inference in the case of the normal dynamic linear model where both the observational variance and the system variance are known. We will talk about filtering equations, smoothing equations and also forecasting in this setting using Bayesian approach.\nSo recall we are working with a model that looks like this: … And then this is my first equation, the observation equation and I have a system equation that looks like this.\nWe are going to assume that V_t and W_t are known for every t. And we also know what the F_t’s and the G_t’s are here. So the response is a uni-dimensional y_t and then I have, say, \\theta_t is a vector of a given dimension, depending on the structure of the model.\nWe are interested in performing Bayesian inference in this setting and we talked about different kinds of distributions\n\nOne is the filtering distribution that allows us to update the distribution of \\theta_t as we receive observations and information over time.\nThe other one is smoothing equations that allows us to just revisit the past once we have observed a chunk of data.\n\nSo I will be talking about those and also smoothing.\nIn a Bayesian setting, you have to set a prior distribution. We will work with the prior distribution that is conjugate.\nIn this case I have to begin with distribution at time zero. So before I know, I have seen any data at all, I have this prior distribution. D_0 stands for the information that I have before collecting any data. And we are going to assume, That this \\theta_0 follows a normal distribution with m_0 mean and variance covariance matrix C_0. So these are also specified when you’re working with this model.\nSo we assume that this m_0 and C_0 is known.\nOnce we have this setting using these equations, we can obtain the filtering equations.\nSo the first assumption is going to be that we have, a structure.\nSo for \\theta_{t -1} \\mid \\mathcal{D}_{t-1} is going to have this normal structure which is going to happen basically because we’re using this conjugate prior. And because we have normal structure in the model, is going to lead to the following distribution. So the first one is the prior at time t.\nSo if I want to think about why my distribution for the t is given the information I have up to t-1, I can look at the equations of the model and use this second equation. And by looking at this equation, if I condition on the information I have up to t-1, I can see that, say, \\theta_t is written as a linear function of, \\theta_{t -1} and I have the assumption of normality here.\nTherefore, say, \\theta_t going to follow a normal distribution with some mean and some variance. So now we’re going to compute this mean and this variance using this equation. So if you think about the expected value of \\theta_t, given D_{t -1}, that’s just going to be G_t is a constant here. So I have my G_t and then I have expected value of \\theta_{t -1} given G_{t -1} plus expect the value of this \\omega_t.\nBut \\omega_t is a zero mean, normally distributed quantity, so it’s just going to be zero. Using the assumption that I have this structure, then I have that the \\mathbb{E}[\\theta_t \\mid \\mathcal{D}_{t -1}] = G_t \\times m_{t-1}. We’re going to call this quantity a_t, so we have here a_t. For the variance covariance matrix, then we just have to compute, do the same type of operation. And again, we can use this equation and see that we obtain this G_t variance of \\theta_{t-1} \\mid \\mathcal{D}_{t -1} G_t'. And then we have now the variance of the omega, the variance of the omega is just W_t. So we have G_t = C_{t -1} G_t' + W_t. So we can call this quantity R_t and just have the form of this prior distribution at time t.\nI can now think about another distribution which is the distribution of y_t \\mid \\mathcal{D}_{t-1}. So this is the so called one-step ahead, Forecast, And in the one-step ahead forecast again is a similar type of structure. So now we’re going to use the first equation rather than the second equation and we see that y_t is written in terms of a linear function of \\theta_t. And we have also the Gaussian in assumption here. So again the y_t is going to be normally distributed, And we just have to compute the mean and the variance for this y_t. So using the first equation, we have the expected value of y_t given D_{t -1} is just F_t' \\mathbb{E}[\\theta_t \\mid D_{t -1}]. And we computed this before, so this is, again, the expected value of \\theta_t given D_{t -1} is what we computed here. So this is to be F_t' a_t. And we are going to call this little f_t. Then, for the variance, Again, we use this equation, we have this component, so we are going to get F_t' R_t F_t + D_t. And I’m going to call this q_t. So my final distribution, the one-step ahead forecast distribution, tells me that this follows a normal f_t q_t. The next equations we are going to discuss are the equations that tell me about what is the distribution of \\theta_t once we incorporate the information provided by y_t. The next distribution is the posterior of \\theta_t given D_t. So that’s, \\theta_t given D_t. And we can write D_t as whatever information we have at time t- 1. And the new data point with this just y_t. So we just want to update the distribution of \\theta_t given that we have received this additional data point at time t. There are two ways of computing this distribution. One uses normal theory, the other one uses Bayes’ theorem. And you obtain that the distribution of \\theta_t given D_t is going to be a normal, with mean we call it m_t and variance C_t. We will see how to obtain this distribution or the moments of this distribution using normal theory.\n\n\nSo, again, we can write down, if we think about just combining the vector \\theta_t with the observation\n\n\nY_t given D_{t -1}, right? We have information about \\theta_t \\mid t-1. That’s the prior for \\theta_{ta,t}, based on the information at t -1. And then we also computed before the one step ahead forecast distribution for y_t| \\mathcal{D}_{t -1}. So we know that when we combine these two in a single vector, we’re going to have a multivariate normal distribution and the first component is going to be a_t. The second component is what we have called F_t, so that’s the mean. And then for the covariance matrix. We’re going to have now, what goes here is just the variance of \\theta_t given D_{t -1}, which we have called R_t. What goes here is the variance of y_t \\mid \\mathcal{D}_{t -1} and we have called this q_t. And now we have to compute the covariance between \\theta_t and y_t, and that goes here. And the covariance between y_t and \\theta_t, which is just the transpose of that, is going to go here. So if I think about computing the covariance of \\theta_t and y_t \\mid \\mathcal{D}_{t -1}, I can write y_t using the first equation here as a function of \\theta_t. That’s going to give us, F_t' \\theta_t + v_t given D_{t -1}. And in this one we can see that this is going to give us basically the variance of \\theta_t given D_{t -1} and then multiplied by F_t' F_t which gives me the F_t. So this is going to be variance of \\theta_t given D_{t -1} times F_t. And then there is a term that combines the \\theta_t with the noise but they are independent, so the covariance is going to be zero. So this one is simply going to be my R_t F_t, so this goes here, And what goes here is just the covariance of y_t with \\theta_t or the transpose of this. So this is going to give me F_t' R_t', but R_t is a covariance matrix, so R_t' = R_t. So now I have my full multivariate distribution and I can use properties of the multivariate distribution to compute the distribution of, \\theta_t, given y_t and D_{t -1}. So that’s going to be a conditional distribution, I’m going to condition on the y_t. And when I combine y_t and D_{t -1} that gives me just the information up to time t. So we are interested in just finding, say, \\theta_t given y_t and D_{t -1} which is the same as \\theta_t given D_t. We partition the normal distribution in this way, so I can just think about this is the first component and then I have these different pieces in my covariance matrix. And we know from normal theory that if we have a distribution, if we have a vector that is partitioned into vectors here where they are normally distributed. And I have my mean partition here and let’s say I have one component here, Then we know that if I wanted to compute the distribution of X_1 conditional on X_2, that’s going to give me normal, let’s say \\alpha^*. And let’s call this one the \\sigma^*, where \\alpha^* is going to be my \\alpha_1 + \\sigma_{12}^{-1}. And then I have _1 - \\alpha_2 and then I have my \\sigma^*. And this one gives me my \\sigma_{11} - \\sigma_{21}. So this is a result from normal theory. So if I want my conditional distribution of X_1 given X_2 I can apply these equations. So we notice we have the same type of structure here. If I partition my vector and in \\theta_t and y_t. And now I condition on, I take the distribution of \\theta_t conditioning on y_t. I’m going to have that same structure where this is normal, m_t C_t. And my m_t using normal theory, again, is going to be a_t + \\sigma_{22}^{-1}. And then I have y_t - f_t. So that’s my mean and my covariance matrix. It’s going to be R_t - q_t^{-1} and then I have this transpose again. So if we simplify things a bit here and we call e_t, it’s just the error that we make when we compare y_t, which is the observation with the prediction, right? And then I also use the notation I call a_t, let’s call here A_t R_t F_t q_t^{-1}. Then we can write this down, to mean, we can write as a_t + A_t. And the covariance matrix. We can write it as R_t, A_t q_t A_t'. So this gives me the posterior mean after receiving this y_t observation. And you can see that you can write down the posterior mean, has this usual form of the prior plus something that relates to the error that I make with the prediction.\nSo the y_t appears there and then is weighted by this quantity that we just call a_t.\nAnd for the covariance structure, we are also incorporating information about the prior and what the y_t observation provides. So this gives us our filtering equation for \\theta_t given D_t. And now we can apply all these equations as we receive observations from t = 1 all the way to T. If we happen to have T observations in the time series, we can do this filtering process and obtain these distributions as we receive information.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-filtering-distributions-reading",
    "href": "C4-L03.html#summary-of-filtering-distributions-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.2 Summary of filtering distributions (Reading)",
    "text": "93.2 Summary of filtering distributions (Reading)\n\n93.2.1 Bayesian Inference in NDLM: Known Variances\nConsider an NDLM given by:\n\n\\begin{aligned}\ny_t &= F_t' \\theta_t + \\nu_t, \\quad \\nu_t \\sim  \\mathcal{N}(0, v_t), \\\\\n\\theta_t &= G_t \\theta_{t-1} + \\omega_t, \\quad \\omega_t \\sim  \\mathcal{N}(0, W_t),\n\\end{aligned}\n\\tag{93.9}\nwith F_t, G_t, v_t, and W_t known. We also assume a prior distribution of the form (\\theta_0 \\mid \\mathcal{D}_0) \\sim  \\mathcal{N}(m_0, C_0), with m_0, C_0 known.\n\n93.2.1.1 Filtering\nWe are interested in finding \\mathbb{P}r(\\theta_t \\mid \\mathcal{D}_t) for all t. Assume that the posterior at t-1 is such that:\n\n(\\theta_{t-1} \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(m_{t-1}, C_{t-1}).\n\\tag{93.10}\nThen, we can obtain the following:\n\nPrior at Time t\n\n\n(\\theta_t \\mid \\mathcal{D}_{t-1}) \\sim  \\mathcal{N}(a_t, R_t),\n\nwith\n\na_t = G_t m_{t-1} \\qquad R_t = G_t C_{t-1} G_t' + W_t.\n\n\nOne-Step Forecast\n\n\n(y_t \\mid D_{t-1}) \\sim  \\mathcal{N}(f_t, q_t),\n\nwith\n\nf_t = F_t' a_t, \\quad q_t = F_t' R_t F_t + v_t.\n\n\nPosterior at Time t: (\\theta_t \\mid \\mathcal{D}_t) \\sim  \\mathcal{N}(m_t, C_t) with\n\n\\begin{aligned}\nm_t &= a_t + R_t F_t q_t^{-1} (y_t - f_t), \\\\\nC_t &= R_t - R_t F_t q_t^{-1} F_t' R_t.\n\\end{aligned}\n\nNow, denoting e_t = (y_t - f_t) and A_t = R_t F_t q_t^{-1}, we can rewrite the equations above as:\n\\begin{aligned}\nm_t &= a_t + A_t e_t, \\\\\nC_t &= R_t - A_t q_t A_t'\n\\end{aligned}",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#rcode-filtering-in-the-ndlm-example-reading",
    "href": "C4-L03.html#rcode-filtering-in-the-ndlm-example-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.3 Rcode Filtering in the NDLM: Example (Reading)",
    "text": "93.3 Rcode Filtering in the NDLM: Example (Reading)\n\n\nCode\n#################################################\n##### Univariate DLM: Known, constant variances\n#################################################\nset_up_dlm_matrices &lt;- function(FF, GG, VV, WW){\n  return(list(FF=FF, GG=GG, VV=VV, WW=WW))\n}\n\nset_up_initial_states &lt;- function(m0, C0){\n  return(list(m0=m0, C0=C0))\n}\n\n### forward update equations ###\nforward_filter &lt;- function(data, matrices, initial_states){\n  ## retrieve dataset\n  y_t &lt;- data$y_t\n  T &lt;- length(y_t)\n  \n  ## retrieve a set of quadruples \n  # FF, GG, VV, WW are scalar\n  FF &lt;- matrices$FF  \n  GG &lt;- matrices$GG\n  VV &lt;- matrices$VV\n  WW &lt;- matrices$WW\n  \n  ## retrieve initial states\n  m0 &lt;- initial_states$m0\n  C0 &lt;- initial_states$C0\n  \n  ## create placeholder for results\n  d &lt;- dim(GG)[1]\n  at &lt;- matrix(NA, nrow=T, ncol=d)\n  Rt &lt;- array(NA, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(NA, nrow=T, ncol=d)\n  Ct &lt;- array(NA, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  \n  for(i in 1:T){\n    # moments of priors at t\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(m0)\n      Rt[, , i] &lt;- GG %*% C0 %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }else{\n      at[i, ] &lt;- GG %*% t(mt[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , i-1] %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(FF) %*% (at[i, ]) \n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% FF / Qt[i]\n    et[i] &lt;- y_t[i] - ft[i]\n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- Rt[, , i] - Qt[i] * At %*% t(At)\n    Ct[, , i] &lt;- 0.5*Ct[, , i]+ 0.5*t(Ct[, , i])\n  }\n  cat(\"Forward filtering is completed!\") # indicator of completion\n  return(list(mt = mt, Ct = Ct, at = at, Rt = \n                Rt, ft = ft, Qt = Qt))\n}\n\nforecast_function &lt;- function(posterior_states, k, matrices){\n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  WW &lt;- matrices$WW\n  VV &lt;- matrices$VV\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state-space parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(mt[T, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , T] %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }else{\n      at[i, ] &lt;- GG %*% t(at[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Rt[, , i-1] %*% t(GG) + WW\n      Rt[, , i] &lt;- 0.5*Rt[, , i]+0.5*t(Rt[, , i])\n    }\n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(FF) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n  }\n  cat(\"Forecasting is completed!\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval &lt;- function(mu, sigma2, \n                          quantile = c(0.025, 0.975)){\n  z_quantile &lt;- qnorm(quantile)\n  bound &lt;- matrix(0, nrow=length(mu), ncol=2)\n  bound[, 1] &lt;- mu + \n    z_quantile[1]*sqrt(as.numeric(sigma2)) # lower bound\n  bound[, 2] &lt;- mu + \n    z_quantile[2]*sqrt(as.numeric(sigma2)) # upper bound\n  return(bound)\n}\n\n####################### Example: Lake Huron Data ######################\nplot(LakeHuron,main=\"Lake Huron Data\",\n     ylab=\"level in feet\") # Total of 98 observations \n\n\n\n\n\n\n\n\n\nCode\nk=4\nT=length(LakeHuron)-k # We take the first 94 observations \n                      # only as our data\nts_data=LakeHuron[1:T]\nts_validation_data &lt;- LakeHuron[(T+1):98]\n\ndata &lt;- list(y_t = ts_data)\n\n# First order polynomial model \n\n## set up the DLM matrices \nFF &lt;- as.matrix(1)\nGG &lt;- as.matrix(1)\nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(1)\nm0 &lt;- as.matrix(570)\nC0 &lt;- as.matrix(1e4)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF, GG, VV, WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering\nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nnames(results_filtered)\n\n\n[1] \"mt\" \"Ct\" \"at\" \"Rt\" \"ft\" \"Qt\"\n\n\nCode\nci_filtered &lt;- get_credible_interval(results_filtered$mt, \n                                     results_filtered$Ct)\n\n## forecasting \nresults_forecast &lt;- forecast_function(results_filtered,k, \n                                      matrices)\n\n\nForecasting is completed!\n\n\nCode\nci_forecast &lt;- get_credible_interval(results_forecast$ft, \n                                     results_forecast$Qt)\n\nindex=seq(1875, 1972, length.out = length(LakeHuron))\nindex_filt=index[1:T]\nindex_forecast=index[(T+1):98]\n\nplot(index, LakeHuron, ylab = \"level\", \n     main = \"Lake Huron Level\",type='l',\n     xlab=\"time\",lty=3,ylim=c(574,584))\npoints(index,LakeHuron,pch=20)\n\nlines(index_filt, results_filtered$mt, type='l',\n      col='red',lwd=2)\nlines(index_filt, ci_filtered[, 1], type='l', \n      col='red', lty=2)\nlines(index_filt, ci_filtered[, 2], type='l', col='red', lty=2)\n\n\nlines(index_forecast, results_forecast$ft, type='l',\n      col='green',lwd=2)\nlines(index_forecast, ci_forecast[, 1], type='l',\n      col='green', lty=2)\nlines(index_forecast, ci_forecast[, 2], type='l',\n      col='green', lty=2)\n\nlegend('bottomleft', legend=c(\"filtered\",\"forecast\"),\n       col = c(\"red\", \"green\"), lty=c(1, 1))\n\n\n\n\n\n\n\n\n\nCode\n#Now consider a 100 times smaller signal to noise ratio \nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(0.01)\nmatrices_2 &lt;- set_up_dlm_matrices(FF,GG, VV, WW)\n\n## filtering\nresults_filtered_2 &lt;- forward_filter(data, matrices_2, \n                                     initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nci_filtered_2 &lt;- get_credible_interval(results_filtered_2$mt, \n                                       results_filtered_2$Ct)\n\nresults_forecast_2 &lt;- forecast_function(results_filtered_2, \n                             length(ts_validation_data), \n                             matrices_2)\n\n\nForecasting is completed!\n\n\nCode\nci_forecast_2 &lt;- get_credible_interval(results_forecast_2$ft, \n                                       results_forecast_2$Qt)\n\n\nplot(index, LakeHuron, ylab = \"level\", \n     main = \"Lake Huron Level\",type='l',\n     xlab=\"time\",lty=3,ylim=c(574,584))\npoints(index,LakeHuron,pch=20)\n\nlines(index_filt, results_filtered_2$mt, type='l', \n      col='magenta',lwd=2)\nlines(index_filt, ci_filtered_2[, 1], type='l', \n      col='magenta', lty=2)\nlines(index_filt, ci_filtered_2[, 2], type='l', \n      col='magenta', lty=2)\n\nlines(index_forecast, results_forecast_2$ft, type='l', \n      col='green',lwd=2)\nlines(index_forecast, ci_forecast_2[, 1], type='l', \n      col='green', lty=2)\nlines(index_forecast, ci_forecast_2[, 2], type='l', \n      col='green', lty=2)\n\nlegend('bottomleft', legend=c(\"filtered\",\"forecast\"),\n       col = c(\"magenta\", \"green\"), lty=c(1, 1))\n\n\n\n\n\n\n\n\n\nCode\nplot(index_filt,results_filtered$mt,type='l',col='red',lwd=2,\n     ylim=c(574,584),ylab=\"level\")\nlines(index_filt,results_filtered_2$mt,col='magenta',lwd=2)\npoints(index,LakeHuron,pch=20)\nlines(index,LakeHuron,lty=2)",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#smoothing-and-forecasting-video",
    "href": "C4-L03.html#smoothing-and-forecasting-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.4 Smoothing and forecasting (Video)",
    "text": "93.4 Smoothing and forecasting (Video)\n\n\n\n\nSmoothing\n\n\n\n\nForecasting\n\n\nWe now discuss the smoothing equations for the case of the NDLM, where we are assuming that the variance at the observation level \\nu_t and the covariance matrix at the system level \\mathbf{W}_t are both known.\n \\begin{aligned}\ny_t &= \\mathbf{F}_t' \\mathbf{\\theta}_t + \\nu_t, &\\nu_t &\\sim \\mathcal{N} (0, v_t), & \\text{(observation)} \\\\\n\\mathbf{\\theta}_t & = \\mathbf{G}_t \\mathbf{\\theta}_{t-1} + \\mathbf{\\omega}_t, &\\mathbf{\\omega}_t & \\sim \\mathcal{N} (0, \\mathbf{W}_t), & \\text{(evolution)} \\\\\n&\\{ \\mathbf{F}_t, \\mathbf{G}_t, v_t, \\mathbf{W}_t \\}  &(\\mathbf{\\omega}_0 \\mid \\mathcal{D}_0) & \\sim \\mathcal{N}(\\mathbf{m}_0, \\mathbf{C}_0) & \\text{(prior)}\n\\end{aligned}\n\\tag{93.11}\nwith F_t, G_t, v_t, W_t, m_0 and C_0 known.\nWe have discussed the filtering equations, i.e. the process for obtaining the distributions of \\theta_t \\mid \\mathcal{D}_t, as we collect observations over time, called filtering.\nWe do this by updating the distribution of \\theta_t given the data we have collected step by step, as we move forward in time - updating the from the prior distribution.\nNow we will discuss what happens when we do smoothing, meaning when we revisit the distributions of \\theta_t, given now that we have received a set of observations.\n\n93.4.0.1 Smoothing\nFor t &lt; T, we have that:\n\n(\\theta_t \\mid D_T) \\sim  \\mathcal{N}(a_T(t - T), R_T(t - T)),\n\nwhere\n\na_T(t - T) = m_t - B_t [a_{t+1} - a_T(t - T + 1)],\n\n\nR_T(t - T) = C_t - B_t [R_{t+1} - R_T(t - T + 1)] B_t',\n\nfor t = (T - 1), (T - 2), \\dots, 0, with B_t = C_t G_t' R_{t+1}^{-1}, and a_T(0) = m_T, R_T(0) = C_T. Here a_t, m_t, R_t, and C_t are obtained using the filtering equations as explained before.\n\n\n93.4.0.2 Forecasting\nFor h \\geq 0, it is possible to show that:\n\n(\\theta_{t+h} \\mid D_t) \\sim  \\mathcal{N}(a_t(h), R_t(h)),\n\n\n(y_{t+h} \\mid D_t) \\sim  \\mathcal{N}(f_t(h), q_t(h)),\n\nwith\n\na_t(h) = G_{t+h} a_t(h - 1),\n\n\nR_t(h) = G_{t+h} R_t(h - 1) G_{t+h}' + W_{t+h},\n\n\nf_t(h) = F_{t+h}' a_t(h),\n\n\nq_t(h) = F_{t+h}' R_t(h) F_{t+h} + v_{t+h},\n\nand\n\na_t(0) = m_t, \\quad R_t(0) = C_t.\n\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\n\nSmoothing\n\nWe know, we now discuss the smoothing equations for the case of the normal dynamic linear model. When we are assuming that both the variance at the observation level is known and the covariance matrix at the system level is also known.\n\n\n\nthe NDLM we will be inferring\n\nRecall we have two equations here, we have the observation equation, where y_t is modeled as F_t'\\theta_t + \\text{noise} the noise is \\mathcal{N}(0,\\nu_t). And we’re assuming that the vt is given. We are also assuming that we know Ft for all t. And then in the evolution equation we have \\theta_t= G_t \\theta(t-1) + noise. And then again, the assumption for the w_t is here is that they are normally distributed with mean zero, and these variants co variance matrix, capital W_t. So we can summarize the model in terms of F_t, G_t, Vt and W_t, that are given for all t. We have discussed the filtering equations.\n\n\n\nRecall what is Filtering?\n\nSo the process for obtaining the distributions of \\theta_t \\mid \\mathcal{D}_t, as we collect observations over time is called filtering.\n\n\n\nRecall what is Smoothing?\n\nNow we will discuss what happens when we do smoothing, meaning when we revisit the distributions of \\theta_t, given now that we have received a set of observations.\n\n\n\nFiltering illustrated\n\nSo Just to illustrate the process, we have here, \\theta_0,\\theta_1 all way up to \\theta_4. And we can assume just for the sake of the example, that we are going to receive three observations. So we are going to proceed with the filtering, and then once we receive the last observation at time three, we’re going to go backwards and we’re going to revisit the distributions for the state parameters.\nSo just to remind you how the filtering works, we move forward, before we receive any observations. In the NDLM, when we have all the variances known. The conjugate prior distribution is a \\mathcal{N}(m_0,C_0), and this is specified by the user, before collecting any observations.\nWe can then use the structure of the model, meaning the system equation and the observation equation to obtain the distribution of \\theta_t \\mid \\mathcal{D}_0. Before observing the first y. This gives us first the distribution of \\theta_t, \\theta_1 \\mid \\mathcal{D}_0, which is \\mathcal{N}(a_1, R_1). And then we can also get the one step ahead forecast distribution for y_1 \\mid  \\mathcal{D}_0, which is a \\mathcal{N}(f_1, q_1). And we have discussed how to obtain these moments using the filtering equations.\nThen we received the first observation, and the first observation can allows us to update the distribution of . So we obtain now the distribution of \\theta1 \\mid y_1, and whatever information we have at \\mathcal{D}_0. So this gives us \\mathcal{N}(m_1, C_1). And using again the structure of the model, we can get the prior distribution for \\theta_2 given the one and that’s a \\mathcal{N}(a_2, R_2). And then the one step ahead forecast distribution now for y_2 \\mid \\mathcal{D}_1 and that’s a \\mathcal{N}(f_2, q_2). So we can receive y_2 update the distribution of and we can continue this process, now get the priors at T=3. And then once we get the observation at T=3, we update the distribution. And we can continue like this with the prior for \\theta_4 and so on. Let’s say that we stop here, at T=3.\n\n\nAnd now we are interested in answering the question. Well, what is the distribution for example of \\theta_2 given that, now, I obtain not only y_1 and y_2, but also y_3. I want to revisit that distribution using all that information. Same thing for say, the distribution of \\theta_0 \\mid D_0, y_1, y_2, y_3. So that’s what it’s called smoothing.\nSo the smoothing equations, allow us to obtain those distributions. So just to talk a little bit about the notation again, in the normal dynamic linear model where v_t and w_t are known for all t’s. We have that this is a normal, so the notation here, the T &gt;t, here. So we’re looking at the distribution of \\theta_t, now in the past and that one follows a normal distribution with mean aT(t-T). So the notation here for the subscript T means that I’m conditioning on all the information I have to T. And then the variance covariance matrix is given by this, RT(t-T). So this is just going to indicate how many steps I’m going to go backwards as you will see in the example.\n\n\nSo we have some recursions in the same way that we have the filtering equations. Now we have the smoothing equations. And for these smoothing equations we have that the mean. You can see here, that whenever you’re computing a particular step t- T, you’re going to need a quantity that you computed in the previous step, t-T+1. So you’re going to need that, is a recursion, but you’re also going to need mt and and at+1. So those are quantities that you computed using the filtering equations. So in order to get the smoothing equations, you first have to proceed with the filtering. Similarly for RT(t-T), you have also that depends on something you previously obtained. And then you also have the Ct, the Rt+1 and so on. So those quantities you computed when you were updating the filtering equations. The recursion begins with aT(0) meaning that you are not going to go backwards any points in time. So that is precisely the mean is going to be whatever you computed with the filtering equations of up to T, that’s mT. And then RT(0) is going to be CT. So just to again illustrate how this would work in the example, if we start here right? If we condition, so the first step would be to compute again to initialize using the distribution of given D3. And that is a normal with mean a3(0) and variance covariance matrix R3(0), But those are precisely m3 and C3 respectively. Then we go backwards one step. And if we want to look at what is the distribution of \\theta^2, now conditional on D3. That’s a normal with mean a3(-1) and variance covariance matrix R3(-1). So if you look at the equations down here, you will see that, in order to compute a3 (-1), and R3(-1). You’re going to need m2,C2, a3,R3 and then what you computed here these moments in the previous step, a3(0) and R3(0). Then you obtain that distribution and you can now look at the distribution of given D3, that’s the normal a3(-2), R3(-2). And once again, to compute these moments, you’re going to need m1,C1,a2,R2 and then you’re going to need a3(-1),R3(-1). And you can continue all the way down to given D3 using these recursions. So the smoothing equations allow us to, just compute all these distributions. And the important equations work basically because of the linear and Gaussian structure in the normal dynamic linear model.\n\n\n\n93.4.1 Forecasting\n\nIn a similar way, we can compute the forecasting distributions. Now we are going to be looking forward, and in the case of forecasting, we are interested in the distribution of \\theta(t+h) given D_t. And now h is a positive lag. So here we assume that is h≥0. So we are going to have the recursion is a N(a_t(h), R_t(h)). The mean is a_t(h) and we are going to use the structure of the model to obtain these recursions, again. So here we are using the system equation, and the moment at(h) depends on what you computed at a_t(h-1) the previous lag, times G_{t+h}. And then, would you initialize the recursion with a_t(0)=m_t.\n\n\nSimilarly, for the covariance matrix h steps ahead, you’re going to have a recursion that depends on Rt(h-1). And then you’re going to need to input also G_{t+h} and W_{t+h}. To initialize, the recursion with Rt(0)= Ct. So you can see that in order to compute these moments, you’re going to need mt and Ct to start with. And then you’re also going to have to input all the G’s and the W’s for the number of steps ahead that you require.\n\n\nSimilarly, you can compute the distribution, the h steps ahead distribution of y_t+h given Dt. And that one also follows a normal, with mean f_t(h), q_t(h). And now we also have a recursion here, ft(h) depends on at(h) and as we said, a_t(h) depends on a_t(h-1) and so on. And q_t(h) is just given by these equations. So once again, you have to have access to F_{t+h} for all the h, a number of steps ahead that you are trying to compute this distribution. And then you also have to provide the observational variance for every h value. So that you get v_{t+h}. So this is specified in the modeling framework as well. If you want proceed with the forecasting distributions.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#summary-of-the-smoothing-and-forecasting-distributions-reading",
    "href": "C4-L03.html#summary-of-the-smoothing-and-forecasting-distributions-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.5 Summary of the smoothing and forecasting distributions (reading)",
    "text": "93.5 Summary of the smoothing and forecasting distributions (reading)\n\n\n93.5.1 Bayesian Inference in NDLM: Known Variances\nConsider the NDLM given by:\n \\begin{aligned}\ny_t &= \\mathbf{F}_t' \\mathbf{\\theta}_t + \\nu_t, &\\nu_t &\\sim \\mathcal{N} (0, v_t), \\\\\n\\mathbf{\\theta}_t &= \\mathbf{G}_t \\mathbf{\\theta}_{t-1} + \\mathbf{\\omega}_t, &\\mathbf{\\omega}_t &\\sim \\mathcal{N} (0, \\mathbf{W}_t), \\\\\n&\\{ \\mathbf{F}_t, \\mathbf{G}_t, v_t, \\mathbf{W}_t \\}  &(\\mathbf{\\omega}_0 \\mid \\mathcal{D}_0) &\\sim  \\mathcal{N}(\\mathbf{m}_0, \\mathbf{C}_0)\n\\end{aligned}\n\\tag{93.12}\nwith F_t, G_t, v_t, and W_t known.\nWe also assume a prior distribution of the form (\\theta_0 \\mid D_0) \\sim  \\mathcal{N}(m_0, C_0), with m_0 and C_0 known.\n\n93.5.1.1 Smoothing\nFor t &lt; T, we have that:\n\n(\\theta_t \\mid D_T) \\sim  \\mathcal{N}(a_T(t - T), R_T(t - T)),\n\nwhere\n\na_T(t - T) = m_t - B_t [a_{t+1} - a_T(t - T + 1)],\n\n\nR_T(t - T) = C_t - B_t [R_{t+1} - R_T(t - T + 1)] B_t',\n\nfor t = (T - 1), (T - 2), \\dots, 0, with B_t = C_t G_t' R_{t+1}^{-1}, and a_T(0) = m_T, R_T(0) = C_T. Here a_t, m_t, R_t, and C_t are obtained using the filtering equations as explained before.\n\n\n93.5.1.2 Forecasting\nFor h \\geq 0, it is possible to show that:\n\n(\\theta_{t+h} \\mid D_t) \\sim  \\mathcal{N}(a_t(h), R_t(h)),\n\n\n(y_{t+h} \\mid D_t) \\sim  \\mathcal{N}(f_t(h), q_t(h)),\n\nwith\n\na_t(h) = G_{t+h} a_t(h - 1),\n\n\nR_t(h) = G_{t+h} R_t(h - 1) G_{t+h}' + W_{t+h},\n\n\nf_t(h) = F_{t+h}' a_t(h),\n\n\nq_t(h) = F_{t+h}' R_t(h) F_{t+h} + v_{t+h},\n\nand\n\na_t(0) = m_t, \\quad R_t(0) = C_t.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#smoothing-in-the-ndlm-example-video",
    "href": "C4-L03.html#smoothing-in-the-ndlm-example-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.6 Smoothing in the NDLM, Example (Video)",
    "text": "93.6 Smoothing in the NDLM, Example (Video)",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#r-code-smoothing-in-the-ndlm-example-reading",
    "href": "C4-L03.html#r-code-smoothing-in-the-ndlm-example-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.7 R-code: Smoothing in the NDLM, Example (Reading)",
    "text": "93.7 R-code: Smoothing in the NDLM, Example (Reading)\n\n\nCode\n#################################################\n##### Univariate DLM: Known, constant variances\n#################################################\nset_up_dlm_matrices &lt;- function(FF, GG, VV, WW){\n  return(list(FF=FF, GG=GG, VV=VV, WW=WW))\n}\n\nset_up_initial_states &lt;- function(m0, C0){\n  return(list(m0=m0, C0=C0))\n}\n\n### forward update equations ###\nforward_filter &lt;- function(data, matrices, initial_states){\n  ## retrieve dataset\n  y_t &lt;- data$y_t\n  T &lt;- length(y_t)\n  \n  ## retrieve a set of quadruples \n  # FF, GG, VV, WW are scalar\n  FF &lt;- matrices$FF  \n  GG &lt;- matrices$GG\n  VV &lt;- matrices$VV\n  WW &lt;- matrices$WW\n  \n  ## retrieve initial states\n  m0 &lt;- initial_states$m0\n  C0 &lt;- initial_states$C0\n  \n  ## create placeholder for results\n  d &lt;- dim(GG)[1]\n  at &lt;- matrix(NA, nrow=T, ncol=d)\n  Rt &lt;- array(NA, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(NA, nrow=T, ncol=d)\n  Ct &lt;- array(NA, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  \n  \n  for(i in 1:T){\n    # moments of priors at t\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(m0)\n      Rt[, , i] &lt;- GG %*% C0 %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(mt[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(FF) %*% (at[i, ]) \n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% FF / Qt[i]\n    et[i] &lt;- y_t[i] - ft[i]\n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- Rt[, , i] - Qt[i] * At %*% t(At)\n    Ct[,,i] &lt;- 0.5*Ct[,,i] + 0.5*t(Ct[,,i]) \n  }\n  cat(\"Forward filtering is completed!\") # indicator of completion\n  return(list(mt = mt, Ct = Ct, at = at, Rt = Rt, \n              ft = ft, Qt = Qt))\n}\n\n\nforecast_function &lt;- function(posterior_states, k, matrices){\n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  WW &lt;- matrices$WW\n  VV &lt;- matrices$VV\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(mt[T, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , T] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(at[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Rt[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(FF) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n  }\n  cat(\"Forecasting is completed!\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval &lt;- function(mu, sigma2, \n                          quantile = c(0.025, 0.975)){\n  z_quantile &lt;- qnorm(quantile)\n  bound &lt;- matrix(0, nrow=length(mu), ncol=2)\n  bound[, 1] &lt;- mu + z_quantile[1]*sqrt(as.numeric(sigma2)) # lower bound\n  bound[, 2] &lt;- mu + z_quantile[2]*sqrt(as.numeric(sigma2)) # upper bound\n  return(bound)\n}\n\n### smoothing equations ###\nbackward_smoothing &lt;- function(data, matrices, \n                               posterior_states){\n  ## retrieve data \n  y_t &lt;- data$y_t\n  T &lt;- length(y_t) \n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  at &lt;- posterior_states$at\n  Rt &lt;- posterior_states$Rt\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  for(i in T:1){\n    # moments for the distributions of the state vector given D_T\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n      Cnt[, , i] &lt;- 0.5*Cnt[, , i] + 0.5*t(Cnt[, , i]) \n    }else{\n      inv_Rtp1&lt;-solve(Rt[,,i+1])\n      Bt &lt;- Ct[, , i] %*% t(GG) %*% inv_Rtp1\n      mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n      Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i + 1] - Rt[, , i+1]) %*% t(Bt)\n      Cnt[,,i] &lt;- 0.5*Cnt[,,i] + 0.5*t(Cnt[,,i]) \n    }\n    # moments for the smoothed distribution of the mean response of the series\n    fnt[i] &lt;- t(FF) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(FF) %*% t(Cnt[, , i]) %*% FF\n  }\n  cat(\"Backward smoothing is completed!\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n####################### Example: Lake Huron Data ######################\nplot(LakeHuron,main=\"Lake Huron Data\",ylab=\"level in feet\") \n\n\n\n\n\n\n\n\n\nCode\n# 98 observations total \nk=4\nT=length(LakeHuron)-k # We take the first 94 observations \n                     #  as our data\nts_data=LakeHuron[1:T]\nts_validation_data &lt;- LakeHuron[(T+1):98]\n\ndata &lt;- list(y_t = ts_data)\n\n## set up matrices\nFF &lt;- as.matrix(1)\nGG &lt;- as.matrix(1)\nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(1)\nm0 &lt;- as.matrix(570)\nC0 &lt;- as.matrix(1e4)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF,GG,VV,WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering\nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nci_filtered&lt;-get_credible_interval(results_filtered$mt,\n                                   results_filtered$Ct)\n## smoothing\nresults_smoothed &lt;- backward_smoothing(data, matrices, \n                                       results_filtered)\n\n\nBackward smoothing is completed!\n\n\nCode\nci_smoothed &lt;- get_credible_interval(results_smoothed$mnt, \n                                     results_smoothed$Cnt)\n\n\nindex=seq(1875, 1972, length.out = length(LakeHuron))\nindex_filt=index[1:T]\n\nplot(index, LakeHuron, main = \"Lake Huron Level \",type='l',\n     xlab=\"time\",ylab=\"level in feet\",lty=3,ylim=c(575,583))\npoints(index,LakeHuron,pch=20)\n\nlines(index_filt, results_filtered$mt, type='l', \n      col='red',lwd=2)\nlines(index_filt, ci_filtered[,1], type='l', col='red',lty=2)\nlines(index_filt, ci_filtered[,2], type='l', col='red',lty=2)\n\nlines(index_filt, results_smoothed$mnt, type='l', \n      col='blue',lwd=2)\nlines(index_filt, ci_smoothed[,1], type='l', col='blue',lty=2)\nlines(index_filt, ci_smoothed[,2], type='l', col='blue',lty=2)\n\nlegend('bottomleft', legend=c(\"filtered\",\"smoothed\"),\n       col = c(\"red\", \"blue\"), lty=c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#second-order-polynomial-filtering-and-smoothing-example-video",
    "href": "C4-L03.html#second-order-polynomial-filtering-and-smoothing-example-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.8 Second order polynomial: Filtering and smoothing example (Video)",
    "text": "93.8 Second order polynomial: Filtering and smoothing example (Video)\nIn this video walk through the code provided in the section below the comment\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nWe now consider another example where instead of fitting a first order polynomial we’re fitting a second order polynomial DLM. So I just want to show you how to set up the structure of the model in a case in which you have a state parameter vector. That is of dimension larger than one in this particular case we have a bivariate state parameter vector. So once again we are going to source this file that has all the DLM functions for the case in which the F, G, V and W are known. So we’re just assuming that this is the case and then we’re assuming that F, G, V and W are constant over time in these examples. So we just I’m going to use a new data set which is also data set available in R this data set corresponds to the atmospheric CO2 concentrations in parts per million in the location of Mauna Loa. And this is monthly data so I’m just plotting the data here. If you look at the data you can see that it has two important features. One of them is an increasing trend as the time increases the concentration increases. And then the other very specific feature that you can see in this data set is this seasonal behavior. So right now what I’m going to do with this example is we are going to ignore the seasonal behavior, and we are going to try to fit the model that captures the linear increasing trend using a second order polynomial model.\nSo I’m going to just specify everything here. We are going to use the entire data set here. We’re going to analyze the entire data. We are going to read in this into a list and then we’re going to set up the DLM in matrices. So here because the model it’s a second order polynomial we are going to have a state vector. That is of dimension two the F matrix is going to be, so it’s a vector that has 1 in the first entry and 0 in the second one. And then G is this upper triangular matrix that has 1s in the diagonal and 1 above the diagonal as well. So the two parameters that we’re fitting here one of them you can view the two components in the state of theta_t parameter vector. The first component corresponds to the baseline of the level and then the second component corresponds to the rate of growth in that level that we are fitting. So just defining the F and G like that. And then V the observational variance I’m just going to set it at 10. You can play with different numbers here, and the W is a diagonal matrix with .0001 in each of the elements in the diagonal. So these models are not as flexible as the ones that we are going to consider later. So in particular we are using an assumption that the two components in the state sector are independent over time which is usually not very realistic. And we can consider more flexible models later but just to show you here how to fit these models, for the prior distribution I have again two components. So I’m going to say that a priori my baseline is 315 parts per million. And then for the second, the rate of growth is going to be 0 a priori. And then I have C0 which is this 10 times the diagonal of dimension 2 so this is an identity matrix. So is we have a diagonal with the elements in the diagonal equal to 10. So we wrap up all the DLM matrices with the functions that we defined before. And then we proceed with the filtering equations just using the forward filter function. We can obtain credible intervals for the expected value of y_t via this filtering equations.\nSo the reason why I’m calling it the expected value of y_t via filtering it’s just the first component of the say that theta_t vectors. So that corresponds to the level of the series, the expected value of that y_t. And then, I can compute the smoothing equations using the backward smoothing. And again I have to pass the data, the structure of the model in terms of the matrices and the results that I obtained via the filtering equations. And I can compute credible intervals for this expected value via smoothing and as we mentioned before, it has the same structure the smoothing and the filtering is just that, we call the mean and the variance mt and Ct. In the case of the filtering equations for the smoothing equations we just call them mnt and Cnt. So now we can plot all the results here. I’m just going to plot the results that correspond to the smoothing distributions just for you to see. And we can see here that is this trend that is estimated here is capturing the structure of this linear increasing trend. And you can play with different values of the signal to noise ratio. So different values of the V and the W. And if you change the values so that there is more or less signal to noise ratio, you will see that you will capture more of the seasonal structure and less of this linear trend structure. If you were to change those values. So if I go back a little bit here you can see that I have a very low signal to noise ratio and I picked this on purpose, because I didn’t want to capture any of the seasonal behavior that I observe in the series through these parameters. So I’m assuming that a lot of the variation that I see now I’m just keeping it in the noise. Just because I want to just get a very smooth estimate for this linear trend through a second order polynomial model. In practice what we’re going to do later is we really want to construct a model in which we have a component for the linear trend using the second order polynomial model. And then we add another component that will allow us to capture also the seasonal behavior that we observe in this series using a Fourier component model. So we will illustrate that later, in a separate example here is just again to show you how to use the code for specifying a second order polynomial.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#using-the-dlm-package-in-r-video",
    "href": "C4-L03.html#using-the-dlm-package-in-r-video",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.9 Using the dlm package in R (Video)",
    "text": "93.9 Using the dlm package in R (Video)\nThe dlm package in R is a powerful tool for working with dynamic linear models. The package provides a wide range of functions for filtering, smoothing, forecasting, and parameter estimation in DLMs. In this video, we walk through the code provided in Listing 93.7.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\n\nSo here I’m going to show you how to use the dlm package to fit these dynamic linear models as well. So the dlm is package that is available from Cran. And it allows you to compute the filtering smoothing and forecasting equations for dynamic linear models. So I’m just going to show you how to do the same thing we’ve been doing with the code that I provided just using the dlm package. So I’m going to just run here the first examples that we ran. And I’m going to show you how to do the same again. So here, I’m just going through the Lake Huron data. So just setting up every_thing as we did before. And then going through the filtering and smoothing equations. And so we can now plot the results and just want to have all the results here. So we have the red line corresponds to the posterior mean for the distribution of \\theta_t given the Dt using a first order polynomial model to fit the data. And the blue line corresponds to the smoothing mean. So the mean of the posterior distribution of the smoothing equations here. So now we can look at how to fit this with the dlm package. So you have to call, install the package if you don’t have it installed. And then just call that library once you have installed the package. And the dlm package has a different set of functions to construct the model first.\nSo I’m going to use the function that is called the dlmModPoly, which allows you to fit polynomial models. So it constructs the polynomial models. The default function as you can see here is a function in that assumes that the polynomial model is of order 2. So here I want to polynomial model of all the 1. And then I’m going to specify the variance at the observational level, which is called dV in that package. dW is the variance at the evolution level. And then I have my prior mean for theta and the prior variance. I’m just using exactly the same prior distribution. And the package provides two functions of the dlm filter function allows you to providing the data. And the model that you just define computes the filtering recursions here. And then there is another function that is called the dlmSmooth that you essentially pass the results of the filtering equations. And then you obtain the smoothing distributions. So we’re just going to do that. And now I’m going to plot the results that I obtained from those filtering equations. One thing that you can see here, if I do names of, let’s say results_filter_dlm. You can see that the way in which the dlm functions from the dlm package keep the results. It has a particular format. So in the case of the dlm package, you’re going to have the information about what model you fitted. Then you have the mean of theta_t given Dt is kept in this m object. And then you have a is the prior mean of theta_t, given the t -1. And then f is the mean of the one step ahead forecast distribution. And then you have these U.C, D.C, U.R, D.R, those are just decompositions of the C variance matrix. So each of the Cs at time t. And then if you have also the composition of the R matrices. So the model, the way in which the functions are implemented in this dlm package. Assume used an SVD decomposition of all the matrices. So you have to keep in mind if you’re going to recover the structure here for the different components in the model. You have to keep this in mind. So for the filtering results, this is the structure. If you do names of the results, smooth, with the dlm package. You’re going to have again, here is the mean here that is called S and then you have the decomposition of the matrix as well. So, I’m just going to plot now for the filtering results. I’m just going to plot the mean here. And then for the smoothing distribution, I’m also going to plot that means. In this case, we’re working with the first order polynomial. So the dimension of the state vector is 1. So you can see that we obtain exactly the same results. And you can compare them numerically. The upper plot corresponds to the results we get with the code that we’ve been using. And the second block corresponds to just using the code from the dlm package. We can also run the example with the second order polynomial. So again, if I use the specification of the model that we use before with the functions that we described. I can keep my results there. And if I use the dlm package, I can use again, this is a second order polynomial model. I say that the order of the polynomial is 2, I use this dlmModPoly function. I specify the observational variance, the system variance m0 and C0. So I’m using exactly the same priors in this case. And then I use the dlm filter function and the dlm smooth just to compute the moments of the filtering and smoothing distributions. And then I can plot every_thing here. We are plotting just the first component here. The posterior distribution for the first component of the theta vector. Which also corresponds to the expected value of the y_t. And then if I do the same with the dlm package, you can see that you obtain the same results. So again, the upper plot corresponds to the results that we get from the code that we’ve been using. And then the bottom plot corresponds to the results that we get from the dlm package. So I just wanted to illustrate this. You’re welcome to always use the dlm package. Just keep in mind the structure in which the matrices are kept is a little bit different than what we have been discussing. Because the dlm package uses and SVD decomposition of the covariance matrices and keeps every_thing like that. So there are some differences. But you can also use this package to obtain inference in the case of dynamic linear models.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#r-code-using-the-dlm-package-in-r-reading",
    "href": "C4-L03.html#r-code-using-the-dlm-package-in-r-reading",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.10 R-code: Using the dlm package in R (Reading)",
    "text": "93.10 R-code: Using the dlm package in R (Reading)\n\n\n\n\nListing 93.1: Using the dlm package for dynamic linear models\n\n\n\nCode\n#################################################\n##### Univariate DLM: Known, constant variances\n#################################################\nset_up_dlm_matrices &lt;- function(FF, GG, VV, WW){\n  return(list(FF=FF, GG=GG, VV=VV, WW=WW))\n}\n\nset_up_initial_states &lt;- function(m0, C0){\n  return(list(m0=m0, C0=C0))\n}\n\n### forward update equations ###\nforward_filter &lt;- function(data, matrices, initial_states){\n  ## retrieve dataset\n  y_t &lt;- data$y_t\n  T &lt;- length(y_t)\n  \n  ## retrieve a set of quadruples \n  # FF, GG, VV, WW are scalar\n  FF &lt;- matrices$FF  \n  GG &lt;- matrices$GG\n  VV &lt;- matrices$VV\n  WW &lt;- matrices$WW\n  \n  ## retrieve initial states\n  m0 &lt;- initial_states$m0\n  C0 &lt;- initial_states$C0\n  \n  ## create placeholder for results\n  d &lt;- dim(GG)[1]\n  at &lt;- matrix(NA, nrow=T, ncol=d)\n  Rt &lt;- array(NA, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(NA, nrow=T, ncol=d)\n  Ct &lt;- array(NA, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  \n  \n  for(i in 1:T){\n    # moments of priors at t\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(m0)\n      Rt[, , i] &lt;- GG %*% C0 %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(mt[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(FF) %*% (at[i, ]) \n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% FF / Qt[i]\n    et[i] &lt;- y_t[i] - ft[i]\n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- Rt[, , i] - Qt[i] * At %*% t(At)\n    Ct[,,i] &lt;- 0.5*Ct[,,i] + 0.5*t(Ct[,,i]) \n  }\n  cat(\"Forward filtering is completed!\") # indicator of completion\n  return(list(mt = mt, Ct = Ct, at = at, Rt = Rt, \n              ft = ft, Qt = Qt))\n}\n\nforecast_function &lt;- function(posterior_states, k, matrices){\n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  WW &lt;- matrices$WW\n  VV &lt;- matrices$VV\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- GG %*% t(mt[T, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Ct[, , T] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }else{\n      at[i, ] &lt;- GG %*% t(at[i-1, , drop=FALSE])\n      Rt[, , i] &lt;- GG %*% Rt[, , i-1] %*% t(GG) + WW\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i]) \n    }\n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(FF) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(FF) %*% Rt[, , i] %*% FF + VV\n  }\n  cat(\"Forecasting is completed!\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval &lt;- function(mu, sigma2, \n                          quantile = c(0.025, 0.975)){\n  z_quantile &lt;- qnorm(quantile)\n  bound &lt;- matrix(0, nrow=length(mu), ncol=2)\n  bound[, 1] &lt;- mu + z_quantile[1]*sqrt(as.numeric(sigma2)) # lower bound\n  bound[, 2] &lt;- mu + z_quantile[2]*sqrt(as.numeric(sigma2)) # upper bound\n  return(bound)\n}\n\n### smoothing equations ###\nbackward_smoothing &lt;- function(data, matrices, \n                               posterior_states){\n  ## retrieve data \n  y_t &lt;- data$y_t\n  T &lt;- length(y_t) \n  \n  ## retrieve matrices\n  FF &lt;- matrices$FF\n  GG &lt;- matrices$GG\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  at &lt;- posterior_states$at\n  Rt &lt;- posterior_states$Rt\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  for(i in T:1){\n    # moments for the distributions of the state vector given D_T\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n      Cnt[, , i] &lt;- 0.5*Cnt[, , i] + 0.5*t(Cnt[, , i]) \n    }else{\n      inv_Rtp1&lt;-solve(Rt[,,i+1])\n      Bt &lt;- Ct[, , i] %*% t(GG) %*% inv_Rtp1\n      mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n      Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i + 1] - Rt[, , i+1]) %*% t(Bt)\n      Cnt[,,i] &lt;- 0.5*Cnt[,,i] + 0.5*t(Cnt[,,i]) \n    }\n    # moments for the smoothed distribution of the mean response of the series\n    fnt[i] &lt;- t(FF) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(FF) %*% t(Cnt[, , i]) %*% FF\n  }\n  cat(\"Backward smoothing is completed!\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n\n####################### Example: Lake Huron Data ######################\nplot(LakeHuron) # 98 observations total \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 93.2: Using the dlm package for dynamic linear models\n\n\n\nCode\nk=4\nT=length(LakeHuron)-k # We take the first \n                      # 94 observations only as our data\nts_data=LakeHuron[1:T]\nts_validation_data &lt;- LakeHuron[(T+1):98]\n\ndata &lt;- list(y_t = ts_data)\n\n## set up dlm matrices\nGG &lt;- as.matrix(1)\nFF &lt;- as.matrix(1)\nVV &lt;- as.matrix(1)\nWW &lt;- as.matrix(1)\nm0 &lt;- as.matrix(570)\nC0 &lt;- as.matrix(1e4)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF, GG, VV, WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering and smoothing \nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\n\n\n\nForward filtering is completed!\n\n\n\n\nListing 93.3: Using the dlm package for dynamic linear models\n\n\n\nCode\nresults_smoothed &lt;- backward_smoothing(data, matrices, \n                                       results_filtered)\n\n\n\n\n\nBackward smoothing is completed!\n\n\n\n\nListing 93.4: Using the dlm package for dynamic linear models\n\n\n\nCode\nindex=seq(1875, 1972, length.out = length(LakeHuron))\nindex_filt=index[1:T]\n\n\npar(mfrow=c(2,1), mar = c(3, 4, 2, 1))\nplot(index, LakeHuron, main = \"Lake Huron Level \",type='l',\n     xlab=\"time\",ylab=\"feet\",lty=3,ylim=c(575,583))\npoints(index,LakeHuron,pch=20)\nlines(index_filt, results_filtered$mt, type='l', \n      col='red',lwd=2)\nlines(index_filt, results_smoothed$mnt, type='l', \n      col='blue',lwd=2)\n\n\n# Now let's look at the DLM package \nlibrary(dlm)\nmodel=dlmModPoly(order=1,dV=1,dW=1,m0=570,C0=1e4)\nresults_filtered_dlm=dlmFilter(LakeHuron[1:T],model)\nresults_smoothed_dlm=dlmSmooth(results_filtered_dlm)\n\nplot(index_filt, LakeHuron[1:T], ylab = \"level\", \n     main = \"Lake Huron Level\",\n     type='l', xlab=\"time\",lty=3,ylim=c(575,583))\npoints(index_filt,LakeHuron[1:T],pch=20)\nlines(index_filt,results_filtered_dlm$m[-1],col='red',lwd=2)\nlines(index_filt,results_smoothed_dlm$s[-1],col='blue',lwd=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 93.5: Using the dlm package for dynamic linear models\n\n\n\nCode\n# Similarly, for the second order polynomial and the co2 data:\nT=length(co2)\ndata=list(y_t = co2)\n\nFF &lt;- (as.matrix(c(1,0)))\nGG &lt;- matrix(c(1,1,0,1),ncol=2,byrow=T)\nVV &lt;- as.matrix(200)\nWW &lt;- 0.01*diag(2)\nm0 &lt;- t(as.matrix(c(320,0)))\nC0 &lt;- 10*diag(2)\n\n## wrap up all matrices and initial values\nmatrices &lt;- set_up_dlm_matrices(FF,GG, VV, WW)\ninitial_states &lt;- set_up_initial_states(m0, C0)\n\n## filtering and smoothing \nresults_filtered &lt;- forward_filter(data, matrices, \n                                   initial_states)\n\n\n\n\n\nForward filtering is completed!\n\n\n\n\nListing 93.6: Using the dlm package for dynamic linear models\n\n\n\nCode\nresults_smoothed &lt;- backward_smoothing(data, matrices, \n                                       results_filtered)\n\n\n\n\n\nBackward smoothing is completed!\n\n\n\n\nListing 93.7: Using the dlm package for dynamic linear models\n\n\n\nCode\n#### Now, using the DLM package: \nmodel=dlmModPoly(order=2,dV=200,dW=0.01*rep(1,2),\n                 m0=c(320,0),C0=10*diag(2))\n# filtering and smoothing \nresults_filtered_dlm=dlmFilter(data$y_t,model)\nresults_smoothed_dlm=dlmSmooth(results_filtered_dlm)\n\npar(mfrow=c(2,1), mar = c(3, 4, 2, 1))\nplot(as.vector(time(co2)),co2,type='l',xlab=\"time\",\n     ylim=c(300,380))\nlines(as.vector(time(co2)),results_filtered$mt[,1],\n      col='red',lwd=2)\nlines(as.vector(time(co2)),results_smoothed$mnt[,1],\n      col='blue',lwd=2)\n\nplot(as.vector(time(co2)),co2,type='l',xlab=\"time\",\n     ylim=c(300,380))\nlines(as.vector(time(co2)),results_filtered_dlm$m[-1,1],\n      col='red',lwd=2)\nlines(as.vector(time(co2)),results_smoothed_dlm$s[-1,1],\n      col='blue',lwd=2)",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#practice-graded-assignment-ndlm-sensitivity-to-the-model-parameters",
    "href": "C4-L03.html#practice-graded-assignment-ndlm-sensitivity-to-the-model-parameters",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.11 Practice Graded Assignment: NDLM – sensitivity to the model parameters",
    "text": "93.11 Practice Graded Assignment: NDLM – sensitivity to the model parameters\nOmitted due to the Coursera honor code.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#quiz---ndlm-part-i-review",
    "href": "C4-L03.html#quiz---ndlm-part-i-review",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "93.12 Quiz - NDLM, Part I: Review",
    "text": "93.12 Quiz - NDLM, Part I: Review\nOmitted due to the Coursera honor code.\n\n\n\n\n\n\nPrado, Raquel, Gabriel Huerta, and Mike West. 2000. “Bayesian Time-Varying Autoregressions: Theory, Methods and Applications.” Resenhas Do Instituto de Matemática e Estatı́stica Da Universidade de São Paulo 4 (4): 405–22. https://www2.stat.duke.edu/~mw/MWextrapubs/Prado2001.pdf.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L03.html#footnotes",
    "href": "C4-L03.html#footnotes",
    "title": "91  Normal Dynamic Linear Models, Part 1",
    "section": "",
    "text": "the state makes it’s appearance↩︎",
    "crumbs": [
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 1</span>"
    ]
  },
  {
    "objectID": "C4-L04.html",
    "href": "C4-L04.html",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "",
    "text": "92.1 Seasonal NDLMs",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#seasonal-ndlms",
    "href": "C4-L04.html#seasonal-ndlms",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "",
    "text": "NoteLearning Objectives\n\n\n\n\n\n\nUse R for analysis and forecasting of time series using the NDLM (cases of known or unknown observational variance and unknown system variance specified using a discount factor)\nDerive the equations to obtain posterior inference and forecasting in the NDLM with unknown observational variance and system variance specified via discount factors\nDefine seasonal NDLMs\nApply the NDLM superposition principle and explain the role of the forecast function",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#fourier-representation-video",
    "href": "C4-L04.html#fourier-representation-video",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "92.2 Fourier representation (Video)",
    "text": "92.2 Fourier representation (Video)\nTranscript:\n\nI will now describe how to incorporate seasonal components in a normal dynamic linear model. What we will do is we will first talk about the so-called single Fourier component representation . Just in case you have a single frequency and how to incorporate that single frequency in your model for the seasonality. Then using the superposition principle, you can incorporate several frequencies or a single frequency and the corresponding harmonics in your model.single Fourier component representation\nThere are other seasonal representations as well clarification needed. We will focus on the Fourier representation as is is flexible without needing too many parameters. E.g. if you want to consider, a fundamental frequency but you don’t want all the harmonics of that frequency. The Fourier representation, if you happen to have a single frequency.\nWe will discuss two cases with different component representations:\n\n\\omega \\in (0,\\pi)\n\\omega = \\pi \\implies \\{ 1,1,\\cdot, \\cdot\\}\n\nIn the case of any frequency \\omega \\in (0,\\pi), we will have a DLM that has this structure:\n\n\\{ \\underbrace {E_2}_{F},  \\underbrace {J_2(1,\\omega)}_{G}, \\underbrace{\\cdot}_{v_t}, \\underbrace{\\cdot}_{W_t}\\}\n\\tag{92.1}\nWe will have the F vector the 2-dimensional vector: \nE_2=(1,0)'\n\\tag{92.2}\nAs usual and the G matrix will be the 2 by 2 matrix:\n\nJ_2(1, \\omega) =\n\\begin{pmatrix}\n\\cos(\\omega) & \\sin(\\omega) \\\\\n-\\sin(\\omega) & \\cos(\\omega)\n\\end{pmatrix},\n\\tag{92.3}\nwhere \\omega is the frequency that we are considering.\nSince this is a 2 by 2 matrix the our state parameter vector will also be a vector of dimension 2.\nIf we think about the forecast function, f_t(h) h-steps ahead, (you are at time t and you want to look for h steps ahead).\nLet’s recall: the way we work with this is F* G^h * a_t\ngoing to be your E_2', then you have to take this G matrix, which is just this J_2(1,\\omega)^h, and then you have a vector, I’m going to call a_t and b_t, which is just going to be this vector value of your Theta t vector given the information up to the time t. It’s going to have two components, I’m just going to generically call them a_t and b_t. When you take this to the power of h using just trigonometric results, you’re going to get that J_2(1,\\omega)^h, is just going to give you cosine of Omega h sine of Omega h minus sine of Omega h cosine of Omega h. When you look at this expression, you get something that looks like this, and then you have, again, times these a_t, b_t.\n\n\\begin{aligned}\nf_t(h) &= E_2' [J_2(1, \\omega)]^h \\underbrace{\\begin{pmatrix} a_t \\\\ b_t \\end{pmatrix}}_{\\mathbb{E}[\\theta\\mid \\mathcal{D}]} \\\\\n&= (1,0) \\begin{pmatrix} \\cos(\\omega h) & \\sin(\\omega h) \\\\ -\\sin(\\omega h) & \\cos(\\omega h) \\end{pmatrix} \\begin{pmatrix} a_t \\\\ b_t \\end{pmatrix} \\\\\n&= a_t \\cos(\\omega h) + b_t \\sin(\\omega h) \\\\\n&= A_t \\cos(\\omega h + B_t).\n\\end{aligned}\n\\tag{92.4}\n\nYou’re going to have the cosine and sine only multiplied by this. In the end, you’re going to have something that looks like this.\nYou have this sinusoidal form with the period Omega in your forecast function. You can also write this down in terms of an amplitude that I’m going to call A_t and then a phase that is B_t. Here again, you have your periodicity that appears in this cosine wave. This is again for the case in which you have a single frequency and the frequencies in this range. There was a second case that I mentioned, and that case is the case in which the Omega is exactly Pi. In this case, your Fourier representation is going to be your model that has a state vector that is just one dimensional. In the case where Omega is between zero and Pi, you have a two-dimensional state, vector here you’re going to have a one-dimensional state vector.\nThis is going to be your F and your G. Then you have again whatever you want to put here as your v_t and W_t. This gives me, if I think about the forecast function, h steps ahead is just going to be something that has the form -1^h \\times a_t. Now I have a single component here, is uni-dimensional. This is going to have an oscillatory behavior between a_t and -a_t if I were to look h steps ahead forward when I’m at time t. These two forms give me the single component Fourier representation and using the superposition principle, we will see that we can combine a single frequency and the corresponding harmonics or several different frequencies just using the superposition principle in the normal dynamic linear model. You can also incorporate more than one component in a full Fourier representation. Usually the way this works is you have a fundamental period, let’s say p. For example, if you are recording monthly data, p could be 12 and then you are going to incorporate in the model the fundamental frequency, and then all the harmonics that go with that fundamental frequency related to the period p.\n\n\n\n\n\nslide 1\n\n\nHere p, is the period and in this case, we are going to discuss essentially two different situations. One is when p is an odd number, the other one is when p is an even number. Let’s begin with the case of p is odd and in this particular scenario, we can write down p as 2 times m minus 1 for some value of m. This gives me a period that is odd. How many frequencies I’m going to incorporate in this model? I’m going to be able to write down \\omega_j = 2 \\pi \\times j / p, which is the fundamental period. j here goes from one all the way to m minus 1. Now we can use the superposition principle thinking we have a component DLM representation for each of these frequencies. They are all going to be between 0 and Pi. For each of them I’m going to have that two-dimensional DLM representation in terms of the state vector and then I can use the superposition principle to concatenate them all and get a model that has all these frequencies, the one related to the fundamental period and all the harmonics for that. Again, if I think about what is my F and my G here, I’m not writing down the t because both F and G are going to be constant over time. So my F is going to be again, I concatenate as many E_2 as I have frequencies in here. I’m going to have E_2 transpose and so on and I’m going to have m minus one of those. Times 2 gives me the dimension of \\theta_t. The vector here is 2 times m minus 1 dimensional vector.\nMy G is going to have that block diagonal structure where we are going to just have all those J_{2,1} \\omega_1, all the way down to the last harmonic. Each of these blocks is a two-by-two matrix and I’m going to put them together in a block diagonal form. This gives me the representation when the period is odd, what is the structure of the forecast function? Again, using the superposition principle, the forecast function is going to be just the sum of m minus 1 components, where each of those components is going to have an individual forecast function that has that cosine wave representation that we discussed before. Again, if I think about the forecast function at time t h steps ahead, I will be able to write it down like this.\nThis should be a B. B_{t,j}. Again here, I have an amplitude for each of the components and a phase for each of the components so it depends on time but does not depend on h. The h enters here, and this is my forecast function. In the case of P even the situation is slightly different. But again, it’s the same in terms of using the superposition principle. In this case, we can write down P as 2 times m because it’s an even number. Now I can write down these Omega j’s as a function of the fundamental period. Again, this goes from 1 up to m minus 1. But there is a last frequency here. When j is equal to m, this simplifies to be the Nyquist frequency. In this case, I have my Omega is equal to Pi. In this particular case, when I concatenate everything, I’m going to have again an F and a G that look like this. Once again, I concatenate all of these up to the component m minus 1. Then I have this 1 for the last frequency. Then my G is going to be the block diagonal.\nFor the last frequency I have that minus 1. This determines the dimension of the state vector, in this case I’m going to have 2 times m minus 1 plus 1.\nMy f function, my forecast function, is again a function of the number of steps ahead. I’m going to have the same structure I had before for the m minus 1 components. Then I have to add one more component that corresponds to the frequency Pi. This one appears with the power of h. As you can see, I’m using once again the superposition principle to go from component representation to the full Fourier representation. In practice, once we set the period, we can use a model that has the fundamental period and all the harmonics related to that fundamental period. We could also use, discard some of those harmonics and use a subset of them. This is one of the things that the Fourier representation allows. It allows you to be flexible in terms of how many components you want to add in this model. There are other representations that are also used in practice. One of them is the seasonal factors representation. In that case, you’re going to have a model in which the state vector has dimension p for a given period. It uses a G matrix that is a permutation matrix. There is a correspondence between this parameterization using the Fourier representation and that other parameterization. If you want to use that parameterization, the way to interpret the components of this state vector, since you have P of those, is going to be a representation in terms of factors. For example, if you think about monthly data, you will have the say January factor, February factor, March factor, and so on. You could think about those effects and do a correspondence with this particular model. We will always work in this class with these representations because it’s more flexible. But again, you can go back and forth between one and the other.\n\n\n\n\n\nslide 2",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#fourier-representation-example-1-reading",
    "href": "C4-L04.html#fourier-representation-example-1-reading",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "92.3 Fourier Representation: Example 1 (Reading)",
    "text": "92.3 Fourier Representation: Example 1 (Reading)\n\n92.3.1 Seasonal Models\nExample: Full Fourier Model with p=5\nIn this case the Fourier frequencies are\n\nω_1 = 2π/5 and\nω_2 = 4π/5 and so\np = 2 × 3 − 1. Then,\nm = 3 and\n\\theta_t = (\\theta_{t,1}, \\ldots , \\theta_{t,4})′,\nF = (1, 0, 1, 0),\nG is given by:\n\n\nG = \\begin{bmatrix}\n\\cos(2\\pi/5) & \\sin(2\\pi/5) & 0 & 0 \\\\\n\\cos(4\\pi/5) & \\sin(4\\pi/5) & 0 & 0 \\\\\n0 & 0 & \\cos(2\\pi/5) & \\sin(2\\pi/5) \\\\\n0 & 0 & \\cos(4\\pi/5) & \\sin(4\\pi/5) \\\\\n0 & 0 & 0 & 0\n\\end{bmatrix}\n\nand the forecast function is:\n\nf_t(h) = A_{t,1} \\cos(2\\pi h/5 + \\gamma_t) + A_{t,2} \\cos(4\\pi h /5 + \\gamma_{t,2}) \\qquad\n\\tag{92.5}",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#building-ndlms-with-multiple-components-examples-video",
    "href": "C4-L04.html#building-ndlms-with-multiple-components-examples-video",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "92.4 Building NDLMs with multiple components: Examples (Video)",
    "text": "92.4 Building NDLMs with multiple components: Examples (Video)\n\n\n\n\ntwo component model\n\n\nIn this second example, we are going to have two components; a linear trend plus a seasonal component where the fundamental period is four. The way to build this model, again, is using the superposition principle.\nFirst we need to think “what structure do we need, to get a linear trend in the forecast function?”\nThe linear trend is a linear function on the number of steps ahead.\nWhenever you have that structure, you will get a DLM that is the so-called polynomial model of order 2. So let’s discuss first the linear. Let’s say the linear trend part, and in this case, we have an F and a G, I’m going to call them 1, F_1 and G_1 to denote that this is the first component in the model.\nF_1 is just going to be 1, 0 transpose, and the G_1 is that upper triangular matrix, it’s a 2 by 2 matrix that has 1, 1 in the first row, 0, 1 in the second row, so this gives me a linear trend.\nMy forecast function, let’s call it f_{1,t} in terms of the number of steps ahead is just a linear function on h, is a linear polynomial order 1. Let’s say it’s a constant of K but depends on t0 plus K_{t_1}^h. This is the structure of the first component. Then I have to think about the seasonal component with period of four. If we are going to incorporate all the harmonics, we have to think again, is this an even period or a not period? In this example, this is an even period. I can write p, which is 4, as 2 times 2, so this gives me that m. I’m going to have one frequency, the first one, Omega 1, is related to the fundamental period of 4, so is 2 Pi over 4, which I can simplify and write down this as Pi over 2. This is the first frequency. The last one is going to correspond to the Nyquist.\nWe could obtain that doing 4Pi over 4, which is just Pi. As you remember, this component is going to require a two-dimensional DLM component model, this one is going to require a one-dimensional DLM component model in terms of the dimension here is the dimension of the state vectors. When we build this concatenating these components, we are going to have, again, let’s call it F_2 and G_2 for this particular component. I had called this here a, let’s call this b. My F_2 has that E_2 transpose and a 1, which gives me just 1, 0, 1. My G matrix is going to be a 3 by 3 matrix. The first component is\nthe component associated to that fundamental period. It’s a block diagonal again, and I’m going to have that J_2, 1 Omega 1, and then I have my minus 1 here. What this means is if I write this down as a matrix, let me write it here, G_2 is going to be cosine of that Pi halves,\nand then I have zeros here, I have my minus 1 here, 0, and 0. I can further simplify these to have this structure. The cosine of Pi halves is 0, the sine is 1, so I can write this down as 0, 1, 0, minus 1, 0, 0, and 0, 0 minus 1. Now if I want to go back to just having a model that has both components, I use the superposition principle again and combine this component with this component. The linear plus seasonal\nis a model that is going to have the representation F, G, with F is going to be just concatenate F_1 and F_2. G now has that block diagonal form again.\nIf I look at what I have, I have this block that is a 2 by 2, this block that is a 3 by 3. Therefore my model is going to be a five-dimensional model in terms of the state parameter vector, so this G is a 5 by 5, and this one is also a five-dimensional vector. Finally, if I think about the forecast function in this case, if I call here the forecast function f_{2,t} for the component that is seasonal, I’m going to have my A_t1 cosine of Pi halves h plus B_{t,1}, and then I have my A_{t,2} minus 1^h. My forecast function for the final model is going to be just the sum of these two components.\nYou can see how I can now put together all these blocks, so I have a block that is seasonal and a block that is a linear polynomial model, and I can put them together in a single model just to create a more flexible structure. You could add regression components, you could add autoregressive components and put together as many components as you need for the forecast function to have the form that you expect it to have. All of these models are using, again, the superposition principle and the fact that we’re working with a linear and Gaussian structure in terms of doing the posterior inference later.",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#summary-dlm-fourier-representation-reading",
    "href": "C4-L04.html#summary-dlm-fourier-representation-reading",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "92.5 Summary: DLM Fourier representation (Reading)",
    "text": "92.5 Summary: DLM Fourier representation (Reading)\n\n92.5.1 Seasonal Models: Fourier Representation\nFor any frequency \\omega \\in (0, \\pi), a model of the form \\{E_2, J_2(1, \\omega), \\cdot, \\cdot\\} with a 2-dimensional state vector \\theta_t = (\\theta_{t,1}, \\theta_{t,2})' and\n\nJ_2(1, \\omega) =\n\\begin{pmatrix}\n\\cos(\\omega) & \\sin(\\omega) \\\\\n-\\sin(\\omega) & \\cos(\\omega)\n\\end{pmatrix},\n\nhas a forecast function\n\n\\begin{aligned}\nf_t(h) &= (1, 0) J_2^h(1, \\omega) (a_t, b_t) \\\\\n       &= a_t \\cos(\\omega h) + b_t \\sin(\\omega h) \\\\\n       &= A_t \\cos(\\omega h + B_t).\n\\end{aligned}\n\nFor \\omega = \\pi, the NDLM is \\{1, -1, \\cdot, \\cdot\\} and has a forecast function of the form\n\nf_t(h) = (-1)^h m_t\n\nThese are component Fourier models. Now, for a given period p, we can build a model that contains components for the fundamental period and all the harmonics of such a period using the superposition principle as follows:\n\n\n92.5.2 Case: p = 2m - 1 (odd)\nLet \\omega_j = 2\\pi j / p for j = 1 : (m - 1), F a (p - 1)-dimensional vector, or equivalently, a 2(m - 1)-dimensional vector, and G a (p - 1) \\times (p - 1) matrix with F = (E_2', E_2', \\dots, E_2')',\n\nG = \\text{blockdiag}[J_2(1, \\omega_1), \\dots, J_2(1, \\omega_{m-1})].\n\n\n\n92.5.3 Case: p = 2m (even)\nIn this case, F is again a (p - 1)-dimensional vector (or equivalently a (2m - 1)-dimensional vector), and G is a (p - 1) \\times (p - 1) matrix such that F = (E_2', \\dots, E_2', 1)' and\n\nG = \\text{blockdiag}[J_2(1, \\omega_1), \\dots, J_2(1, \\omega_{m-1}), -1].\n\nIn both cases, the forecast function has the general form:\n\nf_t(h) = \\sum_{j=1}^{m-1} A_{t,j} \\cos(\\omega_j h + \\gamma_{t,j}) + (-1)^h A_{t,m},\n\nwith A_{t,m} = 0 if p is odd.",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#examples",
    "href": "C4-L04.html#examples",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "92.6 Examples",
    "text": "92.6 Examples\n\n92.6.1 Fourier Representation, p = 12:\nIn this case, p = 2 \\times 6 so \\theta_t is an 11-dimensional state vector,\n\nF = (1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1)',\n\nthe Fourier frequencies are \\omega_1 = 2\\pi/12, \\omega_2 = 4\\pi/12 = 2\\pi/6, \\omega_3 = 6\\pi/12 = 2\\pi/4, \\omega_4 = 8\\pi/12 = 2\\pi/3, \\omega_5 = 10\\pi/12 = 5\\pi/6, and \\omega_6 = 12\\pi/12 = \\pi (the Nyquist frequency).\n\nG = \\text{blockdiag}(J_2(1, \\omega_1), \\dots, J_2(1, \\omega_5), 1)\n\nand the forecast function is given by:\n\nf_t(h) = \\sum_{j=1}^{5} A_{t,j} \\cos(2\\pi j / 12 + \\gamma_{t,j}) + (-1)^h A_{t,6}.\n\n\n\n92.6.2 Linear Trend + Seasonal Component with p = 4\nWe can use the superposition principle to build more sophisticated models. For instance, assume that we want a model with the following 2 components:\n\nLinear trend: \\{F_1, G_1, \\cdot, \\cdot\\} with F_1 = (1, 0)',\n\n\nG_1 = J_2(1) =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}.\n\n\nFull seasonal model with p = 4: \\{F_2, G_2, \\cdot, \\cdot\\}, p = 2 \\times 2 so m = 2 and \\omega = 2\\pi / 4 = \\pi / 2,\n\n\nF_2 = (1, 0, 1)',\n\nand\n\nG_2 =\n\\begin{pmatrix}\n\\cos(\\pi / 2) & \\sin(\\pi / 2) & 0 \\\\\n-\\sin(\\pi / 2) & \\cos(\\pi / 2) & 0 \\\\\n0 & 0 & -1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 & 1 & 0 \\\\\n-1 & 0 & 0 \\\\\n0 & 0 & -1\n\\end{pmatrix}.\n\nThe resulting DLM is a 5-dimensional model \\{F, G, \\cdot, \\cdot\\} with\n\nF = (1, 0, 1, 0, 1)',\n\nand\n\nG =\n\\begin{pmatrix}\n1 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & -1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & -1\n\\end{pmatrix}.\n\nThe forecast function is:\n\nf_t(h) = (k_{t,1} + k_{t,2} h) + k_{t,3} \\cos(\\pi h / 2) + k_{t,4} \\sin(\\pi h / 2) + k_{t,5} (-1)^h.",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#quiz-seasonal-models-and-superposition",
    "href": "C4-L04.html#quiz-seasonal-models-and-superposition",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "92.7 Quiz: Seasonal Models and Superposition",
    "text": "92.7 Quiz: Seasonal Models and Superposition\nThis is omitted due to the Coursera honor code.",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#filtering-smoothing-and-forecasting-unknown-observational-variance-video",
    "href": "C4-L04.html#filtering-smoothing-and-forecasting-unknown-observational-variance-video",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "93.1 Filtering, Smoothing and Forecasting: Unknown observational variance (Video)",
    "text": "93.1 Filtering, Smoothing and Forecasting: Unknown observational variance (Video)\nIn this video we cover the following material aslo provided as a handout:\nInference in the NDLM with unknown but constant observational variance:\nLet v_t = v for all t, with v unknown and consider a DLM with the following structure: \n\\begin{aligned}\ny_t &= \\mathbf{F}_t' \\mathbf{\\theta}_t + \\nu_t, &\\nu_t &\\sim N (0, v)\\\\\n\\mathbf{\\theta}_t &= \\mathbf{G}_t \\mathbf{\\theta}_{t-1} + \\mathbf{\\omega}_t, & \\mathbf{\\omega}_t &\\sim N (0, v \\mathbf{W}^*_t)\n\\end{aligned}\n\\tag{93.1}\nwith conjugate prior distributions: \n(\\mathbf{\\theta}_0 \\mid D_0, v) \\sim N (\\mathbf{m}_0, v\\mathbf{C}^*_0), \\qquad (v \\mid D_0) \\sim IG(\\frac{n_0}{2}, \\frac{d_0}{2}),\n\\tag{93.2} and d_0 = n_0s_0\n\n93.1.1 Filtering\nAssuming (\\theta_{t-1} \\mid D_{t-1}, v) \\sim N (m_{t-1}, vC^*_{t-1}), we have the following results:\n\n(\\theta_t \\mid D_{t-1}, v) \\sim N (a_t, vR^*_t) with a_t = G_t m_{t-1} and R^*_t = G_t C^*_{t-1} G'_t + W^*_t, and unconditional on v, (\\theta_t \\mid D_{t-1}) \\sim T_{n_{t-1}} (a_t, R_t), with R_t = s_{t-1} R^*_t. The expression for s_t for all t is given below.\n(y_t \\mid D_{t-1}, v) \\sim N (f_t, vq^*_t), with f_t = F'_t a_t, and q^*_t = (1 + F'_t R^*_t F_t) and unconditional on v we have (y_t \\mid D_{t-1}) \\sim T_{n_{t-1}} (f_t, q_t), with q_t = s_{t-1} q^*_t.\n(v \\mid D_t) \\sim IG(n_t/2, s_t/2), with n_t = n_{t-1} + 1 and \ns_t = s_{t-1} + \\frac{s_{t-1}}{n_t} \\left ( \\frac{e^2_t}{q^*_t} - 1 \\right ),\n\\tag{93.3}\nwhere e_t = y_t - f_t\nθt|Dt, v) ∼ N (mt, vC∗ t ), with mt = at + Atet, and C∗ t = R∗ t − AtA′ tq∗ t . Similarly, unconditional on v we have (θt|Dt) ∼ Tnt (mt, Ct), with Ct = stC∗ t",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#summary-of-filtering-smoothing-and-forecasting-distributions-ndlm-unknown-observational-variance-reading",
    "href": "C4-L04.html#summary-of-filtering-smoothing-and-forecasting-distributions-ndlm-unknown-observational-variance-reading",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "93.2 Summary of Filtering, Smoothing and Forecasting Distributions, NDLM unknown observational variance (Reading)",
    "text": "93.2 Summary of Filtering, Smoothing and Forecasting Distributions, NDLM unknown observational variance (Reading)",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#specifying-the-system-covariance-matrix-via-discount-factors-video",
    "href": "C4-L04.html#specifying-the-system-covariance-matrix-via-discount-factors-video",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "93.3 Specifying the system covariance matrix via discount factors (Video)",
    "text": "93.3 Specifying the system covariance matrix via discount factors (Video)",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#ndlm-unknown-observational-variance-example-video",
    "href": "C4-L04.html#ndlm-unknown-observational-variance-example-video",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "93.4 NDLM, Unknown Observational Variance: Example (Video)",
    "text": "93.4 NDLM, Unknown Observational Variance: Example (Video)\nThis is a walk though of the R code for the example bellow.",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#rcode-ndlm-unknown-observational-variance-example-reading",
    "href": "C4-L04.html#rcode-ndlm-unknown-observational-variance-example-reading",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "93.5 Rcode: NDLM, Unknown Observational Variance Example (Reading)",
    "text": "93.5 Rcode: NDLM, Unknown Observational Variance Example (Reading)\nThis code allows time-varying F_t, G_t and W_t matrices and assumes an unknown but constant \\nu. It also allows the user to specify W_t using a discount factor \\delta \\in (0,1] or assume W_t known.\n\n\nCode\n## create list for matrices\nset_up_dlm_matrices_unknown_v &lt;- function(Ft, Gt, Wt_star){\n  if(!is.array(Gt)){\n    Stop(\"Gt and Ft should be array\")\n  }\n  if(missing(Wt_star)){\n    return(list(Ft=Ft, Gt=Gt))\n  }else{\n    return(list(Ft=Ft, Gt=Gt, Wt_star=Wt_star))\n  }\n}\n\n\n## create list for initial states\nset_up_initial_states_unknown_v &lt;- function(m0, C0_star, n0, S0){\n  return(list(m0=m0, C0_star=C0_star, n0=n0, S0=S0))\n}\n\nforward_filter_unknown_v &lt;- function(data, matrices, \n                              initial_states, delta){\n  ## retrieve dataset\n  yt &lt;- data$yt\n  T&lt;- length(yt)\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  ## retrieve initial state\n  m0 &lt;- initial_states$m0\n  C0_star &lt;- initial_states$C0_star\n  n0 &lt;- initial_states$n0\n  S0 &lt;- initial_states$S0\n  C0 &lt;- S0*C0_star\n  \n  ## create placeholder for results\n  d &lt;- dim(Gt)[1]\n  at &lt;- matrix(0, nrow=T, ncol=d)\n  Rt &lt;- array(0, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(0, nrow=T, ncol=d)\n  Ct &lt;- array(0, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  nt &lt;- numeric(T)\n  St &lt;- numeric(T)\n  dt &lt;- numeric(T)\n  \n  # moments of priors at t\n  for(i in 1:T){\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , i] %*% m0\n      Pt &lt;- Gt[, , i] %*% C0 %*% t(Gt[, , i])\n      Pt &lt;- 0.5*Pt + 0.5*t(Pt)\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i]*S0\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n      \n    }else{\n      at[i, ] &lt;- Gt[, , i] %*% t(mt[i-1, , drop=FALSE])\n      Pt &lt;- Gt[, , i] %*% Ct[, , i-1] %*% t(Gt[, , i])\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i] * St[i-1]\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i]=0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(Ft[, , i]) %*% t(at[i, , drop=FALSE]) \n    Qt[i] &lt;- t(Ft[, , i]) %*% Rt[, , i] %*% Ft[, , i] + \n      ifelse(i==1, S0, St[i-1])\n    et[i] &lt;- yt[i] - ft[i]\n    \n    nt[i] &lt;- ifelse(i==1, n0, nt[i-1]) + 1\n    St[i] &lt;- ifelse(i==1, S0, \n                    St[i-1])*(1 + 1/nt[i]*(et[i]^2/Qt[i]-1))\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% Ft[, , i] / Qt[i]\n    \n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- St[i]/ifelse(i==1, S0, \n                  St[i-1])*(Rt[, , i] - Qt[i] * At %*% t(At))\n    Ct[,,i] &lt;- 0.5*Ct[,,i]+0.5*t(Ct[,,i])\n  }\n  cat(\"Forward filtering is completed!\\n\")\n  return(list(mt = mt, Ct = Ct,  at = at, Rt = Rt, \n              ft = ft, Qt = Qt,  et = et, \n              nt = nt, St = St))\n}\n\n### smoothing function ###\nbackward_smoothing_unknown_v &lt;- function(data, matrices, \n                                posterior_states,delta){\n  ## retrieve data \n  yt &lt;- data$yt\n  T &lt;- length(yt) \n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  Rt &lt;- posterior_states$Rt\n  nt &lt;- posterior_states$nt\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  \n  for(i in T:1){\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n    }else{\n      if(missing(delta)){\n        inv_Rtp1 &lt;- chol2inv(chol(Rt[, , i+1]))\n        Bt &lt;- Ct[, , i] %*% t(Gt[, , i+1]) %*% inv_Rtp1\n        mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n        Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i+1] - \n                                    Rt[, , i+1]) %*% t(Bt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }else{\n        inv_Gt &lt;- solve(Gt[, , i+1])\n        mnt[i, ] &lt;- (1-delta)*mt[i, ] + \n                delta*inv_Gt %*% t(mnt[i+1, ,drop=FALSE])\n        Cnt[, , i] &lt;- (1-delta)*Ct[, , i] + \n                delta^2*inv_Gt %*% Cnt[, , i + 1]  %*% t(inv_Gt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }\n    }\n    fnt[i] &lt;- t(Ft[, , i]) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(Ft[, , i]) %*% t(Cnt[, , i]) %*% Ft[, , i]\n  }\n  for(i in 1:T){\n     Cnt[,,i]=St[T]*Cnt[,,i]/St[i] \n     Qnt[i]=St[T]*Qnt[i]/St[i]\n  }\n  cat(\"Backward smoothing is completed!\\n\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n## Forecast Distribution for k step\nforecast_function_unknown_v &lt;- function(posterior_states, k, \n                                        matrices, delta){\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , T+i] %*% t(mt[T, , drop=FALSE])\n      \n      if(missing(delta)){\n       Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n         t(Gt[, , T+i]) + St[T]*Wt_star[, , T+i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      \n    }else{\n      at[i, ] &lt;- Gt[, , T+i] %*% t(at[i-1, , drop=FALSE])\n      if(missing(delta)){\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i]) + St[T]*Wt_star[, , T + i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n    }\n    \n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(Ft[, , T+i]) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(Ft[, , T+i]) %*% Rt[, , i] %*% Ft[, , T+i] + \n      St[T]\n  }\n  cat(\"Forecasting is completed!\\n\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval_unknown_v &lt;- function(ft, Qt, nt, \n                                   quantile = c(0.025, 0.975)){\n  bound &lt;- matrix(0, nrow=length(ft), ncol=2)\n\n  if ((length(nt)==1)){\n   for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt)\n      bound[t, 1] &lt;- ft[t] + t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt)\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }else{\n  # lower bound of 95% credible interval\n    for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt[t])\n      bound[t, 1] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt[t])\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }\n  return(bound)\n\n}\n\n\n\n## Example: Nile River Level (in 10^8 m^3), 1871-1970 \n## Model: First order polynomial DLM\nplot(Nile) \n\n\n\n\n\n\n\n\n\nCode\nn=length(Nile) #n=100 observations \nk=5\nT=n-k\ndata_T=Nile[1:T]\ntest_data=Nile[(T+1):n]\ndata=list(yt = data_T)\n\n\n## set up matrices for first order polynomial model \nFt=array(1, dim = c(1, 1, n))\nGt=array(1, dim = c(1, 1, n))\nWt_star=array(1, dim = c(1, 1, n))\nm0=as.matrix(800)\nC0_star=as.matrix(10)\nn0=1\nS0=10\n\n## wrap up all matrices and initial values\nmatrices = set_up_dlm_matrices_unknown_v(Ft, Gt, Wt_star)\ninitial_states = set_up_initial_states_unknown_v(m0, \n                                      C0_star, n0, S0)\n\n## filtering \nresults_filtered = forward_filter_unknown_v(data, matrices, \n                                            initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nci_filtered=get_credible_interval_unknown_v(results_filtered$mt, \n                                    results_filtered$Ct, \n                                     results_filtered$nt)\n\n## smoothing\nresults_smoothed=backward_smoothing_unknown_v(data, matrices, \n                                             results_filtered)\n\n\nBackward smoothing is completed!\n\n\nCode\nci_smoothed=get_credible_interval_unknown_v(results_smoothed$mnt, \n                                         results_smoothed$Cnt, \n                                         results_filtered$nt[T])\n\n## one-step ahead forecasting\nresults_forecast=forecast_function_unknown_v(results_filtered, \n                                                k,  matrices)\n\n\nForecasting is completed!\n\n\nCode\nci_forecast=get_credible_interval_unknown_v(results_forecast$ft, \n                                          results_forecast$Qt, \n                                     results_filtered$nt[T])\n\n\n## plot results\nindex=seq(1871, 1970, length.out = length(Nile))\nindex_filt=index[1:T]\nindex_forecast=index[(T+1):(T+k)]\n\nplot(index, Nile, main = \"Nile River Level \",type='l',\n     xlab=\"time\",ylab=\"feet\",lty=3,ylim=c(400,1500))\npoints(index,Nile,pch=20)\n\nlines(index_filt,results_filtered$mt, type='l', col='red',lwd=2)\nlines(index_filt,ci_filtered[, 1], type='l', col='red', lty=2)\nlines(index_filt,ci_filtered[, 2], type='l', col='red', lty=2)\nlines(index_filt,results_smoothed$mnt, type='l', col='blue',lwd=2)\nlines(index_filt, ci_smoothed[, 1], type='l', col='blue', lty=2)\nlines(index_filt, ci_smoothed[, 2], type='l', col='blue', lty=2)\n\nlines(index_forecast, results_forecast$ft, type='l', \n      col='green',lwd=2)\nlines(index_forecast, ci_forecast[, 1], type='l', \n      col='green', lty=2)\nlines(index_forecast, ci_forecast[, 2], type='l', \n      col='green', lty=2)",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#practice-graded-assignment-ndlm-data-analysis",
    "href": "C4-L04.html#practice-graded-assignment-ndlm-data-analysis",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "93.6 Practice Graded Assignment: NDLM data analysis",
    "text": "93.6 Practice Graded Assignment: NDLM data analysis\nThis peer-reviewed activity is highly recommended. It does not figure into your grade for this course, but it does provide you with the opportunity to apply what you’ve learned in R and prepare you for your data analysis project in week 5.\nThe R code below fits a Normal Dynamic Linear Model to the monthly time series of Google trends “hits” for the term “time series”. The model has two components: (a) a polynomial model of order 2 and (b) a seasonal component with 4 frequencies: ω_1=2π/12, (annual cycle) ω_2=2π/6 (6 months cycle), ω_3=2π/4 and ω_4=2π/3. The model assumes that the observational variance v is unknown and the system variance-covariance matrix W_t is specified using a single discount factor. The discount factor is chosen using an optimality criterion as explained in the course.\nYou will be asked to modify the code in order to consider a DLM with two components: (a) a polynomial model of order 1 and (b) a seasonal component that contains a fundamental period of p = 12 and 2 additional harmonics for a total of 3 frequencies: ω1=2π/12, ω2=2π/6 and ω3=2π/4. You will also need to optimize the choice of the discount factor for this model. You will be asked to upload pictures summarizing your results.\nR code to fit the model: requires R packages gtrends,and dlm as well as the files “all_dlm_functions_unknown_v.R” and “discountfactor_selection_functions.R” also provided below.\n#| label: code-gtrendsR-data-analysis\n# download data \nlibrary(gtrendsR)\ntimeseries_data &lt;- gtrends(\"time series\",time=\"all\")\nplot(timeseries_data)\nnames(timeseries_data)\n\ntimeseries_data=timeseries_data$interest_over_time\ndata=list(yt=timeseries_data$hits)\n\nlibrary(dlm)\nmodel_seasonal=dlmModTrig(s=12,q=4,dV=0,dW=1)\nmodel_trend=dlmModPoly(order=2,dV=10,dW=rep(1,2),m0=c(40,0))\nmodel=model_trend+model_seasonal\nmodel$C0=10*diag(10)\nn0=1\nS0=10\nk=length(model$m0)\nT=length(data$yt)\n\nFt=array(0,c(1,k,T))\nGt=array(0,c(k,k,T))\nfor(t in 1:T){\n   Ft[,,t]=model$FF\n   Gt[,,t]=model$GG\n}\n\nsource('all_dlm_functions_unknown_v.R')\nsource('discountfactor_selection_functions.R')\n\nmatrices=set_up_dlm_matrices_unknown_v(Ft=Ft,Gt=Gt)\ninitial_states=set_up_initial_states_unknown_v(model$m0,\n                                               model$C0,n0,S0)\n\ndf_range=seq(0.9,1,by=0.005)\n\n## fit discount DLM\n## MSE\nresults_MSE &lt;- adaptive_dlm(data, matrices, \n               initial_states, df_range,\"MSE\",forecast=FALSE)\n\n## print selected discount factor\nprint(paste(\"The selected discount factor:\",results_MSE$df_opt))\n\n## retrieve filtered results\nresults_filtered &lt;- results_MSE$results_filtered\nci_filtered &lt;- get_credible_interval_unknown_v(\n  results_filtered$ft,results_filtered$Qt,results_filtered$nt)\n\n## retrieve smoothed results\nresults_smoothed &lt;- results_MSE$results_smoothed\nci_smoothed &lt;- get_credible_interval_unknown_v(\n  results_smoothed$fnt, results_smoothed$Qnt, \n  results_filtered$nt[length(results_smoothed$fnt)])\n\n## plot smoothing results \npar(mfrow=c(1,1), mar = c(3, 4, 2, 1))\nindex &lt;- timeseries_data$date\nplot(index, data$yt, ylab='Google hits',\n     main = \"Google Trends: time series\", type = 'l',\n     xlab = 'time', lty=3,ylim=c(0,100))\nlines(index, results_smoothed$fnt, type = 'l', col='blue', \n      lwd=2)\nlines(index, ci_smoothed[, 1], type='l', col='blue', lty=2)\nlines(index, ci_smoothed[, 2], type='l', col='blue', lty=2)\n\n# Plot trend and rate of change \npar(mfrow=c(2,1), mar = c(3, 4, 2, 1))\nplot(index,data$yt,pch=19,cex=0.3,col='lightgray',xlab=\"time\",\n     ylab=\"Google hits\",main=\"trend\")\nlines(index,results_smoothed$mnt[,1],lwd=2,col='magenta')\nplot(index,results_smoothed$mnt[,2],col='darkblue',lwd=2,\n     type='l', ylim=c(-0.6,0.6), xlab=\"time\",\n     ylab=\"rate of change\")\nabline(h=0,col='red',lty=2)\n\n# Plot seasonal components \npar(mfrow=c(2,2), mar = c(3, 4, 2, 1))\nplot(index,results_smoothed$mnt[,3],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=12\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,5],lwd=2,col=\"darkgreen\",\n     type='l',xlab=\"time\",ylab=\"\",main=\"period=6\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,7],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=4\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,9],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=3\",\n     ylim=c(-12,12))\n\n#Estimate for the observational variance: St[T]\nresults_filtered$St[T]\n\n93.6.1 All dlm functions unknown v\n\n\nCode\n## create list for matrices\nset_up_dlm_matrices_unknown_v &lt;- function(Ft, Gt, Wt_star){\n  if(!is.array(Gt)){\n    Stop(\"Gt and Ft should be array\")\n  }\n  if(missing(Wt_star)){\n    return(list(Ft=Ft, Gt=Gt))\n  }else{\n    return(list(Ft=Ft, Gt=Gt, Wt_star=Wt_star))\n  }\n}\n\n\n## create list for initial states\nset_up_initial_states_unknown_v &lt;- function(m0, C0_star, n0, S0){\n  return(list(m0=m0, C0_star=C0_star, n0=n0, S0=S0))\n}\n\nforward_filter_unknown_v &lt;- function(data, matrices, \n                              initial_states, delta){\n  ## retrieve dataset\n  yt &lt;- data$yt\n  T&lt;- length(yt)\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  ## retrieve initial state\n  m0 &lt;- initial_states$m0\n  C0_star &lt;- initial_states$C0_star\n  n0 &lt;- initial_states$n0\n  S0 &lt;- initial_states$S0\n  C0 &lt;- S0*C0_star\n  \n  ## create placeholder for results\n  d &lt;- dim(Gt)[1]\n  at &lt;- matrix(0, nrow=T, ncol=d)\n  Rt &lt;- array(0, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(0, nrow=T, ncol=d)\n  Ct &lt;- array(0, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  nt &lt;- numeric(T)\n  St &lt;- numeric(T)\n  dt &lt;- numeric(T)\n  \n  # moments of priors at t\n  for(i in 1:T){\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , i] %*% m0\n      Pt &lt;- Gt[, , i] %*% C0 %*% t(Gt[, , i])\n      Pt &lt;- 0.5*Pt + 0.5*t(Pt)\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i]*S0\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n      \n    }else{\n      at[i, ] &lt;- Gt[, , i] %*% t(mt[i-1, , drop=FALSE])\n      Pt &lt;- Gt[, , i] %*% Ct[, , i-1] %*% t(Gt[, , i])\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i] * St[i-1]\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i]=0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(Ft[, , i]) %*% t(at[i, , drop=FALSE]) \n    Qt[i] &lt;- t(Ft[, , i]) %*% Rt[, , i] %*% Ft[, , i] + \n      ifelse(i==1, S0, St[i-1])\n    et[i] &lt;- yt[i] - ft[i]\n    \n    nt[i] &lt;- ifelse(i==1, n0, nt[i-1]) + 1\n    St[i] &lt;- ifelse(i==1, S0, \n                    St[i-1])*(1 + 1/nt[i]*(et[i]^2/Qt[i]-1))\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% Ft[, , i] / Qt[i]\n    \n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- St[i]/ifelse(i==1, S0, \n                  St[i-1])*(Rt[, , i] - Qt[i] * At %*% t(At))\n    Ct[,,i] &lt;- 0.5*Ct[,,i]+0.5*t(Ct[,,i])\n  }\n  cat(\"Forward filtering is completed!\\n\")\n  return(list(mt = mt, Ct = Ct,  at = at, Rt = Rt, \n              ft = ft, Qt = Qt,  et = et, \n              nt = nt, St = St))\n}\n\n### smoothing function ###\nbackward_smoothing_unknown_v &lt;- function(data, matrices, \n                                posterior_states,delta){\n  ## retrieve data \n  yt &lt;- data$yt\n  T &lt;- length(yt) \n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  Rt &lt;- posterior_states$Rt\n  nt &lt;- posterior_states$nt\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  \n  for(i in T:1){\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n    }else{\n      if(missing(delta)){\n        inv_Rtp1 &lt;- chol2inv(chol(Rt[, , i+1]))\n        Bt &lt;- Ct[, , i] %*% t(Gt[, , i+1]) %*% inv_Rtp1\n        mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n        Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i+1] - \n                                    Rt[, , i+1]) %*% t(Bt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }else{\n        inv_Gt &lt;- solve(Gt[, , i+1])\n        mnt[i, ] &lt;- (1-delta)*mt[i, ] + \n                delta*inv_Gt %*% t(mnt[i+1, ,drop=FALSE])\n        Cnt[, , i] &lt;- (1-delta)*Ct[, , i] + \n                delta^2*inv_Gt %*% Cnt[, , i + 1]  %*% t(inv_Gt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }\n    }\n    fnt[i] &lt;- t(Ft[, , i]) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(Ft[, , i]) %*% t(Cnt[, , i]) %*% Ft[, , i]\n  }\n  for(i in 1:T){\n     Cnt[,,i]=St[T]*Cnt[,,i]/St[i] \n     Qnt[i]=St[T]*Qnt[i]/St[i]\n  }\n  cat(\"Backward smoothing is completed!\\n\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n## Forecast Distribution for k step\nforecast_function_unknown_v &lt;- function(posterior_states, k, \n                                        matrices, delta){\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , T+i] %*% t(mt[T, , drop=FALSE])\n      \n      if(missing(delta)){\n       Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n         t(Gt[, , T+i]) + St[T]*Wt_star[, , T+i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      \n    }else{\n      at[i, ] &lt;- Gt[, , T+i] %*% t(at[i-1, , drop=FALSE])\n      if(missing(delta)){\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i]) + St[T]*Wt_star[, , T + i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n    }\n    \n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(Ft[, , T+i]) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(Ft[, , T+i]) %*% Rt[, , i] %*% Ft[, , T+i] + \n      St[T]\n  }\n  cat(\"Forecasting is completed!\\n\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval_unknown_v &lt;- function(ft, Qt, nt, \n                                   quantile = c(0.025, 0.975)){\n  bound &lt;- matrix(0, nrow=length(ft), ncol=2)\n\n  if ((length(nt)==1)){\n   for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt)\n      bound[t, 1] &lt;- ft[t] + t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt)\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }else{\n  # lower bound of 95% credible interval\n    for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt[t])\n      bound[t, 1] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt[t])\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }\n  return(bound)\n\n}\n\n\n\n\n93.6.2 Discount factor selection functions\n\n\nCode\n##################################################\n##### using discount factor ##########\n##################################################\n## compute measures of forecasting accuracy\n## MAD: mean absolute deviation\n## MSE: mean square error\n## MAPE: mean absolute percentage error\n## Neg LL: Negative log-likelihood of disc,\n##         based on the one step ahead forecast distribution\nmeasure_forecast_accuracy &lt;- function(et, yt, Qt=NA, nt=NA, type){\n  if(type == \"MAD\"){\n    measure &lt;- mean(abs(et))\n  }else if(type == \"MSE\"){\n    measure &lt;- mean(et^2)\n  }else if(type == \"MAPE\"){\n    measure &lt;- mean(abs(et)/yt)\n  }else if(type == \"NLL\"){\n    measure &lt;- log_likelihood_one_step_ahead(et, Qt, nt)\n  }else{\n    stop(\"Wrong type!\")\n  }\n  return(measure)\n}\n\n\n## compute log likelihood of one step ahead forecast function\nlog_likelihood_one_step_ahead &lt;- function(et, Qt, nt){\n  ## et:the one-step-ahead error\n  ## Qt: variance of one-step-ahead forecast function\n  ## nt: degrees freedom of t distribution\n  T &lt;- length(et)\n  aux=0\n  for (t in 1:T){\n    zt=et[t]/sqrt(Qt[t])\n    aux=(dt(zt,df=nt[t],log=TRUE)-log(sqrt(Qt[t]))) + aux \n  } \n  return(-aux)\n}\n\n## Maximize log density of one-step-ahead forecast function to select discount factor\nadaptive_dlm &lt;- function(data, matrices, initial_states, df_range, type, \n                         forecast=TRUE){\n  measure_best &lt;- NA\n  measure &lt;- numeric(length(df_range))\n  valid_data &lt;- data$valid_data\n  df_opt &lt;- NA\n  j &lt;- 0\n  ## find the optimal discount factor\n  for(i in df_range){\n    j &lt;- j + 1\n    results_tmp &lt;- forward_filter_unknown_v(data, matrices, initial_states, i)\n     \n    measure[j] &lt;- measure_forecast_accuracy(et=results_tmp$et, yt=data$yt,\n                                  Qt=results_tmp$Qt, \n                                  nt=c(initial_states$n0,results_tmp$nt), type=type)\n    \n    \n    if(j == 1){\n      measure_best &lt;- measure[j]\n      results_filtered &lt;- results_tmp\n      df_opt &lt;- i\n    }else if(measure[j] &lt; measure_best){\n      measure_best &lt;- measure[j]\n      results_filtered &lt;- results_tmp\n      df_opt &lt;- i\n    }\n  }\n  results_smoothed &lt;- backward_smoothing_unknown_v(data, matrices, results_filtered, delta = df_opt)\n  if(forecast){\n    results_forecast &lt;- forecast_function(results_filtered, length(valid_data), \n                                          matrices, df_opt)\n    return(list(results_filtered=results_filtered, \n                results_smoothed=results_smoothed, \n                results_forecast=results_forecast, \n                df_opt = df_opt, measure=measure))\n  }else{\n    return(list(results_filtered=results_filtered, \n                results_smoothed=results_smoothed, \n                df_opt = df_opt, measure=measure))\n  }\n  \n}\n\n\n\n\n93.6.3 Grading Criteria\nThe assignment will be graded based on the uploaded pictures summarizing the results. Estimates of some of the model parameters and additional discussion will also be requested.",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#eeg-data",
    "href": "C4-L04.html#eeg-data",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "94.1 EEG data",
    "text": "94.1 EEG data",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L04.html#google-trends",
    "href": "C4-L04.html#google-trends",
    "title": "92  Normal Dynamic Linear Models, Part 2",
    "section": "94.2 Google Trends",
    "text": "94.2 Google Trends",
    "crumbs": [
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Normal Dynamic Linear Models, Part 2</span>"
    ]
  },
  {
    "objectID": "C4-L05.html",
    "href": "C4-L05.html",
    "title": "93  Final Project",
    "section": "",
    "text": "In this final project you will use normal dynamic linear models to analyze a time series dataset downloaded from Google trend.\n\n\n\n\n\n\nNoteObjectives\n\n\n\n\nUse R for analysis and forecasting of time series using NDLM (case of known observational and system variances)\nUse R for analysis and forecasting of time series using the NDLM (cases of known or unknown observational variance and unknown system variance specified using a discount factor)\n\n\n\n\n\n\n\n\n\nNoteInstructions\n\n\n\nSo far in this course, we have discussed the following aspects of Bayesian time series models:\n\nConcepts of stationarity, the autocorrelation function, definition and properties of autoregressive (AR) models;\nMaximum likelihood and Bayesian conjugate analysis of AR models;\nDetermination of the order of AR models using AIC or BIC as criteria;\nDefinition of Normal Dynamic Linear Models (NDLMs);\nNDLM building using polynomial trend, seasonal and regression components via the superposition principle;\nBayesian filtering, smoothing and forecasting in the NDLM with known observational variances and known system covariance matrices;\nBayesian filtering, smoothing and forecasting in the NDLM with unknown but constant observational variance and known system covariance matrix;\nBayesian filtering, smoothing and forecasting in the NDLM with known observational variances and unknown system covariance matrices using discount factors;\nBayesian filtering, smoothing and forecasting in the NDLM with unknown but constant observational variance and unknown system covariance matrices using discount factors.\n\nIn this project, you will download a dataset from Google trends. In order to do this you can type a term/terms of interest in Google trends, just like we did with the example with the term “time series” analyzed in the course. You could use any term such as “flu”, “cranberry” or any other term(s). Here is a tutorial on how to download data from Google trends:",
    "crumbs": [
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>Final Project</span>"
    ]
  },
  {
    "objectID": "C4-L06.html",
    "href": "C4-L06.html",
    "title": "94  Week 0: Feynman Notebook on Bayesian Time Series Analysis",
    "section": "",
    "text": "94.1 A Feynman Notebook - For Bayesian Time Series Analysis\nWhat is the relation between Dynamic linear time series models (DLTS) models and Bayesian structural time series models (BSTS) models?",
    "crumbs": [
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Week 0: Feynman Notebook on Bayesian Time Series Analysis</span>"
    ]
  },
  {
    "objectID": "C4-L06.html#a-feynman-notebook---for-bayesian-time-series-analysis",
    "href": "C4-L06.html#a-feynman-notebook---for-bayesian-time-series-analysis",
    "title": "94  Week 0: Feynman Notebook on Bayesian Time Series Analysis",
    "section": "",
    "text": "ImportantTS Questions — A Feynman Notebook\n\n\n\nHere is where I can collect questions about TS analysis that I have as I go through the course. Hopefully I will be better equipped to answer many of these them by the end of the course.\n\nHow is Bayesian TS analysis differ from regular TS analysis?\n\nIn the NDLM we supply a Prior.\nWe the use Bayesian updating to update the model with the data.\nWe maintain a distributional view with estimates of the error.\nWe also the use Bayesian updating and inference for Filtering, Smoothing.\n\nFourier analysis is a powerful tool for time series analysis. How does it relate to Bayesian time series analysis?\n\nWe can incorporate the outcomes to incorporate seasonal elements into an NDLM\n\nHow and what type of prior knowledge into time series analysis?\n\nIn (West and Harrison 2013) they authors discuss both is the actual prior.\nBut they also talk about supporting interventions. E.g. when a major competitor goes out of business.The model should be able to handle this information and they make a big issues of how we need to incorporate into the next time step both new expected demand as well as an estimate of its variance which give better estimates of required production.\n\nAre there models that are unique to Bayesian time series analysis?\n\nHard to say but DLM seem to be.\n\nHow does distributional thinking affect time series analysis?\n\nIt gives us confidence bounds on future estimates.\n\nHow do we represent uncertainty in Bayesian time series analysis?\n\nWe have distribution and we can derive for any point estimate a corresponding credible interval.\nWe can use smoothing to try and reason about trend or seasonality separately.\n\nWill we learn about Gaussian Processes/Neural Networks in this course?\n\nThis is a type of Bayesian Non-parametric and we don’t cover these in the specialization. However Abel Rodriguez, the instructor of the third course on mixture model has a short course\nHerbert Lee wrote a Bayesian Nonparametrics via Neural Networks on the subject.\n\nWhat BTS models are most useful in economics and finance?\nIs there a cleanup procedure for time series data?\n\nUsing exponential smoothing\nUsing weighted averaging going back and forward enough steps can smooth seasonal effects.\nMore generally this is handled by smoothing\nGoing backwards this is can be done using filtering.\n\nIs there an Bayesian EDA for time series?\n\nwe can use differencing to make the time series stationary\nwe can use the ACF and PACF\nwe can decompose the time series into trend, seasonal, and residual components\nwe can visualize autocorrelation using a correlogram\nwe can visualize periodicity using a periodogram and spectral density.\nsee (Nielsen 2019)\n\nHow do we handle missing data in time series?\nHow do we handle non-stationary time series?\n\nBy applying differencing we can make the time series stationary.\n\nAre there processes for long term memory in time series?\n\nsee (Prado, Ferreira, and West 2023, 124)\nthe book also touches on EKF and MKF\n\nAre there processes for power laws.\n\n\nsee https://wiki.santafe.edu/images/5/52/Powerlaws.pdf\n\n\nCan BTS handle dynamic systems in time series?\nCan we model time series with multiple scales?\nWhat TS models are useful for regime switching?\n\nI recall this came up in Davidson-Pilon (2015)\nThis is also covered in module 3 of the course.\n\nHow can we simulate time series data?\nHow can we forecast time series data?\nHow can we find periodicity in time series data?\nIs the Kalman Filter a state-space or dynamic linear model\n\nsee (Prado, Ferreira, and West 2023, 141)\nthe book also touches on EKF and MKF\n\nParticle filters AKA Sequential Monte Carlo methods in the book.\n\nsee (Prado, Ferreira, and West 2023, 205)\n\nAre there Bayesian time series models of contagion?\nAre there Bayesian time series models of epidemics?\nWhat are Seasonal adjustments?\nHow to do a seasonal adjustment?\nWhat are the tools for wrangling and cleaning TS data.\n\nData Engineering using Wrangling and Cleaning c.f. (Woodward, Sadler, and Robertson 2022, sec. 1.4.1.3)\n\nHow to use the frequency domain as a key part of understanding and analyzing data?\nHow to assess whether an existing trend should be predicted to continue or whether caution should be used in forecasts?\nDo you really understand AR models or are they just a black box?\nWhat is a unit root?\nHow to use tools that would help you decide whether to use a seasonal model and/or include a unit root in models?\nHow to use predictor variables to help forecast some variable such as sales? (i.e. regression on time series data)\n\n\n94.1.1 Co-integration\n\nWhat are Cointegrated time series?\n\nCo-integration  is a technique used to find a long term correlation between time series processes that was introduced in 1987 by Nobel laureates Robert Engle and Clive Granger\nalso see (Pfaff 2008)\n\nWhat are some test for co-integration:\n\nEngle-Granger,\nJohansen Test,\nthe Phillips-Ouliaris test.\n\n\n\n\n94.1.2 NN and Deep learning\n\nHow to use neural network methods to forecast time series?\n\nRNNs\nlstms\nconvolutions\nGRUs\ntransformers\nTS foundations models\nNeural Prophet citation needed\n\nDeep learning foundation models citation needed pre-train NN model with many time series. Is this a form of Bayesian time series analysis?\nHow does this BTS relate to deep learning?\n\nDiffusion models in DL are autoregressive citation needed\nthe recently the mamba architecture has been proposed which is an autoregressive state space model. citation needed\n\n\n\n\n94.1.3 Web scraping\n\nAny tips on scaraping time series data?\n\n\nWeb Scraping using Bots c.f (Woodward, Sadler, and Robertson 2022, sec. 1.4.1.4)\n\n\n\n94.1.4 Filtering & Smoothing\n\nWhat is smoothing in BTS\n\ndecomposing the series as a sum of two components: a smooth component, plus another component that includes all the features that are unexplained by the smooth component.\none way is to use a moving average.\nin the Bayesian context smoothing is the process of estimating the hidden states of a system given the observed data.\n\nWhat is filtering in Bayesian Time Series?\n\nin the Bayesian context filtering is the process of estimating the previous hidden states of a system given the observed data. I.e. a retrospective analysis to understand the process better\nwe want to sample \\mathbb{P}r(\\theta_t,k \\mid \\mathcal{D}_t)\n\nWhat is the Kalman filter?\n\nsee (Prado, Ferreira, and West 2023, 141)\nthe book also toches on EKF and MKF\n\nWhat is a particle filter?\n\nsee (Prado, Ferreira, and West 2023, sec. 6.2.2) on the The Auxiliary Particle Filter\n\nWhat is the Butterworth filter?\n\nThe Butterworth filter is a signal processing filter that has a flat response in passband (or as close as possible to flat) - making it good for cleaning up noise !?\n\n\n\n\n94.1.5 Models:\n\nWhite noise\nWiener process (random walk)\nAR(1): Autoregressive process order 1\nOrnstein–Uhlenbeck process a continuous-time version of the AR(1) process\nAR(p): Autoregressive process order p\nMA(q): Moving average process order q\nARMA(p,q): Autoregressive moving average\nSARMA: Seasonal ARMA\nARIMA: Autoregressive integrated moving average\nSARIMA: Seasonal ARIMA\nVAR: Vector autoregressive\nSVAR: structural vector autoregressive models (SVAR).\nVECM: Vector error correction models (VECM).\nGARCH: Generalized autoregressive conditional heteroskedasticity\nARCH: Autoregressive conditional heteroskedasticity\nSMC: Sequential Monte Carlo\nMDM: Multi-regression dynamic models\nLTMs: latent threshold models\nFFBS: Forward Filtering Backward Sampling\nDLM: Dynamic Linear Models\nBSTS: Bayesian Structural Time Series\n\nhttps://drive.google.com/file/d/14US56VzanuLt03XBkoAGzLy0gDEreZUc/view\n\n\nTVAR: Time-varying autoregressive models\nDGLM: Dynamic Generalized Linear Models\n\n\n\n\n\nmagic trick\n\nDynamic Linear Time Series (DLTS) models and Bayesian Structural Time Series (BSTS) models are both frameworks for modeling time series data, and they share a strong connection, particularly in the way they approach model formulation and uncertainty. Here’s a breakdown of their relationship:\n\n\nDynamic Linear Time Series (DLTS) Models:\n\n\nDLTS models, often referred to as Dynamic Linear Models (DLMs), are a class of models where the parameters (such as the intercept or slope) evolve over time according to a stochastic process. They can be written in a state-space form, consisting of:\nObservation Equation: Relates the observed data to the hidden state.\nState Equation: Describes how the hidden state evolves over time.\nThese models use Kalman filtering for inference and prediction.\nDLTS models are flexible in handling non-stationarity and time-varying parameters.\n\n\nIn the course we primarily learned to use Bayesian methods to estimate the parameters of the model.\n\n\nBayesian Structural Time Series (BSTS) Models:\n\n\nBSTS models are a Bayesian approach to time series modeling, which generalizes the DLTS framework.\nLike DLTS, they use a state-space form, where the time series is decomposed into different components (e.g., trend, seasonality, regression effects).\nBSTS explicitly incorporates Bayesian inference, where prior distributions are placed on the model components and parameters, and inference is conducted using MCMC or other Bayesian methods.\nOne of the key advantages of BSTS is its ability to incorporate model uncertainty, allowing the user to specify structural components (such as trend or seasonality) with uncertainty about their presence or importance in the data.\n\n\nRelation Between DLTS and BSTS:\n\n\nBayesian Extension of DLTS: BSTS can be seen as a Bayesian extension of DLTS models. While DLTS uses Kalman filtering for deterministic inference, BSTS uses Bayesian methods to quantify and propagate uncertainty in model components and parameters.\nComponent Decomposition: Both models can represent the time series in terms of structural components (like trends, seasonal patterns, or covariates), but BSTS allows for more flexible modeling of these components using Bayesian priors and hierarchical structures.\nHandling of Uncertainty: DLTS models provide point estimates for parameters using Kalman filters, while BSTS incorporates full probabilistic estimates, enabling better uncertainty quantification in the presence of small data, model misspecification, or structural breaks.\nModel Complexity: BSTS models can handle more complex scenarios where the structure of the time series isn’t fully known (e.g., unknown seasonality or trends), whereas DLTS is typically used when the structure of the model (e.g., presence of trend or seasonality) is more defined.\nfor more information on BSTS",
    "crumbs": [
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Week 0: Feynman Notebook on Bayesian Time Series Analysis</span>"
    ]
  },
  {
    "objectID": "C4-L06.html#software",
    "href": "C4-L06.html#software",
    "title": "94  Week 0: Feynman Notebook on Bayesian Time Series Analysis",
    "section": "94.2 Software",
    "text": "94.2 Software\n\nWhat are the most useful packages in R for time series analysis?\n\nBOA Bayesian Output Analysis (BOA, Smith 2007) citation needed and\nCODA Convergence Diagnosis and Output Analysis for MCMC (CODA, Plummer, Best, Cowles, and Vines 2006). citation needed\nURCA Unit Root and Cointegration Tests for Time Series Data (URCA, Pfaff 2008)citation needed.\nVars VAR Modelling (Vars, Pfaff 2008). citation needed\nBSTS Bayesian Structural Time Series (BSTS, Scott and Varian 2014). citation needed\nCausalImpact Causal Impact Analysis (CausalImpact, Brodersen, Gallusser, Koehler, Remy, and Scott 2015). citation needed builds on BSTS and methods from this Inferring causal impact using Bayesian structural time-series models\nKFAS Kalman Filter and Smoother for Exponential Family State Space Models (KFAS, Helske 2017). citation needed\nMARSS Multivariate Autoregressive State-Space Models (MARSS, Holmes, Ward, and Scheuerell 2012). citation needed\nMCMCpack Markov Chain Monte Carlo (MCMCpack, Martin, Quinn, and Park 2011). citation needed\nMCMCglmm Markov Chain Monte Carlo Generalized Linear Mixed Models (MCMCglmm, Hadfield 2010). citation needed\nR-INLA Integrated Nested Laplace Approximations (R-INLA, Rue, Martino, and Chopin 2009). citation needed used approximate Bayesian inference for Latent Gaussian Models that can be expressed as latent Gaussian Markov random fields (GMRF)\n\nWhat about in python?\n\n\n\n\n\n\n\nDavidson-Pilon, C. 2015. Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference. Addison-Wesley Data & Analytics Series. Pearson Education. https://books.google.co.il/books?id=rMKiCgAAQBAJ.\n\n\nNielsen, A. 2019. Practical Time Series Analysis: Prediction with Statistics and Machine Learning. O’Reilly Media. https://books.google.co.il/books?id=xNOwDwAAQBAJ.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series with r. Use r! Springer New York. https://books.google.co.il/books?id=ca5MkRbF3fYC.\n\n\nPrado, R., M. A. R. Ferreira, and M. West. 2023. Time Series: Modeling, Computation, and Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=pZ6lzgEACAAJ.\n\n\nWest, M., and J. Harrison. 2013. Bayesian Forecasting and Dynamic Models. Springer Series in Statistics. Springer New York. https://books.google.co.il/books?id=NmfaBwAAQBAJ.\n\n\nWoodward, W. A., B. P. Sadler, and S. Robertson. 2022. Time Series for Data Science: Analysis and Forecasting. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://books.google.co.il/books?id=_W16EAAAQBAJ.",
    "crumbs": [
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Week 0: Feynman Notebook on Bayesian Time Series Analysis</span>"
    ]
  },
  {
    "objectID": "A01.html",
    "href": "A01.html",
    "title": "95  Appendix: Notation",
    "section": "",
    "text": "95.1 The argmax function\nParameters describe the population and are usually designated with Greek letters and the preferred letter is \\theta\n\\theta\n\\tag{95.1}\nother common parameters are: \n\\mu, \\sigma^2, \\alpha, \\beta\n\\tag{95.2}\nwhere \\mu is the mean, \\sigma^2 is the variance, \\alpha is the intercept, and \\beta is the slope in a linear regression context.\nStatistics are population estimates of parameters and are usually designated with Latin letters, such as \\hat{\\theta}.\n\\hat{p}\n\\tag{95.3}\nthe Certain event\n\\Omega\nprobability of RV X taking value x\n\\mathbb{P}r(X=x)\nodds\n\\mathcal{O}(X)\nrandom variables \nX\nX is distributed as\nX\n\\sim N(\\mu, \\sigma^2)\nX is proportional to\nX\\propto N(\\mu, \\sigma^2)\nProbability of A and B\n\\mathbb{P}r(X \\cap Y)\nConditional probability\n\\mathbb{P}r(X \\mid Y)\nJoint probability\n\\mathbb{P}r(X,Y)\nY_i \\stackrel{iid}\\sim N(\\mu, \\sigma^2)\nApproximately distributed as (say using the CLT)\nY_i \\stackrel{.}\\sim N(\\mu, \\sigma^2)\n\\mathbb{E}[X_i]\nThe expected value of an RV X set to 0 (A.K.A. a fair bet)\n\\mathbb{E}[X_i]  \\stackrel{set} = 0\nThe variance of an RV\n\\mathbb{V}ar[X_i]\nlogical implication\n\\implies\nif and only if\n\\iff\ntherefore\n\\therefore\nindependence\nA \\perp \\!\\!\\! \\perp B \\iff \\mathbb{P}r(A \\mid B) = \\mathbb{P}r(A)\nIndicator function \n\\mathbb{I}_{\\{A\\}} = \\begin{cases}\n1 & \\text{if } A \\text{ is true} \\\\ 0 & \\text{otherwise} \\end{cases}\nDirichlet function\nThis is a continuous version of the indicator function, defined as a limit.\n\\delta(x) = \\lim_{\\epsilon \\to 0} \\frac{1}{2\\epsilon} \\mathbb{I}_{\\{|x| &lt; \\epsilon\\}}\nThe Dirichlet function is used to represent a point mass at a point, often used as a component for zero inflated mixtures.\nThe following are from course 4\nWhen we want to maximize a function f(x), there are two things we may be interested in:",
    "crumbs": [
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Appendix: Notation</span>"
    ]
  },
  {
    "objectID": "A01.html#sec-argmax-function",
    "href": "A01.html#sec-argmax-function",
    "title": "95  Appendix: Notation",
    "section": "",
    "text": "The value f(x) achieves when it is maximized, which we denote \\max_x f(x).\nThe x-value that results in maximizing f(x), which we denote \\hat x = \\arg \\max_x f(x). Thus \\max_x f(x) = f(\\hat x).",
    "crumbs": [
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Appendix: Notation</span>"
    ]
  },
  {
    "objectID": "A01.html#sec-indicator-functions",
    "href": "A01.html#sec-indicator-functions",
    "title": "95  Appendix: Notation",
    "section": "95.2 Indicator Functions",
    "text": "95.2 Indicator Functions\nThe concept of an indicator function is a really useful one. This is a function that takes the value one if its argument is true, and the value zero if its argument is false. Sometimes these functions are called Heaviside functions or unit step functions. I write an indicator function as \\mathbb{I}_{A}(x), although sometimes they are written \\mathbb{1}_{A}(x). If the context is obvious, we can also simply write I{A}.\nExample:\n\n    \\mathbb{I}_{x&gt;3}(x)=\n    \\begin{cases}\n      0, & \\text{if}\\ x \\le 3 \\\\\n      1, & \\text{otherwise}\n    \\end{cases}\n\nNote: Indicator functions are easy to implement in code using a lambda function. They can be combined using a dictionary.\nBecause 0 · 1 = 0, the product of indicator functions can be combined into a single indicator function with a modified condition.\n\n95.2.1 Products of Indicator Functions:\n\n    \\mathbb{I}{x&lt;5} \\cdot \\mathbb{I}{x≥0} = \\mathbb{I}{0≤x&lt;5}\n\n\n    \\prod_{i=1}^N \\mathbb{I}_{(x_i&lt;2)} = \\mathbb{I}_{(x_i&lt;2) \\forall i} = \\mathbb{I}_{\\max_i x_i&lt;2}",
    "crumbs": [
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Appendix: Notation</span>"
    ]
  },
  {
    "objectID": "A02.html",
    "href": "A02.html",
    "title": "96  Appendix: Discrete Distributions",
    "section": "",
    "text": "96.1 Discrete Uniform",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-discrete-uniform",
    "href": "A02.html#sec-discrete-uniform",
    "title": "96  Appendix: Discrete Distributions",
    "section": "",
    "text": "96.1.1 Stories\n\n\n\n\n\n\nNoteDiscrete Uniform Finite set Parametrization\n\n\n\nLet C be a finite, nonempty set of numbers and X random variable associated with the event of choosing one of these numbers uniformly at random, that is all values being equally likely X(x=c)\nThen X is said to have the Discrete Uniform distribution with parameter C.\nWe denote this by X ∼ DUnif(C).\n\n\n\n\n\n\n\n\nNoteDiscrete Uniform with Lower and Upper bound Parametrization\n\n\n\nWhen the set C above is C=\\{c \\in \\mathbb{Z} \\mid a \\le c \\le b\\ \\}.\nThen X is said to have the Discrete Uniform distribution with lower bound parameter a and upper bound parameter b.\nWe denote this by X ∼ DUnif(a,b).\n\n\n\n\n\n\n\n\nNoteUrn Model\n\n\n\nSuppose we have an urn with n balls labeled with the numbers a 1, \\dots, a_n . One drawing from the urn produces a discrete uniform random variable on the set \\{a_1, \\dots, a_n \\}.\n\n\n\n\n96.1.2 Moments\n\n\\begin{aligned}\n    \\phi_X(t)&={\\displaystyle {\\frac {e^{at}-e^{(b+1)t}}{n(1-e^{t})}}}  && \\text{(MGF)}\n\\\\  \\mathbb{E}[X] &= \\frac{a + b}{2} && \\text{(Expectation)}\n\\\\  \\mathbb{V}ar[X] &= \\frac{(b - a + 1)^2 - 1}{12} && \\text{(Variance)}\n\\end{aligned}\n\\tag{96.1}\n\n\n96.1.3 Probability mass function (PMF)\n\nf(x \\mid a, b) = \\frac{1}{b - a + 1}\n\n\n\n96.1.4 Cumulative distribution function (CDF)\n\nF(x \\mid a, b) = \\frac{\\lfloor x \\rfloor - a - 1}{b - a + 1} \\\\\\text{where} \\lfloor x \\rfloor \\text{ is the floor function (rounds down reals to nearest smaller integer)}\n\n\n\n96.1.5 Prior\nSince a number of families have the uniform as a special case we can use them as priors when we want a uniform prior:",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-bernoulli-distribution",
    "href": "A02.html#sec-bernoulli-distribution",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.2 Bernoulli Distribution",
    "text": "96.2 Bernoulli Distribution\n\n96.2.1 Stories\n\n\n\n\n\n\nNote\n\n\n\nThe Bernoulli distribution arises when modeling the outcome of a binary event called a Bernoulli trial. .\nLet X be the indicator variable corresponding to the success of getting “heads” in a “coin toss”, with a coin that has probability of success p for getting “heads”.\nThen X has a Bernoulli Distribution with parameter p\nWe denote this as X \\sim Bern(p)\n\n\n\n\n96.2.2 Parameters\nBecause of this story, the parameter p is often called the success probability of the Bern(p) distribution.\n\n\n96.2.3 Examples\n\n\n\n\n\n\nNote\n\n\n\n\nfair coin toss\nunfair coin toss\nad click\nweb site conversion\ndeath or survival of a patient in a medical trial\nindicator random variable\n\n\n\n\n\n96.2.4 Checklist\n\n\n\n\n\n\nNote\n\n\n\n\nDiscrete data\nA single trial\nOnly two trial outcomes: success and failure (These do not need to literally represent successes and failures, but this shorthand is typically used.)\n\n\n\n\n\\begin{aligned}\nX &\\sim Bernoulli(p)\\\\ & \\sim Bern(p)\\\\ & \\sim B(p)  \\end{aligned}\n\\tag{96.2}\n\n\n96.2.5 Moments\n\nM_X(t)=q+pe^{t} \\qquad \\text{(MGF)}\n\\tag{96.3}\n\n\\mathbb{E}[X]= p \\qquad \\text{(Expectation)}\n\\tag{96.4}\n\n\\mathbb{V}ar[x]= \\mathbb{P}r(1-p) \\qquad \\text{(Variance)}\n\\tag{96.5}\n\n\n96.2.6 PMF\nWhere parameter p is the probability of getting heads.\nThe probability for the two events is:\n\n\\mathbb{P}r(X=1) = p \\qquad \\mathbb{P}r(X=0)=1-p\n\n\n{\\displaystyle {\\begin{cases}1-p&{\\text{if }}k=0\\\\p&{\\text{if }}k=1\\end{cases}}}  \\qquad \\text{(PMF)}\n\\tag{96.6}\n\n\n96.2.7 CDF\n\n{\\displaystyle {\\begin{cases}0&{\\text{if }}k&lt;0\\\\1-p&{\\text{if }}0\\leq k&lt;1\\\\1&{\\text{if }}k\\geq 1\\end{cases}}} \\qquad \\text{(CDF)}\n\\tag{96.7}\n\n\n96.2.8 Likelihood\n\nL(\\theta) = \\prod p^x(1-p)^{1-x} \\mathbb{I}_{[0,1]}(x)  \\qquad \\text{(Likelihood)}\n\\tag{96.8}\n\n\\mathcal{L}(\\theta) =log(p) \\sum x + log(1-p)\\sum (1-x)  \\qquad \\text{(Log Likelihood)}\n\\tag{96.9}\n\n\n96.2.9 Entropy and Information\n\n\\mathbb{H}(x)= -q \\ln(q)- p \\ln(p) \\qquad \\text{(Entropy)}\n\\tag{96.10}\n\n\\mathcal{I}[X]\\frac{1}{\\mathbb{P}r(1-p)} \\qquad \\text{(Fisher Information)}\n\\tag{96.11}\n\nBeta(x) \\qquad \\text{(Conjugate Prior)}\n\\tag{96.12}\n\n\n96.2.10 Usage\n\n\n\nTable 96.1: Usage of Bernoulli\n\n\n\n\n\nPackage\nSyntax\n\n\n\n\nNumPy\nrg.choice([0, 1], p=[1-theta, theta])\n\n\nSciPy\nscipy.stats.bernoulli(theta)\n\n\nStan\nbernoulli(theta)\n\n\n\n\n\n\n\n\n96.2.11 Plots\n\n\nCode\nimport numpy as np\nfrom scipy.stats import bernoulli\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1)\np = 0.3\nmean, var, skew, kurt = bernoulli.stats(p, moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=0.30, var=0.21, skew=0.87, kurt=-1.24\n\n\nCode\nx = np.arange(bernoulli.ppf(0.01, p),\n              bernoulli.ppf(0.99, p))\nax.plot(x, bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')\nax.vlines(x, 0, bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)\n\nrv = bernoulli(p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n## Generate random numbers\nr = bernoulli.rvs(p, size=10)\nr\n\n\narray([0, 0, 0, 0, 1, 1, 0, 0, 0, 0])\n\n\n\n\n\n\nA Swiss stamp issueed in 1994 depicting Mathematician Jakob Bernouilli and the formula and diagram of the law of large numbers\n\n\n\n\n\n\n\nTipBiographical note on Jacob Bernoulli\n\n\n\n\nIt seems that to make a correct conjecture about any event whatever, it is necessary to calculate exactly the number of possible cases and then to determine how much more likely it is that one case will occur than another. (Bernoulli 1713)\n\nThe Bernoulli distribution as well as The Binomial distribution are due to Jacob Bernoulli (1655-1705) who was a prominent mathematician in the Bernoulli family. He discovered the fundamental mathematical constant e. With his brother Johann, he was among the first to develop Leibniz’s calculus, introducing the word integral and applying it to polar coordinates and the study of curves such as the catenary, the logarithmic spiral and the cycloid\nHis most important contribution was in the field of probability, where he derived the first version of the law of large numbers (LLN). The LLN is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value and will tend to become closer to the expected value as more trials are performed. A special form of the LLN (for a binary random variable) was first proved by Jacob Bernoulli. It took him over 20 years to develop sufficiently rigorous mathematical proof.\n\nFor a more extensive biography visit the following link\n\n\nThe Bernoulli distribution is built on a trial of a coin toss (possibly biased).\n\nWe use the Bernoulli distribution to model a random variable for the probability of such a coin toss trial.\nWe use the Binomial distribution to model a random variable for the probability of getting k heads in N independent trails.",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-binomial-distribution",
    "href": "A02.html#sec-binomial-distribution",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.3 Binomial distribution",
    "text": "96.3 Binomial distribution\n\n96.3.1 Stories\n\n\n\n\n\n\nNote\n\n\n\n\n\\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N\n\\tag{96.13}\nThe Binomial distribution arises when we conduct multiple independent Bernoulli trials and wish to model X the number of successes in Y_i\\mid \\theta identically distributed Bernoulli trials with the same probability of success \\theta. If n independent Bernoulli trials are performed, each with the same success probability p. The distribution of X is called the Binomial distribution with parameters n and p. We write X \\sim \\text{Bin}(n, p) to mean that X has the Binomial distribution with parameters n and p, where n is a positive integer and 0 &lt; p &lt; 1.\n\n\n\n\n96.3.2 Parameters\n\n\\theta - the probability of success in the Bernoulli trials\nN - the total number of trials being conducted\n\n\n\n96.3.3 Conditions\n\n\n\n\n\n\nTip\n\n\n\n\nDiscrete data\nTwo possible outcomes for each trial\nEach trial is independent and\nThe probability of success/failure is the same in each trial\nThe outcome is the aggregate number of successes\n\n\n\n\n\n96.3.4 Examples\n\nto model the aggregate outcome of clinical drug trials,\nto estimate the proportion of the population voting for each political party using exit poll data (where there are only two political parties).\n\n\nX \\sim Bin[n,p]\n\\tag{96.14}\n\nf(X=x \\mid \\theta) = {n \\choose x} \\theta^x(1-\\theta)^{n-x}\n\\tag{96.15}\n\nL(\\theta)=\\prod_{i=1}^{n} {n\\choose x_i}  \\theta ^ {x_i} (1− \\theta) ^ {(n−x_i)}\n\\tag{96.16}\n\n\\begin{aligned}\\ell( \\theta) &= \\log \\mathcal{L}( \\theta) \\\\&= \\sum_{i=1}^n \\left[\\log {n\\choose x_i} + x_i \\log  \\theta + (n-x_i)\\log (1- \\theta) \\right].\\end{aligned}\n\\tag{96.17}\n\n\\mathbb{E}[X]= N \\times  \\theta\n\\tag{96.18}\n\n\\mathbb{V}ar[X]=N \\cdot \\theta \\cdot (1-\\theta)\n\\tag{96.19}\n\n\\mathbb{H}(X) = \\frac{1}{2}\\log_2 \\left (2\\pi n \\theta(1 - \\theta)\\right) + O(\\frac{1}{n})\n\\tag{96.20}\n\n\\mathcal{I}(\\theta)=\\frac{n}{ \\theta \\cdot (1- \\theta)}\n\\tag{96.21}\n\n\n96.3.5 Usage\n\n\n\nTable 96.2: Usage of Binomial\n\n\n\n\n\nPackage\nSyntax\n\n\n\n\nNumPy\nrg.binomial(N, theta)\n\n\nSciPy\nscipy.stats.binom(N, theta)\n\n\nStan\nbinomial(N, theta)\n\n\n\n\n\n\n\n\n96.3.6 Relationships\n\n\n\nbinomial distribution relations\n\n\nThe Binomial Distribution is related to\n\nThe Binomial is a special case of the Multinomial distribution with K =2 (two categories).\nthe Poisson distribution distribution. If X \\sim Binomial(n, p) rv and Y \\sim Poisson(np) distribution then \\mathbb{P}r(X = n) ≈ \\mathbb{P}r(Y = n) for large n and small np.\nThe Bernoulli distribution is a special case of the the Binomial distribution  X \\sim Binomial(n=1, p) \\\\ \\implies X \\sim Bernoulli(p)\nthe Normal distribution If X \\sim Binomial(n, p) RV and Y \\sim Normal(\\mu=np,\\sigma=n\\mathbb{P}r(1-p)) then for integers j and k, \\mathbb{P}r(j ≤ X ≤ k) ≈ \\mathbb{P}r(j – 1/2 ≤ Y ≤ k + 1/2). The approximation is better when p ≈ 0.5 and when n is large. For more information, see normal approximation to the Binomial\nThe Binomial is a limit of the Hypergeometric. The difference between a binomial distribution and a hypergeometric distribution is the difference between sampling with replacement and sampling without replacement. As the population size increases relative to the sample size, the difference becomes negligible. So If X \\sim Binomial(n, p) RV and Y \\sim HyperGeometric(N,a,b) then\n\n\\lim_{n\\to \\infty} X = Y\n\n\n\n96.3.7 Plots\n\n\nCode\nimport numpy as np\nfrom scipy.stats import binom\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\nn, p = 5, 0.4\nmean, var, skew, kurt = binom.stats(n, p, moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=2.00, var=1.20, skew=0.18, kurt=-0.37\n\n\nCode\nx = np.arange(binom.ppf(0.01, n, p),\n              binom.ppf(0.99, n, p))\nax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\nax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)\nrv = binom(n, p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n## generate random numbers\nr = binom.rvs(n, p, size=10)\nr\n\n\narray([2, 2, 3, 2, 2, 3, 4, 3, 2, 2])\n\n\n``` {{python}}\nfrom __future__ import print_function\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\nimport numpy as np\nimport scipy\nfrom scipy.special import gamma, factorial, comb\nimport plotly.express as px\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\n#pyo.init_notebook_mode()\nINTERACT_FLAG=False\ndef binomial_vector_over_y(theta, n):\n    total_events = n\n    y =  np.linspace(0, total_events , total_events + 1)\n    p_y = [comb(int(total_events), int(yelem)) * theta** yelem * (1 - theta)**(total_events - yelem) for yelem in y]\n\n    fig = px.line(x=y, y=p_y, color_discrete_sequence=[\"steelblue\"], \n                  height=600, width=800, title=\" Binomial distribution for theta = %lf, n = %d\" %(theta, n))\n    fig.data[0].line['width'] = 4\n    fig.layout.xaxis.title.text = \"y\"\n    fig.layout.yaxis.title.text = \"P(y)\"\n    fig.show()\n    \nif(INTERACT_FLAG):    \n    interact(binomial_vector_over_y, theta=0.5, n=15)\nelse:\n    binomial_vector_over_y(theta=0.5, n=10)\n```",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-hypergeometric-distribution",
    "href": "A02.html#sec-hypergeometric-distribution",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.4 Hypergeometric distribution",
    "text": "96.4 Hypergeometric distribution\n\n96.4.1 story 1 - Urn Model\nThe beta-binomial distribution with parameters \\alpha success rate and \\beta failure and n the number of trials can be motivated by an Pólya urn model.\nImagine a trial in which a ball is drawn without replacement from urn containing \\alpha white balls and \\beta black balls. If this is repeated n times, then the probability of observing x white balls follows a hypergeometric distribution with parameters n, \\alpha and \\beta.\nNote: is we used a\nIf the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.\n\n\n\n96.4.2 Examples\n\nk white balls from an in Urn without replacement\ncapture-recapture\nAces in a poker hand\n\n\n\n96.4.3 Story\nConsider an urn with w white balls and b black balls. We draw n balls out of the urn at random without replacement, such that all w+b samples are equally likely. Let X be the number of white balls in n the sample. Then X is said to have the Hypergeometric distribution with parameters w, b, and n; we denote this by X ∼ HGeom(w, b, n)",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-poisson-distribution",
    "href": "A02.html#sec-poisson-distribution",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.5 Poisson distribution",
    "text": "96.5 Poisson distribution\n\n96.5.1 Stories\n\n\n\n\n\n\nNotePoisson Parametrization\n\n\n\nThe Poisson distribution arises when modeling the number of successes of independent and identically distributed (IID) events in a fixed interval of time or space, occurring at a constant rate \\lambda. Let X represent the count of the number of phone calls received at a call center in a given interval, such as an hour, with the parameter \\lambda corresponding to the average rate at which events occur in that interval. Then X is said to have the Poisson distribution with parameter \\lambda, and we denote this as X \\sim \\text{Pois}(\\lambda).\n\nX \\sim Pois(\\lambda)\n\\tag{96.22}\n\n\n\n\n\n96.5.2 Checklist\n\nCount of discrete events\nIndividual events occur at a given rate and independently of other events\nFixed amount of time or space in which the events can occur\n\n\n\n96.5.3 Examples\n\nThe number of emails you receive in an hour. There are a lot of people who could potentially email you at that hour, but it is unlikely that any specific person will actually email you at that hour. Alternatively, imagine subdividing the hour into milliseconds. There are 3.6×106 seconds in an hour, but in any specific millisecond, it is unlikely that you will get an email.\nThe number of chips in a chocolate chip cookie. Imagine subdividing the cookie into small cubes; the probability of getting a chocolate chip in a single cube is small, but the number of cubes is large.\nThe number of earthquakes in a year in some regions of the world. At any given time and location, the probability of an earthquake is small, but there are a large number of possible times and locations for earthquakes to occur over the course of the year.\nCount of component failures per week\nestimating the failure rate of artificial heart valves,\nestimating the prevalence of violent crimes in different districts,\napproximating the binomial which is, itself, being used to explain the prevalence of autism in the UK.\n\n\n\n96.5.4 Moments\n\n\\mathrm{E}(X) = \\lambda\n\n\n\\mathrm{V}ar(X) = \\lambda\n\n\n\n96.5.5 Probability mass function (PMF)\n\nf(x \\mid \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\\tag{96.23}\n\n\n96.5.6 Cumulative distribution function (CDF)\n\nF(x \\mid \\lambda) = \\frac{\\Gamma(\\lfloor x+1\\rfloor,\\lambda)}{\\lfloor x \\rfloor !} \\qquad \\text{CDF}\n\\tag{96.24}\n\n\\text{where }\\Gamma(u,v)=\\int_{v}^{\\infty}t^{u-1}e^{-t} \\mathrm{d}t \\text{ is the upper incomplete gamma function}\n\\tag{96.25}\n\n\\text{and } \\lfloor x \\rfloor \\text{ is the floor function (rounds down reals to nearest smaller integer)}\n\\tag{96.26}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-geometric-distribution",
    "href": "A02.html#sec-geometric-distribution",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.6 Geometric distribution",
    "text": "96.6 Geometric distribution\n\n96.6.1 Stories\n\n\n\n\n\n\nNoteGeometric Distribution Failures before success\n\n\n\nConsider a sequence of independent Bernoulli trials, each with the same success probability p \\in (0, 1), with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by X \\sim Geom(p).\nFor example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).\nTo get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0’s (failures) ending in a single 1 (success). Each 0 has probability q = 1 − p and the final 1 has probability p, so a string of k failures followed by one success has probability q^kp.\n\n\n\n\n\n\n\n\nNoteGeometric distribution Failures and success\n\n\n\nConsider a sequence of independent Bernoulli trials, each with the same success probability p \\in (0, 1), with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by X \\sim Geom(p).\nFor example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).\nTo get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0’s (failures) ending in a single 1 (success). Each 0 has probability q = 1 − p and the final 1 has probability p, so a string of k failures followed by one success has probability q^kp.\n\n\n\n\n\n96.6.2 Conditions\n\n\n\n\n\n\nTip\n\n\n\n\nDiscrete data\nTwo possible outcomes for each trial\nEach trial is independent and\nThe probability of success/failure is the same in each trial\nThe outcome is the count of failures before the first success\n\n\n\n\n\n96.6.3 Examples\n\nConsider polymerization of an actin filament. At each time step, an actin monomer may add to the end of the filament (“failure”), or an actin monomer may fall off the end (“success”) with (usually very low) probability θ. The length of actin filaments, measured in a number of constitutive monomers, is Geometrically distributed.\n\nThe Geometric distribution arises when we want to know “What is the number of Bernoulli trials required to get the first success?”, i.e., the number of Bernoulli events until a success is observed, such as the probability of getting the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).\n\n\nX \\sim Geo(p)\n\\tag{96.27}\n\n\n96.6.4 Moments\n\n\\mathbb{M}_X[t] = \\frac{pe^t}{1-(1-p)e^t} \\qquad t&lt;-ln(1-p)\n\\tag{96.28}\n\n\\mathbb{E}[X] = \\frac{1}{p}\n\\tag{96.29}\n\n\\mathbb{V}ar[X]=\\frac{1-p}{p^2}\n\\tag{96.30}\n\n\n96.6.5 PMF\n\n\\mathbb{P}r(X = x \\mid p) = \\mathbb{P}r(1-p)^{x-1} \\qquad \\forall x \\in N;\\quad 0\\le p \\le 1\n\\tag{96.31}\n\n\n96.6.6 CDF\n\n1-(1-p)^{\\lfloor x\\rfloor } \\qquad x&lt;1\n\\tag{96.32}\n\n\n96.6.7 Memoryless property\n\nThe geometric distribution is based on geometric series.\nThe geometric distribution has the memoryless property:\n\nP (X &gt; s \\mid X &gt;  t) = P (X &gt; s − t)\n\nOne can say that the distribution “forgets” what has occurred, so that The probability of getting an additional s − t failures, having already observed t failures, is the same as the probability of observing s − t failures at the start of the sequence. In other words, the probability of getting a run of failures depends only on the length of the run, not on its position.\nY=X-1 is the \\text{negative binomial}(1,p)\n\n\n96.6.8 Worked out Examples\n\nExample 96.1 (Geometric Distribution) The Geometric distribution arises when we consider how long we will have to “wait for a success” during repeated Bernoulli trials.\nWhat is the probability that we flip a fair coin four times and don’t see any heads?\nThis is the same as asking what is \\mathbb{P}r(X &gt; 4) where X ∼ Geo(1/2).\n\n  \\begin{aligned}\n    \\mathbb{P}r(X &gt; 4) &= 1 − \\mathbb{P}r(X =1)−\\mathbb{P}r(X = 2)−\\mathbb{P}r(X = 3)−\\mathbb{P}r(X = 4) \\\\\n    &= 1−(\\frac{1}{2})−(\\frac{1}{2})(\\frac{1}{2})−(\\frac{1}{2})(\\frac{1}{2})^2−(\\frac{1}{2})(\\frac{1}{2})^3  \\\\\n   &= \\frac{1}{16}\n    \\end{aligned}\n\nOf course, we could also have just computed it directly, but here we see an example of using the geometric distribution and we can also see that we got the right answer.\n\n\n\n96.6.9 Plots\n\n\nCode\nimport numpy as np\nfrom scipy.stats import geom\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\np = 0.5\nmean, var, skew, kurt = geom.stats(p,moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=2.00, var=2.00, skew=2.12, kurt=6.50\n\n\nCode\nx = np.arange(geom.ppf(0.01, p),\n              geom.ppf(0.99, p))\nax.plot(x, geom.pmf(x, p), 'bo', ms=8, label='geom pmf')\nax.vlines(x, 0, geom.pmf(x, p), colors='b', lw=5, alpha=0.5)\n\nrv = geom(p)\nax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n        label='frozen pmf')\nax.legend(loc='best', frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\nr = geom.rvs(p,size=10)\nr\n\n\narray([2, 1, 5, 2, 1, 1, 2, 1, 1, 2])",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-negative-binomial-distribution",
    "href": "A02.html#sec-negative-binomial-distribution",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.7 Negative Binomial Distribution",
    "text": "96.7 Negative Binomial Distribution\n\n96.7.1 Story\n\n\n\n\n\n\nNote\n\n\n\nIn a sequence of independent Bernoulli trials with success probability p, if X is the number of failures before the rth success, then X is said to have the Negative Binomial distribution with parameters r and p, denoted X \\sim NBin(r, p).\n\n\nBoth the Binomial and the Negative Binomial distributions are based on independent Bernoulli trials; they differ in the stopping rule and in what they are counting.\nThe Binomial counts the number of successes in a fixed number of trials; the Negative Binomial counts the number of failures until a fixed number of successes.\nIn light of these similarities, it comes as no surprise that the derivation of the Negative Binomial PMF bears a resemblance to the corresponding derivation for the Binomial.\n\n\n96.7.2 Parameters\n\nr the number of successes.\np the probability of the Bernoulli trial.\n\n\n\n96.7.3 Conditions\n\n\n\n\n\n\nTip\n\n\n\n\nCount of discrete events\nNon-independent events; it is sometimes said that the events can exhibit contagion, meaning that if one event occurs, it is more likely that another will also occur\nCan model a data-generating process where the variance exceeds the mean\nFixed amount of time or space in which the events can occur\n\n\n\n\n\n96.7.4 Examples\n\nStamp collection - Suppose there are n types of stamps, which you are collecting one by one, with the goal of getting a complete set. When collecting stamps, the stamp types are random. Assume that each time you collect a stamp, it is equally likely to be any of the n types. What is the expected number of toys needed until you have a complete set?\neverything the Poisson can do and more,\nto model the number of measles cases that occur on an island,\nthe number of banks that collapse in a financial crisis.\nthe length of a hospital stay\nthe probability you will have to visit Y houses if you must sell r cookies before returning home\n\n\n\n96.7.5 Moments\n\n\\mathrm{E}(X) = \\lambda\n\n\nvar(X) = \\lambda + \\frac{\\lambda^2}{\\kappa}\n\n\n\n96.7.6 Probability mass function (PMF)\n\nf(x \\mid \\lambda,\\kappa) = \\frac{\\Gamma(x+\\kappa)}{x!\\Gamma(\\kappa+1)}\\left(\\frac{\\lambda}{\\lambda+\\kappa}\\right)^x \\left(\\frac{\\kappa}{\\lambda+\\kappa}\\right)^\\kappa\n\n\n\n96.7.7 Cumulative distribution function (CDF)\n\nF(x \\mid \\lambda,\\kappa) =\n\\begin{cases}\n  I_{\\frac{\\kappa}{\\kappa+\\lambda}}(\\kappa,1+\\lfloor x \\rfloor), & x \\ge q 0 \\\\\n  0,                                                             & \\text{Otherwise}\n\\end{cases}\n\n\n\\text{where } I_w(u,v) \\text{ is the regularised incomplete beta function: }\nI_w(u,v) = \\frac{B(w; u, v)}{B(u,v)}\n\n\n\\text{where } B(w; u,v)=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the incomplete beta function and }\\\\ B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the complete beta function}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#sec-multinomial-distribution",
    "href": "A02.html#sec-multinomial-distribution",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.8 Multinomial Distribution",
    "text": "96.8 Multinomial Distribution\nThe Multinomial distribution is a generalization of the Binomial. Whereas the Binomial distribution counts the successes in a fixed number of trials that can only be categorized as success or failure, the Multinomial distribution keeps track of trials whose outcomes can fall into multiple categories, such as excellent, adequate, poor; or red, yellow, green, blue.\n\n96.8.1 Story\nMultinomial distribution. Each of N objects is independently placed into one of k categories. An object is placed into category j with probability p_j ,P where the p_j are non-negative and \\sum^k_{j=1} p_j = 1. Let X_1 be the number of objects in category 1, X_2 the number of objects in category 2, etc., so that X_1 + \\dots + X_k = n. Then X = (X_1 , \\dots , X_k ) is said to have the Multinomial distribution with parameters n and p = (p_1 , \\dots , p_k ). We write this as X \\sim Mult_k(n, p).\nWe call X a random vector because it is a vector of random variables. The joint PMF of X can be derived from the story.\n\n\n96.8.2 Examples\n\nBlood type counts across n individuals\nNumbers of people voting for each party in a sample\n\n\n\n96.8.3 Moments\n\n\\mathrm{E}(X_i) = n p_i \\text{, }\\forall i\n\n\nvar(X_i) = n p_i (1-p_i) \\text{, }\\forall i\n\n\ncov(X_i,X_j) = -n p_i p_j \\text{, }\\forall i\\neq j\n\n\n\n96.8.4 Probability Mass Function (PMF)\n\nf(x_1,x_2,\\dots,x_d \\mid n,p_1,p_2,\\dots,p_d) = \\frac{n!}{x_1 ! x_2 ! \\dots x_d !} p_1^{x_1} p_2^{x_2}\\dots p_d^{x_d}",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A02.html#beta-binomial",
    "href": "A02.html#beta-binomial",
    "title": "96  Appendix: Discrete Distributions",
    "section": "96.9 Beta Binomial",
    "text": "96.9 Beta Binomial\n\n96.9.1 Story 1 - Polya Urn Model\nThe beta-binomial distribution with parameters \\alpha success rate and \\beta failure and n the number of trials can be motivated by an Pólya urn model.\nImagine an urn containing \\alpha red balls and \\beta black balls, where random draws are made. If a red ball is observed, then two red balls are returned to the urn. Likewise, if a black ball is drawn, then two black balls are returned to the urn. If this is repeated n times, then the probability of observing x red balls follows a beta-binomial distribution with parameters n, \\alpha and \\beta.\nIf the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.\n\n\n96.9.2 Story 2 compound distribution\nThe Beta distribution is a conjugate distribution of the binomial distribution. This fact leads to an analytically tractable compound distribution constructed in a hierarchical fashion where one can think of the p parameter in the binomial distribution as being randomly drawn from a beta distribution.\nSuppose we were interested in predicting the number of heads, x in n future trials. This is given by\n\n{\\displaystyle {\\begin{aligned}f(x\\mid n,\\alpha ,\\beta )&=\\int _{0}^{1}\\mathrm {Bin} (x \\mid n,p)\\mathrm {Beta} (p\\mid \\alpha ,\\beta )\\,dp\\\\[6pt]&={n \\choose x}{\\frac {1}{\\mathrm {B} (\\alpha ,\\beta )}}\\int _{0}^{1}p^{x+\\alpha -1}(1-p)^{n-x+\\beta -1}\\,dp\\\\[6pt]&={n \\choose x}{\\frac {\\mathrm {B} (x+\\alpha ,n-x+\\beta )}{\\mathrm {B} (\\alpha ,\\beta )}}.\\end{aligned}}}\n\n\n{\\displaystyle f(x\\mid n,\\alpha ,\\beta )={\\frac {\\Gamma (n+1)}{\\Gamma (x+1)\\Gamma (n-x+1)}}{\\frac {\\Gamma (x+\\alpha )\\Gamma (n-x+\\beta )}{\\Gamma (n+\\alpha +\\beta )}}{\\frac {\\Gamma (\\alpha +\\beta )}{\\Gamma (\\alpha )\\Gamma (\\beta )}}.}\n\n\n\n96.9.3 Moments\n\n\\mathrm{E}(X) = \\frac{n\\alpha}{\\alpha+\\beta}\n \nvar(X) = \\frac{n\\alpha\\beta(\\alpha+\\beta+n)}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n\n\n\n96.9.4 Probability mass function (PMF)\n\nf(x \\mid n,\\alpha,\\beta) = \\binom{n}{x}\\frac{B(x+\\alpha,n-x+\\beta)}{B(\\alpha,\\beta)}\n\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the (complete) beta function }\n\n\n\n96.9.5 Cumulative distribution function (CDF)\n\nF(x\\mid n,\\alpha,\\beta) = \\begin{cases}\n0, & x&lt;0 \\\\\n\\binom{n}{x}\\frac{B(x+\\alpha,n-x+\\beta)}{B(\\alpha,\\beta)} {}_{3}F_2(1,-x,n-x+\\beta;n-x-1,1-x-\\alpha;1), & 0\\leq x \\leq n \\\\\n1, & x&gt;n \\end{cases}\n\n\n\\text{where } {}_{3}F_2(a,b,x) \\text{ is the generalised hypergeometric function}\n\n\n\n96.9.6 Relations\n\nThe Pascal distribution (after Blaise Pascal) is special cases of the negative binomial distribution. Used with an integer-valued stopping-time parameter r\nThe Pólya distribution (for George Pólya) is special cases of the negative binomial distribution. Used with a real-valued-valued stopping-time parameter r\n\n\n\n\n\nA photo of Hungarian Mathematician George Pólya\n\n\n\n\n\n\n\nTipBiographical note on George Pólya\n\n\n\n\nThe cookbook gives a detailed description of ingredients and procedures but no proofs for its prescriptions or reasons for its recipes; the proof of the pudding is in the eating … Mathematics cannot be tested in exactly the same manner as a pudding; if all sorts of reasoning are debarred, a course of calculus may easily become an incoherent inventory of indigestible information. (Polya 1945)\n\nPólya was arguably the most influential mathematician of the 20th century. His basic research contributions span complex analysis, mathematical physics, probability theory, geometry, and combinatorics. He was a teacher par excellence who maintained a strong interest in pedagogical matters throughout his long career.\nHe was awarded a doctorate in mathematics having studied, essentially without supervision, a problem in the theory of geometric probability. Later Pólya looked at the Fourier transform of a probability measure, showing in 1923 that it was a characteristic function. He wrote on the normal distribution and coined the term “central limit theorem” in 1920 which is now standard usage.\nIn 1921 he proved his famous theorem on random walks on an integer lattice. He considered a d-dimensional array of lattice points where a point moves to any of its neighbors with equal probability. He asked whether given an arbitrary point A in the lattice, a point executing a random walk starting from the origin would reach A with probability 1. Pólya’s surprising answer was that it would for d=1 and for d=2, but it would not for d\\ge 3. In later work he looked at two points executing independent random walks and also at random walks satisfying the condition that the moving point never passed through the same lattice point twice.\nOne of Pólya’s notable achievements was his collaboration with the economist Abraham Wald during World War II. They developed statistical techniques to solve military problems, including estimating enemy troop movements and predicting the effectiveness of bombing missions. These contributions played a vital role in aiding the Allies during the war.\nHis book “How to Solve It,” published in 1945, presented problem-solving heuristics applicable to various mathematical domains, including probability and statistics. This influential work emphasized the importance of understanding the problem, devising a plan, executing the plan, and reflecting on the results. Pólya’s problem-solving strategies continue to be widely taught and practiced.\n\nFor a more extensive biography visit the following link\n\n\n\n\n\n\n\n\nBernoulli, J. 1713. Ars Conjectandi [the Art of Conjecturing]. Impensis Thurnisiorum. https://books.google.co.il/books?id=Ba5DAAAAcAAJ.\n\n\nPolya, G. 1945. How to Solve It. Princeton University Press. https://doi.org/10.1515/9781400828678.",
    "crumbs": [
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Appendix: Discrete Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html",
    "href": "A03.html",
    "title": "97  Appendix: Continuous Distributions",
    "section": "",
    "text": "97.1 The Continuous Uniform\nFollowing a subjective view of distribution, which is more amenable to reinterpretation I use an indicator function to place restrictions on the range of parameter of the PDF.",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-continuous-uniform",
    "href": "A03.html#sec-continuous-uniform",
    "title": "97  Appendix: Continuous Distributions",
    "section": "",
    "text": "97.1.1 Stories\n\n\n\n\n\n\nNoteDiscrete Uniform Finite set Parametrization\n\n\n\n\n\n\n\nX \\sim U[\\alpha,\\beta]\n\\tag{97.1}\n\n\n97.1.2 Moments\n\n\\mathbb{E}[X]=\\frac{(\\alpha+\\beta)}{2}\n\\tag{97.2}\n\n\\mathbb{V}ar[X]=\\frac{(\\beta-\\alpha)^2}{12}\n\\tag{97.3}\n\n\n97.1.3 Probability mass function (PDF)\n\nf(x)= \\frac{1}{\\alpha-\\beta} \\mathbb{I}_{\\{\\alpha \\le x \\le \\beta\\}}(x)\n\\tag{97.4}\n\n\n97.1.4 Cumulative distribution function (CDF)\n\nF(x\\mid \\alpha,\\beta)=\\begin{cases}\n  0,  & \\text{if }x &lt; \\alpha \\\\\n  \\frac{x-\\alpha}{\\beta-\\alpha}, & \\text{if } x\\in [\\alpha,\\beta]\\\\\n  1, & \\text{if } x &gt; \\beta\n  \\end{cases}\n\\tag{97.5}\n\n\n97.1.5 Prior\nSince a number of families have the uniform as a special case we can use them as priors when we want a uniform prior:\nNormal(0,1)= Beta(1,1)",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-beta-distribution",
    "href": "A03.html#sec-the-beta-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.2 The Beta Distribution",
    "text": "97.2 The Beta Distribution\n\n\n97.2.1 Story\nThe Beta distribution is used for random variables which take on values between 0 and 1. For this reason (and other reasons we will see later in the course), the Beta distribution is commonly used to model probabilities.\n\nX \\sim Beta(\\alpha, \\beta)\n\\tag{97.6}\n\n\n97.2.2 PDF & CDF\n\nf(x \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha−1}(1 − x)^{\\beta−1}\\mathbb{I}_{x\\in(0,1)}\\mathbb{I}_{\\alpha\\in\\mathbb{R}^+}\\mathbb{I}_{\\beta\\in\\mathbb{R}^+} \\qquad \\text{(PDF)}\n\\tag{97.7}\n\n\\begin{aligned}\n                 & F(x \\mid \\alpha,\\beta) &= I_x(\\alpha,\\beta) && \\text{(CDF)}\n\\\\ \\text{where } & I_w(u,v) & &&\\text{ is the regularized beta function: }\n\\\\               & I_w(u,v) &= \\frac{B(w; u, v)}{B(u,v)}\n\\\\ \\text{where } & B(w; u,v) &=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t  && \\text{ is the incomplete beta function  }\n\\\\ \\text{and }   & B(u,v)& && \\text{ is the (complete) beta function}\n\\end{aligned}\n\\tag{97.8}\n\n\n97.2.3 Moments\n\n\\mathbb{E}[X] = \\frac{\\alpha}{\\alpha + \\beta} \\qquad (\\text{expectation})\n\\tag{97.9}\n\n\\mathbb{V}ar[X] = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)} \\qquad (\\text{variance})\n\\tag{97.10}\n\n\\mathbb{M}_X(t) = 1+ \\sum^\\infty_{i=1} \\left ( {\\prod^\\infty_{j=0} \\frac{\\alpha+j}{\\alpha + \\beta + j} } \\right ) \\frac{t^i}{i!}\n\\tag{97.11}\nwhere \\Gamma(·) is the Gamma function introduced with the gamma distribution.\nNote also that \\alpha &gt; 0 and \\beta &gt; 0.\n\n\n97.2.4 Relations\n\n\n\nRelations of the Beta distribution\n\n\nThe standard Uniform(0, 1) distribution is a special case of the beta distribution with \\alpha = \\beta = 1.\n\nUniform(0, 1) = Beta(1,1)\n\\tag{97.12}\n\n\n97.2.5 As a prior\nThe Beta distribution is often used as a prior for parameters that are probabilities,since it takes values from 0 and 1.\nDuring prior elicitation the parameters can be set using\n\nthe mean: \\alpha \\over \\alpha +\\beta which I would interpret here as count of successes over trials prior to seeing the data.\nvariance: Equation 97.10 or\nThe effective sample size which is \\alpha+\\beta (see course 1 lesson 7.3 for the derivation).",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-cauchy",
    "href": "A03.html#sec-cauchy",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.3 The Cauchy Distribution",
    "text": "97.3 The Cauchy Distribution\n\n\n97.3.1 PDF\n\n\\text{Cauchy}(y\\mid\\mu,\\sigma) = \\frac{1}{\\pi \\sigma} \\\n\\frac{1}{1 + \\left((y - \\mu)/\\sigma\\right)^2} \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{97.13}\n\n\n97.3.2 CDF\n\nF(x \\mid \\mu, \\sigma) = \\frac{1}{2} + \\frac{1}{\\pi}\\text{arctan}\\left(\\frac{x-\\mu}{\\sigma}\\right) \\qquad \\text{(CDF)}\n\\tag{97.14}\n\n\\mathbb{E}(X) = \\text{ undefined}\n\n\n\\mathbb{V}ar[X] = \\text{ undefined}\n\n\n\n97.3.3 As a prior\nThe Cauchy despite having no mean or variance is recommended as a prior for regression coefficients in Logistic regression. see (Gelman et al. 2008) this is analyzed and discussed in (Ghosh, Li, and Mitra 2018)",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-double-exponential",
    "href": "A03.html#sec-double-exponential",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.4 Double Exponential Distribution (Laplace)",
    "text": "97.4 Double Exponential Distribution (Laplace)\n \n\n\\text{DoubleExponential}(y \\mid \\mu,\\sigma) =\n\\frac{1}{2\\sigma} \\exp \\left( - \\, \\frac{|y - \\mu|}{\\sigma} \\right)\n\\qquad \\text (PDF)\n\\tag{97.15}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-gamma-distribution",
    "href": "A03.html#sec-the-gamma-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.5 The Gamma Distribution",
    "text": "97.5 The Gamma Distribution\n\n\n97.5.1 Story\nIf X_1, X_2, ..., X_n are independent (and identically distributed Exp(\\lambda)) waiting times between successive events, then the total waiting time for all n events to occur Y = \\sum X_i will follow a gamma distribution with shape parameter \\alpha = n and rate parameter \\beta = \\lambda:\nWe denote this as:\n\nY =\\sum^N_{i=0} \\mathrm{Exp}_i(\\lambda) \\sim \\mathrm{Gamma}(\\alpha = N, \\beta = \\lambda)\n\\tag{97.16}\n\n\n97.5.2 PDF\n\nf(y \\mid \\alpha , \\beta) = \\frac{\\beta^\\alpha} {\\Gamma(\\alpha)} y^{\\alpha−1} e^{− \\beta y} \\mathbb{I}_{y \\ge \\theta }(y)\n\\tag{97.17}\n\n\n97.5.3 Moments\n\n\\mathbb{E}[Y] = \\frac{\\alpha}{ \\beta}\n\\tag{97.18}\n\n\\mathbb{V}ar[Y] = \\frac{\\alpha}{ \\beta^2}\n\\tag{97.19}\nwhere \\Gamma(·) is the gamma function, a generalization of the factorial function which can accept non-integer arguments. If n is a positive integer, then \\Gamma(n) = (n − 1)!.\nNote also that \\alpha &gt; 0 and $ &gt; 0$.\n\n\n97.5.4 Relations\n\n\n\nRelations of the Gamma Distribution\n\n\nThe exponential distribution is a special case of the Gamma distribution with \\alpha = 1. The gamma distribution commonly appears in statistical problems, as we will see in this course. It is used to model positive-valued, continuous quantities whose distribution is right-skewed. As \\alpha increases, the gamma distribution more closely resembles the normal distribution.",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#inverse-gamma-distribution",
    "href": "A03.html#inverse-gamma-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.6 Inverse Gamma Distribution",
    "text": "97.6 Inverse Gamma Distribution\n\n\n97.6.1 PDF\n\n\\text{InvGamma}(y|\\alpha,\\beta) =\n\\frac{1} {\\Gamma(\\alpha)}\\frac{\\beta^{\\alpha}}{y^{\\alpha + 1}}  e^{- \\frac{ \\beta}{y}}\n   \\ \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{\\beta \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)\n\\tag{97.20}\n\n\n97.6.2 Moments\n\n\\mathbb{E}[X]=\\frac{\\beta}{\\alpha - 1} \\qquad \\text{Expectation}\n\\tag{97.21}\n\n\\mathbb{V}ar[X]=\\frac{\\beta^2}{(\\alpha-1)^2(\\alpha-2)}\\qquad \\text{Variance}\n\\tag{97.22}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#the-z-or-standard-normal-distribution",
    "href": "A03.html#the-z-or-standard-normal-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.7 The Z or Standard normal distribution",
    "text": "97.7 The Z or Standard normal distribution\n· The Standard normal distribution is given by:\n\nZ \\sim \\mathcal{N}[1,0]\n\\tag{97.23}\n\nf(z) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}\n\\tag{97.24}\n\n\\mathcal{L}(\\mu,\\sigma)=\\prod_{i=1}^{n}{1 \\over 2 \\pi \\sigma}e^{−(x_i−\\mu)^2 \\over 2 \\sigma^2}\n\\tag{97.25}\n\n\\begin{aligned}\n\\ell(\\mu, \\sigma) &= \\log \\mathcal{L}(\\mu, \\sigma) \\\\&= -\\frac{n}{2}\\log(2\\pi) - n\\log\\sigma - \\sum_{i=1}^n \\frac{(x_i-\\mu)^2}{2\\sigma^2}\n\\end{aligned}\\sigma^2\n\\tag{97.26}\n\n\\begin{aligned}\n  \\mathbb{E}(Z)&= 0 \\quad \\text{(Expectation)} \\qquad  \\mathbb{V}ar(Z)&= 1 \\quad \\text{(Variance)}\n\\end{aligned}\n\\tag{97.27}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-normal-distribution",
    "href": "A03.html#sec-the-normal-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.8 The Normal Distribution",
    "text": "97.8 The Normal Distribution\n The normal, or Gaussian distribution is one of the most important distributions in statistics.\nIt arises as the limiting distribution of sums (and averages) of random variables. This is due to the Section 100.1. Because of this property, the normal distribution is often used to model the “errors,” or unexplained variations of individual observations in regression models.\nNow consider X = \\sigma Z+\\mu where \\sigma &gt; 0 and \\mu is any real constant. Then E(X) = E(\\sigma Z+\\mu) = \\sigma E(Z) + \\mu = \\sigma_0 + \\mu = \\mu and $Var(X) = Var(^2 Z + ) = ^2 Var(Z) + 0 = ^2 = ^2 $\nThen, X follows a normal distribution with mean \\mu and variance \\sigma^2 (standard deviation \\sigma) denoted as\n\nX \\sim N[\\mu,\\sigma^2]\n\\tag{97.28}\n\n97.8.1 PDF\n\nf(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}  e^{-\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}(x-\\mu)^2}\n\\tag{97.29}\n\n\n97.8.2 Moments\n\n\\mathbb{E}(x)= \\mu\n\\tag{97.30}\n\nVar(x)= \\sigma^2\n\\tag{97.31}\n\nThe normal distribution is symmetric about the mean \\mu and is often described as a bell-shaped curve.\nAlthough X can take on any real value (positive or negative), more than 99% of the probability mass is concentrated within three standard deviations of the mean.\n\nThe normal distribution has several desirable properties.\nOne is that if X_1 \\sim N(\\mu_1, \\sigma^2_1) and X_2 ∼ N(\\mu_2, \\sigma^2_2) are independent, then X_1+X_2 \\sim N(\\mu_1+\\mu_2, \\sigma^2_1+\\sigma^2_2).\nConsequently, if we take the average of n Independent and Identically Distributed (IID) Normal random variables we have:\n\n\\bar X = \\frac{1}{n}\\sum_{i=1}^n X_i \\sim N(\\mu, \\frac{\\sigma^2}{n})\n\\tag{97.32}\n\n\nCode\nimport numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = norm.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=0.00, var=1.00, skew=0.00, kurt=0.00\n\n\nCode\nx = np.linspace(norm.ppf(0.01),\n                norm.ppf(0.99), 100)\nax.plot(x, norm.pdf(x),\n       'r-', lw=5, alpha=0.6, label='norm pdf')\n\nrv = norm()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\nr = norm.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n\n(array([0.00377651, 0.        , 0.        , 0.01510605, 0.01888256,\n       0.08308327, 0.05287117, 0.09441281, 0.15861352, 0.26057936,\n       0.32100356, 0.36632171, 0.40786334, 0.41919288, 0.33988612,\n       0.31722704, 0.28701495, 0.22659075, 0.1510605 , 0.10196584,\n       0.06797722, 0.04909466, 0.02265907, 0.00755302, 0.        ,\n       0.00377651]), array([-3.52647772, -3.26168314, -2.99688857, -2.732094  , -2.46729942,\n       -2.20250485, -1.93771028, -1.6729157 , -1.40812113, -1.14332656,\n       -0.87853198, -0.61373741, -0.34894284, -0.08414826,  0.18064631,\n        0.44544088,  0.71023545,  0.97503003,  1.2398246 ,  1.50461917,\n        1.76941375,  2.03420832,  2.29900289,  2.56379747,  2.82859204,\n        3.09338661,  3.35818119]), [&lt;matplotlib.patches.Polygon object at 0x779a790b29e0&gt;])\n\n\nCode\nax.set_xlim([x[0], x[-1]])\n\n\n(-2.3263478740408408, 2.3263478740408408)\n\n\nCode\nax.legend(loc='best', frameon=False)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-t-distribution",
    "href": "A03.html#sec-the-t-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.9 The t-Distribution",
    "text": "97.9 The t-Distribution\n If we have normal data, we can use (Equation 97.32) to help us estimate the mean \\mu. Reversing the transformation from the previous section, we get:\n\n\\frac {\\hat X - \\mu}{\\sigma / \\sqrt(n)} \\sim N(0, 1)\n\\tag{97.33}\nHowever, we may not know the value of \\sigma. If we estimate it from data, we can replace it with S = \\sqrt{\\sum_i \\frac{(X_i-\\hat X)^2}{n-1}}, the sample standard deviation. This causes the expression (Equation 97.33) to no longer be distributed as a Standard Normal; but as a standard t-distribution with ν = n − 1 degrees of freedom\n\nX \\sim t[\\nu]\n\\tag{97.34}\nf(t\\mid\\nu) = \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\nu\\pi}}\\left (1 + \\frac{t^2}{\\nu}\\right)^{-(\\frac{\\nu+1}{2})}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{97.35}\n\n\\text{where }\\Gamma(w)=\\int_{0}^{\\infty}t^{w-1}e^{-t}\\mathrm{d}t \\text{ is the gamma function}\n\nf(t\\mid\\nu)={\\frac {1}{{\\sqrt {\\nu }}\\,\\mathrm {B} ({\\frac {1}{2}},{\\frac {\\nu }{2}})}}\\left(1+{\\frac {t^{2}}{\\nu }}\\right)^{-(\\nu +1)/2}\\mathbb{I}_{t\\in\\mathbb{R}} \\qquad \\text{(PDF)}\n\\tag{97.36}\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the beta function}\n\n\\begin{aligned} && F(t)&=\\int _{-\\infty }^{t}f(u)\\,du=1-{\\tfrac {1}{2}}I_{x(t)}\\left({\\tfrac {\\nu }{2}},{\\tfrac {1}{2}}\\right) &&\\text{(CDF)}\n\\\\ \\text{where } && I_{x(t)}&= \\frac{B(x; u, v)}{B(u,v)} &&\\text{is the regularized Beta function}\n\\\\ \\text{where } &&B(w; u,v)&=\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t &&  \\text{ is the incomplete Beta function }\n\\\\ \\text {and }&& B(u,v)&=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t && \\text{ is the (complete) beta function} \\end{aligned}\n\\tag{97.37}\n\\int _{-\\infty }^{t}f(u)\\,du={\\tfrac {1}{2}}+t{\\frac {\\Gamma \\left({\\tfrac {1}{2}}(\\nu +1)\\right)}{{\\sqrt {\\pi \\nu }}\\,\\Gamma \\left({\\tfrac {\\nu }{2}}\\right)}}\\,{}_{2}F_{1}\\left({\\tfrac {1}{2}},{\\tfrac {1}{2}}(\\nu +1);{\\tfrac {3}{2}};-{\\tfrac {t^{2}}{\\nu }}\\right)\n\n\n\\mathcal{L}(\\mu, \\sigma, \\nu) = \\prod_{i=1}^n \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu\\pi}\\Gamma(\\frac{\\nu}{2})} \\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right)^{-\\frac{\\nu+1}{2}}\n\\tag{97.38}\n\n\\begin{aligned}\n\\ell(\\mu, \\sigma, \\nu) &= \\log \\mathcal{L}(\\mu, \\sigma, \\nu) \\\\&= \\sum_{i=1}^n \\left[\\log\\Gamma\\left(\\frac{\\nu+1}{2}\\right) - \\log\\sqrt{\\nu\\pi} - \\log\\Gamma\\left(\\frac{\\nu}{2}\\right) - \\frac{\\nu+1}{2}\\log\\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right)\\right] \\\\ &= n\\log\\Gamma\\left(\\frac{\\nu+1}{2}\\right) - n\\log\\sqrt{\\nu\\pi} - n\\log\\Gamma\\left(\\frac{\\nu}{2}\\right) - \\frac{\\nu+1}{2}\\sum_{i=1}^n\\log\\left(1+\\frac{(x_i-\\mu)^2}{\\sigma^2\\nu}\\right).\n\\end{aligned}\n\\tag{97.39}\n\n\\mathbb{E}[Y] = 0 \\qquad \\text{ if } \\nu &gt; 1\n\\tag{97.40}\n\n\\mathbb{V}ar[Y] = \\frac{\\nu}{\\nu - 2} \\qquad \\text{ if } \\nu &gt; 2\n\\tag{97.41}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#location-scale-parametrization-t-distribution",
    "href": "A03.html#location-scale-parametrization-t-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.10 Location Scale Parametrization t-distribution",
    "text": "97.10 Location Scale Parametrization t-distribution\n\nX=\\mu+\\sigma T\n\nThe resulting distribution is also called the non-standardized Student’s t-distribution.\nthis is another parameterization of the student-t with:\n\nlocation \\mu \\in \\mathbb{R}^+\nscale \\sigma \\in \\mathbb{R}^+\ndegrees of freedom \\nu \\in \\mathbb{R}^+\n\n\nf(x \\mid \\mu, \\sigma, \\nu) = \\frac{\\left(\\frac{\\nu }{\\nu +\\frac{(x-\\mu )^2}{\\sigma ^2}}\\right)^{\\frac{\\nu+1}{2}}}{\\sqrt{\\nu } \\sigma  B\\left(\\frac{\\nu }{2},\\frac{1}{2} \\right)}\n\\tag{97.42}\n\n\\text{where } B(u,v)=\\int_{0}^{1}t^{u-1}(1-t)^{v-1}\\mathrm{d}t \\text{ is the beta function}\n\n\nF(\\mu, \\sigma, \\nu) =\n\\begin{cases}\n\\frac{1}{2} I_{\\frac{\\nu  \\sigma ^2}{(x-\\mu )^2+\\nu  \\sigma  ^2}}\\left(\\frac{\\nu }{2},\\frac{1}{2}\\right),                & x\\leq \\mu  \n\\\\ \\frac{1}{2} \\left(I_{\\frac{(x-\\mu )^2}{(x-\\mu )^2+\\nu  \\sigma   ^2}}\\left(\\frac{1}{2},\\frac{\\nu }{2}\\right)+1\\right), & \\text{Otherwise}\n\\end{cases}\n\\tag{97.43}\nwhere I_w(u,v) is the regularized incomplete beta function:\n\n\\\\ I_w(u,v) = \\frac{B(w; u, v)}{B(u,v)}\n\nwhere B(w; u,v) is the incomplete beta function:\n\nB(w; u,v) =\\int_{0}^{w}t^{u-1}(1-t)^{v-1}\\mathrm{d}t\n\nAnd B(u,v) is the (complete) beta function\n\n\\mathbb{E}[X] = \\begin{cases}\n  \\mu,               & \\text{if }\\nu &gt; 1\n  \\\\\\text{undefined} & \\text{ otherwise}\n\\end{cases}\n\\tag{97.44}\n\n\\mathbb{V}ar[X] = \\frac{\\nu \\sigma^2}{\\nu-2}\n\\tag{97.45}\nThe t distribution is symmetric and resembles the Normal Distribution but with thicker tails. As the degrees of freedom increase, the t distribution looks more and more like the standard normal distribution.\n\n\n\n\n\n\n\nFigure 97.1: William Sealy Gosset AKA Student\n\n\n\n\n\n\n\n\nTipHistorical Note on The William Sealy Gosset A.K.A Student\n\n\n\n The student-t distribution is due to Gosset, William Sealy (1876-1937) who was an English statistician, chemist and brewer who served as Head Brewer of Guinness and Head Experimental Brewer of Guinness and was a pioneer of modern statistics. He is known for his pioneering work on small sample experimental designs. Gosset published under the pseudonym “Student” and developed most famously Student’s t-distribution – originally called Student’s “z” – and “Student’s test of statistical significance”.\nHe was told to use a Pseudonym and choose ‘Student’ after a predecessor at Guinness published a paper that leaked trade secrets. Gosset was a friend of both Karl Pearson and Ronald Fisher. Fisher suggested a correction to the student-t using the degrees of freedom rather than the sample size. Fisher is also credited with helping to publicize its use.\nfor a full biography see (Pearson et al. 1990)",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-the-exponential-distribution",
    "href": "A03.html#sec-the-exponential-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.11 The Exponential Distribution",
    "text": "97.11 The Exponential Distribution\n\n\n97.11.1 Story\nThe Exponential distribution models the waiting time between events for events with a rate lambda. Those events, typically, come from a Poisson process\nThe exponential distribution is often used to model the waiting time between random events. Indeed, if the waiting times between successive events are independent then they form an Exp(λ) distribution. Then for any fixed time window of length t, the number of events occurring in that window will follow a Poisson distribution with mean tλ.\n\nX \\sim Exp[\\lambda]\n\\tag{97.46}\n\n\n97.11.2 PDF\n\nf(x \\mid \\lambda) = \\frac{1}{\\lambda} e^{- \\frac{x}{\\lambda}}(x)\\mathbb{I}_{\\lambda\\in\\mathbb{R}^+ } \\mathbb{I}_{x\\in\\mathbb{R}^+_0 } \\quad \\text{(PDF)}\n\\tag{97.47}\n\n\n97.11.3 CDF\n\nF(x \\mid \\lambda) = 1 - e^{-\\lambda x} \\qquad \\text{(CDF)}\n\n\n\\mathcal{L}(\\lambda) = \\prod_{i=1}^n \\lambda e^{-\\lambda x_i}\n\\tag{97.48}\n\n\\begin{aligned} \\ell(\\lambda) &= \\log \\mathcal{L}(\\lambda) \\\\ &= \\sum_{i=1}^n \\log(\\lambda) - \\lambda x_i \\\\\n&= n\\log(\\lambda) - \\lambda\\sum_{i=1}^n x_i \\end{aligned}\n\\tag{97.49}\n\n\n97.11.4 Moments\n\n\\mathbb{E}(x)= \\lambda\n\\tag{97.50}\n\n\\mathbb{V}ar[X]= \\lambda^2\n\\tag{97.51}\n\n\\mathbb{M}_X(t)= \\frac{1}{1-\\lambda t} \\qquad t &lt; \\frac{1}{\\gamma}\n\\tag{97.52}\n\n\n97.11.5 Special cases:\n\nWeibull Y = X^{\\frac{1}{\\gamma}}\nRayleigh Y = \\sqrt{\\frac{2X}{\\lambda}}\nGumbel Y=\\alpha - \\gamma \\log(\\frac{X}{\\lambda})\n\n\n\n97.11.6 Properties:\n\nmemoryless\n\n\n\nCode\nimport numpy as np\nfrom scipy.stats import expon\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\nn, p = 5, 0.4\nmean, var, skew, kurt = expon.stats(moments='mvsk')\nprint(f'{mean=:1.2f}, {var=:1.2f}, {skew=:1.2f}, {kurt=:1.2f}')\n\n\nmean=1.00, var=1.00, skew=2.00, kurt=6.00\n\n\nCode\nx = np.linspace(expon.ppf(0.01), expon.ppf(0.99), 100)\nax.plot(x, expon.pdf(x), 'r-', lw=5, alpha=0.6, label='expon pdf')\n\nrv = expon()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n\nr = expon.rvs(size=1000)\n\nax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n\n\n(array([0.91444551, 0.72246248, 0.6466797 , 0.58100129, 0.41933137,\n       0.36880952, 0.31828766, 0.18187867, 0.17682648, 0.13135681,\n       0.09093933, 0.12125244, 0.06567841, 0.03031311, 0.07073059,\n       0.04041748, 0.00505219, 0.02526093, 0.02020874, 0.02526093,\n       0.01010437, 0.01010437, 0.01010437, 0.01515656, 0.01010437,\n       0.        , 0.        , 0.02526093, 0.00505219, 0.        ,\n       0.01010437]), array([7.00414267e-04, 1.98634570e-01, 3.96568725e-01, 5.94502880e-01,\n       7.92437036e-01, 9.90371191e-01, 1.18830535e+00, 1.38623950e+00,\n       1.58417366e+00, 1.78210781e+00, 1.98004197e+00, 2.17797612e+00,\n       2.37591028e+00, 2.57384443e+00, 2.77177859e+00, 2.96971274e+00,\n       3.16764690e+00, 3.36558106e+00, 3.56351521e+00, 3.76144937e+00,\n       3.95938352e+00, 4.15731768e+00, 4.35525183e+00, 4.55318599e+00,\n       4.75112014e+00, 4.94905430e+00, 5.14698845e+00, 5.34492261e+00,\n       5.54285676e+00, 5.74079092e+00, 5.93872508e+00, 6.13665923e+00]), [&lt;matplotlib.patches.Polygon object at 0x779a76f2c940&gt;])\n\n\nCode\nax.set_xlim([x[0], x[-1]])\n\n\n(0.010050335853501442, 4.605170185988091)\n\n\nCode\nax.legend(loc='best', frameon=False)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-lognormal-distribution",
    "href": "A03.html#sec-lognormal-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.12 LogNormal Distribution",
    "text": "97.12 LogNormal Distribution\nThe long normal arises when the a log transform is applied to the normal distribution.\n\n\n\\text{LogNormal}(y\\mid\\mu,\\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\ \\sigma} \\, \\frac{1}{y} \\ \\exp \\! \\left( - \\, \\frac{1}{2} \\, \\left( \\frac{\\log y - \\mu}{\\sigma} \\right)^2 \\right) \\ \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)\n\\tag{97.53}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-pareto-distribution",
    "href": "A03.html#sec-pareto-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.13 Pareto Distribution",
    "text": "97.13 Pareto Distribution\n\n\n\\text{Pareto}(y|y_{\\text{min}},\\alpha) = \\frac{\\displaystyle\n\\alpha\\,y_{\\text{min}}^\\alpha}{\\displaystyle y^{\\alpha+1}} \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{y_{min} \\in \\mathbb{R}^+}\\mathbb{I}_{y\\ge y_{min} \\in \\mathbb{R}^+}\n\\qquad \\text (PDF)\n\\tag{97.54}\n\n\\mathrm{Pareto\\_Type\\_2}(y|\\mu,\\lambda,\\alpha) = \\\n\\frac{\\alpha}{\\lambda} \\, \\left( 1+\\frac{y-\\mu}{\\lambda}\n\\right)^{-(\\alpha+1)} \\! \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\lambda \\in \\mathbb{R}^+}\\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{y\\ge \\mu \\in \\mathbb{R}}\n\\qquad \\text (PDF)\n\\tag{97.55}\n\n\\mathbb{E}[X]=\\displaystyle{\\frac{\\alpha y_\\mathrm{min}}{\\alpha - 1}}\\mathbb{I}_{\\alpha&gt;1} \\qquad \\text (expectation)\n\\tag{97.56}\n\n\\mathbb{V}ar[X]=\\displaystyle{\\frac{\\alpha y_\\mathrm{min}^2}{(\\alpha - 1)^2(\\alpha - 2)}}\\mathbb{I}_{\\alpha&gt;2} \\qquad \\text (variance)\n\\tag{97.57}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-weibull-distribution",
    "href": "A03.html#sec-weibull-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.14 Weibull Distribution",
    "text": "97.14 Weibull Distribution\n\n\n97.14.1 PDF\n\n\\text{Weibull}(y|\\alpha,\\sigma) =\n\\frac{\\alpha}{\\sigma} \\, \\left( \\frac{y}{\\sigma} \\right)^{\\alpha - 1} \\, e^{ - \\left( \\frac{y}{\\sigma} \\right)^{\\alpha}} \\mathbb{I}_{\\alpha \\in \\mathbb{R}^+}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}^+} \\qquad \\text (PDF)",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-chi-squared-distribution",
    "href": "A03.html#sec-chi-squared-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.15 Chi Squared Distribution",
    "text": "97.15 Chi Squared Distribution\n\nThe chi squared distribution is a special case of the gamma. It is widely used in hypothesis testing and the construction of confidence intervals. It is parameterized using parameter \\nu for the degrees of predom\n\n97.15.1 PDF:\n\n\\text{ChiSquare}(y\\mid\\nu) = \\frac{2^{-\\nu/2}}     {\\Gamma(\\nu / 2)} \\,\ny^{\\nu/2 - 1} \\, \\exp \\! \\left( -\\, \\frac{1}{2} \\, y \\right) \\mathbb{I}_{\\nu \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}} \\qquad \\text (PDF)\n\\tag{97.58}\n\n\n97.15.2 CDF:\n\n{\\frac {1}{\\Gamma (\\nu/2)}}\\;\\gamma \\left({\\frac {\\nu}{2}},\\,{\\frac {x}{2}}\\right) \\qquad \\text (CDF)\n\\tag{97.59}\n\n\n97.15.3 MOMENTS\n\n\\mathbb{E}[X]=\\nu\n\\tag{97.60}\n\n\\mathbb{V}ar[X] = 2\\nu\n\\tag{97.61}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-logistic-distribution",
    "href": "A03.html#sec-logistic-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.16 Logistic Distribution",
    "text": "97.16 Logistic Distribution\n\n\\text{Logistic}(y|\\mu,\\sigma) = \\frac{1}{\\sigma} \\\n\\exp\\!\\left( - \\, \\frac{y - \\mu}{\\sigma} \\right) \\ \\left(1 + \\exp\n\\!\\left( - \\, \\frac{y - \\mu}{\\sigma} \\right) \\right)^{\\!-2} \\mathbb{I}_{\\mu \\in \\mathbb{R}}\\mathbb{I}_{\\sigma \\in \\mathbb{R}^+}\\mathbb{I}_{y \\in \\mathbb{R}}  \\qquad \\text (PDF)\n\\tag{97.62}",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A03.html#sec-f-distribution",
    "href": "A03.html#sec-f-distribution",
    "title": "97  Appendix: Continuous Distributions",
    "section": "97.17 F Distribution",
    "text": "97.17 F Distribution\n   The F-distribution or F-ratio, arises frequently as the null distribution of a test statistic, in the analysis of variance (ANOVA) and other F-tests.F DistributionF-ratio\n\n97.17.1 PDF\n\n\\frac {\\sqrt {\\frac {(d_{1}x)^{d_{1}}d_{2}^{d_{2}}}{(d_{1}x+d_{2})^{d_{1}+d_{2}}}}}{x\\,\\mathrm {B} \\!\\left({\\frac {d_{1}}{2}},{\\frac {d_{2}}{2}}\\right)}\n\\tag{97.63}\n\n\n97.17.2 CDF\n\n\\mathbb{I}_{\\frac {d_{1}x}{d_{1}x+d_{2}}}\\left({\\tfrac {d_{1}}{2}},{\\tfrac {d_{2}}{2}}\\right)\n\\tag{97.64}\n\n\n97.17.3 Moments\n\n\\mathbb{E}[X]=\\frac {d_{2}}{d_{2}-2}\n\\tag{97.65}\n\n\\mathbb{V}ar[X] = {\\frac {2\\,d_{2}^{2}\\,(d_{1}+d_{2}-2)}{d_{1}(d_{2}-2)^{2}(d_{2}-4)}}\n\\tag{97.66}\n\n\n\n\n\n\nGelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” The Annals of Applied Statistics 2 (4). https://doi.org/10.1214/08-aoas191.\n\n\nGhosh, Joyee, Yingbo Li, and Robin Mitra. 2018. “On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression.” Bayesian Analysis 13 (2). https://doi.org/10.1214/17-ba1051.\n\n\nPearson, E. S., W. S. Gosset, R. L. Plackett, and G. A. Barnard. 1990. Student: A Statistical Biography of William Sealy Gosset. Clarendon Press. https://books.google.co.il/books?id=LBDvAAAAMAAJ.",
    "crumbs": [
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Appendix: Continuous Distributions</span>"
    ]
  },
  {
    "objectID": "A05.html",
    "href": "A05.html",
    "title": "98  Appendix: Exponents & Logarithms",
    "section": "",
    "text": "98.1 Exponents\nExponents are of the form a^x where:\nRecall that a^0 = 1. Exponents have the following useful properties\nNote: that the first property requires that both terms have the same base a.\nWe cannot simplify a^x ·b^y if a \\ne b.",
    "crumbs": [
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A05.html#sec-exponents",
    "href": "A05.html#sec-exponents",
    "title": "98  Appendix: Exponents & Logarithms",
    "section": "",
    "text": "a (called the base) and\nx (called the exponent) is any real number.\n\n\n\na^x· a^y = a^{x+y}\n(a^x)^y = a^{x·y}\n\n\n\n\nOne common base is the number e which is approximately equal to 2.7183.\nThe function e^x is so common in mathematics and has its own symbol e^x = \\exp(x).\nBecause e &gt; 0 we have e^x &gt; 0 for all real numbers x\n\\lim_{x \\to \\infty} x = e^{−x} = 0.",
    "crumbs": [
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A05.html#sec-natural-logarithms",
    "href": "A05.html#sec-natural-logarithms",
    "title": "98  Appendix: Exponents & Logarithms",
    "section": "98.2 Natural Logarithms",
    "text": "98.2 Natural Logarithms\nWe will need to manipulate long products of probabilities. Since there often comprise small fractions, their calculation on computers can be problematic due to the underflow of floats. We will therefore prefer to convert these products into sums of logarithms.\n\nDefinition 98.1 (The Logarithm) A log is the inverse of a power. We can use (Equation 98.1).\n\ny = a^x \\implies log_a(y) = x\n\\tag{98.1}\n\n\nDefinition 98.2 (The Natural log) The natural logarithm function has base e and is written without the subscript\n\nlog_e(y) = log(y)\n\\tag{98.2}\n\n\nTheorem 98.1 (Logs take positive values) logs only exist for values greater than 0\n\n\\forall x(e^x &gt; 0) \\implies \\exists \\log(y) \\iff {y &gt; 0}\n\n\nWe can use the properties of exponents from the previous section to obtain some important properties of logarithms:\n\nDefinition 98.3 (Log of a product) we can use Equation 98.3 to convert a log of a product to a sum of logs.\n\n\\log(x·y) = \\log(x) + \\log(y)\n\\tag{98.3}\n\n\nDefinition 98.4 (Log of a quotient) we can use Equation 98.4 to convert a log of a quotient to a difference of logs.\n\n\\log(\\frac{x}{y}) = log(x) − log(y)\n\\tag{98.4}\n\n\nDefinition 98.5 (Log of a power) we can use Equation 98.5 to convert a log of a variable raised to a power into the product.\n\n    \\log(x^b) = b \\cdot log(x)\n\\tag{98.5}\n\n\nDefinition 98.6 (Log of one) we can use (Equation 98.6) to replace a log of 1 with zero since $x(x^0 = 1) $\n\n    \\log(1)=0\n\\tag{98.6}\n\n\n98.2.1 Log of exponent\nwe can use (Equation 98.7) to cancel a log of an exponent since the log is the inverse function of the exponent.\n\nexp(log(y)) = log(exp(y)) = y\n\\tag{98.7}\n\nExample 98.1 (Logarithm) \n    \\begin{aligned}\n    log \\frac{5^2}{10}= 2 log(5) − log(10) ≈ 0.916.\n    \\end{aligned}\n\n\n\nDefinition 98.7 (Change of base for a log) we can use (Equation 98.8) to change the base of a logarithm.\n\n    \\log_b(a)=\\frac{\\log_c(a)}{\\log_c(n)}\n\\tag{98.8}\n\n\nDefinition 98.8 (Derivative of a Log) we can use (Equation 98.9) to differentiate a log.\n\n    \\frac{d}{dx} \\log_(x)=\\frac{1}{x}\n\\tag{98.9}\n\n\nBecause the natural logarithm is a monotonically increasing one-to-one function, finding the x which maximizes any (positive-valued function) f(x) is equivalent to maximizing log(f(x)).\nThis is useful because we often take derivatives to maximize functions.\nIf f(x) has product terms, then log(f(x)) will have summation terms, which are usually simpler when taking derivatives.",
    "crumbs": [
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>Appendix: Exponents & Logarithms</span>"
    ]
  },
  {
    "objectID": "A07.html",
    "href": "A07.html",
    "title": "99  Appendix: The Law of Large Numbers",
    "section": "",
    "text": "99.1 Law of large numbers\nSuppose we observe data D=\\{x_1, \\ldots, x_n\\} with each x_i \\sim F .\nBy the strong law of large numbers the empirical distribution \\hat{F}_n based on data D=\\{x_1, \\ldots, x_n\\} converges to the true underlying distribution F as n \\rightarrow \\infty almost surely:\n\\hat{F}_n\\overset{a. s.}{\\to} F\nThe Glivenko–Cantelli asserts that the convergence is uniform. Since the strong law implies the weak law we also have convergence in probability:\n\\hat{F}_n\\overset{P}{\\to} F\nCorrespondingly, for n \\rightarrow \\infty the average \\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{i=1}^n h(x_i) converges to the expectation \\text{E}_{F}(h(x)) .",
    "crumbs": [
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Appendix: The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "A08.html",
    "href": "A08.html",
    "title": "100  Appendix: The Central Limit Theorem",
    "section": "",
    "text": "100.1 Central Limit Theorem\nThe Central Limit Theorem is one of the most important results in statistics, stating that with sufficiently large sample sizes, the sample average approximately follows a normal distribution. This underscores the importance of the normal distribution, as well as most of the methods commonly used which make assumptions about the data being normally distributed.\nLet’s first stop and think about what it means for the sample average to have a distribution. Imagine going to the store and buying a bag of your favorite brand of chocolate chip cookies. Suppose the bag has 24 cookies in it. Will each cookie have the exact same number of chocolate chips in it? It turns out that if you make a batch of cookies by adding chips to dough and mixing it really well, then putting the same amount of dough onto a baking sheet, the number of chips per cookie closely follows a Poisson distribution. (In the limiting case of chips having zero volume, this is exactly a Poisson process.) Thus we expect there to be a lot of variability in the number of chips per cookie. We can model the number of chips per cookie with a Poisson distribution. We can also compute the average number of chips per cookie in the bag. For the bag we have, that will be a particular number. But there may be more bags of cookies in the store. Will each of those bags have the same average number of chips? If all of the cookies in the store are from the same industrial-sized batch, each cookie will individually have a Poisson number of chips. So the average number of chips in one bag may be different from the average number of chips in another bag. Thus we could hypothetically find out the average number of chips for each bag in the store. And we could think about what the distribution of these averages is, across the bags in the store, or all the bags of cookies in the world. It is this distribution of averages that the central limit theorem says is approximately a normal distribution, with the same mean as the distribution for the individual cookies, but with a standard deviation that is divided by the square root of the number of samples in each average (i.e., the number of cookies per bag).",
    "crumbs": [
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Appendix: The Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "A08.html#sec-cl-theorem",
    "href": "A08.html#sec-cl-theorem",
    "title": "100  Appendix: The Central Limit Theorem",
    "section": "",
    "text": "Theorem 100.1 (Central Limit Theorem) Let X_1, ..., X_n be independent and identically distributed (IID) with \\mathbb{E}(X_i) = \\mu and Var(X_i) = \\sigma^2 &lt;\\infty\nThen:\n\n\\lim_{n\\to\\infty} \\sqrt{n} \\sum_{i=0}^{n} \\frac{1}{n}\\frac{(X_i-\\mu)}{\\sigma} = \\sum_{i=0}^{n} \\frac{X_i-\\mu}{\\sqrt{n} \\sigma} = N(0, 1)\n\nThat is, \\hat{X_n} is approximately normally distributed with mean µ and variance \\frac{\\sigma}{2/n} or standard deviation \\frac{\\sigma}{\\sqrt{n}}.",
    "crumbs": [
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Appendix: The Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "A09.html",
    "href": "A09.html",
    "title": "101  Appendix: Conjugate Priors",
    "section": "",
    "text": "101.1 Conjugate Priors",
    "crumbs": [
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Appendix: Conjugate Priors</span>"
    ]
  },
  {
    "objectID": "A09.html#sec-conjugate-priors",
    "href": "A09.html#sec-conjugate-priors",
    "title": "101  Appendix: Conjugate Priors",
    "section": "",
    "text": "Table 101.1: Conjugate prior\n\n\n\n\n\n\n\n\n\n\n\nLikelihood\nConjugate prior\nPosterior\nPosterior predictive\n\n\n\n\n\\text{Bernoulli}(p)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle \\text{Beta}\\left( \\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +n-\\sum _{i=1}^{n}x_{i}\\right)}\n{\\displaystyle \\mathbb{P}r({\\tilde {x}}=1)={\\frac {\\alpha '}{\\alpha '+\\beta '}}}\n\n\n\\text{Binomial}(trials=m,p)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle \\text{Beta}\\left(\\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +\\sum _{i=1}^{n}N_{i}-\\sum _{i=1}^{n}x_{i}\\right)}\n{\\displaystyle \\operatorname {BetaBin} ({\\tilde {x}}|\\alpha ',\\beta ')}\n\n\n\\text{NegBinomial}(fails=r)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle \\text{Beta}\\left( \\alpha +rn,\\beta + \\sum _{i=1}^{n} x_{i}\\right)}\n{\\displaystyle \\operatorname {BetaNegBin} ({\\tilde {x}}|\\alpha ',\\beta ')}\n\n\n\\text{Poisson}(rate=\\lambda)\n\\text{Gamma}(k,\\theta)\n{\\displaystyle \\text{Gamma}\\left( k+\\sum _{i=1}^{n}x_{i},\\ {\\frac {\\theta }{n\\theta +1}}\\!\\right)}\n{\\displaystyle \\operatorname {NB} \\left({\\tilde {x}}\\mid k',{\\frac {1}{\\theta '+1}}\\right)}\n\n\n\\text{Poisson}(rate=\\lambda)\n\\text{Gamma}(\\alpha,\\beta)\n{\\displaystyle\\text{Gamma}\\left( \\alpha +\\sum _{i=1}^{n}x_{i},\\ \\beta +n\\!\\right)}\n{\\displaystyle \\operatorname {NB} \\left({\\tilde {x}}\\mid \\alpha ',{\\frac {\\beta '}{1+\\beta '}}\\right)}\n\n\n\\text{Categorical}(probs=p,cats=k)\n\\text{Dir}(\\alpha_k)\\mathbb{I}_{k\\ge1}\n{\\displaystyle \\text{Dir}\\left({ {\\boldsymbol {\\alpha }}+(c_{1},\\ldots ,c_{k})}\\right)}\n{\\displaystyle {\\begin{aligned}\\mathbb{P}r({\\tilde {x}}=i)&={\\frac {{\\alpha _{i}}'}{\\sum _{i}{\\alpha _{i}}'}}\\\\&={\\frac {\\alpha _{i}+c_{i}}{\\sum _{i}\\alpha _{i}+n}}\\end{aligned}}}\n\n\n\\text{Multinomial}(probs=p,cats=k)\n\\text{Dir}(\\alpha_k)\\mathbb{I}_{k\\ge1}\n{\\displaystyle \\text{Dir}\\left({ {\\boldsymbol {\\alpha }}+\\sum _{i=1}^{n}\\mathbf {x} _{i}\\!}\\right)}\n{\\displaystyle \\operatorname {DirMult} ({\\tilde {\\mathbf {x} }}\\mid {\\boldsymbol {\\alpha }}')}\n\n\n\\text{Hypergeometric}(pop=n)\n\\text{BetaBinomial}(\\alpha,\\beta,n=N)\n{\\displaystyle \\text{BetaBinomial}\\left({\\displaystyle \\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +\\sum _{i=1}^{n}N_{i}-\\sum _{i=1}^{n}x_{i}}\\right)}\n\n\n\n\\text{Geometric}(p)\n\\text{Beta}(\\alpha,\\beta)\n{\\displaystyle\\text{Beta}\\left( \\alpha +n,\\,\\beta +\\sum _{i=1}^{n}x_{i}\\right)}",
    "crumbs": [
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Appendix: Conjugate Priors</span>"
    ]
  },
  {
    "objectID": "A10.html",
    "href": "A10.html",
    "title": "102  Appendix: Link Function",
    "section": "",
    "text": "102.1 Link function\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\nThe link function provides the relationship between the linear predictor and the mean of the distribution function. There are many commonly used link functions, and their choice is informed by several considerations. There is always a well-defined canonical link function which is derived from the exponential of the response’s density function. However, in some cases, it makes sense to try to match the domain of the link function to the range of the distribution function’s mean, or use a non-canonical link function for algorithmic purposes, for example Bayesian probit regression.\nWhen using a distribution function with a canonical parameter \\theta , the canonical link function is the function that expresses \\theta in terms of \\mu i.e. \\theta =b(\\mu) . For the most common distributions, the mean μ is one of the parameters in the standard form of the distribution’s Density function, and then b(\\mu ) is the function as defined above that maps the density function into its canonical form. When using the canonical link function, b(\\mu )=\\theta =\\mathbf {X} {\\boldsymbol {\\beta }} , which allows \\mathbf{X}^{T}\\mathbf{Y} to be a sufficient statistic for \\beta .\nFollowing is a table of several exponential-family distributions in common use and the data they are typically used for, along with the canonical link functions and their inverses (sometimes referred to as the mean function, as done here).\nIn the cases of the exponential and gamma distributions, the domain of the canonical link function is not the same as the permitted range of the mean. In particular, the linear predictor may be positive, which would give an impossible negative mean. When maximizing the likelihood, precautions must be taken to avoid this. An alternative is to use a non-canonical link function.\nIn the case of the Bernoulli, binomial, categorical and multinomial distributions, the support of the distributions is not the same type of data as the parameter being predicted. In all of these cases, the predicted parameter is one or more probabilities, i.e. real numbers in the range [0,1]. The resulting model is known as Logistic regression (or Multinomial logistic regression in the case that K-way rather than binary values are being predicted).\nFor the Bernoulli and binomial distributions, the parameter is a single probability, indicating the likelihood of occurrence of a single event. The Bernoulli still satisfies the basic condition of the generalized linear model in that, even though a single outcome will always be either 0 or 1, the expected value will nonetheless be a real-valued probability, i.e. the probability of occurrence of a “yes” (or 1) outcome. Similarly, in a binomial distribution, the expected value is Np, i.e. the expected proportion of “yes” outcomes will be the probability to be predicted.\nFor categorical and multinomial distributions, the parameter to be predicted is a K-vector of probabilities, with the further restriction that all probabilities must add up to 1. Each probability indicates the likelihood of occurrence of one of the K possible values. For the multinomial distribution, and for the vector form of the categorical distribution, the expected values of the elements of the vector can be related to the predicted probabilities similarly to the binomial and Bernoulli distributions.",
    "crumbs": [
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Appendix: Link Function</span>"
    ]
  },
  {
    "objectID": "A10.html#sec-link-function",
    "href": "A10.html#sec-link-function",
    "title": "102  Appendix: Link Function",
    "section": "",
    "text": "Common distributions with typical uses and canonical link functions\n\n\n\n\n\n\n\n\n\n\nDistribution\nSupport\nUses\nLink name\nLink fn\nMean fn\n\n\n\n\nNormal\n\\mathbb{R}\n\nIdentity\n\\mathbf {X} {\\boldsymbol {\\beta }}=\\mu\n\n\n\nExpoential\n\\mathbb{R}^+_0\n\nNegative inverse\n\\mathbf {X} {\\boldsymbol {\\beta }}=-\\mu^{-1}\n\n\n\nGamma\n\\mathbb{R}^+_0\n\nNegative inverse\n\\mathbf {X} {\\boldsymbol {\\beta }}=-\\mu^{-1}\n\n\n\nInverse Gamma\n\\mathbb{R}^+_0\n\nInverse squared\n\\mathbf {X} {\\boldsymbol {\\beta }}=\\mu^{-2}\n\n\n\nPoisson\n\\mathbb{N}_0\n\nLog\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\mu)\n\n\n\nBernuolli\n\\{0,1\\}\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{1-\\mu})\n\n\n\nBinomial\n\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{n-\\mu})\n\n\n\nCategorical\n\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{1-\\mu})\n\n\n\nMultinomial\n\n\nLogit\n\\mathbf {X} {\\boldsymbol {\\beta }}=ln(\\frac{\\mu}{1-\\mu})",
    "crumbs": [
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Appendix: Link Function</span>"
    ]
  },
  {
    "objectID": "A10.html#credits",
    "href": "A10.html#credits",
    "title": "102  Appendix: Link Function",
    "section": "Credits:",
    "text": "Credits:\nThis page is based on the Generalized linear model article on Wikipedia, which is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License. By Wikimedia contributors, available under CC BY-SA 3.0.\nThe text has been modified for clarity and conciseness.",
    "crumbs": [
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Appendix: Link Function</span>"
    ]
  },
  {
    "objectID": "A11.html",
    "href": "A11.html",
    "title": "103  Bayes by backprop",
    "section": "",
    "text": "103.1 Introduction\nThis appendix reviews of a method to introduce weight uncertainty into neural networks called the “Bayes by Backprop” method introduced in (Blundell et al. 2015). where, the main question is how to determine the parameters of the distribution for each network weight. I learned about it from Probabilistic Deep Learning with TensorFlow 2 by Dr Kevin Webster, S reading from based this on\nThe authors note that prior work which considered uncertainty at the hidden unit (H_i) an approach that allows to state the uncertainty with respect to a particular observation and which is an easier problem since the number of weight is greater by two orders of magnitude. But considering the uncertainty in the weights is complementary, in the sense that it captures uncertainty about which neural network is appropriate, leading to regularization of the weights and model averaging. This weight uncertainty can be used to drive the exploration/exploitation in contextual bandit problems using Thompson sampling . Weights with greater uncertainty introduce more variability into the decisions made by the network, naturally leading to exploration. As more data are observed, the uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the environment is better understood.\nIn a traditional neural network, as shown in the upper left, each weight has a single value. But in the true value for these weights is not certain. Much of this uncertainty comes from imperfect training data, which is an approximation of the the distribution of the data generating process from which the data were sampled. Recall that this is called epistemic uncertainty, which we expect to decrease as the amount of training data increases.\nIn this method, we want to include such uncertainty in deep learning models. This is done by changing each weight from a single deterministic value to a probability distribution. We then learn the parameters of this distribution. Consider a neural network weight w_i . In a standard (deterministic) neural network, this has a single value \\hat{w}_i , learnt via backpropagation. In a neural network with weight uncertainty, each weight is represented by a probability distribution, and the parameters of this distribution are learned via backpropagation. Suppose, for example, that each weight has a normal distribution. This has two parameters: a mean \\mu_i and a standard deviation \\sigma_i .\nSince the weights are uncertain, the feedforward value of some input x_i is not constant. A single feedforward value is determined in two steps: 1. Sample each network weight from their respective distributions – this gives a single set of network weights. 2. Use these weights to determine a feedforward value \\hat{y}_i .\nHence, the key question is how to determine the parameters of the distribution for each network weight. The paper introduces exactly such a scheme, called Bayes by Backprop.",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#introduction",
    "href": "A11.html#introduction",
    "title": "103  Bayes by backprop",
    "section": "",
    "text": "Fig. 1 from (Blundell et al. 2015) contrasting traditional and Bayesian neural networks\n\n\n\n\n\nClassic deterministic NN: w_i = \\hat{w}_i\nNN with weight uncertainty represented by normal distribution: w_i \\sim N(\\hat{\\mu}_i, \\hat{\\sigma}_i) .",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#bayesian-learning",
    "href": "A11.html#bayesian-learning",
    "title": "103  Bayes by backprop",
    "section": "103.2 Bayesian learning",
    "text": "103.2 Bayesian learning\nNote: We use the notation P to refer to a probability density. For simplicity, we’ll only consider continuous distributions (which have a density). In the case of discrete distributions, P would represent a probability mass and integrals should be changed to sums. However, the formulae are the same.\nWhat you need to know now is that Bayesian methods can be used to calculate the distribution of a model parameter given some data. In the context of weight uncertainty in neural networks, this is convenient, since we are looking for the distribution of weights (model parameters) given some (training) data. The key step relies on Bayes’ theorem. This theorem states, in mathematical notation, that\n\n\\mathbb{P}r(w \\mid D) = \\frac{\\mathbb{P}r(D \\mid w) \\mathbb{P}r(w)}{\\int \\mathbb{P}r(D \\mid w') \\mathbb{P}r(w') \\text{d}w'}\n\nwhere the terms mean the following:\n\nD is some data, e.g. x and y value pairs: D = \\{(x_1, y_1), \\ldots, (x_n, y_n)\\} . This is sometimes called the evidence.\nw is the value of a model weight.\n\\mathbb{P}r(w) is called the prior. This is our “prior” belief on the probability density of a model weight, i.e. the distribution that we postulate before seeing any data.\n\\mathbb{P}r(D \\mid w) is the likelihood of having observed data D given weight w . It is precisely the same likelihood used to calculate the negative log-likelihood.\n\\mathbb{P}r(w \\mid D) is the posterior density of the distribution of the model weight at value w , given our training data. It is called posterior since it represents the distribution of our model weight after taking the training data into account.\n\nNote that the term {\\int \\mathbb{P}r(D \\mid w') \\mathbb{P}r(w') \\text{d}w'} = \\mathbb{P}r(D) does not depend on w (as the w' is an integration variable). It is only a normalization term. For this reason, we will from this point on write Bayes’ theorem as\n\n\\mathbb{P}r(w \\mid D) = \\frac{\\mathbb{P}r(D \\mid w) \\mathbb{P}r(w)}{\\mathbb{P}r(D)}.\n\nBayes’ theorem gives us a way of combining data with some “prior belief” on model parameters to obtain a distribution for these model parameters that considers the data, called the posterior distribution.",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#bayesian-neural-network-with-weight-uncertainty-in-principle",
    "href": "A11.html#bayesian-neural-network-with-weight-uncertainty-in-principle",
    "title": "103  Bayes by backprop",
    "section": "103.3 Bayesian neural network with weight uncertainty – in principle",
    "text": "103.3 Bayesian neural network with weight uncertainty – in principle\nThe above formula gives a way to determine the distribution of each weight in the neural network:\n\nPick a prior density \\mathbb{P}r(w) .\nUsing training data D , determine the likelihood \\mathbb{P}r(D \\mid w) .\nDetermine the posterior density \\mathbb{P}r(w \\mid D) using Bayes’ theorem.\n\nThis is the distribution of the NN weight.\nWhile this works in principle, in many practical settings it is difficult to implement. The main reason is that the normalization constant {\\int \\mathbb{P}r(D \\mid w') \\mathbb{P}r(w') \\text{d}w'} = \\mathbb{P}r(D) may be very difficult to calculate, as it involves solving or approximating a complicated integral. For this reason, approximate methods, such as Variational Bayes described below, are often employed.",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#variational-bayes",
    "href": "A11.html#variational-bayes",
    "title": "103  Bayes by backprop",
    "section": "103.4 Variational Bayes",
    "text": "103.4 Variational Bayes\nVariational Bayes methods approximate the posterior distribution with a second function, called a variational posterior. This function has a known functional form, and hence avoids the need to determine the posterior \\mathbb{P}r(w \\mid D) exactly. Of course, approximating a function with another one has some risks, since the approximation may be very bad, leading to a posterior that is highly inaccurate. In order to mediate this, the variational posterior usually has a number of parameters, denoted by \\theta , that are tuned so that the function approximates the posterior as well as possible. Let’s see how this works below.\nInstead of \\mathbb{P}r(w \\mid D) , we assume the network weight has density q(w \\mid \\theta) , parameterized by \\theta . q(w \\mid \\theta) is known as the variational posterior . We want q(w \\mid \\theta) to approximate \\mathbb{P}r(w \\mid D) , so we want the “difference” between q(w \\mid \\theta) and \\mathbb{P}r(w \\mid D) to be as small as possible. This “difference” between the two distributions is measured by the Kullback-Leibler divergence D_{\\text{KL}} (note that this is unrelated to the D we use to denote the data). The Kullback-Leibler divergence between two distributions with densities f(x) and g(x) respectively is defined as\n\nD_{KL} (f(x) \\parallel g(x)) = \\int f(x) \\log \\left( \\frac{f(x)}{g(x)} \\right) \\text{d} x\n\nNote that this function has value 0 (indicating no difference) when f(x) \\equiv g(x) , which is the result we expect. We use the convention that \\frac{0}{0} = 1 here.\nViewing the data D as a constant, the Kullback-Leibler divergence between q(w \\mid \\theta) and \\mathbb{P}r(w \\mid D) is hence:\n\n\\begin{aligned}\n  D_{KL} (q(w \\mid \\theta) \\parallel \\mathbb{P}r(w \\mid D)) &= \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta)}{\\mathbb{P}r(w \\mid D)} \\right) \\text{d} w \\\\\n&= \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta) \\mathbb{P}r(D)}{\\mathbb{P}r(D \\mid w) \\mathbb{P}r(w)} \\right) \\text{d} w \\\\\n&= \\int q(w \\mid \\theta) \\log \\mathbb{P}r(D) \\text{d} w + \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta)}{\\mathbb{P}r(w)} \\right) \\text{d} w - \\int q(w \\mid \\theta) \\log \\mathbb{P}r(D \\mid w) \\text{d} w \\\\\n&= \\log \\mathbb{P}r(D) + D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w))\n\\end{aligned}\n\nwhere, in the last line, we have used\n\n\\int q(w \\mid \\theta) \\log \\mathbb{P}r(D) \\text{d}w = \\log \\mathbb{P}r(D) \\int q(w \\mid \\theta) \\text{d} w = \\log \\mathbb{P}r(D)\n\nsince q(w \\mid \\theta) is a probability distribution and hence integrates to 1. If we consider the data D to be constant, the first term is a constant also, and we may ignore it when minimizing the above. Hence, we are left with the function\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w))\n\\end{aligned}\n\nNote that this function depends only on \\theta and D , since w is an integration variable. This function has a nice interpretation as the sum of: - The Kullback-Leibler divergence between the variational posterior q(w \\mid \\theta) and the prior \\mathbb{P}r(w) . This is called the complexity cost, and it depends on \\theta and the prior but not the data D . - The expectation of the negative log likelihood \\log \\mathbb{P}r(D \\mid w) under the variational posterior q(w \\mid \\theta) . This is called the likelihood cost and it depends on \\theta and the data but not the prior.\nL(\\theta \\mid D) is the loss function that we minimize to determine the parameter \\theta . Note also from the above derivation, that we have\n\n\\begin{aligned}\n\\log \\mathbb{P}r(D) &= \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) - D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) + D_{KL} (q(w \\mid \\theta) \\parallel \\mathbb{P}r(w \\mid D))\\\\\n&\\ge \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) - D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) =: ELBO\n\\end{aligned}\n\nwhich follows because D_{KL} (q(w \\mid \\theta) \\parallel \\mathbb{P}r(w \\mid D)) is non negative. The final expression on the right hand side is therefore a lower bound on the log-evidence, and is called the evidence lower bound, often shortened to ELBO. The {ELBO} is the negative of our loss function, so minimizing the loss function is equivalent to maximizing the ELBO.\nMaximizing the ELBO requires a trade off between the KL term and expected log-likelihood term. On the one hand, the divergence between q(w \\mid \\theta) and \\mathbb{P}r(w) should be kept small, meaning the variational posterior shouldn’t be too different to the prior. On the other, the variational posterior parameters should maximize the expectation of the log-likelihood \\log \\mathbb{P}r(D \\mid w) , meaning the model assigns a high likelihood to the data.",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A11.html#a-backpropagation-scheme",
    "href": "A11.html#a-backpropagation-scheme",
    "title": "103  Bayes by backprop",
    "section": "103.5 A backpropagation scheme",
    "text": "103.5 A backpropagation scheme\n\n103.5.1 The idea\nWe can use the above ideas to create a neural network with weight uncertainty, which we will call a Bayesian neural network. From a high level, this works as follows. Suppose we want to determine the distribution of a particular neural network weight w .\n\nAssign the weight a prior distribution with density \\mathbb{P}r(w) , which represents our beliefs on the possible values of this network before any training data. This may be something simple, like a unit Gaussian. Furthermore, this prior distribution will usually not have any trainable parameters.\nAssign the weight a variational posterior with density q(w \\mid \\theta) with some trainable parameter \\theta .\nq(w \\mid \\theta) is the approximation for the weight’s posterior distribution. Tune \\theta to make this approximation as accurate as possible as measured by the ELBO.\n\nThe remaining question is then how to determine \\theta . Recall that neural networks are typically trained via a backpropagation algorithm, in which the weights are updated by perturbing them in a direction that reduces the loss function. We aim to do the same here, by updating \\theta in a direction that reduces L(\\theta \\mid D) .\nHence, the function we want to minimise is\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) \\\\\n&= \\int q(w \\mid \\theta) ( \\log q(w \\mid \\theta) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w) ) \\text{d}w.\n\\end{aligned}\n\nIn principle, we could take derivatives of L(\\theta \\mid D) with respect to \\theta and use this to update its value. However, this involves doing an integral over w , and this is a calculation that may be impossible or very computationally expensive. Instead, we want to write this function as an expectation and use a Monte Carlo approximation to calculate derivatives. At present, we can write this function as\n\nL(\\theta \\mid D) = \\mathbb{E}_{q(w \\mid \\theta)} ( \\log q(w \\mid \\theta) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w) )\n\nHowever, taking derivatives with respect to \\theta is difficult because the underlying distribution the expectation is taken with respect to depends on \\theta . One way we can handle this is with the reparameterization trick.\n\n\n103.5.2 The reparameterization trick\nThe reparameterization trick is a way to move the dependence on \\theta around so that an expectation may be taken independently of it. It’s easiest to see how this works with an example. Suppose q(w \\mid \\theta) is a Gaussian, so that \\theta = (\\mu, \\sigma) . Then, for some arbitrary f(w; \\mu, \\sigma) , we have\n\n\\begin{aligned}\n\\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\int q(w \\mid \\mu, \\sigma) f(w; \\mu, \\sigma) \\text{d}w \\\\\n&= \\int \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( -\\frac{1}{2 \\sigma^2} (w - \\mu)^2 \\right) f(w; \\mu, \\sigma) \\text{d}w \\\\\n&= \\int \\frac{1}{\\sqrt{2 \\pi}} \\exp \\left( -\\frac{1}{2} \\epsilon^2 \\right) f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right) \\text{d}\\epsilon \\\\\n&= \\mathbb{E}_{\\epsilon \\sim N(0, 1)} (f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right) )\n\\end{aligned}\n\nwhere we used the change of variable w = \\mu + \\sigma \\epsilon . Note that the dependence on \\theta = (\\mu, \\sigma) is now only in the integrand and we can take derivatives with respect to \\mu and \\sigma:\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\mu} \\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\frac{\\partial}{\\partial \\mu} \\mathbb{E}_{\\epsilon \\sim N(0, 1)} (f \\left( w; \\mu, \\sigma \\right) ) = \\mathbb{E}_{\\epsilon \\sim N(0, 1)} \\frac{\\partial}{\\partial \\mu} f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right)\n\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\sigma} \\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\frac{\\partial}{\\partial \\sigma} \\mathbb{E}_{\\epsilon \\sim N(0, 1)} (f \\left( w; \\mu, \\sigma \\right) ) = \\mathbb{E}_{\\epsilon \\sim N(0, 1)} \\frac{\\partial}{\\partial \\sigma} f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right)\n\\end{aligned}\n\nFinally, note that we can approximate the expectation by its Monte Carlo estimate:\n\n\\begin{aligned}\n\\mathbb{E}_{\\epsilon \\sim N(0, 1)}  \\frac{\\partial}{\\partial \\theta} f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right) \\approx \\sum_{i}  \\frac{\\partial}{\\partial \\theta} f \\left( \\mu + \\sigma \\epsilon_i; \\mu, \\sigma \\right),\\qquad \\epsilon_i \\sim N(0, 1).\n\\end{aligned}\n\nThe above reparameterization trick works in cases where we can write the w = g(\\epsilon, \\theta) , where the distribution of the random variable \\epsilon is independent of \\theta .\n\n\n103.5.3 Implementation\nPutting this all together, for our loss function L(\\theta \\mid D) \\equiv L(\\mu, \\sigma \\mid D) , we have\n\nf(w; \\mu, \\sigma) = \\log q(w \\mid \\mu, \\sigma) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w)\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\mu} L(\\mu, \\sigma \\mid D) \\approx \\sum_{i} \\left( \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\mu} \\right)\n\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\sigma} L(\\mu, \\sigma \\mid D) \\approx \\sum_{i} \\left( \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} \\epsilon_i + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\sigma} \\right)\n\\end{aligned}\n\n\nf(w; \\mu, \\sigma) = \\log q(w \\mid \\mu, \\sigma) - \\log \\mathbb{P}r(D \\mid w) - \\log \\mathbb{P}r(w)\n\nwhere w_i = \\mu + \\sigma \\epsilon_i, \\, \\epsilon_i \\sim N(0, 1) . In practice, we often only take a single sample \\epsilon_1 for each training point. This leads to the following backpropagation scheme:\n\nSample \\epsilon_i \\sim N(0, 1) . 2. Let w_i = \\mu + \\sigma \\epsilon_i\nCalculate\n\n\n\\nabla_{\\mu}f = \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\mu} \\hspace{3em} \\nabla_{\\sigma}f = \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} \\epsilon_i + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\sigma}\n\n\nUpdate the parameters with some gradient-based optimizer using the above gradients.\n\nThis is how we learn the parameters of the distribution for each neural network weight.\n\n\n103.5.4 Minibatches\nNote that the loss function (or negative of the ELBO) is\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log \\mathbb{P}r(D \\mid w)) \\\\\n& = D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\sum_{j=1}^N \\log \\mathbb{P}r(y_j, x_j \\mid w_j)\n\\end{aligned}\n\nwhere j runs over all the data points in the training data (N in total) and w_j = \\mu + \\sigma \\epsilon_j is sampled using \\epsilon_j \\sim N(0, 1) (we assume a single sample from the approximate posterior per data point for simplicity).\nIf training occurs in minibatches of size B , typically much smaller than N , we instead have a loss function\n\n\\begin{aligned}\nD_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\sum_{j=1}^{B} \\log \\mathbb{P}r(y_j, x_j \\mid w_j).\n\\end{aligned}\n\nNote that the scaling factors between the first and second terms have changed, since before the sum ran from 1 to N , but it now runs from 1 to B . To correct for this, we should add a correction factor \\frac{N}{B} to the second term to ensure that its expectation is the same as before. This leads to the loss function, after dividing by N to take the average per training value, of\n\n\\begin{aligned}\n\\frac{1}{N} D_{KL} ( q(w \\mid \\theta) \\parallel \\mathbb{P}r(w) ) - \\frac{1}{B} \\sum_{j=1}^{B} \\log \\mathbb{P}r(y_j, x_j \\mid w_j).\n\\end{aligned}\n\nBy default, when Tensorflow calculates the loss function, it calculates the average across the minibatch. Hence, it already uses the factor \\frac{1}{B} present on the second term. However, it does not, by default, divide the first term by N . In an implementation, we will have to specify this. You’ll see in the next lectures and coding tutorials how to do this.\n\n\n103.5.5 Conclusion\nWe introduced the Bayes by Backpropagation method, which can be used to embed weight uncertainty into neural networks. Good job getting through it, as the topic is rather advanced. This approach allows the modelling of epistemic uncertainty on the model weights. We expect that, as the number of training points increases, the uncertainty on the model weights decreases. This can be shown to be the case in many settings. In the next few lectures and coding tutorials, you’ll learn how to apply these methods to your own models, which will make the idea much clearer.\n\n\n103.5.6 Further reading and resources\n\nBayes by backprop paper (Blundell et al. 2015)\nWikipedia article on Bayesian inference\n\n\n\n\n\n\n\nBlundell, Charles, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015. “Weight Uncertainty in Neural Networks.” https://doi.org/10.48550/ARXIV.1505.05424.",
    "crumbs": [
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Bayes by backprop</span>"
    ]
  },
  {
    "objectID": "A12.html",
    "href": "A12.html",
    "title": "104  Bayesian Books in R & Python",
    "section": "",
    "text": "104.1 Introduction to Probability\nThere are many books in R and Python that can help you learn more about these languages and how to use them for data analysis.\nHere are some of the most popular books on R and Python:",
    "crumbs": [
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#introduction-to-probability",
    "href": "A12.html#introduction-to-probability",
    "title": "104  Bayesian Books in R & Python",
    "section": "",
    "text": "Introduction to Probability by Dennis L. Sun",
    "crumbs": [
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#sec-bayesian-books",
    "href": "A12.html#sec-bayesian-books",
    "title": "104  Bayesian Books in R & Python",
    "section": "104.2 Books in R",
    "text": "104.2 Books in R\n\nR for Data Science by Hadley Wickham & Garrett Grolemund\nAdvanced R by Hadley Wickham\nggplot2: Elegant Graphics for Data Analysis (3e)\nR Graphics Cookbook, 2nd edition\nAn Introduction to Statistical Learning\nEngineering Production-Grade Shiny Apps\nForecasting: Principles and Practice (3rd ed)\nExploratory Data Analysis with R Roger D. Peng\nModern R with the tidyverse by Bruno Rodrigues\nModern Statistics with R by Benjamin S. Baumer, Daniel T. Kaplan, and Nicholas J. Horton\nMastering Shiny by Hadley Wickham, Winston Chang, and Joe Cheng\nLearning Statistics with R by Danielle Navarro\nText Mining with R by Julia Silge and David Robinson",
    "crumbs": [
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "A12.html#books-in-python",
    "href": "A12.html#books-in-python",
    "title": "104  Bayesian Books in R & Python",
    "section": "104.3 Books in Python",
    "text": "104.3 Books in Python\n\nAn Introduction to Statistical Learning with python by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\nPython for Data Analysis by Wes McKinney of Pandas infamy parquet and Apache Arrow\nPython Data Science Handbook by Jake VanderPlas\nThink Stats by Allen B. Downey\nThink Bayes by Allen B. Downey\nProbabilistic Programming & Bayesian Methods for Hackers by Cameron Davidson-Pilon",
    "crumbs": [
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Bayesian Books in R & Python</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "105  Summary",
    "section": "",
    "text": "In summary, this Specialization we covered a wide array of Bayesian methods.",
    "crumbs": [
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]