[
  {
    "objectID": "C2-L10.html",
    "href": "C2-L10.html",
    "title": "Poisson regression",
    "section": "",
    "text": "Poisson regression is the preferred method to handle count data where the response is positive values but includes zeroes. The gist of this method is that We use a log transform link function on the regressors but not on the response which allows the response to be zero valued which correspond to zero counts. One limit of this approach mentioned below is that the Poisson takes one parameter \\lambda for both its expected value and its variance. We look give a deeper solution to this problem in the next course on mixture models, however in this course we will consider more restricted cases where we extend the Poisson regression with the Negative Binomial Distribution which allows us to model over-dispersed data.",
    "crumbs": [
      "2. Techniques and Models",
      "Poisson regression"
    ]
  },
  {
    "objectID": "C2-L10.html#sec-introduction-to-poisson-regression",
    "href": "C2-L10.html#sec-introduction-to-poisson-regression",
    "title": "Poisson regression",
    "section": "1 Introduction to Poisson regression",
    "text": "1 Introduction to Poisson regression\n\n\n\n\n\n\n\nFigure 1: Introduction to Poisson regression\n\n\nWe now have experience fitting regression models when the response is continuous, and when it is binary. What about when we have count data? We could fit a linear normal regression, but here we have a couple of drawbacks. First of all, counts usually aren’t negative. And the variances might not be constant. The Poisson distribution provides a natural likelihood for count data.\n\ny_i\\mid \\lambda+i \\stackrel {iid} \\sim \\mathrm{Pois}(\\lambda_i) \\qquad i=1, \\ldots, n\n\nHere, \\lambda conveniently represents the expected value of y \\mathbb{E}[y]. It turns out that \\lambda is also the variance of y \\mathbb{V}ar[y]. So if we expect a count to be higher, we also expect the variability in counts to go up.\nWe saw this earlier with the warp breaks data.\nIf we model the mean directly, like we did with linear regression. That is, we had the expected value yi was directly modeled with this linear form.\n\n\\mathbb{E}[y]=\\beta_0 + \\beta_1x_i \\qquad \\text{(linear regression)}\n\nWe would run into the same problem we did with logistic regression. The expected value has to be greater than zero in the Poisson distribution. To naturally deal with that restriction, we’re going to use the logarithmic link function.\nSo, the log link. That is, that the log of \\lambda_i is equal to this linear piece.\nlog link:\n\nlog(\\lambda_i) = \\beta_0+\\beta_1x_i \\qquad \\text{(log link)}\n\\tag{1}\n\n\\mathbb{E}[y]=\\beta_0+\\beta_1x_i \\qquad \\text{(linear regression)}\n\nFrom this, we can easily recover the expression for the mean itself. That is, we can invert this link function to get the expected value of y_i,\n\n\\implies \\mathbb{E}[y] = \\lambda_i = e^{\\left(\\beta_0+\\beta_1x_i \\right)}\n\\tag{2}\nIt might seem like this model is equivalent to fitting a normal linear regression to the log of y. But there are a few key differences. In the normal regression, we’re modeling the mean of the response directly. So we would be fitting a model to the \\log(y). Where we’re modeling the expected value of the \\log(y). This is different from what we’re modeling here, here we’re doing the log of the expected value of y.\n\n\\mathbb{E}[log(y)]\\ne log(\\mathbb{E}[y])\n\nThese are not equal, they’re usually similar, but they’re not the same. Another difference is that we have a separate independent parameter for the variants in a normal regression. In Poisson regression, the variance is automatically the same as \\lambda,which may not always be appropriate, as we’ll see in an upcoming example.\nAs usual, we can add more explanatory x variables to the Poisson regression framework. They can be continuous, categorical, or they could be counts themselves.\nIf we have three predictor variables x_i = ( x_{1,i}, x_{2,i}, x_{3,i} ), what would the likelihood part of the hierarchical representation of a Poisson regression with logarithmic link look like?\n\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left( e^{-(\\beta_0+\\beta_1 x_{1,i}+\\beta_2 x_{2,i}+\\beta_3 x_{3,i})}\\right)\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left(\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i} \\right)\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left(e^{\\beta_0 + \\beta_1 x_{1,i}+\\beta_2 x_{2,i}+\\beta_3 x_{3,i}}\\right)\ny_i \\mid x_i, \\beta \\overset{\\text{ind}}{\\sim} \\mathrm{Pois} \\left( \\log[ \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i} ] \\right)\n\nHere we incorporated the (inverse) link function directly into the likelihood rather than writing it with two lines.",
    "crumbs": [
      "2. Techniques and Models",
      "Poisson regression"
    ]
  },
  {
    "objectID": "C2-L10.html#poisson-regression---jags-model",
    "href": "C2-L10.html#poisson-regression---jags-model",
    "title": "Poisson regression",
    "section": "2 Poisson regression - JAGS model",
    "text": "2 Poisson regression - JAGS model\n For an example of Poisson regression, we’ll use the badhealth data set from the COUNT package in R.doctor visits\n\n\nCode\nlibrary(\"COUNT\")\n\n\nLoading required package: msme\n\n\nLoading required package: MASS\n\n\nLoading required package: lattice\n\n\nLoading required package: sandwich\n\n\nCode\ndata(\"badhealth\")\n#?badhealth\nhead(badhealth)\n\n\n  numvisit badh age\n1       30    0  58\n2       20    0  54\n3       16    0  44\n4       20    0  57\n5       15    0  33\n6       15    0  28\n\n\naccording to the description:\n\n\n\n\n\n\nNoteData Card for badhealth\n\n\n\n1,127 observations from a 1998 German survey with 3 variables:\n\nnumvisit - number of visits to the doctor in 1998 (response)\nbadh - \\begin{cases} 1 \\qquad \\text{ patient claims to be in bad health} \\\\ 0 \\qquad \\text{ patient does not claim to be in bad health} \\end{cases}\nage - age of patient\n\n\n\n\n\nCode\nany(is.na(badhealth))\n\n\n[1] FALSE\n\n\n\nremove na\n\nAs usual, let’s visualize these data.\n\n\nCode\nhist(badhealth$numvisit, breaks=20)\n\n\n\n\n\n\n\n\nFigure 2: Histogram of number of doctor visits\n\n\n\n\n\n\n\nCode\nplot(jitter(log(numvisit)) ~ jitter(age), data=badhealth, subset=badh==0, xlab=\"age\", ylab=\"log(visits)\")\npoints(jitter(log(numvisit)) ~ jitter(age), data=badhealth, subset=badh==1, col=\"red\")\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n2.1 Doctor Visits Model\n It appears that both age and bad health are related to the number of doctor visits. We should include model terms for both variables. If we believe the age/visits relationship is different between healthy and non-healthy populations, we should also include an interaction term. We will fit the full model here and leave it to you to compare it with the simpler additive model.doctor visits\n\n\nCode\nlibrary(\"rjags\")\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/1e4)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n    b_intx ~ dnorm(0.0, 1.0/1e4)\n} \"\n\nset.seed(102)\n\ndata_jags = as.list(badhealth)\n\nparams = c(\"int\", \"b_badh\", \"b_age\", \"b_intx\")\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 4\n   Total graph size: 3665\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,  variable.names=params, n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod_sim)\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nb_age        1.01       1.03\nb_badh       1.01       1.05\nb_intx       1.01       1.05\nint          1.01       1.03\n\nMultivariate psrf\n\n1.01\n\n\nCode\nautocorr.diag(mod_sim)\n\n\n           b_age    b_badh    b_intx       int\nLag 0  1.0000000 1.0000000 1.0000000 1.0000000\nLag 1  0.9592776 0.9680917 0.9705949 0.9567349\nLag 5  0.8422200 0.8795245 0.8862814 0.8418455\nLag 10 0.7210438 0.7853174 0.7963564 0.7205695\nLag 50 0.2620261 0.3147533 0.3268107 0.2579339\n\n\nCode\nautocorr.plot(mod_csim)\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod_sim)\n\n\n   b_age   b_badh   b_intx      int \n251.1574 181.3245 163.0702 243.1021 \n\n\nCode\n## compute DIC\ndic = dic.samples(mod, n.iter=1e3)\n\n\n\n\n2.2 Model checking - Residuals\n\n“While inexact models may mislead, attempting to allow for every contingency a priori is impractical. Thus models must be built by an iterative feedback process in which an initial parsimonious model may be modified when diagnostic checks applied to residuals indicate the need.” —G. E. P. Box\n\nTo get a general idea of the model’s performance, we can look at predicted values and residuals as usual. Don’t forget that we must apply the inverse of the link function to get predictions for \\lambda .\n\n\nCode\n1X = as.matrix(badhealth[,-1])\n2X = cbind(X, with(badhealth, badh*age))\nhead(X)\n\n\n\n1\n\nwe drop the first column since it is the column for our y.\n\n2\n\nwe add a third column with \\mathbb{I}_{badh}\\times age\n\n\n\n\n     badh age  \n[1,]    0  58 0\n[2,]    0  54 0\n[3,]    0  44 0\n[4,]    0  57 0\n[5,]    0  33 0\n[6,]    0  28 0\n\n\n\n\nCode\n1(pmed_coef = apply(mod_csim, 2, median))\n\n\n\n1\n\nthis are the column medians of the coefficients.\n\n\n\n\n       b_age       b_badh       b_intx          int \n 0.008520553  1.572654849 -0.010997422  0.346261276 \n\n\n\n\nCode\n1llam_hat = pmed_coef[\"int\"] + X %*% pmed_coef[c(\"b_badh\", \"b_age\", \"b_intx\")]\n2lam_hat = exp(llam_hat)\n\nhist(lam_hat)\n\n\n\n1\n\nX \\cdot \\vec b_i gives the linear part.\n\n2\n\n\\hat\\lambda_i=e^{X \\cdot \\vec b_i} we need to apply the inverse link function\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nresid = badhealth$numvisit - lam_hat\nplot(resid) # the data were ordered\n\n\n\n\n\n\n\n\n\nthis plot looks bad, it might not be iid but we can ignore the issue since the data is presorted/\n\n\nCode\nplot(lam_hat, badhealth$numvisit)\nabline(0.0, 1.0)\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\nCode\nplot(lam_hat[which(badhealth$badh==0)], resid[which(badhealth$badh==0)], xlim=c(0, 8), ylab=\"residuals\", xlab=expression(hat(lambda)), ylim=range(resid))\npoints(lam_hat[which(badhealth$badh==1)], resid[which(badhealth$badh==1)], col=\"red\")\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nIt is not surprising that the variability increases for values predicted at higher values since the mean is also the variance in the Poisson distribution. However, observations predicted to have about two visits should have variance about two, and observations predicted to have about six visits should have variance about six.\n\n\nCode\nvar(resid[which(badhealth$badh==0)])\n\n\n[1] 7.022518\n\n\n\n\nCode\nvar(resid[which(badhealth$badh==1)])\n\n\n[1] 41.1961\n\n\nFor this data the variance is much bigger this is not the case with these data. This indicates that either the model fits poorly (meaning the covariates don’t explain enough of the variability in the data), or the data are “overdispersed” for the Poisson likelihood we have chosen. This is a common issue with count data. If the data are more variable than the Poisson likelihood would suggest, a good alternative is the negative binomial distribution, which we will not pursue here.",
    "crumbs": [
      "2. Techniques and Models",
      "Poisson regression"
    ]
  },
  {
    "objectID": "C2-L10.html#sec-predictive-distributions",
    "href": "C2-L10.html#sec-predictive-distributions",
    "title": "Poisson regression",
    "section": "3 Predictive distributions",
    "text": "3 Predictive distributions\nAssuming the model fit is adequate, we can interpret the results.\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean       SD  Naive SE Time-series SE\nb_age   0.00851 0.002124 1.735e-05      0.0001339\nb_badh  1.57667 0.191172 1.561e-03      0.0143081\nb_intx -0.01111 0.004426 3.613e-05      0.0003485\nint     0.34585 0.082801 6.761e-04      0.0052871\n\n2. Quantiles for each variable:\n\n            2.5%       25%       50%       75%     97.5%\nb_age   0.004404  0.007039  0.008521  0.009950  0.012776\nb_badh  1.205415  1.448986  1.572655  1.700515  1.958368\nb_intx -0.019954 -0.013983 -0.010997 -0.008115 -0.002525\nint     0.178969  0.290351  0.346261  0.403344  0.503312\n\n\nThe intercept is not necessarily interpretable here because it corresponds to the number of doctor visits for a healthy 0-year-old. While the number of visits for a newborn baby sounds like interesting information, the youngest person in the data set is 20 years old. In such cases we should avoid making such projections and say that the intercept is an artifact of the model.\n\nFor healthy individuals, it appears that age is associated with an increase in the Expected number of doctor visits.\nBad health is associated with an increase in expected number of visits.\nThe interaction coefficient is interpreted as an adjustment to the age coefficient for people in bad health. Hence, for people with bad health, age is essentially unassociated with number of visits.\n\n\n3.1 Predictive distributions\nLet’s say we have two people aged 35, one in good health and the other in poor health. Q. What is the posterior probability that the individual with poor health will have more doctor visits?\nThis goes beyond the posterior probabilities we have calculated comparing expected responses in previous lessons. Here we will create Monte Carlo samples for the responses themselves. This is done by taking the Monte Carlo samples of the model parameters, and for each of those, drawing a sample from the likelihood.\nLet’s walk through this.\nFirst, we need the x values for each individual. We’ll say the healthy one is Person 1 and the unhealthy one is Person 2. Their x values are:\n\n\nCode\n1x1 = c(0, 35, 0)\n2x2 = c(1, 35, 35)\n\n\n\n1\n\ngood health person’s data (bad_health_indicator=0,age=35,age*indicator=0)\n\n2\n\nbad health person’s (bad_health_indicator=1,age=35,age*indicator=35)\n\n\n\n\nThe posterior samples of the model parameters are stored in mod_csim:\n\n\nCode\nhead(mod_csim)\n\n\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1 \nEnd = 7 \nThinning interval = 1 \n           b_age   b_badh       b_intx       int\n[1,] 0.005290453 1.529232 -0.009187788 0.4786304\n[2,] 0.005052663 1.606766 -0.011027587 0.4227358\n[3,] 0.005580439 1.596672 -0.010291266 0.4389609\n[4,] 0.005597212 1.581482 -0.011181978 0.4460846\n[5,] 0.006224239 1.564051 -0.011856860 0.4564888\n[6,] 0.006001431 1.644581 -0.013174529 0.4539493\n[7,] 0.006372604 1.696334 -0.014579037 0.4606763\n\n\nFirst, we’ll compute the linear part of the predictor:\n\n\nCode\nloglam1 = mod_csim[,\"int\"] + mod_csim[,c(2,1,3)] %*% x1\nloglam2 = mod_csim[,\"int\"] + mod_csim[,c(2,1,3)] %*% x2\n\n\nNext we’ll apply the inverse link:\n\n\nCode\nlam1 = exp(loglam1)\nlam2 = exp(loglam2)\n\n\nThe final step is to use these samples for the \\lambda parameter for each individual and simulate actual number of doctor visits using the likelihood:\n\n\nCode\n(n_sim = length(lam1))\n\n\n[1] 15000\n\n\nwe have distribution of 15000 samples of \\lambda for each person.\n\n\nCode\nplot(table(factor(y1, levels=0:18))/n_sim, pch=2, ylab=\"posterior prob.\", xlab=\"visits\")\npoints(table(y2+0.1)/n_sim, col=\"red\")\n\n\n\n\n\n\n\n\nFigure 6\n\n\n\n\n\n\n\nCode\ny1 = rpois(n=n_sim, lambda=lam1)\ny2 = rpois(n=n_sim, lambda=lam2)\n\nplot(table(factor(y1, levels=0:18))/n_sim, pch=2, ylab=\"posterior prob.\", xlab=\"visits\")\npoints(table(y2+0.1)/n_sim, col=\"red\")\n\n\n\n\n\n\n\n\n\nFinally, we can answer the original question: What is the probability that the person with poor health will have more doctor visits than the person with good health?\n\n\nCode\nmean(y2 &gt; y1)\n\n\n[1] 0.921\n\n\nBecause we used our posterior samples for the model parameters in our simulation (the loglam1 and loglam2 step above), this posterior predictive distribution on the number of visits for these two new individuals naturally account for our uncertainty in the model estimates. This is a more honest/realistic distribution than we would get if we had fixed the model parameters at their MLE or posterior means and simulated data for the new individuals.",
    "crumbs": [
      "2. Techniques and Models",
      "Poisson regression"
    ]
  },
  {
    "objectID": "C2-L10.html#sec-prior-sensitivity-analysis",
    "href": "C2-L10.html#sec-prior-sensitivity-analysis",
    "title": "Poisson regression",
    "section": "4 Prior sensitivity analysis",
    "text": "4 Prior sensitivity analysis\n  When communicating results from any analysis, a responsible statistician will report and justify modeling decisions, especially assumptions. In a Bayesian analysis, there is an additional assumption that is open to scrutiny: the choices of prior distributions. In the models considered so far in this course, there are an infinite number of prior distributions we could have chosen from. When communicating results from any analysis, a responsible statistician will report and justify modeling decisions, especially assumptions. In a Bayesian analysis, there is another assumption that is open to scrutiny: the choices of prior distributions. In the models considered so far in this course, there are an infinite number of prior distributions we could have chosen from.Q. How do you justify the model you choose?\n If they truly represent your beliefs about the parameters before analysis and the model is appropriate, then the posterior distribution truly represents your updated beliefs. If you don’t have any strong beliefs beforehand, there are often default, reference, or non-informative prior options, and you will have to select one. However, a collaborator or a boss (indeed, somebody somewhere) may not agree with your choice of prior. One way to increase the credibility of your results is to repeat the analysis under a variety of priors, and report how the results differ as a result. This process is called prior sensitivity analysis. Q. How do you justify the priors you choose?\nAt a minimum you should always report your choice of model and prior. If you include a sensitivity analysis, select one or more alternative priors and describe how the results of the analysis change. If they are sensitive to the choice of prior, you will likely have to explain both sets of results, or at least explain why you favor one prior over another. If the results are not sensitive to the choice of prior, this is evidence that the data are strongly driving the results. It suggests that different investigators coming from different backgrounds should come to the same conclusions.\nIf the purpose of your analysis is to establish a hypothesis, it is often prudent to include a “skeptical” prior which does not favor the hypothesis. Then, if the posterior distribution still favors the hypothesis despite the unfavorable prior, you will be able to say that the data substantially favor the hypothesis. This is the approach we will take in the following example, continued from the previous lesson.\n\n4.1 Poisson regression example\n Let’s return to the example of number of doctor visits. We concluded from our previous analysis of these data that both bad health and increased age are associated with more visits. Suppose the burden of proof that bad health is actually associated with more visits rests with us, and we need to convince a skeptic.doctor visits\nFirst, let’s re-run the original analysis and remind ourselves of the posterior distribution for the badh (bad health) indicator.\n\n\nCode\nlibrary(\"COUNT\")\nlibrary(\"rjags\")\n\ndata(\"badhealth\")\n\n\n\n\nCode\nmod_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/1e4)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n    b_intx ~ dnorm(0.0, 1.0/1e4)\n} \"\n\nset.seed(102)\n\ndata_jags = as.list(badhealth)\n\nparams = c(\"int\", \"b_badh\", \"b_age\", \"b_intx\")\n\nmod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 4\n   Total graph size: 3665\n\nInitializing model\n\n\nCode\nupdate(mod, 1e3)\n\nmod_sim = coda.samples(model=mod,\n                        variable.names=params,\n                        n.iter=5e3)\nmod_csim = as.mcmc(do.call(rbind, mod_sim))\n\n\n\n\nCode\nplot(density(mod_csim[,\"b_badh\"]))\n\n\n\n\n\n\n\n\nFigure 7\n\n\n\n\n\nEssentially all of the posterior probability mass is above 0, suggesting that this coefficient is positive (and consequently that bad health is associated with more visits). We obtained this result using a relatively noninformative prior. What if we use a prior that strongly favors values near 0? Let’s repeat the analysis with a normal prior on the badh coefficient that has mean 0 and standard deviation 0.2, so that the prior probability that the coefficient is less than 0.6 is &gt;0.998 . We’ll also use a small variance on the prior for the interaction term involving badh (standard deviation 0.01 because this coefficient is on a much smaller scale).\n\n\nCode\nmod2_string = \" model {\n    for (i in 1:length(numvisit)) {\n        numvisit[i] ~ dpois(lam[i])\n        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n    }\n    \n    int ~ dnorm(0.0, 1.0/1e6)\n    b_badh ~ dnorm(0.0, 1.0/0.2^2)\n    b_age ~ dnorm(0.0, 1.0/1e4)\n    b_intx ~ dnorm(0.0, 1.0/0.01^2)\n} \"\n\nmod2 = jags.model(textConnection(mod2_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 4\n   Total graph size: 3672\n\nInitializing model\n\n\nCode\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params,\n                        n.iter=5e3)\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim))\n\n\nHow did the posterior distribution for the coefficient of badh change?\n\n\nCode\ncurve(dnorm(x, mean=0.0, sd=sqrt(1e4)), from=-3.0, to=3.0, ylim=c(0.0, 3.0), lty=2,\n      main=\"b_badh\", ylab=\"density\", xlab=\"b_badh\")\ncurve(dnorm(x, mean=0.0, sd=0.2), from=-3.0, to=3.0, col=\"red\", lty=2, add=TRUE)\nlines(density(mod_csim[,\"b_badh\"]))\nlines(density(mod2_csim[,\"b_badh\"]), col=\"red\")\nlegend(\"topleft\", legend=c(\"noninformative prior\", \"posterior\", \"skeptical prior\", \"posterior\"),\n       lty=c(2,1,2,1), col=rep(c(\"black\", \"red\"), each=2), bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 8\n\n\n\n\n\nUnder the skeptical prior, our posterior distribution for b_badh has significantly dropped to between about 0.6 and 1.1. Although the strong prior influenced our inference on the magnitude of the bad health effect on visits, it did not change the fact that the coefficient is significantly above 0. In other words: even under the skeptical prior, bad health is associated with more visits, with posterior probability near 1.\nWe should also check the effect of our skeptical prior on the interaction term involving both age and health.\n\n\nCode\ncurve(dnorm(x, mean=0.0, sd=sqrt(1e4)), from=-0.05, to=0.05, ylim=c(0.0, 140.0), lty=2,\n      main=\"b_intx\", ylab=\"density\", xlab=\"b_intx\")\ncurve(dnorm(x, mean=0.0, sd=0.01), from=-0.05, to=0.05, col=\"red\", lty=2, add=TRUE)\nlines(density(mod_csim[,\"b_intx\"]))\nlines(density(mod2_csim[,\"b_intx\"]), col=\"red\")\nlegend(\"topleft\", legend=c(\"noninformative prior\", \"posterior\", \"skeptical prior\", \"posterior\"),\n       lty=c(2,1,2,1), col=rep(c(\"black\", \"red\"), each=2), bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 9\n\n\n\n\n\n\n\nCode\nmean(mod2_csim[,\"b_intx\"] &gt; 0) # posterior probability that b_intx is positive\n\n\n[1] 0.9251333\n\n\nThe result here is interesting. Our estimate for the interaction coefficient has gone from negative under the non-informative prior to positive under the skeptical prior, so the result is sensitive. In this case, because the skeptical prior shrinks away much of the bad health main effect, it is likely that this interaction effect attempts to restore some of the positive effect of bad health on visits. Thus, despite some observed prior sensitivity, our conclusion that bad health positively associates with more visits remains unchanged.",
    "crumbs": [
      "2. Techniques and Models",
      "Poisson regression"
    ]
  },
  {
    "objectID": "C2-L10.html#overdispersed-model",
    "href": "C2-L10.html#overdispersed-model",
    "title": "Poisson regression",
    "section": "5 Overdispersed model",
    "text": "5 Overdispersed model\nRecall that the Negative Binomial can be used to model overdispersed count data.\nstan has three parameterizations for the Negative Binomial.\nThe first looks like similar to a binomial parameterization:\n\n\\text{NegBinomial}(y~|~\\alpha,\\beta)  = \\binom{y +\n\\alpha - 1}{\\alpha - 1} \\, \\left( \\frac{\\beta}{\\beta+1}\n\\right)^{\\!\\alpha} \\, \\left( \\frac{1}{\\beta + 1} \\right)^{\\!y} \\!.\n\n\n\\mathbb{E}[y] = \\frac{\\alpha}{\\beta} \\ \\ \\text{ and } \\ \\ \\text{Var}[Y] = \\frac{\\alpha}{\\beta^2} (\\beta + 1).\n\nwe can sample from this using the following statement\nn ~ neg_binomial(alpha, beta)\nBut this parameterization if not a match to the Poisson model, so we move on\nThe second parametrization \\mu \\in \\mathbb{R}^+ and \\phi \\in \\mathbb{R}^+:\n\n\\text{NegBinomial2}(n \\, | \\, \\mu, \\phi)  = \\binom{n + \\phi - 1}{n} \\,\n\\left( \\frac{\\mu}{\\mu+\\phi} \\right)^{\\!n} \\, \\left(\n\\frac{\\phi}{\\mu+\\phi} \\right)^{\\!\\phi}\n\n\n\\mathbb{E}[n] = \\mu \\ \\ \\text{ and } \\ \\ \\ \\mathbb{V}\\text{ar}[n] = \\mu + \\frac{\\mu^2}{\\phi}\n\nwe can sample from this using the following statement\nn ~ neg_binomial_2(mu, phi)\nAnd there is a third parametrization\n\nNegBinomial2Log(y\\mid\\mu,\\phi) = NegBinomial2(y\\mid exp(\\eta),\\phi).\n\nwe can sample from this using the following statement:\ny \\~ **neg_binomial_2\\_log**(y\\|mu, phi)`\njags has just one parameterization:\n\nf(y \\mid r, p) = \\frac{\\Gamma(y+r)}{\\Gamma(r)\\Gamma(y+1)}p^r(1-p)^y\n\nWe think of the Negative Binomial Distribution as the probability of completing y successful trials allowing for r failures in a sequence of (y+r) Bernoulli trials where success is defined as drawing (with replacement) a white ball from an urn of white and black balls with a probability p of success.\n\n\\mathbb{E}[Y] = \\mu = { r(1-p) \\over p }\\ \\ \\text{ and } \\ \\ \\ \\mathbb{V}\\text{ar}[Y] = \\mu + \\frac{\\mu^2}{r}\n\n\n5.1 Transformations:\nSince we want to have a model corresponding to a poisson regression we will transform the model as follows:\nIf we set p = {\\text{r} \\over {r} + \\lambda } then the mean becomes : \\lambda\nand if we also set r= {\\lambda^2 \\over \\omega} then the variance becomes a sum of \\lambda + \\omega where \\omega is our over dispersion term.\n\n\\omega = \\lambda^2 / r\n\n\n\\begin{aligned}\n\\mathbb{E}[Y] &= { r(1-p) \\over p }\n\\\\ &= rp^{-1} -r\n\\\\ & \\stackrel {sub\\ p} =  {\\cancel{r}(\\bcancel{r}+\\lambda) \\over \\cancel{r}} - \\bcancel{r}\n\\\\ &= \\lambda \\mathbb{V}\\text{ar}[Y]\n\\\\ &= { (1-p) r \\over p^2 }\n\\\\ & \\stackrel {sub \\ \\lambda } = {1 \\over p} \\lambda\n\\\\ & \\stackrel {sub p} = \\lambda { (r+ \\lambda) \\over r}\n\\\\ &=  {\\lambda r +  \\lambda^2 \\over r }\n\\\\ &= 1 \\lambda + {\\lambda^2 \\over r}\n\\\\ &\\stackrel { sub \\ \\omega}= \\lambda + \\omega\n\\end{aligned}\n\nWhere we interpret \\lambda as the mean and \\omega as the overdispersion \n\n\nCode\nlibrary(\"rjags\")\nlibrary(\"COUNT\")\ndata(\"badhealth\")\n\n\n\n\nCode\nmod3_string = \"\nmodel {\n    for (i in 1:length(numvisit)) { \n1        mu[i]       = b0 + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]\n2        lambda[i]   = exp(mu[i])\n3        p[i]        = r / (r + lambda[i])\n4        numvisit[i] ~ dnegbin(p[i], r)\n5        resid[i]       = numvisit[i] - p[i]\n    }\n    ## Priors\n6    b0        ~ dnorm(0.0, 1.0/1e6)\n7    b_badh    ~ dnorm(0.0, 1.0/0.2^2)\n8    b_age     ~ dnorm(0.0, 1.0/1e4)\n9    b_intx    ~ dnorm(0.0, 1.0/0.01^2)\n10    r ~ dunif(0,50)\n\n    ## extra deterministic parameters\n    omega      &lt;-  pow(mean(lambda),2)/2\n11    #theta      &lt;- pow(1/mean(p),2)\n12    #scale      &lt;- mean((1-p)/p)\n}\"\ndata3_jags = as.list(badhealth)\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, n.chains=3)\n13update(mod3, 1e3)\nparams3 = c(\"b_intx\", \"b_badh\", \"b_age\", 'over_disp', 'b0','omega','r')\n14mod3_sim = coda.samples(model=mod3,  variable.names=params3, n.iter=5e3)\n15mod3_csim = as.mcmc(do.call(rbind, mod3_sim))\n16(dic3 = dic.samples(mod3, n.iter=1e3))\n\n\n\n1\n\nthe linear part\n\n2\n\nlambda corresponds to the parameter used in the Poisson regression\n\n3\n\np is the success parameter\n\n4\n\nwe draw from the negative binomial distribution\n\n5\n\nsampling using the parametrization of the Negative Binomial distribution.\n\n6\n\nnormal prior for intercept b0\n\n7\n\nnormal prior for b_badh\n\n8\n\nnormal prior for b_age\n\n9\n\nnormal prior for b_intx\n\n10\n\nuniform prior for over_disp - at the upper limit of 50 NegBin converges to Poisson see (Jackman 2009, 280)\n\n11\n\ntheta param\n\n12\n\nscale param\n\n13\n\nburn in\n\n14\n\nsample\n\n15\n\nstack samples from the chains\n\n16\n\nestimate the DIC\n\n\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1127\n   Unobserved stochastic nodes: 5\n   Total graph size: 4204\n\nInitializing model\n\nMean deviance:  4477 \npenalty 4.055 \nPenalized deviance: 4481 \n\n\n\n\nCode\ngelman.diag(mod3_sim )\n\n\nPotential scale reduction factors:\n\n       Point est. Upper C.I.\nb0           1.01       1.01\nb_age        1.01       1.01\nb_badh       1.00       1.00\nb_intx       1.00       1.01\nomega        1.00       1.00\nr            1.00       1.00\n\nMultivariate psrf\n\n1\n\n\n\n\nCode\nraftery.diag(mod3_sim)\n\n\n[[1]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                              \n        Burn-in  Total Lower bound  Dependence\n        (M)      (N)   (Nmin)       factor (I)\n b0     27       29388 3746         7.85      \n b_age  28       29498 3746         7.87      \n b_badh 12       12572 3746         3.36      \n b_intx 18       21819 3746         5.82      \n omega  3        4062  3746         1.08      \n r      5        5871  3746         1.57      \n\n\n[[2]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                              \n        Burn-in  Total Lower bound  Dependence\n        (M)      (N)   (Nmin)       factor (I)\n b0     18       19100 3746         5.10      \n b_age  24       24334 3746         6.50      \n b_badh 12       13268 3746         3.54      \n b_intx 12       12678 3746         3.38      \n omega  2        3803  3746         1.02      \n r      5        5673  3746         1.51      \n\n\n[[3]]\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n                                              \n        Burn-in  Total Lower bound  Dependence\n        (M)      (N)   (Nmin)       factor (I)\n b0     42       50334 3746         13.400    \n b_age  26       28752 3746          7.680    \n b_badh 14       13732 3746          3.670    \n b_intx 12       12728 3746          3.400    \n omega  2        3680  3746          0.982    \n r      5        5673  3746          1.510    \n\n\n\n\nCode\nautocorr.diag(mod3_sim)\n\n\n               b0     b_age      b_badh      b_intx       omega            r\nLag 0  1.00000000 1.0000000 1.000000000 1.000000000  1.00000000  1.000000000\nLag 1  0.93370705 0.9346078 0.784735253 0.795801833  0.01908193  0.238782320\nLag 5  0.74672691 0.7508936 0.374285108 0.383383936 -0.01326354 -0.010792019\nLag 10 0.56978037 0.5677051 0.156078365 0.168269346 -0.01851913  0.014250700\nLag 50 0.01816689 0.0171772 0.001551632 0.002502067  0.01531242 -0.001484443\n\n\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n        b0      b_age     b_badh     b_intx      omega          r \n  411.1193   421.8928  1475.6070  1426.9707 14958.5971  9222.8008 \n\n\n\n\nCode\nsummary(mod3_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean       SD  Naive SE Time-series SE\nb0     0.465107 0.125807 1.027e-03      0.0062846\nb_age  0.005694 0.003268 2.669e-05      0.0001631\nb_badh 0.378740 0.168177 1.373e-03      0.0043766\nb_intx 0.014878 0.004311 3.520e-05      0.0001141\nomega  2.775407 0.216049 1.764e-03      0.0017664\nr      0.988001 0.068882 5.624e-04      0.0007187\n\n2. Quantiles for each variable:\n\n             2.5%      25%      50%      75%   97.5%\nb0      0.2121766 0.383124 0.463586 0.548234 0.71291\nb_age  -0.0007964 0.003535 0.005727 0.007812 0.01222\nb_badh  0.0522866 0.264232 0.376815 0.493034 0.70985\nb_intx  0.0064113 0.011972 0.014918 0.017783 0.02327\nomega   2.3798276 2.624586 2.767403 2.916428 3.22150\nr       0.8602568 0.940839 0.984807 1.032203 1.13181\n\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod3_sim, auto.layout = FALSE)\n\n\n\n\n\n\n\n\n\n\nFigure 10\n\n\n\n\n\n\n\n\n\n\n\nFigure 11\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12\n\n\n\n\n\n\n\n\n\n\n\nFigure 13\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 14\n\n\n\n\n\n\n\n\n\n\n\nFigure 15\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 16\n\n\n\n\n\n\n\n\n\n\n\nFigure 17\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 18\n\n\n\n\n\n\n\n\n\n\n\nFigure 19\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 20\n\n\n\n\n\n\n\n\n\n\n\nFigure 21\n\n\n\n\n\n\n\nCode\nautocorr.plot(mod3_csim,auto.layout = FALSE)\n\n\n\n\n\n\n\n\n\n\nFigure 22\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 23\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 24\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 25\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 26\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 27\n\n\n\n\n\n\n\n\nCode\nX = as.matrix(badhealth[,-1])\nX = cbind(X, with(badhealth, badh*age))\n(pmed_coef = apply(mod3_csim, 2, median))\n\n\n         b0       b_age      b_badh      b_intx       omega           r \n0.463585543 0.005726857 0.376815015 0.014917844 2.767403254 0.984806654 \n\n\nCode\n(r = pmed_coef[\"r\"] )\n\n\n        r \n0.9848067 \n\n\nCode\nmu_hat = pmed_coef[\"b0\"] + X %*% pmed_coef[c(\"b_badh\", \"b_age\", \"b_intx\")]\nlambda_hat = exp(mu_hat)\np_hat = r / (r + lambda_hat)\nhist(lambda_hat)\n\n\n\n\n\n\n\n\n\nCode\nhist(p_hat)\n\n\n\n\n\n\n\n\n\nresiduals\n\n\nCode\nresid = badhealth$numvisit - p_hat\nhead(resid)\n\n\n         [,1]\n[1,] 29.69233\n[2,] 19.68743\n[3,] 15.67500\n[4,] 19.69111\n[5,] 14.66103\n[6,] 14.65458\n\n\n\n\nCode\nplot(resid) # the data were ordered\n\n\n\n\n\n\n\n\nFigure 28: Plot of residuals\n\n\n\n\n\n\nCode\nhead(mod3_csim)\n\n\n\n\nTable 1: First few rows of mod3_csim\n\n\n\nMarkov Chain Monte Carlo (MCMC) output:\nStart = 1 \nEnd = 7 \nThinning interval = 1 \n            b0       b_age    b_badh     b_intx    omega         r\n[1,] 0.4585149 0.004660465 0.5236388 0.01131598 2.488047 1.0334043\n[2,] 0.5131659 0.004195786 0.4538343 0.01262845 2.663287 0.9278381\n[3,] 0.5062904 0.004209453 0.5352869 0.01171546 2.681452 0.9522651\n[4,] 0.5396153 0.005596650 0.3210580 0.01399573 3.030899 1.0261184\n[5,] 0.4559783 0.005517106 0.3364373 0.01749889 2.777185 0.9943383\n[6,] 0.4279814 0.005486275 0.3872663 0.01983019 2.859494 0.9943618\n[7,] 0.4876701 0.003198972 0.3430875 0.01520471 2.348750 0.9742482\n\n\n\n\n\n\nCode\nplot(p_hat, badhealth$numvisit)\nabline(0.0, 1.0)\n\n\n\n\n\n\n\n\nFigure 29: Plot of p_hat vs numvisit\n\n\n\n\n\n\n\nCode\nplot(p_hat[which(badhealth$badh==0)], resid[which(badhealth$badh==0)], xlim=range(p_hat), ylab=\"residuals\", xlab=expression(hat(p)), ylim=range(resid))\npoints(p_hat[which(badhealth$badh==1)], resid[which(badhealth$badh==1)], col=\"red\")\n\n\n\n\n\n\n\n\nFigure 30: Plot of p_hat vs residuals, colored by health status\n\n\n\n\n\n\n\nCode\nvar(resid[which(badhealth$badh==0)])\n\n\n[1] 7.061266\n\n\nCode\nvar(resid[which(badhealth$badh==1)])\n\n\n[1] 41.2124",
    "crumbs": [
      "2. Techniques and Models",
      "Poisson regression"
    ]
  },
  {
    "objectID": "C2-L07.html",
    "href": "C2-L07.html",
    "title": "Notes - Linear regression",
    "section": "",
    "text": "Introduction to linear regression\n\nWe discussed linear regression briefly in the previous course. And we fit a few models with non-informative priors. Here, we’ll provide a brief review, demonstrate fitting linear regression models in JAGS And discuss a few practical skills that are helpful when fitting linear models in general. \nThis is not meant to be a comprehensive treatment of linear models, which you can find in numerous courses and textbooks. \nLinear regression is perhaps the simplest way to relate a continuous response variable to multiple explanatory variables.\nThis may arise from observing several variables together and investigating which variables correlate with the response variable. Or it could arise from conducting an experiment, where we carefully assign values of explanatory variables to randomly selected subjects. And try to establish a cause-and-effect relationship.\nA linear regression model has the following form:\n\ny_i=\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k + \\epsilon_i\n\\\\ \\epsilon_i \\stackrel {iid} \\sim N(0,\\sigma^2)\n\\tag{1}\nThis describes the mean, and then we would also add an error, individual term for each observation. We would assume that the errors are IID from a normal distribution means 0 variance \\sigma^2 for observations 1 \\ldots k.\nEquivalently we can write this model for y_i directly as y_i given all of the x_i values, betas and a constant variance \\sigma^2. Again, k is the number of predictor variables.\n\ny_i\\mid x_i,\\beta_i,\\sigma^2 \\sim N(\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k, \\sigma^2)\n\\\\ \\beta_i \\sim p(\\beta_i)\n\\\\ \\sigma^2 \\sim p(\\sigma^2)\n\\tag{2}\nThis yields the following graphical model structure.\n\n\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeOneSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeTwoSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeThreeSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFourSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFiveSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmtt10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmb10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmss10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['DejaVu Sans Display'] not found. Falling back to DejaVu Sans.\n\n\n\n\n\n\n\n\nFigure 1: The graphical model for linear regression\n\n\n\n\n\n\n\n\n\n\n\nImportantUnderstanding the Graphical Models\n\n\n\n\nThis graphical model uses plate notation\nWe’ll start with a plate for all of our different y variables,\n\nIt is repeated i = 1 \\ldots N times\n\ny_i, are random variable - (indicated by a circle)\n\nthey are observed - indicated by a filled shape.\n\nX_i variables.\n\nthey are drawn as squares around to indicate that they are constants and not random variables.\nWe’re always conditioning on the Xs. So they’ll just be constants.\nthey are observed, so they are filled in.\n\nThe y_i depend on the values of the x and the values of these parameters. So, we have \\beta_0, \\ldots, \\beta_k.\nSigma squared.\nSince the y_i depend on all of these, so this would be the graphical model representation.\n\n\n\nThe terms of a linear model are always linearly related because of the structure of the model.\nBut the model does not have to be linear necessarily in the xy relationship. For example, it may be that y is related linearly to x^2. Hence we could transform the x and y variables to get new x’s and new y’s but we would still have a linear model. However, in that case, if we transform the variables, we must be careful about how this changes the final interpretation of the results.\n\n\n\n\n\n\nImportantInterpreting Coefficients\n\n\n\nThe basic interpretation of the \\beta_i coefficients is:\nWhile holding all other X variables constant, if we increases X_i by one then the mean of \\bar{y} is expected to increase by \\beta_i .\nThat is \\beta_i describes how the \\bar{y} changes with changes in X_i, while accounting for all the other X variables.\n\n\\beta \\approx  \\frac{\\partial \\bar{y} }{\\partial x_i}\n\\tag{3}\nThat’s true for all of the x variables.\n\n\n\n\n\n\n\n\nWarningRegression assumptions\n\n\n\nWe’re going to assume that\n\nThe ys are independent of each other, given the xs.\nThe y_is have the same variance.\nThe residuals are normally distributed with mean 0 and variance \\sigma^2.\n\nThese are actually strong assumptions that are not often not realistic in many situations.\nThere are many statistical models to address that.\nWe’ll look at some hierarchical methods in the coming lessons.\n\n\n\n\nThe model is not complete until we add the prior distributions.\nSo we might say \\beta_0 comes from its prior.\n\\beta_1 would come from its prior, and so forth for all the \\betas. And sigma squared would come from its prior.\nThe most common choice for prior on the \\betas, is a Normal distribution. Or we can do a Multivariate normal for all of the betas at once.\nThis is conditionally conjugate and allows us to do Gibbs sampling.\nIf we want to be non-informative, we can choose Normal(0,\\sigma^2=1e6) priors with very large variance. Which are practically flat for realistic values of beta. The non-informative priors used in the last class are equivalent to using normal priors with infinite variance.\nWe can also use the conditionally conjugate InverseGamma() prior for \\sigma^2 that we’re familiar with.\nAnother common prior for the betas is Double exponential, or the Laplace prior, or Laplace distribution. \nThe Laplace prior has this density:\n\nf(x\\mid \\mu,\\beta)=\\frac{1}{2\\beta} e^{|\\frac{x-\\mu}{\\beta}|}\n\\tag{4}\nwhere:\n\n\\mu is the location parameter and\n\\beta is the scale parameter.\n\nThe case where \\mu = 0 and \\beta = 1 is called the standard double exponential distribution\n\nf(x)=\\frac{1}{2} e^{|x|}\n\\tag{5}\nAnd the density looks like this.\n\n\n\n\n\n\n\nFigure 2: The Double Exponential Distribution\n\n\n\n\n\n\n\n\n\n\nFigure 3: The Double Exponential Distribution\n\n\n\n\nRPython\n\n\n\n\nCode\n# Grid of X-axis values\nx &lt;- seq(-10, 10, 0.1)\nplot(x, ddexp(x, 0, 2), type = \"l\", ylab = \"\", lwd = 2, col = \"red\")\nlines(x, ddexp(x, 0, 1.5), type = \"l\", ylab = \"\", lwd = 2, col = \"green\")\nlines(x, ddexp(x, 0, 1), type = \"l\", ylab = \"\", lwd = 2, col = \"blue\")\nlegend(\"topright\",\n       c(expression(paste(, beta)), \"1.5\",\"1\", \"2\"),\n       lty = c(0, 1, 1, 1),\n       col = c(\"red\",\"green\", \"blue\"), box.lty = 0, lwd = 2)\n\n#x &lt;- rdexp(500, location = 2, scale = 1)\n#de_sample=ddexp(x, 2, 1)\n#CDF &lt;- ecdf(de_sample )\n#plot(CDF)\n\n\n\n\n\n\n\nCode\nloc, scale = 0., 1.\ns = np.random.laplace(loc, scale, 1000)\n\ncount, bins, ignored = plt.hist(s, 30, density=True)\nx = np.arange(-8., 8., .01)\npdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\nplt.plot(x, pdf);\n\ng = (1/(scale * np.sqrt(2 * np.pi)) *\n     np.exp(-(x - loc)**2 / (2 * scale**2)))\nplt.plot(x,g);\n\n\n\n\n\n\nIt’s called double exponential because it looks like the exponential distribution except it’s been reflected over the y axis. It has a sharp peak at x equals 0, or beta equals 0 in this case, which can be useful if we want to do variable selection among our x’s. Because it’ll favor values in your 0 for these betas.\nThis is related to the popular regression technique known as the LASSO. \nMore information is available from:\n\nNIST\nWikipedia",
    "crumbs": [
      "2. Techniques and Models",
      "Notes - Linear regression"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-introduction-to-linear-regression",
    "href": "C2-L07.html#sec-introduction-to-linear-regression",
    "title": "Notes - Linear regression",
    "section": "",
    "text": "Introduction to linear regression\n\nWe discussed linear regression briefly in the previous course. And we fit a few models with non-informative priors. Here, we’ll provide a brief review, demonstrate fitting linear regression models in JAGS And discuss a few practical skills that are helpful when fitting linear models in general. \nThis is not meant to be a comprehensive treatment of linear models, which you can find in numerous courses and textbooks. \nLinear regression is perhaps the simplest way to relate a continuous response variable to multiple explanatory variables.\nThis may arise from observing several variables together and investigating which variables correlate with the response variable. Or it could arise from conducting an experiment, where we carefully assign values of explanatory variables to randomly selected subjects. And try to establish a cause-and-effect relationship.\nA linear regression model has the following form:\n\ny_i=\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k + \\epsilon_i\n\\\\ \\epsilon_i \\stackrel {iid} \\sim N(0,\\sigma^2)\n\\tag{1}\nThis describes the mean, and then we would also add an error, individual term for each observation. We would assume that the errors are IID from a normal distribution means 0 variance \\sigma^2 for observations 1 \\ldots k.\nEquivalently we can write this model for y_i directly as y_i given all of the x_i values, betas and a constant variance \\sigma^2. Again, k is the number of predictor variables.\n\ny_i\\mid x_i,\\beta_i,\\sigma^2 \\sim N(\\beta_0+\\beta_1 x_i +\\ldots+ \\beta_k x_k, \\sigma^2)\n\\\\ \\beta_i \\sim p(\\beta_i)\n\\\\ \\sigma^2 \\sim p(\\sigma^2)\n\\tag{2}\nThis yields the following graphical model structure.\n\n\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXGeneral'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXNonUnicode'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeOneSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeTwoSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeThreeSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFourSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['STIXSizeFiveSym'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmtt10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmb10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['cmss10'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['DejaVu Sans Display'] not found. Falling back to DejaVu Sans.\n\n\n\n\n\n\n\n\nFigure 1: The graphical model for linear regression\n\n\n\n\n\n\n\n\n\n\n\nImportantUnderstanding the Graphical Models\n\n\n\n\nThis graphical model uses plate notation\nWe’ll start with a plate for all of our different y variables,\n\nIt is repeated i = 1 \\ldots N times\n\ny_i, are random variable - (indicated by a circle)\n\nthey are observed - indicated by a filled shape.\n\nX_i variables.\n\nthey are drawn as squares around to indicate that they are constants and not random variables.\nWe’re always conditioning on the Xs. So they’ll just be constants.\nthey are observed, so they are filled in.\n\nThe y_i depend on the values of the x and the values of these parameters. So, we have \\beta_0, \\ldots, \\beta_k.\nSigma squared.\nSince the y_i depend on all of these, so this would be the graphical model representation.\n\n\n\nThe terms of a linear model are always linearly related because of the structure of the model.\nBut the model does not have to be linear necessarily in the xy relationship. For example, it may be that y is related linearly to x^2. Hence we could transform the x and y variables to get new x’s and new y’s but we would still have a linear model. However, in that case, if we transform the variables, we must be careful about how this changes the final interpretation of the results.\n\n\n\n\n\n\nImportantInterpreting Coefficients\n\n\n\nThe basic interpretation of the \\beta_i coefficients is:\nWhile holding all other X variables constant, if we increases X_i by one then the mean of \\bar{y} is expected to increase by \\beta_i .\nThat is \\beta_i describes how the \\bar{y} changes with changes in X_i, while accounting for all the other X variables.\n\n\\beta \\approx  \\frac{\\partial \\bar{y} }{\\partial x_i}\n\\tag{3}\nThat’s true for all of the x variables.\n\n\n\n\n\n\n\n\nWarningRegression assumptions\n\n\n\nWe’re going to assume that\n\nThe ys are independent of each other, given the xs.\nThe y_is have the same variance.\nThe residuals are normally distributed with mean 0 and variance \\sigma^2.\n\nThese are actually strong assumptions that are not often not realistic in many situations.\nThere are many statistical models to address that.\nWe’ll look at some hierarchical methods in the coming lessons.\n\n\n\n\nThe model is not complete until we add the prior distributions.\nSo we might say \\beta_0 comes from its prior.\n\\beta_1 would come from its prior, and so forth for all the \\betas. And sigma squared would come from its prior.\nThe most common choice for prior on the \\betas, is a Normal distribution. Or we can do a Multivariate normal for all of the betas at once.\nThis is conditionally conjugate and allows us to do Gibbs sampling.\nIf we want to be non-informative, we can choose Normal(0,\\sigma^2=1e6) priors with very large variance. Which are practically flat for realistic values of beta. The non-informative priors used in the last class are equivalent to using normal priors with infinite variance.\nWe can also use the conditionally conjugate InverseGamma() prior for \\sigma^2 that we’re familiar with.\nAnother common prior for the betas is Double exponential, or the Laplace prior, or Laplace distribution. \nThe Laplace prior has this density:\n\nf(x\\mid \\mu,\\beta)=\\frac{1}{2\\beta} e^{|\\frac{x-\\mu}{\\beta}|}\n\\tag{4}\nwhere:\n\n\\mu is the location parameter and\n\\beta is the scale parameter.\n\nThe case where \\mu = 0 and \\beta = 1 is called the standard double exponential distribution\n\nf(x)=\\frac{1}{2} e^{|x|}\n\\tag{5}\nAnd the density looks like this.\n\n\n\n\n\n\n\nFigure 2: The Double Exponential Distribution\n\n\n\n\n\n\n\n\n\n\nFigure 3: The Double Exponential Distribution\n\n\n\n\nRPython\n\n\n\n\nCode\n# Grid of X-axis values\nx &lt;- seq(-10, 10, 0.1)\nplot(x, ddexp(x, 0, 2), type = \"l\", ylab = \"\", lwd = 2, col = \"red\")\nlines(x, ddexp(x, 0, 1.5), type = \"l\", ylab = \"\", lwd = 2, col = \"green\")\nlines(x, ddexp(x, 0, 1), type = \"l\", ylab = \"\", lwd = 2, col = \"blue\")\nlegend(\"topright\",\n       c(expression(paste(, beta)), \"1.5\",\"1\", \"2\"),\n       lty = c(0, 1, 1, 1),\n       col = c(\"red\",\"green\", \"blue\"), box.lty = 0, lwd = 2)\n\n#x &lt;- rdexp(500, location = 2, scale = 1)\n#de_sample=ddexp(x, 2, 1)\n#CDF &lt;- ecdf(de_sample )\n#plot(CDF)\n\n\n\n\n\n\n\nCode\nloc, scale = 0., 1.\ns = np.random.laplace(loc, scale, 1000)\n\ncount, bins, ignored = plt.hist(s, 30, density=True)\nx = np.arange(-8., 8., .01)\npdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\nplt.plot(x, pdf);\n\ng = (1/(scale * np.sqrt(2 * np.pi)) *\n     np.exp(-(x - loc)**2 / (2 * scale**2)))\nplt.plot(x,g);\n\n\n\n\n\n\nIt’s called double exponential because it looks like the exponential distribution except it’s been reflected over the y axis. It has a sharp peak at x equals 0, or beta equals 0 in this case, which can be useful if we want to do variable selection among our x’s. Because it’ll favor values in your 0 for these betas.\nThis is related to the popular regression technique known as the LASSO. \nMore information is available from:\n\nNIST\nWikipedia",
    "crumbs": [
      "2. Techniques and Models",
      "Notes - Linear regression"
    ]
  },
  {
    "objectID": "C2-L07.html#eda",
    "href": "C2-L07.html#eda",
    "title": "Notes - Linear regression",
    "section": "1.1 EDA",
    "text": "1.1 EDA\n\n\nCode\n1pairs(Leinhardt)\n\n\n\n1\n\nUsing pairs to investigate the marginal relationships between each of the four variables.\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.0.1 Simple linear Model\nWe’ll start with a simple linear regression model that relates infant mortality to per capita income.\n\n\nCode\nplot(infant ~ income, data=Leinhardt)\n\n\n\n\n\n\n\n\n\n\n\nCode\nhist(Leinhardt$infant)\n\n\n\n\n\n\n\n\n\nthis is right-skewed (many small values and a number of much larger one)\n\n\nCode\nhist(Leinhardt$income)\n\n\n\n\n\n\n\n\n\nalso right-skewed.\nthis indicates that we may do better if we do a log transform on these two variables.\n\n\n1.1.0.2 Log-Log Linear Model\n\n\nCode\n1Leinhardt$loginfant = log(Leinhardt$infant)\n2Leinhardt$logincome = log(Leinhardt$income)\n\n\n3plot(loginfant ~ logincome,data=Leinhardt)\n\n\n\n1\n\nlog transform infant column.\n\n2\n\nlog transform income column.\n\n3\n\nscatter plot of the log log transformed data.\n\n\n\n\n\n\n\n\n\n\nFigure 4: log log transformed infant mortality vs income\n\n\n\n\n\nSince infant mortality and per capita income are positive and right-skewed quantities, we consider modeling them on the logarithmic scale. A linear model appears much more appropriate on this scale.\n\n\nCode\n1scatterplot(loginfant ~ logincome,data=Leinhardt)\n\n\n\n1\n\nscatterplot with a regression fit and uncertainty for the data\n\n\n\n\n\n\n\n\n\n\nFigure 5: log log transformed infant mortality vs income scatterplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.1 Modeling\nThe reference Bayesian analysis (with a non-informative prior) is available directly in R.\n\n\nCode\nlmod0 = lm(loginfant ~ logincome, data=Leinhardt)\nsummary(lmod0)\n\n\n\n\nregression output\nlm(formula = loginfant ~ logincome, data = Leinhardt)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.66694 -0.42779 -0.02649  0.30441  3.08415 \n\nCoefficients: \n            Estimate Std. Error t value Pr(&gt;|t|)    \n1(Intercept)  7.14582    0.31654  22.575   &lt;2e-16 ***\n2logincome   -0.51179    0.05122  -9.992   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n3Residual standard error: 0.6867 on 99 degrees of freedom\n4  (4 observations deleted due to missingness)\n5Multiple R-squared:  0.5021,    Adjusted R-squared:  0.4971\nF-statistic: 99.84 on 1 and 99 DF,  p-value: &lt; 2.2e-16\n\n\n\n1\n\nintercept is \\gg its error so it appears statistically significant (***)\n\n2\n\nposterior mean logincome too\n\n3\n\nResidual standard error gives us an estimate of the left over variance after fitting the model.\n\n4\n\n4 rows were dropped due to missing values\n\n5\n\nAdjusted R-squared is the explained variance adjusted for degrees of freedom",
    "crumbs": [
      "2. Techniques and Models",
      "Notes - Linear regression"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-residual-checks",
    "href": "C2-L07.html#sec-residual-checks",
    "title": "Notes - Linear regression",
    "section": "3.1 Residual checks",
    "text": "3.1 Residual checks\n\n\n\n\n\n\nImportant\n\n\n\nAnalysis gets complicated quickly when we have multiple models. What we shall soon see is how to get residuals from the Bayesian model in Stan so we can compare it visually with the reference model we got using LM.\n\n\nChecking residuals (the difference between the response and the model’s prediction for that value) is important with linear models since residuals can reveal violations of the assumptions we made to specify the model. In particular, we are looking for any sign that the model is not linear, normally distributed, or that the observations are not independent (conditional on covariates).\nFirst, let’s look at what would have happened if we fit the reference linear model to the un-transformed variables.\n\n\nCode\nlmod0 = lm(infant ~ income, data=Leinhardt)\nplot(resid(lmod0)) # to check independence (looks okay)\n\n\n\n\n\n\n\n\n\nthere should not be a pattern - but we can see an increase. This is not an issue and due to the data being presorted.\n\n\nCode\nplot(predict(lmod0), resid(lmod0)) # to check for linearity, constant variance (looks bad)\n\n\n\n\n\n\n\n\n\nafter 80 the variance starts increasing\n\n\nCode\nqqnorm(resid(lmod0)) # to check Normality assumption (we want this to be a straight line)\n\n\n\n\n\n\n\n\n\nCode\n#?qqnorm\n\n\nThis looks good except for the last few points.\nNow let’s return to our model fit to the log-transformed variables. In a Bayesian model, we have distributions for residuals, but we’ll simplify and look only at the residuals evaluated at the posterior mean of the parameters.\n\n\nCode\nX = cbind(rep(1.0, data1_jags$n), data1_jags$log_income)\nhead(X)\n\n\n     [,1]     [,2]\n[1,]    1 8.139149\n[2,]    1 8.116716\n[3,]    1 8.115521\n[4,]    1 8.466110\n[5,]    1 8.522976\n[6,]    1 8.105308\n\n\n\n\nCode\n1(pm_params1 = colMeans(mod1_csim))\n\n\n\n1\n\nposterior mean - using (var = expr) forces R to return the value of var\n\n\n\n\n      b[1]       b[2]        sig \n 7.1673671 -0.5152645  0.9705816 \n\n\n\n\nCode\n1yhat1 = drop(X %*% pm_params1[1:2])\n2resid1 = data1_jags$y - yhat1\n3plot(resid1)\n\n\n\n1\n\nwe are evaluating \\\\hat{y} = b_0 \\times 1 + b_1 \\times x_1 via matrix multiplication of [1, data1_jags$log_income] *[b_0,b_1]\n\n2\n\nres_i = y_i- \\hat y = y_i - (b_0 \\times 1 + b_1 \\times x_{1,i})\n\n3\n\nplots the residual against the data index\n\n\n\n\n\n\n\n\n\n\n\nSo to get the residuals from Stan we extract the b parameter.\nAlthough we did not discuss it we could estimate \\hat y by drawing K predictions for each x_i and look at res_i=\\frac{1}{K}\\sum_k|y_i -\\hat y_{i,k}| and plot upper and fit a line as well as lower and upper bounds as well. Also I’m not sure but I guess we can also do with using the predictive posterior dist. Anyhow here is a link to something like this: Extracting and visualizing tidy residuals from Bayesian models -jk\n\n\nCode\nplot(yhat1, resid1) # against predicted values\n\n\n\n\n\n\n\n\n\n\n\nCode\nqqnorm(resid1) # checking normality of residuals\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(predict(lmod0), resid(mod1)) # to compare with reference linear model\n\n\n\n\n\n\n\n\n\n\n\nCode\nrownames(dat)[order(resid1, decreasing=TRUE)[1:5]] # which countries have the largest positive residuals?\n\n\n[1] \"Saudi.Arabia\" \"Libya\"        \"Zambia\"       \"Brazil\"       \"Afganistan\"  \n\n\nThe residuals look pretty good here (no patterns, shapes) except for two strong outliers, Saudi Arabia and Libya. When outliers appear, it is a good idea to double check that they are not just errors in data entry. If the values are correct, you may reconsider whether these data points really are representative of the data you are trying to model. If you conclude that they are not (for example, they were recorded on different years), you may be able to justify dropping these data points from the data set.\nIf you conclude that the outliers are part of data and should not be removed, we have several modeling options to accommodate them. We will address these in the next segment.",
    "crumbs": [
      "2. Techniques and Models",
      "Notes - Linear regression"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-additional-covariates",
    "href": "C2-L07.html#sec-additional-covariates",
    "title": "Notes - Linear regression",
    "section": "4.1 Additional covariates",
    "text": "4.1 Additional covariates\nThe first approach is to look for additional covariates that may be able to explain the outliers. For example, there could be a number of variables that provide information about infant mortality above and beyond what income provides.\nLooking back at our data, there are two variables we haven’t used yet: region and oil. The oil variable indicates oil-exporting countries. Both Saudi Arabia and Libya are oil-exporting countries, so perhaps this might explain part of the anomaly.\n\n\nCode\nlibrary(\"rjags\")\n\nmod2_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[i], prec)\n1        mu[i] = b[1] + b[2]*log_income[i] + b[3]*is_oil[i]\n    }\n    \n2    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*10.0/2.0)\n    sig = sqrt( 1.0 / prec )\n} \"\n\n\nset.seed(73)\ndata2_jags = list(y=dat$loginfant, log_income=dat$logincome,\n3                  is_oil=as.numeric(dat$oil==\"yes\"))\ndata2_jags$is_oil\n\nparams2 = c(\"b\", \"sig\")\n\ninits2 = function() {\n4    inits = list(\"b\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod2 = jags.model(textConnection(mod2_string), data=data2_jags, inits=inits2, n.chains=3)\nupdate(mod2, 1e3) # burn-in\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params2,\n                        n.iter=5e3)\n\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim)) # combine multiple chains\n\n\n\n1\n\nwe add the is_oil indicator parameter\n\n2\n\nwe increment the number of parameters\n\n3\n\nencode the is_oil from text to be binary\n\n4\n\ndraw another var for b.\n\n\n\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 101\n   Unobserved stochastic nodes: 4\n   Total graph size: 507\n\nInitializing model\n\n\nAs usual, check the convergence diagnostics.\n\n\nCode\npar(mar = c(2., 1, 2., 1))\nplot(mod2_sim)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod2_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]       1.02       1.06\nb[2]       1.02       1.06\nb[3]       1.00       1.00\nsig        1.00       1.00\n\nMultivariate psrf\n\n1.02\n\n\nCode\nautocorr.diag(mod2_sim)\n\n\n             b[1]       b[2]         b[3]         sig\nLag 0  1.00000000 1.00000000  1.000000000 1.000000000\nLag 1  0.95252030 0.95238535  0.058764945 0.024410101\nLag 5  0.79164054 0.79173989 -0.003923887 0.015577955\nLag 10 0.63340207 0.63318712  0.005500414 0.007958675\nLag 50 0.09064409 0.09007222 -0.009372781 0.006403192\n\n\n\n\nCode\n#autocorr.plot(mod2_sim,auto.layout=FALSE )\nautocorr.plot(mod2_csim,auto.layout=FALSE )\n\n\n\n\n\n\n\n\nFigure 6: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: auto-correlation plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: auto-correlation plot\n\n\n\n\n\n\n\nCode\neffectiveSize(mod2_sim)\n\n\n      b[1]       b[2]       b[3]        sig \n  349.6500   351.8726 13408.9117 12466.6500 \n\n\nWe can get a posterior summary of the parameters in our model.\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 1001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nb[1]  7.1210 0.44239 0.0036121      0.0235178\nb[2] -0.5181 0.07164 0.0005850      0.0037924\nb[3]  0.7890 0.35350 0.0028863      0.0030525\nsig   0.9530 0.06730 0.0005495      0.0006036\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%     75%   97.5%\nb[1]  6.2339  6.8216  7.1283  7.4306  7.9483\nb[2] -0.6520 -0.5684 -0.5198 -0.4693 -0.3742\nb[3]  0.0991  0.5535  0.7859  1.0240  1.4929\nsig   0.8311  0.9059  0.9494  0.9956  1.0941\n\n\nIt looks like there is a positive relationship between oil-production and log-infant mortality. Because these data are merely observational, we cannot say that oil-production causes an increase in infant mortality (indeed that most certainly isn’t the case), but we can say that they are positively correlated.\nNow let’s check the residuals.\n\n\nCode\nX2 = cbind(rep(1.0, data1_jags$n), data2_jags$log_income, data2_jags$is_oil)\nhead(X2)\n\n\n     [,1]     [,2] [,3]\n[1,]    1 8.139149    0\n[2,]    1 8.116716    0\n[3,]    1 8.115521    0\n[4,]    1 8.466110    0\n[5,]    1 8.522976    0\n[6,]    1 8.105308    0\n\n\n\n\nCode\n(pm_params2 = colMeans(mod2_csim)) # posterior mean\n\n\n      b[1]       b[2]       b[3]        sig \n 7.1210192 -0.5180532  0.7890402  0.9530471 \n\n\n\n\nCode\nyhat2 = drop(X2 %*% pm_params2[1:3])\nresid2 = data2_jags$y - yhat2\nplot(resid2) # against data index\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(yhat2, resid2) # against predicted values\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(yhat1, resid1) # residuals from the first model\n\n\n\n\n\n\n\n\n\n\n\nCode\nsd(resid2) # standard deviation of residuals\n\n\n[1] 0.6488827\n\n\nThese look much better, although the residuals for Saudi Arabia and Libya are still more than three standard deviations away from the mean of the residuals. We might consider adding the other covariate region, but instead let’s look at another option when we are faced with strong outliers.\n\n4.1.1 Student-t likelihood\n\nLet’s consider changing the likelihood.\nThe normal likelihood has thin tails (almost all of the probability is concentrated within the first few standard deviations from the mean).\nThis does not accommodate outliers well.\nConsequently, models with the normal likelihood might be overly-influenced by outliers.\nRecall that the t distribution is similar to the normal distribution, but it has thicker tails which can accommodate outliers.\n\nThe t linear model might look something like this. Notice that the t distribution has three parameters, including a positive “degrees of freedom” parameter. The smaller the degrees of freedom, the heavier the tails of the distribution. We might fix the degrees of freedom to some number, or we can assign it a prior distribution.\n\n\nCode\ncurve(dnorm(x), from = -5, to = 5)\ncurve(dt(x,1), from = -5, to = 5,col=\"red\", add = TRUE)\n\n\n\n\n\n\nnormal and t distributions\n\n\n\n\n\nCode\nmod3_string = \" model {\n1    for (i in 1:length(y)) {\n        y[i] ~ dt( mu[i], tau, df )\n        mu[i] = b[1] + b[2]*log_income[i] + b[3]*is_oil[i]\n    }\n    \n    for (i in 1:3) {\n        b[i] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n2    nu ~ dexp(1.0)\n3    df = nu + 2.0\n    \n4    tau ~ dgamma(5/2.0, 5*10.0/2.0)\n5    sig = sqrt( 1.0 / tau * df / (df - 2.0) )\n}\"\n\n\n\n1\n\nwe replaced normal likelihood with a student t likelihood which has thicker tails\n\n2\n\n\\nu nu is the degrees of freedom (dof) but the outcome can be 0 or 1\n\n3\n\nwe force the degrees of freedom dof&gt;2 to guarantee the existence of mean and variance in the t dist.\n\n4\n\n\\tau tau is the inverse scale is close to, but not equal to the precision from above so we use the same prior as we used for precision.\n\n5\n\n\\sigma sig standard deviation of errors is a deterministic function of tau, and df\n\n\n\n\nWe fit this model.\n\n\nCode\nset.seed(73)\ndata3_jags = list(y=dat$loginfant, log_income=dat$logincome,\n                  is_oil=as.numeric(dat$oil==\"yes\"))\n\nparams3 = c(\"b\", \"sig\")\n\ninits3 = function() {\n    inits = list(\"b\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod3 = jags.model(textConnection(mod3_string), data=data3_jags, inits=inits3, n.chains=3)\nupdate(mod3, 1e3) # burn-in\n\nmod3_sim = coda.samples(model=mod3,\n                        variable.names=params3,\n                        n.iter=5e3)\n\nmod3_csim = as.mcmc(do.call(rbind, mod3_sim)) # combine multiple chains\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 101\n   Unobserved stochastic nodes: 5\n   Total graph size: 512\n\nInitializing model\n\n\ncheck MCMC convergence visually\n\n\nCode\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod3_sim)\n\n\n\n\n\n\n\n\n\ncheck MCMC convergence quantitatively using Rubin Gelman\n\n\nCode\ngelman.diag(mod3_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]          1       1.01\nb[2]          1       1.01\nb[3]          1       1.00\nsig           1       1.00\n\nMultivariate psrf\n\n1\n\n\n\n\nCode\neffectiveSize(mod3_sim)\n\n\n      b[1]       b[2]       b[3]        sig \n  272.8130   282.0102  8496.5579 10331.1590",
    "crumbs": [
      "2. Techniques and Models",
      "Notes - Linear regression"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-compare-models-using-deviance-information-criterion-dic",
    "href": "C2-L07.html#sec-compare-models-using-deviance-information-criterion-dic",
    "title": "Notes - Linear regression",
    "section": "4.2 Compare models using Deviance information criterion (DIC)",
    "text": "4.2 Compare models using Deviance information criterion (DIC)\nWe have now proposed three different models. How do we compare their performance on our data? In the previous course, we discussed estimating parameters in models using the maximum likelihood method. Similarly, we can choose between competing models using the same idea.\nWe will use a quantity known as the deviance information criterion (DIC). It essentially calculates the posterior mean of the log-likelihood and adds a penalty for model complexity.\nLet’s calculate the DIC for our first two models:\nthe simple linear regression on log-income,\n\n\nCode\ndic.samples(mod1, n.iter=1e3)\n\n\nMean deviance:  231.2 \npenalty 2.92 \nPenalized deviance: 234.1 \n\n\nand the second model where we add oil production.\n\n\nCode\ndic.samples(mod2, n.iter=1e3)\n\n\nMean deviance:  225.6 \npenalty 4.12 \nPenalized deviance: 229.7 \n\n\nand the second model where we introduce the Student t likelihood.\n\n\nCode\ndic.samples(mod3, n.iter=1e3)\n\n\nMean deviance:  230 \npenalty 3.703 \nPenalized deviance: 233.7 \n\n\nThe first number is the Monte Carlo estimated posterior mean deviance, which equals -2 times the log-likelihood (plus a constant that will be irrelevant for comparing models). Because of that -2 factor, a smaller deviance means a higher likelihood.\nNext, we are given a penalty for the complexity of our model. This penalty is necessary because we can always increase the likelihood of the model by making it more complex to fit the data exactly. We don’t want to do this because over-fit models generalize poorly. This penalty is roughly equal to the effective number of parameters in your model. You can see this here. With the first model, we had a variance parameter and two betas, for a total of three parameters. In the second model, we added one more beta for the oil effect.\nWe add these two quantities to get the DIC (the last number). The better-fitting model has a lower DIC value. In this case, the gains we receive in deviance by adding the is_oil covariate outweigh the penalty for adding an extra parameter. The final DIC for the second model is lower than for the first, so we would prefer using the second model.\nWe encourage you to explore different model specifications and compare their fit to the data using DIC. Wikipedia provides a good introduction to DIC and we can find more details about the JAGS implementation through the rjags package documentation by entering ?dic.samples in the R console.\n\n\nCode\n#?dic.samples",
    "crumbs": [
      "2. Techniques and Models",
      "Notes - Linear regression"
    ]
  },
  {
    "objectID": "C2-L07.html#sec-regression-diagnostics",
    "href": "C2-L07.html#sec-regression-diagnostics",
    "title": "Notes - Linear regression",
    "section": "4.3 Regression Diagnostics",
    "text": "4.3 Regression Diagnostics\nIn production we want to flag regression issues in an automated fashion. However while we develop models we should try to examine these issues visually.\nRegression diagnostics help identify:\n\nshortcoming of our model and the preferred ways to improve them\n\ntransforms of variables\ndifferent likelihood\nadding missing covariate relations to remove patterns in the residuals\nincreasing interpretability by removing covariates that do not contribute to the fit.\n\nissues in the data\n\ntransformation\n\n\nwe should consider the following issues: 1. testing heteroscedasticity with the Breusch-Pagan test\nLet’s try to cover the diagnostic plots which help us validate a regression model.\n\n4.3.1 Residuals vs Fitted\n\nThe “residuals versus fits plot” is the most first diagnostic tool we\nshould look at to determine if the regression is valid. If the regression assumptions are violated we should be able to identify the issues and possibly correct them.\nIt is a scatter plot of residuals on the y axis and fitted values (estimated responses) on the x axis.\nThe plot can be used to detect:\n\nnon-linearity,\nunequal error variances, and\noutliers.\n\n\n\n\nCode\nplot(lmod0, 1)\n\n\n\n\n\nResiduals vs Fitted plot\n\n\n\n\nResiduals will enable us to assess visually whether an appropriate model has been fit to the data no matter how many predictor variables are used. We can checking the validity of a linear regression model by plotting residuals versus x and look for patterns. - Lack of a discernible pattern is indicative of a valid model. - A pattern is is indicative that a function or transformation of X is missing from the model.\n\n\n\n\n\n\nImportantWhat to look for\n\n\n\nLook for patterns that can indicate non-linearity,\n\nthat the residuals all are high in some areas and low in others. Change in variability as X changes - U shape missing quadratic term · we can get this plot as follows.\n\nThe blue line is there to aid the eye - it should ideally be relatively close to a straight line (in this case, it isn’t perfectly straight, which could indicate a mild non-linearity).\n\n\n\n\n4.3.2 QQ plot of the residuals\nThis plot shows if residuals are normally distributed. Do residuals follow a straight line well or do they deviate severely?\nThe regression is valid if the residuals are lined well on the straight dashed line.\nwe can get this plot as follows\n\n\nCode\nplot(lmod0, 2)\n\n\n\n\n\n\n\n\n\nnotice that the two outliers are labeled and should be reviewed for - removal - more robust likelihood\nfor more info see understanding QQ plots\n\n\n4.3.3 Scale Location plot\nThis plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance (homoscedasticity). It’s good if you see a horizontal line with equally (randomly) spread points.\n\n\nCode\nplot(lmod0, 3)\n\n\n\n\n\n\n\n\n\nin this case: - most of the points are to the right - the red line is almost flat which is good - there is increasing variance after 80\n\n\n4.3.4 Cook’s Distance\n\nOriginally introduced in (Cook 1977a) Cook’s Distance is an estimate of the influence of a data point.\nIt takes into account both the leverage and residual of each observation.\nCook’s Distance is a summary of how much a regression model changes when the ith observation is removed.\nWhen it comes to outliers we care about outliers that have a high Cook’s distance as they can have a large impact on the regression model. by shifting the sample fit from the population fit.\nAnother aspect of Cook’s distance is it can be used to identify regions of the design space where the model is poorly supported by the data - i.e. where the model is extrapolating and if we can get more data in that region we can improve the model.\n\n\n\nCode\nplot(lmod0, 4)\n\n\n\n\n\n\n\n\n\nUsed to detect highly influential outliers, i.e. points that can shift the sample fit from the population fit. For large sample sizes, a rough guideline is to consider values above 4/(n-p), where n is the sample size and p is the number of predictors including the intercept, to indicate highly influential points.\nsee Williams (1987)\n\n\n4.3.5 Residuals vs Leverage\n\n\nCode\nplot(lmod0, 5)\n\n\n\n\n\n\n\n\n\nCode\n#plot(mod3, 5)\n\n\nThis plot helps us to sort through the outliers, if there are any. Not all outliers are influential in linear regression analysis. Even though data have extreme values, they might not be influential to determine a regression line. i.e. the fit wouldn’t be much different if we choose to omit them from the analysis. If a point is able to exert a influence on the regression line we call it a high leverage point. Even in this case it might not alter the trend. So we want to identify high leverage points that are at a large distance from their predictor’s mean.\nUnlike the other plots, this time patterns are not relevant. We watch out for outlying values at the upper right corner or at the lower right corner. Those spots are the places where cases can be influential against a regression line. Look for cases outside of the dashed lines. When cases are outside of the dashed lines (meaning they have high “Cook’s distance” scores), the cases are influential to the regression results. The regression results will be altered if we exclude those cases.\nIn this case we see that the pints are within the cook’s distance contours so our outliers are not high leverage points.\n\n\n4.3.6 Cook’s Distance vs Leverage\n\n\nCode\nplot(lmod0, 6)\n\n\n\n\n\n\n\n\nFigure 10: Cooks distance v.s. Leverage\n\n\n\n\n\nCook’s distance and leverage are used to detect highly leverage points, i.e. data points that can shift the sample fit from the population fit.\nFor large sample sizes, a rough guideline is to consider Cook’s distance values above 1 to indicate highly influential points and leverage values greater than 2 times the number of predictors divided by the sample size to indicate high leverage observations. High leverage observations are ones which have predictor values very far from their averages, which can greatly influence the fitted model.\nThe contours in the scatterplot are standardized residuals labelled with their magnitudes\nsee Williams (1987)\n\n\n4.3.7 Python\n\nhttps://emredjan.xyz/blog/2017/07/11/emulating-r-plots-in-python/\nhttps://towardsdatascience.com/going-from-r-to-python-linear-regression-diagnostic-plots-144d1c4aa5a\nhttps://modernstatisticswithr.com/regression.html",
    "crumbs": [
      "2. Techniques and Models",
      "Notes - Linear regression"
    ]
  },
  {
    "objectID": "C3-L02.html",
    "href": "C3-L02.html",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "",
    "text": "NoteTODO\n\n\n\n\n\n\nIn the EM algorithm generate animation from the outputs of the algorithm steps + prior & posterior\nAdd example for carb data",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#em-algorithms-for-mixture-models",
    "href": "C3-L02.html#em-algorithms-for-mixture-models",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.1 EM algorithms for Mixture Models",
    "text": "1.1 EM algorithms for Mixture Models\n\n\n\n\nEM - Challenge\n\n\n\n\nEM - Steps\n\n\n\n\nEM - Deep Dive\n\n\n\nEM algorithm comes up a lot in NLP and other fields so it is worthwhile to understand it the way we will do so in the course.\nIt also important that the EM algorithm we use for mixture models is from the 1970s and is not the same as the general EM algorithm. c.f. (Dempster, Laird, and Rubin 1977)\nThe EM algorithm is iterative and consists of two steps: the E-step and the M-step. The E-step computes the expected value of the complete-data log-likelihood given the observed data and the current parameter estimates, while the M-step maximizes this expected log-likelihood with respect to the parameters. However before we start these steps we need to set initial values for the parameters.\nE step: Set\n\nQ(\\omega,\\theta \\mid \\omega^{(t)}, \\theta^{(t)},x) = E_{c \\mid \\omega^{(t)},\\theta^{(t)}, x} \\left[ \\log p(x,c \\mid \\omega,\\theta) \\right]\n\\tag{1}\nWhere c is the latent variable indicating the component from which each observation was generated, \\omega are the weights, and \\theta are the parameters of the Gaussian components (means and standard deviations).\nM step: Set\n\n\\hat{\\omega}^{(t+1)},\\hat{\\theta}^{(t+1)} = \\arg \\max_{\\omega,\\theta} Q(\\omega,\\theta \\mid \\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)},y)\n\\tag{2}\nwhere \\hat{\\omega}^{(t)} and \\hat{\\theta}^{(t)} are the current estimates of the parameters, and y is the observed data.\nThese two steps are repeated until convergence, which is typically defined as the change in the full-data log-likelihood Q function being below a certain threshold.\nA key point is that if we condition each component independently on the \\omega, \\theta, x we can write\n\np(c_i=k \\mid \\omega, \\theta, x_i) = \\frac{\\omega_k g_k(x_i \\mid \\theta_k)}{\\sum_{j=1}^{K} \\omega_j g_j(x_i \\mid \\theta_j)}= v_{ik}(\\omega, \\theta)\n\nwhere the value of v_{ik} is interpreted as the probability that the i-th observation comes from the k-th component of the mixture assuming the population parameters \\omega and \\theta.",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#em-for-general-mixture",
    "href": "C3-L02.html#em-for-general-mixture",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.2 EM for general Mixture",
    "text": "1.2 EM for general Mixture",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#em-for-location-mixture-of-gaussians",
    "href": "C3-L02.html#em-for-location-mixture-of-gaussians",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.3 EM for location Mixture of Gaussians",
    "text": "1.3 EM for location Mixture of Gaussians\n\n\n\n\nthe responsibility\n\n\n\n\nthe derivative of Q wrt to w\n\n\n\n\nthe derivative of Q wrt to mu\n\n\n\n\nthe derivative of Q wrt to sigma",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#sec-em-example-1",
    "href": "C3-L02.html#sec-em-example-1",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.4 EM example 1",
    "text": "1.4 EM example 1\nThis video covers the code sample given in Listing 4 below. It is a simple implementation of the EM algorithm for fitting a 2-component Gaussian location mixture model to simulated data.\n\nThis code sample is both cool and awkward.\n\nIt is cool because it provides a step-by-step implementation of the EM algorithm, which is a fundamental concept in statistics and machine learning.\nIt is not broken in to functions lacks useful variables naming which would reduce the amounts of comments and cognitive load.\n\nHowever it does provide nice visualizations of the EM algorithm in action - particularly if run inside of RStudio IDE (as shown in the video).\nwould be interesting to make the number of components be drawn from a distribution rather than fixed at 2, then run the EM algorithm for multiple draws and pick the one with the best fit.\nLater on we learn about using BIC to select the number of components in a mixture model, which is a more principled approach than simply fixing the number of components at 2. However it stills seems that the number of components might be a RV even if it’s prior would be centred at the BIC estimate.",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#sec-em-code-example-1",
    "href": "C3-L02.html#sec-em-code-example-1",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.5 Sample code for EM example 1",
    "text": "1.5 Sample code for EM example 1\n\n\n\n\nListing 1: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\n\n## Step 0 - Generate data from a mixture with 2 components:\n\n## Ground Truth parameters initialization\nKK         = 2          # Number of components of the mixture\nw.true     = 0.6        # GT True weights associated with the components\nmu.true    = rep(0, KK) # initialize the true means list\nmu.true[1] = 0   # GT mean for the first component\nmu.true[2] = 5   # GT mean for the second component\nsigma.true = 1   # GT standard deviation of all components\n\nn  = 120         # Number of synthetic samples to generate\n\n# simulate the latent variables for the component indicator function\ncc = sample(1:KK, n, replace=T, prob=c(w.true,1-w.true))\nx  = rep(0, n)   # initialize the data vector x (or load data)\n\nfor(i in 1:n){ # for each observation\n  # sample from a distribution with mean selected by component indicator\n  # the SD is the same for all components as this is a location mixture\n  x[i] = rnorm(1, mu.true[cc[i]], sigma.true)\n}\n\n# Plot the true density\npar(mfrow=c(1,1))\nxx.true = seq(-8,11,length=200)\nyy.true = w.true*dnorm(xx.true, mu.true[1], sigma.true) + \n          (1-w.true)*dnorm(xx.true, mu.true[2], sigma.true) \nplot(xx.true, yy.true, type=\"l\", xlab=\"x\", ylab=\"True density\", lwd=2)\npoints(x, rep(0,n), col=cc)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 2: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\n## Run the actual EM algorithm\n## Initialize the parameters\nw     = 1/2                         #Assign equal weight to each component to start with\nmu    = rnorm(KK, mean(x), sd(x))   #Random cluster centers randomly spread over the support of the data\nsigma = sd(x)                       #Initial standard deviation\n\n# Plot the initial guess for the density\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(yy)), xlab=\"x\", ylab=\"Initial density\")\npoints(x, rep(0,n), col=cc)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 3: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\ns  = 0\nsw = FALSE\nQQ = -Inf\nQQ.out = NULL\nepsilon = 10^(-5)\n\n\n##Checking convergence of the algorithm\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  v[,1] = log(w) + dnorm(x, mu[1], sigma, log=TRUE)    #Compute the log of the weights\n  v[,2] = log(1-w) + dnorm(x, mu[2], sigma, log=TRUE)  #Compute the log of the weights\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  # Weights\n  w = mean(v[,1])\n  mu = rep(0, KK)\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Standard deviations\n  sigma = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n    }\n  }\n  sigma = sqrt(sigma/sum(v))\n  \n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    QQn = QQn + v[i,1]*(log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)) +\n                v[i,2]*(log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE))\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n  #Plot current estimate over data\n  layout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\n  par(mar=c(3.1,4.1,0.5,0.5))\n  plot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n  \n  par(mar=c(5,4,1.5,0.5))\n  xx = seq(-8,11,length=200)\n  yy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\n  plot(xx, yy, type=\"l\", ylim=c(0, max(c(yy,yy.true))), main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), lwd=2, col=\"red\", lty=2, xlab=\"x\", ylab=\"Density\")\n  lines(xx.true, yy.true, lwd=2)\n  points(x, rep(0,n), col=cc)\n  legend(6,0.22,c(\"Truth\",\"Estimate\"),col=c(\"black\",\"red\"), lty=c(1,2))\n}\n\n\n\n\n\n[1] \"1 -343.425690465737\"\n\n\n\n\n\n\n\n\n\n[1] \"2 -339.993932553505\"\n\n\n\n\n\n\n\n\n\n[1] \"3 -333.742916535535\"\n\n\n\n\n\n\n\n\n\n[1] \"4 -322.087405606262\"\n\n\n\n\n\n\n\n\n\n[1] \"5 -299.927704463736\"\n\n\n\n\n\n\n\n\n\n[1] \"6 -265.515667629269\"\n\n\n\n\n\n\n\n\n\n[1] \"7 -246.004047691222\"\n\n\n\n\n\n\n\n\n\n[1] \"8 -243.982291955643\"\n\n\n\n\n\n\n\n\n\n[1] \"9 -243.880207718536\"\n\n\n\n\n\n\n\n\n\n[1] \"10 -243.873888447856\"\n\n\n\n\n\n\n\n\n\n[1] \"11 -243.873372520873\"\n\n\n\n\n\n\n\n\n\n\n\nListing 4: EM algorithm for fitting a 2-component Gaussian location mixture\n\n\n\nCode\n#Plot final estimate over data\nlayout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\npar(mar=c(3.1,4.1,0.5,0.5))\nplot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n\npar(mar=c(5,4,1.5,0.5))\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(c(yy,yy.true))), main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), lwd=2, col=\"red\", lty=2, xlab=\"x\", ylab=\"Density\")\nlines(xx.true, yy.true, lwd=2)\npoints(x, rep(0,n), col=cc)\nlegend(6,0.22,c(\"Truth\",\"Estimate\"),col=c(\"black\",\"red\"), lty=c(1,2), bty=\"n\")",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#em-example-2",
    "href": "C3-L02.html#em-example-2",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.6 EM example 2",
    "text": "1.6 EM example 2",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#sample-code-for-em-example-2",
    "href": "C3-L02.html#sample-code-for-em-example-2",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.7 Sample code for EM example 2",
    "text": "1.7 Sample code for EM example 2\nThis variant differs from the code sample above in that it uses the mvtnorm package to generate multivariate normal distributions. It also uses the ellipse package to plot the ellipses around the means of the components.\n\n\nCode\n#### Example of an EM algorithm for fitting a mixtures of K p-variate Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)    # Multivariate normals are not default in R\nlibrary(ellipse)    # Required for plotting\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\nset.seed(63252)     # For reproducibility\n\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nn  = 120\ncc = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc[i],], Sigma.true[cc[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc, type=\"n\", xlab=expression(x[1]), ylab=expression(x[2]))\ntext(x[,1], x[,2], seq(1,n), col=cc, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\n\n\n\n\n\n\n\n\n\nCode\n#title(main=\"Data + True Components\")\n\n\n### Run the EM algorithm\n## Initialize the parameters\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\ns       = 0\nsw      = FALSE\nQQ      = -Inf\nQQ.out  = NULL\nepsilon = 10^(-5)\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(k in 1:KK){\n    v[,k] = log(w[k]) + dmvnorm(x, mu[k,], Sigma[k,,],log=TRUE)  #Compute the log of the weights\n  }\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w     = apply(v,2,mean)\n  mu    = array(0, dim=c(KK, p))\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0, dim=c(KK, p, p))\n  for(k in 1:KK){\n    for(i in 1:n){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      QQn = QQn + v[i,k]*(log(w[k]) + dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n  #Plot current components over data\n  layout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\n  par(mar=c(3.1,4.1,0.5,0.5))\n  plot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\")\n  \n  par(mar=c(5,4,1,0.5))\n  plot(x[,1], x[,2], col=cc, main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), \n       xlab=expression(x[1]), ylab=expression(x[2]), lwd=2)\n  for(k in 1:KK){\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n  }\n}\n\n\n[1] \"1 -582.05125374123\"\n\n\n\n\n\n\n\n\n\n[1] \"2 -559.067366495985\"\n\n\n\n\n\n\n\n\n\n[1] \"3 -543.8803866857\"\n\n\n\n\n\n\n\n\n\n[1] \"4 -527.840823447868\"\n\n\n\n\n\n\n\n\n\n[1] \"5 -511.540892774085\"\n\n\n\n\n\n\n\n\n\n[1] \"6 -483.797796090743\"\n\n\n\n\n\n\n\n\n\n[1] \"7 -464.070439621255\"\n\n\n\n\n\n\n\n\n\n[1] \"8 -455.865736477295\"\n\n\n\n\n\n\n\n\n\n[1] \"9 -455.214732499627\"\n\n\n\n\n\n\n\n\n\n[1] \"10 -455.176042939796\"\n\n\n\n\n\n\n\n\n\n[1] \"11 -455.171446608628\"\n\n\n\n\n\n\n\n\n\n[1] \"12 -455.170550189128\"\n\n\n\n\n\n\n\n\n\nCode\n#Plot current components over data\nlayout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\npar(mar=c(3.1,4.1,0.5,0.5))\nplot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n\npar(mar=c(5,4,1,0.5))\nplot(x[,1], x[,2], col=cc, main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#sec-mixture-of-log-gaussians",
    "href": "C3-L02.html#sec-mixture-of-log-gaussians",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.8 Mixture of Log Gaussians",
    "text": "1.8 Mixture of Log Gaussians\n\n\n\n\n\n\nNotePrompt\n\n\n\n\n\nIf your data had support on the positive real numbers rather than the whole real line, how could you use the EM algorithm you just learned to instead fit a mixture of log-Gaussian distributions? Would you need to recode your algorithm?\n\nResponse\nUpdating the algorithm is nontrivial - it requires derivatives for each parameter. Depending on the distribution, we may need to add custom code to update each. We also need to update the distribution if these are changed.\nSo while the algorithm does not change, the code may change quite a bit.",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#sec-advanced-em-algorithms",
    "href": "C3-L02.html#sec-advanced-em-algorithms",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.9 Advanced EM algorithms",
    "text": "1.9 Advanced EM algorithms",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02.html#hw-the-em-for-zip-mixtures",
    "href": "C3-L02.html#hw-the-em-for-zip-mixtures",
    "title": "The EM algorithm for zero-inflated mixtures",
    "section": "1.10 HW: The EM for ZIP mixtures",
    "text": "1.10 HW: The EM for ZIP mixtures\nData on the lifetime (in years) of fuses produced by the ACME Corporation is available in the file fuses.csv:\nProvide the EM algorithm to fit the mixture model",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for zero-inflated mixtures"
    ]
  },
  {
    "objectID": "C3-L02-Ex1.html",
    "href": "C3-L02-Ex1.html",
    "title": "The EM algorithm for Zero-Inflated Mixtures",
    "section": "",
    "text": "In the lessons we mentioned that Zero-Inflated Poisson (ZIP) models arises naturally in biology when analyzing nest size data since many birds fail to mate or lay eggs. As such they will have zero eggs in their nests. In this exercise, we will use the EM algorithm to fit a ZIP model to a dataset of nest sizes.\n\n\n\n\n\n\nNoteInstructions\n\n\n\n\nA biologist is interest in characterizing the number of eggs laid by a particular bird species. To do this, they sample\nn=300n, nests on a site in Southern California. The observations are contained in the attached file data/nestsize.csv:\ngenerate a barplot with the empirical frequencies of all the integers included in the sample.\n\nAs you can see, the Poisson distribution underestimates the number of empty nests in the data, and overestimates the number of nests with either 1 or 2 eggs. To address this, you are asked to modify the implementation of the EM algorithm contained in the Reading “Sample code for EM example 1” so that you can fit a mixture between a point mass at zero and a Poisson distribution (we call this a “zero-inflated Poisson” distribution):\n\nf(x) = w \\delta_0(x) + (1-w) \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x \\in \\{0, 1, 2, \\ldots\\}\n\\tag{1}\nwhere w is the weight associated with the point mass at zero, \\lambda is the parameter of the Poisson distribution, and \\delta_0(x) represents the degenerate distribution placing all of its mass at zero.\n\nYou then should run your algorithm with the data contained in nestsize.csv and report the values of the estimates that you obtained, rounded to two decimal places. ​\n\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nThe code you generate should follow the same structure as “Sample code for EM example 1”. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect the fact that\n\nyou provided a reasonable initial point for you algorithm,\nthe observation-specific weights v_i,k are computed correctly (E step),\nthe formulas for the maximum of the Q functions are correct (M step),\nthe converge check is correct, and\nthe numerical values that you obtain are correct.\n\nTo simplify the peer-review process, assume that component 1 corresponds to the point mass at zero, while component 2 corresponds to the Poisson distribution.\nThere are two things that make this problem more challenging than the ones we have used for illustrations so far:\n\nthe two components in the mixture belong to different families, and\neach component has a very different support.\n\nkeep these two circumstances in mind when working on your answer.\n\n\n\n\nCode\n# Load the nest size data\n\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\nnestsize &lt;- read.csv(\"data/nestsize.csv\",header=FALSE)\ncolnames(nestsize) &lt;- c(\"n\")\nx &lt;- nestsize$n\nn &lt;- length(x) # Number of observations\n# how many rows in the data\nnrow(nestsize)\n\n\n[1] 300\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 128\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, breaks=seq(0, max(x), by=1), freq=FALSE, xlab=\"Number of eggs\", ylab=\"Density\", main=\"Empirical distribution of nest sizes\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# EM algorithm for fitting a ZIP\n\n## Run the actual EM algorithm\n## Initialize the parameters\nKK         = 2                     # Number of components\nw     = 1/2                        # equal weights                     #Initial standard deviation\n\nlambda = mean(x) # initial guess for the mean\n\ns  = 0\nsw = FALSE\nQQ = -Inf\nQQ.out = NULL\nepsilon = 10^(-5)\n\nwhile(!sw){ ## run until convergence switch becomes TRUE\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(i in 1:n){\n    if (x[i] == 0){\n      # if the observation is zero it may be due to either component so we assign each a value based on the weights * pdf\n      v[i,1] = w * 1 # delta is 1 at zero\n      v[i,2] = (1-w) * dpois(x[i], lambda) # the weight for the second component\n      v[i,] = v[i,]/sum(v[i,]) # normalize \n    } else {\n      v[i,1] = 0\n      v[i,2] = 1\n      # normalized\n    }\n  }\n  \n  ## M step\n  # Weights\n  w = mean(v[,1]) \n  # parameters\n  lambda = sum(x)/sum(v[,2]) # normalize\n  \n  ##Check convergence\n  ## QQn is the new value of the Q function\n  ## QQ is the old value of the Q function\n  QQn = 0\n  for(i in 1:n){\n    if(x[i] == 0){\n      # log is used to avoid numerical underflow\n      QQn = QQn + v[i,1]*log(w) + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }else{\n      QQn = QQn + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n\n}\n\n\n[1] \"1 -576.591134395629\"\n[1] \"2 -560.13333821497\"\n[1] \"3 -555.36650787464\"\n[1] \"4 -554.153118451655\"\n[1] \"5 -553.854920699012\"\n[1] \"6 -553.78227912419\"\n[1] \"7 -553.764621578937\"\n[1] \"8 -553.760331674038\"\n\n\n\n\nCode\n# w\n# lambda\n\ncat(\"w = \", round(w, 2), \"\\n\")\n\n\nw =  0.4 \n\n\nCode\ncat(\"lambda = \", round(lambda, 2), \"\\n\")\n\n\nlambda =  3.07",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for Zero-Inflated Mixtures"
    ]
  },
  {
    "objectID": "C3-L02-Ex1.html#hw---simulation-of-poisson-mixture-model",
    "href": "C3-L02-Ex1.html#hw---simulation-of-poisson-mixture-model",
    "title": "The EM algorithm for Zero-Inflated Mixtures",
    "section": "",
    "text": "In the lessons we mentioned that Zero-Inflated Poisson (ZIP) models arises naturally in biology when analyzing nest size data since many birds fail to mate or lay eggs. As such they will have zero eggs in their nests. In this exercise, we will use the EM algorithm to fit a ZIP model to a dataset of nest sizes.\n\n\n\n\n\n\nNoteInstructions\n\n\n\n\nA biologist is interest in characterizing the number of eggs laid by a particular bird species. To do this, they sample\nn=300n, nests on a site in Southern California. The observations are contained in the attached file data/nestsize.csv:\ngenerate a barplot with the empirical frequencies of all the integers included in the sample.\n\nAs you can see, the Poisson distribution underestimates the number of empty nests in the data, and overestimates the number of nests with either 1 or 2 eggs. To address this, you are asked to modify the implementation of the EM algorithm contained in the Reading “Sample code for EM example 1” so that you can fit a mixture between a point mass at zero and a Poisson distribution (we call this a “zero-inflated Poisson” distribution):\n\nf(x) = w \\delta_0(x) + (1-w) \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x \\in \\{0, 1, 2, \\ldots\\}\n\\tag{1}\nwhere w is the weight associated with the point mass at zero, \\lambda is the parameter of the Poisson distribution, and \\delta_0(x) represents the degenerate distribution placing all of its mass at zero.\n\nYou then should run your algorithm with the data contained in nestsize.csv and report the values of the estimates that you obtained, rounded to two decimal places. ​\n\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nThe code you generate should follow the same structure as “Sample code for EM example 1”. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect the fact that\n\nyou provided a reasonable initial point for you algorithm,\nthe observation-specific weights v_i,k are computed correctly (E step),\nthe formulas for the maximum of the Q functions are correct (M step),\nthe converge check is correct, and\nthe numerical values that you obtain are correct.\n\nTo simplify the peer-review process, assume that component 1 corresponds to the point mass at zero, while component 2 corresponds to the Poisson distribution.\nThere are two things that make this problem more challenging than the ones we have used for illustrations so far:\n\nthe two components in the mixture belong to different families, and\neach component has a very different support.\n\nkeep these two circumstances in mind when working on your answer.\n\n\n\n\nCode\n# Load the nest size data\n\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\nnestsize &lt;- read.csv(\"data/nestsize.csv\",header=FALSE)\ncolnames(nestsize) &lt;- c(\"n\")\nx &lt;- nestsize$n\nn &lt;- length(x) # Number of observations\n# how many rows in the data\nnrow(nestsize)\n\n\n[1] 300\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 128\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, breaks=seq(0, max(x), by=1), freq=FALSE, xlab=\"Number of eggs\", ylab=\"Density\", main=\"Empirical distribution of nest sizes\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# EM algorithm for fitting a ZIP\n\n## Run the actual EM algorithm\n## Initialize the parameters\nKK         = 2                     # Number of components\nw     = 1/2                        # equal weights                     #Initial standard deviation\n\nlambda = mean(x) # initial guess for the mean\n\ns  = 0\nsw = FALSE\nQQ = -Inf\nQQ.out = NULL\nepsilon = 10^(-5)\n\nwhile(!sw){ ## run until convergence switch becomes TRUE\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(i in 1:n){\n    if (x[i] == 0){\n      # if the observation is zero it may be due to either component so we assign each a value based on the weights * pdf\n      v[i,1] = w * 1 # delta is 1 at zero\n      v[i,2] = (1-w) * dpois(x[i], lambda) # the weight for the second component\n      v[i,] = v[i,]/sum(v[i,]) # normalize \n    } else {\n      v[i,1] = 0\n      v[i,2] = 1\n      # normalized\n    }\n  }\n  \n  ## M step\n  # Weights\n  w = mean(v[,1]) \n  # parameters\n  lambda = sum(x)/sum(v[,2]) # normalize\n  \n  ##Check convergence\n  ## QQn is the new value of the Q function\n  ## QQ is the old value of the Q function\n  QQn = 0\n  for(i in 1:n){\n    if(x[i] == 0){\n      # log is used to avoid numerical underflow\n      QQn = QQn + v[i,1]*log(w) + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }else{\n      QQn = QQn + v[i,2]*(log(1-w) + dpois(x[i], lambda, log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n\n}\n\n\n[1] \"1 -576.591134395629\"\n[1] \"2 -560.13333821497\"\n[1] \"3 -555.36650787464\"\n[1] \"4 -554.153118451655\"\n[1] \"5 -553.854920699012\"\n[1] \"6 -553.78227912419\"\n[1] \"7 -553.764621578937\"\n[1] \"8 -553.760331674038\"\n\n\n\n\nCode\n# w\n# lambda\n\ncat(\"w = \", round(w, 2), \"\\n\")\n\n\nw =  0.4 \n\n\nCode\ncat(\"lambda = \", round(lambda, 2), \"\\n\")\n\n\nlambda =  3.07",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for Zero-Inflated Mixtures"
    ]
  },
  {
    "objectID": "C3-L01-Ex5.html",
    "href": "C3-L01-Ex5.html",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nModify the code above to sample 200 random numbers from a mixture of 3 Poisson distributions with means 1, 2 and 6 and weights 0.7, 0.2 and 0.1, respectively,\ngenerate a barplot with the empirical frequencies of all the integers included in the sample.\n\n\n\n\n\nCode\n# Generate n observations from a mixture of three poisson distributions\nset.seed(452)\n\n\n# n     = 50\nn = 200                # sample size\n# w     = c(0.6, 0.4)  # Weights\nw = c(0.7,0.2,0.1)     # weights\n# mu    = c(0, 5)      # Means\n# sigma = c(1, 2)      # Standard deviations\nlambda = c(1,2,6)      # lambda params (mean,variation)\n\n\n\n#cc    = sample(1:2, n, replace=T, prob=w)\nac     = sample(1:length(w),n, replace=T, prob=w) # sample the active component\n#x     = rnorm(n, mu[cc], sigma[cc])\nx      = rpois(n,lambda=lambda[ac])                # simulate an ac mixture component n time\n\n\n#First converting the vector x into a factor while ensuring that any integer between 0 and the maximum in the sample are valid factors avoids the issue of ignoring zero counts or x=0.\n\n#empfreq = table(factor(x, levels=seq(0, max(x))))/n\nempirical_feqs = table(factor(x, levels=seq(0, max(x)))) # tabulate samples into a counts\nempirical_dist = empirical_feqs /n # convert frequencies to probabilities\n\n\nPlot the empirical distribution\n\n\nCode\npar(mar=c(4,4,1,1) + 0.1)\n#barplot(empfreq)\nbarplot(empirical_dist,xlab=\"counts\",ylab=\"probability\",main=\"Empirical distribution for Poisson mixture\")\n\n\n\n\n\n\n\n\nFigure 1: Empirical distribution for Poisson mixture\n\n\n\n\n\n\n\nCode\nset.seed(42)\n\nn = 1000                  # Larger sample size\nw = c(0.3, 0.25, 0.25, 0.2)  # Weights\nmu = c(1, 4, 7, 10)       # Means\nrates = 1 / mu            # Rates for exponential distributions\n\ncc = sample(1:4, n, replace=TRUE, prob=w)\nx = rexp(n, rate=rates[cc])\n\nsample_mean = mean(x)\nsample_var = var(x)\n\ntheoretical_mean = sum(w * mu)\ntheoretical_variance = sum(w * (mu^2 + (mu - theoretical_mean)^2))\n\ncat(\"Sample Mean:\", sample_mean, \"\\n\")\n\n\nSample Mean: 5.015486 \n\n\nCode\ncat(\"Sample Variance:\", sample_var, \"\\n\")\n\n\nSample Variance: 49.05645 \n\n\nCode\ncat(\"Theoretical Mean:\", theoretical_mean, \"\\n\")\n\n\nTheoretical Mean: 5.05 \n\n\nCode\ncat(\"Theoretical Variance:\", theoretical_variance, \"\\n\")\n\n\nTheoretical Variance: 47.5975",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L01-Ex5.html#hw---simulation-of-poisson-mixture-model",
    "href": "C3-L01-Ex5.html#hw---simulation-of-poisson-mixture-model",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "NoteInstructions\n\n\n\n\nModify the code above to sample 200 random numbers from a mixture of 3 Poisson distributions with means 1, 2 and 6 and weights 0.7, 0.2 and 0.1, respectively,\ngenerate a barplot with the empirical frequencies of all the integers included in the sample.\n\n\n\n\n\nCode\n# Generate n observations from a mixture of three poisson distributions\nset.seed(452)\n\n\n# n     = 50\nn = 200                # sample size\n# w     = c(0.6, 0.4)  # Weights\nw = c(0.7,0.2,0.1)     # weights\n# mu    = c(0, 5)      # Means\n# sigma = c(1, 2)      # Standard deviations\nlambda = c(1,2,6)      # lambda params (mean,variation)\n\n\n\n#cc    = sample(1:2, n, replace=T, prob=w)\nac     = sample(1:length(w),n, replace=T, prob=w) # sample the active component\n#x     = rnorm(n, mu[cc], sigma[cc])\nx      = rpois(n,lambda=lambda[ac])                # simulate an ac mixture component n time\n\n\n#First converting the vector x into a factor while ensuring that any integer between 0 and the maximum in the sample are valid factors avoids the issue of ignoring zero counts or x=0.\n\n#empfreq = table(factor(x, levels=seq(0, max(x))))/n\nempirical_feqs = table(factor(x, levels=seq(0, max(x)))) # tabulate samples into a counts\nempirical_dist = empirical_feqs /n # convert frequencies to probabilities\n\n\nPlot the empirical distribution\n\n\nCode\npar(mar=c(4,4,1,1) + 0.1)\n#barplot(empfreq)\nbarplot(empirical_dist,xlab=\"counts\",ylab=\"probability\",main=\"Empirical distribution for Poisson mixture\")\n\n\n\n\n\n\n\n\nFigure 1: Empirical distribution for Poisson mixture\n\n\n\n\n\n\n\nCode\nset.seed(42)\n\nn = 1000                  # Larger sample size\nw = c(0.3, 0.25, 0.25, 0.2)  # Weights\nmu = c(1, 4, 7, 10)       # Means\nrates = 1 / mu            # Rates for exponential distributions\n\ncc = sample(1:4, n, replace=TRUE, prob=w)\nx = rexp(n, rate=rates[cc])\n\nsample_mean = mean(x)\nsample_var = var(x)\n\ntheoretical_mean = sum(w * mu)\ntheoretical_variance = sum(w * (mu^2 + (mu - theoretical_mean)^2))\n\ncat(\"Sample Mean:\", sample_mean, \"\\n\")\n\n\nSample Mean: 5.015486 \n\n\nCode\ncat(\"Sample Variance:\", sample_var, \"\\n\")\n\n\nSample Variance: 49.05645 \n\n\nCode\ncat(\"Theoretical Mean:\", theoretical_mean, \"\\n\")\n\n\nTheoretical Mean: 5.05 \n\n\nCode\ncat(\"Theoretical Variance:\", theoretical_variance, \"\\n\")\n\n\nTheoretical Variance: 47.5975",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C1-L01.html",
    "href": "C1-L01.html",
    "title": "Probability",
    "section": "",
    "text": "In these notes I supplement the course material with my own notes for establishing an axiomatic foundation for probability These were omitted from the course material, but alluded to in the course and their absence was so irksome that I decided to add them to my notes.\n\n\n\nBackground reading: This reviews the rules of probability, odds, and expectation.\n\nFor all its discussion of different paradigms of probability, the course lacks a rigorous definition of probability.\n\nDefinition 1 (Sample Space and Sample Point)  Sample space \\Omega\n\n\\Omega = \\{ \\forall w \\mid w \\text { is an outcome of an experiment} \\} \\ne \\emptyset\n\\tag{1}\nthen \\Omega is called a sample space.\nSince\n\n\\Omega \\ne \\emptyset \\implies  \\exists\\ \\omega \\in \\Omega\n\\tag{2}\nthen \\omega is called a sample point  Sample point \\omega\n\n\nDefinition 2 (Event)  Event A\n\n\\Omega \\ne \\emptyset \\implies  \\exists \\mathcal{F} \\subset 2^\\Omega \\implies \\exists A\\in F\n\\tag{3}\nLet \\mathcal{F} denote a family of subsets of a sample space \\Omega, and A any such subset. Then A is called an event\n\n\nDefinition 3 (Elementary Event) An event composed of a single point \\omega is called an elementary event.\n\n\nDefinition 4 (Outcome) We say that event A happened if when conducting the experiment we got an outcome \\omega and \\omega\\in A.\n\n\nDefinition 5 (Certain Event) \\Omega is called the certain event.\n\n\nDefinition 6 (Impossible Event) \\emptyset is called the impossible event.\n\n\nDefinition 7 (σ-Algebra) A family of events \\mathcal{F} with the following properties:\n\n\\Omega is the universal set\n\n\\Omega \\in \\mathcal{F}\n  \\tag{4}\n\\mathcal{F} is closed under complement operation:\n\n\\forall A \\in \\mathcal{F} \\implies A^c \\in \\mathcal{F}\n\\tag{5}\n\\mathcal{F} is closed under countable unions:\n\n\\exists A_i \\in \\mathcal{F} \\quad  i \\in \\mathcal{N} \\implies \\bigcup_{n=1}^\\infty {A_i} \\in \\mathcal{F}\n\\tag{6}\n\nis called a \\sigma-algebra or a \\sigma-field .\n\nsome properties of \\sigma-algebra\n\nhttps://math.stackexchange.com/questions/1330649/difference-between-topology-and-sigma-algebra-axioms\nAn epsilon of room: pages from year three of a mathematical blog section 2.7\n\n\nDefinition 8 (Probability Measure) if \\Omega is a sample space Definition 1 and \\mathcal{F} a \\sigma-algebra Definition 7 for \\Omega then a function P: \\mathcal{f} \\to [0,1] with the following properties:\n\nTotal measure of the sample space is 1: \n     P(\\Omega)=1\n  \\tag{7}\ncountably additive for pairwise disjoint countable collections of events: is called a probability measure over \\mathcal{F}. \n\\forall E_{ i \\in \\mathbb{N} } \\quad   P(\\bigcup_{n\\in \\mathbb{N} }{E_n})=\\sum_{n\\in \\mathbb{N} } P(E_n)\n\\tag{8}\nthen P is a probability measure over \\mathcal{F}\n\n\n\nDefinition 9 (Probability Space) If \\Omega is a sample space Definition 1 and \\mathcal{F} a \\sigma-algebra Definition 7 for \\Omega, and P a probability measure (Definition 8) for \\mathcal{F} then the ordered set &lt;\\Omega,\\mathcal{F},P &gt; is called a probability space\n\n\n\n\n\n\n\n\nFigure 1: Illustration of a probability space by Ziggystar\n\n\n\n\n\n\n\n\nTipNotation\n\n\n\nsometimes \\mathcal{F} is replaced with \\Sigma. for the \\sigma-algebra like in the figure below\n\n\n\n\n\nThe probability of the null event is 0.\n\nP(\\emptyset) = 0\n\\tag{9}\nProbabilities of all possible events (the space of all possible outcomes) must sum to one.\n\nP(\\Omega) = 1\n\\tag{10}\n\nA\\cap B = \\emptyset \\implies P(A \\cup B) = P(A)+P(B)\n\\tag{11}\n\n\nP(A^c) =1-P(A) \\qquad \\forall A\\in\\Omega\n\\tag{12}\n\nif A is an event in \\Omega then A^C is in Omega and since they are mutually exclusive by Equation 10\nIf S is the certain event in class C \\Omega then\nFor every event X in class \\Omega\n\n1 \\ge P(X) \\ge 0 \\qquad \\forall X \\in \\Omega \\qquad \\text{(P1)} \\qquad\n\\tag{13}\nProbabilities add to one:\n\n\\sum_{i\\in \\Omega} P(X=i)=1 \\qquad \\text{(P2)}\\qquad\n\\tag{14}\nThe complement of an event A is A^c\n\nP(S) = 1\n\\tag{15}\nIf events A_\\lambda are mutually exclusive (only one event may happen):\n\nP(A_1 \\cup A_2) = P(A_1) + P(A_2) - P(A_1\\cap A_1)\n\\tag{16}\n\nP(\\bigcup_{\\lambda\\in \\Omega} A_\\lambda)=\\sum_{\\lambda \\in \\Omega} P(A_\\lambda)\n\\tag{17}\nif {B_i} is a finite or countably infinite partition of a sample space \\Omega then\n\nP(A) = {\\sum_{i=1}^{N} P(A \\cap B_i)}= {\\sum_{i=1}^{N} P(A|B_i)P(B_i)}\n\\tag{18}\n\n\n\nC-3PO: Sir, the possibility of successfully navigating an asteroid field is approximately 3,720 to 1!  Han Solo: Never tell me the odds! — Star Wars Episode V: The Empire Strikes Back\n\nAnother way to think about probabilities is using odds Equation 19. Odds are more intuitive when we are thinking about the risk of an event happening or not happening. and when we consider the risk associated with uncertainty odds are a handy way of considering the risks.\n\nDefinition 10 (Odds Definitions) the odds of an event A are:\n\n\\mathcal{O}(A)  = \\frac{P(A)}{P(A^c)} = \\frac{ P(A)}{1-P(A)}\n\\tag{19}\n\nIt is also possible to convert odds to probabilities Equation 20\n\nTheorem 1 (Probability from odds) \np(A) = \\frac{ \\mathcal{O}(A)} {1+ \\mathcal{O}(A)}\n\\tag{20}\n\n\nProof. \n\\begin{aligned}\n& & \\mathcal{O}(A)  &= \\frac{P(A)}{1-P(A)} && \\text{(odds definition)}\n  \\\\&\\implies & P(A) &= \\mathcal{O}(A) (1-P(A))  && (\\times \\text{ denominator})\n  \\\\&\\implies &  P(A) &= \\mathcal{O}(A) - \\mathcal{O}(A) P(A) && \\text{(expand)}\n  \\\\&\\implies &  P(A)(1+ \\mathcal{O}(A)) &= \\mathcal{O}(A) && \\text{(collect)}  \n  \\\\&\\implies & P(A) &= \\frac{ \\mathcal{O}(A)} {1+ \\mathcal{O}(A)} && \\blacksquare  \n\\end{aligned}\n\n\nIf we are at the races and thinking about each horse a horse what we may care about is if it will win or lose. In such a case the odds can summarize the ratio of past successes and failures to win. Odds seem to be in line with a frequentist view summarizing ratios of success to failure. In reality, the other horses have odds as well and we may want to consider the probability of winning given the other horses in the race, and perhaps other parameters, like the track type, length of the race, jockey, and perhaps some hot tips. So let us not get ahead of ourselves\n\n\n\n\n\n\nTipData Scientist - insights.\n\n\n\nMany of these formulas are rather tedious. But, once you start to work on a data science project you will often discover that there are some problems with the data and because of that you cannot use your favorite algorithm. Or worse when you do the results are not very useful. It is at this point that the ability to think back to first principles will be very fruitful. The more of this material you can recall, the more the dots will connect, and your ability will translate into models of increasing sophistication. Luckily, the rules of probability are logical. So it is fairly easy to remember or even derive if you take some time to understand them.\nI realize that figuring out which results are more useful is easier in hindsight. And one of the reasons I am taking these courses is to annotate in my note the results I think to be most useful.\n\n\n\n\n\nThe expectation of a random variable (RV) X is the weighted average of the outcomes it can take weighted by their probabilities.\n\nDefinition 11 (Expectation for a discrete RV) \n\\mathbb{E}(x) = \\sum^N_{i=1} x_i \\times P(X=x_i)\n\\tag{21}\n\n\nDefinition 12 (Expectation for a continuous RV) \n\\mathbb{E}(x) = \\int_{\\Omega} x P(X=x) dx\n\\tag{22}\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Probability Paradigms\n\n\nWe start by looking at probability as defined or interpreted under three paradigms. Probability is at its root a logical and scientific approach to formalizing and modeling uncertainty.\nThe three paradigms are:\n\nDefinition 13 (Classical Probability) Deals primarily with cases where probabilities are distributed equally, like with dice and cards.\n\n\n\n\n\n\n\n\nFigure 3: Abraham De Moivre\n\n\n\n\n\n\n\n\nTipBiographical note on Abraham de Moivre\n\n\n\n\n\n\nThe Probability of an Event is greater or less, according to the number of chances by which it may happen, compared with the whole number of chances by which it may either happen or fail. — (Moivre 1718)\n\nAbraham de Moivre (1667-1754) was a prominent French mathematician known for his significant contributions to the field of probability and his work on the foundations of Bayesian statistics. His research and writings played a crucial role in establishing the mathematical principles of probability theory and laid the groundwork for future advancements in the field.\nDe Moivre is best known for his work on the theory of probability. He made significant advancements in understanding the Binomial distribution and its application to games of chance and coin tossing. In his influential book, “The Doctrine of Chances” (1718), he presented a comprehensive treatise on probability theory, providing mathematical explanations for various phenomena such as the law of large numbers and the central limit theorem. His book became a standard reference in the field and greatly influenced subsequent research on probability.\nFurthermore, de Moivre’s work laid the foundation for Bayesian statistics, although the term “Bayesian” was not coined until many years after his death. He developed a formula known as de Moivre’s theorem, which establishes a connection between the normal distribution and the binomial distribution. This theorem became a fundamental tool in probability theory and enabled the calculation of probabilities for large sample sizes. It provided a bridge between frequentist and Bayesian approaches, allowing for the estimation of parameters and the quantification of uncertainty.\n\nAnd thus in all cases it will be found, that although Chance produces irregularities, still the Odds will be infinitely great, that in process of Time, those Irregularities will bear no proportion to the recurrency of that Order which naturally results from Original Design. (Moivre 1718)\n\nHe was an active participant in scientific societies and maintained correspondence with renowned mathematicians of his time, including Isaac Newton and James Stirling. His work played a crucial role in disseminating mathematical knowledge and promoting the study of probability theory across Europe. De Moivre’s research and writings laid the groundwork for the development of probability theory and Bayesian statistics. His ideas and formulas continue to be foundational in the field, and his contributions have had a lasting impact on mathematics, statistics, and the broader scientific community.\nHis work remains an essential reference for researchers and serves as a testament to his profound understanding of probability and statistics.\n\nFurther, the same Arguments which explode the Notion of Luck, may, on the other side, be useful in some cases to establish a due comparison between Chance and Design: We may imagine Chance and Design to be, as it were, in Competition with each other, for the production of some sorts of Events, and many calculate what Probability there is, that those Events should be rather be owing to the one than to the other. (Moivre 1718)\n\n\n\n\n\nDefinition 14 (Frequentist Probability) Defines probabilities using long-run limits of frequencies from repeated independent sampling generated by a hypothetical infinite sequence of experiments from a population\nFrequentist probability or frequentism is an interpretation of probability; it defines an event’s probability as the limit of its relative frequency in many trials AKA long-run probability. Probabilities can be found, in principle, by a repeatable objective process and are thus ideally devoid of opinion. The continued use of frequentist methods in scientific inference, however, has been called into question.\n\nSince in reality we cannot repeat most experiments many times.\n“by definition, scientific researchers do not possess sufficient knowledge about the relevant and irrelevant aspects of their tests and populations to be sure that their replications will be equivalent to one another” - Mark Rubin 2020\n\n\n\nDefinition 15 (Bayesian Probability) Defines probability starting with a subjective view of the problem called a prior and updates it as evidence comes in using Bayes Rule.\n\nThe lesson and assignments test these views with examples - but the division is rather artificial to me. Not that it does not exist, but rather different authors on the subject treat it differently.\n\n\n\n\n\n\n\nVideo 1: Interview with Dennis Lindley, a pioneer of Bayesian statistics, discussing the history and philosophy of Bayesian methods, and his contributions to the field. He emphasizes the importance of subjective probability and the role of prior beliefs in statistical inference.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Coherence\n\n\nA notion of a fair bet - one which we would take either way for the same reward.\n\ncoherence following the rules of statistics\nincoherence or Dutch book one would be guaranteed to lose money.\n\n\n\n\n\n\n\n\nFigure 5: Bruno de Finetti\n\n\n\n\n\n\n\n\nTipBiographical note on Bruno de Finetti\n\n\n\n\n\n\nFrom the subjective standpoint, no assertion is possible without a priori opinion, but the variety of possible opinions makes problems depending on different opinions interesting.\n\nBruno de Finetti 1906-1985 was born in Innsbruck (Austria) to an Italian family. He studied mathematics at the University of Trieste, where he developed a keen interest in probability theory and its applications.\nAfter completing his doctoral studies in 1928, de Finetti embarked on a distinguished academic career. His first research work dealt with mathematical biology and was published, in 1926 when he was still an undergraduate. After graduation and up to 1931, he worked in the mathematical office of the Central Italian Agency for Statistics. From 1931-46, de Finetti worked in Trieste at Assicurazioni Generali, one of the most important insurance companies in Italy. In the same period, he lectured at the University of Trieste and the University of Padua.\nOne of de Finetti’s most significant contributions was his development of the theory of subjective probability, also known as the Bayesian interpretation of probability. He developed his ideas independently of F. P. Ramsey who also published on this (Ramsey 1926)\nIn his seminal work, (Finetti 1937), he proposed that probability should be interpreted as a personal measure of belief or degree of uncertainty rather than as a frequency or long-run proportion. This subjective approach allowed for the incorporation of prior information and updating of beliefs in light of new data, forming the basis of Bayesian inference.\n\nProbabilistic reasoning – always to be understood as subjective – merely stems from our being uncertain about something. (Finetti 2017 § preface)\n\nIt is impossible to summarize in a few paragraphs the scientific activity of de Finetti in the different fields of mathematics (probability), measure theory, analysis, geometry, mathematics of finance, economics, the social sciences, teaching, computer science, and biomathematics or to describe his generous and complex personality as a scientist and a humanitarian. De Finetti discussed his own life in a book edited by Gani (1982). See also the article by Lindley (1989).\n\nMy thesis, paradoxically, and a little provocatively, but nonetheless genuinely, is simply this :  PROBABILITY DOES NOT EXIST.  … Probability, too, if regarded as something endowed with some kind of objective existence, is no less a misleading misconception, an illusory attempt to exteriorize or materialize our true probabilistic beliefs. (Finetti 2017 § preface page x)\n\nde Finetti was a brilliant statistician but his books and papers have garnered a reputation of being challenging to read both in the original Italian, French and English translation. The above quote embodies his radical point of view which he challenged other statisticians to rethink their views.\nWhat I think he meant is that meant primarily was that probabilities unlike physical quantities cannot be measured in the objective sense. de Fineti was well versed with quantum mechanics, where physical quantities like the position and speed of an electron are interpreted primarily through probabilities in a wave equation, to include a discussion in the start of his second volume.\nA large part of this course is that we are inferring parameters - which are often probabilities.\nAnother milestone result by de Finetti is his theorem\n\n\n\n\n\n\n\n\n\nNoteQuestion\n\n\n\n\n\nRepresenting uncertainty with probability: Don’t use any outside information on this question, just determine probabilities subjectively. The country of Chile is divided into 15 administrative regions. The size of the country is 756,096 square kilometers. How big do you think the region of Atacama is? Let:\n\nA_1 be the event: Atacama is less than 10,000 km^2.\nA_2 be the event: Atacama is between 10,000 and 50,000 km^2\nA_3 be the event: Atacama is between 50,000 and 100,000 km^2\nA_4 be the event: Atacama is more than 100,000 km^2 Assign probabilities to A_1 \\ldots A_4\n\n\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n0\n10k\n\\frac{1}{4}\n\n\nA_2\n10k\n50k\n\\frac{1}{4}\n\n\nA_3\n50k\n100k\n\\frac{1}{4}\n\n\nA_4\n100k\n\n\\frac{1}{4}\n\n\n\n\nWhat do I know at this point?\n\nThe expected area for the region is \\frac{750,000}{15}=50,000\\ km^2 .\n\nWhat Do I believe?\n\nI believe that the administrative regions have significantly different sizes\nfrom my familiarity with some other countries.\nAs I don’t know if Atacama is large or small my best bet is to assign equal probabilities to each event.\n\n\n\n\n\n\n\n\nNoteMore information 1\n\n\n\nAtacama is the fourth largest of 15 regions. Using this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10k\n\\frac{1}{16}\n\n\nA_2\n10k\n50k\n\\frac{3}{16}\n\n\nA_3\n50k\n100k\n\\frac{6}{16}\n\n\nA_4\n100k\n\n\\frac{6}{16}\n\n\n\n\nWhat do I know?\n\nThe expected area is \\frac{750,000}{15}=50,000\\ km^2 .\nI know that Atacama is the Fourth largest.\n\nWhat Do I believe?\n\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\n\nHow do I revise my guesstimate?\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3 .\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out.\nA_1 seems extremely unlikely as it necessitates the top three regions account for almost all of the area of the country. \\frac{750,000 - 14 * 10,000}{3} = 203,333.3 that’s about 4 times the average for each state.\nA_2 is fairly unlikely to require the top three regions to account for \\frac{(750,000-14*20000)}{3}=170,000 each that’s more than 3 times the average.\n\n\n\n\n\n\n\n\nNoteMore information 2\n\n\n\nThe smallest region is the capital region, Santiago Metropolitan, which has an area of 15,403 km^2. Using this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10k\n0\n\n\nA_2\n10k\n50k\n\\frac{1}{8}\n\n\nA_3\n50k\n100k\n\\frac{4}{8}\n\n\nA_4\n100k\n\n\\frac{3}{8}\n\n\n\nWhat do I know?\n\nThe expected area is \\frac{750,000}{15}=50,000 \\quad km^2\nP(A_1)=0 since the smallest region is $ 15,403 km^2$.\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\nI know that Atacama is the Fourth largest.\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3.\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out. But A1 and A2 are now very unlikely as they would require the top three regions to account for almost all of the area of the country.\n\n\n\n\n\n\n\n\nNoteMore information 3\n\n\n\nThe third largest region is Aysén del General Carlos Ibáñez del Campo, which has an area of 108,494 km^2.\nUsing this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10K\n0\n\n\nA_2\n10k\n50K\n\\frac{1}{8}\n\n\nA_3\n50k\n100K\n\\frac{6}{8}\n\n\nA_4\n100k\n\n\\frac{1}{8}\n\n\n\n\nThe expected area is \\frac{750,000}{15}=50,000 \\quad km^2\nP(A1)=0 since the smallest region is $15,403 km^2 $ .\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\nI know that Atacama is the Fourth largest.\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3 .\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out. But A1 and A2 are now very unlikely as they would require the top three regions to account for almost all of the area of the country.\n\n\n\n\n\n\n\n\n\n\n\nTipDiscussion: Objectivity\n\n\n\nIn what ways could the frequentist paradigm be considered objective? In what ways could the Bayesian paradigm be considered objective? Identify ways in which each paradigm might be considered subjective.\n\nFrequentist:\n\nThe orthodox approach is statisticians should establish an objective statistical methodology and field researchers should then use it to solve their problems. This leads to following flow charts for analysis and tests without fully understanding the model and how it works. At best one makes mistakes due to misunderstanding. But we can see that there is a systematic gaming of this methodology using p-hacking, multiple hypotheses, and hiding failed experiments leading to the publication of outrageously good results, which then cannot be replicated.\nThe analysis is done on data that is supposedly sampled from a population. But the same data may belong to different populations (the city, the country, etc) each with different statistics. We should assume the same long-run frequencies would converge to different to each one of these statistics if we repeat the experiment enough times.\nThe sample size, or how long we run the experiment is a tricky decision to make in advance and without prior knowledge. And if we do not decide in advance, but periodically as the data comes in. It turns out that this can completely change the outcomes of the experiment - even if both approaches have the same data.\nThe choice of H_0 and H_1 is often subjective and each hypothesis can lead to yet another.\nThe choice of the confidence level 95%, 99%, etc. used for statistical significance is subjective.\nIf an effect size is considered large is subjective and depends on the field one studies.\n\nBayesian:\n\nthe prior should be highly informative and therefore subjective. But it can be\nuninformative and hence more objective.\nit can be difficult to decide what impact the prior should have on the posterior. Ideally, we can quantify the effective sample size for the prior data and we can understand how much information each contributes to the posterior.\n\n\n\n\n\n\n\nThe expectation of an RV is a measure of its central tendency.\nThe expected value, also known as the expectation or mean, of a random variable X is denoted \\mathbb{E}[X]. It is the weighted average of all values X could take, weighted by their probabilities.\n\n\n\n\n\n\nTip\n\n\n\n\nI looked this up and found the following answer, see (https://math.stackexchange.com/users/25097/autolatry) (n.d.).\nThe RV X is a function whereas the Expectation is a Functional (a mapping from a function to a number). Mathematicians adopt the use of square brackets for functionals.\nSee Wikipedia contributors (2023) for more information on what a Functional is.\n\n\nWhy Square Brackets for Expectation\n\nIf X is a discrete-valued random variable then its expectation is defined by(Equation 21)\n\n\\mathbb{E}[X]=\\sum^N_{i=1} x_i \\cdot P(X=x_i) = \\sum^N_{i=1} x_i \\cdot f(x)\n\n\n\n\nIf X is a continuous random variable then its expectation is defined by(Equation 22)\n\n\\mathbb{E}[X]=\\int_{-\\infty}^{\\infty} x \\cdot f(x) dx\n\nwhile the mean is an important descriptive statistic for central tendencies, we often prefer the median which is robust to outliers, and pick the mode as a representative if we need a value in the data set.\n\n\n\nSum and integral are linear operators so the Expectation is also a linear operator\n\n\\mathbb{E}[c]= c\n\\tag{23}\n\n\\mathbb{E}[aX+bY] = a\\mathbb{E}[X] + b\\mathbb{E}[Y]\n\\tag{24}\n\n\\mathbb{E}[g[X]]  = \\int{g(x)f(x)dx}\n\nIf X & Y are independent\n\n\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y]\n\n\n\n\n\nVariance is the dispersion of a distribution about the mean.\n\nDefinition 16 For a discrete random variable, the Variance is defined using (Equation 25)\n\n\\mathbb{V}ar(X)=\\sum^N_{i=1} (x_i-\\mu)^2 P(X=x_i)\n\\tag{25}\n\n\nDefinition 17 For a continuous random variable, the Variance is defined using (Equation 26)\n\n\\mathbb{V}ar[X]=\\int_{- \\infty}^{\\infty} (x-\\mu)^2 f(x)dx\n\\tag{26}\n\n\n\n\n\\mathbb{V}ar[c] = 0\n\\tag{27}\nif X and Y are independent then\n\n\\mathbb{V}ar[aX+by] = a^2\\mathbb{V}ar[X] +b^2\\mathbb{V}ar[Y]\n\\tag{28}\notherwise\n\n\\mathbb{V}ar[aX+by] = a^2\\mathbb{V}ar[X] +b^2\\mathbb{V}ar[Y] + 2ab\\mathbb{C}ov(X,Y)\n\\tag{29}\nwhere \\mathbb{C}ov(X,Y) is the covariance of X and Y.\nHere is one of the most useful identities (Equation 30) for wrangling with variance using the expectation of X and X^2.\n\n\\begin{aligned}\n    \\mathbb{V}ar[X] &= \\mathbb{E}[(X- \\mathbb{E}[X])^2]\n    \\\\&= \\mathbb{E}[X^2] − (\\mathbb{E}[X])^2\n\\end{aligned}\n\\tag{30}\n\n\n\n\nCovariance is a measure of the joint variability of two random variables. It indicates the direction of the linear relationship between the variables.\nIf X and Y are two random variables, the covariance of X and Y is defined as:\n\n\\begin{aligned}\n\\mathrm{Cov}(X,Y) &= \\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])]\n\\\\ &= \\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]\n\\end{aligned}\n\\tag{31}\n\n\n\nCorrelation is a standardized measure of the linear relationship between two random variables. It is a dimensionless quantity that ranges from -1 to 1.\nThe correlation coefficient \\rho_{XY} is defined as the covariance of X and Y divided by the product of their standard deviations:\n\n\\rho_{XY} = \\frac{\\mathrm{Cov}(X,Y)}{\\sigma_X\\sigma_Y}\n\\tag{32}",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-rules-of-probability-odds--expectation",
    "href": "C1-L01.html#sec-rules-of-probability-odds--expectation",
    "title": "Probability",
    "section": "",
    "text": "Background reading: This reviews the rules of probability, odds, and expectation.\n\nFor all its discussion of different paradigms of probability, the course lacks a rigorous definition of probability.\n\nDefinition 1 (Sample Space and Sample Point)  Sample space \\Omega\n\n\\Omega = \\{ \\forall w \\mid w \\text { is an outcome of an experiment} \\} \\ne \\emptyset\n\\tag{1}\nthen \\Omega is called a sample space.\nSince\n\n\\Omega \\ne \\emptyset \\implies  \\exists\\ \\omega \\in \\Omega\n\\tag{2}\nthen \\omega is called a sample point  Sample point \\omega\n\n\nDefinition 2 (Event)  Event A\n\n\\Omega \\ne \\emptyset \\implies  \\exists \\mathcal{F} \\subset 2^\\Omega \\implies \\exists A\\in F\n\\tag{3}\nLet \\mathcal{F} denote a family of subsets of a sample space \\Omega, and A any such subset. Then A is called an event\n\n\nDefinition 3 (Elementary Event) An event composed of a single point \\omega is called an elementary event.\n\n\nDefinition 4 (Outcome) We say that event A happened if when conducting the experiment we got an outcome \\omega and \\omega\\in A.\n\n\nDefinition 5 (Certain Event) \\Omega is called the certain event.\n\n\nDefinition 6 (Impossible Event) \\emptyset is called the impossible event.\n\n\nDefinition 7 (σ-Algebra) A family of events \\mathcal{F} with the following properties:\n\n\\Omega is the universal set\n\n\\Omega \\in \\mathcal{F}\n  \\tag{4}\n\\mathcal{F} is closed under complement operation:\n\n\\forall A \\in \\mathcal{F} \\implies A^c \\in \\mathcal{F}\n\\tag{5}\n\\mathcal{F} is closed under countable unions:\n\n\\exists A_i \\in \\mathcal{F} \\quad  i \\in \\mathcal{N} \\implies \\bigcup_{n=1}^\\infty {A_i} \\in \\mathcal{F}\n\\tag{6}\n\nis called a \\sigma-algebra or a \\sigma-field .\n\nsome properties of \\sigma-algebra\n\nhttps://math.stackexchange.com/questions/1330649/difference-between-topology-and-sigma-algebra-axioms\nAn epsilon of room: pages from year three of a mathematical blog section 2.7\n\n\nDefinition 8 (Probability Measure) if \\Omega is a sample space Definition 1 and \\mathcal{F} a \\sigma-algebra Definition 7 for \\Omega then a function P: \\mathcal{f} \\to [0,1] with the following properties:\n\nTotal measure of the sample space is 1: \n     P(\\Omega)=1\n  \\tag{7}\ncountably additive for pairwise disjoint countable collections of events: is called a probability measure over \\mathcal{F}. \n\\forall E_{ i \\in \\mathbb{N} } \\quad   P(\\bigcup_{n\\in \\mathbb{N} }{E_n})=\\sum_{n\\in \\mathbb{N} } P(E_n)\n\\tag{8}\nthen P is a probability measure over \\mathcal{F}\n\n\n\nDefinition 9 (Probability Space) If \\Omega is a sample space Definition 1 and \\mathcal{F} a \\sigma-algebra Definition 7 for \\Omega, and P a probability measure (Definition 8) for \\mathcal{F} then the ordered set &lt;\\Omega,\\mathcal{F},P &gt; is called a probability space\n\n\n\n\n\n\n\n\nFigure 1: Illustration of a probability space by Ziggystar\n\n\n\n\n\n\n\n\nTipNotation\n\n\n\nsometimes \\mathcal{F} is replaced with \\Sigma. for the \\sigma-algebra like in the figure below",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-properties-of-probability-measures",
    "href": "C1-L01.html#sec-properties-of-probability-measures",
    "title": "Probability",
    "section": "",
    "text": "The probability of the null event is 0.\n\nP(\\emptyset) = 0\n\\tag{9}\nProbabilities of all possible events (the space of all possible outcomes) must sum to one.\n\nP(\\Omega) = 1\n\\tag{10}\n\nA\\cap B = \\emptyset \\implies P(A \\cup B) = P(A)+P(B)\n\\tag{11}\n\n\nP(A^c) =1-P(A) \\qquad \\forall A\\in\\Omega\n\\tag{12}\n\nif A is an event in \\Omega then A^C is in Omega and since they are mutually exclusive by Equation 10\nIf S is the certain event in class C \\Omega then\nFor every event X in class \\Omega\n\n1 \\ge P(X) \\ge 0 \\qquad \\forall X \\in \\Omega \\qquad \\text{(P1)} \\qquad\n\\tag{13}\nProbabilities add to one:\n\n\\sum_{i\\in \\Omega} P(X=i)=1 \\qquad \\text{(P2)}\\qquad\n\\tag{14}\nThe complement of an event A is A^c\n\nP(S) = 1\n\\tag{15}\nIf events A_\\lambda are mutually exclusive (only one event may happen):\n\nP(A_1 \\cup A_2) = P(A_1) + P(A_2) - P(A_1\\cap A_1)\n\\tag{16}\n\nP(\\bigcup_{\\lambda\\in \\Omega} A_\\lambda)=\\sum_{\\lambda \\in \\Omega} P(A_\\lambda)\n\\tag{17}\nif {B_i} is a finite or countably infinite partition of a sample space \\Omega then\n\nP(A) = {\\sum_{i=1}^{N} P(A \\cap B_i)}= {\\sum_{i=1}^{N} P(A|B_i)P(B_i)}\n\\tag{18}\n\n\n\nC-3PO: Sir, the possibility of successfully navigating an asteroid field is approximately 3,720 to 1!  Han Solo: Never tell me the odds! — Star Wars Episode V: The Empire Strikes Back\n\nAnother way to think about probabilities is using odds Equation 19. Odds are more intuitive when we are thinking about the risk of an event happening or not happening. and when we consider the risk associated with uncertainty odds are a handy way of considering the risks.\n\nDefinition 10 (Odds Definitions) the odds of an event A are:\n\n\\mathcal{O}(A)  = \\frac{P(A)}{P(A^c)} = \\frac{ P(A)}{1-P(A)}\n\\tag{19}\n\nIt is also possible to convert odds to probabilities Equation 20\n\nTheorem 1 (Probability from odds) \np(A) = \\frac{ \\mathcal{O}(A)} {1+ \\mathcal{O}(A)}\n\\tag{20}\n\n\nProof. \n\\begin{aligned}\n& & \\mathcal{O}(A)  &= \\frac{P(A)}{1-P(A)} && \\text{(odds definition)}\n  \\\\&\\implies & P(A) &= \\mathcal{O}(A) (1-P(A))  && (\\times \\text{ denominator})\n  \\\\&\\implies &  P(A) &= \\mathcal{O}(A) - \\mathcal{O}(A) P(A) && \\text{(expand)}\n  \\\\&\\implies &  P(A)(1+ \\mathcal{O}(A)) &= \\mathcal{O}(A) && \\text{(collect)}  \n  \\\\&\\implies & P(A) &= \\frac{ \\mathcal{O}(A)} {1+ \\mathcal{O}(A)} && \\blacksquare  \n\\end{aligned}\n\n\nIf we are at the races and thinking about each horse a horse what we may care about is if it will win or lose. In such a case the odds can summarize the ratio of past successes and failures to win. Odds seem to be in line with a frequentist view summarizing ratios of success to failure. In reality, the other horses have odds as well and we may want to consider the probability of winning given the other horses in the race, and perhaps other parameters, like the track type, length of the race, jockey, and perhaps some hot tips. So let us not get ahead of ourselves\n\n\n\n\n\n\nTipData Scientist - insights.\n\n\n\nMany of these formulas are rather tedious. But, once you start to work on a data science project you will often discover that there are some problems with the data and because of that you cannot use your favorite algorithm. Or worse when you do the results are not very useful. It is at this point that the ability to think back to first principles will be very fruitful. The more of this material you can recall, the more the dots will connect, and your ability will translate into models of increasing sophistication. Luckily, the rules of probability are logical. So it is fairly easy to remember or even derive if you take some time to understand them.\nI realize that figuring out which results are more useful is easier in hindsight. And one of the reasons I am taking these courses is to annotate in my note the results I think to be most useful.\n\n\n\n\n\nThe expectation of a random variable (RV) X is the weighted average of the outcomes it can take weighted by their probabilities.\n\nDefinition 11 (Expectation for a discrete RV) \n\\mathbb{E}(x) = \\sum^N_{i=1} x_i \\times P(X=x_i)\n\\tag{21}\n\n\nDefinition 12 (Expectation for a continuous RV) \n\\mathbb{E}(x) = \\int_{\\Omega} x P(X=x) dx\n\\tag{22}",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-probability-paradigms",
    "href": "C1-L01.html#sec-probability-paradigms",
    "title": "Probability",
    "section": "",
    "text": "Figure 2: Probability Paradigms\n\n\nWe start by looking at probability as defined or interpreted under three paradigms. Probability is at its root a logical and scientific approach to formalizing and modeling uncertainty.\nThe three paradigms are:\n\nDefinition 13 (Classical Probability) Deals primarily with cases where probabilities are distributed equally, like with dice and cards.\n\n\n\n\n\n\n\n\nFigure 3: Abraham De Moivre\n\n\n\n\n\n\n\n\nTipBiographical note on Abraham de Moivre\n\n\n\n\n\n\nThe Probability of an Event is greater or less, according to the number of chances by which it may happen, compared with the whole number of chances by which it may either happen or fail. — (Moivre 1718)\n\nAbraham de Moivre (1667-1754) was a prominent French mathematician known for his significant contributions to the field of probability and his work on the foundations of Bayesian statistics. His research and writings played a crucial role in establishing the mathematical principles of probability theory and laid the groundwork for future advancements in the field.\nDe Moivre is best known for his work on the theory of probability. He made significant advancements in understanding the Binomial distribution and its application to games of chance and coin tossing. In his influential book, “The Doctrine of Chances” (1718), he presented a comprehensive treatise on probability theory, providing mathematical explanations for various phenomena such as the law of large numbers and the central limit theorem. His book became a standard reference in the field and greatly influenced subsequent research on probability.\nFurthermore, de Moivre’s work laid the foundation for Bayesian statistics, although the term “Bayesian” was not coined until many years after his death. He developed a formula known as de Moivre’s theorem, which establishes a connection between the normal distribution and the binomial distribution. This theorem became a fundamental tool in probability theory and enabled the calculation of probabilities for large sample sizes. It provided a bridge between frequentist and Bayesian approaches, allowing for the estimation of parameters and the quantification of uncertainty.\n\nAnd thus in all cases it will be found, that although Chance produces irregularities, still the Odds will be infinitely great, that in process of Time, those Irregularities will bear no proportion to the recurrency of that Order which naturally results from Original Design. (Moivre 1718)\n\nHe was an active participant in scientific societies and maintained correspondence with renowned mathematicians of his time, including Isaac Newton and James Stirling. His work played a crucial role in disseminating mathematical knowledge and promoting the study of probability theory across Europe. De Moivre’s research and writings laid the groundwork for the development of probability theory and Bayesian statistics. His ideas and formulas continue to be foundational in the field, and his contributions have had a lasting impact on mathematics, statistics, and the broader scientific community.\nHis work remains an essential reference for researchers and serves as a testament to his profound understanding of probability and statistics.\n\nFurther, the same Arguments which explode the Notion of Luck, may, on the other side, be useful in some cases to establish a due comparison between Chance and Design: We may imagine Chance and Design to be, as it were, in Competition with each other, for the production of some sorts of Events, and many calculate what Probability there is, that those Events should be rather be owing to the one than to the other. (Moivre 1718)\n\n\n\n\n\nDefinition 14 (Frequentist Probability) Defines probabilities using long-run limits of frequencies from repeated independent sampling generated by a hypothetical infinite sequence of experiments from a population\nFrequentist probability or frequentism is an interpretation of probability; it defines an event’s probability as the limit of its relative frequency in many trials AKA long-run probability. Probabilities can be found, in principle, by a repeatable objective process and are thus ideally devoid of opinion. The continued use of frequentist methods in scientific inference, however, has been called into question.\n\nSince in reality we cannot repeat most experiments many times.\n“by definition, scientific researchers do not possess sufficient knowledge about the relevant and irrelevant aspects of their tests and populations to be sure that their replications will be equivalent to one another” - Mark Rubin 2020\n\n\n\nDefinition 15 (Bayesian Probability) Defines probability starting with a subjective view of the problem called a prior and updates it as evidence comes in using Bayes Rule.\n\nThe lesson and assignments test these views with examples - but the division is rather artificial to me. Not that it does not exist, but rather different authors on the subject treat it differently.\n\n\n\n\n\n\n\nVideo 1: Interview with Dennis Lindley, a pioneer of Bayesian statistics, discussing the history and philosophy of Bayesian methods, and his contributions to the field. He emphasizes the importance of subjective probability and the role of prior beliefs in statistical inference.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-bayesian-probability-and-coherence",
    "href": "C1-L01.html#sec-bayesian-probability-and-coherence",
    "title": "Probability",
    "section": "",
    "text": "Figure 4: Coherence\n\n\nA notion of a fair bet - one which we would take either way for the same reward.\n\ncoherence following the rules of statistics\nincoherence or Dutch book one would be guaranteed to lose money.\n\n\n\n\n\n\n\n\nFigure 5: Bruno de Finetti\n\n\n\n\n\n\n\n\nTipBiographical note on Bruno de Finetti\n\n\n\n\n\n\nFrom the subjective standpoint, no assertion is possible without a priori opinion, but the variety of possible opinions makes problems depending on different opinions interesting.\n\nBruno de Finetti 1906-1985 was born in Innsbruck (Austria) to an Italian family. He studied mathematics at the University of Trieste, where he developed a keen interest in probability theory and its applications.\nAfter completing his doctoral studies in 1928, de Finetti embarked on a distinguished academic career. His first research work dealt with mathematical biology and was published, in 1926 when he was still an undergraduate. After graduation and up to 1931, he worked in the mathematical office of the Central Italian Agency for Statistics. From 1931-46, de Finetti worked in Trieste at Assicurazioni Generali, one of the most important insurance companies in Italy. In the same period, he lectured at the University of Trieste and the University of Padua.\nOne of de Finetti’s most significant contributions was his development of the theory of subjective probability, also known as the Bayesian interpretation of probability. He developed his ideas independently of F. P. Ramsey who also published on this (Ramsey 1926)\nIn his seminal work, (Finetti 1937), he proposed that probability should be interpreted as a personal measure of belief or degree of uncertainty rather than as a frequency or long-run proportion. This subjective approach allowed for the incorporation of prior information and updating of beliefs in light of new data, forming the basis of Bayesian inference.\n\nProbabilistic reasoning – always to be understood as subjective – merely stems from our being uncertain about something. (Finetti 2017 § preface)\n\nIt is impossible to summarize in a few paragraphs the scientific activity of de Finetti in the different fields of mathematics (probability), measure theory, analysis, geometry, mathematics of finance, economics, the social sciences, teaching, computer science, and biomathematics or to describe his generous and complex personality as a scientist and a humanitarian. De Finetti discussed his own life in a book edited by Gani (1982). See also the article by Lindley (1989).\n\nMy thesis, paradoxically, and a little provocatively, but nonetheless genuinely, is simply this :  PROBABILITY DOES NOT EXIST.  … Probability, too, if regarded as something endowed with some kind of objective existence, is no less a misleading misconception, an illusory attempt to exteriorize or materialize our true probabilistic beliefs. (Finetti 2017 § preface page x)\n\nde Finetti was a brilliant statistician but his books and papers have garnered a reputation of being challenging to read both in the original Italian, French and English translation. The above quote embodies his radical point of view which he challenged other statisticians to rethink their views.\nWhat I think he meant is that meant primarily was that probabilities unlike physical quantities cannot be measured in the objective sense. de Fineti was well versed with quantum mechanics, where physical quantities like the position and speed of an electron are interpreted primarily through probabilities in a wave equation, to include a discussion in the start of his second volume.\nA large part of this course is that we are inferring parameters - which are often probabilities.\nAnother milestone result by de Finetti is his theorem\n\n\n\n\n\n\n\n\n\nNoteQuestion\n\n\n\n\n\nRepresenting uncertainty with probability: Don’t use any outside information on this question, just determine probabilities subjectively. The country of Chile is divided into 15 administrative regions. The size of the country is 756,096 square kilometers. How big do you think the region of Atacama is? Let:\n\nA_1 be the event: Atacama is less than 10,000 km^2.\nA_2 be the event: Atacama is between 10,000 and 50,000 km^2\nA_3 be the event: Atacama is between 50,000 and 100,000 km^2\nA_4 be the event: Atacama is more than 100,000 km^2 Assign probabilities to A_1 \\ldots A_4\n\n\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n0\n10k\n\\frac{1}{4}\n\n\nA_2\n10k\n50k\n\\frac{1}{4}\n\n\nA_3\n50k\n100k\n\\frac{1}{4}\n\n\nA_4\n100k\n\n\\frac{1}{4}\n\n\n\n\nWhat do I know at this point?\n\nThe expected area for the region is \\frac{750,000}{15}=50,000\\ km^2 .\n\nWhat Do I believe?\n\nI believe that the administrative regions have significantly different sizes\nfrom my familiarity with some other countries.\nAs I don’t know if Atacama is large or small my best bet is to assign equal probabilities to each event.\n\n\n\n\n\n\n\n\nNoteMore information 1\n\n\n\nAtacama is the fourth largest of 15 regions. Using this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10k\n\\frac{1}{16}\n\n\nA_2\n10k\n50k\n\\frac{3}{16}\n\n\nA_3\n50k\n100k\n\\frac{6}{16}\n\n\nA_4\n100k\n\n\\frac{6}{16}\n\n\n\n\nWhat do I know?\n\nThe expected area is \\frac{750,000}{15}=50,000\\ km^2 .\nI know that Atacama is the Fourth largest.\n\nWhat Do I believe?\n\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\n\nHow do I revise my guesstimate?\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3 .\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out.\nA_1 seems extremely unlikely as it necessitates the top three regions account for almost all of the area of the country. \\frac{750,000 - 14 * 10,000}{3} = 203,333.3 that’s about 4 times the average for each state.\nA_2 is fairly unlikely to require the top three regions to account for \\frac{(750,000-14*20000)}{3}=170,000 each that’s more than 3 times the average.\n\n\n\n\n\n\n\n\nNoteMore information 2\n\n\n\nThe smallest region is the capital region, Santiago Metropolitan, which has an area of 15,403 km^2. Using this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10k\n0\n\n\nA_2\n10k\n50k\n\\frac{1}{8}\n\n\nA_3\n50k\n100k\n\\frac{4}{8}\n\n\nA_4\n100k\n\n\\frac{3}{8}\n\n\n\nWhat do I know?\n\nThe expected area is \\frac{750,000}{15}=50,000 \\quad km^2\nP(A_1)=0 since the smallest region is $ 15,403 km^2$.\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\nI know that Atacama is the Fourth largest.\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3.\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out. But A1 and A2 are now very unlikely as they would require the top three regions to account for almost all of the area of the country.\n\n\n\n\n\n\n\n\nNoteMore information 3\n\n\n\nThe third largest region is Aysén del General Carlos Ibáñez del Campo, which has an area of 108,494 km^2.\nUsing this information, I revised my probabilities as follows:\n\n\n\n\n\n\n\nEvent\nMin km^2\nMax km^2\nP\n\n\n\n\nA_1\n\n10K\n0\n\n\nA_2\n10k\n50K\n\\frac{1}{8}\n\n\nA_3\n50k\n100K\n\\frac{6}{8}\n\n\nA_4\n100k\n\n\\frac{1}{8}\n\n\n\n\nThe expected area is \\frac{750,000}{15}=50,000 \\quad km^2\nP(A1)=0 since the smallest region is $15,403 km^2 $ .\nI believe that the administrative regions have significantly different sizes - from my familiarity with some other countries.\nI know that Atacama is the Fourth largest.\n\nIf the region sizes are equally sized I should gamble mostly on A_2 and A_3 .\nBut I think there are a few large regions and many smaller ones.\nAlso I know that 11 regions are smaller than Atacama and that 3 three are larger.\nNone of the events can yet be ruled out. But A1 and A2 are now very unlikely as they would require the top three regions to account for almost all of the area of the country.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-discussions-objectivity",
    "href": "C1-L01.html#sec-discussions-objectivity",
    "title": "Probability",
    "section": "",
    "text": "TipDiscussion: Objectivity\n\n\n\nIn what ways could the frequentist paradigm be considered objective? In what ways could the Bayesian paradigm be considered objective? Identify ways in which each paradigm might be considered subjective.\n\nFrequentist:\n\nThe orthodox approach is statisticians should establish an objective statistical methodology and field researchers should then use it to solve their problems. This leads to following flow charts for analysis and tests without fully understanding the model and how it works. At best one makes mistakes due to misunderstanding. But we can see that there is a systematic gaming of this methodology using p-hacking, multiple hypotheses, and hiding failed experiments leading to the publication of outrageously good results, which then cannot be replicated.\nThe analysis is done on data that is supposedly sampled from a population. But the same data may belong to different populations (the city, the country, etc) each with different statistics. We should assume the same long-run frequencies would converge to different to each one of these statistics if we repeat the experiment enough times.\nThe sample size, or how long we run the experiment is a tricky decision to make in advance and without prior knowledge. And if we do not decide in advance, but periodically as the data comes in. It turns out that this can completely change the outcomes of the experiment - even if both approaches have the same data.\nThe choice of H_0 and H_1 is often subjective and each hypothesis can lead to yet another.\nThe choice of the confidence level 95%, 99%, etc. used for statistical significance is subjective.\nIf an effect size is considered large is subjective and depends on the field one studies.\n\nBayesian:\n\nthe prior should be highly informative and therefore subjective. But it can be\nuninformative and hence more objective.\nit can be difficult to decide what impact the prior should have on the posterior. Ideally, we can quantify the effective sample size for the prior data and we can understand how much information each contributes to the posterior.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-expected-values",
    "href": "C1-L01.html#sec-expected-values",
    "title": "Probability",
    "section": "",
    "text": "The expectation of an RV is a measure of its central tendency.\nThe expected value, also known as the expectation or mean, of a random variable X is denoted \\mathbb{E}[X]. It is the weighted average of all values X could take, weighted by their probabilities.\n\n\n\n\n\n\nTip\n\n\n\n\nI looked this up and found the following answer, see (https://math.stackexchange.com/users/25097/autolatry) (n.d.).\nThe RV X is a function whereas the Expectation is a Functional (a mapping from a function to a number). Mathematicians adopt the use of square brackets for functionals.\nSee Wikipedia contributors (2023) for more information on what a Functional is.\n\n\nWhy Square Brackets for Expectation\n\nIf X is a discrete-valued random variable then its expectation is defined by(Equation 21)\n\n\\mathbb{E}[X]=\\sum^N_{i=1} x_i \\cdot P(X=x_i) = \\sum^N_{i=1} x_i \\cdot f(x)\n\n\n\n\nIf X is a continuous random variable then its expectation is defined by(Equation 22)\n\n\\mathbb{E}[X]=\\int_{-\\infty}^{\\infty} x \\cdot f(x) dx\n\nwhile the mean is an important descriptive statistic for central tendencies, we often prefer the median which is robust to outliers, and pick the mode as a representative if we need a value in the data set.\n\n\n\nSum and integral are linear operators so the Expectation is also a linear operator\n\n\\mathbb{E}[c]= c\n\\tag{23}\n\n\\mathbb{E}[aX+bY] = a\\mathbb{E}[X] + b\\mathbb{E}[Y]\n\\tag{24}\n\n\\mathbb{E}[g[X]]  = \\int{g(x)f(x)dx}\n\nIf X & Y are independent\n\n\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y]",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-variance",
    "href": "C1-L01.html#sec-variance",
    "title": "Probability",
    "section": "",
    "text": "Variance is the dispersion of a distribution about the mean.\n\nDefinition 16 For a discrete random variable, the Variance is defined using (Equation 25)\n\n\\mathbb{V}ar(X)=\\sum^N_{i=1} (x_i-\\mu)^2 P(X=x_i)\n\\tag{25}\n\n\nDefinition 17 For a continuous random variable, the Variance is defined using (Equation 26)\n\n\\mathbb{V}ar[X]=\\int_{- \\infty}^{\\infty} (x-\\mu)^2 f(x)dx\n\\tag{26}\n\n\n\n\n\\mathbb{V}ar[c] = 0\n\\tag{27}\nif X and Y are independent then\n\n\\mathbb{V}ar[aX+by] = a^2\\mathbb{V}ar[X] +b^2\\mathbb{V}ar[Y]\n\\tag{28}\notherwise\n\n\\mathbb{V}ar[aX+by] = a^2\\mathbb{V}ar[X] +b^2\\mathbb{V}ar[Y] + 2ab\\mathbb{C}ov(X,Y)\n\\tag{29}\nwhere \\mathbb{C}ov(X,Y) is the covariance of X and Y.\nHere is one of the most useful identities (Equation 30) for wrangling with variance using the expectation of X and X^2.\n\n\\begin{aligned}\n    \\mathbb{V}ar[X] &= \\mathbb{E}[(X- \\mathbb{E}[X])^2]\n    \\\\&= \\mathbb{E}[X^2] − (\\mathbb{E}[X])^2\n\\end{aligned}\n\\tag{30}",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-covariance",
    "href": "C1-L01.html#sec-covariance",
    "title": "Probability",
    "section": "",
    "text": "Covariance is a measure of the joint variability of two random variables. It indicates the direction of the linear relationship between the variables.\nIf X and Y are two random variables, the covariance of X and Y is defined as:\n\n\\begin{aligned}\n\\mathrm{Cov}(X,Y) &= \\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])]\n\\\\ &= \\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]\n\\end{aligned}\n\\tag{31}",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "C1-L01.html#sec-correlation",
    "href": "C1-L01.html#sec-correlation",
    "title": "Probability",
    "section": "",
    "text": "Correlation is a standardized measure of the linear relationship between two random variables. It is a dimensionless quantity that ranges from -1 to 1.\nThe correlation coefficient \\rho_{XY} is defined as the covariance of X and Y divided by the product of their standard deviations:\n\n\\rho_{XY} = \\frac{\\mathrm{Cov}(X,Y)}{\\sigma_X\\sigma_Y}\n\\tag{32}",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Probability"
    ]
  },
  {
    "objectID": "dists.html",
    "href": "dists.html",
    "title": "dists",
    "section": "",
    "text": "Code\nimport bokeh.io\nbokeh.io.output_notebook(hide_banner=True)\n\nimport numpy as np\nimport scipy.stats as st\nimport scipy.special\n\nimport bokeh.plotting\nimport bokeh.application\nimport bokeh.application.handlers\n\n\nx = np.arange(0, 11)\nx_size = x[-1] - x[0]\nx_c = np.empty(2*len(x))\nx_c[::2] = x\nx_c[1::2] = x\nx_c = np.concatenate(((max(x[0] - 0.05*x_size, x[0] - 0.95),), \n                      x_c,\n                      (min(x[-1] + 0.05*x_size, x[-1] + 0.95),)))\nx_cdf = np.concatenate(((x_c[0],), x))\n\ny = st.binom.cdf(x_cdf, 10, 0.5)\ny_c = np.empty_like(x_c)\ny_c[::2] = y\ny_c[1::2] = y\n\np = bokeh.plotting.figure(min_height=250,\n                          min_width=350,\n                          x_axis_label='n',\n                          y_axis_label='F(n; 10, 0.5)')\np.line(x_c, y_c, line_width=2)\nbokeh.io.show(p)"
  },
  {
    "objectID": "dists.html#example",
    "href": "dists.html#example",
    "title": "dists",
    "section": "5.1 Example",
    "text": "5.1 Example\nAny multi-step process where each step happens at the same rate. This is common in molecular rearrangements."
  },
  {
    "objectID": "dists.html#gamma1-shape-scale-prameterization",
    "href": "dists.html#gamma1-shape-scale-prameterization",
    "title": "dists",
    "section": "5.2 Gamma1 shape, scale prameterization",
    "text": "5.2 Gamma1 shape, scale prameterization\n\nshape (k &lt; 0),\nscale (\\theta &gt; 0)\nVariance \n      \\mathbb{V}ar[Gamma_1|k,\\theta] = k \\theta^2\n   \\tag{1}\nPDF \n      \\frac{1}{\\Gamma(k) \\theta^k} x^{k \\,-\\, 1}e^{-\\frac{x}{\\theta}}\n  \nCDF \n      \\frac{1}{\\Gamma(k)} \\gamma\\left(k,\\, \\frac{x}{\\theta}\\right)\n       \\tag{2}\nSF \n      1 - \\frac{\\Gamma(\\beta,x/\\alpha)}{\\Gamma(\\beta)}\n   \\tag{3}\nmode \n      (k \\,-\\, 1)\\theta \\text{ for } k \\;{\\geq}\\; 1\n   \\tag{4}\nmedian \n      \\text{No simple closed form}\n   \\tag{5}\nmean \n      k \\theta\n   \\tag{6}\n\nFor (k, θ) parameterization: θ is a reciprocal of the event rate λ, which is the mean wait time (the average time between event arrivals)."
  },
  {
    "objectID": "dists.html#gamma2-shape-rate-prameterization",
    "href": "dists.html#gamma2-shape-rate-prameterization",
    "title": "dists",
    "section": "5.3 Gamma2 shape rate prameterization",
    "text": "5.3 Gamma2 shape rate prameterization\n\nshape (\\alpha &gt; 0),\nrate (\\beta &gt; 0)\nPDF \n      \\frac{\\mu^r x^{r-1} e^{-\\mu x}}{\\Gamma(r)}\n   \\tag{7}\nCDF\nVar\n\nFor (α, β) parameterization: Using our notation k (the # of events) & λ (the rate of events), simply substitute α with k, β with λ. The PDF stays the same format as what we’ve derived.\n\n\nCode\nbokeh.io.output_notebook(hide_banner=True)\n\n# Gamma Distribution\n\nk, theta = 7.5, 1.0\n\nmeasured = np.random.gamma(k, theta, 1000)\nhist, edges = np.histogram(measured, density=True, bins=50)\n\nx = np.linspace(0.0001, 20.0, 1000)\npdf = x**(k-1) * np.exp(-x/theta) / (theta**k * scipy.special.gamma(k))\ncdf = scipy.special.gammainc(k, x/theta)\n\np3 = make_plot(\"Gamma Distribution (k=7.5, θ=1)\", hist, edges, x, pdf, cdf)\nshow(gridplot([p3], ncols=1, width=400, height=400, toolbar_location=None))\n\n\n\n  \n\n\n\n\n\nCode\nimport numpy as np\nfrom scipy.stats import gamma\nimport matplotlib.pyplot as plt\n\ndef plot_gamma_k():\n    \"\"\"\n    k : the number of events for which you are waiting to occur.\n    λ : the rate of events happening following Poisson dist.\n    \"\"\"\n    x = np.linspace(0, 50, 1000)\n    a_values=[1.,2.,3.,5., 9.,7.5,0.5]\n    b_values=[2.,2.,2.,1.,0.5,1. ,1.]\n    plt.title(\"PDF of Gamma Distribution\")\n    plt.xlabel(\"T\")\n    plt.ylabel(\"Probability Density\")\n    colors = plt.cm.Pastel1(np.linspace(0, 1, len(a_values)))\n    colors = plt.cm.rainbow(np.linspace(0, 1, len(a_values)))\n\n    for i,z in enumerate(zip(a_values,b_values)): \n      a,b = z\n      #mean, var, skew, kurt = gamma.stats(a, moments='mvsk')\n      y = gamma.pdf(x, a=a,scale=b)\n      plt.plot(x, y, label=f\"k={a}, θ={b}\", color=colors[i])\n      plt.legend(bbox_to_anchor=(1, 1), loc='upper right',\n               borderaxespad=1, fontsize=12)\n    plt.ylim([0, 0.50])\n    plt.xlim([0, 20])\n    plt.show()\n    plt.savefig('gamma_k.png')\n    plt.clf()\n\nplot_gamma_k()\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\nCode\ndef plot_gamma_lambda():\n    \"\"\"\n    k : the number of events for which you are waiting to occur.\n    λ : the rate of events happening following Poisson dist.\n    \"\"\"\n    a = 10  # k = 10\n    x = np.linspace(0, 50, 1000)\n    import matplotlib as mpl\n\n    #colors = ['gold','burlywood','darkorange']\n    plt.title(\"PDF of Gamma Distribution (k = 10)\")\n    plt.xlabel(\"T\")\n    plt.ylabel(\"Probability Density\")\n    lambdas = [1,2,3]\n    #colors = plt.cm.rainbow(np.linspace(0, 1, len(lambdas)))\n    colors = plt.cm.Pastel1(np.linspace(0, 1, len(lambdas)))\n    for i,lambda_  in enumerate(lambdas):\n      #mean, var, skew, kurt = gamma.stats(a, scale=1/lambda_, moments='mvsk')\n      y = gamma.pdf(x, a, scale=1/lambda_)\n      plt.plot(x, y, label=f\"λ = {lambda_}\", color=colors[i])\n    plt.legend(bbox_to_anchor=(1, 1), loc='upper right', borderaxespad=1, fontsize=12)\n    plt.ylim([0, 0.40])\n    plt.xlim([0, 20])\n    plt.show()\n    plt.savefig('gamma_lambda.png')\n    plt.clf()\n\n\n_=plot_gamma_lambda()\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "dists.html#examples",
    "href": "dists.html#examples",
    "title": "dists",
    "section": "6.1 Examples:",
    "text": "6.1 Examples:\n\nThe Beta Distribution can be used for representing the different probabilities as follows:\nThe likelihood of the audience rating the new movie release.\nThe click-through rate of the website, which is the proportion of visitors.\nThe conversion rate for buyers actually purchasing from your website.\nThe survival chance of a person having blood cancer.\n\n\n\nCode\n#from numpy.random import default_rng\nbokeh.io.output_notebook(hide_banner=True)\n# Beta Distribution\n\nstory= \"\"\"Say you wait for two multistep Poisson processes to arive. The individual steps of each process happen at the same rate, but the first multistep process requires alpha steps and the second requires beta \n steps. The fraction of the total waiting time taken by the first process is Beta distributed.\"\"\"\n\nalpha, beta = 2, 3\n# Do this (new version)\nmeasured = np.random.default_rng().beta(alpha, beta, size=10000)\nhist, edges = np.histogram(measured, density=True, bins=50)\nparam_vals={'alpha':1,'beta':1}\nx = np.linspace(0.0001, 0.999, 1000)\n#pdf = x**(k-1) * np.exp(-x/theta) / (theta**k * scipy.special.gamma(k))\nrv = st.beta(alpha, beta)\npdf = rv.pdf(x)##st.beta.pdf(x,*param_vals)\ncdf = rv.cdf(x)##st.beta.cdf(x,*param_vals)\n\np4 = make_plot(\"Beta Distribution (alpha=1, beta=1)\", hist, edges, x, pdf, cdf)\nshow(gridplot([p4], ncols=1, width=400, height=400, toolbar_location=None))"
  },
  {
    "objectID": "dists.html#example-1",
    "href": "dists.html#example-1",
    "title": "dists",
    "section": "8.1 Example",
    "text": "8.1 Example\n\nThe Gutenberg-Richter Law says that the magnitudes of earthquakes in a given region are Pareto distributed.\nsize of human settlement (many small towns, a few huge cities),\nincome distribution (many poor, few obscenely rich).\n\n\n\nCode\nbokeh.io.output_notebook(hide_banner=True)\nfrom scipy.stats import pareto\n\n# Pareto Distribution\n\nstory= \"\"\"Say you wait for two multistep Poisson processes to arive. The individual steps of each process happen at the same rate, but the first multistep process requires alpha steps and the second requires beta  steps. The fraction of the total waiting time taken by the first process is Beta distributed.\"\"\"\n\nb = 2.62\nrv = st.pareto(b)\n# Do this (new version)\n#measured = np.random.default_rng().pareto(b, size=1000)\nmeasured = pareto.rvs(b, size=1000)\n\nhist, edges = np.histogram(measured, density=True, bins=50)\nparam_vals={'alpha':1,'beta':1}\nx = np.linspace(pareto.ppf(0.01, b), pareto.ppf(0.99, b), 100)\npdf = rv.pdf(x)\ncdf = rv.cdf(x)\n\np6 = make_plot(f\"Pareto Distribution (b={b})\", hist, edges, x, pdf, cdf)\nshow(gridplot([p6], ncols=1, width=400, height=400, toolbar_location=None))"
  },
  {
    "objectID": "C3-L01.html",
    "href": "C3-L01.html",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "NoteTODO list\n\n\n\n\n\n\nfor each mixture add.\na formula and.\nan example why such a mixture is useful.\nin the graphs consider also plotting the the components in different color as well as the actual mixture.\nadd code for generating the mixtures in basic python.\nadd code for generating the mixtures in PYMC/bambi\nadd all images light box to a gallery - via a regex !?\nas needed extract from the lesson transcript some key points and add them to the notes - via the save note feature on Coursera.\nexplain the two forms of likelihoods.\n\n\n\n\nHandout: Mixture model\nMixture models provide a flexible approach to modeling data and are useful in density estimation, clustering and classification problems:\n\nStandard families of probability distributions such as the Gaussian, exponential or Poisson are often too restrictive for modeling features of real data such as multimodality or zero inflation. Mixture models, which can be related to kernel density estimation procedures, address this issue in a way that allows for natural generalizations of well-known procedures.\nIn addition to providing flexible probability distributions, finite mixture models have a strong relationship with classical clustering and classification procedures such as K-mean clustering, as well as linear and quadratic discriminant analysis. More generally they provide a tool to understand and generalize these approaches, as well as to quantify the uncertainty associated with the estimates and predictions generated by them.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Mixtures definitions\n\n\n\nDefinition 1 Let \\omega_1 , \\ldots , \\omega_K be a collection of real numbers such that 0 \\le \\omega_k \\le 1 and \\sum^K_{k=1} \\omega_k = 1, and G_1, \\ldots, G_K be a collection of cumulative distribution functions. A random variable X with cumulative distribution function F(x) = Pr(X \\le x) of the form\n\nF(x) =\\sum^K_{k=1} \\underbrace{\\omega_k}_{weight}\\ \\cdot \\ \\underbrace{G_k(X)}_{component} \\qquad\n\\tag{1}\nis said to follow a finite mixture distribution with K components.\n\nf(x) =\\sum^K_{k=1} \\underbrace{\\omega_k}_{weight}\\ \\cdot \\ \\underbrace{g_k(X)}_{component} \\qquad\n\\tag{2}\nwhere g_k(x) is the density associated with G_k(x)\nThe values \\omega_1, \\ldots, \\omega_K are usually called the “weights” of the mixture, and the distributions G_1 , \\ldots, G_K are called the “components” of the mixture.\n\nEach component will typically belong to a parametric family that is indexed by its own parameter \\theta_k .\nWe will write G_k(x) = G_k (x \\mid \\theta_k ) whenever it is necessary to highlight the dependence on these parameters.\nIt is often the case that G_1, \\ldots, G_K all belong to the same family and differ only in the value parameters associated with each of the distributions, so that G_k (x \\mid \\theta_k ) = G(x \\mid \\theta_k ). In that case, the function G (and sometimes its density/probability mass function g) are called the “kernel” of the mixture.\n\n\n\n\nFor example, we could define a mixture with K = 3 components, with G(x \\mid \\theta_1 ), G(x \\mid \\theta_2 ) and G(x \\mid \\theta_3 ) all corresponding to exponential distributions with means \\theta_1 , \\theta_2 and \\theta_3 respectively.\nIn that case, the cumulative distribution function of the mixture is given by\n\nF(x) = \\left(\\omega_1 \\left[ 1 − e^ {x \\over \\theta_1}\\right] + \\omega_2\\left[ 1 − e^ {x \\over \\theta_2}\\right] + \\omega_3 \\left[ 1 − e^ {x \\over \\theta_3}\\right] \\right)\\mathbb{I}_{x\\ge0} \\qquad\n\\tag{3}\n\nf(x) = \\left({\\omega_1\\over \\theta_1} \\left[ 1 − e^ {x \\over \\theta_1}\\right] + {\\omega_2\\over \\theta_2}\\left[ 1 − e^ {x \\over \\theta_2}\\right] + {\\omega_3\\over \\theta_3} \\left[ 1 − e^ {x \\over \\theta_3}\\right] \\right)\\mathbb{I}_{x\\ge0} \\qquad\n\\tag{4}\n\n\n\n\n\n\n\n\nFigure 2: normal mixtures examples\n\n\n\nMixtures of normal can take more flexible form than an individual normal.\nWe can use mixtures to create:\n\nUnimodal distributions Figure 12\nBi-modal distribution c.f. Figure 8\nMulti-modal distributions.\n\nHeavy tailed distributions Figure 12\nAsymmetric distributions Figure 10\nZero inflated distribution Figure 14 Figure 16\n\n\n\nExample 1 (Location mixture of Normals)  \n\nThis is a mixture of Gaussian distributions with the same variance but different means.\nAs the center of the normal distribution is based on the mean \\mu_k, get get a mixture with similar normals at different locations.\n\n\nf(x) = \\sum_k \\omega_k {1\\over \\sqrt{2 \\pi \\sigma}}e^{-{1\\over 2 \\sigma}(x-\\mu_k)^2} \\qquad\n\\tag{5}\n\n\nExample 2 (Location scale mixture of Normals)  \n\nThis time we have a mixture of Gaussian distributions with different means and variances.\nThis allows us to create a mixture with different locations and scales.\n\n\nf(x) = \\sum_k \\omega_k {1\\over \\sqrt{2 \\pi \\sigma_k}}e^{-{1\\over 2 \\sigma_k}(x-\\mu_k)^2} \\qquad\n\\tag{6}\n\n\n\n\n\n\n\n\nFigure 3: Zero inflated Mixture distribution\n\n\n\n\n\n\n\n\nFigure 4: parametrization of the model\n\n\n\n\n\n\n\n\nFigure 5: expectation of a mixture\n\n\n\n\n\n\n\n\nFigure 6: MFG of a mixture\n\n\n\n\n\nThe expectation of a mixture is straightforward to compute, as it is a weighted sum of the expectations of the components.\nthe moment generating function of a mixture is also straightforward to compute, as it is a weighted sum of the moment generating functions of the components.\nThe variance of a mixture is not as straightforward to compute, as it involves the second moment of the components and the square of the expectation. However there is a degenerate case where the variance of the mixture is equal to the weighted sum of the variances of the components.\n\n\n\n\n\n\n\nFigure 7: variance of a mixture\n\n\n\n\nHere we will look at a few examples of mixtures of Gaussians which display different properties not available in a single Gaussian distribution.\n\n\n\nRpython\n\n\n\n\nCode\n# Mixture of univariate Gaussians, bimodal\nx = seq(-5, 12, length=100)\ny = 0.6*dnorm(x, 0, 1) + 0.4*dnorm(x, 5, 2)\n\n\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\n# set the title\ntitle(\"Bimodal Mixture of Gaussians\")\n\n\n\n\n\n\n\n\nFigure 8: Bimodal Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# title: Mixture of univariate Gaussians, bimodal\nfrom scipy.stats import norm\n\n# Values to sample\nx = np.linspace(-5, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nstd_1 = 1\nr_n1 = norm.pdf(x,loc = mu_1, scale = std_1)\n# Normal 2 Distribution\nmu_2 = 5\nstd_2 = 2\nr_n2 = norm.pdf(x, loc = mu_2, scale = std_2)\n\n### computing mixture model\nmixture_model = (0.6 * r_n1) + (0.4 * r_n2)\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=mixture_model)\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of two Gaussians')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9: Bimodal Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()\n\n\n\n\n\n\n\n\n\nf(x) = 0.55 \\times \\mathcal{N}(0, 2) + 0.45 \\times \\mathcal{N}(3, 4) \\qquad\n\\tag{7}\n\nRpython\n\n\n\n\nCode\nx = seq(-5, 12, length=100)\ny = 0.55*dnorm(x, 0, sqrt(2)) + 0.45*dnorm(x, 3, 4)\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\n\n\n\n\n\n\n\n\nFigure 10: Uni-modal Skewed Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# Values to sample\nx = np.linspace(-5, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nvar_1 = 2\nr_n1 = norm.pdf(loc = mu_1, scale = np.sqrt(var_1), x = x)\n# Normal 2 Distribution\nmu_2 = 3\nvar_2 = 16\nr_n2 = norm.pdf(loc = mu_2, scale = np.sqrt(var_2), x = x)\n\n### computing mixture model\nmixture_model = (0.55 * r_n1) + (0.45 * r_n2)\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=mixture_model)\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of two Gaussians Skewed')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 11: Uni-modal Skewed Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()\n\n\n\n\n\n\n\n\n\nf(x) = 0.40 \\times \\mathcal{N}(0, 2) + 0.40 \\times \\mathcal{N}(0, 4) + 0.20 \\times \\mathcal{N}(0, 5) \\qquad\n\\tag{8}\n\nRpython\n\n\n\n\nCode\n# simulate Mixture of univariate Gaussians, unimodal heavy tail\n\nx = seq(-12, 12, length=100)\ny = 0.40 * dnorm(x, 0, sqrt(2)) + \n    0.40 * dnorm(x, 0, sqrt(16)) + \n    0.20 * dnorm(x, 0, sqrt(20))\nz = dnorm(x, 0, sqrt(0.4*2 + 0.4*16 + 0.2*20))\n\n\n\n\nCode\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\nlines(x, z, lty=2, lwd=2)\nlegend(2, 0.16, c(\"Mixture\",\"Gaussian\"), lty=c(1,2), bty=\"n\", cex=0.77, lwd=c(2,2))\n\n\n\n\n\n\n\n\nFigure 12: Unimodal Heavy Tailed Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# Values to sample\nx = np.linspace(-12.0, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nvar_1 = 2\nr_n1 = norm.pdf(loc = mu_1, scale = np.sqrt(var_1), x = x)\n# Normal 2 Distribution\nmu_2 = 0\nvar_2 = 16\nr_n2 = norm.pdf(loc = mu_2, scale = np.sqrt(var_2), x = x)\n# Normal 3 Distribution\nmu_3 = 0\nvar_3 = 20\nr_n3 = norm.pdf(loc = mu_3, scale = np.sqrt(var_3), x = x)\n\n### computing mixture model\ny = (0.4 * r_n1) + (0.4 * r_n2) + (0.2 * r_n3)\nz = norm.pdf(loc = 0, scale = np.sqrt(0.4 * 2 + 0.4 * 16 + 0.2 * 20), x = x)\n\n\n\n\nCode\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=y)\nax.plot(x, z, '--')\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of gaussians heavy tailed')\nplt.legend(['Mixture', 'Gaussian'])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 13: Unimodal Heavy Tailed Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()\n\n\n\n\n\n\n\n\n\n\nZero inflated distributions are useful for modeling data with excess zeros (often in term of count data).\nWe learned in course 1 & 2 that the negative binomial or equivalent beta are zero inflated in comparison to the Poisson distribution.\nToday we see how we use mixture models by adding a point mass at zero to the distribution.\nExample from biology is the number of eggs in a nest.\nExample from insurance is the number of claims in a year.\nExample from survival analysis is the time to event data with a lot of censoring.\n\nNote there are two approaches to zero inflation:\n\none step models like the negative binomial.\nhurdle models - two step models where we first model the zero inflation and then the count data - This corresponds to the hierarchical representation of the mixture model.\n\n\n\nThis is a mixture of a point mass at zero and a log Gaussian distribution. This corresponds to the example where we have a light bulb factory and we want to model the time to failure of the light bulbs. We know that for the defective light bulbs, the time to failure is zero. For the non-defective light bulbs, the time to failure is log normally distributed with mean 1.5 and standard deviation 0.5\n\nf(x) = 0.3 \\times \\mathbb{I}_{x\\ge0} + 0.7 \\times \\mathcal{LN}(1.5, 0.5) \\qquad\n\\tag{9}\n\nRpython\n\n\n\n\nCode\n## The ZILN model \nx = seq(-2, 15, length=1000)\ny = plnorm(x, 1.5, 0.5)\nz = 0.3*as.numeric(x&gt;=0) + (1-0.3)*y\n\n\n\n\nCode\n## The plot\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", las=1, lty=2, xlab=\"x\", \n     ylab=\"Cumulative distribution Function\", lwd=2)\nlines(x, z, lty=1, lwd=2)\nlegend(4, 0.45, c(\"Zero infla. log Gaussian\",\"log Gaussian\"), \n     lty=c(1,2), bty=\"n\", lwd=c(2,2))\n\n\n\n\n\n\n\n\nFigure 14: Zero inflated log Gaussian\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import lognorm\n\n# Zero-inflated continuous distribution\n# Values to sample\nx = np.linspace(-2.0, 15.0, num = 200)\n# See for parameterization\ny = lognorm.pdf(loc = 0, scale = np.exp(1.5), s = 0.5, x = x)\n\n# Point mass vector\np_mass = np.zeros(len(x))\np_mass[x &gt;= 0] = 1\nz = 0.3 * p_mass + (1 - 0.3) * y\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nax.plot(x, y)\nax.plot(x, z, '--')\nplt.xlabel('X')\nplt.ylabel('Cumulative distribution function')\nplt.title('Zero-inflated continuous distribution')\nplt.legend(['Log gaussian', 'Zero infla. Log gaussian'])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 15: Zero inflated log Gaussian\n\n\n\n\n\n\n\n\n\n\n\n\nf(x) = 0.2 \\times \\mathbb{I}_{x=0} + 0.8 \\times NB(8, 0.6) \\qquad\n\\tag{10}\n\nRpython\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\nx = seq(0, 15)\ny = dnbinom(x, 8, 0.6)\nz = 0.2*c(1,rep(0,length(x)-1)) + (1-0.2)*y\npar(mfrow=c(2,1))\npar(mar=c(4,4,2,2)+0.1)\nbarplot(y, names.arg=x, las=1, xlab = \"x\", ylab=\"Probability\", \n        border=NA, main=\"Negative Binomial\")\npar(mar=c(4,4,1,1)+0.1)\nbarplot(z, names.arg=x, las=1, xlab = \"x\", ylab=\"Probability\", \n        border=NA, main=\"Zero-inflated Negative Binomial\")\n\n\n\n\n\n\n\n\nFigure 16: Zero inflated negative binomial\n\n\n\n\n\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\nfrom scipy.stats import nbinom\nimport seaborn as sns\n\n# Values to sample\nx = np.arange(0, 16)\ny = nbinom.pmf(x, n = 8, p = 0.6)\n\n# Plotting the negative binomial model\nfig, ax = plt.subplots(1, 1)\n\nsns.barplot(x=x, y=y, color = 'blue')\n\nplt.title('Negative Binomial')\nplt.xlabel('Count')\nplt.ylabel('PMF')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 17: Zero inflated negative binomial\n\n\n\n\n\nCode\n# Point mass vector\np_mass = np.zeros(len(x))\np_mass[0] = 1\nz = 0.2 * p_mass + (1 - 0.2) * y\n\n# Plotting the zero-inflated model\nfig, ax = plt.subplots(1, 1)\nsns.barplot(x=x, y=z, color = 'blue')\nplt.title('Zero-Inflated model')\nplt.xlabel('Count')\nplt.ylabel('PMF')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 18: Zero inflated negative binomial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 19: Hierarchical representation of a mixture\n\n\n\n\n\n\n\n\nFigure 20: simulation of a mixture\n\n\n\nRecall that the cumulative distribution function of a mixture takes the form Equation 1, where G_k(x) is the cumulative distribution function of the k-th component of the mixture.\nWe can use a RV for each component and introduce an indicator RV for the component selector C_i to select the component from which we will sample. This results in a hierarchical representation of the mixture model.\n\nX \\mid c \\sim g_c(x) \\qquad \\mathbb{P}r(c=k) = \\omega_k \\qquad\n\\tag{11}\nwhere C is a categorical random variable with K categories, and G_k(x \\mid C=k) is the cumulative distribution function of the k-th component of the mixture given that we have selected the k-th component.\nThis allows us to write the cumulative distribution function of the mixture as a weighted sum of the cumulative distribution functions of the components\n\np(x) = \\sum^K_{k=1} p(x \\mid C=k) \\cdot \\mathbb{P}r(C=k) = \\sum^K_{k=1} g_k(x) \\cdot \\omega_k \\qquad\n\\tag{12}\nwhere g_k(x) is the cumulative distribution function of the k-th component of the mixture.\n\n\n\nRpython\n\n\n\n\nCode\n# Generate n observations from a mixture of two Gaussian distributions\nn     = 50           # required sample size\nw     = c(0.6, 0.4)  # mixture weights\nmu    = c(0, 5)      # list of means\nsigma = c(1, 2)      # list of sds\ncc    = sample(1:2, n, replace=T, prob=w) # sample for the component selector\nx     = rnorm(n, mu[cc], sigma[cc]) # sample the selected component\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = seq(-5, 12, length=200)\nyy = w[1] * dnorm(xx, mu[1], sigma[1]) + w[2] * dnorm(xx, mu[2], sigma[2])\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\npoints(x, y=rep(0,n), pch=1, col=cc)\n\n\n\n\n\n\n\n\nFigure 21: Mixture of two Gaussians\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom scipy.stats import norm\n\nn=50           # required sample size\nw=[0.6, 0.4]  # mixture weights\nmu=[0, 5]      # list of means\nsigma=[1, 2]  # list of sds\ncc = np.random.choice([0, 1], size=n, p=w) # sample for the component selector\n# sample the selected component\nx = np.array([np.random.normal(mu[i], sigma[i]) for i in cc])\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = np.linspace(-5, 12, num=200)\nyy = w[0]*norm.pdf(loc=mu[0], scale=sigma[0], x=xx) + \\\n     w[1]*norm.pdf(loc=mu[1], scale=sigma[1], x=xx)\nplt.plot(xx, yy, label='Mixture of Gaussians')\nplt.scatter(x, np.zeros(n), c=cc, label='Sampled data')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.title('Mixture of Gaussians')\nplt.legend()\nplt.show() \n\n\n\n\n\n\n\n\nFigure 22: Mixture of two Gaussians\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 23: observed data likelihood\n\n\n\n\n\n\n\n\nFigure 24: complete data likelihood\n\n\n\n\nwe are now moving on to inferring the parameters of the mixture model from the observed data.\nwe can estimate these using the maximum likelihood estimation or with Bayesian estimation.\nin both cases we will need to compute the likelihood of the observed data.\nthere are two types of likelihoods:\n\nthe observed data likelihood is the probability of observing the data given the parameters of the model.\nthe complete data likelihood is the probability of observing the data and the latent variables given the parameters of the model.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 25: Identifiability - Label switching\n\n\n\n\n\n\n\n\nFigure 26: identifiability - split weights\n\n\n\n\n\n\n\n\nFigure 27: identifiability - zero weights\n\n\n\n\nA probability model is identifiable if and only if different values of the parameters generate different probability distributions of the observable variables.\nOne challenge involved in working with mixture models is that they are not fully identifiable.\nThe problem is that different representations exists for the same mixture.\nQuestion: Is there a “Canonical representation” which fixes this, essentially a convention like:\n1. picking the representation with the least components (no zero weights)\n2. ordered with descending w_i\n\n\nThe labels used to distinguish the components in the mixture are not identifiable. The literature sometimes refers to this type of lack of identifiability as the label switching “problem”. Whether label switching is an actual problem or not depends on the computational algorithm being used to fit the model, and the task we are attempting to complete in any particular case. For example, label switching tends to not be an issue for the purpose of density estimation or classification problems, but it can lead to serious difficulties in clustering problems.",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L01.html#introduction-to-mixture-modeling",
    "href": "C3-L01.html#introduction-to-mixture-modeling",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "Figure 1: Mixtures definitions\n\n\n\nDefinition 1 Let \\omega_1 , \\ldots , \\omega_K be a collection of real numbers such that 0 \\le \\omega_k \\le 1 and \\sum^K_{k=1} \\omega_k = 1, and G_1, \\ldots, G_K be a collection of cumulative distribution functions. A random variable X with cumulative distribution function F(x) = Pr(X \\le x) of the form\n\nF(x) =\\sum^K_{k=1} \\underbrace{\\omega_k}_{weight}\\ \\cdot \\ \\underbrace{G_k(X)}_{component} \\qquad\n\\tag{1}\nis said to follow a finite mixture distribution with K components.\n\nf(x) =\\sum^K_{k=1} \\underbrace{\\omega_k}_{weight}\\ \\cdot \\ \\underbrace{g_k(X)}_{component} \\qquad\n\\tag{2}\nwhere g_k(x) is the density associated with G_k(x)\nThe values \\omega_1, \\ldots, \\omega_K are usually called the “weights” of the mixture, and the distributions G_1 , \\ldots, G_K are called the “components” of the mixture.\n\nEach component will typically belong to a parametric family that is indexed by its own parameter \\theta_k .\nWe will write G_k(x) = G_k (x \\mid \\theta_k ) whenever it is necessary to highlight the dependence on these parameters.\nIt is often the case that G_1, \\ldots, G_K all belong to the same family and differ only in the value parameters associated with each of the distributions, so that G_k (x \\mid \\theta_k ) = G(x \\mid \\theta_k ). In that case, the function G (and sometimes its density/probability mass function g) are called the “kernel” of the mixture.",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L01.html#three-component-exponential-mixture",
    "href": "C3-L01.html#three-component-exponential-mixture",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "For example, we could define a mixture with K = 3 components, with G(x \\mid \\theta_1 ), G(x \\mid \\theta_2 ) and G(x \\mid \\theta_3 ) all corresponding to exponential distributions with means \\theta_1 , \\theta_2 and \\theta_3 respectively.\nIn that case, the cumulative distribution function of the mixture is given by\n\nF(x) = \\left(\\omega_1 \\left[ 1 − e^ {x \\over \\theta_1}\\right] + \\omega_2\\left[ 1 − e^ {x \\over \\theta_2}\\right] + \\omega_3 \\left[ 1 − e^ {x \\over \\theta_3}\\right] \\right)\\mathbb{I}_{x\\ge0} \\qquad\n\\tag{3}\n\nf(x) = \\left({\\omega_1\\over \\theta_1} \\left[ 1 − e^ {x \\over \\theta_1}\\right] + {\\omega_2\\over \\theta_2}\\left[ 1 − e^ {x \\over \\theta_2}\\right] + {\\omega_3\\over \\theta_3} \\left[ 1 − e^ {x \\over \\theta_3}\\right] \\right)\\mathbb{I}_{x\\ge0} \\qquad\n\\tag{4}",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L01.html#zero-inflated-mixtures",
    "href": "C3-L01.html#zero-inflated-mixtures",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "Zero inflated distributions are useful for modeling data with excess zeros (often in term of count data).\nWe learned in course 1 & 2 that the negative binomial or equivalent beta are zero inflated in comparison to the Poisson distribution.\nToday we see how we use mixture models by adding a point mass at zero to the distribution.\nExample from biology is the number of eggs in a nest.\nExample from insurance is the number of claims in a year.\nExample from survival analysis is the time to event data with a lot of censoring.\n\nNote there are two approaches to zero inflation:\n\none step models like the negative binomial.\nhurdle models - two step models where we first model the zero inflation and then the count data - This corresponds to the hierarchical representation of the mixture model.\n\n\n\nThis is a mixture of a point mass at zero and a log Gaussian distribution. This corresponds to the example where we have a light bulb factory and we want to model the time to failure of the light bulbs. We know that for the defective light bulbs, the time to failure is zero. For the non-defective light bulbs, the time to failure is log normally distributed with mean 1.5 and standard deviation 0.5\n\nf(x) = 0.3 \\times \\mathbb{I}_{x\\ge0} + 0.7 \\times \\mathcal{LN}(1.5, 0.5) \\qquad\n\\tag{9}\n\nRpython\n\n\n\n\nCode\n## The ZILN model \nx = seq(-2, 15, length=1000)\ny = plnorm(x, 1.5, 0.5)\nz = 0.3*as.numeric(x&gt;=0) + (1-0.3)*y\n\n\n\n\nCode\n## The plot\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", las=1, lty=2, xlab=\"x\", \n     ylab=\"Cumulative distribution Function\", lwd=2)\nlines(x, z, lty=1, lwd=2)\nlegend(4, 0.45, c(\"Zero infla. log Gaussian\",\"log Gaussian\"), \n     lty=c(1,2), bty=\"n\", lwd=c(2,2))\n\n\n\n\n\n\n\n\nFigure 14: Zero inflated log Gaussian\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import lognorm\n\n# Zero-inflated continuous distribution\n# Values to sample\nx = np.linspace(-2.0, 15.0, num = 200)\n# See for parameterization\ny = lognorm.pdf(loc = 0, scale = np.exp(1.5), s = 0.5, x = x)\n\n# Point mass vector\np_mass = np.zeros(len(x))\np_mass[x &gt;= 0] = 1\nz = 0.3 * p_mass + (1 - 0.3) * y\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nax.plot(x, y)\nax.plot(x, z, '--')\nplt.xlabel('X')\nplt.ylabel('Cumulative distribution function')\nplt.title('Zero-inflated continuous distribution')\nplt.legend(['Log gaussian', 'Zero infla. Log gaussian'])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 15: Zero inflated log Gaussian\n\n\n\n\n\n\n\n\n\n\n\n\nf(x) = 0.2 \\times \\mathbb{I}_{x=0} + 0.8 \\times NB(8, 0.6) \\qquad\n\\tag{10}\n\nRpython\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\nx = seq(0, 15)\ny = dnbinom(x, 8, 0.6)\nz = 0.2*c(1,rep(0,length(x)-1)) + (1-0.2)*y\npar(mfrow=c(2,1))\npar(mar=c(4,4,2,2)+0.1)\nbarplot(y, names.arg=x, las=1, xlab = \"x\", ylab=\"Probability\", \n        border=NA, main=\"Negative Binomial\")\npar(mar=c(4,4,1,1)+0.1)\nbarplot(z, names.arg=x, las=1, xlab = \"x\", ylab=\"Probability\", \n        border=NA, main=\"Zero-inflated Negative Binomial\")\n\n\n\n\n\n\n\n\nFigure 16: Zero inflated negative binomial\n\n\n\n\n\n\n\n\n\nCode\n## title: Zero inflated negative binomial distribution\nfrom scipy.stats import nbinom\nimport seaborn as sns\n\n# Values to sample\nx = np.arange(0, 16)\ny = nbinom.pmf(x, n = 8, p = 0.6)\n\n# Plotting the negative binomial model\nfig, ax = plt.subplots(1, 1)\n\nsns.barplot(x=x, y=y, color = 'blue')\n\nplt.title('Negative Binomial')\nplt.xlabel('Count')\nplt.ylabel('PMF')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 17: Zero inflated negative binomial\n\n\n\n\n\nCode\n# Point mass vector\np_mass = np.zeros(len(x))\np_mass[0] = 1\nz = 0.2 * p_mass + (1 - 0.2) * y\n\n# Plotting the zero-inflated model\nfig, ax = plt.subplots(1, 1)\nsns.barplot(x=x, y=z, color = 'blue')\nplt.title('Zero-Inflated model')\nplt.xlabel('Count')\nplt.ylabel('PMF')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 18: Zero inflated negative binomial",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L01.html#hierarchical-representations",
    "href": "C3-L01.html#hierarchical-representations",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "Figure 19: Hierarchical representation of a mixture\n\n\n\n\n\n\n\n\nFigure 20: simulation of a mixture\n\n\n\nRecall that the cumulative distribution function of a mixture takes the form Equation 1, where G_k(x) is the cumulative distribution function of the k-th component of the mixture.\nWe can use a RV for each component and introduce an indicator RV for the component selector C_i to select the component from which we will sample. This results in a hierarchical representation of the mixture model.\n\nX \\mid c \\sim g_c(x) \\qquad \\mathbb{P}r(c=k) = \\omega_k \\qquad\n\\tag{11}\nwhere C is a categorical random variable with K categories, and G_k(x \\mid C=k) is the cumulative distribution function of the k-th component of the mixture given that we have selected the k-th component.\nThis allows us to write the cumulative distribution function of the mixture as a weighted sum of the cumulative distribution functions of the components\n\np(x) = \\sum^K_{k=1} p(x \\mid C=k) \\cdot \\mathbb{P}r(C=k) = \\sum^K_{k=1} g_k(x) \\cdot \\omega_k \\qquad\n\\tag{12}\nwhere g_k(x) is the cumulative distribution function of the k-th component of the mixture.\n\n\n\nRpython\n\n\n\n\nCode\n# Generate n observations from a mixture of two Gaussian distributions\nn     = 50           # required sample size\nw     = c(0.6, 0.4)  # mixture weights\nmu    = c(0, 5)      # list of means\nsigma = c(1, 2)      # list of sds\ncc    = sample(1:2, n, replace=T, prob=w) # sample for the component selector\nx     = rnorm(n, mu[cc], sigma[cc]) # sample the selected component\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = seq(-5, 12, length=200)\nyy = w[1] * dnorm(xx, mu[1], sigma[1]) + w[2] * dnorm(xx, mu[2], sigma[2])\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\npoints(x, y=rep(0,n), pch=1, col=cc)\n\n\n\n\n\n\n\n\nFigure 21: Mixture of two Gaussians\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom scipy.stats import norm\n\nn=50           # required sample size\nw=[0.6, 0.4]  # mixture weights\nmu=[0, 5]      # list of means\nsigma=[1, 2]  # list of sds\ncc = np.random.choice([0, 1], size=n, p=w) # sample for the component selector\n# sample the selected component\nx = np.array([np.random.normal(mu[i], sigma[i]) for i in cc])\n\n\n\n\nCode\n# Plot f(x) along with the observations just sampled\nxx = np.linspace(-5, 12, num=200)\nyy = w[0]*norm.pdf(loc=mu[0], scale=sigma[0], x=xx) + \\\n     w[1]*norm.pdf(loc=mu[1], scale=sigma[1], x=xx)\nplt.plot(xx, yy, label='Mixture of Gaussians')\nplt.scatter(x, np.zeros(n), c=cc, label='Sampled data')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.title('Mixture of Gaussians')\nplt.legend()\nplt.show() \n\n\n\n\n\n\n\n\nFigure 22: Mixture of two Gaussians",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L01.html#the-likelihood-function",
    "href": "C3-L01.html#the-likelihood-function",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "Figure 23: observed data likelihood\n\n\n\n\n\n\n\n\nFigure 24: complete data likelihood\n\n\n\n\nwe are now moving on to inferring the parameters of the mixture model from the observed data.\nwe can estimate these using the maximum likelihood estimation or with Bayesian estimation.\nin both cases we will need to compute the likelihood of the observed data.\nthere are two types of likelihoods:\n\nthe observed data likelihood is the probability of observing the data given the parameters of the model.\nthe complete data likelihood is the probability of observing the data and the latent variables given the parameters of the model.",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L04.html",
    "href": "C3-L04.html",
    "title": "Applications of Mixture Models",
    "section": "",
    "text": "#### KDE\n\nthe typical method for estimating the density of a random variable is to use a kernel density estimator (KDE)\nthe KDE is a non-parametric method that estimates the density of a random variable by averaging the contributions of a set of kernel functions centered at each data point\n\n\nX_1, \\ldots, X_n \\sim f(x)\n\n\n\\tilde{f}(x) = \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{h}  g(\\frac{|X - X_i|}{h})\n\nwhere h is the bandwidth of the kernel and g is a kernel function. The kernel function is a non-negative function that integrates to 1 and is symmetric around 0.\nFor example, the Gaussian kernel is given by: \ng(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n\ngiving us:\n\n\\tilde{f}(x) = \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{h}  \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{|X - X_i|^2}{2h^2}}\n\\tag{1}\n\n\n\na mixture of K components is a parametric method that estimates the density of a random variable by averaging the contributions of K kernel functions, each centered at a different location and with a different scale\nthe mixture model is given by:\n\n\nX_1, \\ldots, X_n \\sim f(x) = \\sum_{k=1}^K w_k g(x \\mid \\hat{\\theta}_k)\n\\tag{2}\nwhere w_k is the weight of the k-th component, \\hat{\\theta}_k is the location and scale of the k-th component, and g(x \\mid \\hat{\\theta}_k) is the kernel function centered at \\hat{\\theta}_k. The weights are non-negative and sum to 1.\nExample: a location mixture of K Gaussian distributions is given by:\n\nX_1, \\ldots, X_n \\sim \\hat{f}(x) = \\sum_{k=1}^K \\hat{w}_k \\frac{1}{\\sqrt{2\\pi}\\hat{\\sigma}} \\exp^{-\\frac{(x - \\hat{\\mu}_k)^2}{2\\hat{\\sigma}^2}}\n\\tag{3}\nwhere \\hat{w}_k is the weight of the k-th component, \\hat{\\mu}_k is the mean of the k-th component, and \\hat{\\sigma} is the standard deviation of the k-th component.\nwe can see the the two methods are quite similar, but the mixture model is more flexible and can capture more complex shapes in the data.\n\nThe KDE is a special case of the mixture model where all the components have the same scale and location.\nKDE needs as many components as the number of data points, while the mixture model can have fewer components.\nKDE uses a fixed bandwidth,\nMDE can adaptively choose the bandwidth for each component. In fact we have a weight for each component and a scale parameter that controls the width of the kernel function.\nMDE tends to use less components and the weights tend to be 1/K\n\nThe above model can be improved by:\n\nusing a scale-location mixture model, where the scale and location of each component are estimated from the data.\n\n\n\n\n\nWe use the galaxies dataset to illustrate the differences between the two methods.\nThe galaxies dataset contains the velocities of 82 galaxies in the Virgo cluster. The data is available in the MASS package.\n\n\n\n\n\nCode\n## Using mixture models for density estimation in the galaxies dataset\n## Compare kernel density estimation, and estimates from mixtures of KK=6\n## components obtained using both frequentist and Bayesian procedures\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\ndata(galaxies)\nKK = 6          # Based on the description of the dataset\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n### First, compute the \"Maximum Likelihood\" density estimate associated with a location mixture of 6 Gaussian distributions using the EM algorithm\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\n\nepsilon = 0.000001\ns       = 0\nsw      = FALSE\nKL      = -Inf\nKL.out  = NULL\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(k in 1:KK){\n    v[,k] = log(w[k]) + dnorm(x, mu[k], sigma,log=TRUE)  \n  }\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))\n  }\n  \n  ## M step\n  # Weights\n  w = apply(v,2,mean)\n  mu = rep(0, KK)\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Standard deviations\n  sigma = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n    }\n  }\n  sigma = sqrt(sigma/sum(v))\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -835.733942489325\"\n[1] \"2 -828.010809264972\"\n[1] \"3 -824.746233906969\"\n[1] \"4 -822.658999626022\"\n[1] \"5 -821.213895212478\"\n[1] \"6 -820.205593334589\"\n[1] \"7 -819.45255265569\"\n[1] \"8 -818.824551232431\"\n[1] \"9 -818.236534003549\"\n[1] \"10 -817.634208984436\"\n[1] \"11 -816.982967592922\"\n[1] \"12 -816.261886189958\"\n[1] \"13 -815.461265773593\"\n[1] \"14 -814.58192426664\"\n[1] \"15 -813.634925825188\"\n[1] \"16 -812.640825431584\"\n[1] \"17 -811.627832678685\"\n[1] \"18 -810.628730004626\"\n[1] \"19 -809.676914791807\"\n[1] \"20 -808.802324442178\"\n[1] \"21 -808.028006389222\"\n[1] \"22 -807.36782257363\"\n[1] \"23 -806.825578229162\"\n[1] \"24 -806.395771901538\"\n[1] \"25 -806.065864649222\"\n[1] \"26 -805.819434169721\"\n[1] \"27 -805.63925361852\"\n[1] \"28 -805.509531004204\"\n[1] \"29 -805.417065498588\"\n[1] \"30 -805.351515365637\"\n[1] \"31 -805.305136223748\"\n[1] \"32 -805.272302459567\"\n[1] \"33 -805.249006220074\"\n[1] \"34 -805.232424348309\"\n[1] \"35 -805.220578980422\"\n[1] \"36 -805.212086217934\"\n[1] \"37 -805.205976247832\"\n[1] \"38 -805.201567151818\"\n[1] \"39 -805.19837733157\"\n[1] \"40 -805.196065008484\"\n[1] \"41 -805.194386438224\"\n[1] \"42 -805.193166975027\"\n[1] \"43 -805.192280944541\"\n[1] \"44 -805.191637566216\"\n\n\nCode\nxx  = seq(5000,37000,length=300)\nnxx = length(xx)\ndensity.EM = rep(0, nxx)\nfor(s in 1:nxx){\n  for(k in 1:KK){\n    density.EM[s] = density.EM[s] + w[k]*dnorm(xx[s], mu[k], sigma)\n  }\n}\n\n### Get a \"Bayesian\" kernel density estimator based on the same location mixture of 6 normals\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(1,KK)  \neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/KK\n\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\ncc    = sample(1:KK, n, replace=T, prob=w)\n\n## Number of iterations of the sampler\nrrr   = 12000\nburn  = 2000\n\n## Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = rep(0, rrr)\nlogpost   = rep(0, rrr)\n\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  \n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n  \n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(1/rgamma(1, dd.star, qq.star))\n  \n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s,]    = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dnorm(x[i], mu[cc[i]], sigma, log=TRUE)\n  }\n  logpost[s] = logpost[s] + log(ddirichlet(w, aa))\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log=TRUE)\n  }\n  logpost[s] = logpost[s] + dgamma(1/sigma^2, dd, qq, log=TRUE) - 4*log(sigma)\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n\n\nCode\n## Compute the samples of the density over a dense grid\ndensity.mcmc = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n    for(k in 1:KK){\n        density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn])\n    }\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\n## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate and frequentist point estimate\ncolscale = c(\"black\", \"blue\", \"red\")\nyy = density(x)\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Velocity\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=colscale[1], lwd=2)\nlines(xx, density.EM, col=colscale[2], lty=2, lwd=2)\nlines(yy, col=colscale[3], lty=3, lwd=2)\npoints(x, rep(0,n))\nlegend(27000, 0.00017, c(\"KDE\",\"EM\",\"MCMC\"), col=colscale[c(3,2,1)], lty=c(3,2,1), lwd=2, bty=\"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n## Using mixture models for clustering in the iris dataset\n## Compare k-means clustering and a location and scale mixture model with K normals\n\n### Loading data and setting up global variables\nrm(list=ls())\nlibrary(mclust)\n\n\nPackage 'mclust' version 6.1.1\nType 'citation(\"mclust\")' for citing this R package in publications.\n\n\nCode\nlibrary(mvtnorm)\n\n\n\nAttaching package: 'mvtnorm'\n\n\nThe following object is masked from 'package:mclust':\n\n    dmvnorm\n\n\nCode\n### Defining a custom function to create pair plots\n### This is an alternative to the R function pairs() that allows for \n### more flexibility. In particular, it allows us to use text to label \n### the points\npairs2 = function(x, col=\"black\", pch=16, labels=NULL, names = colnames(x)){\n  n = dim(x)[1]\n  p = dim(x)[2]\n  par(mfrow=c(p,p))\n  for(k in 1:p){\n    for(l in 1:p){\n      if(k!=l){\n        par(mar=c(3,3,1,1)+0.1)\n        plot(x[,k], x[,l], type=\"n\", xlab=\"\", ylab=\"\")\n        if(is.null(labels)){\n          points(x[,k], x[,l], pch=pch, col=col)\n        }else{\n          text(x[,k], x[,l], labels=labels, col=col)\n        }\n      }else{\n        plot(seq(0,5), seq(0,5), type=\"n\", xlab=\"\", ylab=\"\", axes=FALSE)\n        text(2.5,2.5,names[k], cex=1.2)\n      }\n    }\n  }\n}\n\n## Setup data\ndata(iris)\nx       = as.matrix(iris[,-5])\nn       = dim(x)[1]\np       = dim(x)[2]       # Number of features\nKK      = 3\nepsilon = 0.0000001\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1))\ncolscale = c(\"black\",\"blue\",\"red\")\nshortnam  = c(\"s\",\"c\",\"g\")\npairs2(x, col=colscale[iris[,5]], labels=shortnam[as.numeric(iris[,5])])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nnumruns = 15\nv.sum   = array(0, dim=c(numruns, n, KK))\nQQ.sum  = rep(0, numruns)\n\nfor(ss in 1:numruns){\n  w   = rep(1,KK)/KK  #Assign equal weight to each component to start with\n  mu  = rmvnorm(KK, apply(x,2,mean), 3*var(x))   #Cluster centers randomly spread over the support of the data\n  Sigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\n  Sigma[1,,] = var(x)\n  Sigma[2,,] = var(x)\n  Sigma[3,,] = var(x)\n  \n  sw     = FALSE\n  QQ     = -Inf\n  QQ.out = NULL\n  s      = 0\n  \n  while(!sw){\n    ## E step\n    v = array(0, dim=c(n,KK))\n    for(k in 1:KK){  #Compute the log of the weights\n      v[,k] = log(w[k]) + mvtnorm::dmvnorm(x, mu[k,], Sigma[k,,], log=TRUE) \n    }\n    for(i in 1:n){\n      v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n    }\n    \n    ## M step\n    w = apply(v,2,mean)\n    mu = matrix(0, nrow=KK, ncol=p)\n    for(k in 1:KK){\n      for(i in 1:n){\n        mu[k,]    = mu[k,] + v[i,k]*x[i,]\n      }\n      mu[k,] = mu[k,]/sum(v[,k])\n    }\n    Sigma = array(0,dim=c(KK, p, p))\n    for(k in 1:KK){\n      for(i in 1:n){\n        Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n      }\n      Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n    }\n    \n    ##Check convergence\n    QQn = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        QQn = QQn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n      }\n    }\n    if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n      sw=TRUE\n    }\n    QQ = QQn\n    QQ.out = c(QQ.out, QQ)\n    s = s + 1\n  }\n  \n  v.sum[ss,,] = v\n  QQ.sum[ss]  = QQ.out[s]\n  print(paste(\"ss =\", ss))\n}\n\n\n[1] \"ss = 1\"\n[1] \"ss = 2\"\n[1] \"ss = 3\"\n[1] \"ss = 4\"\n[1] \"ss = 5\"\n[1] \"ss = 6\"\n[1] \"ss = 7\"\n[1] \"ss = 8\"\n[1] \"ss = 9\"\n[1] \"ss = 10\"\n[1] \"ss = 11\"\n[1] \"ss = 12\"\n[1] \"ss = 13\"\n[1] \"ss = 14\"\n[1] \"ss = 15\"\n\n\nCode\n## Cluster reconstruction under the mixture model\ncc = apply(v.sum[which.max(QQ.sum),,], 1 ,which.max)\ncolscale = c(\"black\",\"blue\",\"red\")\npairs2(x, col=colscale[cc], labels=cc)\n\n\n\n\n\n\n\n\n\nCode\nARImle = adjustedRandIndex(cc, as.numeric(iris[,5]))  # Higher values indicate larger agreement\n\n## Cluster reconstruction under the K-means algorithm\nirisCluster &lt;- kmeans(x, 3, nstart = numruns)\ncolscale = c(\"black\",\"blue\",\"red\")\npairs2(x, col=colscale[irisCluster$cluster], labels=irisCluster$cluster)\n\n\n\n\n\n\n\n\n\nCode\nARIkmeans = adjustedRandIndex(irisCluster$cluster, as.numeric(iris[,5]))\n\n\n\n\n\n\nClassification is a supervised learning problem where we want to predict the class of a new observation based on its features.\nAccording to the instructor the main difference from clustering is that in classification we have a training set. I would think the main difference is that we have labels for some of the data, while in clustering we do not have labels at all.\nThe fact that we have labels and a training set means we should know how many classes we have and we can use these labels to train a model and use it to predict the class of a new observation.\nThe instructor mentions Support Vector Machines (SVM), logistic regression and linear discriminant analysis (LDA) as familiar examples of classification methods. These and a number of others are covered in (isl?). We will focus on Naive Bayes classifiers as it is the most similar to mixture models and the EM algorithm which we have seen earlier\n\n\n\n\n\n\nK-means clustering\n\n\n\n\nK-means clustering\n\n\n\n\nMixture Models for Clustering\n\n\n\n\n\nThe idea of Naive Bayes classifiers is that we want to know what is the probability that observation i belongs to class k and we can obtain this using Bayes’ theorem by computing the prior probability that an observation is in that class. This is just the frequency of the class multiplied by the density of that class and divided by the sum over the classes of the same expression.\n\nP(x_i \\in \\text{class}_k) = \\frac{w_k \\cdot g_k(x_i|\\theta_k)}{\\sum_{j=1}^K w_j \\cdot g_j(x_i|\\theta_j)}\n\\tag{4}\nwhere w_k is the prior probability of class k, g_k(x_i|\\theta_k) is the density of class k, and \\theta_k is the parameter of class k.\nwith\n\n\\tilde{c}_i = \\arg \\max_k \\mathbb{P}r(x_i \\in \\text{class}_k)\\ for \\; i=n+1,\\ldots,n+m\n\nThe naive Bayes classifier assumes that the features are conditionally independent given the class. This means that the density of class k can be written as the product of the densities of each feature given the class: \ng_k(x_i|\\theta_k) = \\prod_{l=1}^p g_{kl}(x_{il}|\\theta_{kl})\n\nwhere g_{kl}(x_{il}|\\theta_{kl}) is the density of feature l given class k and \\theta_{kl} is the parameter of feature l given class k. This means that we can estimate the density of each feature separately and then multiply them together to get the density of the class.\nThis is a very strong assumption and is not true in general. However, it works well in practice and is often used in text classification problems where the features are the words in the text.\nThe naive Bayes classifier is a special case of the mixture model where the components are the classes and the densities are the product of the densities of each feature given the class. This means that we can use the EM algorithm to estimate the parameters of the model in the same way as we did for the mixture model. The only difference is that we need to estimate the densities of each feature separately and then multiply them together to get the density of the class.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nThe last class of problems for which mixture models are very useful is classification problems. If you come from the machine learning literature, you will call this supervised classification to contrast, again, unsupervised classification that I called clustering before. The goal in supervised classification is to start with a training set and use the information in a training set to determine the classes or the labels of a second group of observations that you call the test set. So you start with a training set that contains known labels classes. You also have a test set that has unknown labels, and you want to use this information to make predictions about the test set labels. For example, you may want to decide whether a person suffers from a disease or not based on a set of medical tests, maybe P medical tests, and you have gone out and measured those tests in a number of individuals. So you know those individuals whether they are sick or they are not sick. Based on that training set that is labeled where you know what the real quality of the individuals is, then you go out and you are going to pick just a random person that comes into your medical appointment, and based on the results of the test, now you want to decide if that individual suffers from the disease or not. So the presence of the training set is really what distinguishes clustering problems from classification problems. In clustering problems, we don’t have a training set. We don’t have anything that gives us a hint about how the classes look like. We’re trying to do the process of dividing the observations into groups in some sense blindly. That’s why it’s sometimes called unsupervised classification because you can think that the training set provides supervision in how you do the classification. In typical supervised classification problems on the other hand, you do have that training set. You do have that group of labeled observations that can help you make decisions about how the new groups will look like. So in some sense, supervised classification is a simpler problem than unsupervised classification because of the presence of the training set. Now, there are a number of classification procedures out there. This is a fairly common problem in the literature. You may be familiar with things like support vector machines or logistic regression for classification. I want to discuss today the similarities between using mixture models for classification and some techniques such as linear discriminant analysis, and in particular with Naive Bayes classifiers. The idea of Naive Bayes classifiers is very simple. So if you want to know what is the probability that observation i belongs to class k, you can typically obtain that by just using Bayes’ theorem by computing the prior probability that an observation is in that class. That is typically just the frequency of the class multiplied by the density of that class and divided by the sum over the classes of the same expression. Now, again, this should be very familiar. This quantity here is essentially what we used both in the EM algorithm to compute the [inaudible] case and in the MCMC algorithm if you are fitting a mixture model from a Bayesian perspective to sample the class labels C sub x. So in other words, it’s clear just from writing the expression from Naive Bayes that there should be a very close relationship between doing Naive Bayes and doing mixture models. In fact, you can cast Naive Bayes classifiers as just as a special case of mixture models. Let’s discuss Naive Bayes classifiers where we use Gaussian kernels for the classification. Let’s enter this a little bit of notation. So remember that we have both a test set and a training set. So let’s call X_1 up to X_n my training set, and let’s call X_n plus 1 up to X_n plus m the test set. In other words, we have n observations in the training set, we have m observations in the test set and we just group the observations together so that the first n in the sample are the training and last m are the test. In addition to this, because the training set is labeled, we’re going to have C_1 up to C_n are known, but C_1 or C_n plus 1 up to C_m plus n are unknown and we want to protect them. Let’s write a Naive Bayes classifier that uses Gaussian kernels, and we’re going to use the more general Gaussian kernels that we can. So in that case, the probability that observation i belongs to class k, it’s going to be equal to Omega_k 1 over the square root 2 Pi to the p. Remember that we’re working with P variate normal. So we can have P features for each individual, determinant of Sigma_k to the minus one 1/2 X of minus one 1/2 X_i minus Mu k transpose sigma sub k inverse X_i minus Mu k, divided by the sum over the components of exactly the same expression. This has to be l, minus Mu sub l transpose sigma l inverse X_i minus Mu l. So this is just Bayes theorem as we have written multiple times in this course. So what you do is, you need this expression only for the training set because for the test set you already know what class you are in. So what you typically do is a two-step process in which you get Mu k hat and Sigma hat sub k are estimated from the training set. You could do different things, but it’s very fairly common to just fit a multivariate Gaussian to each one of the components. So your Cs, your labels divide your training set into groups. For each one of those groups, you fit one different normal and that gives you Sigma and Mu. Similarly, for Omega k, you want to get an estimate for Omega k, and the natural thing to do is to just use the frequency, the fraction of the observations in the training set that belong to each one of the classes. Once you have those, then you classify new observations as by letting C_i be equal to the org max of that probability. Where the probabilities are computed by plugging in these maximum likelihood estimators in this formula up here. As I said, this is done for n plus 1 all the way to n plus m. So you don’t need to do this for the training set, the training set you know the labels and you use those labels to compute the MLEs that get plugged into this. Now, with additional observations in those MLEs, you can decide what are the classes for them. So this is what a naive Bayes classifier based on Gaussian distributions for each one of the classes would look like. Now, this is exactly the same as the EM algorithm that we have discussed in the past for mixture models, if we make a couple of assumptions or if we incorporate a couple of assumptions into the algorithm. So let’s write down that next. We can recast the algorithms that we just saw for naive Bayes classifier based on Gaussian kernels in the context of the EM algorithm that we have been discussing for mixtures. That is very easy, we’re going to think, again, about an E-step and an M-step, and we’re going to add an additional post-processing step, if you will. In our E-step, if you remember, what we did in the past was to compute the indicators for the variables. So that is our variables V_i,k that corresponds to the weights that are associated with each one of the components. What we’re going to do in this case is we’re going to define the V_i,k in a very simple fashion rather than doing it using Bayes theorem. Because we actually know what observations or what components are generating each of the observations in the training set, we can call V_i,k just one or zero if C_i is equal to k and zero otherwise, for all the observations that go from one to n. In other words, this is for the training set. Once we have defined our E-step in this way, we’re going to have an M-step where we compute Mu sub k and Omega sub k. To put it in the same way that we did with the EM algorithm, this is going to have a very particular shape. It’s going to have the sum from one to n of V_i,k X_i divided by the sum from one to n of V_i,k. In a similar expression for my matrix Sigma, Sigma is going to be Sigma sub k, it’s going to be one over the sum of the V_i,k from one to n, sum from one to n of V_i,k X_i minus Mu k, X_i minus Mu k transpose. These are expressions that we have seen in the past when filling mixtures of multivariate Gaussians to data. This is just a fancy way, so casting it in terms of the E-step and the M-step, it’s just a fancy way to say, I know what my assignments are, for sure, because this is a training set. So this is just computing the average of the observations that are in category K because, in this case, these are either zeros or ones. Similarly, here, this is just the variance covariance matrix of the observations that are in component K, but it’s written in a fancy way using this V_i,k as indicators. Then, we have a post-processing. It’s in the post-processing step where the test set comes into play. So for now, we have only used the training set for our calculations. In the post-processing step, what we do is we allocate C_i based on the arc max over K of the posterior distribution of the class allocations. So that is probability that X_i belongs to class K. So this is just another way to write the algorithms as we had before, that is very simple in the context of [inaudible]. So why did I go through the trouble of expressing this in this complicated manner when I had a very simple description before? Well, because now you can try to generalize this from this supervised setting where you completely break apart the estimation of the parameters that only uses the training set and the classification that only uses the test set. You can actually try to combine information from both, and it should be clear that if you have training sets that are just very small compared to the test set, the estimates that you get for Mu and Sigma will be very bad because they will be based on very few observations, very few data points. So if you could somehow use some of the information that you are recovering by doing the classification to help you estimate what Mu and Sigma are, they’ll probably give you more robust, stronger algorithm. How to do that should be relatively straightforward once you think about it in this context. For the observations to the training set, we have the value of the V_i,k, but we could add an estimate of the value of the V_i,k for the observations in the test set to this calculation. We already know how to do that. So we’re going to turn the algorithm iterative now. So these guys are always going to be defined in this way because I know the C’s, but these guys are refined at every iteration of the algorithm. I’ll just make this essentially equal to the probability that X_i belongs to class K given the current parameters of the model, so given the current Omegas, the current Mus, and the current Sigmas. Then, I can extend my sums to m down here and down here. Now, what I’m doing is, for the observations that I know what class they are in, these weights are either zeros or ones. For the ones that I don’t know but I’m trying to classify, they will be some number between zero and one, and I’m just going to do a weighted average so you can think about this, again, as a weighted average of the information that I know for sure, and the information that I’m recovering about Mu and Sigma from the classification. So again, this now becomes an iterative algorithm, so I need to think about t plus 1, t plus 1, t plus 1, t plus 1, t plus 1, t plus 1, and t plus 1. So I have turned what was just a two-step algorithm that doesn’t require any iteration, I turned it into an iterative algorithm that uses the whole sample to estimate the parameters of the classes. This is sometimes called a semi-supervised; I don’t necessarily like the term very much. But this is sometimes called a semi-supervised algorithm, in the sense that it’s not completely supervised because of the addition of this information and the fact that now, the sums go up to m. But it’s also not fully unsupervised because I’m using the information, I’m using this piece up here that has information where I know their true labels. Once the algorithm converges, I’m still going to do the post-processing step that is to go from this V_i,k’s that I computed here for the test set to generate what are the labels for those observations.\n\n\n\n\n\n\n\n  It is important to understand the connection between using mixture models for classification and other procedures that are commonly used out there for classification. One example of those procedures that has a strong connection is linear discriminant analysis and also to quadratic discriminant analysis.\nTo illustrate that connection, we start with a very simple mixture model.\nSo let’s start with a mixture model of the form,\n\nf(x) = \\sum_{k=1}^2 \\omega_k \\frac{1}{\\sqrt{2\\pi}} \\frac{1}{\\sqrt{\\text{det}(\\Sigma)}} e^{-\\frac{1}{2}(x - \\mu_k)^T \\Sigma^{-1} (x - \\mu_k)}.\n\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nIt is important to understand the connection between using mixture models for classification and other procedures that are commonly used out there for classification. One example of those procedures that has a strong connection is linear discriminant analysis. And also, by the way, quadratic discriminant analysis. But let’s start with linear discriminant analysis.\nAnd to illustrate that connection, let’s start with a very simple mixture model.\nSo let’s start with a mixture model of the form, f(x) = the sum from 1 to 2. So I’m going to be working only with two components of omega k, 1 over the square root 2pi to the p determinant of sigma to the -1 half, x- 1 half, x, mu sub k, transpose sigma inverse, x- mu sub k. So this is two-component mixture with locations bearing with a component, but the same variance-covariance matrix for the two components that I have in the mixture.\nAnd let’s think about how the procedure would look like if we were to do Naive Bayes classification using this mixture. If I follow the unsupervised example that I have discussed before, the probability that I put observation i in class, 1, say, I only have two classes.\nSo as you see again, consider one of them and the other one is just 1- the numbers that I get here. It’s going to be equal.\nAnd I’m going to expand this in all its glory. It’s going to be a little bit long. So it’s going to be omega 1, 1 over the square root 2pi to the p determinant of sigma to the- 1 half, x of- 1 half, x- mu k transpose sigma inverse x- mu k. And in the denominator, we’re going to have the same expression first. And then we’re going to have omega 2, that is just 1- omega 1 but 2pi to the p determinant of sigma to the- 1 half x- 1 half x- mu 2, sigma inverse x- mu 2. Okay, and we know that the probability that xi belongs to class 1 is exactly the same expression but replacing mu, 1 which is what should be up here, replacing mu1 with mu2.\nSo, in the post processing step, we are going to assign C sub i = 1 if and only if the probability that xi belongs to class 1 is greater than the probability that xi belongs to class 2. And because the two expressions are the same in the denominator, the only thing that changes is the numerator, then this happens if and only if omega 1, 1 over the square root 2pi to the p determinant sigma to the- 1 half x- 1 half, X- mu1 transpose sigma inverse x- mu1, Is greater than omega 2, 1 over the square root 2pi to the p determinant of sigma to the- 1 half x of- 1 half x- mu2, sigma inverse x- mu2. So probability of class 1 greater than probability of class 2 only if this quantity is greater than the same thing but evaluated for the second component in the mixture. So let’s do a little bit of algebra and let’s try to simplify this expression a little bit and we will see that that simplification leads to a very nice expression that matches exactly what you get out of linear discriminant analysis. So now we want to simplify this expression that corresponds to the situation where we’re going to label an observation coming from class 1, and we want to make it much more compact. So a few things that we can observe. So one of them is we have 1 over square root 2pi to the p on both sides, so we can cancel that. The other thing that we observe is that we have the determinant of the variance-covariance matrix on both sides. And because we’re assuming that the two components have the same variance- covariance matrix, we can again just simplify both terms on either side. And the next thing that I’m going to do is I’m going to move all the omegas to one side and bring all the terms with the exponentials to the other side. If I do that, I’m going to end up on the left hand side with the exponent of- 1 half, X- mu1 transpose sigma inverse x- mu1. And then this term came to the other side in the denominator, but that just means that when it goes into the exponential, I need to change all to reverse signs. So it’s going to be- x- mu2 transpose sigma inverse x- mu2. So that’s the expression once you move this to the denominator and combine the two exponentials. And this needs to be greater than omega 2 divided by omega 1. Now, some further simplifications. I can take the logarithm on both sides and I can multiply by -2 on both sides, and I end up with an expression that looks like x- mu 1 transpose sigma inverse x- mu1- x- mu 2 transpose sigma inverse x- mu 2 has to be less than, because I’m going to end up multiplying by a -2. So less than -2 log of omega 2 divided by omega 1. So now we have this difference of two quadratic forms needs to be less than a certain constant that depends on what are my prior weights for each one of the two components. Now, to finish simplifying this, we need to expand these two squares, which is pretty straightforward. So first we’re going to have x sigma inverse x transpose sigma inverse x. This is just a square. So it’s going to be 2 times x transpose sigma inverse mu1. And finally, \\mu_1 transpose sigma inverse \\mu_1. And then we need to subtract a similar expression but using mu2 for it turns. So it’s going to be x transpose sigma inverse x. It’s going to be +, in this case, 2x transpose sigma inverse mu2. And finally, again,- mu2 transpose sigma inverse mu2, and all of these needs to be less than -2 log of omega 2, Divided by omega 1. So you can see that the expressions are relatively straightforward.\nAnd one of the things that is very nice, and it’s a consequence of having the same variance-covariance matrix for each one of the components, is that now this quadratic term of the data is going to cancel out. And so, we can just basically learn together a couple of terms. So we can write, 2 times, X transpose sigma inverse multiplied by mu2- mu1. So I’m taking this term and combining it with this term. So, the term here and the term here.\nAnd then I’m going to say that this has to be less than -2 times log of omega 2 divided by omega 1, and I’m going to move this two terms to the right. So,+ mu2 transpose sigma inverse mu2- mu1 transpose sigma inverse mu1. So this is actually quite a bit of simplification and it’s a very interesting one. Because you can think about this, Thing on the right hand side, just call this T for threshold. So this is your sum threshold and that threshold is basically computed based on the training data. So if I know the classes of some observations, I can get what the means for each one of the classes are, I can estimate the common sigma, and I can estimate the relative frequencies. And with that, I can obtain a stress score from the training set. And I can think about this matrix product as sum vector a. The form of this simplified expression is very interesting. You can see that the right-hand side, all this expression in the box, it’s just a threshold that can be easily computed from the training set. We can estimate the weight and we can estimate the mean and the covariance of the two components. And then, this product of the variance-covariance or the inverse of the variance-covariance matrix times the difference of the means corresponds to a vector a that can also be computed from the training set. So essentially, the decision of whether we classify an observation in class 1 or class 2 is going to depend on whether a linear combination, and that’s what x transpose times a is, is just a linear combination of the values of x. So whether this linear combination of the values of x is greater than a given threshold or not. In other words, what we’re doing, In a setting where we only have two variables, for example, x1 and x2, the linear combination of the entries is just a line on the plane. So this product just corresponds to a line. And by deciding whether we are above the line or below the line, we’re just saying that one of the regions corresponds to class, 2, and the other region corresponds to class 1. So this is the reason why the procedure is called linear discriminant analysis because it uses a straight line to decide whether observations should be classified in class 1 and class 2. Now, there are some more interesting things that you can do. For example, you don’t have to assume that the sigmas are the same, you could assume that the sigmas are different. If you were to do that, then you’d be in a situation that is analogous to this one with the main difference being that now these terms here wouldn’t necessarily simplify. But then, you can rearrange terms in such a way that now, you’re going to have a quadratic form of x being less than a certain threshold. And in that case, you’re separating hyperplane. Instead of being a hyperplane or line, it’s going to be a quadratic form. And that is the reason why when you’re doing Naive Bayes and you’re working with kernels that are Gaussian and have different variance-covariance matrices, you call the procedure quadratic discriminant analysis. Because it uses a quadratic form, a parabola or something like that to separate the two classes that you’re working with. The nice thing about thinking about this classification procedures in the context of mixture models is again, thinking about ways in which you can generalize and address the shortcomings of the procedure. It’s clear that the main issue with classification procedures based on Gaussians is that data in the real world sometimes doesn’t look like multivariate Gaussian distributions. So one possible extension is to instead of considering the density, this ps here to be a single Gaussian, you can kind of use mixtures a second time and borrow some ideas from when we did density estimation. And say well, I’m going to have a mixture and each component of that mixture is in turn a second mixture that may have a few components. And that may allow for the shape of the clusters to be much more general, and that’s what we call mixture discriminant analysis. As before, if you instead of doing the Algorithm and the simple maximum likelihood estimation that I described before, you instead use Bayesian estimators for your process, then you will have Bayesian equivalent of linear discriminant analysis and quadratic discriminant analysis. So it is very useful to think about your statistical methods in the context of mixture models for the purpose of both generalizing and understanding the shortcomings of what you’re doing.\n\n\n\n\n\n\n\n\n\nThis video discusses the code in the next section.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nI’m going to illustrate now to use of mixture models for classification using the wind dataset. Unlike the previous datasets that we work with, this one is not included in R by default. So the two files that you need wind training and wind tests are available on the website, make sure that you download them and that you have them in the right directory for R to read them. And in this case, I made sure that I change the directory where I’m looking at before I start working with this, and that I put my files in there.\nOkay, so the wind dataset is an interesting one, it’s a series of measurements for different varieties of wine. They come from three different cultivars, and for each particular variety of wine. They did a chemical analysis and measure 13 different variables that have to do with different chemical components present in the world. So we have a label set where we know which samples from which of the three cultivars. And now we want to use the information that we clean out of that to classify to decide a series of new wines to assign them to the cultivar that we think they come from. We actually do know the truth for the test set, so we will actually first do the predictions we’ll act as if we don’t know what the cultivar of the test set is. And then we will compare the predictions that we’re making against the truth, as a way to tell how well the algorithm is to it, okay. So the first thing that we need to do is load our dataset as I said, you need to make sure that the two files are in the directory where you’re working. So make sure of that, remember that we called n the sample size of the training set and m the training size the size of the test set. So I’m just calling the variables that way, and I’m going to use mixture of normals mixture of multivariate normals by location and scale. So I’m going to use a method that is essentially equivalent to doing quadratic discriminant analysis. And, I want to run the Algorithm that I discussed on the board, but in a situation which we assume that we’re going to work with semi-supervised learning. In other words, I went around the Version of the algorithm in which we’re going to use all the observation both in the training and the test set, to learn the parameters of the classes. So it’s going to be an iterative algorithm. So we know in advance as we have three classes because we have three cultivars. B in this case is going to be 13 because there are 13 features that were measured on each wine. So if you come down here, you can see that B 13, we can try to do a graph of the data. In this case the graph is not going to be terribly readable because there are so many variables, but it may still provide a little bit of intuition. So the variables that are measured things like alcohol, the ash, the alkalinity, the level of magnesium, the hue that has to do with how dark the wine is, proline. So you can see here where the variables are there are measured, and even though the graph is not very readable at least you can see that the classes do not fully overlap. So we do have some hope that we may be able to do classification in the problem. That’s pretty much the main thing that you can say out of this graph here, okay. So, as I said before mixture of models with different components, different variances and different means for each component its normal component in the mixture. Same type of standard initialization that we have done before. And we’re going to do the E and the M step here, remember that for the observations in the training set. We know the class, so the value of B are either 0 or 1, and because we do the calculation first in the log scale, then we do either 0 or minus infinity. So 0 corresponds to probability of 1 and minus infinity corresponds to a probability of 0 in the log scale. And then for the observations in the test set, we have just a regular way in which we compute the probability that the observation comes from each class. And once we have done this then we subtract, we do as we have always done subtract maximums and then restandardize. So this is how the ES step gets adapted in the case of semisupervised classification. And then the structure of the m-step is exactly the same structure of the regular Algorithm. So we compute means and variances for each one of the components as weighted averages of the different quantities. We check conversions in the standard way, in which we have been checking convergence. And finally once everything is done, we will get a classification, so let’s run it for this dataset. It runs actually quite quickly, we have only 12 iterations and we have converged. Now what the Algorithm gives gave us is just the B values, that is the probability that an observation comes from a given class. Now, we typically are going to want to convert those peas into Cs and as we saw on the board, that is done by just selecting the class that has the highest probability.\nSo if we do that for our training set in this case, and if you look at the indexes here, they run from n + 1 to n + m, which means that we’re looking at test set. If we just get what is the maximum we can see that the first block of observations is assigned to component two. Most of this block is assigned to component two except for this guy here, and then the the remaining block of observation is assigned to components three. So now how does that compare with the truth? So we can actually go into winder test, and the first column of that file contains the true labels, and we can say that it matches actually pretty well. So the ones all match, the twos match except for one guy, the one we had kind of identified before, and the threes all match together. And we can actually if you just want to have a summary of how many errors you make. You can do a little comparison like this, and you can find that there is only a single error in the classification that the algorithm does.\nNow let’s compare that with just using quadratic discriminant analysis and linear discriminant analysis. The way they are implemented in R, so QDA and LDA are the two functions that you will need, they are part of the mass package. So, We first feed the QDA model and then we that fitted model to predict the classes. And now if we see what the regular QDA does is it’s going to give me this long list of probabilities for the test set. And we can turn those into labels and in particular we can see how many errors we’re making in the prediction. And you can see that we make a single mistake, which is actually not the mistake that we had made before. So if we just look at this one here and we compare it against the, Classification that our algorithm did, and we compared it against the truth.\nWe see that our algorithm makes a mistake in this observation and QDA does not, and instead the error is somewhere else in this sample. It’s basically here, so you can see that the QDA classifies this as two, when the reality is that it’s a three. So our results are not identical to QDA even though our method is asymptotically going to be equivalent to QDA but they don’t give us exactly the same result, but they give us very similar accuracy. Interestingly if you run LDA and you try to look at how many errors you have in that case, you will see that LDA in this case has no errors, even though it’s a simpler more restrictive classification procedure. So this can happen, so it’s a relatively large sample, so a single a difference in a single error is not a very large difference. So, hopefully this illustrates how classification or how measurements can be used for classification in a real life setting.\n\n\n\n\n\n\n\n\nCode\n## Using mixture models for classification in the wine dataset\n## Compare linear and quadratic discriminant analysis and a \n##   (semi-supervised) location and scale mixture model with K normals\n## Comparing only against the EM algorithm\n\n# Semi-supervised, quadratic discriminant analysis \n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(mvtnorm)\nwine.training = read.table(\"data/wine_training.txt\", sep=\",\", header=TRUE)\nwine.test = read.table(\"data/wine_test.txt\", sep=\",\", header=TRUE)\nn = dim(wine.training)[1]  # Size of the training set\nm = dim(wine.test)[1]      # Size of the test set\nx = rbind(as.matrix(wine.training[,-1]), as.matrix(wine.test[,-1]))   # Create dataset of observations, first n belong to the training set, and the rest belong to the test set\np       = dim(x)[2]              # Number of features\nKK      = 3\nepsilon = 0.00001\n\npar(mfrow=c(1,1))\npar(mar=c(2,2,2,2)+0.1)\ncolscale = c(\"black\",\"red\",\"blue\")\npairs(wine.training[,-1], col=colscale[wine.training[,1]], pch=wine.training[,1])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #Cluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\nsw     = FALSE\nKL     = -Inf\nKL.out = NULL\ns      = 0\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n+m,KK))\n  for(k in 1:KK){  #Compute the log of the weights\n    v[1:n,k] = ifelse(wine.training[,1]==k,0,-Inf)  # Training set\n    v[(n+1):(n+m),k] = log(w[k]) + mvtnorm::dmvnorm(x[(n+1):(n+m),], mu[k,], Sigma[k,,],log=TRUE)  # Test set\n  }\n  for(i in 1:(n+m)){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w = apply(v,2,mean)\n  mu = matrix(0, nrow=KK, ncol=p)\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0,dim=c(KK,p,p))\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:(n+m)){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -3146.58419305226\"\n[1] \"2 -2942.48222029706\"\n[1] \"3 -2873.76499310479\"\n[1] \"4 -2852.76768638231\"\n[1] \"5 -2796.247735428\"\n[1] \"6 -2791.29098585679\"\n[1] \"7 -2791.23059641487\"\n[1] \"8 -2791.14094416728\"\n[1] \"9 -2791.05612416221\"\n[1] \"10 -2790.99254414223\"\n[1] \"11 -2790.95228067601\"\n[1] \"12 -2790.92945838389\"\n\n\nCode\n## Predicted labels\napply(v, 1, which.max)[(n+1):(n+m)]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## True labels\nwine.test[,1]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## Comparison\napply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1]\n\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nCode\nsum(!(apply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# Using the qda and lda functions in R\n# qda\nmodqda = qda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredqda = predict(modqda,newdata=wine.test[,-1])\nsum(!(ccpredqda$class == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# lda\nmodlda = lda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredlda = predict(modlda,newdata=wine.test[,-1])\nsum(!(ccpredlda$class == wine.test[,1])) # No errors!!!\n\n\n[1] 0",
    "crumbs": [
      "3. Mixture Models",
      "Applications of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L04.html#density-estimation",
    "href": "C3-L04.html#density-estimation",
    "title": "Applications of Mixture Models",
    "section": "",
    "text": "#### KDE\n\nthe typical method for estimating the density of a random variable is to use a kernel density estimator (KDE)\nthe KDE is a non-parametric method that estimates the density of a random variable by averaging the contributions of a set of kernel functions centered at each data point\n\n\nX_1, \\ldots, X_n \\sim f(x)\n\n\n\\tilde{f}(x) = \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{h}  g(\\frac{|X - X_i|}{h})\n\nwhere h is the bandwidth of the kernel and g is a kernel function. The kernel function is a non-negative function that integrates to 1 and is symmetric around 0.\nFor example, the Gaussian kernel is given by: \ng(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n\ngiving us:\n\n\\tilde{f}(x) = \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{h}  \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{|X - X_i|^2}{2h^2}}\n\\tag{1}\n\n\n\na mixture of K components is a parametric method that estimates the density of a random variable by averaging the contributions of K kernel functions, each centered at a different location and with a different scale\nthe mixture model is given by:\n\n\nX_1, \\ldots, X_n \\sim f(x) = \\sum_{k=1}^K w_k g(x \\mid \\hat{\\theta}_k)\n\\tag{2}\nwhere w_k is the weight of the k-th component, \\hat{\\theta}_k is the location and scale of the k-th component, and g(x \\mid \\hat{\\theta}_k) is the kernel function centered at \\hat{\\theta}_k. The weights are non-negative and sum to 1.\nExample: a location mixture of K Gaussian distributions is given by:\n\nX_1, \\ldots, X_n \\sim \\hat{f}(x) = \\sum_{k=1}^K \\hat{w}_k \\frac{1}{\\sqrt{2\\pi}\\hat{\\sigma}} \\exp^{-\\frac{(x - \\hat{\\mu}_k)^2}{2\\hat{\\sigma}^2}}\n\\tag{3}\nwhere \\hat{w}_k is the weight of the k-th component, \\hat{\\mu}_k is the mean of the k-th component, and \\hat{\\sigma} is the standard deviation of the k-th component.\nwe can see the the two methods are quite similar, but the mixture model is more flexible and can capture more complex shapes in the data.\n\nThe KDE is a special case of the mixture model where all the components have the same scale and location.\nKDE needs as many components as the number of data points, while the mixture model can have fewer components.\nKDE uses a fixed bandwidth,\nMDE can adaptively choose the bandwidth for each component. In fact we have a weight for each component and a scale parameter that controls the width of the kernel function.\nMDE tends to use less components and the weights tend to be 1/K\n\nThe above model can be improved by:\n\nusing a scale-location mixture model, where the scale and location of each component are estimated from the data.\n\n\n\n\n\nWe use the galaxies dataset to illustrate the differences between the two methods.\nThe galaxies dataset contains the velocities of 82 galaxies in the Virgo cluster. The data is available in the MASS package.\n\n\n\n\n\nCode\n## Using mixture models for density estimation in the galaxies dataset\n## Compare kernel density estimation, and estimates from mixtures of KK=6\n## components obtained using both frequentist and Bayesian procedures\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\ndata(galaxies)\nKK = 6          # Based on the description of the dataset\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n### First, compute the \"Maximum Likelihood\" density estimate associated with a location mixture of 6 Gaussian distributions using the EM algorithm\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\n\nepsilon = 0.000001\ns       = 0\nsw      = FALSE\nKL      = -Inf\nKL.out  = NULL\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(k in 1:KK){\n    v[,k] = log(w[k]) + dnorm(x, mu[k], sigma,log=TRUE)  \n  }\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))\n  }\n  \n  ## M step\n  # Weights\n  w = apply(v,2,mean)\n  mu = rep(0, KK)\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Standard deviations\n  sigma = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n    }\n  }\n  sigma = sqrt(sigma/sum(v))\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -835.733942489325\"\n[1] \"2 -828.010809264972\"\n[1] \"3 -824.746233906969\"\n[1] \"4 -822.658999626022\"\n[1] \"5 -821.213895212478\"\n[1] \"6 -820.205593334589\"\n[1] \"7 -819.45255265569\"\n[1] \"8 -818.824551232431\"\n[1] \"9 -818.236534003549\"\n[1] \"10 -817.634208984436\"\n[1] \"11 -816.982967592922\"\n[1] \"12 -816.261886189958\"\n[1] \"13 -815.461265773593\"\n[1] \"14 -814.58192426664\"\n[1] \"15 -813.634925825188\"\n[1] \"16 -812.640825431584\"\n[1] \"17 -811.627832678685\"\n[1] \"18 -810.628730004626\"\n[1] \"19 -809.676914791807\"\n[1] \"20 -808.802324442178\"\n[1] \"21 -808.028006389222\"\n[1] \"22 -807.36782257363\"\n[1] \"23 -806.825578229162\"\n[1] \"24 -806.395771901538\"\n[1] \"25 -806.065864649222\"\n[1] \"26 -805.819434169721\"\n[1] \"27 -805.63925361852\"\n[1] \"28 -805.509531004204\"\n[1] \"29 -805.417065498588\"\n[1] \"30 -805.351515365637\"\n[1] \"31 -805.305136223748\"\n[1] \"32 -805.272302459567\"\n[1] \"33 -805.249006220074\"\n[1] \"34 -805.232424348309\"\n[1] \"35 -805.220578980422\"\n[1] \"36 -805.212086217934\"\n[1] \"37 -805.205976247832\"\n[1] \"38 -805.201567151818\"\n[1] \"39 -805.19837733157\"\n[1] \"40 -805.196065008484\"\n[1] \"41 -805.194386438224\"\n[1] \"42 -805.193166975027\"\n[1] \"43 -805.192280944541\"\n[1] \"44 -805.191637566216\"\n\n\nCode\nxx  = seq(5000,37000,length=300)\nnxx = length(xx)\ndensity.EM = rep(0, nxx)\nfor(s in 1:nxx){\n  for(k in 1:KK){\n    density.EM[s] = density.EM[s] + w[k]*dnorm(xx[s], mu[k], sigma)\n  }\n}\n\n### Get a \"Bayesian\" kernel density estimator based on the same location mixture of 6 normals\n## Priors set up using an \"empirical Bayes\" approach\naa  = rep(1,KK)  \neta = mean(x)    \ntau = sqrt(var(x))\ndd  = 2\nqq  = var(x)/KK\n\n## Initialize the parameters\nw     = rep(1,KK)/KK\nmu    = rnorm(KK, mean(x), sd(x))\nsigma = sd(x)/KK\ncc    = sample(1:KK, n, replace=T, prob=w)\n\n## Number of iterations of the sampler\nrrr   = 12000\nburn  = 2000\n\n## Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = rep(0, rrr)\nlogpost   = rep(0, rrr)\n\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma, log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))\n  \n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n  \n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(1/rgamma(1, dd.star, qq.star))\n  \n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s,]    = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dnorm(x[i], mu[cc[i]], sigma, log=TRUE)\n  }\n  logpost[s] = logpost[s] + log(ddirichlet(w, aa))\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log=TRUE)\n  }\n  logpost[s] = logpost[s] + dgamma(1/sigma^2, dd, qq, log=TRUE) - 4*log(sigma)\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\"\n[1] \"s = 6500\"\n[1] \"s = 7000\"\n[1] \"s = 7500\"\n[1] \"s = 8000\"\n[1] \"s = 8500\"\n[1] \"s = 9000\"\n[1] \"s = 9500\"\n[1] \"s = 10000\"\n[1] \"s = 10500\"\n[1] \"s = 11000\"\n[1] \"s = 11500\"\n[1] \"s = 12000\"\n\n\nCode\n## Compute the samples of the density over a dense grid\ndensity.mcmc = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n    for(k in 1:KK){\n        density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn])\n    }\n}\ndensity.mcmc.m = apply(density.mcmc , 2, mean)\n\n## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate and frequentist point estimate\ncolscale = c(\"black\", \"blue\", \"red\")\nyy = density(x)\ndensity.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)\ndensity.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)\nplot(xx, density.mcmc.m, type=\"n\",ylim=c(0,max(density.mcmc.uq)),xlab=\"Velocity\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.mcmc.m, col=colscale[1], lwd=2)\nlines(xx, density.EM, col=colscale[2], lty=2, lwd=2)\nlines(yy, col=colscale[3], lty=3, lwd=2)\npoints(x, rep(0,n))\nlegend(27000, 0.00017, c(\"KDE\",\"EM\",\"MCMC\"), col=colscale[c(3,2,1)], lty=c(3,2,1), lwd=2, bty=\"n\")",
    "crumbs": [
      "3. Mixture Models",
      "Applications of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L04.html#clustering",
    "href": "C3-L04.html#clustering",
    "title": "Applications of Mixture Models",
    "section": "",
    "text": "Code\n## Using mixture models for clustering in the iris dataset\n## Compare k-means clustering and a location and scale mixture model with K normals\n\n### Loading data and setting up global variables\nrm(list=ls())\nlibrary(mclust)\n\n\nPackage 'mclust' version 6.1.1\nType 'citation(\"mclust\")' for citing this R package in publications.\n\n\nCode\nlibrary(mvtnorm)\n\n\n\nAttaching package: 'mvtnorm'\n\n\nThe following object is masked from 'package:mclust':\n\n    dmvnorm\n\n\nCode\n### Defining a custom function to create pair plots\n### This is an alternative to the R function pairs() that allows for \n### more flexibility. In particular, it allows us to use text to label \n### the points\npairs2 = function(x, col=\"black\", pch=16, labels=NULL, names = colnames(x)){\n  n = dim(x)[1]\n  p = dim(x)[2]\n  par(mfrow=c(p,p))\n  for(k in 1:p){\n    for(l in 1:p){\n      if(k!=l){\n        par(mar=c(3,3,1,1)+0.1)\n        plot(x[,k], x[,l], type=\"n\", xlab=\"\", ylab=\"\")\n        if(is.null(labels)){\n          points(x[,k], x[,l], pch=pch, col=col)\n        }else{\n          text(x[,k], x[,l], labels=labels, col=col)\n        }\n      }else{\n        plot(seq(0,5), seq(0,5), type=\"n\", xlab=\"\", ylab=\"\", axes=FALSE)\n        text(2.5,2.5,names[k], cex=1.2)\n      }\n    }\n  }\n}\n\n## Setup data\ndata(iris)\nx       = as.matrix(iris[,-5])\nn       = dim(x)[1]\np       = dim(x)[2]       # Number of features\nKK      = 3\nepsilon = 0.0000001\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1))\ncolscale = c(\"black\",\"blue\",\"red\")\nshortnam  = c(\"s\",\"c\",\"g\")\npairs2(x, col=colscale[iris[,5]], labels=shortnam[as.numeric(iris[,5])])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nnumruns = 15\nv.sum   = array(0, dim=c(numruns, n, KK))\nQQ.sum  = rep(0, numruns)\n\nfor(ss in 1:numruns){\n  w   = rep(1,KK)/KK  #Assign equal weight to each component to start with\n  mu  = rmvnorm(KK, apply(x,2,mean), 3*var(x))   #Cluster centers randomly spread over the support of the data\n  Sigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\n  Sigma[1,,] = var(x)\n  Sigma[2,,] = var(x)\n  Sigma[3,,] = var(x)\n  \n  sw     = FALSE\n  QQ     = -Inf\n  QQ.out = NULL\n  s      = 0\n  \n  while(!sw){\n    ## E step\n    v = array(0, dim=c(n,KK))\n    for(k in 1:KK){  #Compute the log of the weights\n      v[,k] = log(w[k]) + mvtnorm::dmvnorm(x, mu[k,], Sigma[k,,], log=TRUE) \n    }\n    for(i in 1:n){\n      v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n    }\n    \n    ## M step\n    w = apply(v,2,mean)\n    mu = matrix(0, nrow=KK, ncol=p)\n    for(k in 1:KK){\n      for(i in 1:n){\n        mu[k,]    = mu[k,] + v[i,k]*x[i,]\n      }\n      mu[k,] = mu[k,]/sum(v[,k])\n    }\n    Sigma = array(0,dim=c(KK, p, p))\n    for(k in 1:KK){\n      for(i in 1:n){\n        Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n      }\n      Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n    }\n    \n    ##Check convergence\n    QQn = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        QQn = QQn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n      }\n    }\n    if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n      sw=TRUE\n    }\n    QQ = QQn\n    QQ.out = c(QQ.out, QQ)\n    s = s + 1\n  }\n  \n  v.sum[ss,,] = v\n  QQ.sum[ss]  = QQ.out[s]\n  print(paste(\"ss =\", ss))\n}\n\n\n[1] \"ss = 1\"\n[1] \"ss = 2\"\n[1] \"ss = 3\"\n[1] \"ss = 4\"\n[1] \"ss = 5\"\n[1] \"ss = 6\"\n[1] \"ss = 7\"\n[1] \"ss = 8\"\n[1] \"ss = 9\"\n[1] \"ss = 10\"\n[1] \"ss = 11\"\n[1] \"ss = 12\"\n[1] \"ss = 13\"\n[1] \"ss = 14\"\n[1] \"ss = 15\"\n\n\nCode\n## Cluster reconstruction under the mixture model\ncc = apply(v.sum[which.max(QQ.sum),,], 1 ,which.max)\ncolscale = c(\"black\",\"blue\",\"red\")\npairs2(x, col=colscale[cc], labels=cc)\n\n\n\n\n\n\n\n\n\nCode\nARImle = adjustedRandIndex(cc, as.numeric(iris[,5]))  # Higher values indicate larger agreement\n\n## Cluster reconstruction under the K-means algorithm\nirisCluster &lt;- kmeans(x, 3, nstart = numruns)\ncolscale = c(\"black\",\"blue\",\"red\")\npairs2(x, col=colscale[irisCluster$cluster], labels=irisCluster$cluster)\n\n\n\n\n\n\n\n\n\nCode\nARIkmeans = adjustedRandIndex(irisCluster$cluster, as.numeric(iris[,5]))",
    "crumbs": [
      "3. Mixture Models",
      "Applications of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L04.html#classification",
    "href": "C3-L04.html#classification",
    "title": "Applications of Mixture Models",
    "section": "",
    "text": "Classification is a supervised learning problem where we want to predict the class of a new observation based on its features.\nAccording to the instructor the main difference from clustering is that in classification we have a training set. I would think the main difference is that we have labels for some of the data, while in clustering we do not have labels at all.\nThe fact that we have labels and a training set means we should know how many classes we have and we can use these labels to train a model and use it to predict the class of a new observation.\nThe instructor mentions Support Vector Machines (SVM), logistic regression and linear discriminant analysis (LDA) as familiar examples of classification methods. These and a number of others are covered in (isl?). We will focus on Naive Bayes classifiers as it is the most similar to mixture models and the EM algorithm which we have seen earlier\n\n\n\n\n\n\nK-means clustering\n\n\n\n\nK-means clustering\n\n\n\n\nMixture Models for Clustering\n\n\n\n\n\nThe idea of Naive Bayes classifiers is that we want to know what is the probability that observation i belongs to class k and we can obtain this using Bayes’ theorem by computing the prior probability that an observation is in that class. This is just the frequency of the class multiplied by the density of that class and divided by the sum over the classes of the same expression.\n\nP(x_i \\in \\text{class}_k) = \\frac{w_k \\cdot g_k(x_i|\\theta_k)}{\\sum_{j=1}^K w_j \\cdot g_j(x_i|\\theta_j)}\n\\tag{4}\nwhere w_k is the prior probability of class k, g_k(x_i|\\theta_k) is the density of class k, and \\theta_k is the parameter of class k.\nwith\n\n\\tilde{c}_i = \\arg \\max_k \\mathbb{P}r(x_i \\in \\text{class}_k)\\ for \\; i=n+1,\\ldots,n+m\n\nThe naive Bayes classifier assumes that the features are conditionally independent given the class. This means that the density of class k can be written as the product of the densities of each feature given the class: \ng_k(x_i|\\theta_k) = \\prod_{l=1}^p g_{kl}(x_{il}|\\theta_{kl})\n\nwhere g_{kl}(x_{il}|\\theta_{kl}) is the density of feature l given class k and \\theta_{kl} is the parameter of feature l given class k. This means that we can estimate the density of each feature separately and then multiply them together to get the density of the class.\nThis is a very strong assumption and is not true in general. However, it works well in practice and is often used in text classification problems where the features are the words in the text.\nThe naive Bayes classifier is a special case of the mixture model where the components are the classes and the densities are the product of the densities of each feature given the class. This means that we can use the EM algorithm to estimate the parameters of the model in the same way as we did for the mixture model. The only difference is that we need to estimate the densities of each feature separately and then multiply them together to get the density of the class.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nThe last class of problems for which mixture models are very useful is classification problems. If you come from the machine learning literature, you will call this supervised classification to contrast, again, unsupervised classification that I called clustering before. The goal in supervised classification is to start with a training set and use the information in a training set to determine the classes or the labels of a second group of observations that you call the test set. So you start with a training set that contains known labels classes. You also have a test set that has unknown labels, and you want to use this information to make predictions about the test set labels. For example, you may want to decide whether a person suffers from a disease or not based on a set of medical tests, maybe P medical tests, and you have gone out and measured those tests in a number of individuals. So you know those individuals whether they are sick or they are not sick. Based on that training set that is labeled where you know what the real quality of the individuals is, then you go out and you are going to pick just a random person that comes into your medical appointment, and based on the results of the test, now you want to decide if that individual suffers from the disease or not. So the presence of the training set is really what distinguishes clustering problems from classification problems. In clustering problems, we don’t have a training set. We don’t have anything that gives us a hint about how the classes look like. We’re trying to do the process of dividing the observations into groups in some sense blindly. That’s why it’s sometimes called unsupervised classification because you can think that the training set provides supervision in how you do the classification. In typical supervised classification problems on the other hand, you do have that training set. You do have that group of labeled observations that can help you make decisions about how the new groups will look like. So in some sense, supervised classification is a simpler problem than unsupervised classification because of the presence of the training set. Now, there are a number of classification procedures out there. This is a fairly common problem in the literature. You may be familiar with things like support vector machines or logistic regression for classification. I want to discuss today the similarities between using mixture models for classification and some techniques such as linear discriminant analysis, and in particular with Naive Bayes classifiers. The idea of Naive Bayes classifiers is very simple. So if you want to know what is the probability that observation i belongs to class k, you can typically obtain that by just using Bayes’ theorem by computing the prior probability that an observation is in that class. That is typically just the frequency of the class multiplied by the density of that class and divided by the sum over the classes of the same expression. Now, again, this should be very familiar. This quantity here is essentially what we used both in the EM algorithm to compute the [inaudible] case and in the MCMC algorithm if you are fitting a mixture model from a Bayesian perspective to sample the class labels C sub x. So in other words, it’s clear just from writing the expression from Naive Bayes that there should be a very close relationship between doing Naive Bayes and doing mixture models. In fact, you can cast Naive Bayes classifiers as just as a special case of mixture models. Let’s discuss Naive Bayes classifiers where we use Gaussian kernels for the classification. Let’s enter this a little bit of notation. So remember that we have both a test set and a training set. So let’s call X_1 up to X_n my training set, and let’s call X_n plus 1 up to X_n plus m the test set. In other words, we have n observations in the training set, we have m observations in the test set and we just group the observations together so that the first n in the sample are the training and last m are the test. In addition to this, because the training set is labeled, we’re going to have C_1 up to C_n are known, but C_1 or C_n plus 1 up to C_m plus n are unknown and we want to protect them. Let’s write a Naive Bayes classifier that uses Gaussian kernels, and we’re going to use the more general Gaussian kernels that we can. So in that case, the probability that observation i belongs to class k, it’s going to be equal to Omega_k 1 over the square root 2 Pi to the p. Remember that we’re working with P variate normal. So we can have P features for each individual, determinant of Sigma_k to the minus one 1/2 X of minus one 1/2 X_i minus Mu k transpose sigma sub k inverse X_i minus Mu k, divided by the sum over the components of exactly the same expression. This has to be l, minus Mu sub l transpose sigma l inverse X_i minus Mu l. So this is just Bayes theorem as we have written multiple times in this course. So what you do is, you need this expression only for the training set because for the test set you already know what class you are in. So what you typically do is a two-step process in which you get Mu k hat and Sigma hat sub k are estimated from the training set. You could do different things, but it’s very fairly common to just fit a multivariate Gaussian to each one of the components. So your Cs, your labels divide your training set into groups. For each one of those groups, you fit one different normal and that gives you Sigma and Mu. Similarly, for Omega k, you want to get an estimate for Omega k, and the natural thing to do is to just use the frequency, the fraction of the observations in the training set that belong to each one of the classes. Once you have those, then you classify new observations as by letting C_i be equal to the org max of that probability. Where the probabilities are computed by plugging in these maximum likelihood estimators in this formula up here. As I said, this is done for n plus 1 all the way to n plus m. So you don’t need to do this for the training set, the training set you know the labels and you use those labels to compute the MLEs that get plugged into this. Now, with additional observations in those MLEs, you can decide what are the classes for them. So this is what a naive Bayes classifier based on Gaussian distributions for each one of the classes would look like. Now, this is exactly the same as the EM algorithm that we have discussed in the past for mixture models, if we make a couple of assumptions or if we incorporate a couple of assumptions into the algorithm. So let’s write down that next. We can recast the algorithms that we just saw for naive Bayes classifier based on Gaussian kernels in the context of the EM algorithm that we have been discussing for mixtures. That is very easy, we’re going to think, again, about an E-step and an M-step, and we’re going to add an additional post-processing step, if you will. In our E-step, if you remember, what we did in the past was to compute the indicators for the variables. So that is our variables V_i,k that corresponds to the weights that are associated with each one of the components. What we’re going to do in this case is we’re going to define the V_i,k in a very simple fashion rather than doing it using Bayes theorem. Because we actually know what observations or what components are generating each of the observations in the training set, we can call V_i,k just one or zero if C_i is equal to k and zero otherwise, for all the observations that go from one to n. In other words, this is for the training set. Once we have defined our E-step in this way, we’re going to have an M-step where we compute Mu sub k and Omega sub k. To put it in the same way that we did with the EM algorithm, this is going to have a very particular shape. It’s going to have the sum from one to n of V_i,k X_i divided by the sum from one to n of V_i,k. In a similar expression for my matrix Sigma, Sigma is going to be Sigma sub k, it’s going to be one over the sum of the V_i,k from one to n, sum from one to n of V_i,k X_i minus Mu k, X_i minus Mu k transpose. These are expressions that we have seen in the past when filling mixtures of multivariate Gaussians to data. This is just a fancy way, so casting it in terms of the E-step and the M-step, it’s just a fancy way to say, I know what my assignments are, for sure, because this is a training set. So this is just computing the average of the observations that are in category K because, in this case, these are either zeros or ones. Similarly, here, this is just the variance covariance matrix of the observations that are in component K, but it’s written in a fancy way using this V_i,k as indicators. Then, we have a post-processing. It’s in the post-processing step where the test set comes into play. So for now, we have only used the training set for our calculations. In the post-processing step, what we do is we allocate C_i based on the arc max over K of the posterior distribution of the class allocations. So that is probability that X_i belongs to class K. So this is just another way to write the algorithms as we had before, that is very simple in the context of [inaudible]. So why did I go through the trouble of expressing this in this complicated manner when I had a very simple description before? Well, because now you can try to generalize this from this supervised setting where you completely break apart the estimation of the parameters that only uses the training set and the classification that only uses the test set. You can actually try to combine information from both, and it should be clear that if you have training sets that are just very small compared to the test set, the estimates that you get for Mu and Sigma will be very bad because they will be based on very few observations, very few data points. So if you could somehow use some of the information that you are recovering by doing the classification to help you estimate what Mu and Sigma are, they’ll probably give you more robust, stronger algorithm. How to do that should be relatively straightforward once you think about it in this context. For the observations to the training set, we have the value of the V_i,k, but we could add an estimate of the value of the V_i,k for the observations in the test set to this calculation. We already know how to do that. So we’re going to turn the algorithm iterative now. So these guys are always going to be defined in this way because I know the C’s, but these guys are refined at every iteration of the algorithm. I’ll just make this essentially equal to the probability that X_i belongs to class K given the current parameters of the model, so given the current Omegas, the current Mus, and the current Sigmas. Then, I can extend my sums to m down here and down here. Now, what I’m doing is, for the observations that I know what class they are in, these weights are either zeros or ones. For the ones that I don’t know but I’m trying to classify, they will be some number between zero and one, and I’m just going to do a weighted average so you can think about this, again, as a weighted average of the information that I know for sure, and the information that I’m recovering about Mu and Sigma from the classification. So again, this now becomes an iterative algorithm, so I need to think about t plus 1, t plus 1, t plus 1, t plus 1, t plus 1, t plus 1, and t plus 1. So I have turned what was just a two-step algorithm that doesn’t require any iteration, I turned it into an iterative algorithm that uses the whole sample to estimate the parameters of the classes. This is sometimes called a semi-supervised; I don’t necessarily like the term very much. But this is sometimes called a semi-supervised algorithm, in the sense that it’s not completely supervised because of the addition of this information and the fact that now, the sums go up to m. But it’s also not fully unsupervised because I’m using the information, I’m using this piece up here that has information where I know their true labels. Once the algorithm converges, I’m still going to do the post-processing step that is to go from this V_i,k’s that I computed here for the test set to generate what are the labels for those observations.\n\n\n\n\n\n\n\n  It is important to understand the connection between using mixture models for classification and other procedures that are commonly used out there for classification. One example of those procedures that has a strong connection is linear discriminant analysis and also to quadratic discriminant analysis.\nTo illustrate that connection, we start with a very simple mixture model.\nSo let’s start with a mixture model of the form,\n\nf(x) = \\sum_{k=1}^2 \\omega_k \\frac{1}{\\sqrt{2\\pi}} \\frac{1}{\\sqrt{\\text{det}(\\Sigma)}} e^{-\\frac{1}{2}(x - \\mu_k)^T \\Sigma^{-1} (x - \\mu_k)}.\n\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nIt is important to understand the connection between using mixture models for classification and other procedures that are commonly used out there for classification. One example of those procedures that has a strong connection is linear discriminant analysis. And also, by the way, quadratic discriminant analysis. But let’s start with linear discriminant analysis.\nAnd to illustrate that connection, let’s start with a very simple mixture model.\nSo let’s start with a mixture model of the form, f(x) = the sum from 1 to 2. So I’m going to be working only with two components of omega k, 1 over the square root 2pi to the p determinant of sigma to the -1 half, x- 1 half, x, mu sub k, transpose sigma inverse, x- mu sub k. So this is two-component mixture with locations bearing with a component, but the same variance-covariance matrix for the two components that I have in the mixture.\nAnd let’s think about how the procedure would look like if we were to do Naive Bayes classification using this mixture. If I follow the unsupervised example that I have discussed before, the probability that I put observation i in class, 1, say, I only have two classes.\nSo as you see again, consider one of them and the other one is just 1- the numbers that I get here. It’s going to be equal.\nAnd I’m going to expand this in all its glory. It’s going to be a little bit long. So it’s going to be omega 1, 1 over the square root 2pi to the p determinant of sigma to the- 1 half, x of- 1 half, x- mu k transpose sigma inverse x- mu k. And in the denominator, we’re going to have the same expression first. And then we’re going to have omega 2, that is just 1- omega 1 but 2pi to the p determinant of sigma to the- 1 half x- 1 half x- mu 2, sigma inverse x- mu 2. Okay, and we know that the probability that xi belongs to class 1 is exactly the same expression but replacing mu, 1 which is what should be up here, replacing mu1 with mu2.\nSo, in the post processing step, we are going to assign C sub i = 1 if and only if the probability that xi belongs to class 1 is greater than the probability that xi belongs to class 2. And because the two expressions are the same in the denominator, the only thing that changes is the numerator, then this happens if and only if omega 1, 1 over the square root 2pi to the p determinant sigma to the- 1 half x- 1 half, X- mu1 transpose sigma inverse x- mu1, Is greater than omega 2, 1 over the square root 2pi to the p determinant of sigma to the- 1 half x of- 1 half x- mu2, sigma inverse x- mu2. So probability of class 1 greater than probability of class 2 only if this quantity is greater than the same thing but evaluated for the second component in the mixture. So let’s do a little bit of algebra and let’s try to simplify this expression a little bit and we will see that that simplification leads to a very nice expression that matches exactly what you get out of linear discriminant analysis. So now we want to simplify this expression that corresponds to the situation where we’re going to label an observation coming from class 1, and we want to make it much more compact. So a few things that we can observe. So one of them is we have 1 over square root 2pi to the p on both sides, so we can cancel that. The other thing that we observe is that we have the determinant of the variance-covariance matrix on both sides. And because we’re assuming that the two components have the same variance- covariance matrix, we can again just simplify both terms on either side. And the next thing that I’m going to do is I’m going to move all the omegas to one side and bring all the terms with the exponentials to the other side. If I do that, I’m going to end up on the left hand side with the exponent of- 1 half, X- mu1 transpose sigma inverse x- mu1. And then this term came to the other side in the denominator, but that just means that when it goes into the exponential, I need to change all to reverse signs. So it’s going to be- x- mu2 transpose sigma inverse x- mu2. So that’s the expression once you move this to the denominator and combine the two exponentials. And this needs to be greater than omega 2 divided by omega 1. Now, some further simplifications. I can take the logarithm on both sides and I can multiply by -2 on both sides, and I end up with an expression that looks like x- mu 1 transpose sigma inverse x- mu1- x- mu 2 transpose sigma inverse x- mu 2 has to be less than, because I’m going to end up multiplying by a -2. So less than -2 log of omega 2 divided by omega 1. So now we have this difference of two quadratic forms needs to be less than a certain constant that depends on what are my prior weights for each one of the two components. Now, to finish simplifying this, we need to expand these two squares, which is pretty straightforward. So first we’re going to have x sigma inverse x transpose sigma inverse x. This is just a square. So it’s going to be 2 times x transpose sigma inverse mu1. And finally, \\mu_1 transpose sigma inverse \\mu_1. And then we need to subtract a similar expression but using mu2 for it turns. So it’s going to be x transpose sigma inverse x. It’s going to be +, in this case, 2x transpose sigma inverse mu2. And finally, again,- mu2 transpose sigma inverse mu2, and all of these needs to be less than -2 log of omega 2, Divided by omega 1. So you can see that the expressions are relatively straightforward.\nAnd one of the things that is very nice, and it’s a consequence of having the same variance-covariance matrix for each one of the components, is that now this quadratic term of the data is going to cancel out. And so, we can just basically learn together a couple of terms. So we can write, 2 times, X transpose sigma inverse multiplied by mu2- mu1. So I’m taking this term and combining it with this term. So, the term here and the term here.\nAnd then I’m going to say that this has to be less than -2 times log of omega 2 divided by omega 1, and I’m going to move this two terms to the right. So,+ mu2 transpose sigma inverse mu2- mu1 transpose sigma inverse mu1. So this is actually quite a bit of simplification and it’s a very interesting one. Because you can think about this, Thing on the right hand side, just call this T for threshold. So this is your sum threshold and that threshold is basically computed based on the training data. So if I know the classes of some observations, I can get what the means for each one of the classes are, I can estimate the common sigma, and I can estimate the relative frequencies. And with that, I can obtain a stress score from the training set. And I can think about this matrix product as sum vector a. The form of this simplified expression is very interesting. You can see that the right-hand side, all this expression in the box, it’s just a threshold that can be easily computed from the training set. We can estimate the weight and we can estimate the mean and the covariance of the two components. And then, this product of the variance-covariance or the inverse of the variance-covariance matrix times the difference of the means corresponds to a vector a that can also be computed from the training set. So essentially, the decision of whether we classify an observation in class 1 or class 2 is going to depend on whether a linear combination, and that’s what x transpose times a is, is just a linear combination of the values of x. So whether this linear combination of the values of x is greater than a given threshold or not. In other words, what we’re doing, In a setting where we only have two variables, for example, x1 and x2, the linear combination of the entries is just a line on the plane. So this product just corresponds to a line. And by deciding whether we are above the line or below the line, we’re just saying that one of the regions corresponds to class, 2, and the other region corresponds to class 1. So this is the reason why the procedure is called linear discriminant analysis because it uses a straight line to decide whether observations should be classified in class 1 and class 2. Now, there are some more interesting things that you can do. For example, you don’t have to assume that the sigmas are the same, you could assume that the sigmas are different. If you were to do that, then you’d be in a situation that is analogous to this one with the main difference being that now these terms here wouldn’t necessarily simplify. But then, you can rearrange terms in such a way that now, you’re going to have a quadratic form of x being less than a certain threshold. And in that case, you’re separating hyperplane. Instead of being a hyperplane or line, it’s going to be a quadratic form. And that is the reason why when you’re doing Naive Bayes and you’re working with kernels that are Gaussian and have different variance-covariance matrices, you call the procedure quadratic discriminant analysis. Because it uses a quadratic form, a parabola or something like that to separate the two classes that you’re working with. The nice thing about thinking about this classification procedures in the context of mixture models is again, thinking about ways in which you can generalize and address the shortcomings of the procedure. It’s clear that the main issue with classification procedures based on Gaussians is that data in the real world sometimes doesn’t look like multivariate Gaussian distributions. So one possible extension is to instead of considering the density, this ps here to be a single Gaussian, you can kind of use mixtures a second time and borrow some ideas from when we did density estimation. And say well, I’m going to have a mixture and each component of that mixture is in turn a second mixture that may have a few components. And that may allow for the shape of the clusters to be much more general, and that’s what we call mixture discriminant analysis. As before, if you instead of doing the Algorithm and the simple maximum likelihood estimation that I described before, you instead use Bayesian estimators for your process, then you will have Bayesian equivalent of linear discriminant analysis and quadratic discriminant analysis. So it is very useful to think about your statistical methods in the context of mixture models for the purpose of both generalizing and understanding the shortcomings of what you’re doing.\n\n\n\n\n\n\n\n\n\nThis video discusses the code in the next section.\n\n\n\n\n\n\nNoteVideo Transcript\n\n\n\n\n\nI’m going to illustrate now to use of mixture models for classification using the wind dataset. Unlike the previous datasets that we work with, this one is not included in R by default. So the two files that you need wind training and wind tests are available on the website, make sure that you download them and that you have them in the right directory for R to read them. And in this case, I made sure that I change the directory where I’m looking at before I start working with this, and that I put my files in there.\nOkay, so the wind dataset is an interesting one, it’s a series of measurements for different varieties of wine. They come from three different cultivars, and for each particular variety of wine. They did a chemical analysis and measure 13 different variables that have to do with different chemical components present in the world. So we have a label set where we know which samples from which of the three cultivars. And now we want to use the information that we clean out of that to classify to decide a series of new wines to assign them to the cultivar that we think they come from. We actually do know the truth for the test set, so we will actually first do the predictions we’ll act as if we don’t know what the cultivar of the test set is. And then we will compare the predictions that we’re making against the truth, as a way to tell how well the algorithm is to it, okay. So the first thing that we need to do is load our dataset as I said, you need to make sure that the two files are in the directory where you’re working. So make sure of that, remember that we called n the sample size of the training set and m the training size the size of the test set. So I’m just calling the variables that way, and I’m going to use mixture of normals mixture of multivariate normals by location and scale. So I’m going to use a method that is essentially equivalent to doing quadratic discriminant analysis. And, I want to run the Algorithm that I discussed on the board, but in a situation which we assume that we’re going to work with semi-supervised learning. In other words, I went around the Version of the algorithm in which we’re going to use all the observation both in the training and the test set, to learn the parameters of the classes. So it’s going to be an iterative algorithm. So we know in advance as we have three classes because we have three cultivars. B in this case is going to be 13 because there are 13 features that were measured on each wine. So if you come down here, you can see that B 13, we can try to do a graph of the data. In this case the graph is not going to be terribly readable because there are so many variables, but it may still provide a little bit of intuition. So the variables that are measured things like alcohol, the ash, the alkalinity, the level of magnesium, the hue that has to do with how dark the wine is, proline. So you can see here where the variables are there are measured, and even though the graph is not very readable at least you can see that the classes do not fully overlap. So we do have some hope that we may be able to do classification in the problem. That’s pretty much the main thing that you can say out of this graph here, okay. So, as I said before mixture of models with different components, different variances and different means for each component its normal component in the mixture. Same type of standard initialization that we have done before. And we’re going to do the E and the M step here, remember that for the observations in the training set. We know the class, so the value of B are either 0 or 1, and because we do the calculation first in the log scale, then we do either 0 or minus infinity. So 0 corresponds to probability of 1 and minus infinity corresponds to a probability of 0 in the log scale. And then for the observations in the test set, we have just a regular way in which we compute the probability that the observation comes from each class. And once we have done this then we subtract, we do as we have always done subtract maximums and then restandardize. So this is how the ES step gets adapted in the case of semisupervised classification. And then the structure of the m-step is exactly the same structure of the regular Algorithm. So we compute means and variances for each one of the components as weighted averages of the different quantities. We check conversions in the standard way, in which we have been checking convergence. And finally once everything is done, we will get a classification, so let’s run it for this dataset. It runs actually quite quickly, we have only 12 iterations and we have converged. Now what the Algorithm gives gave us is just the B values, that is the probability that an observation comes from a given class. Now, we typically are going to want to convert those peas into Cs and as we saw on the board, that is done by just selecting the class that has the highest probability.\nSo if we do that for our training set in this case, and if you look at the indexes here, they run from n + 1 to n + m, which means that we’re looking at test set. If we just get what is the maximum we can see that the first block of observations is assigned to component two. Most of this block is assigned to component two except for this guy here, and then the the remaining block of observation is assigned to components three. So now how does that compare with the truth? So we can actually go into winder test, and the first column of that file contains the true labels, and we can say that it matches actually pretty well. So the ones all match, the twos match except for one guy, the one we had kind of identified before, and the threes all match together. And we can actually if you just want to have a summary of how many errors you make. You can do a little comparison like this, and you can find that there is only a single error in the classification that the algorithm does.\nNow let’s compare that with just using quadratic discriminant analysis and linear discriminant analysis. The way they are implemented in R, so QDA and LDA are the two functions that you will need, they are part of the mass package. So, We first feed the QDA model and then we that fitted model to predict the classes. And now if we see what the regular QDA does is it’s going to give me this long list of probabilities for the test set. And we can turn those into labels and in particular we can see how many errors we’re making in the prediction. And you can see that we make a single mistake, which is actually not the mistake that we had made before. So if we just look at this one here and we compare it against the, Classification that our algorithm did, and we compared it against the truth.\nWe see that our algorithm makes a mistake in this observation and QDA does not, and instead the error is somewhere else in this sample. It’s basically here, so you can see that the QDA classifies this as two, when the reality is that it’s a three. So our results are not identical to QDA even though our method is asymptotically going to be equivalent to QDA but they don’t give us exactly the same result, but they give us very similar accuracy. Interestingly if you run LDA and you try to look at how many errors you have in that case, you will see that LDA in this case has no errors, even though it’s a simpler more restrictive classification procedure. So this can happen, so it’s a relatively large sample, so a single a difference in a single error is not a very large difference. So, hopefully this illustrates how classification or how measurements can be used for classification in a real life setting.\n\n\n\n\n\n\n\n\nCode\n## Using mixture models for classification in the wine dataset\n## Compare linear and quadratic discriminant analysis and a \n##   (semi-supervised) location and scale mixture model with K normals\n## Comparing only against the EM algorithm\n\n# Semi-supervised, quadratic discriminant analysis \n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(mvtnorm)\nwine.training = read.table(\"data/wine_training.txt\", sep=\",\", header=TRUE)\nwine.test = read.table(\"data/wine_test.txt\", sep=\",\", header=TRUE)\nn = dim(wine.training)[1]  # Size of the training set\nm = dim(wine.test)[1]      # Size of the test set\nx = rbind(as.matrix(wine.training[,-1]), as.matrix(wine.test[,-1]))   # Create dataset of observations, first n belong to the training set, and the rest belong to the test set\np       = dim(x)[2]              # Number of features\nKK      = 3\nepsilon = 0.00001\n\npar(mfrow=c(1,1))\npar(mar=c(2,2,2,2)+0.1)\ncolscale = c(\"black\",\"red\",\"blue\")\npairs(wine.training[,-1], col=colscale[wine.training[,1]], pch=wine.training[,1])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #Cluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\nsw     = FALSE\nKL     = -Inf\nKL.out = NULL\ns      = 0\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n+m,KK))\n  for(k in 1:KK){  #Compute the log of the weights\n    v[1:n,k] = ifelse(wine.training[,1]==k,0,-Inf)  # Training set\n    v[(n+1):(n+m),k] = log(w[k]) + mvtnorm::dmvnorm(x[(n+1):(n+m),], mu[k,], Sigma[k,,],log=TRUE)  # Test set\n  }\n  for(i in 1:(n+m)){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w = apply(v,2,mean)\n  mu = matrix(0, nrow=KK, ncol=p)\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0,dim=c(KK,p,p))\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:(n+m)){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -3146.58419305226\"\n[1] \"2 -2942.48222029706\"\n[1] \"3 -2873.76499310479\"\n[1] \"4 -2852.76768638231\"\n[1] \"5 -2796.247735428\"\n[1] \"6 -2791.29098585679\"\n[1] \"7 -2791.23059641487\"\n[1] \"8 -2791.14094416728\"\n[1] \"9 -2791.05612416221\"\n[1] \"10 -2790.99254414223\"\n[1] \"11 -2790.95228067601\"\n[1] \"12 -2790.92945838389\"\n\n\nCode\n## Predicted labels\napply(v, 1, which.max)[(n+1):(n+m)]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## True labels\nwine.test[,1]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## Comparison\napply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1]\n\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nCode\nsum(!(apply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# Using the qda and lda functions in R\n# qda\nmodqda = qda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredqda = predict(modqda,newdata=wine.test[,-1])\nsum(!(ccpredqda$class == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# lda\nmodlda = lda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredlda = predict(modlda,newdata=wine.test[,-1])\nsum(!(ccpredlda$class == wine.test[,1])) # No errors!!!\n\n\n[1] 0",
    "crumbs": [
      "3. Mixture Models",
      "Applications of Mixture Models"
    ]
  },
  {
    "objectID": "A11.html",
    "href": "A11.html",
    "title": "Bayes by backprop",
    "section": "",
    "text": "This appendix reviews of a method to introduce weight uncertainty into neural networks called the “Bayes by Backprop” method introduced in (Blundell et al. 2015). where, the main question is how to determine the parameters of the distribution for each network weight. I learned about it from Probabilistic Deep Learning with TensorFlow 2 by Dr Kevin Webster, S reading from based this on\nThe authors note that prior work which considered uncertainty at the hidden unit (H_i) an approach that allows to state the uncertainty with respect to a particular observation and which is an easier problem since the number of weight is greater by two orders of magnitude. But considering the uncertainty in the weights is complementary, in the sense that it captures uncertainty about which neural network is appropriate, leading to regularization of the weights and model averaging. This weight uncertainty can be used to drive the exploration/exploitation in contextual bandit problems using Thompson sampling . Weights with greater uncertainty introduce more variability into the decisions made by the network, naturally leading to exploration. As more data are observed, the uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the environment is better understood.\n\n\n\nFig. 1 from (Blundell et al. 2015) contrasting traditional and Bayesian neural networks\n\n\nIn a traditional neural network, as shown in the upper left, each weight has a single value. But in the true value for these weights is not certain. Much of this uncertainty comes from imperfect training data, which is an approximation of the the distribution of the data generating process from which the data were sampled. Recall that this is called epistemic uncertainty, which we expect to decrease as the amount of training data increases.\nIn this method, we want to include such uncertainty in deep learning models. This is done by changing each weight from a single deterministic value to a probability distribution. We then learn the parameters of this distribution. Consider a neural network weight w_i . In a standard (deterministic) neural network, this has a single value \\hat{w}_i , learnt via backpropagation. In a neural network with weight uncertainty, each weight is represented by a probability distribution, and the parameters of this distribution are learned via backpropagation. Suppose, for example, that each weight has a normal distribution. This has two parameters: a mean \\mu_i and a standard deviation \\sigma_i .\n\nClassic deterministic NN: w_i = \\hat{w}_i\nNN with weight uncertainty represented by normal distribution: w_i \\sim N(\\hat{\\mu}_i, \\hat{\\sigma}_i) .\n\nSince the weights are uncertain, the feedforward value of some input x_i is not constant. A single feedforward value is determined in two steps: 1. Sample each network weight from their respective distributions – this gives a single set of network weights. 2. Use these weights to determine a feedforward value \\hat{y}_i .\nHence, the key question is how to determine the parameters of the distribution for each network weight. The paper introduces exactly such a scheme, called Bayes by Backprop.",
    "crumbs": [
      "6. Appendices",
      "Bayes by backprop"
    ]
  },
  {
    "objectID": "A11.html#introduction",
    "href": "A11.html#introduction",
    "title": "Bayes by backprop",
    "section": "",
    "text": "This appendix reviews of a method to introduce weight uncertainty into neural networks called the “Bayes by Backprop” method introduced in (Blundell et al. 2015). where, the main question is how to determine the parameters of the distribution for each network weight. I learned about it from Probabilistic Deep Learning with TensorFlow 2 by Dr Kevin Webster, S reading from based this on\nThe authors note that prior work which considered uncertainty at the hidden unit (H_i) an approach that allows to state the uncertainty with respect to a particular observation and which is an easier problem since the number of weight is greater by two orders of magnitude. But considering the uncertainty in the weights is complementary, in the sense that it captures uncertainty about which neural network is appropriate, leading to regularization of the weights and model averaging. This weight uncertainty can be used to drive the exploration/exploitation in contextual bandit problems using Thompson sampling . Weights with greater uncertainty introduce more variability into the decisions made by the network, naturally leading to exploration. As more data are observed, the uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the environment is better understood.\n\n\n\nFig. 1 from (Blundell et al. 2015) contrasting traditional and Bayesian neural networks\n\n\nIn a traditional neural network, as shown in the upper left, each weight has a single value. But in the true value for these weights is not certain. Much of this uncertainty comes from imperfect training data, which is an approximation of the the distribution of the data generating process from which the data were sampled. Recall that this is called epistemic uncertainty, which we expect to decrease as the amount of training data increases.\nIn this method, we want to include such uncertainty in deep learning models. This is done by changing each weight from a single deterministic value to a probability distribution. We then learn the parameters of this distribution. Consider a neural network weight w_i . In a standard (deterministic) neural network, this has a single value \\hat{w}_i , learnt via backpropagation. In a neural network with weight uncertainty, each weight is represented by a probability distribution, and the parameters of this distribution are learned via backpropagation. Suppose, for example, that each weight has a normal distribution. This has two parameters: a mean \\mu_i and a standard deviation \\sigma_i .\n\nClassic deterministic NN: w_i = \\hat{w}_i\nNN with weight uncertainty represented by normal distribution: w_i \\sim N(\\hat{\\mu}_i, \\hat{\\sigma}_i) .\n\nSince the weights are uncertain, the feedforward value of some input x_i is not constant. A single feedforward value is determined in two steps: 1. Sample each network weight from their respective distributions – this gives a single set of network weights. 2. Use these weights to determine a feedforward value \\hat{y}_i .\nHence, the key question is how to determine the parameters of the distribution for each network weight. The paper introduces exactly such a scheme, called Bayes by Backprop.",
    "crumbs": [
      "6. Appendices",
      "Bayes by backprop"
    ]
  },
  {
    "objectID": "A11.html#bayesian-learning",
    "href": "A11.html#bayesian-learning",
    "title": "Bayes by backprop",
    "section": "2 Bayesian learning",
    "text": "2 Bayesian learning\nNote: We use the notation P to refer to a probability density. For simplicity, we’ll only consider continuous distributions (which have a density). In the case of discrete distributions, P would represent a probability mass and integrals should be changed to sums. However, the formulae are the same.\nWhat you need to know now is that Bayesian methods can be used to calculate the distribution of a model parameter given some data. In the context of weight uncertainty in neural networks, this is convenient, since we are looking for the distribution of weights (model parameters) given some (training) data. The key step relies on Bayes’ theorem. This theorem states, in mathematical notation, that\n\nP(w \\mid D) = \\frac{P(D \\mid w) P(w)}{\\int P(D \\mid w') P(w') \\text{d}w'}\n\nwhere the terms mean the following:\n\nD is some data, e.g. x and y value pairs: D = \\{(x_1, y_1), \\ldots, (x_n, y_n)\\} . This is sometimes called the evidence.\nw is the value of a model weight.\nP(w) is called the prior. This is our “prior” belief on the probability density of a model weight, i.e. the distribution that we postulate before seeing any data.\nP(D \\mid w) is the likelihood of having observed data D given weight w . It is precisely the same likelihood used to calculate the negative log-likelihood.\nP(w \\mid D) is the posterior density of the distribution of the model weight at value w , given our training data. It is called posterior since it represents the distribution of our model weight after taking the training data into account.\n\nNote that the term {\\int P(D \\mid w') P(w') \\text{d}w'} = P(D) does not depend on w (as the w' is an integration variable). It is only a normalization term. For this reason, we will from this point on write Bayes’ theorem as\n\nP(w \\mid D) = \\frac{P(D \\mid w) P(w)}{P(D)}.\n\nBayes’ theorem gives us a way of combining data with some “prior belief” on model parameters to obtain a distribution for these model parameters that considers the data, called the posterior distribution.",
    "crumbs": [
      "6. Appendices",
      "Bayes by backprop"
    ]
  },
  {
    "objectID": "A11.html#bayesian-neural-network-with-weight-uncertainty-in-principle",
    "href": "A11.html#bayesian-neural-network-with-weight-uncertainty-in-principle",
    "title": "Bayes by backprop",
    "section": "3 Bayesian neural network with weight uncertainty – in principle",
    "text": "3 Bayesian neural network with weight uncertainty – in principle\nThe above formula gives a way to determine the distribution of each weight in the neural network:\n\nPick a prior density P(w) .\nUsing training data D , determine the likelihood P(D \\mid w) .\nDetermine the posterior density P(w \\mid D) using Bayes’ theorem.\n\nThis is the distribution of the NN weight.\nWhile this works in principle, in many practical settings it is difficult to implement. The main reason is that the normalization constant {\\int P(D \\mid w') P(w') \\text{d}w'} = P(D) may be very difficult to calculate, as it involves solving or approximating a complicated integral. For this reason, approximate methods, such as Variational Bayes described below, are often employed.",
    "crumbs": [
      "6. Appendices",
      "Bayes by backprop"
    ]
  },
  {
    "objectID": "A11.html#variational-bayes",
    "href": "A11.html#variational-bayes",
    "title": "Bayes by backprop",
    "section": "4 Variational Bayes",
    "text": "4 Variational Bayes\nVariational Bayes methods approximate the posterior distribution with a second function, called a variational posterior. This function has a known functional form, and hence avoids the need to determine the posterior P(w \\mid D) exactly. Of course, approximating a function with another one has some risks, since the approximation may be very bad, leading to a posterior that is highly inaccurate. In order to mediate this, the variational posterior usually has a number of parameters, denoted by \\theta , that are tuned so that the function approximates the posterior as well as possible. Let’s see how this works below.\nInstead of P(w \\mid D) , we assume the network weight has density q(w \\mid \\theta) , parameterized by \\theta . q(w \\mid \\theta) is known as the variational posterior . We want q(w \\mid \\theta) to approximate P(w \\mid D) , so we want the “difference” between q(w \\mid \\theta) and P(w \\mid D) to be as small as possible. This “difference” between the two distributions is measured by the Kullback-Leibler divergence D_{\\text{KL}} (note that this is unrelated to the D we use to denote the data). The Kullback-Leibler divergence between two distributions with densities f(x) and g(x) respectively is defined as\n\nD_{KL} (f(x) \\parallel g(x)) = \\int f(x) \\log \\left( \\frac{f(x)}{g(x)} \\right) \\text{d} x\n\nNote that this function has value 0 (indicating no difference) when f(x) \\equiv g(x) , which is the result we expect. We use the convention that \\frac{0}{0} = 1 here.\nViewing the data D as a constant, the Kullback-Leibler divergence between q(w \\mid \\theta) and P(w \\mid D) is hence:\n\n\\begin{aligned}\n  D_{KL} (q(w \\mid \\theta) \\parallel P(w \\mid D)) &= \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta)}{P(w \\mid D)} \\right) \\text{d} w \\\\\n&= \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta) P(D)}{P(D \\mid w) P(w)} \\right) \\text{d} w \\\\\n&= \\int q(w \\mid \\theta) \\log P(D) \\text{d} w + \\int q(w \\mid \\theta) \\log \\left( \\frac{q(w \\mid \\theta)}{P(w)} \\right) \\text{d} w - \\int q(w \\mid \\theta) \\log P(D \\mid w) \\text{d} w \\\\\n&= \\log P(D) + D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log P(D \\mid w))\n\\end{aligned}\n\nwhere, in the last line, we have used\n\n\\int q(w \\mid \\theta) \\log P(D) \\text{d}w = \\log P(D) \\int q(w \\mid \\theta) \\text{d} w = \\log P(D)\n\nsince q(w \\mid \\theta) is a probability distribution and hence integrates to 1. If we consider the data D to be constant, the first term is a constant also, and we may ignore it when minimizing the above. Hence, we are left with the function\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log P(D \\mid w))\n\\end{aligned}\n\nNote that this function depends only on \\theta and D , since w is an integration variable. This function has a nice interpretation as the sum of: - The Kullback-Leibler divergence between the variational posterior q(w \\mid \\theta) and the prior P(w) . This is called the complexity cost, and it depends on \\theta and the prior but not the data D . - The expectation of the negative log likelihood \\log P(D \\mid w) under the variational posterior q(w \\mid \\theta) . This is called the likelihood cost and it depends on \\theta and the data but not the prior.\nL(\\theta \\mid D) is the loss function that we minimize to determine the parameter \\theta . Note also from the above derivation, that we have\n\n\\begin{aligned}\n\\log P(D) &= \\mathbb{E}_{q(w \\mid \\theta)}(\\log P(D \\mid w)) - D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) + D_{KL} (q(w \\mid \\theta) \\parallel P(w \\mid D))\\\\\n&\\ge \\mathbb{E}_{q(w \\mid \\theta)}(\\log P(D \\mid w)) - D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) =: ELBO\n\\end{aligned}\n\nwhich follows because D_{KL} (q(w \\mid \\theta) \\parallel P(w \\mid D)) is non negative. The final expression on the right hand side is therefore a lower bound on the log-evidence, and is called the evidence lower bound, often shortened to ELBO. The {ELBO} is the negative of our loss function, so minimizing the loss function is equivalent to maximizing the ELBO.\nMaximizing the ELBO requires a trade off between the KL term and expected log-likelihood term. On the one hand, the divergence between q(w \\mid \\theta) and P(w) should be kept small, meaning the variational posterior shouldn’t be too different to the prior. On the other, the variational posterior parameters should maximize the expectation of the log-likelihood \\log P(D \\mid w) , meaning the model assigns a high likelihood to the data.",
    "crumbs": [
      "6. Appendices",
      "Bayes by backprop"
    ]
  },
  {
    "objectID": "A11.html#a-backpropagation-scheme",
    "href": "A11.html#a-backpropagation-scheme",
    "title": "Bayes by backprop",
    "section": "5 A backpropagation scheme",
    "text": "5 A backpropagation scheme\n\n5.1 The idea\nWe can use the above ideas to create a neural network with weight uncertainty, which we will call a Bayesian neural network. From a high level, this works as follows. Suppose we want to determine the distribution of a particular neural network weight w .\n\nAssign the weight a prior distribution with density P(w) , which represents our beliefs on the possible values of this network before any training data. This may be something simple, like a unit Gaussian. Furthermore, this prior distribution will usually not have any trainable parameters.\nAssign the weight a variational posterior with density q(w \\mid \\theta) with some trainable parameter \\theta .\nq(w \\mid \\theta) is the approximation for the weight’s posterior distribution. Tune \\theta to make this approximation as accurate as possible as measured by the ELBO.\n\nThe remaining question is then how to determine \\theta . Recall that neural networks are typically trained via a backpropagation algorithm, in which the weights are updated by perturbing them in a direction that reduces the loss function. We aim to do the same here, by updating \\theta in a direction that reduces L(\\theta \\mid D) .\nHence, the function we want to minimise is\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log P(D \\mid w)) \\\\\n&= \\int q(w \\mid \\theta) ( \\log q(w \\mid \\theta) - \\log P(D \\mid w) - \\log P(w) ) \\text{d}w.\n\\end{aligned}\n\nIn principle, we could take derivatives of L(\\theta \\mid D) with respect to \\theta and use this to update its value. However, this involves doing an integral over w , and this is a calculation that may be impossible or very computationally expensive. Instead, we want to write this function as an expectation and use a Monte Carlo approximation to calculate derivatives. At present, we can write this function as\n\nL(\\theta \\mid D) = \\mathbb{E}_{q(w \\mid \\theta)} ( \\log q(w \\mid \\theta) - \\log P(D \\mid w) - \\log P(w) )\n\nHowever, taking derivatives with respect to \\theta is difficult because the underlying distribution the expectation is taken with respect to depends on \\theta . One way we can handle this is with the reparameterization trick.\n\n\n5.2 The reparameterization trick\nThe reparameterization trick is a way to move the dependence on \\theta around so that an expectation may be taken independently of it. It’s easiest to see how this works with an example. Suppose q(w \\mid \\theta) is a Gaussian, so that \\theta = (\\mu, \\sigma) . Then, for some arbitrary f(w; \\mu, \\sigma) , we have\n\n\\begin{aligned}\n\\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\int q(w \\mid \\mu, \\sigma) f(w; \\mu, \\sigma) \\text{d}w \\\\\n&= \\int \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( -\\frac{1}{2 \\sigma^2} (w - \\mu)^2 \\right) f(w; \\mu, \\sigma) \\text{d}w \\\\\n&= \\int \\frac{1}{\\sqrt{2 \\pi}} \\exp \\left( -\\frac{1}{2} \\epsilon^2 \\right) f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right) \\text{d}\\epsilon \\\\\n&= \\mathbb{E}_{\\epsilon \\sim N(0, 1)} (f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right) )\n\\end{aligned}\n\nwhere we used the change of variable w = \\mu + \\sigma \\epsilon . Note that the dependence on \\theta = (\\mu, \\sigma) is now only in the integrand and we can take derivatives with respect to \\mu and \\sigma:\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\mu} \\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\frac{\\partial}{\\partial \\mu} \\mathbb{E}_{\\epsilon \\sim N(0, 1)} (f \\left( w; \\mu, \\sigma \\right) ) = \\mathbb{E}_{\\epsilon \\sim N(0, 1)} \\frac{\\partial}{\\partial \\mu} f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right)\n\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\sigma} \\mathbb{E}_{q(w \\mid \\mu, \\sigma)} (f(w; \\mu, \\sigma) ) &= \\frac{\\partial}{\\partial \\sigma} \\mathbb{E}_{\\epsilon \\sim N(0, 1)} (f \\left( w; \\mu, \\sigma \\right) ) = \\mathbb{E}_{\\epsilon \\sim N(0, 1)} \\frac{\\partial}{\\partial \\sigma} f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right)\n\\end{aligned}\n\nFinally, note that we can approximate the expectation by its Monte Carlo estimate:\n\n\\begin{aligned}\n\\mathbb{E}_{\\epsilon \\sim N(0, 1)}  \\frac{\\partial}{\\partial \\theta} f \\left( \\mu + \\sigma \\epsilon; \\mu, \\sigma \\right) \\approx \\sum_{i}  \\frac{\\partial}{\\partial \\theta} f \\left( \\mu + \\sigma \\epsilon_i; \\mu, \\sigma \\right),\\qquad \\epsilon_i \\sim N(0, 1).\n\\end{aligned}\n\nThe above reparameterization trick works in cases where we can write the w = g(\\epsilon, \\theta) , where the distribution of the random variable \\epsilon is independent of \\theta .\n\n\n5.3 Implementation\nPutting this all together, for our loss function L(\\theta \\mid D) \\equiv L(\\mu, \\sigma \\mid D) , we have\n\nf(w; \\mu, \\sigma) = \\log q(w \\mid \\mu, \\sigma) - \\log P(D \\mid w) - \\log P(w)\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\mu} L(\\mu, \\sigma \\mid D) \\approx \\sum_{i} \\left( \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\mu} \\right)\n\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\sigma} L(\\mu, \\sigma \\mid D) \\approx \\sum_{i} \\left( \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} \\epsilon_i + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\sigma} \\right)\n\\end{aligned}\n\n\nf(w; \\mu, \\sigma) = \\log q(w \\mid \\mu, \\sigma) - \\log P(D \\mid w) - \\log P(w)\n\nwhere w_i = \\mu + \\sigma \\epsilon_i, \\, \\epsilon_i \\sim N(0, 1) . In practice, we often only take a single sample \\epsilon_1 for each training point. This leads to the following backpropagation scheme:\n\nSample \\epsilon_i \\sim N(0, 1) . 2. Let w_i = \\mu + \\sigma \\epsilon_i\nCalculate\n\n\n\\nabla_{\\mu}f = \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\mu} \\hspace{3em} \\nabla_{\\sigma}f = \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial w_i} \\epsilon_i + \\frac{\\partial f(w_i; \\mu, \\sigma)}{\\partial \\sigma}\n\n\nUpdate the parameters with some gradient-based optimizer using the above gradients.\n\nThis is how we learn the parameters of the distribution for each neural network weight.\n\n\n5.4 Minibatches\nNote that the loss function (or negative of the ELBO) is\n\n\\begin{aligned}\nL(\\theta \\mid D) &= D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) - \\mathbb{E}_{q(w \\mid \\theta)}(\\log P(D \\mid w)) \\\\\n& = D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) - \\sum_{j=1}^N \\log P(y_j, x_j \\mid w_j)\n\\end{aligned}\n\nwhere j runs over all the data points in the training data (N in total) and w_j = \\mu + \\sigma \\epsilon_j is sampled using \\epsilon_j \\sim N(0, 1) (we assume a single sample from the approximate posterior per data point for simplicity).\nIf training occurs in minibatches of size B , typically much smaller than N , we instead have a loss function\n\n\\begin{aligned}\nD_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) - \\sum_{j=1}^{B} \\log P(y_j, x_j \\mid w_j).\n\\end{aligned}\n\nNote that the scaling factors between the first and second terms have changed, since before the sum ran from 1 to N , but it now runs from 1 to B . To correct for this, we should add a correction factor \\frac{N}{B} to the second term to ensure that its expectation is the same as before. This leads to the loss function, after dividing by N to take the average per training value, of\n\n\\begin{aligned}\n\\frac{1}{N} D_{KL} ( q(w \\mid \\theta) \\parallel P(w) ) - \\frac{1}{B} \\sum_{j=1}^{B} \\log P(y_j, x_j \\mid w_j).\n\\end{aligned}\n\nBy default, when Tensorflow calculates the loss function, it calculates the average across the minibatch. Hence, it already uses the factor \\frac{1}{B} present on the second term. However, it does not, by default, divide the first term by N . In an implementation, we will have to specify this. You’ll see in the next lectures and coding tutorials how to do this.\n\n\n5.5 Conclusion\nWe introduced the Bayes by Backpropagation method, which can be used to embed weight uncertainty into neural networks. Good job getting through it, as the topic is rather advanced. This approach allows the modelling of epistemic uncertainty on the model weights. We expect that, as the number of training points increases, the uncertainty on the model weights decreases. This can be shown to be the case in many settings. In the next few lectures and coding tutorials, you’ll learn how to apply these methods to your own models, which will make the idea much clearer.\n\n\n5.6 Further reading and resources\n\nBayes by backprop paper (Blundell et al. 2015)\nWikipedia article on Bayesian inference",
    "crumbs": [
      "6. Appendices",
      "Bayes by backprop"
    ]
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Examples",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "A07.html",
    "href": "A07.html",
    "title": "Appendix: The Law of Large Numbers",
    "section": "",
    "text": "Suppose we observe data D=\\{x_1, \\ldots, x_n\\} with each x_i \\sim F .\nBy the strong law of large numbers the empirical distribution \\hat{F}_n based on data D=\\{x_1, \\ldots, x_n\\} converges to the true underlying distribution F as n \\rightarrow \\infty almost surely:\n\n\\hat{F}_n\\overset{a. s.}{\\to} F\n\nThe Glivenko–Cantelli asserts that the convergence is uniform. Since the strong law implies the weak law we also have convergence in probability:\n\n\\hat{F}_n\\overset{P}{\\to} F\n\nCorrespondingly, for n \\rightarrow \\infty the average \\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{i=1}^n h(x_i) converges to the expectation \\text{E}_{F}(h(x)) .",
    "crumbs": [
      "6. Appendices",
      "Appendix: The Law of Large Numbers"
    ]
  },
  {
    "objectID": "A07.html#sec-appendix-law-of-large-numbers",
    "href": "A07.html#sec-appendix-law-of-large-numbers",
    "title": "Appendix: The Law of Large Numbers",
    "section": "",
    "text": "Suppose we observe data D=\\{x_1, \\ldots, x_n\\} with each x_i \\sim F .\nBy the strong law of large numbers the empirical distribution \\hat{F}_n based on data D=\\{x_1, \\ldots, x_n\\} converges to the true underlying distribution F as n \\rightarrow \\infty almost surely:\n\n\\hat{F}_n\\overset{a. s.}{\\to} F\n\nThe Glivenko–Cantelli asserts that the convergence is uniform. Since the strong law implies the weak law we also have convergence in probability:\n\n\\hat{F}_n\\overset{P}{\\to} F\n\nCorrespondingly, for n \\rightarrow \\infty the average \\text{E}_{\\hat{F}_n}(h(x)) = \\frac{1}{n} \\sum_{i=1}^n h(x_i) converges to the expectation \\text{E}_{F}(h(x)) .",
    "crumbs": [
      "6. Appendices",
      "Appendix: The Law of Large Numbers"
    ]
  },
  {
    "objectID": "C1-L09-Ex1.html",
    "href": "C1-L09-Ex1.html",
    "title": "",
    "section": "",
    "text": "1. From Concept to Data AnalysisHomework exponential data CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Homework exponential data"
    ]
  },
  {
    "objectID": "C1-L09-Ex1.html#homework-exponential-data",
    "href": "C1-L09-Ex1.html#homework-exponential-data",
    "title": "",
    "section": "1 Homework exponential data",
    "text": "1 Homework exponential data\n\n\n\n\n\n\nTipExponential data\n\n\n\nThe following are useful for solving the problems\n\n\\begin{aligned}\nY  &\\sim Exp(\\lambda) && RV \\\\ f(y|\\lambda)&= \\color{red}{\\lambda^n e^{- \\lambda n \\bar{y} }} && Likelihood \\\\ f(\\lambda)&\\sim Gamma(a,b) && Conj. Prior \\\\&=\\color{blue}{\\lambda^{a - 1}e^{-b \\lambda}} && Prior \\\\ \\therefore \\mathbb{E}[f] &= a/b && Prior\\ mean \\\\ \\therefore \\mathbb{V}ar[f] &= a/b^2 && Prior\\ variance \\\\ \\therefore ESS[f] &= a && Prior ESS \\\\f(\\lambda \\mid y) &\\propto f(y|\\lambda)f(\\lambda) && Posterior \\\\  &\\propto \\color{red}{\\lambda^n e^{-\\lambda n \\bar{y} }}\\color{blue}{\\lambda^{a - 1}e^{-b \\lambda}} \\\\ &\\sim \\Gamma(\\alpha =a + n, \\beta=b + \\lambda n \\bar{y} ) \\\\ \\therefore \\mathbb{E}[f(y|\\lambda)] &= \\alpha / \\beta && Post\\ mean \\\\ \\therefore \\mathbb{V}ar[f(y|\\lambda)] &= \\alpha/\\beta^2 && Post\\ variance \\\\ \\therefore ESS[f(y|\\lambda)] &= a && Post\\ Prior\\ ESS \\\\ \\therefore ESS[f(y|\\lambda)] &= n && Post\\ Data\\ ESS\n\\end{aligned}\n\n\n\n\nExercise 1 See ?@exm-bus-times bus waiting time example\nRecall that we used the conjugate gamma prior for \\lambda, the arrival rate in buses per minute. Suppose our prior belief about this rate is that it should have a mean 1/20 arrivals per minute with a standard deviation 1/5. Then the prior is Gamma(a,b) with a=1/16.\nFind the value of b.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n1.25\n\n\n\n\nExercise 2 See ?@exm-bus-times bus waiting time example\nSuppose that we wish to use a prior with the same mean (1/20), but with an effective sample size of one arrival. Then the prior for \\lambda is Gamma(1,20).\nIn addition to the original Y_1 = 12, we observe the waiting times for four additional buses: Y_2 = 15, Y_3 = 8, Y_4 = 13.5, Y_5 = 25\nRecall that with multiple (independent) observations, the posterior for \\lambda is Gamma(\\alpha,\\beta) where α=a+n and \\beta = b + \\sum y_i What is the posterior mean for \\lambda?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n=(1+5)/(20+12+15+8+13.5+25)=\n\n\nCode\n(1+5)/(20+12+15+8+13.5+25)\n\n\n[1] 0.06417112\n\n\n\n\n\n\nExercise 3 See ?@exm-bus-times bus waiting time example\nBus waiting times:\nContinuing Exercise 2, use R or Excel to find the posterior probability that \\lambda &lt; 1/10?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\npgamma(q=1/10,shape=6,rate=93.5)\n\n\n[1] 0.9039699\n\n\n\n\n\nFor Questions 4-10, consider the following earthquake data:\n\nExercise 4  The United States Geological Survey maintains a list of significant earthquakes worldwide. We will model the rate of earthquakes of magnitude 4.0+ in the state of California during 2015. An IID Exponential model on the waiting time between significant earthquakes is appropriate if we assume:Earthquake data\n\nearthquake events are independent,\nthe rate at which earthquakes occur does not change during the year, and\nthe earthquake hazard rate does not change (i.e., the probability of an earthquake happening tomorrow is constant regardless of whether the previous earthquake was yesterday or 100 days ago).\n\nLet Y_i denote the waiting time in days between the ith earthquake and the following earthquake. Our model is Y_i \\stackrel{iid}\\sim Exponential(\\gamma) where the expected waiting time between earthquakes is \\mathbb{E}[Y]=1/\\lambda days.\nAssume the conjugate prior \\lambda \\sim Gamma(a,b). Suppose our prior expectation for \\mathbb{E}[\\lambda]= 1/30, and we wish to use a prior effective sample size of one interval between earthquakes.\n\nWhat is the value of a ?\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\na is the effective sample size of the prior which we were given as 1.\na=1\n\n\n\n\nExercise 5 What is the value of b?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nThe prior mean is a/b = 1/30, and since we know the effective sample size a=1, we have b=30.\n\n\n\n\nExercise 6 The significant earthquakes of magnitude 4.0+ in the state of California during 2015 occurred on the following dates (http://earthquake.usgs.gov/earthquakes/browse/significant.php?year=2015):\nJanuary 4, January 20, January 28, May 22, July 21, July 25, August 17, September 16, December 30.\nRecall that we are modeling the waiting times between earthquakes in days. Which of the following is our data vector?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\ny = (3, 16, 8, 114, 60, 4, 23, 30, 105, 1)\ny = (0, 0, 4, 2, 0, 1, 1, 3)\ny = (3, 16, 8, 114, 60, 4, 23, 30, 105)\ny = (16, 8, 114, 60, 4, 23, 30, 105)\n\nBeginning the data vector with a wait period of three days implicitly assumes an event occurred on Jan. 1, which is not the case. This would bias our estimate of average wait times on the low side. So we should drop the first point.\n\n\n\n\nExercise 7 Earthquake data\nThe posterior distribution is for \\lambda ∼ Gamma(\\alpha ,\\beta). What is the value of \\alpha?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\\alpha = a + n = 1+8=9\n\n\n\n\nExercise 8 Earthquake data\nThe posterior distribution is for \\lambda \\sim Gamma(\\alpha,\\beta). What is the value of \\beta?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nsum(16, 8, 114, 60, 4, 23, 30, 105, 30)\n\n\n[1] 390\n\n\n\\beta = b + \\sum {y_i} = 30 + sum(16, 8, 114, 60, 4, 23, 30, 105,30)=420\n\n\n\n\nExercise 9 Earthquake data\nThe posterior distribution is for \\lambda ∼ Gamma(\\alpha,\\beta). What is the value of \\beta?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nqgamma(p=0.975, shape=9, rate=390)\n\n\n[1] 0.04041843\n\n\n\n\n\n\nExercise 10 Earthquake data\nThe posterior predictive density for a new waiting time y^∗ in days is:\n\n\\begin{aligned}\nf(y^∗ \\mid y) &= \\int f(y^∗ \\mid \\lambda) \\cdot f(\\lambda \\mid y) d \\lambda \\\\&= \\frac{\\beta^αΓ(\\alpha+1) }{(\\beta+y^*)^{\\alpha+1}Γ(\\alpha)} I_{(y^∗\\ge 0)} \\\\&= \\frac{ \\beta ^ \\alpha \\alpha}{(\\beta+y^*)^{\\alpha+1}} I_{(y^∗\\ge 0)}\n\\end{aligned}\n\nwhere f(\\lambda \\mid y) is the Gamma(α,β) posterior found earlier.\nUse R or Excel to evaluate this posterior predictive PDF.\nWhich of the following graphs shows the posterior predictive distribution for y^∗ ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\npost_pred = function(alpha, beta, y_star) {\n  return(beta^alpha / (beta+y_star)^(alpha+1))\n}\ny_star= seq(from = 0.01, to = 120, by =  .01)\nplot(y_star, post_pred(9, 390, y_star),xlab = 'y*', ylab ='f(y*|y)')",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Homework exponential data"
    ]
  },
  {
    "objectID": "C2-L08-Ex1.html",
    "href": "C2-L08-Ex1.html",
    "title": "",
    "section": "",
    "text": "2. Techniques and ModelsHW on ANOVA CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "2. Techniques and Models",
      "HW on ANOVA"
    ]
  },
  {
    "objectID": "C2-L08-Ex1.html#hw-on-anova",
    "href": "C2-L08-Ex1.html#hw-on-anova",
    "title": "",
    "section": "1 HW on ANOVA",
    "text": "1 HW on ANOVA\n\nExercise 1  Which of the following variables qualifies as a “factor” variable?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWeight of a patient reported in kilograms\nPre-treatment temperature reported in degrees Celsius\nPatient age in years\nTreatment with either an experimental drug or a control placebo\n\nThis is a categorical predictor.\n\n\n\n\nExercise 2  In an ANOVA model for a single factor with four levels, there are multiple ways we can parameterize our model for E(y). These include the cell means model or a linear model with a baseline mean and adjustments for different levels. Regardless of the model chosen, what is the maximum number of parameters we use to relate this factor with E(y) in a linear model and still be able to uniquely identify the parameters?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n4\nIf we use any more than four parameters to describe E(y), there will be infinitely many values of the parameters that produce a given E(y) for a given set of predictor values.\n\n\n\nQuestion 3\nFor Questions Exercise 3, refer to the plant growth analysis from the lesson.\nRe-fit the JAGS model on plant growth from the lesson with a separate variance for each of the three groups. To do so, modify the model code to index the precision in the normal likelihood by group, just as we did with the mean. Use the same priors as the original model (except in this case it will be three independent priors for the variances).\n\nExercise 3  Compare the estimates between the original lesson model and this model with the summary function. Notice that the posterior means for the three μ parameters are essentially unchanged. However, the posterior variability for these parameters has changed. The posterior for which group’s mean was most affected by fitting separate group variances?ANOVA\n\n\nCode\nlibrary(\"rjags\")\n\n\n\n\nCode\ndata(\"PlantGrowth\")  # load the data set\n#?PlantGrowth\nmod1_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[grp[i]], prec)\n    }\n    \n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n    }\n    \n    prec ~ dgamma(5/2.0, 5*1.0/2.0)\n    sig = sqrt( 1.0 / prec )\n} \"\n\nset.seed(82)\n#str(PlantGrowth)\ndata1_jags = list(y=PlantGrowth$weight, grp=as.numeric(PlantGrowth$group))\n\nparams = c(\"mu\", \"sig\")\n\ninits1 = function() {\n    inits = list(\"mu\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(1,1.0,1.0))\n}\n\nmod1 = jags.model(textConnection(mod1_string), data=data1_jags, inits=inits1, n.chains=3)\nupdate(mod1, 1e3)\n\nmod1_sim = coda.samples(model=mod1, variable.names=params, n.iter=5e3)\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim)) # combined chains\n\n\n\n\nCode\ndata(\"PlantGrowth\")  # load the data set\n\nmod2_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dnorm(mu[grp[i]], prec[grp[i]])\n    }\n    for (j in 1:3) {\n        mu[j] ~ dnorm(0.0, 1.0/1.0e6)\n        prec[j] ~ dgamma(5/2.0, 5*1.0/2.0)\n        sig[j] = sqrt( 1.0 / prec[j] )\n    }\n} \"\n\nset.seed(82)\ndata2_jags = list(y=PlantGrowth$weight, grp=as.numeric(PlantGrowth$group))\nparams = c(\"mu\", \"sig\")\ninits2 = function() {\n    inits = list(\"mu\"=rnorm(3,0.0,100.0), \"prec\"=rgamma(3,1.0,1.0))\n}\n\nmod2 = jags.model(textConnection(mod2_string), data=data2_jags, inits=inits2, n.chains=3)\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2, variable.names=params, n.iter=5e3)\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim)) # combined chains\n\n\n\n\nCode\nsummary(mod1_csim)\n\n\n\nIterations = 1:15000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 15000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nmu[1] 5.0330 0.22729 0.0018558      0.0018826\nmu[2] 4.6646 0.22762 0.0018585      0.0018585\nmu[3] 5.5255 0.22723 0.0018553      0.0018795\nsig   0.7125 0.09192 0.0007505      0.0008251\n\n2. Quantiles for each variable:\n\n        2.5%    25%    50%    75%  97.5%\nmu[1] 4.5800 4.8837 5.0325 5.1823 5.4795\nmu[2] 4.2224 4.5138 4.6622 4.8129 5.1180\nmu[3] 5.0821 5.3760 5.5236 5.6736 5.9796\nsig   0.5599 0.6474 0.7032 0.7676 0.9215\n\n\nCode\nsummary(mod2_csim)\n\n\n\nIterations = 1:15000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 15000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean     SD Naive SE Time-series SE\nmu[1]  5.0339 0.2620 0.002140       0.002067\nmu[2]  4.6652 0.2972 0.002427       0.002427\nmu[3]  5.5283 0.2354 0.001922       0.001922\nsig[1] 0.8039 0.1666 0.001360       0.001469\nsig[2] 0.9238 0.1926 0.001573       0.001689\nsig[3] 0.7341 0.1517 0.001239       0.001362\n\n2. Quantiles for each variable:\n\n         2.5%    25%    50%    75% 97.5%\nmu[1]  4.5092 4.8666 5.0383 5.1995 5.553\nmu[2]  4.0811 4.4729 4.6612 4.8554 5.256\nmu[3]  5.0566 5.3778 5.5290 5.6755 5.995\nsig[1] 0.5535 0.6861 0.7790 0.8927 1.208\nsig[2] 0.6386 0.7886 0.8905 1.0272 1.392\nsig[3] 0.5079 0.6276 0.7104 0.8154 1.096\n\n\nCompare the estimates between the original lesson model and this model with the summary function. Notice that the posterior means for the three μ parameters are essentially unchanged. However, the posterior variability for these parameters has changed. The posterior for which group’s mean was most affected by fitting separate group variances??\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nGroup 1: control\nGroup 2: treatment 1.\nGroup 3: treatment 2\nThe effect on the marginal posterior was the same for all three groups.\n\nSD of group 2 mean increased from 0.23035 to 0.2988 that a 0.07 change\nGroup 2 has the highest variation in plant weight, which results in less confidence in our posterior mean estimate. The posterior standard deviation of μ has increased the most for this group.\n\n\n\n\nExercise 4  Compute the deviance information criterion (DIC) for each of the two models and save the results as objects dic1 (for the original model) and dic2 (for the new model). Wha is the difference: DIC1 - DIC2?.ANOVA\nHint: You can compute this directly with the following code: dic1−dic2.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n(dic1 = dic.samples(mod1,1e5))\n\n\nMean deviance:  58.99 \npenalty 4.095 \nPenalized deviance: 63.08 \n\n\nCode\n(dic2 = dic.samples(mod2,1e5))\n\n\nMean deviance:  61.21 \npenalty 5.735 \nPenalized deviance: 66.94 \n\n\nCode\ndic1-dic2\n\n\nDifference: -3.858163\nSample standard error: 1.641612\n\n\n-3.892918\n\n\n\n\nExercise 5  Based on the DIC calculations for these competing models, what should we conclude?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe DIC is higher for the new model, indicating preference for the model with separate variances across groups.\nThe DIC is lower for the original model, indicating preference for the model with one common variance across groups.\nThe DIC is higher for the original model, indicating preference for the model with one common variance across groups.\nThe DIC is lower for the new model, indicating preference for the model with separate variances across groups.\n\nThis suggests we should stay with the original model (if our objective is good prediction).\n\n\n\n\nExercise 6  Use the original model (single variance) to calculate a 95% interval of highest posterior density (HPD) for \\mu_3−\\mu_1. Which of the following is closest to this interval?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n1q5 = as.mcmc( cbind(mod1_csim,mudif=mod1_csim[,3]-mod1_csim[,1]) )\n2summary((q5))\n\n\n\n1\n\nadd a parameter called mudiff by calculate \\mu_3-\\mu_1 for each sample\n\n2\n\nuse the summary to get quantiles and read 2.5% and 97.5% for mudiff\n\n\n\n\n\nIterations = 1:15000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 15000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean      SD  Naive SE Time-series SE\nmu[1] 5.0330 0.22729 0.0018558      0.0018826\nmu[2] 4.6646 0.22762 0.0018585      0.0018585\nmu[3] 5.5255 0.22723 0.0018553      0.0018795\nsig   0.7125 0.09192 0.0007505      0.0008251\nmudif 0.4925 0.32201 0.0026292      0.0026225\n\n2. Quantiles for each variable:\n\n         2.5%    25%    50%    75%  97.5%\nmu[1]  4.5800 4.8837 5.0325 5.1823 5.4795\nmu[2]  4.2224 4.5138 4.6622 4.8129 5.1180\nmu[3]  5.0821 5.3760 5.5236 5.6736 5.9796\nsig    0.5599 0.6474 0.7032 0.7676 0.9215\nmudif -0.1473 0.2828 0.4916 0.7038 1.1258\n\n\n\n(-0.20, 1.19)\n(-1.01, 0.25)\n(0.22, 1.49)\n(-0.14, 1.13)\n\nThe interval contains 0, indicating that the data lack strong (at least at the 95% level) evidence for \\mu_3\\ne\\mu_1. In the lesson, the posterior probability that \\mu_3&gt;\\mu_1 was 0.94.\n\n\n\n\nExercise 7  What is the correct interpretation of \\mu_3−\\mu_1 in the context of the plant growth analysis?ANOVA\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIt is the effect (change) of treatment 2 with respect to the control in mean plant weight.\nIt is the mean range of plant weight across the three treatment groups.\nIt is the difference in plant weight between treatment 2 and control.\nIt is the effect (change) of treatment 2 with respect to the control in plant weight.\n\nMCMC algs are based on a process guaranteeing convergence to a stationary distribution.\n\n\n\n\nExercise 8  The linear model with a baseline mean and group effects is the default in R. However, we can also fit the cell means model in R using the following code:ANOVA\n\n\nCode\nmod_cm = lm(weight ~ -1 + group, data=PlantGrowth)\nsummary(mod_cm)\n\n\n\nCall:\nlm(formula = weight ~ -1 + group, data = PlantGrowth)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4180 -0.0060  0.2627  1.3690 \n\nCoefficients:\n          Estimate Std. Error t value Pr(&gt;|t|)    \ngroupctrl   5.0320     0.1971   25.53   &lt;2e-16 ***\ngrouptrt1   4.6610     0.1971   23.64   &lt;2e-16 ***\ngrouptrt2   5.5260     0.1971   28.03   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6234 on 27 degrees of freedom\nMultiple R-squared:  0.9867,    Adjusted R-squared:  0.9852 \nF-statistic: 665.5 on 3 and 27 DF,  p-value: &lt; 2.2e-16\n\n\nwhere the −1 in the model formula tells R to drop the intercept. Because we used fairly noninformative priors for the μ parameters in the analysis with JAGS, the results are very similar.\nIn addition to allowing different prior specifications, what is one advantage of posterior sampling with JAGS over fitting the reference model in R?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWe can obtain posterior mode estimates for each mean (or coefficient).\nWe can obtain posterior standard deviations (standard errors) for each mean (or coefficient).\nWe can estimate the proportion of the variation in plant weight attributable to the treatment group assignment.\nWe can use the posterior samples to obtain simulated posterior distributions of any function of the parameters that may interest us (e.g., μ_3−μ_1).\n\nThe outer edges of the distribution are sampled less frequently and therefore susceptible to changes between simulations. The Raftery and Lewis diagnostic can help you decide how many iterations you need to reliably estimate outer quantiles of the target distribution..",
    "crumbs": [
      "2. Techniques and Models",
      "HW on ANOVA"
    ]
  },
  {
    "objectID": "C2-L06-Ex2.html",
    "href": "C2-L06-Ex2.html",
    "title": "",
    "section": "",
    "text": "2. Techniques and ModelsHonnors Homework on M-H algorithm CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "2. Techniques and Models",
      "Honnors Homework on M-H algorithm"
    ]
  },
  {
    "objectID": "C2-L06-Ex2.html#honnors-homework-on-m-h-algorithm",
    "href": "C2-L06-Ex2.html#honnors-homework-on-m-h-algorithm",
    "title": "",
    "section": "1 Honnors Homework on M-H algorithm",
    "text": "1 Honnors Homework on M-H algorithm\n For Questions Exercise 1 through Exercise 3, consider the following model for data that take on values between 0 and 1:M-H\n\nx_i \\mid \\alpha, \\beta \\overset{\\text{iid}}{\\sim} \\text{Beta}(\\alpha, \\beta) \\, , \\quad i = 1, \\ldots, n\\, , \\\\ \\alpha \\sim \\text{Gamma}(a, b) \\, , \\\\ \\beta \\sim \\text{Gamma}(r, s)\n\nwhere α and β are independent a-priori.\n\nExercise 1  Which of the following gives the full conditional density for α up to proportionality?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\np( \\alpha \\mid \\beta, x) \\propto \\frac{ \\Gamma(\\alpha + \\beta)^n }{ \\Gamma(\\alpha)^n } \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\alpha^{a-1} e^{-b\\alpha} I_{(0 &lt; \\alpha &lt; 1)}\np( \\alpha \\mid \\beta, x) \\propto \\frac{ \\Gamma(\\alpha + \\beta)^n }{ \\Gamma(\\alpha)^n } \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\alpha^{a-1} e^{-b\\alpha} I_{(\\alpha &gt; 0)}\np( \\alpha \\mid \\beta, x) \\propto \\frac{ \\Gamma(\\alpha + \\beta)^n }{ \\Gamma(\\alpha)^n \\Gamma(\\beta)^n } \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\left[ \\prod_{i=1}^n (1-x_i) \\right]^{\\beta - 1} \\alpha^{a-1} e^{-b\\alpha} \\beta^{r-1} e^{-s\\beta} I_{(0 &lt; \\alpha &lt; 1)} I_{(0 &lt; \\beta &lt; 1)}\np( \\alpha \\mid \\beta, x) \\propto \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha - 1} \\alpha^{a-1} e^{-b\\alpha} I_{(\\alpha &gt; 0)}\n\nWhen we treat the data x and β as known constants, the full joint distribution of all quantities x, α, and β is proportional to this expression when reinterpreted as a function of α.\nTo solve this one I had a couple of challenges:\n\nFirst I needed to understand what the full conditional means (I worked that out in the previous homework)\nNext that all the answers look like a likelihood times a prior\nNext I needed to remember that this requires reinterpreting the likelihood p(x\\mid\\alpha,\\beta) as p(\\alpha\\mid\\beta,x).\nFor the solution I multiplied the likelihood for \\text{Beta}(x|\\alpha,\\beta)^n with the prior \\text{Gamma}(\\alpha|a,b) then canceled any term in the product that did not have \\alpha. This was tricky since my reference for Gamma had x, \\alpha and \\beta and without substituting x=\\alpha, \\alpha=a and \\beta=b which is counter intuitive I got wrong answers.\nFinally I had to decide on two options for the indicator. The question talks about restricting the data to values from 0 to 1 but the Likelihood and prior allow values from \\mathbb{R}^+. I picked the latter since the restriction was for the data and not the parameters.\n\n\n\n\n\nExercise 2  Suppose we want posterior samples for α from the model in Exercise 1. What is our best option?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe full conditional for α is not proportional to any common probability distribution, and the marginal posterior for β is not any easier, so we will have to resort to a Metropolis-Hastings sampler.\nThe joint posterior for α and β is a common probability distribution which we can sample directly. Thus we can draw Monte Carlo samples for both parameters and keep the samples for α.\nThe full conditional for α is proportional to a common distribution which we can sample directly, so we can draw from that.\nThe full conditional for α is not a proper distribution (it doesn’t integrate to 1), so we cannot sample from it.\n\nAnother option is to approximate the posterior distribution for α by considering a set of discrete values such as 0.1,0.2, \\ldots, 0.9 etc. You could use a discrete uniform prior, or discrete prior probabilities proportional to the beta prior evaluated at these specific values. Either way, the full conditional distribution for α looks like the discrete version of Bayes’ theorem, which is easy to compute.\n\n\n\n\nExercise 3  If we elect to use a Metropolis-Hastings algorithm to draw posterior samples for α, the Metropolis-Hastings candidate acceptance ratio is computed using the full conditional for α asM-H\n\n\\frac{ \\Gamma(\\alpha)^n \\Gamma(\\alpha^*+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*} {\\alpha^*}^{a-1} e^{-b\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } {  \\Gamma(\\alpha^*)^n \\Gamma(\\alpha+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha} {\\alpha}^{a-1} e^{-b\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\nwhere α^∗ is a candidate value drawn from proposal distribution q(α^∗\\midα). Suppose that instead of the full conditional for α, we use the full joint posterior distribution of α and β and simply plug in the current (or known) value of β. What is the Metropolis-Hastings ratio in this case?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\frac{{\\alpha^*}^{a-1} e^{-b\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } { {\\alpha}^{a-1} e^{-b\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\\frac{ \\Gamma(\\alpha)^n \\Gamma(\\alpha^*+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*} {\\alpha^*}^{a-1} e^{-b\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } { \\Gamma(\\alpha^*)^n \\Gamma(\\alpha+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha} {\\alpha}^{a-1} e^{-b\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\\frac{ \\Gamma(\\alpha)^n \\Gamma(\\alpha^*+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*} q(\\alpha^* | \\alpha) I_{\\alpha^* &gt; 0} } { \\Gamma(\\alpha^*)^n \\Gamma(\\alpha+\\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha} q(\\alpha | \\alpha^*) I_{\\alpha &gt; 0} }\n\\frac{ \\Gamma(\\alpha^* + \\beta)^n \\left[ \\prod_{i=1}^n x_i \\right]^{\\alpha^*- 1} \\left[ \\prod_{i=1}^n (1-x_i) \\right]^{\\beta - 1} {\\alpha^*}^{a-1} e^{-b\\alpha^*} \\beta^{r-1} e^{-s\\beta} q(\\alpha | \\alpha^*) I_{(0 &lt; \\alpha^*)} I_{(0 &lt; \\beta )} }{ \\Gamma(\\alpha^*)^n \\Gamma(\\beta)^n q(\\alpha^* | \\alpha) }\n\nAll of the terms involving only β are identical in the numerator and denominator, and thus cancel out. The acceptance ratio is the same whether we use the full joint posterior or the full conditional in a Gibbs sampler.\n\n\n\nFor Questions 4 and 5, re-run the Metropolis-Hastings algorithm from Lesson 4 to draw posterior samples from the model for mean company personnel growth for six new companies: (-0.2, -1.5, -5.3, 0.3, -0.8, -2.2). Use the same prior as in the lesson.\n\n\nCode\n{library(\"rjags\")}\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\nCode\nlibrary(\"coda\")\n\nlg = function(mu, n, ybar) {\n  mu2 = mu^2\n  n * (ybar * mu - mu2 / 2.0) - log(1 + mu2)\n}\n\nmh = function(n, ybar, n_iter, mu_init, cand_sd) {\n  ## Random-Walk Metropolis-Hastings algorithm\n  \n  ## step 1, initialize\n  mu_out = numeric(n_iter)\n  accpt = 0\n  mu_now = mu_init\n  lg_now = lg(mu=mu_now, n=n, ybar=ybar)\n  \n  ## step 2, iterate\n  for (i in 1:n_iter) {\n    ## step 2a\n    mu_cand = rnorm(n=1, mean=mu_now, sd=cand_sd) # draw a candidate\n    \n    ## step 2b\n    lg_cand = lg(mu=mu_cand, n=n, ybar=ybar) # evaluate log of g with the candidate\n    lalpha = lg_cand - lg_now # log of acceptance ratio\n    alpha = exp(lalpha)\n    \n    ## step 2c\n    u = runif(1) # draw a uniform variable which will be less than alpha with probability min(1, alpha)\n    if (u &lt; alpha) { # then accept the candidate\n      mu_now = mu_cand\n      accpt = accpt + 1 # to keep track of acceptance\n      lg_now = lg_cand\n    }\n    \n    ## collect results\n    mu_out[i] = mu_now # save this iteration's value of mu\n  }\n  \n  ## return a list of output\n  list(mu=mu_out, accpt=accpt/n_iter)\n}\n\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nybar = mean(y)\nn = length(y)\n#hist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\n#curve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\n#points(y, rep(0,n), pch=1) # individual data points\n#points(ybar, 0, pch=19) # sample mean\n#set.seed(43) # set the random seed for reproducibility\n\n\n\n\nCode\nsds = c(0.5,1.5,3.0,4.0)\ny = c(-0.2, -1.5, -5.3, 0.3, -0.8, -2.2)\nybar = mean(y)\nn = length(y)\n\nfor (sd in sds){\n  post = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=sd)\n  #str(post)\n  #traceplot(as.mcmc(post$mu))\n  print(c(sd,\":\",post$accpt,'mu',\":\",mean(post$mu)))\n}\n\n\n[1] \"0.5\"               \":\"                 \"0.654\"            \n[4] \"mu\"                \":\"                 \"-1.49126394287704\"\n[1] \"1.5\"               \":\"                 \"0.316\"            \n[4] \"mu\"                \":\"                 \"-1.49090741085431\"\n[1] \"3\"                 \":\"                 \"0.156\"            \n[4] \"mu\"                \":\"                 \"-1.43986445517579\"\n[1] \"4\"                 \":\"                 \"0.141\"            \n[4] \"mu\"                \":\"                 \"-1.43066531942217\"\n\n\n\nExercise 4  Below are four possible values for the standard deviation of the normal proposal distribution in the algorithm. Which one yields the best sampling results?M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n0.5\n1.5\n3.0\n4.0\n\n\n\n\n\nExercise 5  Report the posterior mean point estimate for μ, the mean growth, using these six data points. Round your answer to two decimal places.M-H\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n-1.46\n\nThe sample mean of the six points is -1.62. Clearly the prior has some influence on this estimate.",
    "crumbs": [
      "2. Techniques and Models",
      "Honnors Homework on M-H algorithm"
    ]
  },
  {
    "objectID": "C1-L12.html",
    "href": "C1-L12.html",
    "title": "Brief Review of Regression",
    "section": "",
    "text": "Recall that linear regression is a model for predicting a response or dependent variable (Y, also called an output) from one or more covariates or independent variables (X, also called explanatory variables, inputs, or features). For a given value of a single x, the expected value of y is\n\\mathbb{E}[y] = \\beta_0 + \\beta_1x\nor we could say that\nY \\sim \\mathcal{N}(\\beta_0 + \\beta_1x, \\sigma^2)\nFor data (x_1, y_1), \\dots , (x_n, y_n), the fitted values for the coefficients, \\hat{\\beta_0} and \\hat{\\beta_1} are those that minimize the sum of squared errors \\sum_{i = 1}^n{(y_i - \\hat{y_i})^2}, where the predicted values for the response are \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x. We can get these values from R. These fitted coefficients give the least-squares line for the data.\nThis model extends to multiple covariates, with one \\beta_j for each k covariates\n\\mathbb{E}[y_i] = \\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_kx_{ik}\nOptionally, we can represent the multivariate case using vector-matrix notation.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Brief Review of Regression"
    ]
  },
  {
    "objectID": "C1-L12.html#conjugate-modeling",
    "href": "C1-L12.html#conjugate-modeling",
    "title": "Brief Review of Regression",
    "section": "1 Conjugate Modeling",
    "text": "1 Conjugate Modeling\nIn the Bayesian framework, we treat the \\beta parameters as unknown, put a prior on them, and then find the posterior. We might treat \\sigma^2 as fixed and known, or we might treat it as an unknown and also put a prior on it. Because the underlying assumption of a regression model is that the errors are independent and identically normally distributed with mean 0 and variance \\sigma^2, this defines a normal likelihood.\n\n1.1 \\sigma^2 known\nSometimes we may know the value of the error variance \\sigma^2 . This simplifies calculations. The conjugate prior for the \\beta is a normal prior. In practice, people typically use a non-informative prior, i.e., the limit as the variance of the normal prior goes to infinity, which has the same mean as the standard least-squares estimates. If we are only estimating \\beta and treating \\sigma^2 as known, then the posterior for \\beta is a (multivariate) normal distribution. If we just have a single covariate, then the posterior for the slope is:\n\n\\beta_1 \\mid y \\sim N\\left(\\frac{\\sum_{i = 1}^n{(x_i-\\bar{x})(y_i - \\bar{y})}}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}, \\frac{\\sigma^2}{\\sum_{i=1}^n{(x_i - \\bar{x})^2}}\\right)\n\nIf we have multiple covariates, then using a matrix-vector notation, the posterior for the vector of coefficients is \n\\beta \\mid y \\sim N((X^tX)^{-1}X^ty, (X^tX)^{-1}\\sigma^2)\n\nwhere X denotes the design matrix and X^t is the transpose of X. The intercept is typically included in X as a column of 1’s. Using an improper prior requires us to have at least as many data points as we have parameters to ensure that the posterior is proper.\n\n\n1.2 \\sigma^2 Unknown\nIf we treat both \\beta and \\sigma^2 as unknown, the standard prior is the non-informative Jeffreys prior, f(\\beta, \\sigma^2) \\propto \\frac{1}{\\sigma^2} . Again, the posterior mean for \\beta will be the same as the standard least-squares estimates. The posterior for \\beta conditional on \\sigma^2 is the same normal distributions as when \\sigma^2 is known, but the marginal posterior distribution for \\beta, with \\sigma^2 integrated out is a t distribution, analogous to the t tests for significance in standard linear regression. The posterior t distribution has mean (X^tX)^{-1}X^ty and scale matrix (related to the variance matrix) s^2(X^tX)^{-1} , where s^2 = \\sum_{i = 1}^n{(y_i - \\hat{y_i})^2/(n - k - 1)} . The posterior distribution for \\sigma^2 is an inverse gamma distribution\n\n\\sigma^2 | y \\sim \\Gamma^{-1}(\\frac{n - k - 1}{2}, \\frac{n - k - 1}{2}s^2)\n\nIn the simple linear regression case (single variable), the marginal posterior for \\beta is a t distribution with mean \\frac{\\sum_{i = 1}^n{(x_i-\\bar{x})(y_i - \\bar{y})}}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}} and scale \\frac{s^2}{\\sum_{i=1}^n{(x_i - \\bar{x})^2}} . If we are trying to predict a new observation at a specified input x^* , that predicted value has a marginal posterior predictive distribution that is a t distribution, with mean \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x^* and scale se_r\\sqrt{1 + \\frac{1}{n} + \\frac{(x^* - \\bar{x})^2}{(n - 1)s_x^2}} . se_r is the residual standard error of the regression, which can be found easily in R. s_x^2 is the sample variance of x. Recall that the predictive distribution for a new observation has more variability than the posterior distribution for \\hat{y}, because individual observations are more variable than the mean.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Brief Review of Regression"
    ]
  },
  {
    "objectID": "C1-L12.html#linear-regression",
    "href": "C1-L12.html#linear-regression",
    "title": "Brief Review of Regression",
    "section": "2 Linear Regression",
    "text": "2 Linear Regression\n\n2.1 Single Variable Regression\nWe’ll be looking at the Challenger dataset. It contains 23 past launches where it has the temperature at the day of launch and the O-ring damage index\nChallenger dataset\nRead in the data https://pdixon.stat.iastate.edu/stat511/datasets/challenger2.txt\n\n\nCode\noring=read.table(\"data/challanger.txt\", header=T)\n# Note that attaching this masks T which is originally TRUE\nattach(oring)\n\n\n\n\nCode\nhead(oring)\n\n\n   t  i\n1 53 11\n2 57  4\n3 58  4\n4 63  2\n5 66  0\n6 67  0\n\n\nNow we’ll see the plot\n\n\nCode\nplot(t,i)\n\n\n\n\n\n\n\n\n\nFit a linear model\n\n\nCode\noring.lm = lm(i ~ t)\nsummary(oring.lm)\n\n\n\nCall:\nlm(formula = i ~ t)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3025 -1.4507 -0.4928  0.7397  5.5337 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 18.36508    4.43859   4.138 0.000468 ***\nt           -0.24337    0.06349  -3.833 0.000968 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.102 on 21 degrees of freedom\nMultiple R-squared:  0.4116,    Adjusted R-squared:  0.3836 \nF-statistic: 14.69 on 1 and 21 DF,  p-value: 0.0009677\n\n\nAdd the fitted line into the scatter plot\n\n\nCode\nplot(t,i)\nlines(t,fitted(oring.lm))     \n\n\n\n\n\n\n\n\n\nCreate a 95% posterior interval for the slope\n\n\nCode\n-0.24337 - 0.06349*qt(.975,21)\n\n\n[1] -0.3754047\n\n\n\n\nCode\n-0.24337 + 0.06349*qt(.975,21)\n\n\n[1] -0.1113353\n\n\nNote: These are the same as the frequentist confidence intervals\nIf the challenger launch was at 31 degrees Fahrenheit, how much O-Ring damage would we predict?\n\n\nCode\ncoef(oring.lm)[1] + coef(oring.lm)[2]*31  \n\n\n(Intercept) \n   10.82052 \n\n\nCode\n# [1] 10.82052 \n\n\nLet’s make our posterior prediction interval\n\n\nCode\npredict(oring.lm,data.frame(t=31),interval=\"predict\")\n\n\n       fit      lwr      upr\n1 10.82052 4.048269 17.59276\n\n\nWe can calculate the lower bound through the following formula\n\n\nCode\n10.82052-2.102*qt(.975,21)*sqrt(1+1/23+((31-mean(T))^2/22/var(t)))\n\n\n[1] 4.850937\n\n\nWhat’s the posterior probability that the damage index is greater than zero?\n\n\nCode\n1-pt((0-10.82052)/(2.102*sqrt(1+1/23+((31-mean(T))^2/22/var(T)))),21)\n\n\n[1] NA\n\n\n\n\n2.2 Multivariate Regression\nWe’re looking at Galton’s seminal data predicting the height of children from the height of the parents.\n\n\n  Family Father Mother Gender Height Kids\n1      1   78.5   67.0      M   73.2    4\n2      1   78.5   67.0      F   69.2    4\n3      1   78.5   67.0      F   69.0    4\n4      1   78.5   67.0      F   69.0    4\n5      2   75.5   66.5      M   73.5    4\n6      2   75.5   66.5      M   72.5    4\n7      2   75.5   66.5      F   65.5    4\n8      2   75.5   66.5      F   65.5    4\n\n\nWhat are the columns in the dataset?\n\n\nCode\nnames(heights)\n\n\n[1] \"Family\" \"Father\" \"Mother\" \"Gender\" \"Height\" \"Kids\"  \n\n\nCode\n# [1] \"Family\" \"Father\" \"Mother\" \"Gender\" \"Height\" \"Kids\"  \n\n\nexplanation of the columns:\n\nFamily: the family the child is from\nFather: height of the father\nMother: height of the mother\nKids: count of children in the family\nGender: the gender of the child\nHeight: the height the child\n\nThe Height is out target variables.\nLet’s look at the relationship between the different variables\n\n\nCode\npairs(heights)\n\n\n\n\n\n\n\n\n\nPair plots are a great tool for doing EDA in R. You need to get used read them.\nWe care primarily about the Height so we can should first consider the row of the height. The other rows can inform us if there is a relation between other variables.\n\nthe Father and Mother are correlated with height.\nGender male children are generally taller.\nKids and Family don’t seem to have a clear pattern.\n\nFirst let’s start by creating a linear model taking all of the columns into account\n\n\nCode\nsummary(lm(Height~Father+Mother+Gender+Kids))\n\n\n\nCall:\nlm(formula = Height ~ Father + Mother + Gender + Kids)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.4748 -1.4500  0.0889  1.4716  9.1656 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.18771    2.79387   5.794 9.52e-09 ***\nFather       0.39831    0.02957  13.472  &lt; 2e-16 ***\nMother       0.32096    0.03126  10.269  &lt; 2e-16 ***\nGenderM      5.20995    0.14422  36.125  &lt; 2e-16 ***\nKids        -0.04382    0.02718  -1.612    0.107    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.152 on 893 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6391 \nF-statistic: 398.1 on 4 and 893 DF,  p-value: &lt; 2.2e-16\n\n\nAs you can see here, the Kids column is not statistically significant. Let’s look at a model with it removed.\n\n\nCode\nheights.lm=lm(Height~Father+Mother+Gender)\nsummary(heights.lm)\n\n\n\nCall:\nlm(formula = Height ~ Father + Mother + Gender)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.523 -1.440  0.117  1.473  9.114 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 15.34476    2.74696   5.586 3.08e-08 ***\nFather       0.40598    0.02921  13.900  &lt; 2e-16 ***\nMother       0.32150    0.03128  10.277  &lt; 2e-16 ***\nGenderM      5.22595    0.14401  36.289  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.154 on 894 degrees of freedom\nMultiple R-squared:  0.6397,    Adjusted R-squared:  0.6385 \nF-statistic:   529 on 3 and 894 DF,  p-value: &lt; 2.2e-16\n\n\nThis model looks good. We can tell from the summary that:\n\neach extra inch of the father’s height contributes an extra 0.4 inches height of the child.\neach extra inch of the mother’s height contributes an extra 0.3 inches height of the child.\nmale gender contributes 5.2 inches to the height of the child.\n\nLet’s create a 95% posterior interval for the difference in height by gender\n\n\nCode\n5.226 - 0.144 * qt(.975,894)\n\n\n[1] 4.943383\n\n\n\n\nCode\n5.226 + 0.144 * qt(.975,894)\n\n\n[1] 5.508617\n\n\nLet’s make a posterior prediction interval for a male and female with a father whose 68 inches and a mother whose 64 inches.\n\n\nCode\npredict(heights.lm,data.frame(Father=68,Mother=64,Gender=\"M\"), interval=\"predict\")\n\n\n       fit      lwr     upr\n1 68.75291 64.51971 72.9861\n\n\n\n\nCode\npredict(heights.lm,data.frame(Father=68,Mother=64,Gender=\"F\"), interval=\"predict\")\n\n\n       fit      lwr      upr\n1 63.52695 59.29329 67.76062",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Brief Review of Regression"
    ]
  },
  {
    "objectID": "C3-L02-Ex2.html",
    "href": "C3-L02-Ex2.html",
    "title": "The EM algorithm for Mixture Models",
    "section": "",
    "text": "NoteInstructions\n\n\n\nData on the lifetime (in years) of fuses produced by the ACME Corporation is available in the file fuses.csv:\nIn order to characterize the distribution of the lifetimes, it seems reasonable to fit to the data a two-component mixture of the form:\n\nf(x)=wλexp{−λx}+(1−w) \\frac{1}{\\sqrt{2\\pi}\\tau x} \\exp{− \\frac{(log(x)−μ)^{2}}{2τ^{2}}}, \\quad x &gt; 0.\n\\tag{1}\nwhere w is the weight associated with the exponential distribution, \\lambda is the rate of the exponential distribution, and \\text{LN}(\\mu, \\tau) is a log-normal distribution with mean \\mu and standard deviation \\tau.\n\nModify code to Generate n observations from a mixture of two Gaussian # distributions into code to sample 100 random numbers from a mixture of 4 exponential distributions with means 1, 4, 7 and 10 and weights 0.3, 0.25, 0.25 and 0.2, respectively.\nUse these sample to approximate the mean and variance of the mixture.\n\n\n\n\n\nCode\n## Clear the environment and load required libraries\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\n# Load the data\nfuses &lt;- read.csv(\"data/fuses.csv\",header=FALSE)\nx &lt;- fuses$V1\nn &lt;- length(x) # Number of observations\n\n# how many rows in the data\nnrow(fuses)\n\n\n[1] 400\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 0\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, freq=FALSE, xlab=\"Fuses\", ylab=\"Density\", main=\"Empirical distribution of fuses failure times\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nKK = 2                             # Number of components\nw     = 0.05                        # Assign equal weight to each component to start with\n#mu = rnorm(1,mean(log(x)), sd(log(x)))\nmu = mean(log(x))\ntau = sd(log(x))\nlambda = 20 / mean(x)\n\ns  = 0              # s_tep counter\nsw = FALSE          # sw_itch to stop the algorithm\nQQ = -Inf           # the Q function (log-likelihood function)\nQQ.out = NULL       # the Q function values\nepsilon = 10^(-5)   # the stopping criterion for the algorithm\n\ntrace &lt;- data.frame(iter=0, w=w, lambda=lambda, mu=mu, tau=tau)\n\nwhile(!sw){ ##Checking convergence\n\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(i in 1:n){\n    v[i,1] = log(w)   + dexp(x[i], rate=lambda, log=TRUE)\n    v[i,2] = log(1-w) + dlnorm(x[i], mu, tau, log=TRUE)    \n    v[i,]  = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,]))) \n  }\n\n  ## M step  \n  w      = mean(v[,1])  # Weights\n  lambda = sum(v[,1]) / sum(v[,1] * x)  # Lambda (rate)\n  mu     = sum(v[,2] * log(x)) / sum(v[,2]) # Mean\n  tau    = sqrt(sum(v[,2] * (log(x) - mu)^2) / sum(v[,2])) # Tau (standard deviation)\n  \n  # collect trace of parameters \n  trace  =  rbind(trace, data.frame(iter=s, w=w, lambda=lambda, mu=mu, tau=tau))\n\n  ## Check convergence\n  QQn = 0\n  #vectorized version\n  log_lik_mat = v[,1]*(log(w)   + dexp(x, lambda, log=TRUE)) +\n                v[,2]*(log(1-w) + dlnorm(x, mu, tau, log=TRUE))\n  QQn = sum(log_lik_mat)\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n}\n\n\n[1] \"1 -621.636631915928\"\n[1] \"2 -576.564676680329\"\n[1] \"3 -562.326030957339\"\n[1] \"4 -558.240693010161\"\n[1] \"5 -559.062812699431\"\n[1] \"6 -560.433982999852\"\n[1] \"7 -561.504096778213\"\n[1] \"8 -562.257984979008\"\n[1] \"9 -562.779349634224\"\n[1] \"10 -563.139561270939\"\n[1] \"11 -563.389080841182\"\n[1] \"12 -563.562415697134\"\n[1] \"13 -563.683109594057\"\n[1] \"14 -563.767298770739\"\n[1] \"15 -563.826100698272\"\n[1] \"16 -563.867209281663\"\n[1] \"17 -563.895967519019\"\n[1] \"18 -563.916095326952\"\n[1] \"19 -563.930187401928\"\n[1] \"20 -563.94005598844\"\n[1] \"21 -563.946968029888\"\n[1] \"22 -563.951809840896\"\n\n\nnext report the MLE parameters of the model.\n\n\nCode\n# Report the MLE parameters\ncat(\"w =\", round(w, 2), \"lambda =\", round(lambda, 2), \"mu =\", round(mu, 2),\"tau =\", round(tau, 2))\n\n\nw = 0.09 lambda = 3.05 mu = 0.78 tau = 0.38",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for Mixture Models"
    ]
  },
  {
    "objectID": "C3-L02-Ex2.html#infer-parameter-of-mixture-of-exponential-and-long-normal-for-lifetime-of-fuses",
    "href": "C3-L02-Ex2.html#infer-parameter-of-mixture-of-exponential-and-long-normal-for-lifetime-of-fuses",
    "title": "The EM algorithm for Mixture Models",
    "section": "",
    "text": "NoteInstructions\n\n\n\nData on the lifetime (in years) of fuses produced by the ACME Corporation is available in the file fuses.csv:\nIn order to characterize the distribution of the lifetimes, it seems reasonable to fit to the data a two-component mixture of the form:\n\nf(x)=wλexp{−λx}+(1−w) \\frac{1}{\\sqrt{2\\pi}\\tau x} \\exp{− \\frac{(log(x)−μ)^{2}}{2τ^{2}}}, \\quad x &gt; 0.\n\\tag{1}\nwhere w is the weight associated with the exponential distribution, \\lambda is the rate of the exponential distribution, and \\text{LN}(\\mu, \\tau) is a log-normal distribution with mean \\mu and standard deviation \\tau.\n\nModify code to Generate n observations from a mixture of two Gaussian # distributions into code to sample 100 random numbers from a mixture of 4 exponential distributions with means 1, 4, 7 and 10 and weights 0.3, 0.25, 0.25 and 0.2, respectively.\nUse these sample to approximate the mean and variance of the mixture.\n\n\n\n\n\nCode\n## Clear the environment and load required libraries\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\n# Load the data\nfuses &lt;- read.csv(\"data/fuses.csv\",header=FALSE)\nx &lt;- fuses$V1\nn &lt;- length(x) # Number of observations\n\n# how many rows in the data\nnrow(fuses)\n\n\n[1] 400\n\n\nCode\n# how many zeros in x\nsum(x==0)\n\n\n[1] 0\n\n\nCode\n# almost half of the data is zeros!\n\npar(mfrow=c(1,1))\nxx.true = seq(0, max(x), by=1)\nhist(x, freq=FALSE, xlab=\"Fuses\", ylab=\"Density\", main=\"Empirical distribution of fuses failure times\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nKK = 2                             # Number of components\nw     = 0.05                        # Assign equal weight to each component to start with\n#mu = rnorm(1,mean(log(x)), sd(log(x)))\nmu = mean(log(x))\ntau = sd(log(x))\nlambda = 20 / mean(x)\n\ns  = 0              # s_tep counter\nsw = FALSE          # sw_itch to stop the algorithm\nQQ = -Inf           # the Q function (log-likelihood function)\nQQ.out = NULL       # the Q function values\nepsilon = 10^(-5)   # the stopping criterion for the algorithm\n\ntrace &lt;- data.frame(iter=0, w=w, lambda=lambda, mu=mu, tau=tau)\n\nwhile(!sw){ ##Checking convergence\n\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(i in 1:n){\n    v[i,1] = log(w)   + dexp(x[i], rate=lambda, log=TRUE)\n    v[i,2] = log(1-w) + dlnorm(x[i], mu, tau, log=TRUE)    \n    v[i,]  = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,]))) \n  }\n\n  ## M step  \n  w      = mean(v[,1])  # Weights\n  lambda = sum(v[,1]) / sum(v[,1] * x)  # Lambda (rate)\n  mu     = sum(v[,2] * log(x)) / sum(v[,2]) # Mean\n  tau    = sqrt(sum(v[,2] * (log(x) - mu)^2) / sum(v[,2])) # Tau (standard deviation)\n  \n  # collect trace of parameters \n  trace  =  rbind(trace, data.frame(iter=s, w=w, lambda=lambda, mu=mu, tau=tau))\n\n  ## Check convergence\n  QQn = 0\n  #vectorized version\n  log_lik_mat = v[,1]*(log(w)   + dexp(x, lambda, log=TRUE)) +\n                v[,2]*(log(1-w) + dlnorm(x, mu, tau, log=TRUE))\n  QQn = sum(log_lik_mat)\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n}\n\n\n[1] \"1 -621.636631915928\"\n[1] \"2 -576.564676680329\"\n[1] \"3 -562.326030957339\"\n[1] \"4 -558.240693010161\"\n[1] \"5 -559.062812699431\"\n[1] \"6 -560.433982999852\"\n[1] \"7 -561.504096778213\"\n[1] \"8 -562.257984979008\"\n[1] \"9 -562.779349634224\"\n[1] \"10 -563.139561270939\"\n[1] \"11 -563.389080841182\"\n[1] \"12 -563.562415697134\"\n[1] \"13 -563.683109594057\"\n[1] \"14 -563.767298770739\"\n[1] \"15 -563.826100698272\"\n[1] \"16 -563.867209281663\"\n[1] \"17 -563.895967519019\"\n[1] \"18 -563.916095326952\"\n[1] \"19 -563.930187401928\"\n[1] \"20 -563.94005598844\"\n[1] \"21 -563.946968029888\"\n[1] \"22 -563.951809840896\"\n\n\nnext report the MLE parameters of the model.\n\n\nCode\n# Report the MLE parameters\ncat(\"w =\", round(w, 2), \"lambda =\", round(lambda, 2), \"mu =\", round(mu, 2),\"tau =\", round(tau, 2))\n\n\nw = 0.09 lambda = 3.05 mu = 0.78 tau = 0.38",
    "crumbs": [
      "3. Mixture Models",
      "The EM algorithm for Mixture Models"
    ]
  },
  {
    "objectID": "C2-L09.html",
    "href": "C2-L09.html",
    "title": "Logistic regression",
    "section": "",
    "text": "Logistic regression is the preferred model when modelling a problem where the response variable is binary such as a classification or the outcome of a Bernoulli trial. In such the traditional least square fit suffers from a number of shortcomings. The main idea here is a log transform. However a naive approach this transform imposes issues with 0 valued inputs since log(0)=-\\infty",
    "crumbs": [
      "2. Techniques and Models",
      "Logistic regression"
    ]
  },
  {
    "objectID": "C2-L09.html#introduction-to-logistic-regression",
    "href": "C2-L09.html#introduction-to-logistic-regression",
    "title": "Logistic regression",
    "section": "1 Introduction to Logistic Regression",
    "text": "1 Introduction to Logistic Regression\n\n\n\n\n\n\n\nFigure 1: Introduction to logistic regression\n\n\n\n1.1 Data\nFor an example of logistic regression  , we’ll use the urine data set from the boot package in R. The response variable is r, which takes on values of 0 or 1. We will remove some rows from the data set which contain missing values.logistic regression\n\n\nCode\nlibrary(\"boot\")\ndata(\"urine\")\n?urine\nhead(urine)\n\n\n  r gravity   ph osmo cond urea calc\n1 0   1.021 4.91  725   NA  443 2.45\n2 0   1.017 5.74  577 20.0  296 4.49\n3 0   1.008 7.20  321 14.9  101 2.36\n4 0   1.011 5.51  408 12.6  224 2.15\n5 0   1.005 6.52  187  7.5   91 1.16\n6 0   1.020 5.27  668 25.3  252 3.34\n\n\n\n\nCode\n1dat = na.omit(urine)\n\n\n\n1\n\ndrop missing values\n\n\n\n\nLet’s look at pairwise scatter plots of the seven variables.\n\n\nCode\npairs(dat)\n\n\n\n\n\n\n\n\n\nOne thing that stands out is that several of these variables are strongly correlated with one another. For example gravity and osmo appear to have a very close linear relationship. Collinearity between x variables in linear regression models can cause trouble for statistical inference. Two correlated variables will compete for the ability to predict the response variable, leading to unstable estimates. This is not a problem for prediction of the response, if prediction is the end goal of the model. But if our objective is to discover how the variables relate to the response, we should avoid collinearity.\n\n\n\n\n\n\nImportantCollinearity and Multicollinearity\n\n\n\n When two covariates are highly correlated we call this relation collinearity. When one covariate in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy we call this relation multicollinearity. It is possible that no two pairs of a such a group of covariates are correlated.\nIn both cases this will lead to the design matrix being almost singular. Near singular matrices are a strong cause of instability in numerical calculations. Statistical this tends to lead to a model with inflated standard errors compared to models where we only keep the a subset where variables are neither collinear nor multicollinear. A consequence of this is that we will see a drop in statistical significance for these variables, which will make interpreting the model harder.\nWe have seen a few strategies ways to deal with these issues:\n\ninclude pair plot in the exploratory data analysis phase.\npicking subsets and checking DIC or,\nvariable selection using double exponential priors.\nPCA creates independent covariates with a lower dimension with a trade of losing interpretability. See (Johnson and Wichern 2001, 386) (Belsley, Kuh, and Welsch 1980, 85–191) (Härdle and Simar 2019)\nFeature elimination based on combination of Variance inflation factors (VIF) (Sheather 2009, 203)\n\n\n\nWe can more formally estimate the correlation among these variables using the corrplot package.\n\n\nCode\nlibrary(\"corrplot\")\n\n\ncorrplot 0.95 loaded\n\n\nCode\nCor = cor(dat)\ncorrplot(Cor, type=\"upper\", method=\"ellipse\", tl.pos=\"d\")\ncorrplot(Cor, type=\"lower\", method=\"number\", col=\"black\", \n         add=TRUE, diag=FALSE, tl.pos=\"n\", cl.pos=\"n\")\n\n\n\n\n\n\n\n\n\n\n\n1.2 Variable selection\nOne primary goal of this analysis is to find out which variables are related to the presence of calcium oxalate crystals. This objective is often called “variable selection.” We have already seen one way to do this: fit several models that include different sets of variables and see which one has the best DIC. Another way to do this is to use a linear model where the priors for the \\beta coefficients favor values near 0 (indicating a weak relationship). This way, the burden of establishing association lies with the data. If there is not a strong signal, we assume it doesn’t exist.\nRather than tailoring a prior for each individual \\beta based on the scale its covariate takes values on, it is customary to subtract the mean and divide by the standard deviation for each variable.\n\n\nCode\nX = scale(dat[,-1], center=TRUE, scale=TRUE)\nhead(X[,\"gravity\"])\n\n\n         2          3          4          5          6          7 \n-0.1403037 -1.3710690 -0.9608139 -1.7813240  0.2699514 -0.8240622 \n\n\n\n\nCode\ncolMeans(X)\n\n\n      gravity            ph          osmo          cond          urea \n-9.861143e-15  8.511409e-17  1.515743e-16 -1.829852e-16  7.335402e-17 \n         calc \n-1.689666e-18 \n\n\n\n\nCode\napply(X, 2, sd)\n\n\ngravity      ph    osmo    cond    urea    calc \n      1       1       1       1       1       1 \n\n\n\n\n1.3 Model\nOur prior for the \\beta (which we’ll call b in the model) coefficients will be the double exponential (or Laplace) distribution, which as the name implies, is the exponential distribution with tails extending in the positive direction as well as the negative direction, with a sharp peak at 0. We can read more about it in the JAGS manual. The distribution looks like:\n\n\nCode\nddexp = function(x, mu, tau) {\n  0.5*tau*exp(-tau*abs(x-mu)) \n}\ncurve(ddexp(x, mu=0.0, tau=1.0), from=-5.0, to=5.0, ylab=\"density\", main=\"Double exponential\\ndistribution\") # double exponential distribution\ncurve(dnorm(x, mean=0.0, sd=1.0), from=-5.0, to=5.0, lty=2, add=TRUE) # normal distribution\nlegend(\"topright\", legend=c(\"double exponential\", \"normal\"), lty=c(1,2), bty=\"n\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(\"rjags\")\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\n\n\nCode\nmod1_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = int + b[1]*gravity[i] + b[2]*ph[i] + b[3]*osmo[i] + b[4]*cond[i] + b[5]*urea[i] + b[6]*calc[i]\n    }\n    int ~ dnorm(0.0, 1.0/25.0)\n    for (j in 1:6) {\n        b[j] ~ ddexp(0.0, sqrt(2.0)) # has variance 1.0\n    }\n} \"\n\nset.seed(92)\nhead(X)\n\n\n     gravity         ph       osmo       cond        urea        calc\n2 -0.1403037 -0.4163725 -0.1528785 -0.1130908  0.25747827  0.09997564\n3 -1.3710690  1.6055972 -1.2218894 -0.7502609 -1.23693077 -0.54608444\n4 -0.9608139 -0.7349020 -0.8585927 -1.0376121 -0.29430353 -0.60978050\n5 -1.7813240  0.6638579 -1.7814497 -1.6747822 -1.31356713 -0.91006194\n6  0.2699514 -1.0672806  0.2271214  0.5490664 -0.07972172 -0.24883614\n7 -0.8240622 -0.5825618 -0.6372741 -0.4379226 -0.51654898 -0.83726644\n\n\nCode\ndata_jags = list(y=dat$r, gravity=X[,\"gravity\"], ph=X[,\"ph\"], osmo=X[,\"osmo\"], cond=X[,\"cond\"], urea=X[,\"urea\"], calc=X[,\"calc\"])\n\nparams = c(\"int\", \"b\")\n\nmod1 = jags.model(textConnection(mod1_string), data=data_jags, n.chains=3)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 77\n   Unobserved stochastic nodes: 7\n   Total graph size: 1085\n\nInitializing model\n\n\nCode\nupdate(mod1, 1e3)\n\nmod1_sim = coda.samples(model=mod1,\n                        variable.names=params,\n                        n.iter=5e3)\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim))\n\n## convergence diagnostics\npar(mar = c(2.5, 1, 2.5, 1))\nplot(mod1_sim, ask=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod1_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]          1       1.00\nb[2]          1       1.00\nb[3]          1       1.01\nb[4]          1       1.01\nb[5]          1       1.01\nb[6]          1       1.00\nint           1       1.00\n\nMultivariate psrf\n\n1.01\n\n\nCode\nautocorr.diag(mod1_sim)\n\n\n              b[1]          b[2]        b[3]       b[4]        b[5]       b[6]\nLag 0   1.00000000  1.0000000000  1.00000000 1.00000000  1.00000000 1.00000000\nLag 1   0.82605674  0.2625955268  0.89139874 0.74976394  0.79464709 0.47113096\nLag 5   0.40777453 -0.0089051309  0.55350468 0.33165286  0.37545022 0.04821104\nLag 10  0.17309601 -0.0097979181  0.30750806 0.16268177  0.17198034 0.01580716\nLag 50 -0.01911765  0.0003585035 -0.01030468 0.01025256 -0.01718429 0.01036221\n                int\nLag 0   1.000000000\nLag 1   0.273173131\nLag 5   0.026880869\nLag 10  0.004038664\nLag 50 -0.017714366\n\n\nCode\nautocorr.plot(mod1_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod1_sim)\n\n\n     b[1]      b[2]      b[3]      b[4]      b[5]      b[6]       int \n1348.3029 8911.5539  861.1515 1530.8348 1487.4498 4959.7345 7677.6320 \n\n\nCode\n## calculate DIC\ndic1 = dic.samples(mod1, n.iter=1e3)\n\n\nLet’s look at the results.\n\n\nCode\nsummary(mod1_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nb[1]  1.6348 0.7364 0.006013       0.020121\nb[2] -0.1399 0.2880 0.002352       0.003053\nb[3] -0.2798 0.7880 0.006434       0.026861\nb[4] -0.7574 0.4994 0.004077       0.012760\nb[5] -0.6060 0.5877 0.004798       0.015233\nb[6]  1.6143 0.4816 0.003932       0.006859\nint  -0.1781 0.3022 0.002468       0.003471\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%      75%  97.5%\nb[1]  0.3307  1.1232  1.5853  2.09582 3.2416\nb[2] -0.7410 -0.3233 -0.1247  0.04686 0.4112\nb[3] -2.0465 -0.7162 -0.2036  0.18645 1.2102\nb[4] -1.7725 -1.0901 -0.7442 -0.40249 0.1357\nb[5] -1.9120 -0.9641 -0.5447 -0.18078 0.3731\nb[6]  0.7366  1.2817  1.5862  1.92165 2.6298\nint  -0.7767 -0.3819 -0.1820  0.02238 0.4219\n\n\n\n\nCode\n#par(mfrow=c(3,2))\npar(mar = c(2.5, 1, 2.5, 1))\n\ndensplot(mod1_csim[,1:6], xlim=c(-3.0, 3.0))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncolnames(X) # variable names\n\n\n[1] \"gravity\" \"ph\"      \"osmo\"    \"cond\"    \"urea\"    \"calc\"   \n\n\nIt is clear that the coefficients for variables gravity, cond (conductivity), and calc (calcium concentration) are not 0. The posterior distribution for the coefficient of osmo (osmolarity) looks like the prior, and is almost centered on 0 still, so we’ll conclude that osmo is not a strong predictor of calcium oxalate crystals. The same goes for ph.\nurea (urea concentration) appears to be a borderline case. However, if we refer back to our correlations among the variables, we see that urea is highly correlated with gravity, so we opt to remove it.\nOur second model looks like this:\n\n\nCode\nmod2_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = int + b[1]*gravity[i] + b[2]*cond[i] + b[3]*calc[i]\n    }\n    int ~ dnorm(0.0, 1.0/25.0)\n    for (j in 1:3) {\n        b[j] ~ dnorm(0.0, 1.0/25.0) # noninformative for logistic regression\n    }\n} \"\n\nmod2 = jags.model(textConnection(mod2_string), data=data_jags, n.chains=3)\n\n\nWarning in jags.model(textConnection(mod2_string), data = data_jags, n.chains =\n3): Unused variable \"ph\" in data\n\n\nWarning in jags.model(textConnection(mod2_string), data = data_jags, n.chains =\n3): Unused variable \"osmo\" in data\n\n\nWarning in jags.model(textConnection(mod2_string), data = data_jags, n.chains =\n3): Unused variable \"urea\" in data\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 77\n   Unobserved stochastic nodes: 4\n   Total graph size: 635\n\nInitializing model\n\n\n\n\nCode\nupdate(mod2, 1e3)\n\nmod2_sim = coda.samples(model=mod2,\n                        variable.names=params,\n                        n.iter=5e3)\nmod2_csim = as.mcmc(do.call(rbind, mod2_sim))\n\npar(mar = c(2.5, 1, 2.5, 1))\n#plot(mod2_sim, ask=TRUE)\nplot(mod2_sim)\n\n\n\n\n\n\n\n\n\nCode\ngelman.diag(mod2_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]          1       1.00\nb[2]          1       1.01\nb[3]          1       1.00\nint           1       1.00\n\nMultivariate psrf\n\n1\n\n\nCode\nautocorr.diag(mod2_sim)\n\n\n               b[1]       b[2]         b[3]          int\nLag 0   1.000000000 1.00000000  1.000000000  1.000000000\nLag 1   0.574342087 0.66136347  0.511131107  0.256841447\nLag 5   0.100101622 0.13810988  0.067272304  0.007058659\nLag 10  0.007163367 0.03348653  0.017876510 -0.001930135\nLag 50 -0.001971459 0.01120583 -0.004284865  0.001979226\n\n\nCode\nautocorr.plot(mod2_sim)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(mod2_sim)\n\n\n    b[1]     b[2]     b[3]      int \n3713.539 2889.370 4348.545 8564.502 \n\n\nCode\ndic2 = dic.samples(mod2, n.iter=1e3)\n\n\n\n\n1.4 Results\n\n\nCode\ndic1\n\n\nMean deviance:  68.7 \npenalty 5.362 \nPenalized deviance: 74.07 \n\n\n\n\nCode\ndic2\n\n\nMean deviance:  71.07 \npenalty 3.882 \nPenalized deviance: 74.95 \n\n\n\n\nCode\nsummary(mod2_sim)\n\n\n\nIterations = 2001:7000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nb[1]  1.4063 0.5032 0.004109       0.008357\nb[2] -1.3392 0.4627 0.003778       0.008660\nb[3]  1.8687 0.5542 0.004525       0.008410\nint  -0.1459 0.3220 0.002629       0.003484\n\n2. Quantiles for each variable:\n\n        2.5%     25%     50%      75%   97.5%\nb[1]  0.4939  1.0555  1.3778  1.72882  2.4853\nb[2] -2.2915 -1.6327 -1.3178 -1.01811 -0.5018\nb[3]  0.8877  1.4848  1.8340  2.21408  3.0539\nint  -0.7776 -0.3598 -0.1491  0.06756  0.4884\n\n\n\n\nCode\nHPDinterval(mod2_csim)\n\n\n          lower      upper\nb[1]  0.4600391  2.4354197\nb[2] -2.2581658 -0.4739610\nb[3]  0.8244628  2.9701115\nint  -0.7597981  0.5037232\nattr(,\"Probability\")\n[1] 0.95\n\n\n\n\nCode\n#par(mfrow=c(3,1))\npar(mar = c(2.5, 1, 2.5, 1))\ndensplot(mod2_csim[,1:3], xlim=c(-3.0, 3.0))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncolnames(X)[c(1,4,6)] # variable names\n\n\n[1] \"gravity\" \"cond\"    \"calc\"   \n\n\nThe DIC is actually better for the first model. Note that we did change the prior between models, and generally we should not use the DIC to choose between priors. Hence comparing DIC between these two models may not be a fair comparison. Nevertheless, they both yield essentially the same conclusions. Higher values of gravity and calc (calcium concentration) are associated with higher probabilities of calcium oxalate crystals, while higher values of cond (conductivity) are associated with lower probabilities of calcium oxalate crystals.\nThere are more modeling options in this scenario, perhaps including transformations of variables, different priors, and interactions between the predictors, but we’ll leave it to you to see if you can improve the model.",
    "crumbs": [
      "2. Techniques and Models",
      "Logistic regression"
    ]
  },
  {
    "objectID": "C2-L01.html",
    "href": "C2-L01.html",
    "title": "Statistical Modeling and Monte Carlo estimation",
    "section": "",
    "text": "What are the objectives of statistical models?\nWhat can they accomplish and where do they fit in the broader field of data science?\n\nThis course is about statistical modelling which falls under the analyzing data objective.\n\nSo what is a statistical model?\nA statistical model will be a mathematical structure used to imitate, And approximate, the data generating process. It typically describes relationships among variables while accounting for uncertainty and variability in the data.\n\nFor what kinds of problems might we use a statistical model?\n\nQuantifying uncertainty:\n\nare relationships between variables we cannot measure?\nhow many peoeple were polled?\nhow were they chosen?\nhow would the data change if we repeated the poll.\n\nInference\n\nExtend the result and infer what percentage of the total population supports the candidate?\nWe may also have other demographic information about each person in the poll.\nA statistical model might allow us to see how these other variables relate to a person’s likelihood of supporting the candidate.\n\nMeasure support for hypothesis\n\nDoes the evidence support a hypothesis that the candidate is more popular with men than women?\n\nPrediction\n\nGiven demographic information on a voter we could use the model to predict her vote.\nAlso important for machine learning.",
    "crumbs": [
      "2. Techniques and Models",
      "Statistical Modeling and Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L01.html#objectives",
    "href": "C2-L01.html#objectives",
    "title": "Statistical Modeling and Monte Carlo estimation",
    "section": "",
    "text": "What are the objectives of statistical models?\nWhat can they accomplish and where do they fit in the broader field of data science?\n\nThis course is about statistical modelling which falls under the analyzing data objective.\n\nSo what is a statistical model?\nA statistical model will be a mathematical structure used to imitate, And approximate, the data generating process. It typically describes relationships among variables while accounting for uncertainty and variability in the data.\n\nFor what kinds of problems might we use a statistical model?\n\nQuantifying uncertainty:\n\nare relationships between variables we cannot measure?\nhow many peoeple were polled?\nhow were they chosen?\nhow would the data change if we repeated the poll.\n\nInference\n\nExtend the result and infer what percentage of the total population supports the candidate?\nWe may also have other demographic information about each person in the poll.\nA statistical model might allow us to see how these other variables relate to a person’s likelihood of supporting the candidate.\n\nMeasure support for hypothesis\n\nDoes the evidence support a hypothesis that the candidate is more popular with men than women?\n\nPrediction\n\nGiven demographic information on a voter we could use the model to predict her vote.\nAlso important for machine learning.",
    "crumbs": [
      "2. Techniques and Models",
      "Statistical Modeling and Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L01.html#a-poll-for-a-political-candidate",
    "href": "C2-L01.html#a-poll-for-a-political-candidate",
    "title": "Statistical Modeling and Monte Carlo estimation",
    "section": "2 A Poll for a political candidate",
    "text": "2 A Poll for a political candidate\n\n57% for a candidate\nthe 99% CI (51,63)\ndemographics:\n\n55% women\n63% men",
    "crumbs": [
      "2. Techniques and Models",
      "Statistical Modeling and Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L01.html#modeling-process",
    "href": "C2-L01.html#modeling-process",
    "title": "Statistical Modeling and Monte Carlo estimation",
    "section": "3 Modeling Process",
    "text": "3 Modeling Process\n Building statistical models is a process, and each step should be taken carefully. Here we outline the general process and offer some practical advice. We’ll call this the statistical modeling process.\n The first step in this process is to understand the problem. This may seem obvious, but understanding the problem and context is critical to success. A sophisticated model might be useless if it is applied inappropriately.understand the problem\n\nExample 1 (international stores) For example, suppose you have revenue data from several different locations of a store chain at unknown locations.\n\nIt seems reasonable to average these revenue numbers as a summary of how the store is doing.\nSuppose you discover that the stores are located in different countries and reported revenues in different currencies.\nNow that average doesn’t seem to have much meaning unless, of course, we get the revenue numbers converted to the same scale.\n\n\n The second step is to plan and properly collect relevant data. There may be multiple quantities that you could potentially measure to help answer your question. In this step, you decide what information will be most useful to solving your problem. How to collect the data and how many data points to collect. The quality of your data collection plan determines the value of your data.plan and collect data\n\nFor example, if you conduct a survey of peers in your workplace. Your results would likely not generalize to all workers in the company, especially if there are multiple work sites. If you want generalizable results, a better plan would be to select a random sample among all employees to participate in your survey.\n\nThe step is addressed in detail in most introductory statistics courses.\n The third step in this process is to explore your data. In this step, you should ensure that the data collection plan was followed. And that the data were recorded accurately. If there are major surprises in that data, verified that they are not errors. In this step, you’ll often want to visualize the data to gain a basic understanding of the relationships among your variables. This can help you decide what kinds of models might be appropriate. Finally, the practice of snooping around or mining your data, looking for interesting hypothesis to test can potentially invalidate your statistical modeling results. If you want to mine your data, and test your findings, it is usually best to randomly split your data into two parts. With one part, you can look for interesting things to test and fit different potential models. With the other, you can fit the model you chose using the first part to validate or see if the results can be replicated on other data.explore your data\n The fourth step in this process is to postulate a model. After gaining an understanding of how your data are structured, choose a model that can appropriately approximate or summarize the interesting content of the data. This might be an off the shelf statistical model like a regression or it could be based on a scientific theory such as a growth model. It could also be multiple models.postulate a model\nGenerally, it is desirable to find a model where the parameters we estimate can be interpreted in the context of the original problem. You might also have to strike a balance between model complexity, and model generalizability. This is often referred to as the bias variance trade-off. Large complex models, might be able to fit your particular dataset very well. But may fail to generalize to future data.\n\nExample 2 (overfitting) Let’s look at an example of this. Let’s suppose your data looked like  where x is your explanatory variable, y is your response variable. And you have points like these. One possible model you could fit would be just a linear regression going through the points.\nAnother possibility for model you could fit here would be essentially an interpolator that makes sure it goes through every single point. Now, consider a future scenario where you’ve got another dataset just like this one with a new cloud of points. You can imagine that perhaps this interpolated model, which fit the original dataset perfectly, might struggle on a future dataset.\n\n The fifth step in our statistical modeling process is to fit the model. In this step we need to estimate the parameters of the model using the data. In this particular class, we’re going to take a Bayesian approach to this step.fit the model\n The sixth step in our statistical modeling process is to check the model. Here we want to check to see if the model adequately imitates the data generating process. Are predictions from the model realistic? Does it fit well to your data? Or does it completely miss some of the features? We’ll look into some the techniques for doing this, including residual analysis and predictive checks later in the course. In this step, we may also compare a competing models according to some criteria.check the model\n The seventh step in our statistical modeling process is to iterate. That is, return, possibly, to steps 4 through 6. If the model you have already fit is, for some reason, inadequate, we should return to step 4 and proceed through step 6 again with a new, and hopefully better, model that would address or correct the deficiencies from your previous model.iterate\n The eighth and final step in our statistical modeling process is to use the model. If we’ve iterated through these enough times and decided that the model is good, or that we have selected an appropriate model, we can use the results to answer your original research questions and arrive at conclusions. In this course, we are going to focus on steps 4 through 8. But this does not mean steps 1 through 3 should be ignored in any analysis. In fact, the importance of steps 1 through 3 cannot be overstated. The validity of you final results depends on them. That is why most introductory statistics courses will emphasize these steps. If you’ll not explore this issues in an introductory statistics course, we highly recommend you do so. We hope you’ll refer to this outline, the statistical modeling process often as you begin modeling data.use the model\n\n3.1 Process outline:\n\nunderstand the problem.\nplan and collect data.\nexplore the data.\npostulate the model.\nfit the model.\ncheck the model.\niterate be going beck to step 4.\nuse the model.",
    "crumbs": [
      "2. Techniques and Models",
      "Statistical Modeling and Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C4-L06.html",
    "href": "C4-L06.html",
    "title": "Week 0: Feyman Notebook on Bayesian Time Series Analysis",
    "section": "",
    "text": "ImportantTS Questions — A Feynman Notebook\n\n\n\nHere is where I can collect questions about TS analysis that I have as I go through the course. Hopefully I will be better equipped to answer many of these them by the end of the course.\n\nHow is Bayesian TS analysis differ from regular TS analysis?\n\nIn the NDLM we supply a Prior.\nWe the use Bayesian updating to update the model with the data.\nWe maintian a distributional view with estimates of the error.\nWe also the use Bayesian updating and inference for Filtering, Smoothing.\n\nFourier analysis is a powerful tool for time series analysis. How does it relate to Bayesian time series analysis?\n\nWe can incorporate the outcomes to incorporate seasonal elements into an NDLM\n\nHow and what type of prior knowledge into time series analysis?\n\nIn (West and Harrison 2013) they authors discuss both is the actual prior.\nBut they aslo talk about supporting interventions. E.g. when a major competitor goes out of buisness.The model should be able to handle this information and they make a big issues of how we need to incorporate into the next time step both new expected demand as well as an estimate of its variance which give better estimates of required production.\n\nAre there models that are unique to Bayesian time series analysis?\n\nHard to say but DLM seem to be.\n\nHow does distributional thinking affect time series analysis?\n\nIt gives us confidence bounds on future estimates.\n\nHow do we represent uncertainty in Bayesian time series analysis?\n\nWe have distribution and we can derive for any point estimate a correspoing creadible interval.\nWe can use smoothing to try and reason about trend or seasonality seperately.\n\nWill we learn about Gaussian Processes/Neural Networks in this course?\n\nThis is a type of Bayesian Non-parametric and we don’t cover these in the specilization. However Abel Rodriguez, the instructor of the third couse on mixture model has a short course\nHerbert Lee wrote a Bayesian Nonparametrics via Neural Networks on the subject.\n\nWhat BTS models are most useful in economics and finance?\nIs there a cleanup procedure for time series data?\n\nUsing exponential smoothing\nUsing weighted avaraging going back and forward enough steps can smooth seasonal effects.\nMore generaly this is handled by smoothing\nGoing backwards this is can be done using filtering.\n\nIs there an Bayesian EDA for time series?\n\nwe can use differencing to make the time series stationary\nwe can use the ACF and PACF\nwe can decompose the time series into trend, seasonal, and residual components\nwe can visualize autocorrelation using a correlogram\nwe can visualize periodicity using a periodogram and spectral density.\nsee (Nielsen 2019)\n\nHow do we handle missing data in time series?\nHow do we handle non-stationary time series?\n\nBy applying differencing we can make the time series stationary.\n\nAre there processes for long term memory in time series?\n\nsee (Prado, Ferreira, and West 2023, 124)\nthe book also toches on EKF and MKF\n\nAre there processes for power laws.\n\n\nsee https://wiki.santafe.edu/images/5/52/Powerlaws.pdf\n\n\nCan BTS handle dynamic systems in time series?\nCan we model time series with multiple scales?\nWhat TS models are useful for regime switching?\n\nI recall this came up in Davidson-Pilon (2015)\nThis is also covered in module 3 of the course.\n\nHow can we simulate time series data?\nHow can we forecast time series data?\nHow can we find periodicity in time series data?\nIs the Kalman Filter a state-space or dynamic linear model\n\nsee (Prado, Ferreira, and West 2023, 141)\nthe book also toches on EKF and MKF\n\nParticle filters AKA Sequential Monte Carlo methods in the book.\n\nsee (Prado, Ferreira, and West 2023, 205)\n\nAre there Bayesian time series models of contagion?\nAre there Bayesian time series models of epidemics?\nWhat are Seasonal adjustments?\nHow to do a seasonal adjustment?\nWhat are the tools for wrangling and cleaning TS data.\n\nData Engineering using Wrangling and Cleaning c.f. (Woodward, Sadler, and Robertson 2022, sec. 1.4.1.3)\n\nHow to use the frequency domain as a key part of understanding and analyzing data?\nHow to assess whether an existing trend should be predicted to continue or whether caution should be used in forecasts?\nDo you really understand AR models or are they just a black box?\nWhat is a unit root?\nHow to use tools that would help you decide whether to use a seasonal model and/or include a unit root in models?\nHow to use predictor variables to help forecast some variable such as sales? (i.e. regression on time series data)\n\n\n\n\nWhat are Cointegrated time series?\n\nCo-integration  is a technique used to find a long term correlation between time series processes that was introduced in 1987 by Nobel laureates Robert Engle and Clive Granger\nalso see (Pfaff 2008)\n\nWhat are some test for co-integration:\n\nEngle-Granger,\nJohansen Test,\nthe Phillips-Ouliaris test.\n\n\n\n\n\n\nHow to use neural network methods to forecast time series?\n\nRNNs\nlstms\nconvolutions\nGRUs\ntransformers\nTS foundations models\nNeural Prophet citation needed\n\nDeep learning foundation models citation needed pre-train NN model with many time series. Is this a form of Bayesian time series analysis?\nHow does this BTS relate to deep learning?\n\nDiffusion models in DL are autoregressive citation needed\nthe recently the mamba architecture has been proposed which is an autoregressive state space model. citation needed\n\n\n\n\n\n\nAny tips on scaraping time series data?\n\n\nWeb Scraping using Bots c.f (Woodward, Sadler, and Robertson 2022, sec. 1.4.1.4)\n\n\n\n\n\nWhat is smoothing in BTS\n\ndecomposing the series as a sum of two components: a smooth component, plus another component that includes all the features that are unexplained by the smooth component.\none way is to use a moving average.\nin the Bayesian context smoothing is the process of estimating the hidden states of a system given the observed data.\n\nWhat is filtering in Bayesian Time Series?\n\nin the Bayesian context filtering is the process of estimating the previous hidden states of a system given the observed data. I.e. a retrospective analysis to understand the process better\nwe want to sample p(\\theta_t,k \\mid \\mathcal{D}_t)\n\nWhat is the Kalman filter?\n\nsee (Prado, Ferreira, and West 2023, 141)\nthe book also toches on EKF and MKF\n\nWhat is a particle filter?\n\nsee (Prado, Ferreira, and West 2023, sec. 6.2.2) on the The Auxiliary Particle Filter\n\nWhat is the Butterworth filter?\n\nThe Butterworth filter is a signal processing filter that has a flat response in passband (or as close as possible to flat) - making it good for cleaning up noise !?\n\n\n\n\n\n\nWhite noise\nWiener process (random walk)\nAR(1): Autoregressive process order 1\nOrnstein–Uhlenbeck process a continuous-time version of the AR(1) process\nAR(p): Autoregressive process order p\nMA(q): Moving average process order q\nARMA(p,q): Autoregressive moving average\nSARMA: Seasonal ARMA\nARIMA: Autoregressive integrated moving average\nSARIMA: Seasonal ARIMA\nVAR: Vector autoregressive\nSVAR: structural vector autoregressive models (SVAR).\nVECM: Vector error correction models (VECM).\nGARCH: Generalized autoregressive conditional heteroskedasticity\nARCH: Autoregressive conditional heteroskedasticity\nSMC: Sequential Monte Carlo\nMDM: Multiregression dynamic models\nLTMs: latent threshold models\nFFBS: Forward Filtering Backward Sampling\nDLM: Dynamic Linear Models\nBSTS: Bayesian Structural Time Series\n\nhttps://drive.google.com/file/d/14US56VzanuLt03XBkoAGzLy0gDEreZUc/view\n\n\nTVAR: Time-varying autoregressive models\nDGLM: Dynamic Generalized Linear Models\n\n\n\n\n\nmagic trickWhat is the relation between Dynamic linear time series models (DLTS) models and Bayesian structural time series models (BSTS) models?\n\nDynamic Linear Time Series (DLTS) models and Bayesian Structural Time Series (BSTS) models are both frameworks for modeling time series data, and they share a strong connection, particularly in the way they approach model formulation and uncertainty. Here’s a breakdown of their relationship:\n\n\nDynamic Linear Time Series (DLTS) Models:\n\n\nDLTS models, often referred to as Dynamic Linear Models (DLMs), are a class of models where the parameters (such as the intercept or slope) evolve over time according to a stochastic process. They can be written in a state-space form, consisting of:\nObservation Equation: Relates the observed data to the hidden state.\nState Equation: Describes how the hidden state evolves over time.\nThese models use Kalman filtering for inference and prediction.\nDLTS models are flexible in handling non-stationarity and time-varying parameters.\n\n\nIn the course we primarily learned to use Bayesian methods to estimate the parameters of the model.\n\n\nBayesian Structural Time Series (BSTS) Models:\n\n\nBSTS models are a Bayesian approach to time series modeling, which generalizes the DLTS framework.\nLike DLTS, they use a state-space form, where the time series is decomposed into different components (e.g., trend, seasonality, regression effects).\nBSTS explicitly incorporates Bayesian inference, where prior distributions are placed on the model components and parameters, and inference is conducted using MCMC or other Bayesian methods.\nOne of the key advantages of BSTS is its ability to incorporate model uncertainty, allowing the user to specify structural components (such as trend or seasonality) with uncertainty about their presence or importance in the data.\n\n\nRelation Between DLTS and BSTS:\n\n\nBayesian Extension of DLTS: BSTS can be seen as a Bayesian extension of DLTS models. While DLTS uses Kalman filtering for deterministic inference, BSTS uses Bayesian methods to quantify and propagate uncertainty in model components and parameters.\nComponent Decomposition: Both models can represent the time series in terms of structural components (like trends, seasonal patterns, or covariates), but BSTS allows for more flexible modeling of these components using Bayesian priors and hierarchical structures.\nHandling of Uncertainty: DLTS models provide point estimates for parameters using Kalman filters, while BSTS incorporates full probabilistic estimates, enabling better uncertainty quantification in the presence of small data, model misspecification, or structural breaks.\nModel Complexity: BSTS models can handle more complex scenarios where the structure of the time series isn’t fully known (e.g., unknown seasonality or trends), whereas DLTS is typically used when the structure of the model (e.g., presence of trend or seasonality) is more defined.\nfor more information on BSTS",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Feyman Notebook on Bayesian Time Series Analysis"
    ]
  },
  {
    "objectID": "C4-L06.html#a-feynman-notebook---for-bayesian-time-series-analysis",
    "href": "C4-L06.html#a-feynman-notebook---for-bayesian-time-series-analysis",
    "title": "Week 0: Feyman Notebook on Bayesian Time Series Analysis",
    "section": "",
    "text": "ImportantTS Questions — A Feynman Notebook\n\n\n\nHere is where I can collect questions about TS analysis that I have as I go through the course. Hopefully I will be better equipped to answer many of these them by the end of the course.\n\nHow is Bayesian TS analysis differ from regular TS analysis?\n\nIn the NDLM we supply a Prior.\nWe the use Bayesian updating to update the model with the data.\nWe maintian a distributional view with estimates of the error.\nWe also the use Bayesian updating and inference for Filtering, Smoothing.\n\nFourier analysis is a powerful tool for time series analysis. How does it relate to Bayesian time series analysis?\n\nWe can incorporate the outcomes to incorporate seasonal elements into an NDLM\n\nHow and what type of prior knowledge into time series analysis?\n\nIn (West and Harrison 2013) they authors discuss both is the actual prior.\nBut they aslo talk about supporting interventions. E.g. when a major competitor goes out of buisness.The model should be able to handle this information and they make a big issues of how we need to incorporate into the next time step both new expected demand as well as an estimate of its variance which give better estimates of required production.\n\nAre there models that are unique to Bayesian time series analysis?\n\nHard to say but DLM seem to be.\n\nHow does distributional thinking affect time series analysis?\n\nIt gives us confidence bounds on future estimates.\n\nHow do we represent uncertainty in Bayesian time series analysis?\n\nWe have distribution and we can derive for any point estimate a correspoing creadible interval.\nWe can use smoothing to try and reason about trend or seasonality seperately.\n\nWill we learn about Gaussian Processes/Neural Networks in this course?\n\nThis is a type of Bayesian Non-parametric and we don’t cover these in the specilization. However Abel Rodriguez, the instructor of the third couse on mixture model has a short course\nHerbert Lee wrote a Bayesian Nonparametrics via Neural Networks on the subject.\n\nWhat BTS models are most useful in economics and finance?\nIs there a cleanup procedure for time series data?\n\nUsing exponential smoothing\nUsing weighted avaraging going back and forward enough steps can smooth seasonal effects.\nMore generaly this is handled by smoothing\nGoing backwards this is can be done using filtering.\n\nIs there an Bayesian EDA for time series?\n\nwe can use differencing to make the time series stationary\nwe can use the ACF and PACF\nwe can decompose the time series into trend, seasonal, and residual components\nwe can visualize autocorrelation using a correlogram\nwe can visualize periodicity using a periodogram and spectral density.\nsee (Nielsen 2019)\n\nHow do we handle missing data in time series?\nHow do we handle non-stationary time series?\n\nBy applying differencing we can make the time series stationary.\n\nAre there processes for long term memory in time series?\n\nsee (Prado, Ferreira, and West 2023, 124)\nthe book also toches on EKF and MKF\n\nAre there processes for power laws.\n\n\nsee https://wiki.santafe.edu/images/5/52/Powerlaws.pdf\n\n\nCan BTS handle dynamic systems in time series?\nCan we model time series with multiple scales?\nWhat TS models are useful for regime switching?\n\nI recall this came up in Davidson-Pilon (2015)\nThis is also covered in module 3 of the course.\n\nHow can we simulate time series data?\nHow can we forecast time series data?\nHow can we find periodicity in time series data?\nIs the Kalman Filter a state-space or dynamic linear model\n\nsee (Prado, Ferreira, and West 2023, 141)\nthe book also toches on EKF and MKF\n\nParticle filters AKA Sequential Monte Carlo methods in the book.\n\nsee (Prado, Ferreira, and West 2023, 205)\n\nAre there Bayesian time series models of contagion?\nAre there Bayesian time series models of epidemics?\nWhat are Seasonal adjustments?\nHow to do a seasonal adjustment?\nWhat are the tools for wrangling and cleaning TS data.\n\nData Engineering using Wrangling and Cleaning c.f. (Woodward, Sadler, and Robertson 2022, sec. 1.4.1.3)\n\nHow to use the frequency domain as a key part of understanding and analyzing data?\nHow to assess whether an existing trend should be predicted to continue or whether caution should be used in forecasts?\nDo you really understand AR models or are they just a black box?\nWhat is a unit root?\nHow to use tools that would help you decide whether to use a seasonal model and/or include a unit root in models?\nHow to use predictor variables to help forecast some variable such as sales? (i.e. regression on time series data)\n\n\n\n\nWhat are Cointegrated time series?\n\nCo-integration  is a technique used to find a long term correlation between time series processes that was introduced in 1987 by Nobel laureates Robert Engle and Clive Granger\nalso see (Pfaff 2008)\n\nWhat are some test for co-integration:\n\nEngle-Granger,\nJohansen Test,\nthe Phillips-Ouliaris test.\n\n\n\n\n\n\nHow to use neural network methods to forecast time series?\n\nRNNs\nlstms\nconvolutions\nGRUs\ntransformers\nTS foundations models\nNeural Prophet citation needed\n\nDeep learning foundation models citation needed pre-train NN model with many time series. Is this a form of Bayesian time series analysis?\nHow does this BTS relate to deep learning?\n\nDiffusion models in DL are autoregressive citation needed\nthe recently the mamba architecture has been proposed which is an autoregressive state space model. citation needed\n\n\n\n\n\n\nAny tips on scaraping time series data?\n\n\nWeb Scraping using Bots c.f (Woodward, Sadler, and Robertson 2022, sec. 1.4.1.4)\n\n\n\n\n\nWhat is smoothing in BTS\n\ndecomposing the series as a sum of two components: a smooth component, plus another component that includes all the features that are unexplained by the smooth component.\none way is to use a moving average.\nin the Bayesian context smoothing is the process of estimating the hidden states of a system given the observed data.\n\nWhat is filtering in Bayesian Time Series?\n\nin the Bayesian context filtering is the process of estimating the previous hidden states of a system given the observed data. I.e. a retrospective analysis to understand the process better\nwe want to sample p(\\theta_t,k \\mid \\mathcal{D}_t)\n\nWhat is the Kalman filter?\n\nsee (Prado, Ferreira, and West 2023, 141)\nthe book also toches on EKF and MKF\n\nWhat is a particle filter?\n\nsee (Prado, Ferreira, and West 2023, sec. 6.2.2) on the The Auxiliary Particle Filter\n\nWhat is the Butterworth filter?\n\nThe Butterworth filter is a signal processing filter that has a flat response in passband (or as close as possible to flat) - making it good for cleaning up noise !?\n\n\n\n\n\n\nWhite noise\nWiener process (random walk)\nAR(1): Autoregressive process order 1\nOrnstein–Uhlenbeck process a continuous-time version of the AR(1) process\nAR(p): Autoregressive process order p\nMA(q): Moving average process order q\nARMA(p,q): Autoregressive moving average\nSARMA: Seasonal ARMA\nARIMA: Autoregressive integrated moving average\nSARIMA: Seasonal ARIMA\nVAR: Vector autoregressive\nSVAR: structural vector autoregressive models (SVAR).\nVECM: Vector error correction models (VECM).\nGARCH: Generalized autoregressive conditional heteroskedasticity\nARCH: Autoregressive conditional heteroskedasticity\nSMC: Sequential Monte Carlo\nMDM: Multiregression dynamic models\nLTMs: latent threshold models\nFFBS: Forward Filtering Backward Sampling\nDLM: Dynamic Linear Models\nBSTS: Bayesian Structural Time Series\n\nhttps://drive.google.com/file/d/14US56VzanuLt03XBkoAGzLy0gDEreZUc/view\n\n\nTVAR: Time-varying autoregressive models\nDGLM: Dynamic Generalized Linear Models\n\n\n\n\n\nmagic trickWhat is the relation between Dynamic linear time series models (DLTS) models and Bayesian structural time series models (BSTS) models?\n\nDynamic Linear Time Series (DLTS) models and Bayesian Structural Time Series (BSTS) models are both frameworks for modeling time series data, and they share a strong connection, particularly in the way they approach model formulation and uncertainty. Here’s a breakdown of their relationship:\n\n\nDynamic Linear Time Series (DLTS) Models:\n\n\nDLTS models, often referred to as Dynamic Linear Models (DLMs), are a class of models where the parameters (such as the intercept or slope) evolve over time according to a stochastic process. They can be written in a state-space form, consisting of:\nObservation Equation: Relates the observed data to the hidden state.\nState Equation: Describes how the hidden state evolves over time.\nThese models use Kalman filtering for inference and prediction.\nDLTS models are flexible in handling non-stationarity and time-varying parameters.\n\n\nIn the course we primarily learned to use Bayesian methods to estimate the parameters of the model.\n\n\nBayesian Structural Time Series (BSTS) Models:\n\n\nBSTS models are a Bayesian approach to time series modeling, which generalizes the DLTS framework.\nLike DLTS, they use a state-space form, where the time series is decomposed into different components (e.g., trend, seasonality, regression effects).\nBSTS explicitly incorporates Bayesian inference, where prior distributions are placed on the model components and parameters, and inference is conducted using MCMC or other Bayesian methods.\nOne of the key advantages of BSTS is its ability to incorporate model uncertainty, allowing the user to specify structural components (such as trend or seasonality) with uncertainty about their presence or importance in the data.\n\n\nRelation Between DLTS and BSTS:\n\n\nBayesian Extension of DLTS: BSTS can be seen as a Bayesian extension of DLTS models. While DLTS uses Kalman filtering for deterministic inference, BSTS uses Bayesian methods to quantify and propagate uncertainty in model components and parameters.\nComponent Decomposition: Both models can represent the time series in terms of structural components (like trends, seasonal patterns, or covariates), but BSTS allows for more flexible modeling of these components using Bayesian priors and hierarchical structures.\nHandling of Uncertainty: DLTS models provide point estimates for parameters using Kalman filters, while BSTS incorporates full probabilistic estimates, enabling better uncertainty quantification in the presence of small data, model misspecification, or structural breaks.\nModel Complexity: BSTS models can handle more complex scenarios where the structure of the time series isn’t fully known (e.g., unknown seasonality or trends), whereas DLTS is typically used when the structure of the model (e.g., presence of trend or seasonality) is more defined.\nfor more information on BSTS",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Feyman Notebook on Bayesian Time Series Analysis"
    ]
  },
  {
    "objectID": "C4-L06.html#software",
    "href": "C4-L06.html#software",
    "title": "Week 0: Feyman Notebook on Bayesian Time Series Analysis",
    "section": "2 Software",
    "text": "2 Software\n\nWhat are the most useful packages in R for time series analysis?\n\nBOA Bayesian Output Analysis (BOA, Smith 2007) citation needed and\nCODA Convergence Diagnosis and Output Analysis for MCMC (CODA, Plummer, Best, Cowles, and Vines 2006). citation needed\nURCA Unit Root and Cointegration Tests for Time Series Data (URCA, Pfaff 2008)citation needed.\nVars VAR Modelling (Vars, Pfaff 2008). citation needed\nBSTS Bayesian Structural Time Series (BSTS, Scott and Varian 2014). citation needed\nCausalImpact Causal Impact Analysis (CausalImpact, Brodersen, Gallusser, Koehler, Remy, and Scott 2015). citation needed builds on BSTS and methods from this Inferring causal impact using Bayesian structural time-series models\nKFAS Kalman Filter and Smoother for Exponential Family State Space Models (KFAS, Helske 2017). citation needed\nMARSS Multivariate Autoregressive State-Space Models (MARSS, Holmes, Ward, and Scheuerell 2012). citation needed\nMCMCpack Markov Chain Monte Carlo (MCMCpack, Martin, Quinn, and Park 2011). citation needed\nMCMCglmm Markov Chain Monte Carlo Generalized Linear Mixed Models (MCMCglmm, Hadfield 2010). citation needed\nR-INLA Integrated Nested Laplace Approximations (R-INLA, Rue, Martino, and Chopin 2009). citation needed used approximate Bayesian inference for Latent Gaussian Models that can be expressed as latent Gaussian Markov random fields (GMRF)\n\nWhat about in python?",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Feyman Notebook on Bayesian Time Series Analysis"
    ]
  },
  {
    "objectID": "C1-L02-Ex2.html",
    "href": "C1-L02-Ex2.html",
    "title": "Conditional Probability and Bayes’ Law",
    "section": "",
    "text": "Exercise 1 Which must be true if random variable X is a continuous RV with PDF f(x)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nf(x) \\ge 0 \\: \\forall x\n\\lim_{x \\to \\infty} f(x)=1\n\n\n\n\n\nExercise 2 If X∼Exp(3), what is the value of P(X&gt;1/3)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n0.37\n\n\\begin{aligned}\nP(X&gt;1/3) &= \\int_{1/3}^\\infty 3 e^{−3x} dx \\\\ &= −e|_{−3x}^\\infty \\\\ &= 0- (-e^{-3/3}) = e^-1 = 0.368 \\end{aligned}\n\n\n\n\n\nExercise 3 Suppose X∼Uniform(0,2) and Y∼Uniform(8,10). What is the value of \\mathbb{E}(4X+Y)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned} \\mathbb{E}(4X+Y)&=4\\mathbb{E}(X)+\\mathbb{E}(Y)\\\\&=4(1)+9 \\\\&= 13\\end{aligned}\n\n\n\n\n For the following questions:Adding normals\nSuppose X∼N(1,25) and Y∼N(−2,9) and that X and Y are independent. We have Z=X+Y∼N(μ,σ^2) because the sum of normal random variables also follows a normal distribution.\n\nExercise 4  What is the value of \\mu?Adding normals\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\\mu=\\mathbb{E}[Z]=\\mathbb{E}[X+Y]=\\mathbb{E}[X]+\\mathbb{E}[Y]=1+(−2)\n\n\n\n\nExercise 5  What is the value of σ^2?Adding normals\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nIf two random variables are independent, the variance of their sum is the sum of their variances.\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n=Var(Z)=Var(X+Y)=Var(X)+Var(Y)=25+9=34\n\n\n\n\nExercise 6  If RVs X and Y are not independent, we still have \n\\mathbb{E}(X+Y)=\\mathbb{E}(X)+\\mathbb{E}(Y)\nAdding normals\nbut now\n\n\\mathbb{V}ar(X+Y)=Var(X)+Var(Y)+2 Cov(X, Y)\n\nwhere\n\nCov(X, Y)=\\mathbb{E}[(X−\\mathbb{E}(X))\\cdot(Y−\\mathbb{E}(Y))]\n\nis called the covariance between X and Y.\n\n\n\n\n\n\nImportant\n\n\n\nA convenient identity for calculating variance:\n\n\\mathbb{V}ar(X) = \\mathbb{E}[(X−\\mathbb{E}[X])^2 ]=\\mathbb{E}[X^2]−(\\mathbb{E}[X])^2\n\n\n\nWhich of the following is an analogous expression for the covariance of X and Y?\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\n\nExpand the terms inside the expectation in the definition of Cov(X, Y)\nRecall that \\mathbb{E}(X) and \\mathbb{E}(Y) are just constants.\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nCov(X,Y) = \\mathbb{E}(XY)−\\mathbb{E}(X)\\mathbb{E}(Y)\n\nsince\n\n\\begin{aligned}\n    Cov(X,Y)&\\equiv \\mathbb{E}[(X−\\mathbb{E}[X])(Y−\\mathbb{E}[Y])] \\\\\n            &= \\mathbb{E}[XY−X\\mathbb{E}(Y)−\\mathbb{E}(X)Y+\\mathbb{E}(X)\\mathbb{E}(Y)] \\\\\n            &= \\mathbb{E}[XY]−\\mathbb{E}[X\\mathbb{E}(Y)]−\\mathbb{E}[\\mathbb{E}(X)Y]+\\mathbb{E}[\\mathbb{E}(X)\\mathbb{E}(Y)] \\\\\n            &= \\mathbb{E}[XY]-  \\mathbb{E}(X)\\mathbb{E}(Y)− \\cancel{ \\mathbb{E}(X)\\mathbb{E}(Y)}+\\cancel{\\mathbb{E}(X)\\mathbb{E}(Y)}\n\\end{aligned}\n\n\n\n\n\nExercise 7  Consider again X∼N(1,5^2) and Y∼N(−2,3^2), but this time X and Y are not independent. Then Z=X+Y is still normally distributed with the same mean found in (Exercise 4). What is the variance of Z if \\mathbb{E}(XY)=−5?Adding normals\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nUse the formulas introduced in Question (Exercise 6).\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\nVar(Z) &= Var(X) + Var(Y) + 2Cov(X,Y) \\\\ &= 25 + 9 + 2Cov(X,Y) \\\\ &= 34 + 2 (\\mathbb{E}[XY] − \\mathbb{E}[X] \\mathbb{E}[Y] ) \\\\  &= 34 + 2 (−5−1(−2))=34−2(3) =28\n\\end{aligned}\n\n\n\n\n\nExercise 8 Use the definition of conditional probability to show that for events A and B, we have\n\n\\begin{aligned}\nP(A \\cap B) = P(B \\mid A)P(A) = P(A \\mid B)P(B)\n\\end{aligned}\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\nP(B \\mid A)= \\frac{P(A \\cap B)}{P(A)} \\\\P(B \\mid A)P(A)=P(A \\cap B)\n\\end{aligned}\n\n\n\n\n\nExercise 9 Show that the two expressions for independence P(A∣B)=P(A) and P(A∩B) = P(A)P(B) are equivalent.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nPlug these expressions into those from (Exercise 8).",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Conditional Probability and Bayes' Law"
    ]
  },
  {
    "objectID": "C1-L02-Ex2.html#homework-honors-1",
    "href": "C1-L02-Ex2.html#homework-honors-1",
    "title": "Conditional Probability and Bayes’ Law",
    "section": "",
    "text": "Exercise 1 Which must be true if random variable X is a continuous RV with PDF f(x)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nf(x) \\ge 0 \\: \\forall x\n\\lim_{x \\to \\infty} f(x)=1\n\n\n\n\n\nExercise 2 If X∼Exp(3), what is the value of P(X&gt;1/3)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n0.37\n\n\\begin{aligned}\nP(X&gt;1/3) &= \\int_{1/3}^\\infty 3 e^{−3x} dx \\\\ &= −e|_{−3x}^\\infty \\\\ &= 0- (-e^{-3/3}) = e^-1 = 0.368 \\end{aligned}\n\n\n\n\n\nExercise 3 Suppose X∼Uniform(0,2) and Y∼Uniform(8,10). What is the value of \\mathbb{E}(4X+Y)?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned} \\mathbb{E}(4X+Y)&=4\\mathbb{E}(X)+\\mathbb{E}(Y)\\\\&=4(1)+9 \\\\&= 13\\end{aligned}\n\n\n\n\n For the following questions:Adding normals\nSuppose X∼N(1,25) and Y∼N(−2,9) and that X and Y are independent. We have Z=X+Y∼N(μ,σ^2) because the sum of normal random variables also follows a normal distribution.\n\nExercise 4  What is the value of \\mu?Adding normals\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\\mu=\\mathbb{E}[Z]=\\mathbb{E}[X+Y]=\\mathbb{E}[X]+\\mathbb{E}[Y]=1+(−2)\n\n\n\n\nExercise 5  What is the value of σ^2?Adding normals\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nIf two random variables are independent, the variance of their sum is the sum of their variances.\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n=Var(Z)=Var(X+Y)=Var(X)+Var(Y)=25+9=34\n\n\n\n\nExercise 6  If RVs X and Y are not independent, we still have \n\\mathbb{E}(X+Y)=\\mathbb{E}(X)+\\mathbb{E}(Y)\nAdding normals\nbut now\n\n\\mathbb{V}ar(X+Y)=Var(X)+Var(Y)+2 Cov(X, Y)\n\nwhere\n\nCov(X, Y)=\\mathbb{E}[(X−\\mathbb{E}(X))\\cdot(Y−\\mathbb{E}(Y))]\n\nis called the covariance between X and Y.\n\n\n\n\n\n\nImportant\n\n\n\nA convenient identity for calculating variance:\n\n\\mathbb{V}ar(X) = \\mathbb{E}[(X−\\mathbb{E}[X])^2 ]=\\mathbb{E}[X^2]−(\\mathbb{E}[X])^2\n\n\n\nWhich of the following is an analogous expression for the covariance of X and Y?\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\n\nExpand the terms inside the expectation in the definition of Cov(X, Y)\nRecall that \\mathbb{E}(X) and \\mathbb{E}(Y) are just constants.\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nCov(X,Y) = \\mathbb{E}(XY)−\\mathbb{E}(X)\\mathbb{E}(Y)\n\nsince\n\n\\begin{aligned}\n    Cov(X,Y)&\\equiv \\mathbb{E}[(X−\\mathbb{E}[X])(Y−\\mathbb{E}[Y])] \\\\\n            &= \\mathbb{E}[XY−X\\mathbb{E}(Y)−\\mathbb{E}(X)Y+\\mathbb{E}(X)\\mathbb{E}(Y)] \\\\\n            &= \\mathbb{E}[XY]−\\mathbb{E}[X\\mathbb{E}(Y)]−\\mathbb{E}[\\mathbb{E}(X)Y]+\\mathbb{E}[\\mathbb{E}(X)\\mathbb{E}(Y)] \\\\\n            &= \\mathbb{E}[XY]-  \\mathbb{E}(X)\\mathbb{E}(Y)− \\cancel{ \\mathbb{E}(X)\\mathbb{E}(Y)}+\\cancel{\\mathbb{E}(X)\\mathbb{E}(Y)}\n\\end{aligned}\n\n\n\n\n\nExercise 7  Consider again X∼N(1,5^2) and Y∼N(−2,3^2), but this time X and Y are not independent. Then Z=X+Y is still normally distributed with the same mean found in (Exercise 4). What is the variance of Z if \\mathbb{E}(XY)=−5?Adding normals\n\n\n\n\n\n\n\nNoteHint\n\n\n\n\n\nUse the formulas introduced in Question (Exercise 6).\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\nVar(Z) &= Var(X) + Var(Y) + 2Cov(X,Y) \\\\ &= 25 + 9 + 2Cov(X,Y) \\\\ &= 34 + 2 (\\mathbb{E}[XY] − \\mathbb{E}[X] \\mathbb{E}[Y] ) \\\\  &= 34 + 2 (−5−1(−2))=34−2(3) =28\n\\end{aligned}\n\n\n\n\n\nExercise 8 Use the definition of conditional probability to show that for events A and B, we have\n\n\\begin{aligned}\nP(A \\cap B) = P(B \\mid A)P(A) = P(A \\mid B)P(B)\n\\end{aligned}\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\\begin{aligned}\nP(B \\mid A)= \\frac{P(A \\cap B)}{P(A)} \\\\P(B \\mid A)P(A)=P(A \\cap B)\n\\end{aligned}\n\n\n\n\n\nExercise 9 Show that the two expressions for independence P(A∣B)=P(A) and P(A∩B) = P(A)P(B) are equivalent.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nPlug these expressions into those from (Exercise 8).",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Conditional Probability and Bayes' Law"
    ]
  },
  {
    "objectID": "soi.html",
    "href": "soi.html",
    "title": "Southern Oscillation Index",
    "section": "",
    "text": "https://www.ncei.noaa.gov/access/monitoring/enso/soi/\n\nThe Southern Oscillation Index (SOI) is a standardized index based on the observed sea level pressure (SLP) differences between Tahiti and Darwin, Australia. The SOI is one measure of the large-scale fluctuations in air pressure occurring between the western and eastern tropical Pacific (i.e., the state of the Southern Oscillation) during El Niño and La Niña episodes. In general, smoothed time series of the SOI correspond very well with changes in ocean temperatures across the eastern tropical Pacific. The negative phase of the SOI represents below-normal air pressure at Tahiti and above-normal air pressure at Darwin.\n\nlet’s load the soi data and plot it.\n\n\nCode\nif(!require('ocedata')) {\n  install.packages('ocedata')\n  library('ocedata')\n}\n\n\nLoading required package: ocedata\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'ocedata'\n\n\nInstalling package into '/home/oren/R/x86_64-pc-linux-gnu-library/4.5'\n(as 'lib' is unspecified)\n\n\n\n\nCode\ndata(soi, package=\"ocedata\")\nrecent &lt;- subset(soi, year &gt; 1950)\nplot(recent$year, recent$index, type='l', xlab=\"Year\", ylab=\"SOI\")"
  },
  {
    "objectID": "soi.html#soi",
    "href": "soi.html#soi",
    "title": "Southern Oscillation Index",
    "section": "",
    "text": "https://www.ncei.noaa.gov/access/monitoring/enso/soi/\n\nThe Southern Oscillation Index (SOI) is a standardized index based on the observed sea level pressure (SLP) differences between Tahiti and Darwin, Australia. The SOI is one measure of the large-scale fluctuations in air pressure occurring between the western and eastern tropical Pacific (i.e., the state of the Southern Oscillation) during El Niño and La Niña episodes. In general, smoothed time series of the SOI correspond very well with changes in ocean temperatures across the eastern tropical Pacific. The negative phase of the SOI represents below-normal air pressure at Tahiti and above-normal air pressure at Darwin.\n\nlet’s load the soi data and plot it.\n\n\nCode\nif(!require('ocedata')) {\n  install.packages('ocedata')\n  library('ocedata')\n}\n\n\nLoading required package: ocedata\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'ocedata'\n\n\nInstalling package into '/home/oren/R/x86_64-pc-linux-gnu-library/4.5'\n(as 'lib' is unspecified)\n\n\n\n\nCode\ndata(soi, package=\"ocedata\")\nrecent &lt;- subset(soi, year &gt; 1950)\nplot(recent$year, recent$index, type='l', xlab=\"Year\", ylab=\"SOI\")"
  },
  {
    "objectID": "C3-L00.html",
    "href": "C3-L00.html",
    "title": "Intro to Mixture Models",
    "section": "",
    "text": "This is the third course in the specialization on Bayesian Statistics. In the first course we looked at the basics of Bayesian statistics and in the second course we looked at Bayesian regression models. Now we turn our attention to mixture models, which are a simple yet powerful generalization of the models we have seen so far. Mixtures are distributions consisting of weighted sums of distributions. The idea dates back to the work of Karl Pearson in 1894, who used mixtures to model the distribution of heights in a population.\nMixture models are widely used in various fields, including machine learning, statistics, and data science.\nWe will cover the following topics:\n\nBasic Concepts: Understanding the fundamental ideas behind mixture models, including components, weights, and the overall mixture distribution.\nBayesian Inference: Learning how to perform Bayesian inference in the context of mixture models, including the use of Markov Chain Monte Carlo (MCMC) methods.\nApplications: Exploring various applications of mixture models in real-world scenarios, such as clustering, density estimation, and anomaly detection.\n\nBy the end of this course, you will have a solid understanding of mixture models and their applications in Bayesian statistics.\n\n\nIn the next course we will look at time series models and in the final course we will also consider using mixture models for time series data.\nAlthough this specialization does not cover Gaussian processes, mixtures are a special case of Gaussian processes and can help us develop some of the intuition behind them. Another omission is that mixture models are the advanced version called mixture of experts which are used in deep learning.\nIf possible I’d like to look into the above topics using material from some textbooks below."
  },
  {
    "objectID": "C3-L00.html#the-course-in-context",
    "href": "C3-L00.html#the-course-in-context",
    "title": "Intro to Mixture Models",
    "section": "",
    "text": "This is the third course in the specialization on Bayesian Statistics. In the first course we looked at the basics of Bayesian statistics and in the second course we looked at Bayesian regression models. Now we turn our attention to mixture models, which are a simple yet powerful generalization of the models we have seen so far. Mixtures are distributions consisting of weighted sums of distributions. The idea dates back to the work of Karl Pearson in 1894, who used mixtures to model the distribution of heights in a population.\nMixture models are widely used in various fields, including machine learning, statistics, and data science.\nWe will cover the following topics:\n\nBasic Concepts: Understanding the fundamental ideas behind mixture models, including components, weights, and the overall mixture distribution.\nBayesian Inference: Learning how to perform Bayesian inference in the context of mixture models, including the use of Markov Chain Monte Carlo (MCMC) methods.\nApplications: Exploring various applications of mixture models in real-world scenarios, such as clustering, density estimation, and anomaly detection.\n\nBy the end of this course, you will have a solid understanding of mixture models and their applications in Bayesian statistics.\n\n\nIn the next course we will look at time series models and in the final course we will also consider using mixture models for time series data.\nAlthough this specialization does not cover Gaussian processes, mixtures are a special case of Gaussian processes and can help us develop some of the intuition behind them. Another omission is that mixture models are the advanced version called mixture of experts which are used in deep learning.\nIf possible I’d like to look into the above topics using material from some textbooks below."
  },
  {
    "objectID": "C3-L00.html#the-instructor",
    "href": "C3-L00.html#the-instructor",
    "title": "Intro to Mixture Models",
    "section": "2 🤯 The Instructor",
    "text": "2 🤯 The Instructor\nThe course comes with extensive notes by Abel Rodríguez.\nRodríguez is associated with Nimble, a system for programming and simulating hierarchical models in R. Nimble is a powerful tool for Bayesian modeling and inference, and it is particularly well-suited for mixture models. And is compatible with JAGS\nHe co-authored “Probability, Decisions, and Games: A Gentle Introduction Using R” an introduction to probability and decision theory using R."
  },
  {
    "objectID": "C3-L00.html#references",
    "href": "C3-L00.html#references",
    "title": "Intro to Mixture Models",
    "section": "3 ✍️ References",
    "text": "3 ✍️ References\nAs I pointed out above I’m also interested in mixtures of experts and Gaussian processes. The following books are good references for these topics:\n\n“Gaussian Processes for Machine Learning” by Carl Edward Rasmussen and Christopher K. I. Williams\n“Mixture Models: Inference and Applications” by Geoffrey McLachlan and David Peel"
  },
  {
    "objectID": "indexing.html",
    "href": "indexing.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "indexing.html#entries-and-subentries",
    "href": "indexing.html#entries-and-subentries",
    "title": "",
    "section": "1.1 Entries and Subentries",
    "text": "1.1 Entries and Subentries\n\\index{main_index_ent}\n\n\n\n\n\n\n\n\nIndex Entry Type\nLaTeX Expression\nExample\n\n\n\n\nMain index entry\n\\index{main_index_ent}\n\\index{scheduling}\n\n\nSub-index entry\n\\index{main_index_ent!sub_ent}\n\\index{scheduling!reg}\n\n\nSub-sub-index entry\n\\index{main_index_ent!sub_ent!sub_sub_ent}\n{\\index{scheduling!reg!MS}"
  },
  {
    "objectID": "indexing.html#page-range-definitions",
    "href": "indexing.html#page-range-definitions",
    "title": "",
    "section": "1.2 Page range definitions",
    "text": "1.2 Page range definitions\nuse \\index{…|(} \\index{…|)} to define a page range"
  },
  {
    "objectID": "indexing.html#see-notes",
    "href": "indexing.html#see-notes",
    "title": "",
    "section": "1.3 See notes",
    "text": "1.3 See notes\n\\index{partitions!harddrive|see{harddrive, partitions}}"
  },
  {
    "objectID": "indexing.html#different-location-and-text",
    "href": "indexing.html#different-location-and-text",
    "title": "",
    "section": "1.4 Different location and text",
    "text": "1.4 Different location and text\n\\index{string1@string2} where - string1 is used to set the location - string2 is used to set the display text\nFormat: \\index{partitions}\n\\index{partitions!harddrive|see{harddrive,partitions}}\nThe primary \\index{SATA} disk drive on your personal Windows 7\ncomputers is filling up. This drive contains the computer’s\n\\index{Windows!operating system} and application of software.\n\\index{harddrive}\n\\index{partitions!harddrive|see{harddrive, partitions}}"
  },
  {
    "objectID": "indexing.html#referrences",
    "href": "indexing.html#referrences",
    "title": "",
    "section": "1.5 referrences",
    "text": "1.5 referrences\n\nhttps://latex-tutorial.com/creating-index-latex/"
  },
  {
    "objectID": "mixture-math.html",
    "href": "mixture-math.html",
    "title": "Mixture Models",
    "section": "",
    "text": "Mixture Model (CDF):\n\n\nF(x) = \\sum_{k=1}^K \\omega_k G_k(x)\n\\tag{1}\nwhere G_k(x) is the CDF of the k-th component distribution and \\omega_k is the weight for the k-th component.\n\nMixture Model (PDF/PMF):\n\n\nf(x) = \\sum_{k=1}^K \\omega_k g_k(x)\n\\tag{2}\nwhere g_k(x) is the PDF/PMF of the k-th component distribution and \\omega_k is the weight for the k-th component.\n\nExample: Exponential Mixture CDF:\n\n\nF(x) = \\omega_1 \\left(1 - \\exp\\left\\{\\frac{x}{\\theta_1}\\right\\}\\right)\n     + \\omega_2 \\left(1 - \\exp\\left\\{\\frac{x}{\\theta_2}\\right\\}\\right)\n     + \\omega_3 \\left(1 - \\exp\\left\\{\\frac{x}{\\theta_3}\\right\\}\\right)\n\\tag{3}\n\nExample: Exponential Mixture PDF:\n\n\nf(x) = \\frac{\\omega_1}{\\theta_1} \\exp\\left\\{\\frac{x}{\\theta_1}\\right\\}\n    + \\frac{\\omega_2}{\\theta_2} \\exp\\left\\{\\frac{x}{\\theta_2}\\right\\}\n    + \\frac{\\omega_3}{\\theta_3} \\exp\\left\\{\\frac{x}{\\theta_3}\\right\\}\n\\tag{4}\n\nGamma Mixture PDF:\n\n\nf(x) =\n\\begin{cases}\n    \\omega \\frac{x^{\\nu_1-1}}{\\Gamma(\\nu_1)\\lambda_1^{\\nu_1}}\\ \\exp \\left\\{\\frac{x}{\\lambda_1}\\right\\}\n    + (1-\\omega) \\frac{x^{\\nu_2-1}}{\\Gamma(\\nu_2)\\lambda_2^{\\nu_2}}\\ \\exp \\left\\{\\frac{x}{\\lambda_2}\\right\\} & x &gt; 0 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\tag{5}\n\nMean and Variance of a Mixture:\n\n\n\\mathbb{E}_F(X) = \\sum_{k=1}^K \\omega_k \\mathbb{E}_{G_k}[X]\n\\tag{6}\n\n\\begin{aligned}\n\\operatorname{Var}_F(X) & = \\mathbb{E}_F(X^2) - \\{\\mathbb{E}_F(X)\\}^2 \\\\\n& = \\sum_{k=1}^K \\omega_k \\left\\{ \\mathbb{E}_{G_k}(X^2) \\right\\} - \\left\\{ \\sum_{k=1}^K \\omega_k \\mathbb{E}_{G_k}(X) \\right\\}^2 \\\\\n& = \\sum_{k=1}^K \\omega_k \\left\\{ \\operatorname{Var}_{G_k}(X) + [\\mathbb{E}_{G_k}(X)]^2 \\right\\} - \\left\\{ \\sum_{k=1}^K \\omega_k \\mathbb{E}_{G_k}(X) \\right\\}^2\n\\end{aligned}\n\\tag{7}\n\nSpecial Case (Component means zero):\n\n\n\\operatorname{Var}_F(X) = \\sum_{k=1}^K \\omega_k \\operatorname{Var}_{G_k}(X)\n\\tag{8}\n\n\n\nFinite mixtures of distributions within a single family provide a lot of flexibility. For example, a mixture of Gaussian distributions can have a bimodal density.\n\nExample: Bimodal Mixture:\n\n\nf(x) = 0.6 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{ -\\frac{1}{2}x^2 \\right\\}\n     + 0.4 \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}} \\exp\\left\\{ -\\frac{1}{2}\\frac{(x-5)^2}{4} \\right\\}\n\\tag{9}\n\nExample: Skewed Unimodal Mixture:\n\n\nf(x) = 0.55 \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{2} \\right\\}\n    + 0.45 \\frac{1}{\\sqrt{2\\pi} 2} \\exp\\left\\{ -\\frac{1}{2}\\left(\\frac{x-3}{2}\\right)^2 \\right\\}\n\\tag{10}\n\nExample: Symmetric Heavy-tailed Mixture:\n\n\nf(x) = 0.4 \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{2} \\right\\}\n    + 0.4 \\frac{1}{\\sqrt{2\\pi} 4} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{16} \\right\\}\n    + 0.2 \\frac{1}{\\sqrt{2\\pi} \\sqrt{20}} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{20} \\right\\}\n\\tag{11}\n\nZero-inflated Negative Binomial PMF:\n\n\np(x) =\n\\begin{cases}\n    \\omega_1 + (1-\\omega_1)\\theta^r & x=0 \\\\\n    (1-\\omega_1) \\binom{x+r-1}{x} \\theta^r (1-\\theta)^x & x&gt;1\n\\end{cases}\n\\tag{12}\n\nRegular Negative Binomial PMF:\n\n\np^*(x) = \\binom{x+r-1}{x} \\theta^r (1-\\theta)^x\n\\tag{13}\n\nZero-inflated Log-Gaussian PDF:\n\n\nf(x) =\n\\begin{cases}\n    \\omega_1 \\delta_0(x) + (1-\\omega_1)\\frac{1}{\\sqrt{2\\pi}\\sigma x}\\exp\\left\\{ -\\frac{(\\ln x - \\mu)^2}{2\\sigma^2} \\right\\} & x &gt; 0 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\tag{14}\nwhere \\delta_0(x) is the Dirac delta function at x=0.\n\n\n\n\nMixture Model (Hierarchical):\n\n\nX \\mid c \\sim G_c, \\quad P(c = k) = \\omega_k\n\\tag{15}\nwhere G_c is the distribution of the k-th component and \\omega_k is the weight for the k-th component.\n\n\n\n\nObserved-data Likelihood for a mixture Model\n\n\nL_O(\\theta, \\omega; x) \\propto p(x \\mid \\theta, \\omega) = \\prod_{i=1}^n \\sum_{k=1}^K \\omega_k g_k(x_i \\mid \\theta_k)\n\\tag{16}\nwhere g_k(x_i \\mid \\theta_k) is the PDF/PMF of the k-th component distribution evaluated at x_i with parameter \\theta_k.\n\nMixture Model (Likelihood, complete-data):\n\n\nL(\\theta, \\omega; x, c) = p(x, c \\mid \\theta, \\omega) = \\prod_{i=1}^n \\prod_{k=1}^K [\\omega_k g_k(x_i \\mid \\theta_k)]^{1(c_i = k)}\n\\tag{17}\nwhere 1(c_i = k) is an indicator function that is 1 if c_i = k and 0 otherwise.\n\nAlternative complete-data likelihood decomposition:\n\n\np(x, c \\mid \\theta, \\omega) = p(x \\mid c, \\theta) p(c \\mid \\omega)\n\\tag{18}\nwith\n\np(x \\mid c, \\theta) = \\prod_{i=1}^n g_{c_i}(x_i \\mid \\theta_{c_i})\n\\tag{19}\n\np(c \\mid \\omega) = \\prod_{k=1}^K \\omega_k^{\\sum_{i=1}^n 1(c_i = k)}\n\\tag{20}\nwhere 1(c_i = k) is an indicator function that is 1 if c_i = k and 0 otherwise.\n\n\n\nLabel switching\nTODO : missing formula\n\nf(x) = ...\n\\tag{21}\nTODO : missing formula\n\nf(x) = ...\n\\tag{22}\nNumber of components\n\nf(x) = ...\n\\tag{23}"
  },
  {
    "objectID": "mixture-math.html#basic-concepts",
    "href": "mixture-math.html#basic-concepts",
    "title": "Mixture Models",
    "section": "",
    "text": "Mixture Model (CDF):\n\n\nF(x) = \\sum_{k=1}^K \\omega_k G_k(x)\n\\tag{1}\nwhere G_k(x) is the CDF of the k-th component distribution and \\omega_k is the weight for the k-th component.\n\nMixture Model (PDF/PMF):\n\n\nf(x) = \\sum_{k=1}^K \\omega_k g_k(x)\n\\tag{2}\nwhere g_k(x) is the PDF/PMF of the k-th component distribution and \\omega_k is the weight for the k-th component.\n\nExample: Exponential Mixture CDF:\n\n\nF(x) = \\omega_1 \\left(1 - \\exp\\left\\{\\frac{x}{\\theta_1}\\right\\}\\right)\n     + \\omega_2 \\left(1 - \\exp\\left\\{\\frac{x}{\\theta_2}\\right\\}\\right)\n     + \\omega_3 \\left(1 - \\exp\\left\\{\\frac{x}{\\theta_3}\\right\\}\\right)\n\\tag{3}\n\nExample: Exponential Mixture PDF:\n\n\nf(x) = \\frac{\\omega_1}{\\theta_1} \\exp\\left\\{\\frac{x}{\\theta_1}\\right\\}\n    + \\frac{\\omega_2}{\\theta_2} \\exp\\left\\{\\frac{x}{\\theta_2}\\right\\}\n    + \\frac{\\omega_3}{\\theta_3} \\exp\\left\\{\\frac{x}{\\theta_3}\\right\\}\n\\tag{4}\n\nGamma Mixture PDF:\n\n\nf(x) =\n\\begin{cases}\n    \\omega \\frac{x^{\\nu_1-1}}{\\Gamma(\\nu_1)\\lambda_1^{\\nu_1}}\\ \\exp \\left\\{\\frac{x}{\\lambda_1}\\right\\}\n    + (1-\\omega) \\frac{x^{\\nu_2-1}}{\\Gamma(\\nu_2)\\lambda_2^{\\nu_2}}\\ \\exp \\left\\{\\frac{x}{\\lambda_2}\\right\\} & x &gt; 0 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\tag{5}\n\nMean and Variance of a Mixture:\n\n\n\\mathbb{E}_F(X) = \\sum_{k=1}^K \\omega_k \\mathbb{E}_{G_k}[X]\n\\tag{6}\n\n\\begin{aligned}\n\\operatorname{Var}_F(X) & = \\mathbb{E}_F(X^2) - \\{\\mathbb{E}_F(X)\\}^2 \\\\\n& = \\sum_{k=1}^K \\omega_k \\left\\{ \\mathbb{E}_{G_k}(X^2) \\right\\} - \\left\\{ \\sum_{k=1}^K \\omega_k \\mathbb{E}_{G_k}(X) \\right\\}^2 \\\\\n& = \\sum_{k=1}^K \\omega_k \\left\\{ \\operatorname{Var}_{G_k}(X) + [\\mathbb{E}_{G_k}(X)]^2 \\right\\} - \\left\\{ \\sum_{k=1}^K \\omega_k \\mathbb{E}_{G_k}(X) \\right\\}^2\n\\end{aligned}\n\\tag{7}\n\nSpecial Case (Component means zero):\n\n\n\\operatorname{Var}_F(X) = \\sum_{k=1}^K \\omega_k \\operatorname{Var}_{G_k}(X)\n\\tag{8}\n\n\n\nFinite mixtures of distributions within a single family provide a lot of flexibility. For example, a mixture of Gaussian distributions can have a bimodal density.\n\nExample: Bimodal Mixture:\n\n\nf(x) = 0.6 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{ -\\frac{1}{2}x^2 \\right\\}\n     + 0.4 \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}} \\exp\\left\\{ -\\frac{1}{2}\\frac{(x-5)^2}{4} \\right\\}\n\\tag{9}\n\nExample: Skewed Unimodal Mixture:\n\n\nf(x) = 0.55 \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{2} \\right\\}\n    + 0.45 \\frac{1}{\\sqrt{2\\pi} 2} \\exp\\left\\{ -\\frac{1}{2}\\left(\\frac{x-3}{2}\\right)^2 \\right\\}\n\\tag{10}\n\nExample: Symmetric Heavy-tailed Mixture:\n\n\nf(x) = 0.4 \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{2} \\right\\}\n    + 0.4 \\frac{1}{\\sqrt{2\\pi} 4} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{16} \\right\\}\n    + 0.2 \\frac{1}{\\sqrt{2\\pi} \\sqrt{20}} \\exp\\left\\{ -\\frac{1}{2} \\frac{x^2}{20} \\right\\}\n\\tag{11}\n\nZero-inflated Negative Binomial PMF:\n\n\np(x) =\n\\begin{cases}\n    \\omega_1 + (1-\\omega_1)\\theta^r & x=0 \\\\\n    (1-\\omega_1) \\binom{x+r-1}{x} \\theta^r (1-\\theta)^x & x&gt;1\n\\end{cases}\n\\tag{12}\n\nRegular Negative Binomial PMF:\n\n\np^*(x) = \\binom{x+r-1}{x} \\theta^r (1-\\theta)^x\n\\tag{13}\n\nZero-inflated Log-Gaussian PDF:\n\n\nf(x) =\n\\begin{cases}\n    \\omega_1 \\delta_0(x) + (1-\\omega_1)\\frac{1}{\\sqrt{2\\pi}\\sigma x}\\exp\\left\\{ -\\frac{(\\ln x - \\mu)^2}{2\\sigma^2} \\right\\} & x &gt; 0 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\tag{14}\nwhere \\delta_0(x) is the Dirac delta function at x=0.\n\n\n\n\nMixture Model (Hierarchical):\n\n\nX \\mid c \\sim G_c, \\quad P(c = k) = \\omega_k\n\\tag{15}\nwhere G_c is the distribution of the k-th component and \\omega_k is the weight for the k-th component.\n\n\n\n\nObserved-data Likelihood for a mixture Model\n\n\nL_O(\\theta, \\omega; x) \\propto p(x \\mid \\theta, \\omega) = \\prod_{i=1}^n \\sum_{k=1}^K \\omega_k g_k(x_i \\mid \\theta_k)\n\\tag{16}\nwhere g_k(x_i \\mid \\theta_k) is the PDF/PMF of the k-th component distribution evaluated at x_i with parameter \\theta_k.\n\nMixture Model (Likelihood, complete-data):\n\n\nL(\\theta, \\omega; x, c) = p(x, c \\mid \\theta, \\omega) = \\prod_{i=1}^n \\prod_{k=1}^K [\\omega_k g_k(x_i \\mid \\theta_k)]^{1(c_i = k)}\n\\tag{17}\nwhere 1(c_i = k) is an indicator function that is 1 if c_i = k and 0 otherwise.\n\nAlternative complete-data likelihood decomposition:\n\n\np(x, c \\mid \\theta, \\omega) = p(x \\mid c, \\theta) p(c \\mid \\omega)\n\\tag{18}\nwith\n\np(x \\mid c, \\theta) = \\prod_{i=1}^n g_{c_i}(x_i \\mid \\theta_{c_i})\n\\tag{19}\n\np(c \\mid \\omega) = \\prod_{k=1}^K \\omega_k^{\\sum_{i=1}^n 1(c_i = k)}\n\\tag{20}\nwhere 1(c_i = k) is an indicator function that is 1 if c_i = k and 0 otherwise.\n\n\n\nLabel switching\nTODO : missing formula\n\nf(x) = ...\n\\tag{21}\nTODO : missing formula\n\nf(x) = ...\n\\tag{22}\nNumber of components\n\nf(x) = ...\n\\tag{23}"
  },
  {
    "objectID": "mixture-math.html#maximum-likelihood-estimation-for-mixture-models",
    "href": "mixture-math.html#maximum-likelihood-estimation-for-mixture-models",
    "title": "Mixture Models",
    "section": "2 2. Maximum Likelihood Estimation For Mixture Models:",
    "text": "2 2. Maximum Likelihood Estimation For Mixture Models:\n\nMaximum Likelihood Estimator (MLE) for Mixture:\n\n\n(\\hat{\\omega}, \\hat{\\theta}) = \\arg\\max_{\\omega, \\theta} \\prod_{i=1}^n \\sum_{k=1}^K \\omega_k g_k(x_i \\mid \\theta_k)\n\\tag{24}\nwhere \\hat{\\omega} and \\hat{\\theta} are the MLEs for the weights and parameters of the mixture components, respectively.\n\n2.1 2.1 EM Algorithm for Mixture Models:\n\nEM algorithm Set Q-function in E step:\n\nE step:\n\nQ(\\omega, \\theta \\mid \\omega^{(t)}, \\theta^{(t)}, x) = \\mathbb{E}_{c \\mid \\omega^{(t)}, \\theta^{(t)}, x} [\\log p(x, c \\mid \\omega, \\theta)]\n\\tag{25}\nwhere Q(\\omega, \\theta \\mid \\omega^{(t)}, \\theta^{(t)}, x) is the expected complete-data log-likelihood given the current estimates of the parameters \\omega^{(t)} and \\theta^{(t)} and the observed data x.\n\nEM algorithm Set parameters in M step:\n\n\n(\\hat{\\omega}^{(t+1)}, \\hat{\\theta}^{(t+1)}) = \\arg\\max_{\\omega, \\theta} Q(\\omega, \\theta \\mid \\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)}, y)   \n\\tag{26}\nwhere (\\hat{\\omega}^{(t+1)}, \\hat{\\theta}^{(t+1)}) are the updated estimates of the parameters after the M step.\n\n\np(c_i = k \\mid \\omega, \\theta, x) = \\frac{\\omega_k g_k(x_i \\mid \\theta_k)}{\\sum_{l=1}^K \\omega_l g_l(x_i \\mid \\theta_l)} = v_{i,k}(\\omega, \\theta)\n\\tag{27}\nwhere v_{i,k}(\\omega, \\theta) is the posterior probability of the k-th component given the observed data x_i and the current estimates of the parameters \\omega and \\theta.\nand (\\hat{\\omega}^{(t+1)}, \\hat{\\theta}^{(t+1)}) are the updated estimates of the parameters after the M step.\nAlso, remember that:\n\np(x, c | \\theta, \\omega) =\n\\prod_{i=1}^n\n\\prod_{k=1}^K\n[\\omega_k g_k(x_i | \\theta_k)]^{\\mathbb{1}(c_i=k)}\n\\tag{28}\nThe value of v_{i,k}(\\omega, \\theta) can be interpreted as the probability that observation i was generated from component k if we assume that the true parameters of the mixture model are \\omega and \\theta.\n\n\np(c_i = k \\mid \\omega, \\theta, x) = \\frac{\\omega_k g_k(x_i \\mid \\theta_k)}{\\sum_{l=1}^K \\omega_l g_l(x_i \\mid \\theta_l)} = v_{i,k}(\\omega, \\theta)\n\\tag{29}\nwhere v_{i,k}(\\omega, \\theta) is the posterior probability of the k-th component given the observed data x_i and the current estimates of the parameters \\omega and \\theta.\nwhich implies that\n\n\\log p(x_i,c \\mid \\theta, \\omega) = \\sum_{n=1}^N \\sum_{k=1}^K \\mathbb{1}(c_i=k) [\\log(\\omega_k) + \\log(g_k(x_i \\mid \\theta_k))]\n\\tag{30}\nwhere \\mathbb{1}(c_i=k) is an indicator function that is 1 if c_i = k and 0 otherwise.\nHence\n\nQ(\\omega, \\theta \\mid \\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)}, x) = \\sum_{i=1}^n \\sum_{k=1}^K v_{i,k} \\mathbb{E}_{c \\mid \\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)}, x} \\left [\\mathbb{1}_{(c_i=k)} \\log(\\omega_k) + \\log(g_k(x_i \\mid \\theta_k))\\right]\n\\tag{31}\nwhere v_{i,k}(\\omega^{(t)}, \\theta^{(t)}) is the posterior probability of the k-th component given the observed data x_i and the current estimates of the parameters \\omega^{(t)} and \\theta^{(t)}.\nand therefore \nQ(\\omega, \\theta \\mid \\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)}, x) = \\sum_{i=1}^n \\sum_{k=1}^K v_{i,k}^{(t+1)}\\left(\\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)}\\right) [\\log(\\omega_k) + \\log(g_k(x_i \\mid \\theta_k))]\n\\tag{32}\nwhere v_{i,k}(\\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)}) is the posterior probability of the k-th component given the observed data x_i and the current estimates of the parameters \\hat{\\omega}^{(t)} and \\hat{\\theta}^{(t)}.\n(Remember that the term that is constant with respect to c can come out of the expectation, and that the expected value of an indicator function is just the probability of the event inside the indicator).\nHence, roughly speaking, we can see that the Q function is in this case equivalent to a weighted average of the log likelihoods associated with each of the components in the mixture."
  },
  {
    "objectID": "mixture-math.html#the-em-algorithm-for-a-location-mixture-of-two-gaussians",
    "href": "mixture-math.html#the-em-algorithm-for-a-location-mixture-of-two-gaussians",
    "title": "Mixture Models",
    "section": "3 2.2 The EM algorithm for a Location Mixture of Two Gaussians",
    "text": "3 2.2 The EM algorithm for a Location Mixture of Two Gaussians\n\nf(x\\mid \\omega, \\mu_1,\\mu_2, \\sigma) = \\omega \\frac{1}{\\sqrt{2\\pi}\\sigma^2} \\exp\\left\\{ -\\frac{(x - \\mu_1)^2}{2\\sigma^2} \\right\\} + (1-\\omega) \\frac{1}{\\sqrt{2\\pi}\\sigma^2} \\exp\\left\\{ -\\frac{(x - \\mu_2)^2}{2\\sigma^2} \\right\\}\n\\tag{33}\nwhere \\omega_1 and \\omega_2 are the weights of the two components, \\mu_1 and \\mu_2 are the means of the two components, and \\sigma^2 is the common variance.\nThe expected weights are:\n\nv^{(t+1)}_{i,1} =v^{(t+1)}_{i,1} \\left (\\hat{\\omega}^{(t)},\\hat{\\mu}^{(t)},\\hat{\\sigma}^{(t)}\\right)=\\frac{\\hat{\\omega}^{(t)}_1 \\frac{1}{\\sqrt{2\\pi}\\hat{\\sigma}^{(t)}} \\exp\\left\\{ -\\frac{(x_i - \\hat{\\mu}^{(t)}_1)^2}{2\\hat{\\sigma}^{(t)}} \\right\\}}{\\sum_{k=1}^K \\hat{\\omega}^{(t)}_k \\frac{1}{\\sqrt{2\\pi}\\hat{\\sigma}^{(t)}} \\exp\\left\\{ -\\frac{(x_i - \\hat{\\mu}^{(t)}_k)^2}{2\\hat{\\sigma}^{(t)}} \\right\\}}\n\\tag{34}\nand\n\nv^{(t+1)}_{i,2} = 1 - v^{(t+1)}_{i,1}\n\nTherefore, the Q function is\n\n\\begin{aligned}\nQ(\\omega, \\mu_1, \\mu_2, \\sigma \\mid \\hat{\\omega}^{(t)}, \\hat{\\mu}^{(t)}_1,\\hat{\\mu}^{(t)}_2, \\hat{\\sigma}^{(t)}, x) = \\sum_{i=1}^n & v_{i,1}^{(t+1)} \\left [\\log(\\omega) - \\frac{1}{2} \\log(2\\pi) - \\log(\\sigma) - \\frac{(x_i - \\mu_1)^2}{2\\sigma^2}\\right ] \\\\\n+ & v_{i,2}^{(t+1)} \\left [\\log(1-\\omega) - \\frac{1}{2} \\log(2\\pi) - \\log(\\sigma) - \\frac{(x_i - \\mu_2)^2}{2\\sigma^2}\\right]\n\\end{aligned}\n\\tag{35}\nwhere v_{i,1}^{(t+1)} and v_{i,2}^{(t+1)} are the posterior probabilities of the first and second components given the observed data x_i and the current estimates of the parameters \\hat{\\omega}^{(t)}, \\hat{\\mu}^{(t)}_1, \\hat{\\mu}^{(t)}_2, and \\hat{\\sigma}^{(t)}.\nThe Q function is a function of the parameters \\omega, \\mu_1, \\mu_2, and \\sigma and is used to update the estimates of these parameters in the M step of the EM algorithm.\nto maximize Q we compute its partial derivatives with respect to \\omega, \\mu_k, and \\sigma and set them equal to zero. The partial derivative with respect to \\omega is:\n\n\\frac{\\partial Q}{\\partial \\omega} = \\sum_{i=1}^n \\left [\\frac{v_{i,1}^{(t+1)}}{\\omega} - \\frac{v_{i,2}^{(t+1)}}{1-\\omega} \\right ] = 0\n\\tag{36}\n\n\\frac{\\partial Q}{\\partial \\mu_k} = \\sum_{i=1}^n v_{i,k}^{(t+1)} \\frac{1}{\\sigma^2} (x_i - \\mu_k) = 0\n\\tag{37}\n\n\\frac{\\partial Q}{\\partial \\sigma} = \\sum_{i=1}^n \\left [\\frac{v_{i,1}^{(t+1)}}{\\sigma} - \\frac{(x_i - \\mu_1)^2}{\\sigma^3} + \\frac{v_{i,2}^{(t+1)}}{\\sigma} - \\frac{(x_i - \\mu_2)^2}{\\sigma^3} \\right ] = 0\n\\tag{38}\nBy setting (Equation 36) equal to zero we get:\n\n\\begin{aligned}\n&\\left \\{ \\sum_{i=1}^n v_{i,2}^{(t+1)} \\right \\}  \\omega^{(t+1)} & = &\n\\left \\{ \\sum_{i=1}^n v_{i,1}^{(t+1)} \\right \\} \\left (1 - \\omega^{(t+1)}\\right)\n\\\\ \\implies & \\left \\{ \\sum_{i=1}^n v_{i,1}^{(t+1)} \\right \\} & = &\n\\left \\{ \\sum_{i=1}^n v_{i,1}^{(t+1)} + \\sum_{i=1}^n v_{i,2}^{(t+1)} \\right \\} \\omega^{(t+1)}\n\\\\ \\implies & \\omega^{(t+1)} & = & \\frac{\\sum_{i=1}^n v_{i,1}^{(t+1)}}{\\sum_{i=1}^n v_{i,1}^{(t+1)} + v_{i,2}^{(t+1)}}\n\\\\ &  &= & \\frac{1}{n} \\sum_{i=1}^n v_{i,1}^{(t+1)}\n\\end{aligned}\n\\tag{39}\nwhere \\omega^{(t+1)} is the updated estimate of the weight for the first component after the M step.\nwhere we used the fact that \\sum_{i=1}^n v_{i,1}^{(t+1)} + \\sum_{i=1}^n v_{i,2}^{(t+1)} = n.\nThis means that the new estimate of \\omega is the average of the posterior probabilities of the first component over all observations.\nby setting (Equation 37) equal to zero we get:\n\\begin{aligned}\n            && 0 && = & \\sum_{i=1}^n v_{i,k}^{(t+1)} (x_i - \\mu_k)\n\\\\ \\implies && \\sum_{i=1}^n v_{i,k}^{(t+1)} x_i && = & \\sum_{i=1}^n v_{i,k}^{(t+1)} \\mu_k\n\\\\ \\implies && \\mu_k^{(t+1)} && = & \\frac{\\sum_{i=1}^n v_{i,k}^{(t+1)} x_i}{\\sum_{i=1}^n v_{i,k}^{(t+1)}}\n\\end{aligned}\n\\tag{40}\nwhere we used the fact that \\sum_{i=1}^n v_{i,k}^{(t+1)} = n.\nNote that the partial estimator for μk is a weighted average of the xis, with the weight associated with observation i being proportional to the probability that such observation was generated by component k. Again, if the components are well separated and values of vi,k are all close to either 0 or 1, this weighted average is roughly the average of the observations coming from component k\nFinally, making the same argument for the partial derivative with respect to σ, we get:\n\n\\begin{aligned}\n&\n    \\sum_{i=1}^n \\sum_{k=1}^K v_{i,k}^{(t+1)} &=& \\left ( \\frac {1}{\\sigma^{(t+1)}} \\right ) ^ 2  \\sum_{i=1}^n \\sum_{k=1}^K v_{i,k}^{(t+1)} (x_i - \\mu_k^{(t+1)})^2\n\\\\ \\implies &\n\\sigma^{(t+1)} &=& \\sqrt{\\frac{\\sum_{i=1}^n \\sum_{k=1}^K v_{i,k}^{(t+1)} (x_i - \\mu_k^{(t+1)})^2}{\\sum_{i=1}^n \\sum_{k=1}^K v_{i,k}^{(t+1)}}}\n\\end{aligned}\n\\tag{41}\n\n3.1 2.3 general location and scale mixtures of p-variate gaussian distributions\n\nf(x) =\n\\sum_{k=1}^K\n\\omega_k\n\\left( \\frac{1}{(2\\pi)} \\right) ^\\frac{q}{2}\n|\\Sigma_k|-\\frac{1}{2} \\exp\n\\left\\{\n(x - \\theta_k)^T \\Sigma_k^{-1}(x - \\theta_k)\n\\right\\}\n\\tag{42}\nwhere \\theta_k is the mean of the k-th component, \\Sigma_k is the covariance matrix of the k-th component, and \\omega_k is the weight for the k-th component. \n\\begin{aligned}\nv_{i,k}^{(t+1)} &= \\frac{\\omega_k^{(t)} |\\Sigma_k^{(t)}|^{-1/2} \\exp\\left\\{-\\frac{1}{2}(x_i - \\mu_k^{(t)})^T [\\Sigma_k^{(t)}]^{-1}(x_i - \\mu_k^{(t)})\\right\\}}{\\sum_{l=1}^K \\omega_l^{(t)} |\\Sigma_l^{(t)}|^{-1/2} \\exp\\left\\{-\\frac{1}{2}(x_i - \\mu_l^{(t)})^T [\\Sigma_l^{(t)}]^{-1}(x_i - \\mu_l^{(t)})\\right\\}} \\\\\n\\omega_k^{(t+1)} &= \\frac{\\sum_{i=1}^n v_{i,k}^{(t+1)}}{\\sum_{i=1}^n \\sum_{l=1}^K v_{i,l}^{(t+1)}} \\\\\n\\mu_k^{(t+1)} &= \\frac{\\sum_{i=1}^n v_{i,k}^{(t+1)} x_i}{\\sum_{i=1}^n v_{i,k}^{(t+1)}} \\\\\n\\Sigma_k^{(t+1)} &= \\frac{\\sum_{i=1}^n v_{i,k}^{(t+1)} (x_i - \\mu_k^{(t+1)}) (x_i - \\mu_k^{(t+1)})^T}{\\sum_{i=1}^n v_{i,k}^{(t+1)}}\n\\end{aligned}\n\\tag{43}\nwhere v_{i,k}^{(t+1)} is the posterior probability of the k-th component given the observed data x_i and the current estimates of the parameters \\omega^{(t)}, \\mu^{(t)}, and \\Sigma^{(t)}."
  },
  {
    "objectID": "mixture-math.html#mcmc",
    "href": "mixture-math.html#mcmc",
    "title": "Mixture Models",
    "section": "4 3. MCMC",
    "text": "4 3. MCMC\n\nf(x) = \\sum_{k=1}^K \\omega_k g_k(x | \\theta_k)\n\\tag{44}\nwhere g_k(x \\mid \\theta_k) is the PDF/PMF of the k-th component distribution evaluated at x with parameter \\theta_k.\n\np(\\omega) \\;=\\;\n\\frac{\\Gamma \\bigl ( \\sum_{k=1}^K a_k \\bigr ) }{\\prod_{k=1}^K \\Gamma(a_k)}\n\\prod_{k=1}^K \\omega_k^{\\,a_k-1},\n\\quad\n\\sum_{k=1}^K \\omega_k = 1\n\\tag{45}\n\n4.1 3.1 Markov chain monte carlo algorithms for mixture mod-\nels\n\np(x, c \\mid \\theta, \\omega) = p(x \\mid c, \\theta)\\ p(c \\mid \\omega)\n\\tag{46}\nwhere\n\np(x \\mid c, \\theta) = \\prod_{i=1}^n g_{c_i}(x_i \\mid \\theta_{c_i})\n\\tag{47}\nand\n\np(c \\mid \\omega) = \\prod_{i=1}^n \\prod_{k=1}^K\n\\omega_k ^{\\mathbb{1}(c_i = k)} =\n\\prod_{k=1}^K \\omega_k^{\\sum_{i=1}^n \\mathbb{1}(c_i = k)}\n\\tag{48}\nwhere 1(c_i = k) is an indicator function that is 1 if c_i = k and 0 otherwise.\n\nJoint posterior (with latent labels)\n\n\np(c,\\theta,\\omega \\mid x)\n\\;\\propto\\;\n\\Bigl(\\prod_{i=1}^n g_{c_i}(x_i\\mid \\theta_{c_i})\\Bigr)\n\\Bigl(\\prod_{k=1}^K \\omega_k^{\\sum_{i=1}^n1(c_i=k)}\\Bigr)\n\\,p(\\omega)\\,p(\\theta)\n\\tag{49}\nEach of the full conditional distributions can be derived from this joint posterior by retaining the terms that involve the parameter of interest, and recognizing the product of the selected terms as the kernel of a known family of distributions.\n\nFull conditional for \\omega\n\n\np(\\omega \\mid c,\\theta,x)\n\\;\\propto\\;\np(c \\mid \\omega) p(\\omega)\n\\;=\\;\n\\prod_{k=1}^K\n\\omega_k^{\\,a_k + \\sum_{i=1}^n1(c_i=k)\\;-\\;1}\n\\tag{50}\nThis clearly corresponds to the kernel of another Dirichlet distribution with updated parameters \na_k^* = a_k + m_k, \\qquad k = 1, \\ldots, K,\n\nwhere m_k = \\sum_{i=1}^n 1(c_i = k) is the number of observations in component k.\nFull conditional for each component c_i\n\np(c_i \\mid c,\\theta_1,\\ldots,\\theta_{k-1},\\omega,x) \\propto p(x_i \\mid c_i,\\theta_k) p(c_i \\mid \\omega)\n\\tag{51}\nhence\n\np(c_i = k \\mid c,\\theta_1,\\ldots,\\theta_{k-1},\\omega,x)\n\\;=\\;\n\\frac{\\omega_k\\,g_k(x_i\\mid \\theta_k)}\n     {\\sum_{l=1}^K \\omega_l\\,g_l(x_i\\mid \\theta_l)}\n\\tag{52}\nNote the similarity with the formula for the expected weights v_{i,k} in the EM algorithm.)\nFull conditional for component parameters \\theta_k\n\np(\\theta_k \\mid c,\\theta_1,\\ldots,\\theta_{k-1},\\omega,x)\n\\;\\propto\\;\np(\\theta_k \\mid c,\\theta_1,\\ldots,\\theta_{k-1},\\omega,x)\n\\prod_{i:c_i=k} p(x_i\\mid \\theta_k)\n\\tag{53}\nIn the most common case in which the priors for \\theta_k are independent this is simply:\n\np(\\theta_k \\mid c,\\theta_1,\\ldots,\\theta_{k-1},\\omega,x)\n\\;\\propto\\;\np(\\theta_k) \\prod_{i:c_i=k} p(x_i\\mid \\theta_k)\n\\tag{54}\n\n\n4.2 3.2 The MCMC algorithm for a location mixture of two gaussian distributions\n\nf(x \\mid \\omega, \\mu_1, \\mu_2, \\sigma) = \\omega \\frac{1}{\\sqrt{2\\pi}\\sigma^2} \\exp\\left\\{ -\\frac{(x - \\mu_1)^2}{2\\sigma^2} \\right\\} + (1-\\omega) \\frac{1}{\\sqrt{2\\pi}\\sigma^2} \\exp\\left\\{ -\\frac{(x - \\mu_2)^2}{2\\sigma^2} \\right\\}\n\\tag{55}\n\nGaussian prior for means \\mu\\_k\n\n\np(\\mu_k)\n=\\frac{1}{\\sqrt{2\\pi\\tau^2}}\n\\exp\\!\\Bigl\\{-\\tfrac{(\\mu_k-\\eta)^2}{2\\tau^2}\\Bigr\\}\n\\tag{56}\n\nInverse-Gamma prior for variance \\sigma^2:\n\nwith shape parameter a and scale parameter b for \\sigma\n\np(\\sigma^2)\n=\\frac{1}{b^a\\Gamma(a)}\n(\\sigma^2)^{-\\,d-1}\n\\exp\\!\\Bigl\\{-\\tfrac{q}{\\sigma^2}\\Bigr\\}\n\\tag{57}\n$$\n\\begin{aligned}\np(\\mu_k \\mid c, \\mu_1, \\ldots, \\mu_{k-1}, \\mu_{k+1}, \\ldots, \\mu_K, \\omega, x)\n& \\;\\propto\\;\n\\exp\\Biggl\\{\n-\\frac{(\\mu_k - \\eta)^2}{2\\tau^2}\n\\Biggr\\} \\prod_{i:c_i=k}\n\\exp\\Biggl\\{\n-\\frac{(x_i - \\mu_k)^2}{2\\sigma^2}\n\\Biggr\\}\n\\\\ & \\;\\propto\\;\n\\exp\\Biggl\\{\n-\\frac{1}{2}\n\\Biggl[ m_k \\frac{1}{\\sigma^2} - 2 \\frac{\\mu_k \\sum_{i:c_i=k} x_i}{\\sigma^2} + \\frac{\\mu_k}{\\tau^2} - 2 \\frac{\\mu_k\\eta}{\\tau^2} \\Biggr] \\Biggr\\}\n\\\\ & \\;\\propto\\;\n\\exp\\Biggl\\{\n-\\frac{1}{2}\n\\Biggl[ \\frac{m_k}{\\sigma^2} + \\frac{1}{\\tau^2} \\Biggr] \\Biggl[ \\mu_k - \\frac{\\sigma^2 \\sum_{i:c_i=k} x_i + \\frac{\\eta}{\\tau^2} }{\\mu_k + \\frac{m_k}{\\sigma^2}+ \\frac{1}{\\tau^2}} \\Biggr] \\Biggr\\}\n\n\\end{aligned}\n$$ {#eq-fullcond-mu_k}\nwhich is just the kernel of a normal distribution with updated mean\n\n\\eta_k^* = \\frac{\\frac{1}{\\sigma^2}\\sum_{i:c_i=k} x_i + \\frac{\\eta}{\\tau^2}}{ \\frac{m_k}{\\sigma^2}+ \\frac{1}{\\tau^2}u^2}\n\\tag{58}\nand updated standard deviation\n\n\\tau_k^*=\\Bigl[ \\frac{m_k}{\\sigma^2}+ \\frac{1}{\\tau^2} \\Bigr]^{-1/2}\n\\tag{59}\nfinaly\n\n\\begin{aligned}\np(\\sigma^2 | c, \\mu, \\omega, x)\n&\\propto\n\\Biggl(\\frac{1}{\\sigma^2}\\Biggr)^{d+1}\n\\exp\\Biggl\\{\n− q\n\\sigma^2\n\\Biggr\\}\n\\Biggl(\\frac{1}{\\sigma^2}\\Biggr)^{n/2}\n\\exp\\Biggl\\{\n− \\frac{1}{2\\sigma^2}\n\\sum_{i=1}^{n}(x_i − \\mu_{c_i})^2\n\\Biggr\\}\n\\\\&=\n\\Biggl(\\frac{1}{\\sigma^2}\\Biggr)^{n/2+d+1}\n\\exp\\Biggl\\{\n− \\frac{1}{\\sigma^2}\n\\Biggl[ \\frac{1}{2} \\sum_{i=1}^{n}(x_i − \\mu_{c_i})^2\n+ q\n\\Biggr]\n\\Biggr\\}\n\\end{aligned}\n\nwhich is the kernel of another inverse Gamma distribution with shape d∗ =n/2 + d and rate parameter\n\nq^*=\\tfrac12\\sum_{i=1}^n(x_i-\\mu_{c_i})^2 + q\n\\tag{60}\n\n\n4.3 3.3 general location and scale mixtures of p-variate gaus-\nsian distributions\n\nGeneral q-variate Gaussian mixture\n\n\n\\sigma^2 \\;\\sim\\;\\mathrm{InvGamma}\\bigl(d^*,\\,q^*\\bigr),\n\\quad\nd^*=\\tfrac{n}{2}+d,\n\\quad\nq^*=\\tfrac12\\sum_{i=1}^n(x_i-\\mu_{c_i})^2 + q\n\\tag{61}\n\nf(x)\n=\\sum_{k=1}^K\n\\omega_k\\,\n\\frac{1}{(2\\pi)^{q/2}\\,\\lvert\\Sigma_k\\rvert^{1/2}}\\,\n\\exp\\!\\Bigl\\{-\\tfrac12(x-\\mu_k)^\\top\\Sigma_k^{-1}(x-\\mu_k)\\Bigr\\}\n\\tag{62}\n\nPosterior for multivariate \\mu\\_k\n\n\n\\mu_k \\;\\sim\\; N\\bigl(b_k^*,\\,B_k^*\\bigr),\n\\quad\nB_k^*=\\bigl(B^{-1}+m_k\\,\\Sigma_k^{-1}\\bigr)^{-1},\n\\quad\nb_k^*=B_k^*\\bigl(B^{-1}b + \\Sigma_k^{-1}\\sum_{i:c_i=k}x_i\\bigr)\n\\tag{63}\n\nPosterior for multivariate \\Sigma\\_k\n\n\n\\Sigma_k \\;\\sim\\;\\mathrm{InvWishart}\\bigl(\\nu^*,\\,S^*\\bigr),\n\\quad\n\\nu^*=\\nu + m_k,\n\\quad\nS^*=S + \\sum_{i:c_i=k}(x_i-\\mu_k)(x_i-\\mu_k)^\\top\n\\tag{64}"
  },
  {
    "objectID": "mixture-math.html#applications-of-mixture-models",
    "href": "mixture-math.html#applications-of-mixture-models",
    "title": "Mixture Models",
    "section": "5 4. Applications of Mixture Models",
    "text": "5 4. Applications of Mixture Models\n\n5.1 4.1 density estimation\n\nKernel density estimator (general form)\n\n\n\\tilde f(x)\n=\\frac{1}{n}\\sum_{i=1}^n\\frac{1}{h}\\,\ng \\Bigl(\\tfrac{\\|x-x_i \\| }{h}\\Bigr)\n\\tag{65}\n\nGaussian kernel density estimator\n\n\n\\tilde f(x)\n=\\sum_{i=1}^n\\frac{1}{n}\\,\n\\tfrac{1}{\\sqrt{2\\pi\\,}h}\\,\n\\exp\\!\\Bigl\\{-\\tfrac{1}{2}\\left(\\dfrac{x-x_i}{h}\\right)^2\\Bigr\\}\n\\tag{66}\nIn order to understand the relationship between kernel density estimation and mixture models it is useful to contrast (8) with the density estimate \n\\hat f(x) = \\sum_{k=1}^K \\hat{\\omega}_k \\frac{1}{\\sqrt{2\\pi} \\hat{\\sigma}} \\exp\\Biggl\\{-\\frac{1}{2\\hat{\\sigma}^2}(x - \\hat{\\mu}_k)^2\\Biggr\\}\n\nobtained by plugging-in the maximum likelihood estimates of the parameters, \\hat{\\omega}_1, . . . , \\hat{\\omega}_K, \\hat{\\mu}_1, . . . , \\hat{\\mu}_K and \\hat{\\sigma} of a location mixture of K univariate Gaussian distributions.\n\n\n5.2 4.2 clustering (unsupervised classification\n\nf(x) = \\sum_{k=1}^K \\frac{1}{K} \\left(\\frac{1}{\\sqrt{2\\pi\\sigma}} \\right)^p \\exp\\left\\{-\\frac{1}{2\\sigma^2} (x − \\mu_k)^T (x − \\mu_k)\\right\\}\n\\tag{67}\n\n\n5.3 4.3 (supervised) classification"
  },
  {
    "objectID": "mixture-math.html#practical-considerations",
    "href": "mixture-math.html#practical-considerations",
    "title": "Mixture Models",
    "section": "6 5. Practical Considerations",
    "text": "6 5. Practical Considerations\n\n6.1 5.1 Ensuring numerical stability when computing class probabilities\n\n\\begin{aligned}\n\\frac{z_k}{\\sum_{l=1}^K z_l} &= \\frac{\\exp\\{ \\log z_k \\}}{\\sum_{l=1}^K \\exp\\left\\{ \\log z_l \\right\\}} &&  \\text{(exp and log are inverse\nfunctions)}\\\\\n&= \\frac{\\exp\\{ -b \\}\\exp\\{ \\log z_k \\}}{\\exp\\{ -b \\}\\sum_{l=1}^K \\exp\\left\\{ \\log z_l \\right\\}} && \\text{(multiply and divide by\nthe same quantity)} \\ e^{-b} \\\\\n&= \\frac{\\exp\\left\\{ \\log z_k - b \\right\\}}{\\sum_{l=1}^K \\exp\\left\\{ \\log z_l - b \\right\\}} \\\\\n\\end{aligned}\n\\tag{68}\nAlthough (11) is valid for any b, it should be clear that some values will work better than others for the purpose of avoiding a 0/0 calculation. In particular, we are interested in choosing a value b that makes at least one of the terms in the denominator different from zero after exponentiation. One such choice is b=\\max_{l=1,\\ldots,K} \\log z_l, which gives us\n\n\\sum_{l=1}^K \\exp\\left\\{ \\log z_l - \\max_{l=1,\\ldots,K} \\log z_l \\right\\} = 1 + \\sum_{l:l \\neq l^*} \\exp\\left\\{ \\log z_l - \\max_{l=1,\\ldots,K} \\log z_l \\right\\}\n\nOne key advantage of this choice is that all the terms in the sum are less or equal than one, which ensures that we do not overflow when computing \\exp\\left\\{ \\log z_l - \\max_{l=1,\\ldots,K} \\log z_l \\right\\}.\n\n\n6.2 5.2 numerical consequences of multimodality\nno math in this section\n\n\n6.3 5.3 selecting the number components\n\n\\text{BIC} = -2 \\ell(\\hat{\\theta}) + p \\log(n)\n\nwhere \\ell(\\hat{\\theta}) is the maximized log-likelihood, p is number of free parameters, n is sample size.\n\n\n6.4 5.4 fully Bayesian inference on the number of components\n\nf(x) = \\sum_{k=1}^K \\omega_k g_k(x | \\theta_k) + \\sum_{k=K+1}^K 0g_k(x | \\theta_k)\n\n\n(\\omega_1, \\ldots, \\omega_K) \\sim Dirichlet( \\frac{1}{K}, \\ldots , \\frac{1}{K} )\n\nwhere K is the number of components in the mixture model.\n\n\\mathbb{E}(K^*)=\\sum_{i=1}^m \\frac{\\alpha}{\\alpha + i - 1} \\approx \\frac{\\alpha \\log(n + \\alpha -1) }{\\alpha}\n\\tag{69}\nwhere \\alpha is the concentration parameter of the Dirichlet process prior, n is the number of observations, and K^* is the number of components in the mixture model.\n\n\n6.5 5.5 fully Bayesian inference on the partition structure\nExtracting formulas from Section 4.2 (“Clustering (unsupervised classification)”) to the end of mixturemodels (2).pdf:"
  },
  {
    "objectID": "mixture-math.html#section-4.2-clustering-unsupervised-classification-formulas",
    "href": "mixture-math.html#section-4.2-clustering-unsupervised-classification-formulas",
    "title": "Mixture Models",
    "section": "7 Section 4.2: Clustering (Unsupervised Classification) — Formulas",
    "text": "7 Section 4.2: Clustering (Unsupervised Classification) — Formulas\n\n7.1 1. Hard assignment (mode assignment for EM):\n\n\\hat{c}_i = \\arg\\max_k \\hat{v}_{i,k}\n\nwhere \\hat{v}_{i,k} are the final iteration weights.\n\n\n\n7.2 2. Posterior Probability of Cluster Assignment (Bayesian approach):\n\nP(c_i = k \\mid x, \\text{rest}) = v_{i,k}\n\nwhere v_{i,k} is as defined in the EM/MCMC steps (probability that observation i comes from component k)."
  },
  {
    "objectID": "mixture-math.html#section-4.3-supervised-classification",
    "href": "mixture-math.html#section-4.3-supervised-classification",
    "title": "Mixture Models",
    "section": "8 Section 4.3: (Supervised) Classification",
    "text": "8 Section 4.3: (Supervised) Classification\n\n8.1 3. Posterior probability of class membership (LDA/QDA/Mixture discriminant analysis):\n\nP(Y = k \\mid X = x) = \\frac{\\pi_k f_k(x)}{\\sum_{l=1}^K \\pi_l f_l(x)}\n\nwhere \\pi_k is prior class probability, f_k(x) is the class-conditional density for class k.\n\n\n\n8.2 4. For a mixture model:\n\nf_k(x) = \\sum_{j=1}^{M_k} w_{k,j} g_{k,j}(x)\n\nwhere each class-conditional density can itself be a mixture (with weights w_{k,j} and kernels g_{k,j}(x)).\n\n\n\n8.3 5. Posterior probability for classification under mixture model:\n\nP(Y = k \\mid X = x) = \\frac{\\pi_k \\sum_{j=1}^{M_k} w_{k,j} g_{k,j}(x)}{\\sum_{l=1}^K \\pi_l \\sum_{j=1}^{M_l} w_{l,j} g_{l,j}(x)}"
  },
  {
    "objectID": "mixture-math.html#section-5-practical-considerations",
    "href": "mixture-math.html#section-5-practical-considerations",
    "title": "Mixture Models",
    "section": "9 Section 5: Practical Considerations",
    "text": "9 Section 5: Practical Considerations\n\n9.1 6. Log-sum-exp trick (for numerical stability):\n\n\\log \\left( \\sum_{k=1}^K e^{a_k} \\right) = a_{k^*} + \\log \\left( \\sum_{k=1}^K e^{a_k - a_{k^*}} \\right)\n\nwhere a_{k^*} = \\max\\{a_1, \\ldots, a_K\\}.\n\n\n\n9.2 7. Bayesian Information Criterion (BIC):\n\n\\text{BIC} = -2 \\ell(\\hat{\\theta}) + p \\log(n)\n\nwhere \\ell(\\hat{\\theta}) is the maximized log-likelihood, p is number of free parameters, n is sample size.\n\n\n\n9.3 8. Dirichlet process partition probability:\n\nP(c_1, \\ldots, c_n) = \\frac{\\alpha^K \\prod_{k=1}^K (n_k - 1)!}{\\prod_{j=1}^n (\\alpha + j - 1)}\n\nwhere K is number of clusters, n_k is number of points in cluster k, \\alpha is the concentration parameter."
  },
  {
    "objectID": "c03-mixtures/component-assignment-problem/index.html",
    "href": "c03-mixtures/component-assignment-problem/index.html",
    "title": "Component Assignment Problem",
    "section": "",
    "text": "Consider a mixture of three Gaussian distribution with common identity covariance matrix and means \\mu_1 =(0,0)' mu, start subscript, 1, end subscript, equals, left parenthesis, 0, comma, 0, right parenthesis, prime, \\mu_2`=(1/3,1/3)' \\mu3 =(−2/3,1/3)'\nFor an observation x_i =(31,−23), the probability of the observation being generated by the second component (rounded to three decimal places)?\nis given by\n\n0.98\n1.00\n0.97\n\nThis is correct. The following code computes the value of interest. Note that the calculations have been done in the log-likelihood scale. Working in the original likelihood scale in this case leads to a wrong answer rather than an error.\nSo I could eyeball it and it has to be 0&gt;0.3 and less than 1.0. So the answer is 0.97. The other two options are not possible. I could have also used the round function to round it to three decimal places.\nHowever we can also use the following based on material from the course to compute the value of interest.\n\n\nCode\nlibrary(mvtnorm)\n\nmu1 = c(0, 0)\nmu2 = c(1/3, 1/3)\nmu3 = c(-2/3, 1/3)\nx = c(31, -23)\nSigma = diag(1,2)\n\nl1 = dmvnorm(x, mu1, Sigma, log=T)\nl2 = dmvnorm(x, mu2, Sigma, log=T)\nl3 = dmvnorm(x, mu3, Sigma, log=T)\n\nexp(l2 - max(l1,l2,l3))/(exp(l1 - max(l1,l2,l3)) + exp(l2 - max(l1,l2,l3)) + exp(l3 - max(l1,l2,l3)))\n\n\n[1] 0.9279459"
  },
  {
    "objectID": "c03-mixtures/m1-basics/two-norm-mix/index.html",
    "href": "c03-mixtures/m1-basics/two-norm-mix/index.html",
    "title": "Mixture of two Gaussian distributions",
    "section": "",
    "text": "Generate n observations from a mixture of two Gaussian distributions\n\n\n\nCode\nn     = 50           # Size of the sample to be generated\nw     = c(0.6, 0.4)  # Weights\nmu    = c(0, 5)      # Means\nsigma = c(1, 2)      # Standard deviations\ncc    = sample(1:2, n, replace=T, prob=w)\nx     = rnorm(n, mu[cc], sigma[cc])\n\n\n\n\nCode\n# Plot f(x) along with the observations \n# just sampled\nxx = seq(-5, 12, length=200)\nyy = w[1]*dnorm(xx, mu[1], sigma[1]) + \n     w[2]*dnorm(xx, mu[2], sigma[2])\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\npoints(x, y=rep(0,n), pch=1)  \n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nSo this is pretty ugly code even for R. The variable names are great at confusing the reader - particularly as they are drawn from complex mathematical formulations omitted from the samples.\nAlso there is a number of Gaussian mixture models in this module, it may be worth whole to convert these snippets into functions.\n\n\nCode\n# Generate sample from a Gaussian mixture\ngen_mixture &lt;- function(components_n=2, samples_n=200, w, mu, sigma) {\n  stopifnot(length(w) == components_n, \n            length(mu) == components_n, \n            length(sigma) == components_n)\n  \n  component_ids &lt;- sample(1:components_n, samples_n, replace=TRUE, prob=w)\n  rnorm(samples_n, mean=mu[component_ids], sd=sigma[component_ids])\n}\n\n# Plot the mixture density and sample\nplot_mixture &lt;- function(x, w, mu, sigma, n_grid=200) {\n  xx &lt;- seq(min(x) - 3, max(x) + 3, length.out = n_grid)\n  yy &lt;- rowSums(sapply(1:length(w), function(k) w[k] * dnorm(xx, mu[k], sigma[k])))\n  \n  par(mar=c(4,4,1,1)+0.1)\n  plot(xx, yy, type=\"l\", ylab=\"Density\", xlab=\"x\", las=1, lwd=2)\n  points(x, y=rep(0, length(x)), pch=1)\n}\n\n\n\n\nCode\nsim1 &lt;- gen_mixture(components_n=2,samples_n=200, w=w, mu=mu, sigma=sigma)\n#sim1\nabc=plot_mixture(x=sim1,w=w,mu=mu,sigma=sigma)"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/honnors/index.html",
    "href": "c03-mixtures/m3-mcmc/honnors/index.html",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "",
    "text": "Example of an MCMC algorithm for fitting a location mixture of 2 Gaussian components\nThe algorithm is tested using simulated data"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/honnors/index.html#clear-the-environment-and-load-required-libraries",
    "href": "c03-mixtures/m3-mcmc/honnors/index.html#clear-the-environment-and-load-required-libraries",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "1 Clear the environment and load required libraries",
    "text": "1 Clear the environment and load required libraries\n\n\nCode\nrm(list=ls())\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\nset.seed(81196)  # So that results are reproducible"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/honnors/index.html#simulating-synthetic-data",
    "href": "c03-mixtures/m3-mcmc/honnors/index.html#simulating-synthetic-data",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "2 Simulating synthetic data",
    "text": "2 Simulating synthetic data\n\n\nCode\n## Generate data from a mixture with 2 components\nKK         = 2\nw.true     = 0.6  # True weights associated with the components\nmu.true    = rep(0, KK)\nmu.true[1] = 0   # True mean for the first component\nmu.true[2] = 5   # True mean for the second component\nsigma.true = 1   # True standard deviation of all components\nn          = 120         # Number of observations to be generated\ncc.true = sample(1:KK, n, replace=T, prob=c(w.true,1-w.true))\nx  = rep(0, n)\nfor(i in 1:n){\n  x[i] = rnorm(1, mu.true[cc.true[i]], sigma.true)\n}"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/honnors/index.html#plot-the-true-density",
    "href": "c03-mixtures/m3-mcmc/honnors/index.html#plot-the-true-density",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "3 Plot the true density",
    "text": "3 Plot the true density\n\n\nCode\n# Plot the true density\npar(mfrow=c(1,1))\nxx.true = seq(-8,11,length=200)\nyy.true = w.true*dnorm(xx.true, mu.true[1], sigma.true) + \n  (1-w.true)*dnorm(xx.true, mu.true[2], sigma.true) \nplot(xx.true, yy.true, type=\"l\", xlab=\"x\", ylab=\"True density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/honnors/index.html#run-the-actual-mcmc-algorithm",
    "href": "c03-mixtures/m3-mcmc/honnors/index.html#run-the-actual-mcmc-algorithm",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "4 Run the actual MCMC algorithm",
    "text": "4 Run the actual MCMC algorithm\n\n\nCode\n## Initialize the parameters\nw     = 1/2                         #Assign equal weight to each component to start with\nmu    = rnorm(KK, mean(x), sd(x))   #Random cluster centers randomly spread over the support of the data\nsigma = sd(x)                       #Initial standard deviation\n\n# Plot the initial guess for the density\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(yy)), xlab=\"x\", \n     ylab=\"Initial density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\n\nCode\n## The actual MCMC algorithm starts here\n# Priors\naa  = rep(1,KK)  # Uniform prior on w\neta = 0          # Mean 0 for the prior on mu_k\ntau = 5          # Standard deviation 5 on the prior for mu_l\ndd  = 2\nqq  = 1\n\n# Number of iterations of the sampler\nrrr   = 6000\nburn  = 1000\n\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = rep(0, rrr)\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = rep(0, rrr)\nlogpost   = rep(0, rrr)\n\n# MCMC iterations\nfor(s in 1:rrr){\n  # Sample the indicators\n  cc = rep(0,n)\n  for(i in 1:n){\n    v = rep(0,KK)\n    v[1] = log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)  #Compute the log of the weights\n    v[2] = log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)  #Compute the log of the weights\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n\n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n\n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(rinvgamma(1, dd.star, qq.star))\n\n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s]     = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    if(cc[i]==1){\n      logpost[s] = logpost[s] + log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)\n    }else{\n      logpost[s] = logpost[s] + log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)\n    }\n  }\n  logpost[s] = logpost[s] + dbeta(w, aa[1], aa[2],log = T)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log = T)\n  }\n  logpost[s] = logpost[s] + log(dinvgamma(sigma^2, dd, 1/qq))\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\""
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/honnors/index.html#plot-the-logposterior-distribution-for-various-samples",
    "href": "c03-mixtures/m3-mcmc/honnors/index.html#plot-the-logposterior-distribution-for-various-samples",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "5 Plot the logposterior distribution for various samples",
    "text": "5 Plot the logposterior distribution for various samples\n\n\nCode\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\nxx = seq(-8,11,length=200)\ndensity.posterior = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  density.posterior[s,] = density.posterior[s,] + w.out[s+burn]*dnorm(xx,mu.out[s+burn,1],sigma.out[s+burn]) +\n                                                  (1-w.out[s+burn])*dnorm(xx,mu.out[s+burn,2],sigma.out[s+burn])\n}\ndensity.posterior.m = apply(density.posterior , 2, mean)\ndensity.posterior.lq = apply(density.posterior, 2, quantile, 0.025)\ndensity.posterior.uq = apply(density.posterior, 2, quantile, 0.975)\n\n\n\n\n\n\n\n\nFigure 1: Trace plots of the MCMC samples\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.posterior.m, type=\"n\",ylim=c(0,max(density.posterior.uq)), xlab=\"x\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.posterior.lq, rev(density.posterior.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.posterior.m, lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\nFigure 2: Posterior density estimates"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html",
    "href": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html",
    "title": "Zero-Inflated Poisson Mixture Models",
    "section": "",
    "text": "NoteGrading Criteria\n\n\n\n\n\nThe code you generate should follow the same structure as “Sample code for MCMC example 1”. In particular, focus on a Gibss sampler that alternates between the full conditionals for w, \\lambda and the latent component indicators c_1 \\ldots c_n. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect the fact that\n\nparameters have been initialized in a reasonable way,\neach of the two full conditional distributions associated with the sampler are correct, and\nthe numerical values that you obtain are correct.\n\n\nTo simplify the peer-review process, assume that component 1 corresponds to the point mass at zero, while component 2 corresponds to the Poisson distribution.\n\n\n\nn        = length(x)\ncc       = rep(0, n)\ncc[x==0] = sample(1:2, sum(x==0), replace=T, prob=c(1/2, 1/2))\ncc[x!=0] = 2\nlambda   = mean(x)\nw        = 0.2\nIs the full conditional for the indicators c_i correct?\nHence, the code to sample the indicators might look something like this:\n  # Full conditional for cc\n  for(i in 1:n){\n    v = rep(0,2)\n    if(x[i]==0){\n      v[1] = log(w)\n      v[2] = log(1-w) + dpois(x[i], lambda, log=TRUE)\n      v    = exp(v - max(v))/sum(exp(v - max(v)))\n    }else{\n      v[1] = 0\n      v[2] = 1\n    }\n    cc[i] = sample(1:2, 1, replace=TRUE, prob=v)\n  }\n\n\n\n # Full conditional for w\n  w = rbeta(1, 1+sum(cc==1), 1+n-sum(cc==1))\nor, alternatively,\n  # Full conditional for w\n  w = rbeta(1, 1+sum(cc==1), 1+sum(cc==2))\nIs the full conditional for the rate lambda correct?\nlambda = rgamma(1, sum(x[cc==2]) + 1, sum(cc==2) + 1)\nf(x)=w\\delta_0(x)+(1-w) \\frac{\\lambda^x}{x!} e^{-\\lambda}\n\\tag{1}\nwhere w is the weight of the zero-inflated component, \\delta_0(x) is the Dirac delta function at 0, and (1-w) \\frac{x!}{\\lambda^x} e^{-\\lambda} is the Poisson distribution with parameter \\lambda.\nIn carrying out this assignment assume the following priors for your unknown parameters:\n\\begin{aligned}\nw &\\sim \\text{Uniform}(0,1) \\\\\n\\lambda &\\sim \\text{Exponential}(1) \\\\\n\\end{aligned}\n where"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html#are-the-parameters-initialized-in-a-reasonable-way",
    "href": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html#are-the-parameters-initialized-in-a-reasonable-way",
    "title": "Zero-Inflated Poisson Mixture Models",
    "section": "",
    "text": "n        = length(x)\ncc       = rep(0, n)\ncc[x==0] = sample(1:2, sum(x==0), replace=T, prob=c(1/2, 1/2))\ncc[x!=0] = 2\nlambda   = mean(x)\nw        = 0.2\nIs the full conditional for the indicators c_i correct?\nHence, the code to sample the indicators might look something like this:\n  # Full conditional for cc\n  for(i in 1:n){\n    v = rep(0,2)\n    if(x[i]==0){\n      v[1] = log(w)\n      v[2] = log(1-w) + dpois(x[i], lambda, log=TRUE)\n      v    = exp(v - max(v))/sum(exp(v - max(v)))\n    }else{\n      v[1] = 0\n      v[2] = 1\n    }\n    cc[i] = sample(1:2, 1, replace=TRUE, prob=v)\n  }"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html#is-the-full-conditional-for-the-weight",
    "href": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html#is-the-full-conditional-for-the-weight",
    "title": "Zero-Inflated Poisson Mixture Models",
    "section": "",
    "text": "# Full conditional for w\n  w = rbeta(1, 1+sum(cc==1), 1+n-sum(cc==1))\nor, alternatively,\n  # Full conditional for w\n  w = rbeta(1, 1+sum(cc==1), 1+sum(cc==2))\nIs the full conditional for the rate lambda correct?\nlambda = rgamma(1, sum(x[cc==2]) + 1, sum(cc==2) + 1)"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html#mcmc",
    "href": "c03-mixtures/m3-mcmc/zero-inflated-mx/index.html#mcmc",
    "title": "Zero-Inflated Poisson Mixture Models",
    "section": "3 MCMC",
    "text": "3 MCMC\n\n\nCode\nrm(list=ls())\nlibrary(MCMCpack)\nset.seed(81196)  # So that results are reproducible\n\n\n# Data loading\nx &lt;- read.csv(\"nestsize.csv\")[[1]]\nn &lt;- length(x)\n\n# The actual MCMC algorithm starts here\n\n## MCMC iterations of the sampler\nburn &lt;- 1000\niterations &lt;- 6000\n\n## Initialize the parameters\ncc         = rep(2, n)\ncc[x == 0] = sample(1:2, sum(x == 0), replace = TRUE, prob = c(0.5, 0.5))\n\n## Priors\naa = c(1, 1)  # Uniform prior on w\nw     = 0.2 # fewer zeros\nlambda = mean(x[x &gt; 0])  # Initial lambda from nonzero data\n\n\n# Storing the samples\nw.out      = rep(0, iterations)\nlambda.out = rep(0, iterations)\nlogpost    = rep(0, iterations)\ncc.out     = array(0, dim=c(iterations, n))\n\n# MCMC iterations\nfor (s in 1:iterations) {\n  # Sample indicators c_i\n  cc = numeric(n)\n  # Full conditional for cc\n  for(i in 1:n){\n    v = rep(0,2)\n    if(x[i]==0){\n      v[1] = log(w)\n      v[2] = log(1-w) + dpois(x[i], lambda, log=TRUE)\n      v    = exp(v - max(v))/sum(exp(v - max(v)))\n    }else{\n      v[1] = 0\n      v[2] = 1\n    }\n    cc[i] = sample(1:2, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n\n  lambda = rgamma(1, shape = 1 + sum(x[cc == 2]), rate = 1 + sum(cc == 2))\n  # Store samples\n  w.out[s] &lt;- w\n  lambda.out[s] &lt;- lambda\n  cc.out[s,] &lt;- cc\n\n}\n\n# Posterior summaries\nw.post &lt;- w.out[-(1:burn)]\nlambda.post &lt;- lambda.out[-(1:burn)]\n\ncat(\"Posterior mean of lambda:\", mean(lambda.post), \"\\n\")\n\n\nPosterior mean of lambda: 3.045713 \n\n\nCode\ncat(\"Posterior mean of w:\", mean(w.post), \"\\n\")\n\n\nPosterior mean of w: 0.3993913"
  },
  {
    "objectID": "c03-mixtures/m2-em/em-location-scale-gaussians/index.html",
    "href": "c03-mixtures/m2-em/em-location-scale-gaussians/index.html",
    "title": "EM algorithm for fitting a location-scale mixture of K p-variate Gaussian components",
    "section": "",
    "text": "This is an example of an EM algorithm for fitting a mixtures of K p-variate Gaussian components\n\n\nCode\n###### Setup data\nx = faithful$eruptions\nn = length(x)\n\n\n\n1 EM algorithm to fit the location-and-scale mixture of 2 Gaussians\n\n\nCode\nw      = 0.5          \nmu     = c(mean(x)-sd(x), mean(x)+sd(x))\nsigma  = rep(sd(x)/4,2)\n\ns  = 0              # s_tep counter\nsw = FALSE          # sw_itch to stop the algorithm\nQQ = -Inf           # the Q function (log-likelihood function)\nQQ.out = NULL       # the Q function values\nepsilon = 10^(-5)   # the stopping criterion for the algorithm\n\nwhile(!sw){ ##Checking convergence\n\n  ## E step\n  v = array(0, dim=c(n,2))\n  for(i in 1:n){\n    v[i,1] = log(w) + dnorm(x[i], mu[1], sigma[1], log=T)\n    v[i,2] = log(1-w) + dnorm(x[i], mu[2], sigma[2], log=T)\n    v[i,]  = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,]))) \n  }\n\n  ## M step\n  # Weights\n  w  = mean(v[,1])\n  # Means\n  mu = rep(0, 2)\n  for(k in 1:2){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Variances\n  sigma = rep(0,2)\n  for(k in 1:2){\n    for(i in 1:n){\n      sigma[k] = sigma[k] + v[i,k]*(x[i] - mu[k])^2\n    }\n    sigma[k] = sqrt(sigma[k]/sum(v[,k]))\n  }\n  ## Check convergence\n  QQn = 0\n  for(i in 1:n){\n    QQn = QQn + v[i,1]*(log(w) + dnorm(x[i],mu[1],sigma[1],log=TRUE)) +\n                v[i,2]*(log(1-w) + dnorm(x[i],mu[2],sigma[2],log=TRUE))\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n}\n\n\n[1] \"1 -309.450737493483\"\n[1] \"2 -292.32994157869\"\n[1] \"3 -280.279590400843\"\n[1] \"4 -278.882852059725\"\n[1] \"5 -278.687833281763\"\n[1] \"6 -278.515594042029\"\n[1] \"7 -278.371067671734\"\n[1] \"8 -278.269313940617\"\n[1] \"9 -278.20429223392\"\n[1] \"10 -278.164685957935\"\n[1] \"11 -278.141072956464\"\n[1] \"12 -278.127115849347\"\n[1] \"13 -278.118891261794\"\n[1] \"14 -278.114049071933\"\n[1] \"15 -278.111198729535\"\n[1] \"16 -278.109520815145\"\n\n\n\n\nCode\nxx  = seq(0,7,length=150)\nnxx = length(xx)\ndensity.EM = rep(0, nxx)\nfor(s in 1:nxx){\n  density.EM[s] = density.EM[s] + w*dnorm(xx[s], mu[1], sigma[1]) + \n                                  (1-w)*dnorm(xx[s], mu[2], sigma[2])\n}\n\n\n\n\nCode\nplot(xx, density.EM, col=\"red\", lwd=2, type=\"l\", xlab=\"Eruptions\")\npoints(x,rep(0,n))\ntitle(main=\"Mixture of 2 Gaussians\")\n\n\n\n\n\n\n\n\nFigure 1"
  },
  {
    "objectID": "c03-mixtures/m2-em/em-2-norm-mix/index.html",
    "href": "c03-mixtures/m2-em/em-2-norm-mix/index.html",
    "title": "EM algorithm for fitting a location mixture of 2 Gaussian components",
    "section": "",
    "text": "We start by simulating data from a mixture of 2 Gaussian components. Recall that in a location mixture model, the data is generated from a mixture of Gaussian distributions with different means \\mu_1,\\mu_2 but the same variance \\sigma\n\n\\begin{aligned}\nx_i &\\sim \\sum_{k=1}^{KK} w_k \\mathcal{N}(\\mu_k, \\sigma^2)\n\\\\&= w_1 \\mathcal{N}(\\mu_1, \\sigma^2) + w_2 \\mathcal{N}(\\mu_2, \\sigma^2)\n\\\\&= w_1 \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x_i - \\mu_1)^2}{2\\sigma^2}} + w_2 \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x_i - \\mu_2)^2}{2\\sigma^2}}\n\\end{aligned}\n\\tag{1}\nwhere x_i is the i-th observation, K is the number of components, w_k are the weights associated with each component, \\mu_k are the means of the components, and \\sigma^2 is the common variance of all components."
  },
  {
    "objectID": "c03-mixtures/m2-em/em-2-norm-mix/index.html#the-mixture-model",
    "href": "c03-mixtures/m2-em/em-2-norm-mix/index.html#the-mixture-model",
    "title": "EM algorithm for fitting a location mixture of 2 Gaussian components",
    "section": "",
    "text": "We start by simulating data from a mixture of 2 Gaussian components. Recall that in a location mixture model, the data is generated from a mixture of Gaussian distributions with different means \\mu_1,\\mu_2 but the same variance \\sigma\n\n\\begin{aligned}\nx_i &\\sim \\sum_{k=1}^{KK} w_k \\mathcal{N}(\\mu_k, \\sigma^2)\n\\\\&= w_1 \\mathcal{N}(\\mu_1, \\sigma^2) + w_2 \\mathcal{N}(\\mu_2, \\sigma^2)\n\\\\&= w_1 \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x_i - \\mu_1)^2}{2\\sigma^2}} + w_2 \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x_i - \\mu_2)^2}{2\\sigma^2}}\n\\end{aligned}\n\\tag{1}\nwhere x_i is the i-th observation, K is the number of components, w_k are the weights associated with each component, \\mu_k are the means of the components, and \\sigma^2 is the common variance of all components."
  },
  {
    "objectID": "c03-mixtures/m2-em/em-2-norm-mix/index.html#simulating-synthetic-data",
    "href": "c03-mixtures/m2-em/em-2-norm-mix/index.html#simulating-synthetic-data",
    "title": "EM algorithm for fitting a location mixture of 2 Gaussian components",
    "section": "2 Simulating synthetic data",
    "text": "2 Simulating synthetic data\nwe first set some parameters and hyper-parameters for the simulation\n\n\nCode\n#### Example of an EM algorithm for fitting a location mixture of 2 Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nset.seed(81196)    # So that results are reproducible (same simulated data every time)\n\n## Generate data from a mixture with 2 components\n\n## Ground truth parameters\nKK         = 2    # Number of components of the mixture\nw.true     = 0.6  # True weights associated with the components\nmu.true    = rep(0, KK) # initialize the true means list\nmu.true[1] = 0   # True mean for the first component\nmu.true[2] = 5   # True mean for the second component\nsigma.true = 1   # True standard deviation of all components\nn  = 120         # Number of observations to be generated\n\n# simulate the component indicator items\ncc = sample(1:KK, n, replace=T, prob=c(w.true,1-w.true))\nx  = rep(0, n) # initialize the data vector x\nfor(i in 1:n){\n  # sample from a distribution selected by component indicator\n  x[i] = rnorm(1, mu.true[cc[i]], sigma.true)\n}\n\n\nnext, we plot the data and the true density of the mixture\n\n\nCode\n# Plot the true density\npar(mfrow=c(1,1))\nxx.true = seq(-8,11,length=200)\nyy.true = w.true     * dnorm(xx.true, mu.true[1], sigma.true) + \n          (1-w.true) * dnorm(xx.true, mu.true[2], sigma.true) \nplot(xx.true, yy.true, type=\"l\", xlab=\"x\", ylab=\"True density\", lwd=2)\npoints(x, rep(0,n), col=cc)"
  },
  {
    "objectID": "c03-mixtures/m2-em/em-2-norm-mix/index.html#run-the-actual-em-algorithm",
    "href": "c03-mixtures/m2-em/em-2-norm-mix/index.html#run-the-actual-em-algorithm",
    "title": "EM algorithm for fitting a location mixture of 2 Gaussian components",
    "section": "3 Run the actual EM algorithm",
    "text": "3 Run the actual EM algorithm\nNow we will use the EM algorithm to estimate the parameters of the mixture from the data we generated above.\nThe algorithm is implemented in the following steps:\n\nInitialization: We initialize the parameters of the model (weights, means, and standard deviations) randomly.\nE-step: We compute the expected value of the full data log-likelihood function, given the current parameters and the data.\n\nQ(\\omega,\\theta \\mid \\omega^{(t)}, \\theta^{(t)},x) = E_{c \\mid \\omega^{(t)},\\theta^{(t)}, x} \\left[ \\log p(x,c \\mid \\omega,\\theta) \\right]\n\\tag{2}\nWhere c is the latent variable indicating the component from which each observation was generated, \\omega are the weights, and \\theta are the parameters of the Gaussian components (means and standard deviations).\nM-step: We maximize the expected log-likelihood function with respect to the parameters.\n\n\n    \\hat{\\omega}^{(t+1)},\\hat{\\theta}^{(t+1)} = \\arg \\max_{\\omega,\\theta} Q(\\omega,\\theta \\mid \\hat{\\omega}^{(t)}, \\hat{\\theta}^{(t)},y)\n   \\tag{3}\nwhere \\hat{\\omega}^{(t)} and \\hat{\\theta}^{(t)} are the current estimates of the parameters, and y is the observed data.\nEach component is independently when conditioning on the \\omega, \\theta, x\n\n  p(c_i=k \\mid x_i, \\omega, \\theta) = \\frac{\\omega_k g_k(x_i \\mid \\theta_k)}{\\sum_{j=1}^{K} \\omega_j g_j(x_i \\mid \\theta_j)}= v_{ik}(\\omega, \\theta)\n  \nwhere the value of v_{ik} is interpreted as the probability that the i-th observation comes from the k-th component of the mixture assuming the population parameters \\omega and \\theta.\nThe M-step consists of updating the parameters of the model by maximizing the expected log-likelihood function with respect to the parameters. This is done by taking the derivative of the expected log-likelihood function with respect to each parameter and setting it to zero.\nThe M-step updates the weights, means, and standard deviations of the components based on the values of v_{ik} computed in the E-step.\n\nConvergence check: We check if the algorithm has converged by comparing the current and previous values of the log-likelihood function.\n\n\n\nCode\n## Initialize the parameters\n\nw     = 1/2                         # Assign equal weight to each component to start with\nmu    = rnorm(KK, mean(x), sd(x))   # Random cluster centers randomly spread over the support of the data\nsigma = sd(x)                       # Initial standard deviation\n\n\n\n\nCode\n# Plot the initial guess for the density\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(yy)), xlab=\"x\", ylab=\"Initial density\")\npoints(x, rep(0,n), col=cc)\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ns  = 0              # s_tep counter\nsw = FALSE          # sw_itch to stop the algorithm\nQQ = -Inf           # the Q function (log-likelihood function)\nQQ.out = NULL       # the Q function values\nepsilon = 10^(-5)   # the stopping criterion for the algorithm\n\n\n##Checking convergence of the algorithm\nwhile(!sw){\n  ## E step - Compute the expected value of the log-likelihood function\n  v = array(0, dim=c(n,KK))\n  v[,1] = log(w) + dnorm(x, mu[1], sigma, log=TRUE)    #Compute the log of the weights\n  v[,2] = log(1-w) + dnorm(x, mu[2], sigma, log=TRUE)  #Compute the log of the weights\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step - Maximize the expected log-likelihood function with respect to the parameters\n  # Weights\n  w = mean(v[,1])\n  mu = rep(0, KK)\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k]    = mu[k] + v[i,k]*x[i]\n    }\n    mu[k] = mu[k]/sum(v[,k])\n  }\n  # Standard deviations\n  sigma = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n    }\n  }\n  sigma = sqrt(sigma/sum(v))\n  \n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    # log is used to avoid numerical underflow\n    QQn = QQn + v[i,1]*(log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)) +\n                v[i,2]*(log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE))\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n  #Plot current estimate over data for each iteration\n#   layout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\n#   par(mar=c(3.1,4.1,0.5,0.5))\n#   plot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n  \n#   par(mar=c(5,4,1.5,0.5))\n#   xx = seq(-8,11,length=200)\n#   yy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\n#   plot(xx, yy, type=\"l\", ylim=c(0, max(c(yy,yy.true))), main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), lwd=2, col=\"red\", lty=2, xlab=\"x\", ylab=\"Density\")\n#   lines(xx.true, yy.true, lwd=2)\n#   points(x, rep(0,n), col=cc)\n#   legend(6,0.22,c(\"Truth\",\"Estimate\"),col=c(\"black\",\"red\"), lty=c(1,2))\n\n}\n\n\n[1] \"1 -343.425690465737\"\n[1] \"2 -339.993932553505\"\n[1] \"3 -333.742916535535\"\n[1] \"4 -322.087405606262\"\n[1] \"5 -299.927704463736\"\n[1] \"6 -265.515667629269\"\n[1] \"7 -246.004047691222\"\n[1] \"8 -243.982291955643\"\n[1] \"9 -243.880207718536\"\n[1] \"10 -243.873888447856\"\n[1] \"11 -243.873372520873\"\n\n\n\n\nCode\n#Plot final estimate over data\nlayout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\npar(mar=c(3.1,4.1,0.5,0.5))\nplot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n\npar(mar=c(5,4,1.5,0.5))\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(c(yy,yy.true))), main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), lwd=2, col=\"red\", lty=2, xlab=\"x\", ylab=\"Density\")\nlines(xx.true, yy.true, lwd=2)\npoints(x, rep(0,n), col=cc)\nlegend(6,0.22,c(\"Truth\",\"Estimate\"),col=c(\"black\",\"red\"), lty=c(1,2), bty=\"n\")"
  },
  {
    "objectID": "c03-mixtures/m5-BIC/index.html",
    "href": "c03-mixtures/m5-BIC/index.html",
    "title": "BIC for Mixture Models",
    "section": "",
    "text": "Illustrating the use of BIC to estimate the number of components of a Mixture Model using the galaxies dataset\n\n\nCode\nrm(list=ls())\n\n### Loading data and setting up global variables\nlibrary(MASS)\ndata(galaxies)\nx  = galaxies\nn  = length(x)\nset.seed(781209)\n\n\n\n\nCode\nKKmax = 20\nBIC   = rep(0, KKmax-1)\n\nw.sum  = vector(\"list\", KKmax-1)\nmu.sum = vector(\"list\", KKmax-1)\nsigma.sum = rep(0, KKmax-1)\n\nfor(KK in 2:KKmax){\n  ### First, compute the \"Maximum Likelihood\" density estimate \n  ### associated with a location mixture of 6 Gaussian distributions \n  ### using the EM algorithm\n  ## Initialize the parameters\n  w     = rep(1,KK)/KK\n  mu    = rnorm(KK, mean(x), sd(x))\n  sigma = sd(x)/KK\n  \n  epsilon = 0.000001\n  s       = 0\n  sw      = FALSE\n  KL      = -Inf\n  KL.out  = NULL\n  \n  while(!sw){\n    ## E step\n    v = array(0, dim=c(n,KK))\n    for(k in 1:KK){\n      v[,k] = log(w[k]) + dnorm(x, mu[k], sigma,log=TRUE)  \n    }\n    for(i in 1:n){\n      v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))\n    }\n    \n    ## M step\n    # Weights\n    w = apply(v,2,mean)\n    mu = rep(0, KK)\n    for(k in 1:KK){\n      for(i in 1:n){\n        mu[k]    = mu[k] + v[i,k]*x[i]\n      }\n      mu[k] = mu[k]/sum(v[,k])\n    }\n    # Standard deviations\n    sigma = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        sigma = sigma + v[i,k]*(x[i] - mu[k])^2\n      }\n    }\n    sigma = sqrt(sigma/sum(v))\n    \n    ##Check convergence\n    KLn = 0\n    for(i in 1:n){\n      for(k in 1:KK){\n        KLn = KLn + v[i,k]*(log(w[k]) + \n                        dnorm(x[i], mu[k], sigma, log=TRUE))\n      }\n    }\n    if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n      sw=TRUE\n    }\n    KL = KLn\n    KL.out = c(KL.out, KL)\n    s = s + 1\n    print(paste(s, KLn))\n  }\n  \n  w.sum[[KK-1]]  = w\n  mu.sum[[KK-1]] = mu\n  sigma.sum[KK-1] = sigma\n  \n  # Computing BIC\n  for(i in 1:n){\n    BIC[KK-1] = BIC[KK-1] - 2*log(sum(w*dnorm(x[i], mu, sigma)))\n  }\n  BIC[KK-1] = BIC[KK-1] + ((KK-1) + 1 + KK)*log(n)  ### KK-1 independent weights, one variance, and KK means\n}\n\n\n[1] \"1 -840.417078041351\"\n[1] \"2 -851.230526887376\"\n[1] \"3 -855.050461450355\"\n[1] \"4 -856.913696904432\"\n[1] \"5 -858.016282262394\"\n[1] \"6 -858.746787409422\"\n[1] \"7 -859.267313476606\"\n[1] \"8 -859.657479031559\"\n[1] \"9 -859.961027129125\"\n[1] \"10 -860.204025972427\"\n[1] \"11 -860.402998138258\"\n[1] \"12 -860.568934570425\"\n[1] \"13 -860.709436794073\"\n[1] \"14 -860.829933349667\"\n[1] \"15 -860.934406439715\"\n[1] \"16 -861.025844708191\"\n[1] \"17 -861.106535626818\"\n[1] \"18 -861.178260175652\"\n[1] \"19 -861.242425955062\"\n[1] \"20 -861.300160340851\"\n[1] \"21 -861.352377028638\"\n[1] \"22 -861.399824445291\"\n[1] \"23 -861.443121549377\"\n[1] \"24 -861.482784698766\"\n[1] \"25 -861.519248085235\"\n[1] \"26 -861.552879466261\"\n[1] \"27 -861.583992411498\"\n[1] \"28 -861.61285593373\"\n[1] \"29 -861.639702134255\"\n[1] \"30 -861.664732324921\"\n[1] \"31 -861.688121969872\"\n[1] \"32 -861.710024704446\"\n[1] \"33 -861.730575626388\"\n[1] \"34 -861.749894008717\"\n[1] \"35 -861.768085549517\"\n[1] \"36 -861.785244248396\"\n[1] \"37 -861.801453979966\"\n[1] \"38 -861.81678981998\"\n[1] \"39 -861.831319168329\"\n[1] \"40 -861.845102704334\"\n[1] \"41 -861.858195202837\"\n[1] \"42 -861.870646234216\"\n[1] \"43 -861.882500767134\"\n[1] \"44 -861.893799689451\"\n[1] \"45 -861.90458025996\"\n[1] \"46 -861.914876501451\"\n[1] \"47 -861.924719543788\"\n[1] \"48 -861.934137924285\"\n[1] \"49 -861.943157851434\"\n[1] \"50 -861.951803437104\"\n[1] \"51 -861.960096901533\"\n[1] \"52 -861.968058754743\"\n[1] \"53 -861.975707957493\"\n[1] \"54 -861.983062064415\"\n[1] \"55 -861.990137351576\"\n[1] \"56 -861.996948930423\"\n[1] \"57 -862.003510849771\"\n[1] \"58 -862.009836187274\"\n[1] \"59 -862.015937131609\"\n[1] \"60 -862.021825056483\"\n[1] \"61 -862.027510587363\"\n[1] \"62 -862.033003661776\"\n[1] \"63 -862.038313583869\"\n[1] \"64 -862.043449073881\"\n[1] \"65 -862.04841831304\"\n[1] \"66 -862.053228984405\"\n[1] \"67 -862.05788831004\"\n[1] \"68 -862.062403084932\"\n[1] \"69 -862.066779707948\"\n[1] \"70 -862.071024210153\"\n[1] \"71 -862.075142280734\"\n[1] \"72 -862.079139290769\"\n[1] \"73 -862.083020315043\"\n[1] \"74 -862.086790152097\"\n[1] \"75 -862.090453342675\"\n[1] \"76 -862.094014186716\"\n[1] \"77 -862.097476759022\"\n[1] \"78 -862.100844923723\"\n[1] \"79 -862.104122347642\"\n[1] \"80 -862.107312512661\"\n[1] \"81 -862.110418727164\"\n[1] \"82 -862.113444136653\"\n[1] \"83 -862.116391733586\"\n[1] \"84 -862.119264366526\"\n[1] \"85 -862.122064748622\"\n[1] \"86 -862.124795465522\"\n[1] \"87 -862.127458982727\"\n[1] \"88 -862.130057652441\"\n[1] \"89 -862.132593719969\"\n[1] \"90 -862.135069329676\"\n[1] \"91 -862.137486530565\"\n[1] \"92 -862.13984728148\"\n[1] \"93 -862.14215345598\"\n[1] \"94 -862.144406846898\"\n[1] \"95 -862.146609170613\"\n[1] \"96 -862.148762071051\"\n[1] \"97 -862.150867123448\"\n[1] \"98 -862.152925837867\"\n[1] \"99 -862.154939662513\"\n[1] \"100 -862.156909986849\"\n[1] \"101 -862.158838144516\"\n[1] \"102 -862.160725416091\"\n[1] \"103 -862.162573031682\"\n[1] \"104 -862.164382173365\"\n[1] \"105 -862.166153977496\"\n[1] \"106 -862.167889536877\"\n[1] \"107 -862.169589902808\"\n[1] \"108 -862.171256087023\"\n[1] \"109 -862.172889063521\"\n[1] \"110 -862.174489770294\"\n[1] \"111 -862.176059110959\"\n[1] \"112 -862.177597956312\"\n[1] \"113 -862.179107145785\"\n[1] \"114 -862.180587488839\"\n[1] \"115 -862.182039766275\"\n[1] \"116 -862.183464731485\"\n[1] \"117 -862.184863111629\"\n[1] \"118 -862.186235608761\"\n[1] \"119 -862.187582900891\"\n[1] \"120 -862.188905642997\"\n[1] \"121 -862.190204467988\"\n[1] \"122 -862.191479987617\"\n[1] \"123 -862.192732793347\"\n[1] \"124 -862.19396345718\"\n[1] \"125 -862.195172532445\"\n[1] \"126 -862.196360554542\"\n[1] \"127 -862.197528041663\"\n[1] \"128 -862.198675495463\"\n[1] \"129 -862.199803401715\"\n[1] \"130 -862.200912230923\"\n[1] \"131 -862.202002438916\"\n[1] \"132 -862.203074467404\"\n[1] \"133 -862.204128744526\"\n[1] \"134 -862.205165685347\"\n[1] \"135 -862.206185692361\"\n[1] \"136 -862.207189155955\"\n[1] \"137 -862.208176454855\"\n[1] \"138 -862.209147956551\"\n[1] \"139 -862.210104017715\"\n[1] \"140 -862.211044984583\"\n[1] \"141 -862.211971193338\"\n[1] \"142 -862.212882970461\"\n[1] \"143 -862.21378063308\"\n[1] \"144 -862.214664489298\"\n[1] \"145 -862.215534838508\"\n[1] \"146 -862.216391971695\"\n[1] \"1 -884.830831896471\"\n[1] \"2 -887.004675879031\"\n[1] \"3 -888.309095992891\"\n[1] \"4 -889.184418694703\"\n[1] \"5 -889.813751444926\"\n[1] \"6 -890.288133505177\"\n[1] \"7 -890.658409560142\"\n[1] \"8 -890.955373465832\"\n[1] \"9 -891.198819031899\"\n[1] \"10 -891.402061970124\"\n[1] \"11 -891.574388333506\"\n[1] \"12 -891.722466209668\"\n[1] \"13 -891.851201668975\"\n[1] \"14 -891.96427955479\"\n[1] \"15 -892.064517067325\"\n[1] \"16 -892.154101743812\"\n[1] \"17 -892.234755659769\"\n[1] \"18 -892.307851191881\"\n[1] \"19 -892.374494187467\"\n[1] \"20 -892.435584724028\"\n[1] \"21 -892.491862163631\"\n[1] \"22 -892.543939012059\"\n[1] \"23 -892.592326674624\"\n[1] \"24 -892.637455265189\"\n[1] \"25 -892.679688995933\"\n[1] \"26 -892.719338245239\"\n[1] \"27 -892.756669102201\"\n[1] \"28 -892.791910975728\"\n[1] \"29 -892.82526270582\"\n[1] \"30 -892.856897506042\"\n[1] \"31 -892.886966986801\"\n[1] \"32 -892.915604450551\"\n[1] \"33 -892.942927606294\"\n[1] \"34 -892.969040818035\"\n[1] \"35 -892.994036976888\"\n[1] \"36 -893.017999067584\"\n[1] \"37 -893.041001485437\"\n[1] \"38 -893.063111148534\"\n[1] \"39 -893.084388441051\"\n[1] \"40 -893.104888016642\"\n[1] \"41 -893.124659485382\"\n[1] \"42 -893.143748003374\"\n[1] \"43 -893.162194780696\"\n[1] \"44 -893.180037520518\"\n[1] \"45 -893.197310800025\"\n[1] \"46 -893.214046401949\"\n[1] \"47 -893.230273604023\"\n[1] \"48 -893.246019432468\"\n[1] \"49 -893.261308884656\"\n[1] \"50 -893.276165125244\"\n[1] \"51 -893.290609659417\"\n[1] \"52 -893.304662486338\"\n[1] \"53 -893.318342235406\"\n[1] \"54 -893.331666287542\"\n[1] \"55 -893.344650883444\"\n[1] \"56 -893.357311220391\"\n[1] \"57 -893.369661539055\"\n[1] \"58 -893.381715201479\"\n[1] \"59 -893.393484761304\"\n[1] \"60 -893.40498202712\"\n[1] \"61 -893.416218119748\"\n[1] \"62 -893.427203524125\"\n[1] \"63 -893.437948136386\"\n[1] \"64 -893.448461306675\"\n[1] \"65 -893.458751878135\"\n[1] \"66 -893.468828222478\"\n[1] \"67 -893.478698272488\"\n[1] \"68 -893.488369551774\"\n[1] \"69 -893.497849202044\"\n[1] \"70 -893.507144008142\"\n[1] \"71 -893.516260421071\"\n[1] \"72 -893.525204579185\"\n[1] \"73 -893.533982327738\"\n[1] \"74 -893.542599236915\"\n[1] \"75 -893.551060618513\"\n[1] \"76 -893.559371541377\"\n[1] \"77 -893.567536845697\"\n[1] \"78 -893.575561156278\"\n[1] \"79 -893.583448894856\"\n[1] \"80 -893.591204291568\"\n[1] \"81 -893.598831395601\"\n[1] \"82 -893.606334085139\"\n[1] \"83 -893.613716076621\"\n[1] \"84 -893.620980933399\"\n[1] \"85 -893.628132073818\"\n[1] \"86 -893.63517277878\"\n[1] \"87 -893.642106198821\"\n[1] \"88 -893.648935360742\"\n[1] \"89 -893.65566317383\"\n[1] \"90 -893.662292435695\"\n[1] \"91 -893.668825837754\"\n[1] \"92 -893.675265970381\"\n[1] \"93 -893.681615327759\"\n[1] \"94 -893.687876312441\"\n[1] \"95 -893.694051239653\"\n[1] \"96 -893.700142341343\"\n[1] \"97 -893.706151770011\"\n[1] \"98 -893.712081602313\"\n[1] \"99 -893.717933842473\"\n[1] \"100 -893.723710425507\"\n[1] \"101 -893.729413220273\"\n[1] \"102 -893.735044032349\"\n[1] \"103 -893.740604606773\"\n[1] \"104 -893.746096630627\"\n[1] \"105 -893.751521735488\"\n[1] \"106 -893.756881499761\"\n[1] \"107 -893.762177450884\"\n[1] \"108 -893.767411067424\"\n[1] \"109 -893.772583781069\"\n[1] \"110 -893.777696978525\"\n[1] \"111 -893.782752003316\"\n[1] \"112 -893.78775015749\"\n[1] \"113 -893.792692703257\"\n[1] \"114 -893.797580864541\"\n[1] \"115 -893.802415828452\"\n[1] \"116 -893.807198746703\"\n[1] \"117 -893.811930736951\"\n[1] \"118 -893.816612884081\"\n[1] \"119 -893.821246241426\"\n[1] \"120 -893.825831831938\"\n[1] \"121 -893.830370649307\"\n[1] \"122 -893.834863659016\"\n[1] \"123 -893.839311799373\"\n[1] \"124 -893.843715982476\"\n[1] \"125 -893.848077095146\"\n[1] \"126 -893.852395999827\"\n[1] \"127 -893.856673535425\"\n[1] \"128 -893.860910518137\"\n[1] \"129 -893.865107742233\"\n[1] \"130 -893.869265980797\"\n[1] \"131 -893.873385986456\"\n[1] \"132 -893.877468492064\"\n[1] \"133 -893.881514211363\"\n[1] \"134 -893.885523839624\"\n[1] \"135 -893.889498054243\"\n[1] \"136 -893.893437515341\"\n[1] \"137 -893.897342866312\"\n[1] \"138 -893.90121473437\"\n[1] \"139 -893.905053731064\"\n[1] \"140 -893.908860452777\"\n[1] \"141 -893.912635481204\"\n[1] \"142 -893.916379383813\"\n[1] \"143 -893.920092714285\"\n[1] \"144 -893.923776012951\"\n[1] \"145 -893.927429807182\"\n[1] \"146 -893.931054611806\"\n[1] \"147 -893.934650929472\"\n[1] \"148 -893.938219251023\"\n[1] \"149 -893.941760055852\"\n[1] \"150 -893.945273812232\"\n[1] \"151 -893.948760977655\"\n[1] \"152 -893.952221999141\"\n[1] \"153 -893.955657313544\"\n[1] \"154 -893.959067347846\"\n[1] \"155 -893.962452519444\"\n[1] \"156 -893.965813236419\"\n[1] \"157 -893.969149897803\"\n[1] \"158 -893.972462893831\"\n[1] \"159 -893.975752606195\"\n[1] \"160 -893.979019408269\"\n[1] \"161 -893.982263665352\"\n[1] \"162 -893.985485734884\"\n[1] \"163 -893.988685966658\"\n[1] \"164 -893.991864703035\"\n[1] \"165 -893.995022279137\"\n[1] \"166 -893.998159023044\"\n[1] \"167 -894.001275255986\"\n[1] \"168 -894.004371292517\"\n[1] \"169 -894.007447440697\"\n[1] \"170 -894.010504002258\"\n[1] \"171 -894.013541272768\"\n[1] \"172 -894.016559541796\"\n[1] \"173 -894.019559093062\"\n[1] \"174 -894.022540204585\"\n[1] \"175 -894.025503148833\"\n[1] \"176 -894.028448192858\"\n[1] \"177 -894.031375598435\"\n[1] \"178 -894.034285622193\"\n[1] \"179 -894.037178515742\"\n[1] \"180 -894.040054525798\"\n[1] \"181 -894.042913894305\"\n[1] \"182 -894.045756858543\"\n[1] \"183 -894.048583651253\"\n[1] \"184 -894.051394500736\"\n[1] \"185 -894.054189630967\"\n[1] \"186 -894.056969261693\"\n[1] \"187 -894.059733608535\"\n[1] \"188 -894.062482883088\"\n[1] \"189 -894.065217293009\"\n[1] \"190 -894.067937042114\"\n[1] \"191 -894.070642330467\"\n[1] \"192 -894.07333335446\"\n[1] \"193 -894.076010306906\"\n[1] \"194 -894.078673377114\"\n[1] \"195 -894.081322750973\"\n[1] \"196 -894.083958611024\"\n[1] \"197 -894.086581136535\"\n[1] \"198 -894.089190503585\"\n[1] \"199 -894.091786885115\"\n[1] \"200 -894.094370451017\"\n[1] \"201 -894.096941368184\"\n[1] \"202 -894.099499800587\"\n[1] \"203 -894.102045909336\"\n[1] \"204 -894.104579852732\"\n[1] \"205 -894.107101786342\"\n[1] \"206 -894.109611863045\"\n[1] \"207 -894.112110233096\"\n[1] \"208 -894.114597044177\"\n[1] \"209 -894.117072441452\"\n[1] \"210 -894.11953656762\"\n[1] \"211 -894.121989562967\"\n[1] \"212 -894.124431565411\"\n[1] \"213 -894.126862710556\"\n[1] \"214 -894.129283131734\"\n[1] \"215 -894.131692960055\"\n[1] \"216 -894.134092324447\"\n[1] \"217 -894.136481351705\"\n[1] \"218 -894.13886016653\"\n[1] \"219 -894.141228891567\"\n[1] \"220 -894.143587647454\"\n[1] \"221 -894.145936552851\"\n[1] \"222 -894.148275724486\"\n[1] \"223 -894.150605277188\"\n[1] \"224 -894.152925323924\"\n[1] \"225 -894.155235975836\"\n[1] \"226 -894.157537342275\"\n[1] \"227 -894.15982953083\"\n[1] \"228 -894.162112647367\"\n[1] \"229 -894.164386796058\"\n[1] \"230 -894.166652079413\"\n[1] \"231 -894.168908598309\"\n[1] \"232 -894.17115645202\"\n[1] \"233 -894.173395738248\"\n[1] \"234 -894.175626553147\"\n[1] \"235 -894.177848991356\"\n[1] \"236 -894.180063146018\"\n[1] \"237 -894.182269108815\"\n[1] \"238 -894.184466969988\"\n[1] \"239 -894.186656818361\"\n[1] \"240 -894.188838741371\"\n[1] \"241 -894.191012825086\"\n[1] \"242 -894.19317915423\"\n[1] \"243 -894.195337812206\"\n[1] \"244 -894.197488881118\"\n[1] \"245 -894.199632441792\"\n[1] \"246 -894.201768573795\"\n[1] \"247 -894.20389735546\"\n[1] \"248 -894.206018863903\"\n[1] \"249 -894.208133175043\"\n[1] \"250 -894.210240363619\"\n[1] \"251 -894.212340503211\"\n[1] \"252 -894.21443366626\"\n[1] \"253 -894.216519924079\"\n[1] \"254 -894.218599346877\"\n[1] \"255 -894.220672003773\"\n[1] \"256 -894.22273796281\"\n[1] \"257 -894.224797290976\"\n[1] \"258 -894.226850054215\"\n[1] \"259 -894.228896317447\"\n[1] \"260 -894.230936144577\"\n[1] \"261 -894.232969598514\"\n[1] \"262 -894.234996741183\"\n[1] \"263 -894.237017633542\"\n[1] \"264 -894.239032335589\"\n[1] \"265 -894.241040906382\"\n[1] \"266 -894.243043404046\"\n[1] \"267 -894.245039885793\"\n[1] \"268 -894.247030407924\"\n[1] \"269 -894.249015025849\"\n[1] \"270 -894.250993794097\"\n[1] \"271 -894.252966766325\"\n[1] \"272 -894.254933995326\"\n[1] \"273 -894.256895533051\"\n[1] \"274 -894.25885143061\"\n[1] \"275 -894.26080173828\"\n[1] \"276 -894.262746505523\"\n[1] \"277 -894.264685780994\"\n[1] \"278 -894.266619612541\"\n[1] \"279 -894.268548047231\"\n[1] \"280 -894.27047113134\"\n[1] \"281 -894.272388910377\"\n[1] \"282 -894.274301429085\"\n[1] \"283 -894.276208731448\"\n[1] \"284 -894.278110860704\"\n[1] \"285 -894.28000785935\"\n[1] \"286 -894.281899769148\"\n[1] \"287 -894.283786631135\"\n[1] \"288 -894.285668485628\"\n[1] \"289 -894.287545372235\"\n[1] \"290 -894.289417329854\"\n[1] \"291 -894.291284396686\"\n[1] \"292 -894.29314661024\"\n[1] \"293 -894.295004007335\"\n[1] \"294 -894.296856624114\"\n[1] \"295 -894.298704496041\"\n[1] \"296 -894.30054765791\"\n[1] \"297 -894.302386143852\"\n[1] \"298 -894.304219987337\"\n[1] \"299 -894.306049221184\"\n[1] \"300 -894.307873877557\"\n[1] \"301 -894.309693987978\"\n[1] \"302 -894.311509583328\"\n[1] \"303 -894.31332069385\"\n[1] \"304 -894.315127349155\"\n[1] \"305 -894.316929578224\"\n[1] \"306 -894.318727409415\"\n[1] \"307 -894.320520870464\"\n[1] \"308 -894.322309988486\"\n[1] \"309 -894.324094789985\"\n[1] \"310 -894.325875300849\"\n[1] \"311 -894.327651546361\"\n[1] \"312 -894.329423551192\"\n[1] \"313 -894.331191339416\"\n[1] \"314 -894.332954934499\"\n[1] \"315 -894.334714359312\"\n[1] \"316 -894.336469636126\"\n[1] \"317 -894.338220786618\"\n[1] \"318 -894.339967831874\"\n[1] \"319 -894.341710792381\"\n[1] \"320 -894.343449688044\"\n[1] \"321 -894.345184538172\"\n[1] \"322 -894.34691536149\"\n[1] \"323 -894.348642176134\"\n[1] \"324 -894.350364999655\"\n[1] \"325 -894.352083849016\"\n[1] \"326 -894.353798740601\"\n[1] \"327 -894.355509690202\"\n[1] \"328 -894.35721671303\"\n[1] \"329 -894.358919823714\"\n[1] \"330 -894.360619036295\"\n[1] \"331 -894.362314364232\"\n[1] \"332 -894.364005820396\"\n[1] \"333 -894.365693417077\"\n[1] \"334 -894.367377165976\"\n[1] \"335 -894.369057078207\"\n[1] \"336 -894.370733164297\"\n[1] \"337 -894.372405434183\"\n[1] \"338 -894.374073897215\"\n[1] \"339 -894.375738562146\"\n[1] \"340 -894.37739943714\"\n[1] \"341 -894.379056529762\"\n[1] \"342 -894.380709846985\"\n[1] \"343 -894.382359395179\"\n[1] \"344 -894.384005180113\"\n[1] \"345 -894.385647206953\"\n[1] \"346 -894.387285480258\"\n[1] \"347 -894.388920003982\"\n[1] \"348 -894.39055078146\"\n[1] \"349 -894.392177815419\"\n[1] \"350 -894.393801107962\"\n[1] \"351 -894.395420660572\"\n[1] \"352 -894.397036474113\"\n[1] \"353 -894.398648548811\"\n[1] \"354 -894.400256884262\"\n[1] \"355 -894.401861479429\"\n[1] \"356 -894.40346233263\"\n[1] \"357 -894.405059441538\"\n[1] \"358 -894.406652803177\"\n[1] \"359 -894.408242413915\"\n[1] \"360 -894.40982826946\"\n[1] \"361 -894.411410364853\"\n[1] \"362 -894.412988694468\"\n[1] \"363 -894.414563251999\"\n[1] \"364 -894.416134030459\"\n[1] \"365 -894.417701022174\"\n[1] \"366 -894.419264218777\"\n[1] \"367 -894.420823611194\"\n[1] \"368 -894.422379189652\"\n[1] \"369 -894.423930943656\"\n[1] \"370 -894.425478861996\"\n[1] \"371 -894.427022932729\"\n[1] \"372 -894.428563143179\"\n[1] \"373 -894.430099479925\"\n[1] \"374 -894.431631928791\"\n[1] \"375 -894.433160474848\"\n[1] \"376 -894.434685102392\"\n[1] \"377 -894.436205794944\"\n[1] \"378 -894.437722535242\"\n[1] \"379 -894.439235305225\"\n[1] \"380 -894.440744086025\"\n[1] \"381 -894.442248857967\"\n[1] \"382 -894.443749600543\"\n[1] \"383 -894.445246292416\"\n[1] \"384 -894.446738911402\"\n[1] \"385 -894.44822743446\"\n[1] \"386 -894.44971183768\"\n[1] \"387 -894.451192096276\"\n[1] \"388 -894.452668184573\"\n[1] \"389 -894.454140075986\"\n[1] \"390 -894.455607743021\"\n[1] \"391 -894.457071157257\"\n[1] \"392 -894.458530289325\"\n[1] \"393 -894.45998510891\"\n[1] \"394 -894.461435584723\"\n[1] \"395 -894.462881684496\"\n[1] \"396 -894.464323374964\"\n[1] \"397 -894.465760621849\"\n[1] \"398 -894.467193389848\"\n[1] \"399 -894.468621642614\"\n[1] \"400 -894.470045342745\"\n[1] \"401 -894.471464451761\"\n[1] \"402 -894.472878930091\"\n[1] \"403 -894.474288737058\"\n[1] \"404 -894.475693830857\"\n[1] \"405 -894.477094168536\"\n[1] \"406 -894.478489705984\"\n[1] \"407 -894.479880397906\"\n[1] \"408 -894.481266197804\"\n[1] \"409 -894.482647057962\"\n[1] \"410 -894.484022929418\"\n[1] \"411 -894.48539376195\"\n[1] \"412 -894.486759504047\"\n[1] \"413 -894.488120102896\"\n[1] \"414 -894.48947550435\"\n[1] \"415 -894.490825652914\"\n[1] \"416 -894.492170491711\"\n[1] \"417 -894.493509962467\"\n[1] \"418 -894.49484400548\"\n[1] \"419 -894.496172559598\"\n[1] \"420 -894.497495562189\"\n[1] \"421 -894.498812949117\"\n[1] \"422 -894.500124654713\"\n[1] \"423 -894.501430611747\"\n[1] \"424 -894.502730751401\"\n[1] \"425 -894.504025003235\"\n[1] \"426 -894.505313295158\"\n[1] \"427 -894.506595553398\"\n[1] \"428 -894.507871702472\"\n[1] \"429 -894.509141665147\"\n[1] \"430 -894.510405362409\"\n[1] \"431 -894.511662713432\"\n[1] \"432 -894.512913635535\"\n[1] \"433 -894.514158044155\"\n[1] \"434 -894.5153958528\"\n[1] \"435 -894.516626973018\"\n[1] \"436 -894.517851314355\"\n[1] \"437 -894.519068784309\"\n[1] \"438 -894.520279288301\"\n[1] \"439 -894.521482729621\"\n[1] \"440 -894.522679009391\"\n[1] \"441 -894.523868026519\"\n[1] \"442 -894.525049677649\"\n[1] \"443 -894.52622385712\"\n[1] \"444 -894.527390456913\"\n[1] \"445 -894.528549366605\"\n[1] \"446 -894.529700473314\"\n[1] \"447 -894.530843661651\"\n[1] \"448 -894.531978813663\"\n[1] \"449 -894.533105808778\"\n[1] \"450 -894.53422452375\"\n[1] \"451 -894.535334832604\"\n[1] \"452 -894.536436606566\"\n[1] \"453 -894.537529714012\"\n[1] \"454 -894.538614020401\"\n[1] \"455 -894.539689388207\"\n[1] \"456 -894.540755676861\"\n[1] \"457 -894.541812742673\"\n[1] \"458 -894.542860438768\"\n[1] \"459 -894.543898615012\"\n[1] \"460 -894.544927117938\"\n[1] \"461 -894.545945790667\"\n[1] \"462 -894.546954472837\"\n[1] \"463 -894.547953000513\"\n[1] \"464 -894.548941206108\"\n[1] \"465 -894.549918918303\"\n[1] \"466 -894.55088596195\"\n[1] \"467 -894.551842157989\"\n[1] \"468 -894.552787323353\"\n[1] \"469 -894.553721270868\"\n[1] \"470 -894.554643809167\"\n[1] \"471 -894.55555474257\"\n[1] \"472 -894.556453871002\"\n[1] \"473 -894.557340989869\"\n[1] \"1 -855.071099785927\"\n[1] \"2 -855.520194575663\"\n[1] \"3 -852.636831979003\"\n[1] \"4 -847.238113586232\"\n[1] \"5 -840.188159663983\"\n[1] \"6 -833.985811252329\"\n[1] \"7 -831.02263822114\"\n[1] \"8 -829.585482706157\"\n[1] \"9 -829.115441702027\"\n[1] \"10 -829.041664155176\"\n[1] \"11 -829.032347759651\"\n[1] \"12 -829.03096630076\"\n[1] \"13 -829.030464449051\"\n[1] \"1 -878.120984704982\"\n[1] \"2 -877.532037186813\"\n[1] \"3 -874.561820360442\"\n[1] \"4 -869.439208837467\"\n[1] \"5 -863.117551686066\"\n[1] \"6 -858.64750591475\"\n[1] \"7 -856.670853282626\"\n[1] \"8 -855.515098899532\"\n[1] \"9 -854.909505003657\"\n[1] \"10 -854.319339687864\"\n[1] \"11 -853.562634661161\"\n[1] \"12 -852.566153540881\"\n[1] \"13 -851.262174010697\"\n[1] \"14 -849.58424659735\"\n[1] \"15 -847.485534791956\"\n[1] \"16 -844.969509007705\"\n[1] \"17 -842.121109945835\"\n[1] \"18 -839.112304081624\"\n[1] \"19 -836.157280243929\"\n[1] \"20 -833.432143007169\"\n[1] \"21 -831.019567064583\"\n[1] \"22 -828.917801210585\"\n[1] \"23 -827.087245264564\"\n[1] \"24 -825.488630238192\"\n[1] \"25 -824.096711645977\"\n[1] \"26 -822.897724044377\"\n[1] \"27 -821.882120291514\"\n[1] \"28 -821.03890119954\"\n[1] \"29 -820.353209199856\"\n[1] \"30 -819.806574730027\"\n[1] \"31 -819.378546934392\"\n[1] \"32 -819.04859937212\"\n[1] \"33 -818.797651396539\"\n[1] \"34 -818.608977939923\"\n[1] \"35 -818.468557664925\"\n[1] \"36 -818.36502420367\"\n[1] \"37 -818.289392458077\"\n[1] \"38 -818.234691682516\"\n[1] \"39 -818.195588563762\"\n[1] \"40 -818.168044247337\"\n[1] \"41 -818.149023122552\"\n[1] \"42 -818.13625612764\"\n[1] \"43 -818.128053888384\"\n[1] \"44 -818.123162123625\"\n[1] \"45 -818.120651320093\"\n[1] \"46 -818.119833394566\"\n[1] \"1 -863.201100966882\"\n[1] \"2 -853.632673605595\"\n[1] \"3 -843.634626078639\"\n[1] \"4 -841.541523924317\"\n[1] \"5 -841.474196043208\"\n[1] \"6 -841.507056149966\"\n[1] \"7 -841.483650613896\"\n[1] \"8 -841.380210174535\"\n[1] \"9 -841.179109143195\"\n[1] \"10 -840.865373397891\"\n[1] \"11 -840.425804898198\"\n[1] \"12 -839.846341197061\"\n[1] \"13 -839.108697964422\"\n[1] \"14 -838.187933850818\"\n[1] \"15 -837.051779467449\"\n[1] \"16 -835.661117480794\"\n[1] \"17 -833.969819992702\"\n[1] \"18 -831.921562148867\"\n[1] \"19 -829.44103681569\"\n[1] \"20 -826.416964018383\"\n[1] \"21 -822.674743299671\"\n[1] \"22 -817.941696854121\"\n[1] \"23 -811.84013073915\"\n[1] \"24 -804.075232689684\"\n[1] \"25 -795.206220591555\"\n[1] \"26 -787.391645989225\"\n[1] \"27 -782.112812081745\"\n[1] \"28 -778.774566825847\"\n[1] \"29 -776.629513625547\"\n[1] \"30 -775.208017236598\"\n[1] \"31 -774.206793839075\"\n[1] \"32 -773.442472474961\"\n[1] \"33 -772.821347677913\"\n[1] \"34 -772.304506689362\"\n[1] \"35 -771.878068698699\"\n[1] \"36 -771.534693952399\"\n[1] \"37 -771.265644235701\"\n[1] \"38 -771.059662768021\"\n[1] \"39 -770.904596396046\"\n[1] \"40 -770.789119074513\"\n[1] \"41 -770.703655372936\"\n[1] \"42 -770.640588620896\"\n[1] \"43 -770.594081740491\"\n[1] \"44 -770.559760933591\"\n[1] \"45 -770.534392148834\"\n[1] \"46 -770.515601580007\"\n[1] \"47 -770.50165258372\"\n[1] \"48 -770.491275290079\"\n[1] \"49 -770.483539864835\"\n[1] \"50 -770.477763740803\"\n[1] \"51 -770.473444315217\"\n[1] \"52 -770.470210303936\"\n[1] \"53 -770.467786582074\"\n[1] \"54 -770.465968710539\"\n[1] \"55 -770.464604408636\"\n[1] \"56 -770.463580017627\"\n[1] \"57 -770.462810565046\"\n[1] \"1 -855.729167863863\"\n[1] \"2 -852.898107053099\"\n[1] \"3 -851.629858052252\"\n[1] \"4 -850.388313297883\"\n[1] \"5 -849.212917819304\"\n[1] \"6 -848.141219526654\"\n[1] \"7 -847.176630585904\"\n[1] \"8 -846.295243650544\"\n[1] \"9 -845.456740050863\"\n[1] \"10 -844.615517491721\"\n[1] \"11 -843.728112861259\"\n[1] \"12 -842.756121617238\"\n[1] \"13 -841.66600134841\"\n[1] \"14 -840.427542741701\"\n[1] \"15 -839.012267973849\"\n[1] \"16 -837.392384501069\"\n[1] \"17 -835.540446334721\"\n[1] \"18 -833.429467753797\"\n[1] \"19 -831.032688982436\"\n[1] \"20 -828.321379092958\"\n[1] \"21 -825.258304324513\"\n[1] \"22 -821.785416716356\"\n[1] \"23 -817.811388918723\"\n[1] \"24 -813.228108012841\"\n[1] \"25 -808.039076829922\"\n[1] \"26 -802.706101918786\"\n[1] \"27 -798.642167242769\"\n[1] \"28 -796.903873239686\"\n[1] \"29 -796.319565325089\"\n[1] \"30 -796.107291820742\"\n[1] \"31 -796.0229516733\"\n[1] \"32 -795.986110413469\"\n[1] \"33 -795.968246714623\"\n[1] \"34 -795.958595759972\"\n[1] \"35 -795.952834733939\"\n[1] \"36 -795.949108044704\"\n[1] \"37 -795.946555467017\"\n[1] \"38 -795.944741048359\"\n[1] \"39 -795.943421793129\"\n[1] \"40 -795.942449657444\"\n[1] \"41 -795.941727713151\"\n[1] \"1 -846.133268361017\"\n[1] \"2 -840.831791837531\"\n[1] \"3 -833.203725194882\"\n[1] \"4 -827.866241690682\"\n[1] \"5 -823.295820753014\"\n[1] \"6 -819.507033161196\"\n[1] \"7 -815.471013362118\"\n[1] \"8 -811.122331568588\"\n[1] \"9 -806.501096291368\"\n[1] \"10 -802.212916983432\"\n[1] \"11 -799.132350162817\"\n[1] \"12 -797.32036098041\"\n[1] \"13 -796.31367192667\"\n[1] \"14 -795.727515359795\"\n[1] \"15 -795.358204705732\"\n[1] \"16 -795.110151288144\"\n[1] \"17 -794.93707448417\"\n[1] \"18 -794.814012677887\"\n[1] \"19 -794.725798194986\"\n[1] \"20 -794.662374351299\"\n[1] \"21 -794.616739495663\"\n[1] \"22 -794.583906964002\"\n[1] \"23 -794.560293085346\"\n[1] \"24 -794.543315268757\"\n[1] \"25 -794.531111847917\"\n[1] \"26 -794.522341633645\"\n[1] \"27 -794.516039161407\"\n[1] \"28 -794.511509941397\"\n[1] \"29 -794.508254701233\"\n[1] \"30 -794.505914671808\"\n[1] \"31 -794.504232127662\"\n[1] \"32 -794.503021964576\"\n[1] \"33 -794.502151248218\"\n[1] \"34 -794.50152451026\"\n[1] \"1 -798.344638678329\"\n[1] \"2 -808.474487846665\"\n[1] \"3 -812.907389480219\"\n[1] \"4 -815.308294099217\"\n[1] \"5 -816.636796210058\"\n[1] \"6 -817.248986150525\"\n[1] \"7 -817.313329837242\"\n[1] \"8 -816.941064994069\"\n[1] \"9 -816.239602976075\"\n[1] \"10 -815.331194168846\"\n[1] \"11 -814.344822848013\"\n[1] \"12 -813.390482575862\"\n[1] \"13 -812.536517770973\"\n[1] \"14 -811.807326302655\"\n[1] \"15 -811.198546411258\"\n[1] \"16 -810.694648135963\"\n[1] \"17 -810.279362162906\"\n[1] \"18 -809.938992019855\"\n[1] \"19 -809.662282369445\"\n[1] \"20 -809.439563423673\"\n[1] \"21 -809.262193044026\"\n[1] \"22 -809.122377722114\"\n[1] \"23 -809.01318758793\"\n[1] \"24 -808.928606524834\"\n[1] \"25 -808.86354262078\"\n[1] \"26 -808.813784570597\"\n[1] \"27 -808.775917154078\"\n[1] \"28 -808.747215284522\"\n[1] \"29 -808.725533044704\"\n[1] \"30 -808.709198549149\"\n[1] \"31 -808.696920445141\"\n[1] \"32 -808.687708269703\"\n[1] \"33 -808.680806658116\"\n[1] \"34 -808.675642208214\"\n[1] \"35 -808.671781291373\"\n[1] \"36 -808.668896992069\"\n[1] \"37 -808.666743465692\"\n[1] \"38 -808.665136211344\"\n[1] \"39 -808.663936993671\"\n[1] \"40 -808.663042378389\"\n[1] \"41 -808.662375052346\"\n[1] \"1 -857.895023257989\"\n[1] \"2 -858.22514880749\"\n[1] \"3 -850.202346176373\"\n[1] \"4 -843.537639650417\"\n[1] \"5 -837.239427389032\"\n[1] \"6 -830.659693150908\"\n[1] \"7 -824.178247269713\"\n[1] \"8 -818.969618623668\"\n[1] \"9 -815.481781192618\"\n[1] \"10 -813.131150792556\"\n[1] \"11 -811.185693268873\"\n[1] \"12 -809.234134496009\"\n[1] \"13 -807.221124865831\"\n[1] \"14 -805.364095108481\"\n[1] \"15 -803.921578202983\"\n[1] \"16 -802.96809527887\"\n[1] \"17 -802.404630675859\"\n[1] \"18 -802.089399157247\"\n[1] \"19 -801.913114407189\"\n[1] \"20 -801.80909130307\"\n[1] \"21 -801.740794594968\"\n[1] \"22 -801.689100949911\"\n[1] \"23 -801.644080455533\"\n[1] \"24 -801.60045474671\"\n[1] \"25 -801.555239572712\"\n[1] \"26 -801.506546626209\"\n[1] \"27 -801.452973638732\"\n[1] \"28 -801.393289284927\"\n[1] \"29 -801.326267126146\"\n[1] \"30 -801.250597607453\"\n[1] \"31 -801.164844687801\"\n[1] \"32 -801.067432923164\"\n[1] \"33 -800.956661053845\"\n[1] \"34 -800.830743720256\"\n[1] \"35 -800.68788564712\"\n[1] \"36 -800.526392943225\"\n[1] \"37 -800.344823811199\"\n[1] \"38 -800.142175499564\"\n[1] \"39 -799.918095668218\"\n[1] \"40 -799.673095387316\"\n[1] \"41 -799.408730170843\"\n[1] \"42 -799.127708678238\"\n[1] \"43 -798.833890439787\"\n[1] \"44 -798.53214717322\"\n[1] \"45 -798.228086300144\"\n[1] \"46 -797.92766473552\"\n[1] \"47 -797.636747009084\"\n[1] \"48 -797.360675405152\"\n[1] \"49 -797.103916292824\"\n[1] \"50 -796.86982772321\"\n[1] \"51 -796.660565682835\"\n[1] \"52 -796.47711911522\"\n[1] \"53 -796.319444157257\"\n[1] \"54 -796.186659144973\"\n[1] \"55 -796.077262950842\"\n[1] \"56 -795.989346780958\"\n[1] \"57 -795.920779799396\"\n[1] \"58 -795.869358788251\"\n[1] \"59 -795.832919760688\"\n[1] \"60 -795.809414492802\"\n[1] \"61 -795.796957586284\"\n[1] \"62 -795.793850528901\"\n[1] \"63 -795.79858894117\"\n[1] \"64 -795.80985832969\"\n[1] \"65 -795.826522591076\"\n[1] \"66 -795.847608455443\"\n[1] \"67 -795.87228814076\"\n[1] \"68 -795.899861750175\"\n[1] \"69 -795.92974038176\"\n[1] \"70 -795.961430511639\"\n[1] \"71 -795.994519927104\"\n[1] \"72 -796.028665297278\"\n[1] \"73 -796.063581349488\"\n[1] \"74 -796.099031549385\"\n[1] \"75 -796.134820146448\"\n[1] \"76 -796.170785432203\"\n[1] \"77 -796.206794058072\"\n[1] \"78 -796.242736267748\"\n[1] \"79 -796.278521911193\"\n[1] \"80 -796.314077121678\"\n[1] \"81 -796.349341551821\"\n[1] \"82 -796.38426607865\"\n[1] \"83 -796.418810900608\"\n[1] \"84 -796.452943961044\"\n[1] \"85 -796.486639642986\"\n[1] \"86 -796.51987768878\"\n[1] \"87 -796.552642305876\"\n[1] \"88 -796.584921426458\"\n[1] \"89 -796.616706094083\"\n[1] \"90 -796.647989955143\"\n[1] \"91 -796.678768836728\"\n[1] \"92 -796.709040395761\"\n[1] \"93 -796.738803826856\"\n[1] \"94 -796.768059618613\"\n[1] \"95 -796.796809349872\"\n[1] \"96 -796.825055518963\"\n[1] \"97 -796.852801400187\"\n[1] \"98 -796.880050922865\"\n[1] \"99 -796.906808569067\"\n[1] \"100 -796.933079286827\"\n[1] \"101 -796.958868416276\"\n[1] \"102 -796.984181626502\"\n[1] \"103 -797.009024861407\"\n[1] \"104 -797.033404293084\"\n[1] \"105 -797.057326281536\"\n[1] \"106 -797.080797339734\"\n[1] \"107 -797.103824103196\"\n[1] \"108 -797.126413303444\"\n[1] \"109 -797.148571744724\"\n[1] \"110 -797.170306283559\"\n[1] \"111 -797.191623810756\"\n[1] \"112 -797.212531235492\"\n[1] \"113 -797.233035471262\"\n[1] \"114 -797.25314342342\"\n[1] \"115 -797.272861978132\"\n[1] \"116 -797.292197992576\"\n[1] \"117 -797.311158286243\"\n[1] \"118 -797.329749633217\"\n[1] \"119 -797.347978755335\"\n[1] \"120 -797.365852316129\"\n[1] \"121 -797.383376915474\"\n[1] \"122 -797.400559084865\"\n[1] \"123 -797.417405283283\"\n[1] \"124 -797.433921893567\"\n[1] \"125 -797.450115219262\"\n[1] \"126 -797.465991481901\"\n[1] \"127 -797.481556818666\"\n[1] \"128 -797.49681728041\"\n[1] \"129 -797.511778830008\"\n[1] \"130 -797.526447340989\"\n[1] \"131 -797.540828596451\"\n[1] \"132 -797.554928288203\"\n[1] \"133 -797.568752016159\"\n[1] \"134 -797.582305287903\"\n[1] \"135 -797.59559351846\"\n[1] \"136 -797.60862203023\"\n[1] \"137 -797.621396053073\"\n[1] \"138 -797.63392072454\"\n[1] \"139 -797.64620109022\"\n[1] \"140 -797.658242104202\"\n[1] \"141 -797.670048629657\"\n[1] \"142 -797.681625439487\"\n[1] \"143 -797.69297721708\"\n[1] \"144 -797.704108557119\"\n[1] \"145 -797.715023966472\"\n[1] \"146 -797.725727865145\"\n[1] \"147 -797.736224587263\"\n[1] \"148 -797.746518382131\"\n[1] \"149 -797.756613415304\"\n[1] \"150 -797.76651376971\"\n[1] \"151 -797.7762234468\"\n[1] \"152 -797.785746367723\"\n[1] \"153 -797.795086374513\"\n[1] \"154 -797.804247231306\"\n[1] \"155 -797.813232625571\"\n[1] \"156 -797.822046169342\"\n[1] \"157 -797.830691400458\"\n[1] \"158 -797.839171783827\"\n[1] \"159 -797.847490712661\"\n[1] \"160 -797.855651509745\"\n[1] \"161 -797.863657428678\"\n[1] \"162 -797.871511655122\"\n[1] \"163 -797.879217308054\"\n[1] \"164 -797.886777440985\"\n[1] \"165 -797.894195043205\"\n[1] \"166 -797.90147304099\"\n[1] \"167 -797.908614298819\"\n[1] \"168 -797.915621620562\"\n[1] \"169 -797.922497750669\"\n[1] \"170 -797.929245375344\"\n[1] \"171 -797.9358671237\"\n[1] \"172 -797.9423655689\"\n[1] \"173 -797.948743229288\"\n[1] \"174 -797.955002569502\"\n[1] \"175 -797.961146001572\"\n[1] \"176 -797.967175885998\"\n[1] \"177 -797.973094532816\"\n[1] \"178 -797.978904202649\"\n[1] \"179 -797.984607107732\"\n[1] \"180 -797.990205412934\"\n[1] \"181 -797.995701236747\"\n[1] \"182 -798.001096652276\"\n[1] \"183 -798.00639368819\"\n[1] \"184 -798.011594329679\"\n[1] \"185 -798.016700519376\"\n[1] \"186 -798.021714158272\"\n[1] \"187 -798.026637106607\"\n[1] \"188 -798.031471184755\"\n[1] \"189 -798.036218174075\"\n[1] \"190 -798.040879817769\"\n[1] \"191 -798.045457821692\"\n[1] \"192 -798.049953855185\"\n[1] \"193 -798.054369551851\"\n[1] \"194 -798.05870651035\"\n[1] \"195 -798.062966295148\"\n[1] \"196 -798.067150437282\"\n[1] \"197 -798.071260435079\"\n[1] \"198 -798.075297754882\"\n[1] \"199 -798.079263831748\"\n[1] \"200 -798.083160070137\"\n[1] \"201 -798.086987844591\"\n[1] \"202 -798.090748500386\"\n[1] \"203 -798.09444335418\"\n[1] \"204 -798.098073694649\"\n[1] \"205 -798.101640783097\"\n[1] \"206 -798.105145854065\"\n[1] \"207 -798.108590115927\"\n[1] \"208 -798.111974751461\"\n[1] \"209 -798.115300918418\"\n[1] \"210 -798.118569750079\"\n[1] \"211 -798.121782355791\"\n[1] \"212 -798.124939821503\"\n[1] \"213 -798.12804321028\"\n[1] \"214 -798.131093562808\"\n[1] \"215 -798.134091897896\"\n[1] \"216 -798.137039212953\"\n[1] \"217 -798.139936484467\"\n[1] \"218 -798.142784668468\"\n[1] \"219 -798.145584700974\"\n[1] \"220 -798.148337498443\"\n[1] \"221 -798.151043958199\"\n[1] \"222 -798.153704958857\"\n[1] \"223 -798.156321360739\"\n[1] \"224 -798.158894006272\"\n[1] \"225 -798.161423720393\"\n[1] \"226 -798.163911310923\"\n[1] \"227 -798.166357568953\"\n[1] \"228 -798.168763269211\"\n[1] \"229 -798.171129170422\"\n[1] \"230 -798.17345601566\"\n[1] \"231 -798.175744532692\"\n[1] \"232 -798.177995434322\"\n[1] \"233 -798.180209418701\"\n[1] \"234 -798.182387169675\"\n[1] \"235 -798.184529357078\"\n[1] \"236 -798.186636637044\"\n[1] \"237 -798.188709652318\"\n[1] \"238 -798.190749032534\"\n[1] \"239 -798.192755394513\"\n[1] \"240 -798.194729342538\"\n[1] \"241 -798.196671468625\"\n[1] \"242 -798.198582352799\"\n[1] \"243 -798.200462563351\"\n[1] \"244 -798.202312657088\"\n[1] \"245 -798.204133179594\"\n[1] \"246 -798.205924665464\"\n[1] \"247 -798.207687638551\"\n[1] \"248 -798.20942261219\"\n[1] \"249 -798.211130089435\"\n[1] \"250 -798.212810563274\"\n[1] \"251 -798.21446451685\"\n[1] \"252 -798.216092423678\"\n[1] \"253 -798.217694747843\"\n[1] \"254 -798.219271944213\"\n[1] \"255 -798.220824458628\"\n[1] \"256 -798.222352728105\"\n[1] \"257 -798.223857181019\"\n[1] \"258 -798.225338237289\"\n[1] \"259 -798.226796308567\"\n[1] \"260 -798.228231798405\"\n[1] \"261 -798.229645102433\"\n[1] \"262 -798.23103660853\"\n[1] \"263 -798.232406696983\"\n[1] \"264 -798.23375574066\"\n[1] \"265 -798.235084105151\"\n[1] \"266 -798.236392148941\"\n[1] \"267 -798.237680223545\"\n[1] \"268 -798.238948673667\"\n[1] \"269 -798.240197837341\"\n[1] \"270 -798.241428046066\"\n[1] \"271 -798.242639624954\"\n[1] \"272 -798.243832892855\"\n[1] \"273 -798.245008162496\"\n[1] \"274 -798.246165740607\"\n[1] \"275 -798.247305928047\"\n[1] \"276 -798.248429019925\"\n[1] \"277 -798.249535305724\"\n[1] \"278 -798.25062506942\"\n[1] \"279 -798.251698589588\"\n[1] \"280 -798.252756139525\"\n[1] \"281 -798.253797987356\"\n[1] \"282 -798.25482439614\"\n[1] \"283 -798.255835623974\"\n[1] \"284 -798.256831924102\"\n[1] \"285 -798.25781354501\"\n[1] \"286 -798.258780730528\"\n[1] \"287 -798.25973371992\"\n[1] \"288 -798.260672747986\"\n[1] \"289 -798.261598045149\"\n[1] \"290 -798.262509837546\"\n[1] \"291 -798.263408347115\"\n[1] \"292 -798.264293791686\"\n[1] \"293 -798.265166385056\"\n[1] \"294 -798.266026337078\"\n[1] \"295 -798.266873853745\"\n[1] \"296 -798.267709137254\"\n[1] \"297 -798.268532386102\"\n[1] \"298 -798.269343795146\"\n[1] \"299 -798.270143555685\"\n[1] \"300 -798.270931855528\"\n[1] \"1 -807.073770554476\"\n[1] \"2 -802.091598793657\"\n[1] \"3 -800.291323157396\"\n[1] \"4 -799.576793898169\"\n[1] \"5 -799.497545977621\"\n[1] \"6 -799.64166892881\"\n[1] \"7 -799.775339544768\"\n[1] \"8 -799.853193696268\"\n[1] \"9 -799.883847592718\"\n[1] \"10 -799.880471772605\"\n[1] \"11 -799.850533301202\"\n[1] \"12 -799.795945457316\"\n[1] \"13 -799.715384549652\"\n[1] \"14 -799.606421530257\"\n[1] \"15 -799.466910246596\"\n[1] \"16 -799.295718886231\"\n[1] \"17 -799.093047774066\"\n[1] \"18 -798.860529044739\"\n[1] \"19 -798.601211528377\"\n[1] \"20 -798.319463648812\"\n[1] \"21 -798.020791659831\"\n[1] \"22 -797.711564190235\"\n[1] \"23 -797.398646819383\"\n[1] \"24 -797.088972089573\"\n[1] \"25 -796.78909110847\"\n[1] \"26 -796.504764179085\"\n[1] \"27 -796.240644724562\"\n[1] \"28 -796.000093556446\"\n[1] \"29 -795.785134899563\"\n[1] \"30 -795.5965398008\"\n[1] \"31 -795.434003867114\"\n[1] \"32 -795.296378277123\"\n[1] \"33 -795.181915096312\"\n[1] \"34 -795.088496714656\"\n[1] \"35 -795.013830584684\"\n[1] \"36 -794.955601061529\"\n[1] \"37 -794.911578202047\"\n[1] \"38 -794.879688388818\"\n[1] \"39 -794.858053995729\"\n[1] \"40 -794.845009758997\"\n[1] \"41 -794.839102828719\"\n[1] \"42 -794.839082260576\"\n[1] \"1 -879.115977629218\"\n[1] \"2 -867.31324471707\"\n[1] \"3 -860.67989709907\"\n[1] \"4 -856.760285115944\"\n[1] \"5 -852.976688546781\"\n[1] \"6 -849.426344478111\"\n[1] \"7 -846.255820669144\"\n[1] \"8 -843.643242047748\"\n[1] \"9 -841.716845898131\"\n[1] \"10 -840.45378957008\"\n[1] \"11 -839.703943889247\"\n[1] \"12 -839.290300397013\"\n[1] \"13 -839.073753012708\"\n[1] \"14 -838.964852085877\"\n[1] \"15 -838.912116107962\"\n[1] \"16 -838.887760145476\"\n[1] \"17 -838.877368323293\"\n[1] \"18 -838.873658271819\"\n[1] \"19 -838.873028427766\"\n[1] \"1 -854.852635180356\"\n[1] \"2 -851.92471877406\"\n[1] \"3 -850.182437921388\"\n[1] \"4 -848.466706801413\"\n[1] \"5 -846.978388740823\"\n[1] \"6 -845.73148029941\"\n[1] \"7 -844.610655799819\"\n[1] \"8 -843.447346389117\"\n[1] \"9 -842.108031872465\"\n[1] \"10 -840.534971015544\"\n[1] \"11 -838.739590248677\"\n[1] \"12 -836.783084442626\"\n[1] \"13 -834.767284587477\"\n[1] \"14 -832.828035122864\"\n[1] \"15 -831.107330787978\"\n[1] \"16 -829.705007227476\"\n[1] \"17 -828.646125847856\"\n[1] \"18 -827.889203404974\"\n[1] \"19 -827.360113686965\"\n[1] \"20 -826.983331709186\"\n[1] \"21 -826.697735589104\"\n[1] \"22 -826.459694602105\"\n[1] \"23 -826.240267882966\"\n[1] \"24 -826.021139568844\"\n[1] \"25 -825.7911946343\"\n[1] \"26 -825.544131193112\"\n[1] \"27 -825.276948624077\"\n[1] \"28 -824.989037764174\"\n[1] \"29 -824.681634153242\"\n[1] \"30 -824.357459055248\"\n[1] \"31 -824.020430749891\"\n[1] \"32 -823.675375415851\"\n[1] \"33 -823.327705080588\"\n[1] \"34 -822.983061221461\"\n[1] \"35 -822.646945982195\"\n[1] \"36 -822.324376560253\"\n[1] \"37 -822.019600619908\"\n[1] \"38 -821.73590230574\"\n[1] \"39 -821.475512972323\"\n[1] \"40 -821.239623208658\"\n[1] \"41 -821.028478080911\"\n[1] \"42 -820.841528910851\"\n[1] \"43 -820.677613054905\"\n[1] \"44 -820.535136713204\"\n[1] \"45 -820.412242438354\"\n[1] \"46 -820.306950417983\"\n[1] \"47 -820.217269123571\"\n[1] \"48 -820.141275733105\"\n[1] \"49 -820.077169711569\"\n[1] \"50 -820.023304348233\"\n[1] \"51 -819.978201343298\"\n[1] \"52 -819.940553143625\"\n[1] \"53 -819.909216995685\"\n[1] \"54 -819.88320385214\"\n[1] \"55 -819.861664478677\"\n[1] \"56 -819.843874429426\"\n[1] \"57 -819.82921901535\"\n[1] \"58 -819.817178975842\"\n[1] \"59 -819.807317262148\"\n[1] \"60 -819.799267130562\"\n[1] \"61 -819.79272160232\"\n[1] \"62 -819.78742425772\"\n[1] \"63 -819.783161279089\"\n[1] \"64 -819.779754629667\"\n[1] \"65 -819.777056244525\"\n[1] \"66 -819.774943109461\"\n[1] \"67 -819.773313109942\"\n[1] \"68 -819.772081541715\"\n[1] \"69 -819.771178185993\"\n[1] \"70 -819.770544863536\"\n[1] \"1 -859.377164660012\"\n[1] \"2 -861.505740375675\"\n[1] \"3 -853.347041966199\"\n[1] \"4 -844.60272246888\"\n[1] \"5 -834.671118419216\"\n[1] \"6 -826.420433837391\"\n[1] \"7 -821.988803666758\"\n[1] \"8 -819.957857157476\"\n[1] \"9 -818.900882390623\"\n[1] \"10 -818.258834946379\"\n[1] \"11 -817.841709012005\"\n[1] \"12 -817.562832894988\"\n[1] \"13 -817.367770970364\"\n[1] \"14 -817.218960931744\"\n[1] \"15 -817.090635300946\"\n[1] \"16 -816.965263447313\"\n[1] \"17 -816.830745904258\"\n[1] \"18 -816.678429957345\"\n[1] \"19 -816.501847809142\"\n[1] \"20 -816.295987712457\"\n[1] \"21 -816.056922520146\"\n[1] \"22 -815.781665556336\"\n[1] \"23 -815.46816391769\"\n[1] \"24 -815.115365651395\"\n[1] \"25 -814.72331213385\"\n[1] \"26 -814.293215395671\"\n[1] \"27 -813.827486701247\"\n[1] \"28 -813.329690680168\"\n[1] \"29 -812.804410407617\"\n[1] \"30 -812.257023016131\"\n[1] \"31 -811.693401037061\"\n[1] \"32 -811.119568824263\"\n[1] \"33 -810.541352769443\"\n[1] \"34 -809.964065935366\"\n[1] \"35 -809.392261406247\"\n[1] \"36 -808.829575730094\"\n[1] \"37 -808.278668013356\"\n[1] \"38 -807.741245941348\"\n[1] \"39 -807.218160690144\"\n[1] \"40 -806.709549732948\"\n[1] \"41 -806.215009142386\"\n[1] \"42 -805.733783011482\"\n[1] \"43 -805.264964499667\"\n[1] \"44 -804.807708132382\"\n[1] \"45 -804.361453324226\"\n[1] \"46 -803.926151125804\"\n[1] \"47 -803.502467764438\"\n[1] \"48 -803.091913824919\"\n[1] \"49 -802.69683224211\"\n[1] \"50 -802.320194212911\"\n[1] \"51 -801.965210533201\"\n[1] \"52 -801.634844609164\"\n[1] \"53 -801.331363135427\"\n[1] \"54 -801.0560448305\"\n[1] \"55 -800.809097994895\"\n[1] \"56 -800.589760822305\"\n[1] \"57 -800.396514032589\"\n[1] \"58 -800.227331237419\"\n[1] \"59 -800.079912826337\"\n[1] \"60 -799.9518751137\"\n[1] \"61 -799.840886946616\"\n[1] \"62 -799.744758070513\"\n[1] \"63 -799.661488759069\"\n[1] \"64 -799.589291124469\"\n[1] \"65 -799.526591301372\"\n[1] \"66 -799.472019734048\"\n[1] \"67 -799.424394827158\"\n[1] \"68 -799.382703558807\"\n[1] \"69 -799.346081378776\"\n[1] \"70 -799.313792795966\"\n[1] \"71 -799.285213428862\"\n[1] \"72 -799.259813879324\"\n[1] \"73 -799.237145530642\"\n[1] \"74 -799.216828217171\"\n[1] \"75 -799.198539629078\"\n[1] \"76 -799.182006276658\"\n[1] \"77 -799.166995827117\"\n[1] \"78 -799.153310631261\"\n[1] \"79 -799.140782270698\"\n[1] \"80 -799.129266973443\"\n[1] \"81 -799.118641764171\"\n[1] \"82 -799.10880123342\"\n[1] \"83 -799.099654826664\"\n[1] \"84 -799.091124569133\"\n[1] \"85 -799.083143155416\"\n[1] \"86 -799.075652344122\"\n[1] \"87 -799.068601607678\"\n[1] \"88 -799.061946995407\"\n[1] \"89 -799.055650175056\"\n[1] \"90 -799.049677623622\"\n[1] \"91 -799.043999943279\"\n[1] \"92 -799.038591282137\"\n[1] \"93 -799.033428842998\"\n[1] \"94 -799.028492466044\"\n[1] \"95 -799.023764273706\"\n[1] \"96 -799.01922836791\"\n[1] \"97 -799.014870571513\"\n[1] \"98 -799.010678207047\"\n[1] \"99 -799.006639907034\"\n[1] \"100 -799.002745451039\"\n[1] \"101 -798.998985625414\"\n[1] \"102 -798.99535210233\"\n[1] \"103 -798.991837335222\"\n[1] \"104 -798.988434468225\"\n[1] \"105 -798.985137257575\"\n[1] \"106 -798.981940003238\"\n[1] \"107 -798.978837489307\"\n[1] \"108 -798.975824931917\"\n[1] \"109 -798.972897933672\"\n[1] \"110 -798.970052443616\"\n[1] \"111 -798.967284722062\"\n[1] \"112 -798.964591309572\"\n[1] \"113 -798.961968999573\"\n[1] \"114 -798.959414814105\"\n[1] \"115 -798.956925982314\"\n[1] \"116 -798.95449992134\"\n[1] \"117 -798.952134219279\"\n[1] \"118 -798.949826619985\"\n[1] \"119 -798.947575009477\"\n[1] \"120 -798.945377403758\"\n[1] \"121 -798.94323193788\"\n[1] \"122 -798.941136856108\"\n[1] \"123 -798.939090503059\"\n[1] \"124 -798.93709131571\"\n[1] \"125 -798.935137816163\"\n[1] \"126 -798.933228605099\"\n[1] \"127 -798.931362355851\"\n[1] \"128 -798.929537809001\"\n[1] \"129 -798.927753767482\"\n[1] \"130 -798.926009092114\"\n[1] \"131 -798.924302697524\"\n[1] \"132 -798.922633548433\"\n[1] \"133 -798.921000656247\"\n[1] \"134 -798.91940307595\"\n[1] \"135 -798.917839903247\"\n[1] \"136 -798.916310271937\"\n[1] \"137 -798.914813351522\"\n[1] \"138 -798.913348344972\"\n[1] \"139 -798.911914486712\"\n[1] \"140 -798.91051104072\"\n[1] \"141 -798.909137298807\"\n[1] \"142 -798.907792579016\"\n[1] \"143 -798.906476224131\"\n[1] \"144 -798.905187600321\"\n[1] \"145 -798.903926095857\"\n[1] \"146 -798.902691119948\"\n[1] \"147 -798.901482101635\"\n[1] \"148 -798.900298488784\"\n[1] \"149 -798.899139747138\"\n[1] \"150 -798.898005359437\"\n[1] \"151 -798.896894824597\"\n[1] \"152 -798.895807656947\"\n[1] \"153 -798.894743385513\"\n[1] \"154 -798.893701553348\"\n[1] \"155 -798.892681716908\"\n[1] \"156 -798.891683445465\"\n[1] \"157 -798.890706320555\"\n[1] \"158 -798.889749935467\"\n[1] \"159 -798.888813894752\"\n[1] \"160 -798.887897813767\"\n[1] \"161 -798.887001318249\"\n[1] \"162 -798.886124043905\"\n[1] \"163 -798.885265636027\"\n[1] \"164 -798.884425749133\"\n[1] \"165 -798.883604046628\"\n[1] \"166 -798.882800200471\"\n[1] \"167 -798.882013890872\"\n[1] \"1 -818.645702858243\"\n[1] \"2 -815.005820887183\"\n[1] \"3 -814.011220911233\"\n[1] \"4 -814.069016953648\"\n[1] \"5 -814.274831110033\"\n[1] \"6 -814.453228611546\"\n[1] \"7 -814.588994594027\"\n[1] \"8 -814.690528356209\"\n[1] \"9 -814.767088350001\"\n[1] \"10 -814.825897788711\"\n[1] \"11 -814.872249019595\"\n[1] \"12 -814.909976505224\"\n[1] \"13 -814.941874919616\"\n[1] \"14 -814.970003526016\"\n[1] \"15 -814.995893022367\"\n[1] \"16 -815.020683663692\"\n[1] \"17 -815.045219044694\"\n[1] \"18 -815.070112340004\"\n[1] \"19 -815.095795443505\"\n[1] \"20 -815.12255712431\"\n[1] \"21 -815.150573674442\"\n[1] \"22 -815.179934018054\"\n[1] \"23 -815.210660439891\"\n[1] \"24 -815.242725672369\"\n[1] \"25 -815.276066873148\"\n[1] \"26 -815.310596922847\"\n[1] \"27 -815.346213418535\"\n[1] \"28 -815.382805703545\"\n[1] \"29 -815.42026024458\"\n[1] \"30 -815.458464637501\"\n[1] \"31 -815.497310492513\"\n[1] \"32 -815.536695418203\"\n[1] \"33 -815.576524293054\"\n[1] \"34 -815.61670998377\"\n[1] \"35 -815.657173642788\"\n[1] \"36 -815.697844693234\"\n[1] \"37 -815.738660588468\"\n[1] \"38 -815.779566415402\"\n[1] \"39 -815.820514395533\"\n[1] \"40 -815.861463325247\"\n[1] \"41 -815.902377986659\"\n[1] \"42 -815.943228552239\"\n[1] \"43 -815.983989999891\"\n[1] \"44 -816.024641550278\"\n[1] \"45 -816.065166134185\"\n[1] \"46 -816.105549894881\"\n[1] \"47 -816.145781728244\"\n[1] \"48 -816.185852861754\"\n[1] \"49 -816.225756472359\"\n[1] \"50 -816.265487342417\"\n[1] \"51 -816.305041552295\"\n[1] \"52 -816.344416207928\"\n[1] \"53 -816.383609201333\"\n[1] \"54 -816.422619002013\"\n[1] \"55 -816.461444477058\"\n[1] \"56 -816.50008473782\"\n[1] \"57 -816.538539010981\"\n[1] \"58 -816.576806531913\"\n[1] \"59 -816.614886458301\"\n[1] \"60 -816.65277780204\"\n[1] \"61 -816.690479377501\"\n[1] \"62 -816.727989764353\"\n[1] \"63 -816.765307283208\"\n[1] \"64 -816.802429982444\"\n[1] \"65 -816.839355634664\"\n[1] \"66 -816.876081741339\"\n[1] \"67 -816.912605544296\"\n[1] \"68 -816.948924042783\"\n[1] \"69 -816.985034015019\"\n[1] \"70 -817.02093204312\"\n[1] \"71 -817.056614540563\"\n[1] \"72 -817.092077781239\"\n[1] \"73 -817.127317929485\"\n[1] \"74 -817.162331070362\"\n[1] \"75 -817.19711323968\"\n[1] \"76 -817.231660453289\"\n[1] \"77 -817.265968735271\"\n[1] \"78 -817.300034144698\"\n[1] \"79 -817.333852800747\"\n[1] \"80 -817.367420905963\"\n[1] \"81 -817.400734767561\"\n[1] \"82 -817.433790816682\"\n[1] \"83 -817.466585625573\"\n[1] \"84 -817.499115922685\"\n[1] \"85 -817.531378605719\"\n[1] \"86 -817.563370752677\"\n[1] \"87 -817.595089631001\"\n[1] \"88 -817.626532704868\"\n[1] \"89 -817.657697640784\"\n[1] \"90 -817.688582311545\"\n[1] \"91 -817.719184798716\"\n[1] \"92 -817.749503393734\"\n[1] \"93 -817.779536597761\"\n[1] \"94 -817.80928312042\"\n[1] \"95 -817.838741877487\"\n[1] \"96 -817.867911987728\"\n[1] \"97 -817.896792768925\"\n[1] \"98 -817.92538373323\"\n[1] \"99 -817.95368458193\"\n[1] \"100 -817.981695199728\"\n[1] \"101 -818.009415648617\"\n[1] \"102 -818.036846161425\"\n[1] \"103 -818.063987135113\"\n[1] \"104 -818.090839123876\"\n[1] \"105 -818.117402832128\"\n[1] \"106 -818.143679107401\"\n[1] \"107 -818.169668933223\"\n[1] \"108 -818.195373422009\"\n[1] \"109 -818.220793808009\"\n[1] \"110 -818.245931440338\"\n[1] \"111 -818.270787776114\"\n[1] \"112 -818.295364373747\"\n[1] \"113 -818.319662886366\"\n[1] \"114 -818.343685055443\"\n[1] \"115 -818.367432704573\"\n[1] \"116 -818.390907733495\"\n[1] \"117 -818.414112112272\"\n[1] \"118 -818.437047875722\"\n[1] \"119 -818.459717118047\"\n[1] \"120 -818.482121987687\"\n[1] \"121 -818.504264682385\"\n[1] \"122 -818.52614744449\"\n[1] \"123 -818.547772556456\"\n[1] \"124 -818.569142336569\"\n[1] \"125 -818.590259134885\"\n[1] \"126 -818.611125329371\"\n[1] \"127 -818.631743322243\"\n[1] \"128 -818.652115536515\"\n[1] \"129 -818.672244412725\"\n[1] \"130 -818.692132405858\"\n[1] \"131 -818.711781982428\"\n[1] \"132 -818.731195617759\"\n[1] \"133 -818.750375793412\"\n[1] \"134 -818.769324994767\"\n[1] \"135 -818.788045708786\"\n[1] \"136 -818.80654042188\"\n[1] \"137 -818.824811617955\"\n[1] \"138 -818.842861776564\"\n[1] \"139 -818.860693371197\"\n[1] \"140 -818.87830886769\"\n[1] \"141 -818.895710722747\"\n[1] \"142 -818.912901382568\"\n[1] \"143 -818.929883281593\"\n[1] \"144 -818.946658841322\"\n[1] \"145 -818.963230469247\"\n[1] \"146 -818.979600557868\"\n[1] \"147 -818.995771483774\"\n[1] \"148 -819.011745606828\"\n[1] \"149 -819.027525269406\"\n[1] \"150 -819.043112795717\"\n[1] \"151 -819.058510491177\"\n[1] \"152 -819.073720641853\"\n[1] \"153 -819.088745513966\"\n[1] \"154 -819.103587353436\"\n[1] \"155 -819.118248385491\"\n[1] \"156 -819.132730814314\"\n[1] \"157 -819.147036822743\"\n[1] \"158 -819.161168572007\"\n[1] \"159 -819.175128201491\"\n[1] \"160 -819.188917828566\"\n[1] \"161 -819.202539548424\"\n[1] \"162 -819.215995433951\"\n[1] \"163 -819.229287535644\"\n[1] \"164 -819.242417881544\"\n[1] \"165 -819.255388477187\"\n[1] \"166 -819.268201305594\"\n[1] \"167 -819.280858327272\"\n[1] \"168 -819.293361480246\"\n[1] \"169 -819.305712680091\"\n[1] \"170 -819.317913820007\"\n[1] \"171 -819.329966770887\"\n[1] \"172 -819.341873381407\"\n[1] \"173 -819.353635478139\"\n[1] \"174 -819.365254865662\"\n[1] \"175 -819.376733326696\"\n[1] \"176 -819.388072622235\"\n[1] \"177 -819.399274491701\"\n[1] \"178 -819.4103406531\"\n[1] \"179 -819.421272803181\"\n[1] \"180 -819.43207261762\"\n[1] \"181 -819.442741751186\"\n[1] \"182 -819.453281837929\"\n[1] \"183 -819.463694491376\"\n[1] \"184 -819.473981304709\"\n[1] \"185 -819.484143850979\"\n[1] \"186 -819.494183683294\"\n[1] \"187 -819.504102335027\"\n[1] \"188 -819.513901320028\"\n[1] \"189 -819.523582132818\"\n[1] \"190 -819.533146248817\"\n[1] \"191 -819.542595124536\"\n[1] \"192 -819.551930197808\"\n[1] \"193 -819.561152887986\"\n[1] \"194 -819.57026459617\"\n[1] \"195 -819.579266705405\"\n[1] \"196 -819.588160580914\"\n[1] \"197 -819.596947570298\"\n[1] \"198 -819.605629003751\"\n[1] \"199 -819.614206194282\"\n[1] \"200 -819.622680437914\"\n[1] \"201 -819.631053013905\"\n[1] \"202 -819.639325184956\"\n[1] \"203 -819.647498197415\"\n[1] \"204 -819.655573281496\"\n[1] \"205 -819.663551651468\"\n[1] \"206 -819.671434505881\"\n[1] \"207 -819.679223027748\"\n[1] \"208 -819.686918384764\"\n[1] \"209 -819.694521729494\"\n[1] \"210 -819.702034199577\"\n[1] \"211 -819.709456917923\"\n[1] \"212 -819.716790992902\"\n[1] \"213 -819.724037518541\"\n[1] \"214 -819.731197574713\"\n[1] \"215 -819.738272227322\"\n[1] \"216 -819.745262528497\"\n[1] \"217 -819.752169516768\"\n[1] \"218 -819.758994217256\"\n[1] \"219 -819.765737641842\"\n[1] \"220 -819.772400789357\"\n[1] \"221 -819.778984645752\"\n[1] \"222 -819.785490184268\"\n[1] \"223 -819.791918365617\"\n[1] \"224 -819.798270138141\"\n[1] \"225 -819.804546437984\"\n[1] \"226 -819.810748189264\"\n[1] \"227 -819.816876304219\"\n[1] \"228 -819.822931683385\"\n[1] \"229 -819.828915215744\"\n[1] \"230 -819.834827778884\"\n[1] \"231 -819.840670239158\"\n[1] \"232 -819.846443451824\"\n[1] \"233 -819.852148261211\"\n[1] \"234 -819.857785500853\"\n[1] \"235 -819.863355993649\"\n[1] \"236 -819.868860551997\"\n[1] \"237 -819.874299977935\"\n[1] \"238 -819.879675063293\"\n[1] \"239 -819.884986589821\"\n[1] \"240 -819.890235329328\"\n[1] \"241 -819.895422043819\"\n[1] \"242 -819.900547485625\"\n[1] \"243 -819.905612397537\"\n[1] \"244 -819.910617512924\"\n[1] \"245 -819.915563555881\"\n[1] \"246 -819.920451241331\"\n[1] \"247 -819.925281275166\"\n[1] \"248 -819.93005435436\"\n[1] \"249 -819.934771167092\"\n[1] \"250 -819.939432392862\"\n[1] \"251 -819.944038702611\"\n[1] \"252 -819.948590758832\"\n[1] \"253 -819.953089215688\"\n[1] \"254 -819.957534719118\"\n[1] \"255 -819.961927906952\"\n[1] \"256 -819.966269409019\"\n[1] \"257 -819.970559847248\"\n[1] \"258 -819.974799835783\"\n[1] \"259 -819.97898998108\"\n[1] \"260 -819.983130882009\"\n[1] \"261 -819.98722312996\"\n[1] \"262 -819.99126730894\"\n[1] \"263 -819.995263995667\"\n[1] \"264 -819.999213759678\"\n[1] \"265 -820.003117163408\"\n[1] \"266 -820.006974762296\"\n[1] \"267 -820.010787104878\"\n[1] \"268 -820.014554732871\"\n[1] \"269 -820.018278181263\"\n[1] \"270 -820.021957978411\"\n[1] \"271 -820.025594646118\"\n[1] \"272 -820.02918869973\"\n[1] \"273 -820.032740648204\"\n[1] \"274 -820.036250994213\"\n[1] \"275 -820.039720234212\"\n[1] \"276 -820.043148858524\"\n[1] \"277 -820.046537351426\"\n[1] \"278 -820.049886191216\"\n[1] \"279 -820.053195850308\"\n[1] \"280 -820.05646679529\"\n[1] \"281 -820.059699487015\"\n[1] \"282 -820.062894380666\"\n[1] \"283 -820.066051925833\"\n[1] \"284 -820.069172566588\"\n[1] \"285 -820.072256741555\"\n[1] \"286 -820.075304883975\"\n[1] \"287 -820.078317421784\"\n[1] \"288 -820.081294777679\"\n[1] \"289 -820.084237369178\"\n[1] \"290 -820.087145608704\"\n[1] \"291 -820.090019903635\"\n[1] \"292 -820.092860656365\"\n[1] \"293 -820.095668264393\"\n[1] \"294 -820.098443120361\"\n[1] \"295 -820.101185612124\"\n[1] \"296 -820.103896122814\"\n[1] \"297 -820.106575030903\"\n[1] \"298 -820.109222710252\"\n[1] \"299 -820.111839530183\"\n[1] \"300 -820.114425855522\"\n[1] \"301 -820.116982046672\"\n[1] \"302 -820.119508459659\"\n[1] \"303 -820.122005446191\"\n[1] \"304 -820.124473353712\"\n[1] \"305 -820.126912525458\"\n[1] \"306 -820.129323300508\"\n[1] \"307 -820.131706013835\"\n[1] \"308 -820.134060996368\"\n[1] \"309 -820.136388575027\"\n[1] \"310 -820.138689072791\"\n[1] \"311 -820.14096280873\"\n[1] \"312 -820.14321009807\"\n[1] \"313 -820.145431252235\"\n[1] \"314 -820.147626578891\"\n[1] \"315 -820.149796382\"\n[1] \"316 -820.151940961863\"\n[1] \"317 -820.154060615165\"\n[1] \"318 -820.156155635022\"\n[1] \"319 -820.15822631103\"\n[1] \"320 -820.160272929299\"\n[1] \"321 -820.162295772503\"\n[1] \"322 -820.164295119927\"\n[1] \"323 -820.1662712475\"\n[1] \"324 -820.168224427841\"\n[1] \"325 -820.170154930304\"\n[1] \"326 -820.172063021014\"\n[1] \"327 -820.173948962908\"\n[1] \"328 -820.175813015772\"\n[1] \"329 -820.177655436292\"\n[1] \"330 -820.179476478075\"\n[1] \"331 -820.181276391699\"\n[1] \"332 -820.18305542475\"\n[1] \"333 -820.184813821851\"\n[1] \"334 -820.186551824712\"\n[1] \"335 -820.188269672151\"\n[1] \"336 -820.189967600139\"\n[1] \"337 -820.191645841836\"\n[1] \"338 -820.19330462762\"\n[1] \"339 -820.194944185126\"\n[1] \"340 -820.196564739275\"\n[1] \"341 -820.198166512312\"\n[1] \"342 -820.199749723838\"\n[1] \"343 -820.201314590843\"\n[1] \"344 -820.202861327731\"\n[1] \"345 -820.204390146362\"\n[1] \"346 -820.20590125608\"\n[1] \"347 -820.207394863738\"\n[1] \"348 -820.208871173738\"\n[1] \"349 -820.210330388053\"\n[1] \"350 -820.211772706258\"\n[1] \"351 -820.213198325566\"\n[1] \"352 -820.21460744085\"\n[1] \"353 -820.21600024467\"\n[1] \"354 -820.217376927311\"\n[1] \"355 -820.218737676797\"\n[1] \"356 -820.220082678935\"\n[1] \"357 -820.221412117324\"\n[1] \"358 -820.222726173398\"\n[1] \"359 -820.224025026441\"\n[1] \"360 -820.225308853616\"\n[1] \"361 -820.226577829998\"\n[1] \"362 -820.227832128589\"\n[1] \"363 -820.229071920348\"\n[1] \"364 -820.230297374217\"\n[1] \"365 -820.231508657141\"\n[1] \"366 -820.232705934097\"\n[1] \"367 -820.233889368116\"\n[1] \"368 -820.235059120306\"\n[1] \"369 -820.236215349875\"\n[1] \"370 -820.237358214154\"\n[1] \"371 -820.238487868622\"\n[1] \"372 -820.239604466924\"\n[1] \"373 -820.240708160899\"\n[1] \"374 -820.241799100597\"\n[1] \"375 -820.242877434301\"\n[1] \"376 -820.243943308549\"\n[1] \"377 -820.244996868157\"\n[1] \"378 -820.246038256239\"\n[1] \"379 -820.24706761422\"\n[1] \"380 -820.248085081872\"\n[1] \"381 -820.249090797318\"\n[1] \"382 -820.250084897061\"\n[1] \"383 -820.251067516002\"\n[1] \"384 -820.252038787454\"\n[1] \"385 -820.252998843168\"\n[1] \"386 -820.25394781335\"\n[1] \"387 -820.254885826674\"\n[1] \"388 -820.255813010311\"\n[1] \"389 -820.256729489935\"\n[1] \"390 -820.25763538975\"\n[1] \"391 -820.258530832501\"\n[1] \"392 -820.2594159395\"\n[1] \"393 -820.260290830631\"\n[1] \"394 -820.261155624378\"\n[1] \"395 -820.262010437836\"\n[1] \"396 -820.262855386732\"\n[1] \"397 -820.263690585433\"\n[1] \"398 -820.264516146972\"\n[1] \"399 -820.265332183059\"\n[1] \"1 -884.937492865987\"\n[1] \"2 -876.786580934868\"\n[1] \"3 -869.05276349624\"\n[1] \"4 -864.608045141605\"\n[1] \"5 -861.937969853825\"\n[1] \"6 -860.146715105911\"\n[1] \"7 -858.866594972293\"\n[1] \"8 -857.9002635539\"\n[1] \"9 -857.12475810377\"\n[1] \"10 -856.464300480836\"\n[1] \"11 -855.874346587638\"\n[1] \"12 -855.329949627321\"\n[1] \"13 -854.817817685361\"\n[1] \"14 -854.331242894779\"\n[1] \"15 -853.866991677301\"\n[1] \"16 -853.42345549639\"\n[1] \"17 -852.999596443464\"\n[1] \"18 -852.59439154953\"\n[1] \"19 -852.206586681065\"\n[1] \"20 -851.834637132759\"\n[1] \"21 -851.47675485176\"\n[1] \"22 -851.131011393479\"\n[1] \"23 -850.795465917732\"\n[1] \"24 -850.468300921442\"\n[1] \"25 -850.14795606494\"\n[1] \"26 -849.833253202245\"\n[1] \"27 -849.523504566737\"\n[1] \"28 -849.218592568661\"\n[1] \"29 -848.919006272864\"\n[1] \"30 -848.625819445747\"\n[1] \"31 -848.340600765798\"\n[1] \"32 -848.065258863375\"\n[1] \"33 -847.801840277827\"\n[1] \"34 -847.552311356552\"\n[1] \"35 -847.318359861734\"\n[1] \"36 -847.10124641354\"\n[1] \"37 -846.901722468618\"\n[1] \"38 -846.720015862534\"\n[1] \"39 -846.555872340513\"\n[1] \"40 -846.408634750858\"\n[1] \"41 -846.27734064302\"\n[1] \"42 -846.160822109866\"\n[1] \"43 -846.057796632621\"\n[1] \"44 -845.966942674695\"\n[1] \"45 -845.88695782523\"\n[1] \"46 -845.816600072902\"\n[1] \"47 -845.754714375545\"\n[1] \"48 -845.700247355558\"\n[1] \"49 -845.652253005052\"\n[1] \"50 -845.609891993797\"\n[1] \"51 -845.572426729738\"\n[1] \"52 -845.539213849014\"\n[1] \"53 -845.509695377768\"\n[1] \"54 -845.4833894419\"\n[1] \"55 -845.459881110731\"\n[1] \"56 -845.438813740919\"\n[1] \"57 -845.419881027678\"\n[1] \"58 -845.402819859088\"\n[1] \"59 -845.38740399481\"\n[1] \"60 -845.373438543406\"\n[1] \"61 -845.360755184456\"\n[1] \"62 -845.349208067391\"\n[1] \"63 -845.338670313348\"\n[1] \"64 -845.32903104678\"\n[1] \"65 -845.320192887099\"\n[1] \"66 -845.312069836462\"\n[1] \"67 -845.304585506117\"\n[1] \"68 -845.297671630541\"\n[1] \"69 -845.291266824995\"\n[1] \"70 -845.285315548149\"\n[1] \"71 -845.279767236891\"\n[1] \"72 -845.274575585227\"\n[1] \"73 -845.269697943448\"\n[1] \"74 -845.265094817424\"\n[1] \"75 -845.260729450988\"\n[1] \"76 -845.256567477141\"\n[1] \"77 -845.252576626044\"\n[1] \"78 -845.248726479768\"\n[1] \"79 -845.244988265368\"\n[1] \"80 -845.241334679279\"\n[1] \"81 -845.237739737179\"\n[1] \"82 -845.234178644458\"\n[1] \"83 -845.23062768329\"\n[1] \"84 -845.227064112968\"\n[1] \"85 -845.223466080801\"\n[1] \"86 -845.219812541318\"\n[1] \"87 -845.216083182024\"\n[1] \"88 -845.212258354263\"\n[1] \"89 -845.208319008053\"\n[1] \"90 -845.204246630049\"\n[1] \"91 -845.200023184003\"\n[1] \"92 -845.195631053285\"\n[1] \"93 -845.191052985186\"\n[1] \"94 -845.186272036889\"\n[1] \"95 -845.181271523125\"\n[1] \"96 -845.176034965585\"\n[1] \"97 -845.170546044364\"\n[1] \"98 -845.164788551641\"\n[1] \"99 -845.158746348053\"\n[1] \"100 -845.152403322103\"\n[1] \"101 -845.145743353124\"\n[1] \"102 -845.138750278319\"\n[1] \"103 -845.131407864397\"\n[1] \"104 -845.123699784443\"\n[1] \"105 -845.115609600551\"\n[1] \"106 -845.107120752915\"\n[1] \"107 -845.098216555939\"\n[1] \"108 -845.088880202022\"\n[1] \"109 -845.079094773589\"\n[1] \"110 -845.068843264001\"\n[1] \"111 -845.058108607848\"\n[1] \"112 -845.046873721203\"\n[1] \"113 -845.035121552256\"\n[1] \"114 -845.022835142751\"\n[1] \"115 -845.009997700569\"\n[1] \"116 -844.996592683664\"\n[1] \"117 -844.98260389551\"\n[1] \"118 -844.96801559205\"\n[1] \"119 -844.952812600024\"\n[1] \"120 -844.93698044634\"\n[1] \"121 -844.920505498079\"\n[1] \"122 -844.903375112382\"\n[1] \"123 -844.885577795395\"\n[1] \"124 -844.867103369062\"\n[1] \"125 -844.847943144479\"\n[1] \"126 -844.828090100093\"\n[1] \"127 -844.807539062871\"\n[1] \"128 -844.786286890282\"\n[1] \"129 -844.764332650621\"\n[1] \"130 -844.741677799028\"\n[1] \"131 -844.718326346269\"\n[1] \"132 -844.694285017232\"\n[1] \"133 -844.669563395828\"\n[1] \"134 -844.644174053073\"\n[1] \"135 -844.618132654907\"\n[1] \"136 -844.591458046531\"\n[1] \"137 -844.564172310067\"\n[1] \"138 -844.536300792637\"\n[1] \"139 -844.507872102231\"\n[1] \"140 -844.478918069205\"\n[1] \"141 -844.449473671697\"\n[1] \"142 -844.419576923861\"\n[1] \"143 -844.389268726517\"\n[1] \"144 -844.358592680422\"\n[1] \"145 -844.32759486328\"\n[1] \"146 -844.296323572176\"\n[1] \"147 -844.264829034095\"\n[1] \"148 -844.233163087718\"\n[1] \"149 -844.201378840487\"\n[1] \"150 -844.169530305471\"\n[1] \"151 -844.137672023041\"\n[1] \"152 -844.105858672757\"\n[1] \"153 -844.074144681098\"\n[1] \"154 -844.042583830784\"\n[1] \"155 -844.011228877344\"\n[1] \"156 -843.980131178495\"\n[1] \"157 -843.949340341486\"\n[1] \"158 -843.918903893224\"\n[1] \"159 -843.888866977407\"\n[1] \"160 -843.859272082294\"\n[1] \"161 -843.830158802078\"\n[1] \"162 -843.801563634081\"\n[1] \"163 -843.77351981329\"\n[1] \"164 -843.746057184983\"\n[1] \"165 -843.719202115503\"\n[1] \"166 -843.692977440537\"\n[1] \"167 -843.6674024497\"\n[1] \"168 -843.642492905583\"\n[1] \"169 -843.618261095021\"\n[1] \"170 -843.594715909895\"\n[1] \"171 -843.571862954503\"\n[1] \"172 -843.549704676291\"\n[1] \"173 -843.528240516597\"\n[1] \"174 -843.507467078008\"\n[1] \"175 -843.487378304951\"\n[1] \"176 -843.467965674161\"\n[1] \"177 -843.449218391909\"\n[1] \"178 -843.431123594959\"\n[1] \"179 -843.413666552494\"\n[1] \"180 -843.396830866521\"\n[1] \"181 -843.380598668483\"\n[1] \"182 -843.364950810163\"\n[1] \"183 -843.349867047217\"\n[1] \"184 -843.335326213918\"\n[1] \"185 -843.32130638811\"\n[1] \"186 -843.307785045453\"\n[1] \"187 -843.294739202427\"\n[1] \"188 -843.282145547751\"\n[1] \"189 -843.26998056202\"\n[1] \"190 -843.258220625628\"\n[1] \"191 -843.246842115133\"\n[1] \"192 -843.235821488393\"\n[1] \"193 -843.225135358871\"\n[1] \"194 -843.214760559633\"\n[1] \"195 -843.204674197587\"\n[1] \"196 -843.194853698598\"\n[1] \"197 -843.185276844097\"\n[1] \"198 -843.175921799876\"\n[1] \"199 -843.166767137711\"\n[1] \"200 -843.157791850473\"\n[1] \"201 -843.148975361362\"\n[1] \"202 -843.140297527914\"\n[1] \"203 -843.13173864132\"\n[1] \"204 -843.123279421672\"\n[1] \"205 -843.114901009601\"\n[1] \"206 -843.106584954863\"\n[1] \"207 -843.098313202254\"\n[1] \"208 -843.090068075331\"\n[1] \"209 -843.081832258272\"\n[1] \"210 -843.073588776245\"\n[1] \"211 -843.065320974586\"\n[1] \"212 -843.057012497065\"\n[1] \"213 -843.048647263491\"\n[1] \"214 -843.040209446866\"\n[1] \"215 -843.031683450302\"\n[1] \"216 -843.023053883847\"\n[1] \"217 -843.014305541393\"\n[1] \"218 -843.005423377763\"\n[1] \"219 -842.99639248614\"\n[1] \"220 -842.987198075861\"\n[1] \"221 -842.977825450731\"\n[1] \"222 -842.96825998787\"\n[1] \"223 -842.958487117175\"\n[1] \"224 -842.948492301437\"\n[1] \"225 -842.938261017142\"\n[1] \"226 -842.927778736011\"\n[1] \"227 -842.917030907258\"\n[1] \"228 -842.906002940609\"\n[1] \"229 -842.894680190096\"\n[1] \"230 -842.883047938603\"\n[1] \"231 -842.871091383188\"\n[1] \"232 -842.858795621136\"\n[1] \"233 -842.846145636786\"\n[1] \"234 -842.833126289067\"\n[1] \"235 -842.819722299725\"\n[1] \"236 -842.805918242254\"\n[1] \"237 -842.791698531449\"\n[1] \"238 -842.777047413574\"\n[1] \"239 -842.761948957093\"\n[1] \"240 -842.746387043908\"\n[1] \"241 -842.730345361071\"\n[1] \"242 -842.713807392883\"\n[1] \"243 -842.69675641332\"\n[1] \"244 -842.67917547872\"\n[1] \"245 -842.661047420636\"\n[1] \"246 -842.642354838763\"\n[1] \"247 -842.623080093844\"\n[1] \"248 -842.603205300432\"\n[1] \"249 -842.582712319413\"\n[1] \"250 -842.561582750133\"\n[1] \"251 -842.539797922006\"\n[1] \"252 -842.517338885449\"\n[1] \"253 -842.494186401994\"\n[1] \"254 -842.470320933378\"\n[1] \"255 -842.445722629483\"\n[1] \"256 -842.420371314875\"\n[1] \"257 -842.394246473794\"\n[1] \"258 -842.367327233371\"\n[1] \"259 -842.339592344829\"\n[1] \"260 -842.311020162512\"\n[1] \"261 -842.281588620429\"\n[1] \"262 -842.251275206153\"\n[1] \"263 -842.220056931793\"\n[1] \"264 -842.187910301829\"\n[1] \"265 -842.154811277555\"\n[1] \"266 -842.1207352379\"\n[1] \"267 -842.085656936406\"\n[1] \"268 -842.049550454146\"\n[1] \"269 -842.012389148353\"\n[1] \"270 -841.974145596604\"\n[1] \"271 -841.934791536359\"\n[1] \"272 -841.894297799729\"\n[1] \"273 -841.85263424335\"\n[1] \"274 -841.809769673301\"\n[1] \"275 -841.765671765023\"\n[1] \"276 -841.720306978265\"\n[1] \"277 -841.673640467148\"\n[1] \"278 -841.625635985505\"\n[1] \"279 -841.576255787736\"\n[1] \"280 -841.525460525532\"\n[1] \"281 -841.473209140912\"\n[1] \"282 -841.419458756182\"\n[1] \"283 -841.364164561567\"\n[1] \"284 -841.307279701409\"\n[1] \"285 -841.248755160124\"\n[1] \"286 -841.188539649239\"\n[1] \"287 -841.126579497198\"\n[1] \"288 -841.062818543868\"\n[1] \"289 -840.997198042123\"\n[1] \"290 -840.929656569212\"\n[1] \"291 -840.860129951167\"\n[1] \"292 -840.788551204026\"\n[1] \"293 -840.714850496249\"\n[1] \"294 -840.638955137445\"\n[1] \"295 -840.560789599276\"\n[1] \"296 -840.480275575309\"\n[1] \"297 -840.397332087569\"\n[1] \"298 -840.311875648613\"\n[1] \"299 -840.223820489063\"\n[1] \"300 -840.13307886189\"\n[1] \"301 -840.03956143593\"\n[1] \"302 -839.943177792512\"\n[1] \"303 -839.843837040375\"\n[1] \"304 -839.741448565279\"\n[1] \"305 -839.635922931779\"\n[1] \"306 -839.527172955349\"\n[1] \"307 -839.415114963412\"\n[1] \"308 -839.299670263421\"\n[1] \"309 -839.180766834945\"\n[1] \"310 -839.058341260303\"\n[1] \"311 -838.932340904443\"\n[1] \"312 -838.802726348941\"\n[1] \"313 -838.66947407718\"\n[1] \"314 -838.532579397191\"\n[1] \"315 -838.392059575286\"\n[1] \"316 -838.247957137377\"\n[1] \"317 -838.100343275428\"\n[1] \"318 -837.949321274713\"\n[1] \"319 -837.795029853652\"\n[1] \"320 -837.637646283637\"\n[1] \"321 -837.477389132964\"\n[1] \"322 -837.314520459184\"\n[1] \"323 -837.149347260886\"\n[1] \"324 -836.982221996021\"\n[1] \"325 -836.813541982797\"\n[1] \"326 -836.643747523432\"\n[1] \"327 -836.473318632428\"\n[1] \"328 -836.302770309396\"\n[1] \"329 -836.132646370038\"\n[1] \"330 -835.963511933138\"\n[1] \"331 -835.79594474986\"\n[1] \"332 -835.630525646078\"\n[1] \"333 -835.467828420127\"\n[1] \"334 -835.308409588746\"\n[1] \"335 -835.152798397207\"\n[1] \"336 -835.001487502016\"\n[1] \"337 -834.854924696907\"\n[1] \"338 -834.713505989053\"\n[1] \"339 -834.577570249315\"\n[1] \"340 -834.447395567086\"\n[1] \"341 -834.32319734545\"\n[1] \"342 -834.205128084446\"\n[1] \"343 -834.093278725255\"\n[1] \"344 -833.9876813701\"\n[1] \"345 -833.888313153047\"\n[1] \"346 -833.795101015352\"\n[1] \"347 -833.707927133583\"\n[1] \"348 -833.62663475688\"\n[1] \"349 -833.551034228241\"\n[1] \"350 -833.480908990745\"\n[1] \"351 -833.416021410152\"\n[1] \"352 -833.356118278215\"\n[1] \"353 -833.300935893959\"\n[1] \"354 -833.250204651655\"\n[1] \"355 -833.203653093028\"\n[1] \"356 -833.161011406405\"\n[1] \"357 -833.122014376673\"\n[1] \"358 -833.086403806739\"\n[1] \"359 -833.053930443976\"\n[1] \"360 -833.024355453823\"\n[1] \"361 -832.997451488191\"\n[1] \"362 -832.973003398706\"\n[1] \"363 -832.950808644896\"\n[1] \"364 -832.930677445699\"\n[1] \"365 -832.912432719634\"\n[1] \"366 -832.895909855085\"\n[1] \"367 -832.880956347703\"\n[1] \"368 -832.867431337471\"\n[1] \"369 -832.855205073342\"\n[1] \"370 -832.844158329138\"\n[1] \"371 -832.834181790322\"\n[1] \"372 -832.825175427716\"\n[1] \"373 -832.81704787096\"\n[1] \"374 -832.809715791776\"\n[1] \"375 -832.803103304667\"\n[1] \"376 -832.797141390704\"\n[1] \"377 -832.791767348339\"\n[1] \"378 -832.78692427386\"\n[1] \"379 -832.782560572947\"\n[1] \"380 -832.778629503937\"\n[1] \"381 -832.775088752726\"\n[1] \"382 -832.771900038715\"\n[1] \"383 -832.769028750781\"\n[1] \"384 -832.766443612058\"\n[1] \"385 -832.764116372049\"\n[1] \"386 -832.762021524517\"\n[1] \"387 -832.760136049532\"\n[1] \"388 -832.758439178057\"\n[1] \"389 -832.756912177412\"\n[1] \"390 -832.7555381561\"\n[1] \"391 -832.754301886427\"\n[1] \"392 -832.753189643496\"\n[1] \"393 -832.752189059208\"\n[1] \"394 -832.751288989989\"\n[1] \"395 -832.750479397037\"\n[1] \"1 -811.325696666313\"\n[1] \"2 -817.860292083431\"\n[1] \"3 -821.281240109882\"\n[1] \"4 -823.496341579665\"\n[1] \"5 -825.060281510018\"\n[1] \"6 -826.216871740142\"\n[1] \"7 -827.099106608717\"\n[1] \"8 -827.787844345463\"\n[1] \"9 -828.335616491631\"\n[1] \"10 -828.778160012172\"\n[1] \"11 -829.140635754682\"\n[1] \"12 -829.44123530788\"\n[1] \"13 -829.693390513905\"\n[1] \"14 -829.907187241054\"\n[1] \"15 -830.090303140587\"\n[1] \"16 -830.248648777967\"\n[1] \"17 -830.386817353516\"\n[1] \"18 -830.508407092972\"\n[1] \"19 -830.616256644176\"\n[1] \"20 -830.712619627954\"\n[1] \"21 -830.79929574977\"\n[1] \"22 -830.877730341811\"\n[1] \"23 -830.949090607787\"\n[1] \"24 -831.01432444979\"\n[1] \"25 -831.074206129337\"\n[1] \"26 -831.129371885654\"\n[1] \"27 -831.180347835529\"\n[1] \"28 -831.227571904726\"\n[1] \"29 -831.271411121123\"\n[1] \"30 -831.312175288798\"\n[1] \"31 -831.35012782929\"\n[1] \"32 -831.385494399706\"\n[1] \"33 -831.418469762546\"\n[1] \"34 -831.449223278389\"\n[1] \"35 -831.477903312318\"\n[1] \"36 -831.504640782492\"\n[1] \"37 -831.529552030579\"\n[1] \"38 -831.552741155518\"\n[1] \"39 -831.574301922154\"\n[1] \"40 -831.59431933264\"\n[1] \"41 -831.612870929901\"\n[1] \"42 -831.630027887773\"\n[1] \"43 -831.645855930738\"\n[1] \"44 -831.660416117046\"\n[1] \"45 -831.673765511617\"\n[1] \"46 -831.685957769359\"\n[1] \"47 -831.69704364491\"\n[1] \"48 -831.707071441125\"\n[1] \"49 -831.716087405718\"\n[1] \"50 -831.724136083141\"\n[1] \"51 -831.731260626969\"\n[1] \"52 -831.7375030766\"\n[1] \"53 -831.742904600957\"\n[1] \"54 -831.747505711086\"\n[1] \"55 -831.751346442863\"\n[1] \"56 -831.754466510627\"\n[1] \"57 -831.7569054323\"\n[1] \"58 -831.758702626419\"\n[1] \"59 -831.759897481497\"\n[1] \"60 -831.760529398233\"\n[1] \"1 -882.613942161698\"\n[1] \"2 -878.133415905558\"\n[1] \"3 -871.670975487342\"\n[1] \"4 -863.509204384117\"\n[1] \"5 -855.963428878494\"\n[1] \"6 -850.444488780454\"\n[1] \"7 -847.095951007811\"\n[1] \"8 -844.846623155797\"\n[1] \"9 -843.282673066288\"\n[1] \"10 -842.221045832193\"\n[1] \"11 -841.520451357025\"\n[1] \"12 -841.061863378601\"\n[1] \"13 -840.755389126761\"\n[1] \"14 -840.539956880064\"\n[1] \"15 -840.376947930845\"\n[1] \"16 -840.242903744459\"\n[1] \"17 -840.123721539604\"\n[1] \"18 -840.010682307742\"\n[1] \"19 -839.897909977106\"\n[1] \"20 -839.780784325688\"\n[1] \"21 -839.654956224401\"\n[1] \"22 -839.515752163291\"\n[1] \"23 -839.357854827965\"\n[1] \"24 -839.175206294319\"\n[1] \"25 -838.96111191567\"\n[1] \"26 -838.70853844531\"\n[1] \"27 -838.4106071024\"\n[1] \"28 -838.061281972001\"\n[1] \"29 -837.656240290858\"\n[1] \"30 -837.193874172729\"\n[1] \"31 -836.676307473088\"\n[1] \"32 -836.110227448931\"\n[1] \"33 -835.507268495827\"\n[1] \"34 -834.883708337925\"\n[1] \"35 -834.259376268806\"\n[1] \"36 -833.655790287794\"\n[1] \"37 -833.093097117283\"\n[1] \"38 -832.58296111847\"\n[1] \"39 -832.106649420412\"\n[1] \"40 -831.549890278729\"\n[1] \"41 -830.582876068161\"\n[1] \"42 -828.826242062658\"\n[1] \"43 -826.512063771391\"\n[1] \"44 -823.543252534587\"\n[1] \"45 -819.975722971767\"\n[1] \"46 -816.764324976477\"\n[1] \"47 -813.839328775938\"\n[1] \"48 -811.132288191954\"\n[1] \"49 -808.656097813239\"\n[1] \"50 -806.462721371818\"\n[1] \"51 -804.615048812251\"\n[1] \"52 -803.145555479112\"\n[1] \"53 -802.036531871857\"\n[1] \"54 -801.232597098017\"\n[1] \"55 -800.665406017434\"\n[1] \"56 -800.271758230079\"\n[1] \"57 -800.001081377367\"\n[1] \"58 -799.815981762989\"\n[1] \"59 -799.689946009883\"\n[1] \"60 -799.604532650141\"\n[1] \"61 -799.546979095854\"\n[1] \"62 -799.508422138162\"\n[1] \"63 -799.482654085321\"\n[1] \"64 -799.46527505645\"\n[1] \"65 -799.453118237458\"\n[1] \"66 -799.443858126739\"\n[1] \"67 -799.435740945879\"\n[1] \"68 -799.427397276311\"\n[1] \"69 -799.41771084433\"\n[1] \"70 -799.405726379941\"\n[1] \"71 -799.390585377782\"\n[1] \"72 -799.37148256407\"\n[1] \"73 -799.347638637249\"\n[1] \"74 -799.318286803091\"\n[1] \"75 -799.282671944736\"\n[1] \"76 -799.24006195061\"\n[1] \"77 -799.18977060782\"\n[1] \"78 -799.131190293551\"\n[1] \"79 -799.063830251075\"\n[1] \"80 -798.987352669928\"\n[1] \"81 -798.901595035038\"\n[1] \"82 -798.806565254631\"\n[1] \"83 -798.7023985377\"\n[1] \"84 -798.58927356841\"\n[1] \"85 -798.467298833085\"\n[1] \"86 -798.33639263819\"\n[1] \"87 -798.19618545934\"\n[1] \"88 -798.045967157879\"\n[1] \"89 -797.884687348061\"\n[1] \"90 -797.711002636159\"\n[1] \"91 -797.52335651342\"\n[1] \"92 -797.320078118037\"\n[1] \"93 -797.099491800561\"\n[1] \"94 -796.860035842598\"\n[1] \"95 -796.600392561416\"\n[1] \"96 -796.319632263182\"\n[1] \"97 -796.017370348518\"\n[1] \"98 -795.693931068578\"\n[1] \"99 -795.350503843015\"\n[1] \"100 -794.989269879538\"\n[1] \"101 -794.61347001389\"\n[1] \"102 -794.227382038366\"\n[1] \"103 -793.836180479427\"\n[1] \"104 -793.445665996165\"\n[1] \"105 -793.06187465941\"\n[1] \"106 -792.690604581768\"\n[1] \"107 -792.336920339128\"\n[1] \"108 -792.00470534866\"\n[1] \"109 -791.696323673354\"\n[1] \"110 -791.412427740102\"\n[1] \"111 -791.151916589355\"\n[1] \"112 -790.912023254214\"\n[1] \"113 -790.688500098266\"\n[1] \"114 -790.475880956368\"\n[1] \"115 -790.267823020674\"\n[1] \"116 -790.057553688047\"\n[1] \"117 -789.838443163304\"\n[1] \"118 -789.604668694695\"\n[1] \"119 -789.351834958115\"\n[1] \"120 -789.077330165171\"\n[1] \"121 -788.780234207257\"\n[1] \"122 -788.460799928185\"\n[1] \"123 -788.119791102822\"\n[1] \"124 -787.758082012771\"\n[1] \"125 -787.376812111334\"\n[1] \"126 -786.978127702853\"\n[1] \"127 -786.566252856305\"\n[1] \"128 -786.148373199432\"\n[1] \"129 -785.734671791659\"\n[1] \"130 -785.337040770431\"\n[1] \"131 -784.966665285232\"\n[1] \"132 -784.631498367106\"\n[1] \"133 -784.334835080832\"\n[1] \"134 -784.075463614167\"\n[1] \"135 -783.848928015242\"\n[1] \"136 -783.649080669712\"\n[1] \"137 -783.469347360711\"\n[1] \"138 -783.303521641659\"\n[1] \"139 -783.146151753778\"\n[1] \"140 -782.992659155106\"\n[1] \"141 -782.839313025282\"\n[1] \"142 -782.683145215569\"\n[1] \"143 -782.521854307014\"\n[1] \"144 -782.353722857418\"\n[1] \"145 -782.177557104718\"\n[1] \"146 -781.99265005203\"\n[1] \"147 -781.798764192693\"\n[1] \"148 -781.596127325427\"\n[1] \"149 -781.385433019207\"\n[1] \"150 -781.167836044437\"\n[1] \"151 -780.944932703616\"\n[1] \"152 -780.718716961482\"\n[1] \"153 -780.491506090143\"\n[1] \"154 -780.26583437246\"\n[1] \"155 -780.044319747823\"\n[1] \"156 -779.829514849453\"\n[1] \"157 -779.623758845102\"\n[1] \"158 -779.429048140031\"\n[1] \"159 -779.246941518647\"\n[1] \"160 -779.078509255756\"\n[1] \"161 -778.924327905987\"\n[1] \"162 -778.784515135777\"\n[1] \"163 -778.65879390442\"\n[1] \"164 -778.546573303253\"\n[1] \"165 -778.447034134656\"\n[1] \"166 -778.359209896916\"\n[1] \"167 -778.282057129182\"\n[1] \"168 -778.214512183418\"\n[1] \"169 -778.155533928442\"\n[1] \"170 -778.1041335022\"\n[1] \"171 -778.059393089628\"\n[1] \"172 -778.02047599702\"\n[1] \"173 -777.986630219124\"\n[1] \"174 -777.95718742025\"\n[1] \"175 -777.931558896475\"\n[1] \"176 -777.909229728489\"\n[1] \"177 -777.889752014688\"\n[1] \"178 -777.872737808616\"\n[1] \"179 -777.857852176484\"\n[1] \"180 -777.844806633688\"\n[1] \"181 -777.833353106155\"\n[1] \"182 -777.823278483372\"\n[1] \"183 -777.814399777478\"\n[1] \"184 -777.806559869333\"\n[1] \"185 -777.799623802859\"\n[1] \"186 -777.79347557875\"\n[1] \"187 -777.788015394758\"\n[1] \"188 -777.783157279915\"\n[1] \"189 -777.778827072679\"\n[1] \"190 -777.774960696943\"\n[1] \"191 -777.771502694393\"\n[1] \"192 -777.76840497646\"\n[1] \"193 -777.765625763658\"\n[1] \"194 -777.763128684381\"\n[1] \"195 -777.760882009096\"\n[1] \"196 -777.758857999334\"\n[1] \"197 -777.7570323539\"\n[1] \"198 -777.755383737373\"\n[1] \"199 -777.75389337824\"\n[1] \"200 -777.752544725934\"\n[1] \"201 -777.751323157748\"\n[1] \"202 -777.750215727978\"\n[1] \"203 -777.749210952847\"\n[1] \"204 -777.748298625781\"\n[1] \"205 -777.747469658466\"\n[1] \"206 -777.746715943813\"\n[1] \"1 -844.207685930303\"\n[1] \"2 -838.259092354054\"\n[1] \"3 -836.941786504369\"\n[1] \"4 -836.634187455723\"\n[1] \"5 -836.545935147057\"\n[1] \"6 -836.495019164235\"\n[1] \"7 -836.433916703547\"\n[1] \"8 -836.350558135709\"\n[1] \"9 -836.243307221638\"\n[1] \"10 -836.113639139667\"\n[1] \"11 -835.963788267096\"\n[1] \"12 -835.79595570284\"\n[1] \"13 -835.612052093951\"\n[1] \"14 -835.41364320439\"\n[1] \"15 -835.201981630885\"\n[1] \"16 -834.978078654146\"\n[1] \"17 -834.742794738937\"\n[1] \"18 -834.4969367786\"\n[1] \"19 -834.241354173579\"\n[1] \"20 -833.977026832454\"\n[1] \"21 -833.705137283915\"\n[1] \"22 -833.427117623976\"\n[1] \"23 -833.144661824544\"\n[1] \"24 -832.859696769273\"\n[1] \"25 -832.574311947303\"\n[1] \"26 -832.29065674671\"\n[1] \"27 -832.010822652582\"\n[1] \"28 -831.736731996721\"\n[1] \"29 -831.470053676934\"\n[1] \"30 -831.212160872124\"\n[1] \"31 -830.96413994896\"\n[1] \"32 -830.726857751243\"\n[1] \"33 -830.501099423382\"\n[1] \"34 -830.287801396648\"\n[1] \"35 -830.088418239941\"\n[1] \"36 -829.905450710939\"\n[1] \"37 -829.743028041531\"\n[1] \"38 -829.60685751681\"\n[1] \"39 -829.500825836634\"\n[1] \"40 -829.411289375974\"\n[1] \"41 -829.255141672644\"\n[1] \"42 -828.767438201107\"\n[1] \"43 -827.54749039493\"\n[1] \"44 -825.733731433991\"\n[1] \"45 -823.483664805677\"\n[1] \"46 -820.617994007656\"\n[1] \"47 -818.073940541337\"\n[1] \"48 -816.000387021182\"\n[1] \"49 -814.254261115774\"\n[1] \"50 -812.789833632369\"\n[1] \"51 -811.577391500583\"\n[1] \"52 -810.590351504619\"\n[1] \"53 -809.801366345833\"\n[1] \"54 -809.180199205724\"\n[1] \"55 -808.694182589221\"\n[1] \"56 -808.310600613316\"\n[1] \"57 -807.999321049133\"\n[1] \"58 -807.734535424167\"\n[1] \"59 -807.495408237107\"\n[1] \"60 -807.265963558671\"\n[1] \"61 -807.034614377922\"\n[1] \"62 -806.793613092577\"\n[1] \"63 -806.538550029135\"\n[1] \"64 -806.267917560032\"\n[1] \"65 -805.982697400681\"\n[1] \"66 -805.685908445429\"\n[1] \"67 -805.382062641425\"\n[1] \"68 -805.07650928448\"\n[1] \"69 -804.774694155667\"\n[1] \"70 -804.481404689712\"\n[1] \"71 -804.200098655846\"\n[1] \"72 -803.932408940844\"\n[1] \"73 -803.677880910464\"\n[1] \"74 -803.433946066435\"\n[1] \"75 -803.196088390043\"\n[1] \"76 -802.958136067312\"\n[1] \"77 -802.712618255994\"\n[1] \"78 -802.451160987547\"\n[1] \"79 -802.164950873751\"\n[1] \"80 -801.845362767957\"\n[1] \"81 -801.484915976766\"\n[1] \"82 -801.07875647656\"\n[1] \"83 -800.626764318643\"\n[1] \"84 -800.135990412668\"\n[1] \"85 -799.622341266538\"\n[1] \"86 -799.10966758379\"\n[1] \"87 -798.624909610221\"\n[1] \"88 -798.190586806402\"\n[1] \"89 -797.818754548539\"\n[1] \"90 -797.509913319851\"\n[1] \"91 -797.256454068517\"\n[1] \"92 -797.047492689749\"\n[1] \"93 -796.872502462792\"\n[1] \"94 -796.723043018817\"\n[1] \"95 -796.593068642346\"\n[1] \"96 -796.47852445334\"\n[1] \"97 -796.376737692514\"\n[1] \"98 -796.285868883937\"\n[1] \"99 -796.204521288573\"\n[1] \"100 -796.131513754935\"\n[1] \"101 -796.065778569424\"\n[1] \"102 -796.006334705251\"\n[1] \"103 -795.952294474273\"\n[1] \"104 -795.902876491032\"\n[1] \"105 -795.857411960154\"\n[1] \"106 -795.815340920505\"\n[1] \"107 -795.776199993995\"\n[1] \"108 -795.739604764993\"\n[1] \"109 -795.705229714284\"\n[1] \"110 -795.672787770439\"\n[1] \"111 -795.642010638775\"\n[1] \"112 -795.612630383439\"\n[1] \"113 -795.584362340517\"\n[1] \"114 -795.556889323071\"\n[1] \"115 -795.529847220812\"\n[1] \"116 -795.502812476846\"\n[1] \"117 -795.475292502558\"\n[1] \"118 -795.446720762789\"\n[1] \"119 -795.416458784111\"\n[1] \"120 -795.383807283214\"\n[1] \"121 -795.348027437672\"\n[1] \"122 -795.308370665931\"\n[1] \"123 -795.264111504992\"\n[1] \"124 -795.214574819881\"\n[1] \"125 -795.159148129469\"\n[1] \"126 -795.097274249062\"\n[1] \"127 -795.028428179586\"\n[1] \"128 -794.95209146217\"\n[1] \"129 -794.867742009307\"\n[1] \"130 -794.774874637903\"\n[1] \"131 -794.673057913397\"\n[1] \"132 -794.562020169241\"\n[1] \"133 -794.44174615367\"\n[1] \"134 -794.312559335405\"\n[1] \"135 -794.175165734484\"\n[1] \"136 -794.030643602721\"\n[1] \"137 -793.880377178661\"\n[1] \"138 -793.725947454535\"\n[1] \"139 -793.569003054968\"\n[1] \"140 -793.411136510273\"\n[1] \"141 -793.253785638619\"\n[1] \"142 -793.098169791817\"\n[1] \"143 -792.945260663796\"\n[1] \"144 -792.795780284867\"\n[1] \"145 -792.650215725845\"\n[1] \"146 -792.508840257888\"\n[1] \"147 -792.371732902207\"\n[1] \"148 -792.238791194021\"\n[1] \"149 -792.109734767488\"\n[1] \"150 -791.984099712465\"\n[1] \"151 -791.861225573836\"\n[1] \"152 -791.740238561838\"\n[1] \"153 -791.620036277842\"\n[1] \"154 -791.499281242728\"\n[1] \"155 -791.37641276769\"\n[1] \"156 -791.249688877962\"\n[1] \"157 -791.117271117488\"\n[1] \"158 -790.977363345425\"\n[1] \"159 -790.828408640949\"\n[1] \"160 -790.669333999831\"\n[1] \"161 -790.499810830984\"\n[1] \"162 -790.320475589745\"\n[1] \"163 -790.133040644806\"\n[1] \"164 -789.940234570619\"\n[1] \"165 -789.745550328234\"\n[1] \"166 -789.552839231855\"\n[1] \"167 -789.365841794909\"\n[1] \"168 -789.187765981468\"\n[1] \"169 -789.020999837811\"\n[1] \"170 -788.866994094146\"\n[1] \"171 -788.726298178121\"\n[1] \"172 -788.598700818569\"\n[1] \"173 -788.483419156679\"\n[1] \"174 -788.379290872074\"\n[1] \"175 -788.284941371436\"\n[1] \"176 -788.198914295133\"\n[1] \"177 -788.11976473144\"\n[1] \"178 -788.046120344914\"\n[1] \"179 -787.976717542217\"\n[1] \"180 -787.910419504715\"\n[1] \"181 -787.846221711009\"\n[1] \"182 -787.78324922056\"\n[1] \"183 -787.720748835784\"\n[1] \"184 -787.658078392531\"\n[1] \"185 -787.594694816374\"\n[1] \"186 -787.53014215816\"\n[1] \"187 -787.464040523706\"\n[1] \"188 -787.396076592806\"\n[1] \"189 -787.325996249266\"\n[1] \"190 -787.253599693123\"\n[1] \"191 -787.178739258888\"\n[1] \"192 -787.101320001012\"\n[1] \"193 -787.021302912519\"\n[1] \"194 -786.938710402266\"\n[1] \"195 -786.853633368108\"\n[1] \"196 -786.766238882571\"\n[1] \"197 -786.676777193707\"\n[1] \"198 -786.585586502221\"\n[1] \"199 -786.493093891326\"\n[1] \"200 -786.399810943812\"\n[1] \"201 -786.306323036983\"\n[1] \"202 -786.213272053663\"\n[1] \"203 -786.121333193626\"\n[1] \"204 -786.031187541457\"\n[1] \"205 -785.94349282769\"\n[1] \"206 -785.858855216592\"\n[1] \"207 -785.777804860424\"\n[1] \"208 -785.700777397909\"\n[1] \"209 -785.628102684816\"\n[1] \"210 -785.560001037246\"\n[1] \"211 -785.496586355035\"\n[1] \"212 -785.437874826759\"\n[1] \"213 -785.383797566496\"\n[1] \"214 -785.33421548064\"\n[1] \"215 -785.288934839995\"\n[1] \"216 -785.247722345507\"\n[1] \"217 -785.210318838155\"\n[1] \"218 -785.176451148823\"\n[1] \"219 -785.145841873242\"\n[1] \"220 -785.118217074068\"\n[1] \"221 -785.093312057348\"\n[1] \"222 -785.070875454435\"\n[1] \"223 -785.0506718766\"\n[1] \"224 -785.032483412759\"\n[1] \"225 -785.016110222889\"\n[1] \"226 -785.001370450476\"\n[1] \"227 -784.988099643539\"\n[1] \"228 -784.976149839766\"\n[1] \"229 -784.965388439682\"\n[1] \"230 -784.955696963967\"\n[1] \"231 -784.946969767413\"\n[1] \"232 -784.939112762468\"\n[1] \"233 -784.93204218969\"\n[1] \"234 -784.925683459986\"\n[1] \"235 -784.919970083954\"\n[1] \"236 -784.914842696345\"\n[1] \"237 -784.910248178266\"\n[1] \"238 -784.906138875797\"\n[1] \"239 -784.902471910997\"\n[1] \"240 -784.899208579399\"\n[1] \"241 -784.896313827016\"\n[1] \"242 -784.893755799298\"\n[1] \"243 -784.891505454291\"\n[1] \"244 -784.889536232389\"\n[1] \"245 -784.887823775414\"\n[1] \"246 -784.88634568821\"\n[1] \"247 -784.885081336541\"\n[1] \"248 -784.884011675641\"\n[1] \"249 -784.88311910448\"\n[1] \"250 -784.882387341334\"\n[1] \"1 -810.37521084413\"\n[1] \"2 -817.499493924075\"\n[1] \"3 -821.737195911788\"\n[1] \"4 -824.589869270007\"\n[1] \"5 -826.633609212907\"\n[1] \"6 -828.155996000067\"\n[1] \"7 -829.3205265809\"\n[1] \"8 -830.228551010087\"\n[1] \"9 -830.946832176898\"\n[1] \"10 -831.521361859834\"\n[1] \"11 -831.984926024808\"\n[1] \"12 -832.361534546689\"\n[1] \"13 -832.669155121733\"\n[1] \"14 -832.921473964607\"\n[1] \"15 -833.129070400709\"\n[1] \"16 -833.300224050251\"\n[1] \"17 -833.441483813741\"\n[1] \"18 -833.558078170841\"\n[1] \"19 -833.654218099587\"\n[1] \"20 -833.733328938719\"\n[1] \"21 -833.79824397846\"\n[1] \"22 -833.85140629159\"\n[1] \"23 -833.895175504965\"\n[1] \"24 -833.932461817871\"\n[1] \"25 -833.968129604484\"\n[1] \"26 -834.011537334959\"\n[1] \"27 -834.076994294295\"\n[1] \"28 -834.153550299133\"\n[1] \"29 -834.005111958705\"\n[1] \"30 -832.725905369098\"\n[1] \"31 -830.156051114643\"\n[1] \"32 -827.071211158222\"\n[1] \"33 -822.828320194195\"\n[1] \"34 -819.239750901936\"\n[1] \"35 -816.672321130525\"\n[1] \"36 -814.92846406561\"\n[1] \"37 -813.797816216795\"\n[1] \"38 -813.078886676968\"\n[1] \"39 -812.618759984269\"\n[1] \"40 -812.315430568933\"\n[1] \"41 -812.105132226465\"\n[1] \"42 -811.948972942973\"\n[1] \"43 -811.823201958197\"\n[1] \"44 -811.713050517589\"\n[1] \"45 -811.609065477297\"\n[1] \"46 -811.504978449978\"\n[1] \"47 -811.39647375855\"\n[1] \"48 -811.28047385996\"\n[1] \"49 -811.154723045185\"\n[1] \"50 -811.017544397972\"\n[1] \"51 -810.867697580563\"\n[1] \"52 -810.704293941435\"\n[1] \"53 -810.526741409249\"\n[1] \"54 -810.334700729222\"\n[1] \"55 -810.128040218808\"\n[1] \"56 -809.906780270724\"\n[1] \"57 -809.671022355219\"\n[1] \"58 -809.420860803498\"\n[1] \"59 -809.15627942113\"\n[1] \"60 -808.877039049294\"\n[1] \"61 -808.582566548232\"\n[1] \"62 -808.271860235161\"\n[1] \"63 -807.943431301214\"\n[1] \"64 -807.595304462685\"\n[1] \"65 -807.225102617552\"\n[1] \"66 -806.830237170895\"\n[1] \"67 -806.408214925956\"\n[1] \"68 -805.957051658831\"\n[1] \"69 -805.475752434228\"\n[1] \"70 -804.964785736759\"\n[1] \"71 -804.426455006394\"\n[1] \"72 -803.865071585323\"\n[1] \"73 -803.286865589023\"\n[1] \"74 -802.699630506219\"\n[1] \"75 -802.112165441457\"\n[1] \"76 -801.533636409859\"\n[1] \"77 -800.97301976313\"\n[1] \"78 -800.438836279231\"\n[1] \"79 -799.93947257007\"\n[1] \"80 -799.484504043974\"\n[1] \"81 -799.087090830468\"\n[1] \"82 -798.763594043948\"\n[1] \"83 -798.504763259057\"\n[1] \"84 -798.120855021132\"\n[1] \"85 -796.909896958982\"\n[1] \"86 -794.055113300411\"\n[1] \"87 -790.285451215687\"\n[1] \"88 -787.153631807471\"\n[1] \"89 -784.992194276168\"\n[1] \"90 -783.598094743802\"\n[1] \"91 -782.736865151918\"\n[1] \"92 -782.218952553911\"\n[1] \"93 -781.910778116528\"\n[1] \"94 -781.726548280544\"\n[1] \"95 -781.61414952176\"\n[1] \"96 -781.542723446657\"\n[1] \"97 -781.49401840198\"\n[1] \"98 -781.457015475417\"\n[1] \"99 -781.424773200445\"\n[1] \"100 -781.392623208429\"\n[1] \"101 -781.357150641875\"\n[1] \"102 -781.315625926617\"\n[1] \"103 -781.26570248691\"\n[1] \"104 -781.205281609748\"\n[1] \"105 -781.132493982545\"\n[1] \"106 -781.045772424683\"\n[1] \"107 -780.944000015901\"\n[1] \"108 -780.826715822239\"\n[1] \"109 -780.694348597789\"\n[1] \"110 -780.548430024752\"\n[1] \"111 -780.391719788501\"\n[1] \"112 -780.228166855044\"\n[1] \"113 -780.06264938956\"\n[1] \"114 -779.900488785464\"\n[1] \"115 -779.746812116596\"\n[1] \"116 -779.605909047403\"\n[1] \"117 -779.480750896991\"\n[1] \"118 -779.372789324121\"\n[1] \"119 -779.282052022636\"\n[1] \"120 -779.207456613408\"\n[1] \"121 -779.147217391089\"\n[1] \"122 -779.099231241857\"\n[1] \"123 -779.06137478568\"\n[1] \"124 -779.031693362082\"\n[1] \"125 -779.008495125653\"\n[1] \"126 -778.990377116862\"\n[1] \"127 -778.976210369868\"\n[1] \"128 -778.965105061396\"\n[1] \"129 -778.956369439428\"\n[1] \"130 -778.949470236867\"\n[1] \"131 -778.943998123586\"\n[1] \"132 -778.9396392634\"\n[1] \"133 -778.936152743729\"\n[1] \"134 -778.933353086621\"\n[1] \"135 -778.931096900991\"\n[1] \"136 -778.929272787635\"\n[1] \"137 -778.927793739731\"\n[1] \"138 -778.926591429565\"\n[1] \"139 -778.925611908308\"\n[1] \"140 -778.924812359465\"\n[1] \"141 -778.92415863695\"\n\n\nPlot of BIC as a function of K\n\n\nCode\npar(mar=c(4,4,1,1) + 0.1)\nplot(seq(2,KKmax), BIC, type=\"l\", xlab=\"K\", ylab=\"BIC\", lwd=2)\nabline(v=6, lty=3)\n\n## Computing density estimates for various values of K\ndensity.est = function(xx, w, mu, sigma){\n  KK  = length(w)\n  nxx = length(xx)\n  density.EM = rep(0, nxx)\n  for(s in 1:nxx){\n    for(k in 1:KK){\n      density.EM[s] = density.EM[s] + w[k]*dnorm(xx[s], mu[k], sigma)\n    }\n  }\n  return(density.EM)\n}\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nCode\nxx  = seq(5000,37000,length=300)\nKK = 8\nmdeKK8 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 7\nmdeKK7 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 6\nmdeKK6 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 5\nmdeKK5 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\nKK = 4\nmdeKK4 = density.est(xx, w.sum[[KK-1]], mu.sum[[KK-1]], sigma.sum[KK-1])\n\n\nComparing density estimates for K=4, 5 and 6\n\n\nCode\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, mdeKK6, type=\"n\",ylim=c(0,max(c(mdeKK4,mdeKK5,mdeKK6,mdeKK7))), \n     xlab=\"Velocity\", ylab=\"Density\")\nlines(xx, mdeKK6, col=\"black\", lty=1, lwd=2)\nlines(xx, mdeKK5, col=\"red\", lty=2, lwd=2)\nlines(xx, mdeKK4, col=\"blue\", lty=3, lwd=2)\npoints(x, rep(0,n))\nlegend(26000, 0.00022, c(\"K = 6\",\"K = 5\",\"K = 4\"), \n       lty=c(1,2,3), col=c(\"black\",\"red\",\"blue\"), bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\nComparing density estimates for K=6, 7 and 8\n\n\nCode\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, mdeKK6, type=\"n\",ylim=c(0,max(c(mdeKK6,mdeKK7,mdeKK8))), \n     xlab=\"Velocity\", ylab=\"Density\")\nlines(xx, mdeKK6, col=\"black\", lty=1, lwd=2)\nlines(xx, mdeKK7, col=\"red\", lty=2, lwd=2)\nlines(xx, mdeKK8, col=\"blue\", lty=3, lwd=2)\npoints(x, rep(0,n))\nlegend(26000, 0.00022, c(\"K = 6\",\"K = 7\",\"K = 8\"), \n       lty=c(1,2,3), col=c(\"black\",\"red\",\"blue\"), bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\nWhat happens with the variance (bandwidth) as K increases?\n\n\nCode\npar(mar=c(4,4,1,1) + 0.1)\nplot(seq(2,KKmax), sigma.sum, type=\"l\", xlab=\"K\", \n     ylab=expression(hat(sigma)), lwd=2)\nabline(v=6, lty=3)\n\n\n\n\n\n\n\n\nFigure 4"
  },
  {
    "objectID": "c03-mixtures/m2-em/em-exp-lognormal-mix/index.html",
    "href": "c03-mixtures/m2-em/em-exp-lognormal-mix/index.html",
    "title": "EM algorithm for fitting a mixture of Exponential and LogNormal components",
    "section": "",
    "text": "f(x)= w \\lambda \\exp\\{− \\lambda x\\}+(1 − w) \\cdot \\frac{1}{\\sqrt{2 \\pi }\\tau x} \\exp \\{-\\frac{1}{2 \\tau ^2}(\\log(x) − μ)^2 \\} \\qquad \\text{for } x&gt;0\nwhere w is the weight of the exponential component, \\lambda is the rate of the exponential distribution, and \\mu and \\tau are the mean and standard deviation of the log-normal distribution.\nLoad the data and required libraries\nCode\nrm(list=ls())\nlibrary(mvtnorm)    # Multivariate normals are not default in R\nlibrary(ellipse)    # Required for plotting\n\n#set.seed(63252)     # For reproducibility\nCode\n#x &lt;- read.csv('./posts/mixtures/mx4-fuses/fuses.csv', header = FALSE)\ndf = read.csv('fuses.csv', header = FALSE)\nhead(df,5)\n\n\n        V1\n1 1.062163\n2 1.284631\n3 2.733352\n4 2.284062\n5 3.289444\n\n\nCode\nx =  as.numeric(df[[1]])\nn = length(x)         # Correct way to get the number of observations\nmean(x)\n\n\n[1] 2.17509\n\n\nCode\nsd(x)\n\n\n[1] 1.075932\n\n\nCode\nKK = 2"
  },
  {
    "objectID": "c03-mixtures/m2-em/em-exp-lognormal-mix/index.html#run-the-actual-em-algorithm",
    "href": "c03-mixtures/m2-em/em-exp-lognormal-mix/index.html#run-the-actual-em-algorithm",
    "title": "EM algorithm for fitting a mixture of Exponential and LogNormal components",
    "section": "1 Run the actual EM algorithm",
    "text": "1 Run the actual EM algorithm\nNow we will use the EM algorithm to estimate the parameters of the mixture from the data we generated above.\nThe algorithm is implemented in the following steps:\n\nInitialization: We initialize the parameters of the model (weights, means, and standard deviations) randomly.\nE-step: We compute the expected value of the log-likelihood function, given the current parameters and the data.\nM-step: We maximize the expected log-likelihood function with respect to the parameters. \n\\begin{aligned}\n&Q\\left(w, \\lambda, \\mu, \\tau \\mid \\hat{w}^{(t)}, \\hat{\\lambda}^{(t)}, \\hat{\\mu}^{(t)} , \\hat{\\tau}^{(t)}\\right) \\\\&= \\sum_{i=1}^{n} v_{i,1} \\left[ \\log w + \\log \\lambda - \\lambda x_i \\right]\n\\\\ &+ v_{i,2}\\left[ \\log(1-w) - \\frac{1}{2} \\log(2 \\pi) - \\log \\tau - \\log x_i - \\frac{1}{2\\tau^2} \\left( \\log x_i - \\mu \\right) \\right]\n\\end{aligned}\n\\tag{1}\n\nwhere (v_{i,1}) and (v_{i,2}) are the responsibilities of the two components for the i-th observation.\nComputing the derivatives and setting them to zero yields\n\n\\hat{w}^{(t+1)} = \\frac{1}{n} \\sum_{i=1}^{n} v_{i,1}\n\n\n\\hat{\\lambda}^{(t+1)} = \\frac{\\sum_{i=1}^{n} v_{i,1}}{\\sum_{i=1}^{n} v_{i,1} x_i}\n\n\n\\hat{\\mu}^{(t+1)}  = \\frac{\\sum_{i=1}^{n} v_{i,2} \\log x_i}{\\sum_{i=1}^{n} v_{i,2}}\n\n\n\\hat{\\tau}^{(t+1)} =\\sqrt{ \\frac{\\sum_{i=1}^{n} v_{i,2} \\left( \\log x_i - \\hat{\\mu}^{(t+1)} \\right)^2}{\\sum_{i=1}^{n} v_{i,2}}}\n\n\nConvergence check: We check if the algorithm has converged by comparing the current and previous values of the log-likelihood function.\n\n\n\nCode\nKK = 2                             # Number of components\nw     = 0.05                        # Assign equal weight to each component to start with\n#mu = rnorm(1,mean(log(x)), sd(log(x)))\nmu = mean(log(x))\ntau = sd(log(x))\nlambda = 20 / mean(x)\n\ns  = 0              # s_tep counter\nsw = FALSE          # sw_itch to stop the algorithm\nQQ = -Inf           # the Q function (log-likelihood function)\nQQ.out = NULL       # the Q function values\nepsilon = 10^(-5)   # the stopping criterion for the algorithm\n\ntrace &lt;- data.frame(iter=0, w=w, lambda=lambda, mu=mu, tau=tau)\n\nwhile(!sw){ ##Checking convergence\n\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(i in 1:n){\n    v[i,1] = log(w)   + dexp(x[i], rate=lambda, log=TRUE)\n    v[i,2] = log(1-w) + dlnorm(x[i], mu, tau, log=TRUE)    \n    v[i,]  = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,]))) \n  }\n\n  ## M step  \n  w      = mean(v[,1])  # Weights\n  lambda = sum(v[,1]) / sum(v[,1] * x)  # Lambda (rate)\n  mu     = sum(v[,2] * log(x)) / sum(v[,2]) # Mean\n  tau    = sqrt(sum(v[,2] * (log(x) - mu)^2) / sum(v[,2])) # Tau (standard deviation)\n  \n  # collect trace of parameters \n  trace  =  rbind(trace, data.frame(iter=s, w=w, lambda=lambda, mu=mu, tau=tau))\n\n  ## Check convergence\n  QQn = 0\n  #vectorized version\n  log_lik_mat = v[,1]*(log(w)   + dexp(x, lambda, log=TRUE)) +\n                v[,2]*(log(1-w) + dlnorm(x, mu, tau, log=TRUE))\n  QQn = sum(log_lik_mat)\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n}\n\n\n[1] \"1 -621.636631915928\"\n[1] \"2 -576.564676680329\"\n[1] \"3 -562.326030957339\"\n[1] \"4 -558.240693010161\"\n[1] \"5 -559.062812699431\"\n[1] \"6 -560.433982999852\"\n[1] \"7 -561.504096778213\"\n[1] \"8 -562.257984979008\"\n[1] \"9 -562.779349634224\"\n[1] \"10 -563.139561270939\"\n[1] \"11 -563.389080841182\"\n[1] \"12 -563.562415697134\"\n[1] \"13 -563.683109594057\"\n[1] \"14 -563.767298770739\"\n[1] \"15 -563.826100698272\"\n[1] \"16 -563.867209281663\"\n[1] \"17 -563.895967519019\"\n[1] \"18 -563.916095326952\"\n[1] \"19 -563.930187401928\"\n[1] \"20 -563.94005598844\"\n[1] \"21 -563.946968029888\"\n[1] \"22 -563.951809840896\"\n\n\n\n\nCode\n#Plot final estimate over data\nxx  = seq(0,7,length=150)\nnxx = length(xx)\ndensity.EM = rep(0, nxx)\nfor(s in 1:nxx){\n  #density.EM[s] = density.EM[s] + w*dexp(xx[s], lambda[1]) + \n  density.EM[s] = w*dexp(xx[s], rate=lambda) + (1-w)*dlnorm(xx[s],meanlog=mu, sdlog=tau)\n}\n\n\n\n\nCode\nplot(xx, density.EM, col=\"red\", lwd=2, type=\"l\", xlab=\"x\")\npoints(x,rep(0,n))\ntitle(main=\"Mixture of Exponential and LogNormal\")\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nCode\npar(mfrow=c(2,2))\nplot(trace$iter, trace$w, type=\"b\", col=\"purple\", main=\"Weight w\", ylab=\"w\", xlab=\"Iter\")\nplot(trace$iter, trace$lambda, type=\"b\", col=\"red\", main=\"Exponential rate λ\", ylab=\"λ\", xlab=\"Iter\")\nplot(trace$iter, trace$mu, type=\"b\", col=\"blue\", main=\"Normal mean μ\", ylab=\"μ\", xlab=\"Iter\")\nplot(trace$iter, trace$tau, type=\"b\", col=\"darkgreen\", main=\"Normal std.dev τ\", ylab=\"τ\", xlab=\"Iter\")\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\nCode\ncat(\"w =\", round(w, 2), \"lambda =\", round(lambda, 2), \"mu =\", round(mu, 2),\"tau =\", round(tau, 2))\n\n\nw = 0.09 lambda = 3.05 mu = 0.78 tau = 0.38\n\n\n\n\nCode\n# Compute final responsibilities one last time\nv = matrix(0, nrow=n, ncol=2)\n\n#vectorised version\nv[,1] = log(w)   + dexp(x, rate=lambda, log=TRUE)\nv[,2] = log(1-w) + dlnorm(x, mean=mu, sd=tau, log=TRUE)\nfor(i in 1:n){\n  v[i,] = exp(v[i,] - max(v[i,])) / sum(exp(v[i,] - max(v[i,])))\n}\n\n# Assign component with higher responsibility\nz_hat = apply(v, 1, which.max)\n\n# Plot data colored by most likely component\nplot(x, rep(0, n), col=ifelse(z_hat==1, \"red\", \"blue\"), pch=19,\n     ylab=\"\", yaxt=\"n\", xlab=\"x\", main=\"Point-wise Component Assignment\")\nlegend(\"topright\", legend=c(\"Exponential\", \"LogNormal\"), col=c(\"red\", \"blue\"), pch=19)\n\n\n\n\n\n\n\n\nFigure 3"
  },
  {
    "objectID": "c03-mixtures/m2-em/em-k-p-norm-mix/index.html",
    "href": "c03-mixtures/m2-em/em-k-p-norm-mix/index.html",
    "title": "EM algorithm for fitting a location mixture of K p-variate Gaussian components",
    "section": "",
    "text": "This is an example of an EM algorithm for fitting a mixtures of K p-variate Gaussian components"
  },
  {
    "objectID": "c03-mixtures/m2-em/em-k-p-norm-mix/index.html#simulation-of-data",
    "href": "c03-mixtures/m2-em/em-k-p-norm-mix/index.html#simulation-of-data",
    "title": "EM algorithm for fitting a location mixture of K p-variate Gaussian components",
    "section": "1 Simulation of data",
    "text": "1 Simulation of data\nThe algorithm is tested using simulated data\n\n\nCode\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)    # Multivariate normals are not default in R\nlibrary(ellipse)    # Required for plotting\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\nset.seed(63252)     # For reproducibility\n\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nn  = 120\ncc = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc[i],], Sigma.true[cc[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc, type=\"n\", xlab=expression(x[1]), ylab=expression(x[2]))\ntext(x[,1], x[,2], seq(1,n), col=cc, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Data + True Components\")\n\n\n\n\n\n\n\n\n\n\n1.1 Run the EM algorithm\n\n\nCode\n## Initialize the parameters\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\ns       = 0\nsw      = FALSE\nQQ      = -Inf\nQQ.out  = NULL\nepsilon = 10^(-5)\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n,KK))\n  for(k in 1:KK){\n    v[,k] = log(w[k]) + dmvnorm(x, mu[k,], Sigma[k,,],log=TRUE)  #Compute the log of the weights\n  }\n  for(i in 1:n){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w     = apply(v,2,mean)\n  mu    = array(0, dim=c(KK, p))\n  for(k in 1:KK){\n    for(i in 1:n){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0, dim=c(KK, p, p))\n  for(k in 1:KK){\n    for(i in 1:n){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  QQn = 0\n  for(i in 1:n){\n    for(k in 1:KK){\n      QQn = QQn + v[i,k]*(log(w[k]) + dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(QQn-QQ)/abs(QQn)&lt;epsilon){\n    sw=TRUE\n  }\n  QQ = QQn\n  QQ.out = c(QQ.out, QQ)\n  s = s + 1\n  print(paste(s, QQn))\n  \n  #Plot current components over data\n  layout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\n  par(mar=c(3.1,4.1,0.5,0.5))\n  plot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\")\n  \n  par(mar=c(5,4,1,0.5))\n  plot(x[,1], x[,2], col=cc, main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), \n       xlab=expression(x[1]), ylab=expression(x[2]), lwd=2)\n  for(k in 1:KK){\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n    lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n  }\n}\n\n\n[1] \"1 -582.05125374123\"\n\n\n\n\n\n\n\n\n\n[1] \"2 -559.067366495985\"\n\n\n\n\n\n\n\n\n\n[1] \"3 -543.8803866857\"\n\n\n\n\n\n\n\n\n\n[1] \"4 -527.840823447868\"\n\n\n\n\n\n\n\n\n\n[1] \"5 -511.540892774085\"\n\n\n\n\n\n\n\n\n\n[1] \"6 -483.797796090743\"\n\n\n\n\n\n\n\n\n\n[1] \"7 -464.070439621255\"\n\n\n\n\n\n\n\n\n\n[1] \"8 -455.865736477295\"\n\n\n\n\n\n\n\n\n\n[1] \"9 -455.214732499627\"\n\n\n\n\n\n\n\n\n\n[1] \"10 -455.176042939796\"\n\n\n\n\n\n\n\n\n\n[1] \"11 -455.171446608628\"\n\n\n\n\n\n\n\n\n\n[1] \"12 -455.170550189128\"\n\n\n\n\n\n\n\n\n\nCode\n#Plot current components over data\nlayout(matrix(c(1,2),2,1), widths=c(1,1), heights=c(1.3,3))\npar(mar=c(3.1,4.1,0.5,0.5))\nplot(QQ.out[1:s],type=\"l\", xlim=c(1,max(10,s)), las=1, ylab=\"Q\", lwd=2)\n\npar(mar=c(5,4,1,0.5))\nplot(x[,1], x[,2], col=cc, main=paste(\"s =\",s,\"   Q =\", round(QQ.out[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/ex2/index.html",
    "href": "c03-mixtures/m3-mcmc/ex2/index.html",
    "title": "Mixture Models with MCMC 2",
    "section": "",
    "text": "Code\n#### Example of an MCMC algorithm for fitting a mixtures of K p-variate Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)\nlibrary(ellipse)\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nset.seed(63252)    #Keep seed the same so that we can reproduce results\nn  = 120\ncc.true = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc.true[i],], Sigma.true[cc.true[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]), type=\"n\")\ntext(x[,1], x[,2], seq(1,n), col=cc.true, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2)\n}\ntitle(main=\"Data + True Components\")\n\n\n\n\n\n\n\n\n\nCode\n## Initialize the parameters\nw          = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu         = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\ncc         = sample(1:KK, n, replace=TRUE, prob=w)\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\n# Priors\naa = rep(1, KK)\ndd = apply(x,2,mean)\nDD = 10*var(x)\nnu = p\nSS = var(x)/3\n\n# Number of iteration of the sampler\nrrr = 1000\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK, p))\nSigma.out = array(0, dim=c(rrr, KK, p, p))\nlogpost   = rep(0, rrr)\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + mvtnorm::dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc)))\n  \n  # Sample the means\n  DD.st = matrix(0, nrow=p, ncol=p)\n  for(k in 1:KK){\n    mk    = sum(cc==k)\n    xsumk = apply(x[cc==k,], 2, sum)\n    DD.st = solve(mk*solve(Sigma[k,,]) + solve(DD))\n    dd.st = DD.st%*%(solve(Sigma[k,,])%*%xsumk + solve(DD)%*%dd)\n    mu[k,] = as.vector(rmvnorm(1,dd.st,DD.st))\n  }\n  \n  # Sample the variances\n  xcensumk = array(0, dim=c(KK,p,p))\n  for(i in 1:n){\n    xcensumk[cc[i],,] = xcensumk[cc[i],,] + (x[i,] - mu[cc[i],])%*%t(x[i,] - mu[cc[i],])\n  }\n  for(k in 1:KK){\n    Sigma[k,,] = riwish(nu + sum(cc==k), SS + xcensumk[k,,])\n  }\n  \n  # Store samples\n  cc.out[s,]      = cc\n  w.out[s,]       = w\n  mu.out[s,,]     = mu\n  Sigma.out[s,,,] = Sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + mvtnorm::dmvnorm(x[i,], mu[cc[i],], Sigma[cc[i],,], log=TRUE)\n  }\n  logpost[s] = logpost[s] + ddirichlet(w, aa)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + mvtnorm::dmvnorm(mu[k,], dd, DD, log=TRUE)\n    logpost[s] = logpost[s] + log(diwish(Sigma[k,,], nu, SS))\n  }\n  \n  if(s/250==floor(s/250)){\n    print(paste(\"s = \", s))\n  }\n  \n}\n\n\n[1] \"s =  250\"\n[1] \"s =  500\"\n[1] \"s =  750\"\n[1] \"s =  1000\"\n\n\nCode\n## Plot the logposterior distribution for various samples\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\n\n\n\n\n\n\n\n\nCode\n## Plot the density estimate for the last iteration of the MCMC\npar(mfrow=c(1,1))\npar(mar=c(4,4,2,1)+0.1)\nplot(x[,1], x[,2], col=cc.true, main=paste(\"s =\",s,\"   logpost =\", round(logpost[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/ex1/index.html",
    "href": "c03-mixtures/m3-mcmc/ex1/index.html",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "",
    "text": "Example of an MCMC algorithm for fitting a location mixture of 2 Gaussian components\nThe algorithm is tested using simulated data"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/ex1/index.html#clear-the-environment-and-load-required-libraries",
    "href": "c03-mixtures/m3-mcmc/ex1/index.html#clear-the-environment-and-load-required-libraries",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "1 Clear the environment and load required libraries",
    "text": "1 Clear the environment and load required libraries\n\n\nCode\nrm(list=ls())\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\nset.seed(81196)  # So that results are reproducible"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/ex1/index.html#simulating-synthetic-data",
    "href": "c03-mixtures/m3-mcmc/ex1/index.html#simulating-synthetic-data",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "2 Simulating synthetic data",
    "text": "2 Simulating synthetic data\n\n\nCode\n## Generate data from a mixture with 2 components\nKK         = 2\nw.true     = 0.6  # True weights associated with the components\nmu.true    = rep(0, KK)\nmu.true[1] = 0   # True mean for the first component\nmu.true[2] = 5   # True mean for the second component\nsigma.true = 1   # True standard deviation of all components\nn          = 120         # Number of observations to be generated\ncc.true = sample(1:KK, n, replace=T, prob=c(w.true,1-w.true))\nx  = rep(0, n)\nfor(i in 1:n){\n  x[i] = rnorm(1, mu.true[cc.true[i]], sigma.true)\n}"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/ex1/index.html#plot-the-true-density",
    "href": "c03-mixtures/m3-mcmc/ex1/index.html#plot-the-true-density",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "3 Plot the true density",
    "text": "3 Plot the true density\n\n\nCode\n# Plot the true density\npar(mfrow=c(1,1))\nxx.true = seq(-8,11,length=200)\nyy.true = w.true*dnorm(xx.true, mu.true[1], sigma.true) + \n  (1-w.true)*dnorm(xx.true, mu.true[2], sigma.true) \nplot(xx.true, yy.true, type=\"l\", xlab=\"x\", ylab=\"True density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)"
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/ex1/index.html#run-the-actual-mcmc-algorithm",
    "href": "c03-mixtures/m3-mcmc/ex1/index.html#run-the-actual-mcmc-algorithm",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "4 Run the actual MCMC algorithm",
    "text": "4 Run the actual MCMC algorithm\n\n\nCode\n## Initialize the parameters\nw     = 1/2                         #Assign equal weight to each component to start with\nmu    = rnorm(KK, mean(x), sd(x))   #Random cluster centers randomly spread over the support of the data\nsigma = sd(x)                       #Initial standard deviation\n\n# Plot the initial guess for the density\nxx = seq(-8,11,length=200)\nyy = w*dnorm(xx, mu[1], sigma) + (1-w)*dnorm(xx, mu[2], sigma)\nplot(xx, yy, type=\"l\", ylim=c(0, max(yy)), xlab=\"x\", \n     ylab=\"Initial density\", lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\n\nCode\n## The actual MCMC algorithm starts here\n# Priors\naa  = rep(1,KK)  # Uniform prior on w\neta = 0          # Mean 0 for the prior on mu_k\ntau = 5          # Standard deviation 5 on the prior for mu_l\ndd  = 2\nqq  = 1\n\n# Number of iterations of the sampler\nrrr   = 6000\nburn  = 1000\n\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = rep(0, rrr)\nmu.out    = array(0, dim=c(rrr, KK))\nsigma.out = rep(0, rrr)\nlogpost   = rep(0, rrr)\n\n# MCMC iterations\nfor(s in 1:rrr){\n  # Sample the indicators\n  cc = rep(0,n)\n  for(i in 1:n){\n    v = rep(0,KK)\n    v[1] = log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)  #Compute the log of the weights\n    v[2] = log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)  #Compute the log of the weights\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))\n\n  # Sample the means\n  for(k in 1:KK){\n    nk    = sum(cc==k)\n    xsumk = sum(x[cc==k])\n    tau2.hat = 1/(nk/sigma^2 + 1/tau^2)\n    mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)\n    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))\n  }\n\n  # Sample the variances\n  dd.star = dd + n/2\n  qq.star = qq + sum((x - mu[cc])^2)/2\n  sigma = sqrt(rinvgamma(1, dd.star, qq.star))\n\n  # Store samples\n  cc.out[s,]   = cc\n  w.out[s]     = w\n  mu.out[s,]   = mu\n  sigma.out[s] = sigma\n  for(i in 1:n){\n    if(cc[i]==1){\n      logpost[s] = logpost[s] + log(w) + dnorm(x[i], mu[1], sigma, log=TRUE)\n    }else{\n      logpost[s] = logpost[s] + log(1-w) + dnorm(x[i], mu[2], sigma, log=TRUE)\n    }\n  }\n  logpost[s] = logpost[s] + dbeta(w, aa[1], aa[2],log = T)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dnorm(mu[k], eta, tau, log = T)\n  }\n  logpost[s] = logpost[s] + log(dinvgamma(sigma^2, dd, 1/qq))\n  if(s/500==floor(s/500)){\n    print(paste(\"s =\",s))\n  }\n}\n\n\n[1] \"s = 500\"\n[1] \"s = 1000\"\n[1] \"s = 1500\"\n[1] \"s = 2000\"\n[1] \"s = 2500\"\n[1] \"s = 3000\"\n[1] \"s = 3500\"\n[1] \"s = 4000\"\n[1] \"s = 4500\"\n[1] \"s = 5000\"\n[1] \"s = 5500\"\n[1] \"s = 6000\""
  },
  {
    "objectID": "c03-mixtures/m3-mcmc/ex1/index.html#plot-the-logposterior-distribution-for-various-samples",
    "href": "c03-mixtures/m3-mcmc/ex1/index.html#plot-the-logposterior-distribution-for-various-samples",
    "title": "Mixture Models with MCMC - 2 Gaussian components",
    "section": "5 Plot the logposterior distribution for various samples",
    "text": "5 Plot the logposterior distribution for various samples\n\n\nCode\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\nxx = seq(-8,11,length=200)\ndensity.posterior = array(0, dim=c(rrr-burn,length(xx)))\nfor(s in 1:(rrr-burn)){\n  density.posterior[s,] = density.posterior[s,] + w.out[s+burn]*dnorm(xx,mu.out[s+burn,1],sigma.out[s+burn]) +\n                                                  (1-w.out[s+burn])*dnorm(xx,mu.out[s+burn,2],sigma.out[s+burn])\n}\ndensity.posterior.m = apply(density.posterior , 2, mean)\ndensity.posterior.lq = apply(density.posterior, 2, quantile, 0.025)\ndensity.posterior.uq = apply(density.posterior, 2, quantile, 0.975)\n\n\n\n\n\n\n\n\nFigure 1: Trace plots of the MCMC samples\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(xx, density.posterior.m, type=\"n\",ylim=c(0,max(density.posterior.uq)), xlab=\"x\", ylab=\"Density\")\npolygon(c(xx,rev(xx)), c(density.posterior.lq, rev(density.posterior.uq)), col=\"grey\", border=\"grey\")\nlines(xx, density.posterior.m, lwd=2)\npoints(x, rep(0,n), col=cc.true)\n\n\n\n\n\n\n\n\nFigure 2: Posterior density estimates"
  },
  {
    "objectID": "c03-mixtures/m1-basics/sim/index.html",
    "href": "c03-mixtures/m1-basics/sim/index.html",
    "title": "Mixture of two Gaussian distributions",
    "section": "",
    "text": "Enter code to sample 200 random numbers from a mixture of 3 Poisson distributions with means 1, 2 and 6 and weights 0.7, 0.2 and 0.1, respectively.\n\n\nCode\n# Generate n observations from a mixture of two Gaussian \n# distributions\n\nset.seed(452) # Ensure simulation is reproducible\n#n     = 50           # Size of the sample to be generated\nn = 200 # sample size\n#w     = c(0.6, 0.4)  # Weights\nw = c(0.7,0.2,0.1) # weights\n# mu    = c(0, 5)      # Means\n# sigma = c(1, 2)      # Standard deviations\nlambda = c(1,2,6) # lambda params (mean,variation)\n# cc    = sample(1:2, n, replace=T, prob=w)\ncc = sample(1:3,n, replace=T, prob=w)\n\n# x     = rnorm(n, mu[cc], sigma[cc])\nx = rpois(n,lambda=lambda[cc]) # simulate an cc mixture component n times\n\n\n\n\nCode\n# Plot f(x) along with the observations \n# just sampled\n\n\nempirical_feqs = table(factor(x, levels=seq(0, max(x))))/n\n\nempirical_dist = empirical_feqs /n # convert frequencies to probabilities\n\nbarplot(empirical_dist,xlab=\"counts\",ylab=\"probability\",main=\"Empirical poisson mixture\")\n\n\n\n\n\n\n\n\nFigure 1"
  },
  {
    "objectID": "c03-mixtures/binder-expected-loss-function/index.html",
    "href": "c03-mixtures/binder-expected-loss-function/index.html",
    "title": "Simplifying Binder’s expected loss function",
    "section": "",
    "text": "Complete the algebra and other details required to prove that maximizing\n\\mathcal{L}^*(\\hat{c}) = E\\left[\\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\gamma_1 1(c_i=c_j) 1(\\hat{c}_i \\neq \\hat{c}_j) + \\gamma_2 1(c_i \\neq c_j) 1(\\hat{c}_i = \\hat{c}_j)\\right]\nis equivalent to maximizing\n\\mathcal{L}^{**}(\\hat{c}) = \\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} \\left\\{ D_{i,j} - \\frac{\\gamma_2}{\\gamma_1 + \\gamma_2} \\right\\}\nwhere \nD_{i,j} = Pr(c_i = c_j \\mid data)\nproof:\nI couldn’t find much on binder’s expected loss function. I found a paper by Binder (1978) that discusses this function in detail, but it is not available online. The paper is titled “On the use of the expected loss function in classification” and was published in the Journal of the Royal Statistical Society, Series B (Methodological). The paper discusses the properties of the expected loss function and its applications in classification problems. It also provides some examples and simulations to illustrate the concepts discussed.\nOne resource is Bayesian cluster analysis: Point estimation and credible balls"
  },
  {
    "objectID": "c03-mixtures/binder-expected-loss-function/index.html#references",
    "href": "c03-mixtures/binder-expected-loss-function/index.html#references",
    "title": "Simplifying Binder’s expected loss function",
    "section": "1 References",
    "text": "1 References\n\nBinder, D. A. (1978). On the use of the expected loss function in classification. Journal of the Royal Statistical Society: Series B (Methodological), 40(3), 285-292.\nMcLachlan, G. J., & Peel, D. (2000). Finite mixture models (Vol. 38). John Wiley & Sons.\nCeleux, G., & Govaert, G. (1995). Gaussian parsimonious clustering models. Pattern Recognition, 28(5), 781-793.\nFraley, C., & Raftery, A. E. (2002). Model-based clustering, discriminant analysis, and density estimation. Journal of the American Statistical Association, 97(458), 611-631.\nBiernacki, C., Celeux, G., & Govaert, G. (2000). Assessing a mixture model for clustering with the integrated completed likelihood. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(7), 719-725.\nMcLachlan, G. J., & Peel, D. (2000). Finite mixture models (Vol. 38). John Wiley & Sons."
  },
  {
    "objectID": "C4-L02-ex2-bayesian-analysis-of-an-eeg-dataset-using-an-ar-p.html",
    "href": "C4-L02-ex2-bayesian-analysis-of-an-eeg-dataset-using-an-ar-p.html",
    "title": "Bayesian analysis of an EEG dataset using an AR(p)",
    "section": "",
    "text": "Code\nset.seed(2021)\n# Load the EEG dataset\nyt=scan('data/eeg.txt')\n\npng(\"eeg_plot.png\", width = 800, height = 600)  # Open PNG device\n# plot and save image to file()\nplot(yt, type = \"l\", main = \"EEG Data\", xlab = \"Index\", ylab = \"eeg\")\n# Save the plot as an image\ndev.off()  # Close the PNG device\n\n\npng \n  2 \n\n\nconvert to AR(8) process\n\n\nCode\nset.seed(2021)\nyt=scan('data/eeg.txt')\nT=length(yt) # length of the time series\np=8\n\ny=rev(yt[(p+1):T]) # response\nX=t(matrix(yt[rev(rep((1:p),T-p)+rep((0:(T-p-1)),rep(p,T-p)))],p,T-p));\nXtX=t(X)%*%X\nXtX_inv=solve(XtX)\nphi_MLE=XtX_inv%*%t(X)%*%y # MLE for phi\ns2=sum((y - X%*%phi_MLE)^2)/(length(y) - p) #unbiased estimate for v\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_MLE, \"\\n\",\n    \"Estimate for v: \", s2, \"\\n\")\n\n\n\n MLE of conditional likelihood for phi:  0.2722455 0.06832964 -0.1301794 -0.1478096 -0.1084817 -0.1477537 -0.2259507 -0.1363678 \n Estimate for v:  3784.705 \n\n\nCode\n# step2\nn_sample=500 # posterior sample size\nlibrary(MASS)\n\n## step 1: sample v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2*p)/2, sum((y-X%*%phi_MLE)^2)/2)\n\n## step 2: sample phi conditional on v from normal distribution\nphi_sample=matrix(0, nrow = n_sample, ncol = p)\n\nfor(i in 1:n_sample){\n  phi_sample[i, ]=mvrnorm(1,phi_MLE,Sigma=v_sample[i]*XtX_inv)\n}\n\n#posterior means of ϕ and v\nphi_hat=colMeans(phi_sample)\nv_hat=mean(v_sample)\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_hat, \"\\n\",\n    \"Estimate for v: \", v_hat, \"\\n\")\n\n\n\n MLE of conditional likelihood for phi:  0.2749163 0.0657131 -0.129826 -0.1496683 -0.1077438 -0.1459253 -0.2262027 -0.1360168 \n Estimate for v:  3819.373 \n\n\nphi should be: 0.2732092 -0.1584926 -0.1398177 -0.1362393 -0.1432613 -0.2306927 -0.194208 -0.2684075\nv should be: 3776\n\n\nCode\n## plot histogram of posterior samples of phi and nu\npar(mfrow = c(3, 3), cex.lab = 1.3)\n\nfor(i in 1:p){\n  hist(phi_sample[, i], xlab = bquote(phi), \n       main = bquote(\"Histogram of \"~phi_sample[.(i)]))\n  abline(v = phi_hat[i], col = 'red')\n  abline(v = phi_MLE[i], col = 'blue')\n}\n\nhist(v_sample, xlab = bquote(nu), main = bquote(\"Histogram of \"~v))\nabline(v = v_hat, col = 'red')\nabline(v = s2, col = 'blue')\n\n\n\n\n\n\n\n\n\n\n\nCode\n#phi=phi_MLE\nphi=phi_hat\nroots=1/polyroot(c(1, -phi)) # compute reciprocal characteristic roots\nr=Mod(roots)\n# compute moduli of reciprocal roots\nlambda=2*pi/Arg(roots) # compute periods of reciprocal roots\n# print results modulus and frequency by decreasing order\nprint(cbind(r, abs(lambda))[order(r, decreasing=TRUE), ][c(2,4,6,8),])\n\n\n             r          \n[1,] 0.9696646 12.716694\n[2,] 0.8078736  5.108559\n[3,] 0.7180932  2.986182\n[4,] 0.6556174  2.230944\n\n\nthe moduli should be:\n[1,] 0.9780549 [2,] 0.8658228\n[3,] 0.7840114\n[4,] 0.7803378\nthe periods should be:\n[1,] 12.124565 [2,] 5.121583 [3,] 2.305216 [4,] 3.224417"
  },
  {
    "objectID": "C1-L03-alt.html",
    "href": "C1-L03-alt.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBernoulli mindmap\n\n\n\n\n X \\sim Bernoulli(p)\n\\tag{1}\nWhere parameter p is the probability of getting heads.\nThe probability for the two events is:\n\nP(X=1) = p \\qquad P(X=0)=1-p\n\nNotation:\n\nwe use (Roman) p if its value is known.\n\nwe use (Greek) \\theta when its value is unknown.\n\nThis is a probability mass function since it is discrete. But we call it a Probability Density Function (PDF) in the measure-theoretic sense.\n\nf(X=x\\mid p) = p^x(1-p)^x \\mathbb{I}_{[0,1]}(x)\n\\tag{2}\n\nL(\\theta) = \\prod p^x(1-p)^x \\mathbb{I}_{[0,1]}(x)\n\\tag{3}\n\n\\log L(\\theta) =log(p) \\sum x + log(1-p)\\sum (1-x)\n\\tag{4}\n\n\\mathbb{E}(x)= p\n\\tag{5}\n\n\\text{Var}(x)= p(1-p)\n\\tag{6}\n\n\\text{Entropy}(x)= -q \\ln(q)- p \\ln(p)\n\\tag{7}\n\\text{Fisher Information}(x)\\frac{1}{pq}\n\\tag{8}\n\n\n\n\n\n\n\n\n\nBinomial reparams mindmap\n\n\n\n\n\nX \\sim Bin[n,p]\n\\tag{9}\nthe probability function\n\nf(X=x \\mid \\theta) = {n \\choose x} \\theta^x(1-\\theta)^{n-x}\n\\tag{10}\n\nL(\\theta)=\\prod_{i=1}^{n} {n\\choose x_i}  \\theta ^ {x_i} (1− \\theta) ^ {(n−x_i)}\n\\tag{11}\n\n\\begin{aligned}\n\\ell( \\theta) &= \\log \\mathcal{L}( \\theta) \\\\&= \\sum_{i=1}^n \\left[\\log {n\\choose x_i} + x_i \\log  \\theta + (n-x_i)\\log (1- \\theta) \\right]\n\\end{aligned}\n\\tag{12}\n\n\\mathbb{E}[X]= N \\times  \\theta\n\\tag{13}\n\n\\mathbb{V}ar[X]=N \\cdot \\theta \\cdot (1-\\theta)\n\\tag{14}\n\n\\mathbb{H}(X) = \\frac{1}{2}\\log_2 \\left (2\\pi n \\theta(1 - \\theta)\\right) + O(\\frac{1}{n})\n\\tag{15}\n\n\\mathcal{I}(\\theta)=\\frac{n}{ \\theta \\cdot (1- \\theta)}\n\\tag{16}\n\n0.0.1 Relationships\n\n\n\n\n\n\n\n\n\nBinomial mindmap\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinomial Relations\n\n\n\n\n\n\nCode\nfrom __future__ import print_function\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\nimport numpy as np\nimport scipy\nfrom scipy.special import gamma, factorial, comb\nimport plotly.express as px\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\n#pyo.init_notebook_mode()\nINTERACT_FLAG=False\ndef binomial_vector_over_y(theta, n):\n    total_events = n\n    y =  np.linspace(0, total_events , total_events + 1)\n    p_y = [comb(int(total_events), int(yelem)) * theta** yelem * (1 - theta)**(total_events - yelem) for yelem in y]\n\n    fig = px.line(x=y, y=p_y, color_discrete_sequence=[\"steelblue\"], \n                  height=600, width=800, title=\" Binomial distribution for theta = %lf, n = %d\" %(theta, n))\n    fig.data[0].line['width'] = 4\n    fig.layout.xaxis.title.text = \"y\"\n    fig.layout.yaxis.title.text = \"P(y)\"\n    fig.show()\n    \nif(INTERACT_FLAG):    \n    interact(binomial_vector_over_y, theta=0.5, n=15)\nelse:\n    binomial_vector_over_y(theta=0.5, n=10)"
  },
  {
    "objectID": "charts.html",
    "href": "charts.html",
    "title": "charts",
    "section": "",
    "text": "graph LR\n    A(Binomial Distribution)--$np_0$--&gt;B(Geometric Distribution)\n    A(Binomial Distribution)--&gt;C(Poisson Distribution)\n    A(Binomial Distribution)--&gt;D(Normal Distribution)\n    A(Binomial Distribution)--&gt;E(Bernoulli Distribution)\n    A(Binomial Distribution)--&gt;F(Beta Distribution)\n\n\n\n\n\n\n#| echo: false\n#| fig-cap: \"Complete pooling\"\n#| fig-align: center\n#| fig-ext: svg\n#| out-width: 100%\n\\usetikzlibrary{positioning, fit, calc}   \n\\usepackage{xcolor}\n\\tikzset{block/.style={draw, thick, text width=2cm , minimum height=1.3cm, align=center},   \nline/.style={-latex} \n}\n\\begin{tikzpicture}  \n\\node[block, fill=olive] (a) {A};  \n\\node[block,right=of a, fill=yellow] (b) {B};   \n\\node[block,right=of b, fill= gray] (c) {C};  \n\\node[block, fill=purple] (d) at ([yshift=-2cm]$(a)!0.5!(b)$) {D};  \n\\node[block, fill= orange] (e) at ([yshift=-2cm]$(b)!0.5!(c)$) {E};  \n\\node[draw, fill=pink, fill opacity=0.5,inner xsep=5mm,inner  \n     ysep=6mm,fit=(d)(e),label={130:A}](f){}; % here label command is used to label the block, which covers block D and E.  \n\\draw[line] (a)-- (b);  \n\\draw[line] (b)-- (c);  \n\\draw[line] (d)-- (e);  \n\\draw[line] (e)-- ($(b)!0.5!(c)$);  \n\\draw[line] (d)-- ($(a)!0.5!(b)$);  \n\\end{tikzpicture}"
  },
  {
    "objectID": "good-prompts.html",
    "href": "good-prompts.html",
    "title": "Good Prompts",
    "section": "",
    "text": "1 adding labels to code cells\n“give the full version of this file after adding unique missing labels for code cells”\n\n\n2 adding table and figure captions\n“give the full version of this file after adding missing captions for table and figure cells. These should follow the label using this form:\n#| fig-caption: “A caption for the figure” or #| table-caption: “A caption for the table”\n”\n\n\n3 adding id to all equations\n” give the full version of this file after adding unique missing labels for display equations - the equation needs a final and a unique label at the end of the equation. E.g.\n\n\\pi \\qquad\n\\tag{1}\nand ensuring two newline before and after ”"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction to Bayesian Statistics",
    "section": "",
    "text": "Note\n\n\n\nInitially I signed up to two different specializations on Bayesian statistics. My notes cover the UoSCSC specialization This intro covers the",
    "crumbs": [
      "Intro",
      "Introduction to Bayesian Statistics"
    ]
  },
  {
    "objectID": "intro.html#why-inference",
    "href": "intro.html#why-inference",
    "title": "Introduction to Bayesian Statistics",
    "section": "1.1 Why Inference?",
    "text": "1.1 Why Inference?\nThe purpose of the set of courses is to focus on Inferential Statistics as opposed to Descriptive Statistics.\nAll the samples in the group that we are interested in learning about make up a population. Populations can be described by parameters such as the mean and variance since they represent all of the data. Often, we do not have access to all the data in our population and have to sample from the population. The metrics of mean and variance computed from these samples are not called parameters but statistics of the data.\n\n1.1.1 Descriptive Statistics\nThis is used to summarize the data so that we have a quantitative way to understand data. This allows to understand and visualize data qualitatively. We can draw conclusions about the nature of the data. Descriptive statistics is applied to a population and hence can provide measures such as the mean and variance of the data. They do not allow us to make predictions about data that we have not analyzed.\n\n\n1.1.2 Inferential Statistics\nInferential Statistics allow us to make generalizations about the population from the samples. This process of sampling introduces errors as this is never a perfect representation of the underlying data. The statistics thus computed are supposed to be an estimate of the true population parameters. It allows you to form a distribution of the population from the sampled data by accounting for the errors in the sampling, thereby allowing you to make predictions about data that is not yet seen or sampled.",
    "crumbs": [
      "Intro",
      "Introduction to Bayesian Statistics"
    ]
  },
  {
    "objectID": "intro.html#how-is-inference-different-from-prediction",
    "href": "intro.html#how-is-inference-different-from-prediction",
    "title": "Introduction to Bayesian Statistics",
    "section": "1.2 How is Inference different from Prediction?",
    "text": "1.2 How is Inference different from Prediction?\nReference\n\n1.2.1 Prediction\nIf you happen to come from a background in Machine Learning, you are probably used to making predictions. This is exactly what it sounds like, you use a model to make predictions on unseen data. The predictive process involves the following steps\n\nCreate the model\nSelect the best model using performance metrics such as accuracy, F1 scores on out-of-sample data\nMake predictions on new data\n\n\n\n1.2.2 Inference\nIn Inference, you are trying to model a distribution and understand the process that generates the data. This involves the following steps\n\nCreate the model, usually involves some prior understanding of the data generation process\nSelect the model using goodness-of-fit measures such as such as residual analysis, deviance, AIC scores etc.\nPerform inference by generating distributions that describe the data, or the data generation process",
    "crumbs": [
      "Intro",
      "Introduction to Bayesian Statistics"
    ]
  },
  {
    "objectID": "intro.html#references",
    "href": "intro.html#references",
    "title": "Introduction to Bayesian Statistics",
    "section": "1.3 References",
    "text": "1.3 References\n\n(Casella and Berger 2002) e-book solutions\n(Spanos 2019)\n(Hobbs and Hooten 2015) ebook website\n(VanderPlas 2016) ebook notebooks\n(Bishop 2006) ebook website",
    "crumbs": [
      "Intro",
      "Introduction to Bayesian Statistics"
    ]
  },
  {
    "objectID": "C2-L06.html",
    "href": "C2-L06.html",
    "title": "Assessing Convergence",
    "section": "",
    "text": "In the previous two lessons, we have demonstrated ways you can simulate a Markov chain whose stationary distribution is the target distribution (usually the posterior). Before using the simulated chain to obtain Monte Carlo estimates, we should first ask ourselves: Has our simulated Markov chain converged to its stationary distribution yet? Unfortunately, this is a difficult question to answer, but we can do several things to investigate.\n\n\nOur first visual tool for assessing chains is the trace plot. A trace plot shows the history of a parameter value across iterations of the chain. It shows you precisely where the chain has been exploring.\nFirst, let’s talk about what a chain should look like. Here is an example of a chain that has most likely converged.\n\n\nCode\nsource('mh.r')\n\n\nList of 2\n $ mu   : num [1:1000] 0 0 0 0 0 ...\n $ accpt: num 0.14\n\n\nCode\nlibrary(\"coda\")\nset.seed(61)\npost0 = mh(n=n, ybar=ybar, n_iter=10e3, mu_init=0.0, cand_sd=0.9)\ncoda::traceplot(as.mcmc(post0$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf the chain is stationary, it should not be showing any long-term trends. The average value for the chain should be roughly flat. It should not be wandering as in this example:\n\n\nCode\nset.seed(61)\npost1 = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post1$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf this is the case, you need to run the chain many more iterations, as seen here:\n\n\nCode\nset.seed(61)\npost2 = mh(n=n, ybar=ybar, n_iter=100e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\nThe chain appears to have converged at this much larger time scale.\n\n\n\nOne major difference between the two chains we’ve looked at is the level of autocorrelation in each. Autocorrelation is a number between -1 and +1 which measures how linearly dependent the current value of the chain is on past values (called lags). We can see this with an autocorrelation plot:\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post0$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post1$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.diag(as.mcmc(post1$mu))\n\n\n            [,1]\nLag 0  1.0000000\nLag 1  0.9850078\nLag 5  0.9213126\nLag 10 0.8387333\nLag 50 0.3834563\n\n\nAutocorrelation is important because it tells us how much information is available in our Markov chain. Sampling 1000 iterations from a highly correlated Markov chain yields less information about the stationary distribution than we would obtain from 1000 samples independently drawn from the stationary distribution.\nAutocorrelation is a major component in calculating the Monte Carlo effective sample size of your chain. The Monte Carlo effective sample size is how many independent samples from the stationary distribution you would have to draw to have equivalent information in your Markov chain. Essentially it is the m (sample size) we chose in the lesson on Monte Carlo estimation.\n\n\nCode\nstr(post2) # contains 100,000 iterations\n\n\nList of 2\n $ mu   : num [1:100000] -0.0152 -0.1007 -0.0867 -0.1092 -0.0811 ...\n $ accpt: num 0.958\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post2$mu)) # effective sample size of ~350\n\n\n   var1 \n373.858 \n\n\n\n\nCode\n## thin out the samples until autocorrelation is essentially 0. This will leave you with approximately independent samples. The number of samples remaining is similar to the effective sample size.\ncoda::autocorr.plot(as.mcmc(post2$mu), lag.max=500)\n\n\n\n\n\n\n\n\n\n\n\nCode\nthin_interval = 400 # how far apart the iterations are for autocorrelation to be essentially 0.\nthin_indx = seq(from=thin_interval, to=length(post2$mu), by=thin_interval)\nhead(thin_indx)\n\n\n[1]  400  800 1200 1600 2000 2400\n\n\n\n\nCode\npost2mu_thin = post2$mu[thin_indx]\ntraceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ntraceplot(as.mcmc(post2mu_thin))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post2mu_thin), lag.max=10)\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(as.mcmc(post2mu_thin))\n\n\nvar1 \n 250 \n\n\n\n\nCode\nlength(post2mu_thin)\n\n\n[1] 250\n\n\n\n\nCode\nstr(post0) # contains 10,000 iterations\n\n\nList of 2\n $ mu   : num [1:10000] 0 0 0.315 0.315 0.949 ...\n $ accpt: num 0.382\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post0$mu)) # effective sample size of ~2,500\n\n\n    var1 \n2537.924 \n\n\n?effectiveSize\nThe chain from post0 has 10,000 iterations, but an effective sample size of about 2,500. That is, this chain essentially provides the equivalent of 2,500 independent Monte Carlo samples.\nNotice that the chain from post0 has 10 times fewer iterations than for post2, but its Monte Carlo effective sample size is about seven times greater than the longer (more correlated) chain. We would have to run the correlated chain for 700,000+ iterations to get the same amount of information from both chains.\nIt is usually a good idea to check the Monte Carlo effective sample size of your chain. If all you seek is a posterior mean estimate, then an effective sample size of a few hundred to a few thousand should be enough. However, if you want to create something like a 95% posterior interval, you may need many thousands of effective samples to produce a reliable estimate of the outer edges of the distribution. The number you need can be quickly calculated using the Raftery and Lewis diagnostic.\nraftery.diag(as.mcmc(post0$mu))\n\n\nCode\nraftery.diag(as.mcmc(post0$mu), q=0.005, r=0.001, s=0.95)\n\n\n\nQuantile (q) = 0.005\nAccuracy (r) = +/- 0.001\nProbability (s) = 0.95 \n\nYou need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n## \n## Quantile (q) = 0.005\n## Accuracy (r) = +/- 0.001\n## Probability (s) = 0.95 \n## \n## You need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n?raftery.diag\n\n\nIn the case of the first chain from post0, it looks like we would need about 3,700 effective samples to calculate reliable 95% intervals. With the autocorrelation in the chain, that requires about 13,200 total samples. If we wanted to create reliable 99% intervals, we would need at least 19,100 total samples.\n\n\n\n\nWe have also seen how the initial value of the chain can affect how quickly the chain converges. If our initial value is far from the bulk of the posterior distribution, then it may take a while for the chain to travel there. We saw this in an earlier example.\n\n\nCode\nset.seed(62)\npost3 = mh(n=n, ybar=ybar, n_iter=500, mu_init=10.0, cand_sd=0.3)\ncoda::traceplot(as.mcmc(post3$mu))\n\n\n\n\n\n\n\n\n\nClearly, the first 100 or so iterations do not reflect draws from the stationary distribution, so they should be discarded before we use this chain for Monte Carlo estimates. This is called the “burn-in” period. You should always discard early iterations that do not appear to be coming from the stationary distribution. Even if the chain appears to have converged early on, it is safer practice to discard an initial burn-in.\n\n\nIf we want to be more confident that we have converged to the true stationary distribution, we can simulate multiple chains, each with a different starting value.\n\n\nCode\nset.seed(61)\n\nnsim = 500\npost1 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=15.0, cand_sd=0.4)\npost1$accpt\n\n\n[1] 0.616\n\n\n\n\nCode\npost2 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-5.0, cand_sd=0.4)\npost2$accpt\n\n\n[1] 0.612\n\n\n\n\nCode\npost3 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=7.0, cand_sd=0.1)\npost3$accpt\n\n\n[1] 0.844\n\n\n\n\nCode\npost4 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=23.0, cand_sd=0.5)\npost4$accpt\n\n\n[1] 0.53\n\n\n\n\nCode\npost5 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-17.0, cand_sd=0.4)\npost5$accpt\n\n\n[1] 0.618\n\n\n\n\nCode\npmc = mcmc.list(as.mcmc(post1$mu), as.mcmc(post2$mu), \n                as.mcmc(post3$mu), as.mcmc(post4$mu), as.mcmc(post5$mu))\nstr(pmc)\n\n\nList of 5\n $ : 'mcmc' num [1:500] 14.8 14 14 13.8 13.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -5 -5 -5 -5 -4.89 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 7 7 7 6.94 6.94 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 23 21.9 21.9 21.8 21.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -17 -17 -16.9 -16.2 -15.7 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n - attr(*, \"class\")= chr \"mcmc.list\"\n\n\n\n\nCode\ncoda::traceplot(pmc)\n\n\n\n\n\n\n\n\n\nIt appears that after about iteration 200, all chains are exploring the stationary (posterior) distribution. We can back up our visual results with the Gelman Rubin diagnostic. This diagnostic statistic calculates the variability within chains, comparing that to the variability between chains. If all chains have converged to the stationary distribution, the variability between chains should be relatively small, and the potential scale reduction factor, reported by the the diagnostic, should be close to one. If the values are much higher than one, then we would conclude that the chains have not yet converged.\n\n\nCode\ncoda::gelman.diag(pmc)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\n[1,]       1.01       1.02\n\n\n\n\nCode\ncoda::gelman.plot(pmc)\n\n\n\n\n\n\n\n\n\n\n\nCode\n?gelman.diag\n\n\n From the plot, we can see that if we only used the first 50 iterations, the potential scale reduction factor or “shrink factor” would be close to 10, indicating that the chains have not converged. But after about iteration 300, the “shrink factor” is essentially one, indicating that by then, we have probably reached convergence. Of course, we shouldn’t stop sampling as soon as we reach convergence. Instead, this is where we should begin saving our samples for Monte Carlo estimation.\n\n\n\nIf we are reasonably confident that our Markov chain has converged, then we can go ahead and treat it as a Monte Carlo sample from the posterior distribution. Thus, we can use the techniques from Lesson 3 to calculate posterior quantities like the posterior mean and posterior intervals from the samples directly.\n\n\nCode\nnburn = 1000 # remember to discard early iterations\npost0$mu_keep = post0$mu[-c(1:1000)]\nsummary(as.mcmc(post0$mu_keep))\n\n\n\nIterations = 1:9000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 9000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n      0.889449       0.304514       0.003210       0.006295 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n0.2915 0.6825 0.8924 1.0868 1.4890 \n\n\n\n\nCode\nmean(post0$mu_keep &gt; 1.0) # posterior probability that mu  &gt; 1.0\n\n\n[1] 0.3554444",
    "crumbs": [
      "2. Techniques and Models",
      "Assessing Convergence"
    ]
  },
  {
    "objectID": "C2-L06.html#convergence-diagnostics",
    "href": "C2-L06.html#convergence-diagnostics",
    "title": "Assessing Convergence",
    "section": "",
    "text": "In the previous two lessons, we have demonstrated ways you can simulate a Markov chain whose stationary distribution is the target distribution (usually the posterior). Before using the simulated chain to obtain Monte Carlo estimates, we should first ask ourselves: Has our simulated Markov chain converged to its stationary distribution yet? Unfortunately, this is a difficult question to answer, but we can do several things to investigate.\n\n\nOur first visual tool for assessing chains is the trace plot. A trace plot shows the history of a parameter value across iterations of the chain. It shows you precisely where the chain has been exploring.\nFirst, let’s talk about what a chain should look like. Here is an example of a chain that has most likely converged.\n\n\nCode\nsource('mh.r')\n\n\nList of 2\n $ mu   : num [1:1000] 0 0 0 0 0 ...\n $ accpt: num 0.14\n\n\nCode\nlibrary(\"coda\")\nset.seed(61)\npost0 = mh(n=n, ybar=ybar, n_iter=10e3, mu_init=0.0, cand_sd=0.9)\ncoda::traceplot(as.mcmc(post0$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf the chain is stationary, it should not be showing any long-term trends. The average value for the chain should be roughly flat. It should not be wandering as in this example:\n\n\nCode\nset.seed(61)\npost1 = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post1$mu[-c(1:500)]))\n\n\n\n\n\n\n\n\n\nIf this is the case, you need to run the chain many more iterations, as seen here:\n\n\nCode\nset.seed(61)\npost2 = mh(n=n, ybar=ybar, n_iter=100e3, mu_init=0.0, cand_sd=0.04)\ncoda::traceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\nThe chain appears to have converged at this much larger time scale.\n\n\n\nOne major difference between the two chains we’ve looked at is the level of autocorrelation in each. Autocorrelation is a number between -1 and +1 which measures how linearly dependent the current value of the chain is on past values (called lags). We can see this with an autocorrelation plot:\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post0$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post1$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.diag(as.mcmc(post1$mu))\n\n\n            [,1]\nLag 0  1.0000000\nLag 1  0.9850078\nLag 5  0.9213126\nLag 10 0.8387333\nLag 50 0.3834563\n\n\nAutocorrelation is important because it tells us how much information is available in our Markov chain. Sampling 1000 iterations from a highly correlated Markov chain yields less information about the stationary distribution than we would obtain from 1000 samples independently drawn from the stationary distribution.\nAutocorrelation is a major component in calculating the Monte Carlo effective sample size of your chain. The Monte Carlo effective sample size is how many independent samples from the stationary distribution you would have to draw to have equivalent information in your Markov chain. Essentially it is the m (sample size) we chose in the lesson on Monte Carlo estimation.\n\n\nCode\nstr(post2) # contains 100,000 iterations\n\n\nList of 2\n $ mu   : num [1:100000] -0.0152 -0.1007 -0.0867 -0.1092 -0.0811 ...\n $ accpt: num 0.958\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post2$mu)) # effective sample size of ~350\n\n\n   var1 \n373.858 \n\n\n\n\nCode\n## thin out the samples until autocorrelation is essentially 0. This will leave you with approximately independent samples. The number of samples remaining is similar to the effective sample size.\ncoda::autocorr.plot(as.mcmc(post2$mu), lag.max=500)\n\n\n\n\n\n\n\n\n\n\n\nCode\nthin_interval = 400 # how far apart the iterations are for autocorrelation to be essentially 0.\nthin_indx = seq(from=thin_interval, to=length(post2$mu), by=thin_interval)\nhead(thin_indx)\n\n\n[1]  400  800 1200 1600 2000 2400\n\n\n\n\nCode\npost2mu_thin = post2$mu[thin_indx]\ntraceplot(as.mcmc(post2$mu))\n\n\n\n\n\n\n\n\n\n\n\nCode\ntraceplot(as.mcmc(post2mu_thin))\n\n\n\n\n\n\n\n\n\n\n\nCode\ncoda::autocorr.plot(as.mcmc(post2mu_thin), lag.max=10)\n\n\n\n\n\n\n\n\n\n\n\nCode\neffectiveSize(as.mcmc(post2mu_thin))\n\n\nvar1 \n 250 \n\n\n\n\nCode\nlength(post2mu_thin)\n\n\n[1] 250\n\n\n\n\nCode\nstr(post0) # contains 10,000 iterations\n\n\nList of 2\n $ mu   : num [1:10000] 0 0 0.315 0.315 0.949 ...\n $ accpt: num 0.382\n\n\n\n\nCode\ncoda::effectiveSize(as.mcmc(post0$mu)) # effective sample size of ~2,500\n\n\n    var1 \n2537.924 \n\n\n?effectiveSize\nThe chain from post0 has 10,000 iterations, but an effective sample size of about 2,500. That is, this chain essentially provides the equivalent of 2,500 independent Monte Carlo samples.\nNotice that the chain from post0 has 10 times fewer iterations than for post2, but its Monte Carlo effective sample size is about seven times greater than the longer (more correlated) chain. We would have to run the correlated chain for 700,000+ iterations to get the same amount of information from both chains.\nIt is usually a good idea to check the Monte Carlo effective sample size of your chain. If all you seek is a posterior mean estimate, then an effective sample size of a few hundred to a few thousand should be enough. However, if you want to create something like a 95% posterior interval, you may need many thousands of effective samples to produce a reliable estimate of the outer edges of the distribution. The number you need can be quickly calculated using the Raftery and Lewis diagnostic.\nraftery.diag(as.mcmc(post0$mu))\n\n\nCode\nraftery.diag(as.mcmc(post0$mu), q=0.005, r=0.001, s=0.95)\n\n\n\nQuantile (q) = 0.005\nAccuracy (r) = +/- 0.001\nProbability (s) = 0.95 \n\nYou need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n## \n## Quantile (q) = 0.005\n## Accuracy (r) = +/- 0.001\n## Probability (s) = 0.95 \n## \n## You need a sample size of at least 19112 with these values of q, r and s\n\n\n\n\nCode\n?raftery.diag\n\n\nIn the case of the first chain from post0, it looks like we would need about 3,700 effective samples to calculate reliable 95% intervals. With the autocorrelation in the chain, that requires about 13,200 total samples. If we wanted to create reliable 99% intervals, we would need at least 19,100 total samples.",
    "crumbs": [
      "2. Techniques and Models",
      "Assessing Convergence"
    ]
  },
  {
    "objectID": "C2-L06.html#burn-in",
    "href": "C2-L06.html#burn-in",
    "title": "Assessing Convergence",
    "section": "",
    "text": "We have also seen how the initial value of the chain can affect how quickly the chain converges. If our initial value is far from the bulk of the posterior distribution, then it may take a while for the chain to travel there. We saw this in an earlier example.\n\n\nCode\nset.seed(62)\npost3 = mh(n=n, ybar=ybar, n_iter=500, mu_init=10.0, cand_sd=0.3)\ncoda::traceplot(as.mcmc(post3$mu))\n\n\n\n\n\n\n\n\n\nClearly, the first 100 or so iterations do not reflect draws from the stationary distribution, so they should be discarded before we use this chain for Monte Carlo estimates. This is called the “burn-in” period. You should always discard early iterations that do not appear to be coming from the stationary distribution. Even if the chain appears to have converged early on, it is safer practice to discard an initial burn-in.\n\n\nIf we want to be more confident that we have converged to the true stationary distribution, we can simulate multiple chains, each with a different starting value.\n\n\nCode\nset.seed(61)\n\nnsim = 500\npost1 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=15.0, cand_sd=0.4)\npost1$accpt\n\n\n[1] 0.616\n\n\n\n\nCode\npost2 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-5.0, cand_sd=0.4)\npost2$accpt\n\n\n[1] 0.612\n\n\n\n\nCode\npost3 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=7.0, cand_sd=0.1)\npost3$accpt\n\n\n[1] 0.844\n\n\n\n\nCode\npost4 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=23.0, cand_sd=0.5)\npost4$accpt\n\n\n[1] 0.53\n\n\n\n\nCode\npost5 = mh(n=n, ybar=ybar, n_iter=nsim, mu_init=-17.0, cand_sd=0.4)\npost5$accpt\n\n\n[1] 0.618\n\n\n\n\nCode\npmc = mcmc.list(as.mcmc(post1$mu), as.mcmc(post2$mu), \n                as.mcmc(post3$mu), as.mcmc(post4$mu), as.mcmc(post5$mu))\nstr(pmc)\n\n\nList of 5\n $ : 'mcmc' num [1:500] 14.8 14 14 13.8 13.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -5 -5 -5 -5 -4.89 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 7 7 7 6.94 6.94 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] 23 21.9 21.9 21.8 21.8 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n $ : 'mcmc' num [1:500] -17 -17 -16.9 -16.2 -15.7 ...\n  ..- attr(*, \"mcpar\")= num [1:3] 1 500 1\n - attr(*, \"class\")= chr \"mcmc.list\"\n\n\n\n\nCode\ncoda::traceplot(pmc)\n\n\n\n\n\n\n\n\n\nIt appears that after about iteration 200, all chains are exploring the stationary (posterior) distribution. We can back up our visual results with the Gelman Rubin diagnostic. This diagnostic statistic calculates the variability within chains, comparing that to the variability between chains. If all chains have converged to the stationary distribution, the variability between chains should be relatively small, and the potential scale reduction factor, reported by the the diagnostic, should be close to one. If the values are much higher than one, then we would conclude that the chains have not yet converged.\n\n\nCode\ncoda::gelman.diag(pmc)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\n[1,]       1.01       1.02\n\n\n\n\nCode\ncoda::gelman.plot(pmc)\n\n\n\n\n\n\n\n\n\n\n\nCode\n?gelman.diag\n\n\n From the plot, we can see that if we only used the first 50 iterations, the potential scale reduction factor or “shrink factor” would be close to 10, indicating that the chains have not converged. But after about iteration 300, the “shrink factor” is essentially one, indicating that by then, we have probably reached convergence. Of course, we shouldn’t stop sampling as soon as we reach convergence. Instead, this is where we should begin saving our samples for Monte Carlo estimation.\n\n\n\nIf we are reasonably confident that our Markov chain has converged, then we can go ahead and treat it as a Monte Carlo sample from the posterior distribution. Thus, we can use the techniques from Lesson 3 to calculate posterior quantities like the posterior mean and posterior intervals from the samples directly.\n\n\nCode\nnburn = 1000 # remember to discard early iterations\npost0$mu_keep = post0$mu[-c(1:1000)]\nsummary(as.mcmc(post0$mu_keep))\n\n\n\nIterations = 1:9000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 9000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n      0.889449       0.304514       0.003210       0.006295 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n0.2915 0.6825 0.8924 1.0868 1.4890 \n\n\n\n\nCode\nmean(post0$mu_keep &gt; 1.0) # posterior probability that mu  &gt; 1.0\n\n\n[1] 0.3554444",
    "crumbs": [
      "2. Techniques and Models",
      "Assessing Convergence"
    ]
  },
  {
    "objectID": "C1-L04.html",
    "href": "C1-L04.html",
    "title": "Frequentist Inference",
    "section": "",
    "text": "Figure 1: frequentist approach to confidence intervals\n\n\nA brief review of the frequentist approach to inference will be useful for contrasting with the Bayesian approach. (Kruschke 2011) Chapter 2 suggests that CI provides the basis for a Bayesian workflow and that the rest of the text fills in the missing pieces.\n\n\n\n\n\n\nImportantFrequentist paradigm\n\n\n\nUnder the frequentist paradigm, one views the data as a random sample from some larger, potentially hypothetical population. We can then make probability statements i.e. long-run frequency statements based on this larger population.\n\n\n\nExample 1 (Coin Flip Example - Central Limit Theorem) Suppose we flip a coin 100 times. And we get 44 heads and 56 tails. We can view these 100 flips as a random sample from a much larger infinite hypothetical population of flips from this coin. We can say that each flip is X_i an RV which follows a Bernoulli distribution with some probability p. In this case p is unknown, but we can assume it is fixed since we are using a specific physical coin.\n\nX_i \\sim B(p)\n\\tag{1}\nWe ask :\n\nWhat is our best estimate of p the probability of getting a head?\nHow confident are we in the estimate of p?\n\nTo estimate p we will apply the Central limit theorem c.f. ?@thm-clt which states that the mean of a large number of IID RV with mean \\mu and variance \\sigma^2 is approximately N(\\mu,\\sigma^2).\n\n\\sum^{100}_{i=1} X_i\\mathrel{\\dot \\sim } N(100 \\enspace p, 100 \\enspace p(1-p))\n\\tag{2}\nGiven that this is a Normal distribution, we can use the empirical rule often called the 68-95-99.7 rule see (Wikipedia contributors 2023), that says 95% of the time we will get a result is in within 1.96 standard deviations of the mean. This is referred to as a Confidence Interval or (CI).\n\n95\\% \\: \\text{CI}= 100 \\: \\hat{p} \\pm 1.96\\sqrt{100 \\: \\hat{p}(1-\\hat{p})}\n\\tag{3}\nSince we observed 44 heads we can estimate \\hat{p} as\n\n\\hat p = \\frac{44}{100} = .44\n\\tag{4}\nThis answers our first questions. Now we want to quantify our uncertainty.\n\\begin{aligned}\n95\\% \\: \\text{CI for 100 tosses} &= 100 \\: (.44) \\pm 1.96\\sqrt{100(0.44)(1-0.44)} \\\\ &= 44 \\pm 1.96\\sqrt{(44) (0.56)} \\\\ &= 44 \\pm 1.96\\sqrt{23.64} \\\\ &= (34.27,53.73) \\end{aligned}\n\\tag{5}\nWe can be 95% confident that 100\\times \\hat{p} \\in [34.3,53.7] We can say that we’re 95% confident that the true probability p \\in (.343, .537).\nIf one were to ask do I think this coin is Fair ? This is a reasonable hypothesis, since 0.5 \\in [.343,.537].\nBut we can also step back and say what does this interval mean when we say we’re 95% confident? Under the frequentist paradigm, we have to think back to our infinite hypothetical sequence of events, were we to repeat this trial an arbitrarily large number of times and each time create a confidence interval, then on average 95% of the intervals we make will contain the true value of p. This makes senses as a long run frequency explanation.\nOn the other hand, we might want to know something about this particular interval. Does this interval contain the true p. What’s the probability that this interval contains a true p? Well, we don’t know for this particular interval. But under the frequentist paradigm, we’re assuming that there is a fixed right answer for p. Either p is in that interval or it’s not in that interval. And so technically, from a frequentist perspective, the probability that p is in this interval is either 0 or 1. This is not a particularly satisfying explanation. In the other hand when we get to the Bayesian approach we will be able to compute an interval and actually say there is probably a p is in this interval is 95% based on a random interpretation of an unknown parameter.\n\n\n\n\n\n\n\nTip\n\n\n\nIn this example of flipping a coin 100 times, observing 44 heads resulted in the following 95% confidence interval for p: (.343, .537). From this, we concluded that it is plausible that the coin may be fair because p=.5 is in the interval.\nSuppose instead that we flipped the coin 100,000 times, observing 44,000 heads (the same percentage of heads as before). Then using the method just presented, the 95% confidence interval for p is (.437, .443). Is it still reasonable to conclude that this is a fair coin with 95% confidence?\nNo Because 0.5 \\not\\in (.437, .443), we must conclude that p=.5 is not a plausible value for the population mean . Observing 100,000 flips increases the power of the experiment, leading to a more precise estimate with a narrower CI, due to the law of large numbers.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-confidence-intervals",
    "href": "C1-L04.html#sec-confidence-intervals",
    "title": "Frequentist Inference",
    "section": "",
    "text": "Figure 1: frequentist approach to confidence intervals\n\n\nA brief review of the frequentist approach to inference will be useful for contrasting with the Bayesian approach. (Kruschke 2011) Chapter 2 suggests that CI provides the basis for a Bayesian workflow and that the rest of the text fills in the missing pieces.\n\n\n\n\n\n\nImportantFrequentist paradigm\n\n\n\nUnder the frequentist paradigm, one views the data as a random sample from some larger, potentially hypothetical population. We can then make probability statements i.e. long-run frequency statements based on this larger population.\n\n\n\nExample 1 (Coin Flip Example - Central Limit Theorem) Suppose we flip a coin 100 times. And we get 44 heads and 56 tails. We can view these 100 flips as a random sample from a much larger infinite hypothetical population of flips from this coin. We can say that each flip is X_i an RV which follows a Bernoulli distribution with some probability p. In this case p is unknown, but we can assume it is fixed since we are using a specific physical coin.\n\nX_i \\sim B(p)\n\\tag{1}\nWe ask :\n\nWhat is our best estimate of p the probability of getting a head?\nHow confident are we in the estimate of p?\n\nTo estimate p we will apply the Central limit theorem c.f. ?@thm-clt which states that the mean of a large number of IID RV with mean \\mu and variance \\sigma^2 is approximately N(\\mu,\\sigma^2).\n\n\\sum^{100}_{i=1} X_i\\mathrel{\\dot \\sim } N(100 \\enspace p, 100 \\enspace p(1-p))\n\\tag{2}\nGiven that this is a Normal distribution, we can use the empirical rule often called the 68-95-99.7 rule see (Wikipedia contributors 2023), that says 95% of the time we will get a result is in within 1.96 standard deviations of the mean. This is referred to as a Confidence Interval or (CI).\n\n95\\% \\: \\text{CI}= 100 \\: \\hat{p} \\pm 1.96\\sqrt{100 \\: \\hat{p}(1-\\hat{p})}\n\\tag{3}\nSince we observed 44 heads we can estimate \\hat{p} as\n\n\\hat p = \\frac{44}{100} = .44\n\\tag{4}\nThis answers our first questions. Now we want to quantify our uncertainty.\n\\begin{aligned}\n95\\% \\: \\text{CI for 100 tosses} &= 100 \\: (.44) \\pm 1.96\\sqrt{100(0.44)(1-0.44)} \\\\ &= 44 \\pm 1.96\\sqrt{(44) (0.56)} \\\\ &= 44 \\pm 1.96\\sqrt{23.64} \\\\ &= (34.27,53.73) \\end{aligned}\n\\tag{5}\nWe can be 95% confident that 100\\times \\hat{p} \\in [34.3,53.7] We can say that we’re 95% confident that the true probability p \\in (.343, .537).\nIf one were to ask do I think this coin is Fair ? This is a reasonable hypothesis, since 0.5 \\in [.343,.537].\nBut we can also step back and say what does this interval mean when we say we’re 95% confident? Under the frequentist paradigm, we have to think back to our infinite hypothetical sequence of events, were we to repeat this trial an arbitrarily large number of times and each time create a confidence interval, then on average 95% of the intervals we make will contain the true value of p. This makes senses as a long run frequency explanation.\nOn the other hand, we might want to know something about this particular interval. Does this interval contain the true p. What’s the probability that this interval contains a true p? Well, we don’t know for this particular interval. But under the frequentist paradigm, we’re assuming that there is a fixed right answer for p. Either p is in that interval or it’s not in that interval. And so technically, from a frequentist perspective, the probability that p is in this interval is either 0 or 1. This is not a particularly satisfying explanation. In the other hand when we get to the Bayesian approach we will be able to compute an interval and actually say there is probably a p is in this interval is 95% based on a random interpretation of an unknown parameter.\n\n\n\n\n\n\n\nTip\n\n\n\nIn this example of flipping a coin 100 times, observing 44 heads resulted in the following 95% confidence interval for p: (.343, .537). From this, we concluded that it is plausible that the coin may be fair because p=.5 is in the interval.\nSuppose instead that we flipped the coin 100,000 times, observing 44,000 heads (the same percentage of heads as before). Then using the method just presented, the 95% confidence interval for p is (.437, .443). Is it still reasonable to conclude that this is a fair coin with 95% confidence?\nNo Because 0.5 \\not\\in (.437, .443), we must conclude that p=.5 is not a plausible value for the population mean . Observing 100,000 flips increases the power of the experiment, leading to a more precise estimate with a narrower CI, due to the law of large numbers.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-likelihood-function-and-MLE",
    "href": "C1-L04.html#sec-likelihood-function-and-MLE",
    "title": "Frequentist Inference",
    "section": "0.2 Likelihood function and MLE",
    "text": "0.2 Likelihood function and MLE\n\n\n\n\n\n\n\nFigure 2: Likelihood fn and MLE\n\n\n\nExample 2 (Heart Attack Patients - MLE) Consider a hospital where 400 patients are admitted over a month for heart attacks, and a month later 72 of them have died and 328 of them have survived.\nwhat’s our estimate of the mortality rate?\n\n\n\n\n\n\nWarningReference Population\n\n\n\nUnder the frequentist paradigm, we must first establish our reference population. This is the cornerstone of our thinking as we are considering how the sample parameter approximates the population statistic. What do we think our reference population is here?\n\nRef Pop 1: Heart attack patients in the region.\nRef Pop 2: Heart attack patients that are admitted to this hospital, but over a longer period.\nRef Pop 3: The people in the region who might have a heart attack and might get admitted to this hospital.\n\nBoth Ref Pop 1 and Ref Pop 2 seem like viable options. Unfortunately, in our data is not a random sample drawn from either. We could pretend they are and move on, or we could also try to think harder about what our data is sampled from, perhaps Ref Pop 3.\nThis is an odd hypothetical situation, and so there are some philosophical issues with the setup of this whole problem within the frequentist paradigm\n\n\n\nY_i \\sim Bernulli(p)\n\\tag{6}\nSince this is a Bernoulli trial we need to specify what we interpret as the success . In this case, the success is a mortality.\n\nP(Y_i=1) = \\theta\n\\tag{7}\nThe PDF for the dataset can be written in vector form. P(\\vec{Y}=\\vec{y} \\mid \\theta) is the Probability of all the Y’s take some value little y given a value of theta.\n\n\\begin{aligned}\nP(\\vec{Y}=\\vec{y} \\mid \\theta) &= P(Y_1=y,\\dots,Y_n=y_n \\mid \\theta) && \\text{(joint probability)}\n\\\\&= P(Y_1=y_1 \\mid \\theta) \\cdots P(Y_n=y_n \\mid \\theta)            && \\text {(independence)}\n\\\\&= \\prod^n_{i=1} P(Y_i=y_i \\mid \\theta)                            && \\text {(product notation)}\n\\\\&= \\prod^n_{i=1} \\theta^{y_i} (1-\\theta)^{1-y_i}                   && \\text {(Bernoulli PMF)}\n\\end{aligned}\n\\tag{8}\nWe now cal the expression for P(\\vec{Y}=\\vec{y} \\mid \\theta) above the likelihood function L(\\theta \\mid \\vec{y} ):\n  \n\\mathcal{L}(\\theta\\mid\\vec{y}) = \\prod^n_{i=1} \\theta^{y_i} (1-\\theta)^{1-y_i}\n\\tag{9}\nRecall that we want to find the mortality rate parameter \\theta for our Sample \\vec Y.\nSince it is a probability, it has a range of values from 0 to 1. One way to estimate it is that there should be one value that maximizes (Equation 9). It makes the data the most likely to occur for the particular data we observed. This is referred to as the maximum likelihood estimate (MLE).\n\n\\mathop{\\mathrm{MLE}}(\\hat \\theta) = \\mathop{\\mathrm{argmax}} \\; \\mathcal{L}(\\theta\\mid y)\n\nAlthough we are trying to find the \\theta that maximizes the likelihood, in practice, it’s usually easier to maximize the natural logarithm of the likelihood, commonly referred to as the log-likelihood.\n \\begin{aligned}\n  \\mathcal{L}(\\theta) &= \\log(L(\\theta|\\vec{y}))  &&\n\\\\        &= \\log(\\prod^n_{i=1} {\\theta^{y_i} (1-\\theta)^{1-y_i}})  && \\text{subst. liklihood}\n\\\\        &= \\sum^n_{i=1}{ \\log(\\theta^{y_i}) + \\log(1-\\theta)^{1-y_i}} && \\text{log product rule}\n\\\\        &= \\sum^n_{i=1}{ y_i \\log(\\theta) + (1-y_i) \\log(1-\\theta)} && \\text{log power rule}\n\\\\        &= \\log(\\theta) \\sum^n_{i=1}{  y_i + \\log(1-\\theta)} \\sum^n_{i=1}{  (1-y_i) }&& \\text{extracting logs}\n\\end{aligned}\n\\tag{10}\nWhat is the interpretation of the MLE of \\theta in the context of the heart attack example?\nIf \\hat \\theta is the MLE for \\theta, the 30-day mortality rate, then all possible values of θ produce a lower value of the likelihood than \\hat \\theta.\nTo calculate the MLE one should differentiate \\mathcal{L}(\\theta) w.r.t. \\theta and then set it equal to 0.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-computing-the-MLE",
    "href": "C1-L04.html#sec-computing-the-MLE",
    "title": "Frequentist Inference",
    "section": "0.3 Computing the MLE",
    "text": "0.3 Computing the MLE\n\n\n\n\n\n\n\nFigure 3: Computing the MLE\n\n\n\n\\begin{aligned}\n   && \\mathcal{L}'(\\theta)=& \\frac{1}{\\theta}\\sum_{i=1}^n y_i-\\frac{1}{1-\\theta}\\sum_{i=1}^n 1-y_i \\stackrel{\\text{set}}{=}0  \\text {set derivative to 0}\n\\\\ & \\implies   & \\frac{1}{\\hat \\theta}\\sum_{i=1}^n y_i & = \\frac{1}{1- \\hat \\theta}\\sum_{i=1}^n 1 - y_i\n\\\\ & \\implies   & (1 -\\hat \\theta) \\sum_{i=1}^n{y_i}    &= \\hat\\theta \\sum_{i=1}^n {1-y_i}  \n\\\\ & \\implies   & 1 \\sum_{i=1}^n{y_i} - \\cancel{ \\hat \\theta \\sum_{i=1}^{n}{y_i}} &= \\hat\\theta \\sum_{i=1}^n {1} - \\cancel{\\hat\\theta \\sum_{i=1}^n {y_i}}  \n\\\\ & \\implies   & \\sum_{i=1}^n{y_i}  &= \\hat\\theta N\n\\\\ & \\implies   &  \\hat \\theta &= \\frac{1}{N} \\sum_{i=1}^n y_i  = \\hat p = \\frac{72}{400}=.18\n\\end{aligned}\n\nMaximum Likelihood Estimates (MLEs) possess the following favorable properties:\n\nUnbiased - Thus given sufficient data the MLE will converge to the true value. As a consequence, MLEs are asymptotically unbiased. As we will see in the examples they can still be biased in finite samples.\nconsistent - One important property of maximum likelihood is that it produces consistent estimates.\ninvariant - The invariance principle states that the MLE is invariant against reparameterization.\n\nusing the Central Limit theorem (see ?@thm-clt).\n\n\\hat \\theta \\pm 1.96\\sqrt\\frac{\\hat \\theta(1-\\hat \\theta)}{n}\n\n\n\\hat \\theta \\simeq \\mathcal{N}(\\theta,\\frac{1}{\\mathcal{I} (\\hat \\theta)})\n\nwhere \\mathcal{I} is the Fischer information which for the Bernoulli distribution is:\n\n\\mathcal{I}( \\hat \\theta) = \\frac{1}{\\theta(1-\\theta)}\n\nNote: The Fischer information is a measure of how much information about theta is in each data point!\n\n\n\n\n\n\nTipExplainable AI (XAI) & Fischer information\n\n\n\nIn XAI we use discuss local and global explanations.\n\nGlobal explanations explain a black box model’s predictions based on each feature, via its parameters.\nLocal explanations explain the prediction of a specific datum from its features.\n\nsince Fischer information quantifies the information in a data point on a parameter we should be able to use it to produce local and perhaps even global explanations for Bayesian models.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-computing-the-MLE-examples",
    "href": "C1-L04.html#sec-computing-the-MLE-examples",
    "title": "Frequentist Inference",
    "section": "0.4 Computing the MLE: examples",
    "text": "0.4 Computing the MLE: examples\nSome more examples of maximum likelihood estimators.\n\n0.4.1 Computing the MLE for Exponential RV\n\n\n\n\n\n\n\nFigure 4: computing the MLE for Exponential RV\n\n\nLet’s say X_i are exponential distributed\n\nX_i \\sim Exp(\\lambda)\n\nLet’s say the data is independent and identically distributed, therefore making the overall density function\n\n\\begin{aligned}\n  f(x \\mid \\lambda) &= \\prod_{i = 1}^n{\\lambda e^{-\\lambda x_i}} && \\text {(simplifying)}\n  \\\\ &= \\lambda^ne^{-\\lambda \\sum{x_i}}\n\\end{aligned}\n\\tag{11}\nNow the likelihood function is\n\nL(\\lambda \\mid x)=\\lambda^ne^{-\\lambda \\sum{x_i}}\n\\tag{12}\nthe log likelihood is\n\n\\mathcal{L}(\\lambda) = n\\ln{\\lambda} - \\lambda\\sum_i{x_i}\n\\tag{13}\nTaking the derivative\n\n\\begin{aligned}\n  \\mathcal{L}^\\prime(\\lambda) &= \\frac{n}{\\lambda} - \\sum_i{x_i} \\stackrel{\\text{set}}{=}0 && \\text {(set derivative = 0)}\n\\\\ \\implies \\frac{n}{\\hat{\\lambda}} &= \\sum_i{x_i} && \\text{(rearranging)}\n\\end{aligned}\n\\tag{14}\n\n\\hat{\\lambda} = \\frac{n}{\\sum_i{x_i}} = \\frac{1}{\\bar{x}}\n\\tag{15}\n\n\n0.4.2 Computing the MLE for Uniform RV\n\n\n\n\n\n\n\nFigure 5: computing the MLE for Uniform RV\n\n\n\nX_i \\sim  \\mathrm{Uniform}[0, \\theta]\n\\tag{16}\n\nf(x \\mid \\theta) = \\prod_{i = 1}^n{\\frac{1}{\\theta}\\mathbb{I}_{0 \\le x_i \\le \\theta}}\n\\tag{17}\nCombining all the indicator functions, for this to be a 1, each of these has to be true. These are going to be true if all the observations are bigger than 0, as in the minimum of the x is bigger than or equal to 0. The maximum of the x’s is also less than or equal to \\theta.\n\n\\mathcal{L}(\\theta|x) = \\theta^{-1} \\mathbb{I}_{0\\le min(x_i) \\le max(x_i) \\le \\theta}\n\\tag{18}\n\n\\mathcal{L}^\\prime(\\theta) = -n\\theta^{-(n + 1)}\\mathbb{I}_{0 \\le min(x_i) \\le max(x_i)\\le \\theta}\n\\tag{19}\nWe ask, can we set this equal to zero and solve for \\theta? It turns out, this is not equal to zero for any \\theta positive value. We need \\theta to be strictly larger than zero. But for \\theta positive, this will always be negative. The derivative is negative, that says this is a decreasing function. Therefore this function will be maximized when we pick \\theta as small as possible. What’s the smallest possible value of \\theta we can pick? Well we need in particular for \\theta to be larger than all of the X_i. And so, the maximum likelihood estimate is the maximum of X_i\n\n\\hat{\\theta} = max(x_i)\n\\tag{20}",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-cumulative-distribution-function",
    "href": "C1-L04.html#sec-cumulative-distribution-function",
    "title": "Frequentist Inference",
    "section": "0.5 Cumulative Distribution Function",
    "text": "0.5 Cumulative Distribution Function\nThe cumulative distribution function (CDF) exists for every distribution. We define it as F(x) = P(X \\le x) for random variable X.\nIf X is discrete-valued, then the CDF is computed with summation F(x) = \\sum_{t = -\\infty}^x {f(t)}. where f(t) = P(X = t) is the probability mass function (PMF) which we’ve already seen.\nIf X is continuous, the CDF is computed with an integral F(x) = \\int_{-\\infty}^x{f(t)dt}\nThe CDF is convenient for calculating probabilities of intervals. Let a and b be any real numbers with a &lt; b. Then the probability that X falls between a and b is equal to P(a &lt; X &lt; b) = P(X \\le b) - P(X \\le a) = F(b) - F(a)\n\n\n\n\n\n\nFigure 6: Illustration of using the CDF to calculate the probability of an interval for continuous random variable X. Probability values are represented with shaded regions in the graphs.\n\n\n\n\nExample 3 (CDF example 1) Suppose X ∼ Binomial(5, 0.6). Then\n\n  \\begin{aligned}\n  F(1) &= P(X \\le 1)\n\\\\ &= \\sum_{−∞}^1 f(t)\n\\\\ &= \\sum_{t=−∞}^{-1} 0 + \\sum_{t=0}^1 {5 \\choose t} 0.6^t (1 − 0.6)^{5−t}\n\\\\ &= {5 \\choose 0} 0.6^0 (1 − 0.6)5−0 +{5 \\choose 1} 0.6^1 (1 − 0.6)^{5−1}\n\\\\ &= (0.4)^5 + 5(0.6)(0.4)^4\n\\\\ &≈ 0.087\n\\end{aligned}\n\\tag{21}\n\n\nExample 4 (CDF example 1) Example: Suppose Y ∼ Exp(1). Then\n\n\\begin{aligned}\nF(2) &= P(Y \\le 2)\n\\\\ &= \\int^{2}_{−∞} e^{−t}\\mathbb{I}_{(t≥0)} dt\n\\\\ &= \\int^{2}_{0} e^{−t}dt\n\\\\ &= −e^{−t}|^2_0\n\\\\ &= −(e^{−2} − e^0)\n\\\\ &= 1−e^{−2}\n\\\\ &≈ 0.865\n\\end{aligned}\n\\tag{22}",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-quantile-function",
    "href": "C1-L04.html#sec-quantile-function",
    "title": "Frequentist Inference",
    "section": "0.6 Quantile Function",
    "text": "0.6 Quantile Function\nThe CDF takes a value for a random variable and returns a probability. Suppose instead we start with a number between 0 and 1, which we call p, and we wish to find a value x so that P(X \\le x) = p. The value x which satisfies this equation is called the p quantile. (or 100p percentile) of the distribution of X.\n\nExample 5 (Quantile Function example 1) In a standardized test, the 97th percentile of scores among all test-takers is 23. Then 23 is the score you must achieve on the test in order to score higher than 97% of all test-takers. We could equivalently call q = 23 the .97 quantile of the distribution of test scores.\n\n\nExample 6 (Quantile Function example 2) The middle 50% of probability mass for a continuous random variable is found between the .25 and .75 quantiles of its distribution. If Z \\sim N(0, 1), then the .25 quantile is −0.674 and the .75 quantile is 0.674. Therefore, P(−0.674 &lt;Z &lt;0.674) = 0.5.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L04.html#sec-plotting-the-likelihood-function-in-r",
    "href": "C1-L04.html#sec-plotting-the-likelihood-function-in-r",
    "title": "Frequentist Inference",
    "section": "1.1 Plotting the likelihood function in R",
    "text": "1.1 Plotting the likelihood function in R\nGoing back to the hospital example\n\n\nCode\nlikelihood = function(n, y, theta) {\n  return(theta^y * (1 - theta)^(n - y))\n}\ntheta = seq(from = 0.01, to = 0.99, by = 0.01)\nplot(theta, likelihood(400, 72, theta))\n\n\n\n\n\n\n\n\n\nYou can also do this with log likelihoods. This is typically more numerically stable to compute\n\n\nCode\nloglike = function(n, y, theta) {\n  return(y * log(theta) + (n - y) * log(1 - theta))\n}\nplot(theta, loglike(400, 72, theta))\n\n\n\n\n\n\n\n\n\nHaving these plotted as points makes it difficult to see, let’s plot it as lines\n\n\nCode\nplot(theta, loglike(400, 72, theta), type = \"l\")",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Frequentist Inference"
    ]
  },
  {
    "objectID": "C1-L07.html",
    "href": "C1-L07.html",
    "title": "Binomial Data",
    "section": "",
    "text": "Figure 1: Binomial likelihood with a Uniform prior\n\n\nWhen we use a uniform prior for a Bernoulli likelihood, we get a beta posterior.\nThe Bernoulli likelihood of \\vec Y \\mid \\theta is\n\n{\\color{green}f(\\vec Y \\mid \\theta) = {\\theta^{\\sum{y_i}}(1-\\theta)^{n - \\sum{y_i}}}} \\qquad \\text{Bernoulli Likelihood}\n\nOur prior for \\theta is just a Uniform distribution\n\n{\\color{red}f(\\theta) = I_{\\{0 \\le \\theta \\le 1\\}} }\\qquad \\text {Uniform prior}\n\nThus our posterior for \\theta is \n\\begin{aligned}\nf(\\theta \\mid y) & = \\frac{f(y \\mid \\theta) f(\\theta)}{\\int f(y \\mid \\theta)f(\\theta) \\, d\\theta} & \\text{Bayes law} \\\\\n& = \\frac{\\theta^{\\sum{y_i}} (1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}}}{\\int_0^1 \\theta^{\\sum{y_i}}(1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}} \\, d\\theta} & \\text{subst. Likelihood \\& Prior} \\\\\n& = \\frac{\\theta^{\\sum{y_i}} (1-\\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}}}{\\frac{\\Gamma(\\sum{y_i} + 1)\\Gamma(n - \\sum{y_i} + 1)}{\\Gamma(n + 2)} \\cancel{\\int_0^1 \\frac{\\Gamma(n + 2)}{\\Gamma(\\sum{y_i} + 1) \\Gamma(n - \\sum{y_i} + 1)} \\theta^{\\sum{y_i}} (1 - \\theta)^{n - \\sum{y_i}} \\, d\\theta}} & \\text{Beta PDF integrates to 1} \\\\\n& = \\frac{\\Gamma(n + 2)}{\\Gamma(\\sum{y_i}+ 1) \\Gamma(n - \\sum{y_i}+ 1)} \\theta^{\\sum{y_i}}(1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}} & \\text{simplifying} \\\\\n& = \\mathrm{Beta} \\left (\\sum{y_i} + 1, n - \\sum{y_i} + 1 \\right )\n\\end{aligned}\n\nWhere we used a trick of recognizing the denominator as a Beta distribution (?@eq-beta-pdf) we then manipulate it to take the exact form of Beta. We can then cancel it since the beta density integrates to 1, we can simplify this as From here we can see that the posterior follows a beta distribution\n\n\\theta | y \\sim Beta(\\sum{y_i} + 1, n - \\sum{y_i} + 1)\n\n\n\n\n\n\n\nTipHistorical Note on R.A. Fisher\n\n\n\n R.A. Fisher’s objection to the Bayesian approach is that “The theory of inverse probability is founded upon an error, and must be wholly rejected” (Fisher 1925) was specifically referring to this example of a”Binomial with a Uniform prior”. The gist of it is that the posterior depends on the parametrization of the prior.(Aldrich 2008). R.A. Jeffry who corresponded with Fisher went on to develop his eponymous priors which were invariant to reparametrization. Which we will consider in ?@sec-jeffreys-prior",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Binomial Data"
    ]
  },
  {
    "objectID": "C1-L07.html#bernoullibinomial-likelihood-with-a-uniform-prior",
    "href": "C1-L07.html#bernoullibinomial-likelihood-with-a-uniform-prior",
    "title": "Binomial Data",
    "section": "",
    "text": "Figure 1: Binomial likelihood with a Uniform prior\n\n\nWhen we use a uniform prior for a Bernoulli likelihood, we get a beta posterior.\nThe Bernoulli likelihood of \\vec Y \\mid \\theta is\n\n{\\color{green}f(\\vec Y \\mid \\theta) = {\\theta^{\\sum{y_i}}(1-\\theta)^{n - \\sum{y_i}}}} \\qquad \\text{Bernoulli Likelihood}\n\nOur prior for \\theta is just a Uniform distribution\n\n{\\color{red}f(\\theta) = I_{\\{0 \\le \\theta \\le 1\\}} }\\qquad \\text {Uniform prior}\n\nThus our posterior for \\theta is \n\\begin{aligned}\nf(\\theta \\mid y) & = \\frac{f(y \\mid \\theta) f(\\theta)}{\\int f(y \\mid \\theta)f(\\theta) \\, d\\theta} & \\text{Bayes law} \\\\\n& = \\frac{\\theta^{\\sum{y_i}} (1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}}}{\\int_0^1 \\theta^{\\sum{y_i}}(1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}} \\, d\\theta} & \\text{subst. Likelihood \\& Prior} \\\\\n& = \\frac{\\theta^{\\sum{y_i}} (1-\\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}}}{\\frac{\\Gamma(\\sum{y_i} + 1)\\Gamma(n - \\sum{y_i} + 1)}{\\Gamma(n + 2)} \\cancel{\\int_0^1 \\frac{\\Gamma(n + 2)}{\\Gamma(\\sum{y_i} + 1) \\Gamma(n - \\sum{y_i} + 1)} \\theta^{\\sum{y_i}} (1 - \\theta)^{n - \\sum{y_i}} \\, d\\theta}} & \\text{Beta PDF integrates to 1} \\\\\n& = \\frac{\\Gamma(n + 2)}{\\Gamma(\\sum{y_i}+ 1) \\Gamma(n - \\sum{y_i}+ 1)} \\theta^{\\sum{y_i}}(1 - \\theta)^{n - \\sum{y_i}} \\mathbb{I}_{\\{0 \\le \\theta \\le 1\\}} & \\text{simplifying} \\\\\n& = \\mathrm{Beta} \\left (\\sum{y_i} + 1, n - \\sum{y_i} + 1 \\right )\n\\end{aligned}\n\nWhere we used a trick of recognizing the denominator as a Beta distribution (?@eq-beta-pdf) we then manipulate it to take the exact form of Beta. We can then cancel it since the beta density integrates to 1, we can simplify this as From here we can see that the posterior follows a beta distribution\n\n\\theta | y \\sim Beta(\\sum{y_i} + 1, n - \\sum{y_i} + 1)\n\n\n\n\n\n\n\nTipHistorical Note on R.A. Fisher\n\n\n\n R.A. Fisher’s objection to the Bayesian approach is that “The theory of inverse probability is founded upon an error, and must be wholly rejected” (Fisher 1925) was specifically referring to this example of a”Binomial with a Uniform prior”. The gist of it is that the posterior depends on the parametrization of the prior.(Aldrich 2008). R.A. Jeffry who corresponded with Fisher went on to develop his eponymous priors which were invariant to reparametrization. Which we will consider in ?@sec-jeffreys-prior",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Binomial Data"
    ]
  },
  {
    "objectID": "C1-L07.html#conjugate-priors",
    "href": "C1-L07.html#conjugate-priors",
    "title": "Binomial Data",
    "section": "2 Conjugate Priors",
    "text": "2 Conjugate Priors\n\n\n\n\nConjugate Priors\n\nThe uniform distribution is Beta(1, 1)\nAny beta distribution is conjugate for the Bernoulli distribution. Any beta prior will give a beta posterior.\n\nf(\\theta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha - 1}(1-\\theta)^{\\beta -1}\\mathbb{I}_{\\{\\theta \\le \\theta \\le 1\\}}\n\n\nf(\\theta \\mid y) \\propto f(y \\mid \\theta)f(\\theta) = \\theta^{\\sum{y_i}}(1-\\theta)^{n - \\sum{y_i}}\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha - 1}(1 - \\theta)^{\\beta - 1}\\mathbb{I}_{\\{\\theta \\le \\theta \\le 1\\}}\n\n\nf(y \\mid\\theta)f(\\theta) \\propto \\theta^{\\alpha + \\sum{y_i}-1}(1-\\theta)^{\\beta + n - \\sum{y_i} - 1}\n\nThus we see that this is a beta distribution\n\n\\theta \\mid y \\sim \\mathrm{Beta}(\\alpha + \\sum{y_i}, \\beta + n - \\sum{y_i})\n\nWhen \\alpha and \\beta are one like in the uniform distribution, then we get the same result as earlier.\nThis whole process where we choose a particular form of prior that works with a likelihood is called using a conjugate family.\nA family of distributions is referred to as conjugate if when you use a member of that family as a prior, you get another member of that family as your posterior.\nThe beta distribution is conjugate for the Bernoulli distribution. It’s also conjugate for the binomial distribution. The only difference in the binomial likelihood is that there is a combinatorics term. Since that does not depend on \\theta, we get the same posterior.\nWe often use conjugate priors because they make life much simpler, sticking to conjugate families allows us to get closed-form solutions easily.\nIf the family is flexible enough, then you can find a member of that family that closely represents your beliefs.\n\nthe Uniform distribution can be written as the Beta(1,1) prior.\nAny Beta prior will give a Beta posterior.\nBeta is conjugate for Binomial and for Bernoulli",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Binomial Data"
    ]
  },
  {
    "objectID": "C1-L07.html#posterior-mean-and-effective-sample-size",
    "href": "C1-L07.html#posterior-mean-and-effective-sample-size",
    "title": "Binomial Data",
    "section": "3 Posterior mean and effective sample size",
    "text": "3 Posterior mean and effective sample size\n Returning to the beta posterior model it is clear how both the prior and the data contribute to the posterior.\nFor a prior Beta(\\alpha,\\beta) we can say that the effective sample size of the prior is\n\n\\alpha + \\beta \\qquad \\text {(ESS)}\n\\tag{1}\nRecall that the expected value or mean of a Beta distribution is \\frac{\\alpha}{\\alpha + \\beta}\nTherefore we can derive the posterior mean as\n\n\\begin{aligned}\n   posterior_{mean} &= \\frac{\\alpha + \\sum{y_i}}{\\alpha + \\sum{y_i}+\\beta + n - \\sum{y_i}}\n\\\\                  &= \\frac{\\alpha+\\sum{y_i}}{\\alpha + \\beta + n}\n\\\\                  &= \\frac{\\alpha + \\beta}{\\alpha + \\beta + n}\\frac{\\alpha}{\\alpha + \\beta} + \\frac{n}{\\alpha + \\beta + n}\\frac{\\sum{y_i}}{n}\n\\\\ &= (\\text{prior weight} \\times \\text{prior mean}) + (\\text{data weight} \\times \\text{data mean})\n\\end{aligned}\n\\tag{2}\ni.e. The posterior mean is a weighted average of the prior mean and the data mean.\nThis effective sample size gives you an idea of how much data you would need to make sure that your prior does not have much influence on your posterior.\nIf \\alpha + \\beta is small compared to n then the posterior will largely just be driven by the data. If \\alpha + \\beta is large relative to n then the posterior will be largely driven by the prior.\nWe can make a 95% credible interval using our posterior distribution for \\theta . We can find an interval that has 95 \\% probability of containing \\theta.\nUsing Bayesian Statistics we can do sequential analysis by doing a sequential update every time we get new data. We can get a new posterior, and we just use our previous Posterior as a Prior for doing another update using Bayes’ theorem.\n\nfor a Beta prior, its effective sample size is a + b\nif n &gt;&gt; \\alpha+\\beta the posterior will be predominantly determined by the prior\nif n &lt;&lt; \\alpha+\\beta the posterior will be predominantly determined by the data\nthe idea of an effective sample size of the prior is a useful concept to work with.\n(Wiesenfarth and Calderazzo 2020)\n\nEffective Sample Size (ESS)\nEffective Current Sample size (ECSS)\n\n\n\nESS algorithms\n\n\nwith (Morita, Thall, and Müller 2008) on the left and ECSS on the right\n\n\n\nExercise 1 (Discussion on Prior elicitation) Suppose we are interested in global temperatures, and that we have a summary measure that represents the average global temperature for each year. Now we could ask “What is the probability that next year will have a higher average global temperature than this year?” What would be your choice of prior and why? Be specific about the distribution and its parameters. You may use any other information that you want to bring into this problem.\n\nSolution. It is possible to get historical estimates using:\n\nmeteorological and satellites for the last 200 years. \nice cores for the last 800,000 years \ndeep sea sediment oxygen 18 isotope fractation for the last 5 million years.  or yearly temperature data from 1850 till today based on meteorological readings. We can also consider Greenland ice core data covering 800,000 years.\n\nOne simple way is to model the yearly temperature as a random walk\ni.e. Each year is a Bernoulli trial where success is the temperature getting warmer. We can then use the historical data since 1800 to estimate theta the probability that we get warmer.\nI suppose we can use a Binomial prior with parameters for alpha the count of years the temperature increased and N for the total number of years and p the probability the a given year is hotter than the previous.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Binomial Data"
    ]
  },
  {
    "objectID": "C1-L07.html#data-analysis-example-in-r",
    "href": "C1-L07.html#data-analysis-example-in-r",
    "title": "Binomial Data",
    "section": "4 Data Analysis Example in R",
    "text": "4 Data Analysis Example in R\nSuppose we’re giving two students a multiple-choice exam with 40 questions, where each question has four choices. We don’t know how much the students have studied for this exam, but we think that they’ll do better than just guessing randomly\n\nWhat are the parameters of interest?\n\nThe parameters of interests are \\theta_1 = true the probability that the first student will answer a question correctly, \\theta_2 = true the probability that the second student will answer a question correctly.\n\nWhat is our likelihood?\n\nThe likelihood is \\mathrm{Binomial}(40, \\theta) if we assume that each question is independent and that the probability a student gets each question right is the same for all questions for that student.\n\nWhat prior should we use?\n\nThe Conjugate Prior is a Beta Distribution. We can plot the density with dbeta\n\n\nCode\ntheta = seq(from = 0, to = 1, by = 0.1)\n# Uniform\nplot(theta, dbeta(theta, 1, 1), type = 'l')\n\n\n\n\n\n\n\n\n\nCode\n# Prior mean 2/3\nplot(theta, dbeta(theta, 4, 2), type = 'l')\n\n\n\n\n\n\n\n\n\nCode\n# Prior mean 2/3 but higher effect size (more concentrated at mean)\nplot(theta, dbeta(theta, 8, 4), type = 'l')\n\n\n\n\n\n\n\n\n\n\nWhat are the prior probabilities P(\\theta &gt; 0.25)? P(\\theta &gt; 0.5)? P(\\theta &gt; 0.8)?\n\n\n\nCode\n1 - pbeta(0.25, 8, 4)\n\n\n[1] 0.9988117\n\n\nCode\n#[1] 0.998117\n1 - pbeta(0.5, 8, 4)\n\n\n[1] 0.8867188\n\n\nCode\n#[1] 0.8867188\n1 - pbeta(0.8, 8, 4)\n\n\n[1] 0.1611392\n\n\nCode\n#[1] 0.16113392\n\n\n\nSuppose the first student gets 33 questions right. What is the posterior distribution for \\theta_1 ? P(\\theta &gt; 0.25) ? P(\\theta &gt; 0.5) ? P(\\theta &gt; 0.8) ? What is the 95% posterior credible interval for \\theta_1?\n\n\\text{Posterior} \\sim Beta(8 + 33, 4 + 40 - 33) = Beta(41, 11)\n\nWith a posterior mean of \\frac{41}{41+11} = \\frac{41}{52}\n\nWe can plot the posterior distribution with the prior\n\n\nCode\nplot(theta, dbeta(theta, 41, 11), type = 'l')\nlines(theta, dbeta(theta, 8 ,4), lty = 2) #Dashed line for prior\n\n\n\n\n\n\n\n\n\nPosterior probabilities\n\n\nCode\n1 - pbeta(0.25, 41, 11)\n\n\n[1] 1\n\n\nCode\n#[1] 1\n1 - pbeta(0.5, 41, 11)\n\n\n[1] 0.9999926\n\n\nCode\n#[1] 0.9999926\n1 - pbeta(0.8, 41, 11)\n\n\n[1] 0.4444044\n\n\nCode\n#[1] 0.4444044\n\n\nEqual-tailed 95% credible interval\n\n\nCode\nqbeta(0.025, 41, 11)\n\n\n[1] 0.6688426\n\n\nCode\n#[1] 0.6688426\nqbeta(0.975, 41, 11)\n\n\n[1] 0.8871094\n\n\nCode\n#[1] 0.8871094\n\n\n95% confidence that \\theta_1 is between 0.67 and 0.89\n\nSuppose the second student gets 24 questions right. What is the posterior distribution for \\theta_2? P(\\theta &gt; 0.25)? P(\\theta &gt; 0.5)? P(\\theta &gt; 0.8)? What is the 95% posterior credible interval for \\theta_2\n\n\n\\text{Posterior} \\sim Beta(8 + 24, 4 + 40 - 24) = Beta(32, 20)\n\nWith a posterior mean of \\frac{32}{32+20} = \\frac{32}{52}\nWe can plot the posterior distribution with the prior\n\n\nCode\nplot(theta, dbeta(theta, 32, 20), type = 'l')\nlines(theta, dbeta(theta, 8 ,4), lty = 2) #Dashed line for prior\n\n\n\n\n\n\n\n\n\nPosterior probabilities\n\n\nCode\n1 - pbeta(0.25, 32, 20)\n\n\n[1] 1\n\n\nCode\n#[1] 1\n1 - pbeta(0.5, 32, 20)\n\n\n[1] 0.9540427\n\n\nCode\n#[1] 0.9540427\n1 - pbeta(0.8, 32, 20)\n\n\n[1] 0.00124819\n\n\nCode\n#[1] 0.00124819\n\n\nEqual-tailed 95% credible interval\n\n\nCode\nqbeta(0.025, 32, 20)\n\n\n[1] 0.4808022\n\n\nCode\n#[1] 0.4808022\nqbeta(0.975, 32, 20)\n\n\n[1] 0.7415564\n\n\nCode\n#[1] 0.7415564\n\n\n95% confidence that \\theta_1 is between 0.48 and 0.74\n\nWhat is the posterior probability that \\theta_1 &gt; \\theta_2?\n\ni.e., that the first student has a better chance of getting a question right than the second student?\nEstimate by simulation: draw 1,000 samples from each and see how often we observe \\theta_1 &gt; \\theta_2\n\n\nCode\ntheta1 = rbeta(100000, 41, 11)\ntheta2 = rbeta(100000, 32, 20)\nmean(theta1 &gt; theta2)\n\n\n[1] 0.97608\n\n\nCode\n#[1] 0.975",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Binomial Data"
    ]
  },
  {
    "objectID": "C3-L04-Ex3.html",
    "href": "C3-L04-Ex3.html",
    "title": "Bayesian Mixture Models for Classification of Banknotes",
    "section": "",
    "text": "The data set banknote contains six measurements (length of bill, width of left edge, width of right edge, bottom margin width, top margin width, and length of diagonal, all in mm) made on 100 genuine and 100 counterfeit old-Swiss 1000-franc bank notes\n\n\n\n\n\n\nNoteInstructions\n\n\n\nTo load the dataset in R, use the command load(“banknoteclassification.Rdata”), but first make sure that your working directory is set to the directory containing the file. You should see four objects:\n\nbanknote.training contains the characteristics for 30 notes (15 genuine and 15 counterfeit) in the training set.\nbanknote.training.labels contains the labels (“genuine” or “counterfeit”) for the 30 notes in the training set\nbanknote.test contains the characteristics for 170 notes (85 genuine and 85 counterfeit) in the test set.\nbanknote.test.labels contains the labels (“genuine” or “counterfeit”) for the 170 notes in the test set. These are provided only for validation purposes.\n\nYou are asked to modify the MCMC algorithm in “Sample code for MCMC example 2” to create an algorithm for semi-supervised classification that is the Bayesian equivalent of that provided under “Sample EM algorithm for classification problems” and apply it to classify the observations contained in the test set. You are then asked to compare your results against those generated by the qda function in R.\nAs your priors, use distributions in the same families as in “Sample code for MCMC example 2”. In particular, use a uniform distribution for the weights, multivariate normal distributions for the means of the components, and inverse Wishart priors for the variance-covariance matrices of the components. The parameters of the priors should be set using the same empirical Bayes approach used in that example.\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nReviewers will check that the code has been properly adapted, and whether the classification results you provide are correct.\n\n\n\n\n\n\n\n\nNoteSample code for MCMC example 2\n\n\n\n\n\n\n\nCode\n#### Example of an MCMC algorithm for fitting a mixtures of K p-variate Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)\nlibrary(ellipse)\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nset.seed(63252)    #Keep seed the same so that we can reproduce results\nn  = 120\ncc.true = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc.true[i],], Sigma.true[cc.true[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]), type=\"n\")\ntext(x[,1], x[,2], seq(1,n), col=cc.true, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2)\n}\ntitle(main=\"Data + True Components\")\n\n\n\n\n\n\n\n\n\nCode\n## Initialize the parameters\nw          = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu         = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\ncc         = sample(1:KK, n, replace=TRUE, prob=w)\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\n# Priors\naa = rep(1, KK)\ndd = apply(x,2,mean)\nDD = 10*var(x)\nnu = p\nSS = var(x)/3\n\n# Number of iteration of the sampler\nrrr = 1000\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK, p))\nSigma.out = array(0, dim=c(rrr, KK, p, p))\nlogpost   = rep(0, rrr)\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + mvtnorm::dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc)))\n  \n  # Sample the means\n  DD.st = matrix(0, nrow=p, ncol=p)\n  for(k in 1:KK){\n    mk    = sum(cc==k)\n    xsumk = apply(x[cc==k,], 2, sum)\n    DD.st = solve(mk*solve(Sigma[k,,]) + solve(DD))\n    dd.st = DD.st%*%(solve(Sigma[k,,])%*%xsumk + solve(DD)%*%dd)\n    mu[k,] = as.vector(rmvnorm(1,dd.st,DD.st))\n  }\n  \n  # Sample the variances\n  xcensumk = array(0, dim=c(KK,p,p))\n  for(i in 1:n){\n    xcensumk[cc[i],,] = xcensumk[cc[i],,] + (x[i,] - mu[cc[i],])%*%t(x[i,] - mu[cc[i],])\n  }\n  for(k in 1:KK){\n    Sigma[k,,] = riwish(nu + sum(cc==k), SS + xcensumk[k,,])\n  }\n  \n  # Store samples\n  cc.out[s,]      = cc\n  w.out[s,]       = w\n  mu.out[s,,]     = mu\n  Sigma.out[s,,,] = Sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + mvtnorm::dmvnorm(x[i,], mu[cc[i],], Sigma[cc[i],,], log=TRUE)\n  }\n  logpost[s] = logpost[s] + ddirichlet(w, aa)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + mvtnorm::dmvnorm(mu[k,], dd, DD, log=TRUE)\n    logpost[s] = logpost[s] + log(diwish(Sigma[k,,], nu, SS))\n  }\n  \n  if(s/250==floor(s/250)){\n    print(paste(\"s = \", s))\n  }\n  \n}\n\n\n[1] \"s =  250\"\n[1] \"s =  500\"\n[1] \"s =  750\"\n[1] \"s =  1000\"\n\n\nCode\n## Plot the logposterior distribution for various samples\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\n\n\n\n\n\n\n\n\nCode\n## Plot the density estimate for the last iteration of the MCMC\npar(mfrow=c(1,1))\npar(mar=c(4,4,2,1)+0.1)\nplot(x[,1], x[,2], col=cc.true, main=paste(\"s =\",s,\"   logpost =\", round(logpost[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\n\n\n\n\n\n\n\n\n\nsample code for classification of the wine dataset using a mixture model with EM algorithm\n\n\nCode\n## Using mixture models for classification in the wine dataset\n## Compare linear and quadratic discriminant analysis and a \n##   (semi-supervised) location and scale mixture model with K normals\n## Comparing only against the EM algorithm\n\n# Semi-supervised, quadratic discriminant analysis\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(mvtnorm)\nwine.training = read.table(\"data/wine_training.txt\", sep=\",\", header=TRUE)\nwine.test = read.table(\"data/wine_test.txt\", sep=\",\", header=TRUE)\nn = dim(wine.training)[1]  # Size of the training set\nm = dim(wine.test)[1]      # Size of the test set\nx = rbind(as.matrix(wine.training[,-1]), as.matrix(wine.test[,-1]))   # Create dataset of observations, first n belong to the training set, and the rest belong to the test set\np       = dim(x)[2]              # Number of features\nKK      = 3\nepsilon = 0.00001\n\npar(mfrow=c(1,1))\npar(mar=c(2,2,2,2)+0.1)\ncolscale = c(\"black\",\"red\",\"blue\")\npairs(wine.training[,-1], col=colscale[wine.training[,1]], pch=wine.training[,1])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #Cluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\nsw     = FALSE\nKL     = -Inf\nKL.out = NULL\ns      = 0\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n+m,KK))\n  for(k in 1:KK){  #Compute the log of the weights\n    v[1:n,k] = ifelse(wine.training[,1]==k,0,-Inf)  # Training set\n    v[(n+1):(n+m),k] = log(w[k]) + mvtnorm::dmvnorm(x[(n+1):(n+m),], mu[k,], Sigma[k,,],log=TRUE)  # Test set\n  }\n  for(i in 1:(n+m)){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w = apply(v,2,mean)\n  mu = matrix(0, nrow=KK, ncol=p)\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0,dim=c(KK,p,p))\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:(n+m)){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -3146.58419305226\"\n[1] \"2 -2942.48222029706\"\n[1] \"3 -2873.76499310479\"\n[1] \"4 -2852.76768638231\"\n[1] \"5 -2796.247735428\"\n[1] \"6 -2791.29098585679\"\n[1] \"7 -2791.23059641487\"\n[1] \"8 -2791.14094416728\"\n[1] \"9 -2791.05612416221\"\n[1] \"10 -2790.99254414223\"\n[1] \"11 -2790.95228067601\"\n[1] \"12 -2790.92945838389\"\n\n\nCode\n## Predicted labels\napply(v, 1, which.max)[(n+1):(n+m)]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## True labels\nwine.test[,1]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## Comparison\napply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1]\n\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nCode\nsum(!(apply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# Using the qda and lda functions in R\n# qda\nmodqda = qda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredqda = predict(modqda,newdata=wine.test[,-1])\nsum(!(ccpredqda$class == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# lda\nmodlda = lda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredlda = predict(modlda,newdata=wine.test[,-1])\nsum(!(ccpredlda$class == wine.test[,1])) # No errors!!!\n\n\n[1] 0",
    "crumbs": [
      "3. Mixture Models",
      "Bayesian Mixture Models for Classification of Banknotes"
    ]
  },
  {
    "objectID": "C3-L04-Ex3.html#hhw---banknote-classification-the-mcmc-algorithms",
    "href": "C3-L04-Ex3.html#hhw---banknote-classification-the-mcmc-algorithms",
    "title": "Bayesian Mixture Models for Classification of Banknotes",
    "section": "",
    "text": "The data set banknote contains six measurements (length of bill, width of left edge, width of right edge, bottom margin width, top margin width, and length of diagonal, all in mm) made on 100 genuine and 100 counterfeit old-Swiss 1000-franc bank notes\n\n\n\n\n\n\nNoteInstructions\n\n\n\nTo load the dataset in R, use the command load(“banknoteclassification.Rdata”), but first make sure that your working directory is set to the directory containing the file. You should see four objects:\n\nbanknote.training contains the characteristics for 30 notes (15 genuine and 15 counterfeit) in the training set.\nbanknote.training.labels contains the labels (“genuine” or “counterfeit”) for the 30 notes in the training set\nbanknote.test contains the characteristics for 170 notes (85 genuine and 85 counterfeit) in the test set.\nbanknote.test.labels contains the labels (“genuine” or “counterfeit”) for the 170 notes in the test set. These are provided only for validation purposes.\n\nYou are asked to modify the MCMC algorithm in “Sample code for MCMC example 2” to create an algorithm for semi-supervised classification that is the Bayesian equivalent of that provided under “Sample EM algorithm for classification problems” and apply it to classify the observations contained in the test set. You are then asked to compare your results against those generated by the qda function in R.\nAs your priors, use distributions in the same families as in “Sample code for MCMC example 2”. In particular, use a uniform distribution for the weights, multivariate normal distributions for the means of the components, and inverse Wishart priors for the variance-covariance matrices of the components. The parameters of the priors should be set using the same empirical Bayes approach used in that example.\n\n\n\n\n\n\n\n\nNoteGrading overview\n\n\n\nReviewers will check that the code has been properly adapted, and whether the classification results you provide are correct.\n\n\n\n\n\n\n\n\nNoteSample code for MCMC example 2\n\n\n\n\n\n\n\nCode\n#### Example of an MCMC algorithm for fitting a mixtures of K p-variate Gaussian components\n#### The algorithm is tested using simulated data\n\n## Clear the environment and load required libraries\nrm(list=ls())\nlibrary(mvtnorm)\nlibrary(ellipse)\n\n\n\nAttaching package: 'ellipse'\n\n\nThe following object is masked from 'package:graphics':\n\n    pairs\n\n\nCode\nlibrary(MCMCpack)\n\n\nLoading required package: coda\n\n\nLoading required package: MASS\n\n\n##\n## Markov Chain Monte Carlo Package (MCMCpack)\n\n\n## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n\n\n##\n## Support provided by the U.S. National Science Foundation\n\n\n## (Grants SES-0350646 and SES-0350613)\n##\n\n\nCode\n## Generate data from a mixture with 3 components\nKK      = 3\np       = 2\nw.true = c(0.5,0.3,0.2)  # True weights associated with the components\nmu.true     = array(0, dim=c(KK,p))\nmu.true[1,] = c(0,0)   #True mean for the first component\nmu.true[2,] = c(5,5)   #True mean for the second component\nmu.true[3,] = c(-3,7)   #True mean for the third component\nSigma.true      = array(0, dim=c(KK,p,p))\nSigma.true[1,,] = matrix(c(1,0,0,1),p,p)   #True variance for the first component\nSigma.true[2,,] = matrix(c(2,0.9,0.9,1),p,p)   #True variance for the second component\nSigma.true[3,,] = matrix(c(1,-0.9,-0.9,4),p,p)   #True variance for the third component\nset.seed(63252)    #Keep seed the same so that we can reproduce results\nn  = 120\ncc.true = sample(1:3, n, replace=T, prob=w.true)\nx  = array(0, dim=c(n,p))\nfor(i in 1:n){\n  x[i,] = rmvnorm(1, mu.true[cc.true[i],], Sigma.true[cc.true[i],,])\n}\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]), type=\"n\")\ntext(x[,1], x[,2], seq(1,n), col=cc.true, cex=0.6)\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.50), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.82), col=\"grey\", lty=2)\n  lines(ellipse(x=Sigma.true[k,,], centre=mu.true[k,], level=0.95), col=\"grey\", lty=2)\n}\ntitle(main=\"Data + True Components\")\n\n\n\n\n\n\n\n\n\nCode\n## Initialize the parameters\nw          = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu         = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\ncc         = sample(1:KK, n, replace=TRUE, prob=w)\n\npar(mfrow=c(1,1))\nplot(x[,1], x[,2], col=cc.true, xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\ntitle(main=\"Initial estimate + Observations\")\n\n\n\n\n\n\n\n\n\nCode\n# Priors\naa = rep(1, KK)\ndd = apply(x,2,mean)\nDD = 10*var(x)\nnu = p\nSS = var(x)/3\n\n# Number of iteration of the sampler\nrrr = 1000\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK, p))\nSigma.out = array(0, dim=c(rrr, KK, p, p))\nlogpost   = rep(0, rrr)\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in 1:n){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + mvtnorm::dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc)))\n  \n  # Sample the means\n  DD.st = matrix(0, nrow=p, ncol=p)\n  for(k in 1:KK){\n    mk    = sum(cc==k)\n    xsumk = apply(x[cc==k,], 2, sum)\n    DD.st = solve(mk*solve(Sigma[k,,]) + solve(DD))\n    dd.st = DD.st%*%(solve(Sigma[k,,])%*%xsumk + solve(DD)%*%dd)\n    mu[k,] = as.vector(rmvnorm(1,dd.st,DD.st))\n  }\n  \n  # Sample the variances\n  xcensumk = array(0, dim=c(KK,p,p))\n  for(i in 1:n){\n    xcensumk[cc[i],,] = xcensumk[cc[i],,] + (x[i,] - mu[cc[i],])%*%t(x[i,] - mu[cc[i],])\n  }\n  for(k in 1:KK){\n    Sigma[k,,] = riwish(nu + sum(cc==k), SS + xcensumk[k,,])\n  }\n  \n  # Store samples\n  cc.out[s,]      = cc\n  w.out[s,]       = w\n  mu.out[s,,]     = mu\n  Sigma.out[s,,,] = Sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + mvtnorm::dmvnorm(x[i,], mu[cc[i],], Sigma[cc[i],,], log=TRUE)\n  }\n  logpost[s] = logpost[s] + ddirichlet(w, aa)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + mvtnorm::dmvnorm(mu[k,], dd, DD, log=TRUE)\n    logpost[s] = logpost[s] + log(diwish(Sigma[k,,], nu, SS))\n  }\n  \n  if(s/250==floor(s/250)){\n    print(paste(\"s = \", s))\n  }\n  \n}\n\n\n[1] \"s =  250\"\n[1] \"s =  500\"\n[1] \"s =  750\"\n[1] \"s =  1000\"\n\n\nCode\n## Plot the logposterior distribution for various samples\npar(mfrow=c(1,1))\npar(mar=c(4,4,1,1)+0.1)\nplot(logpost, type=\"l\", xlab=\"Iterations\", ylab=\"Log posterior\")\n\n\n\n\n\n\n\n\n\nCode\n## Plot the density estimate for the last iteration of the MCMC\npar(mfrow=c(1,1))\npar(mar=c(4,4,2,1)+0.1)\nplot(x[,1], x[,2], col=cc.true, main=paste(\"s =\",s,\"   logpost =\", round(logpost[s],4)), xlab=expression(x[1]), ylab=expression(x[2]))\nfor(k in 1:KK){\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.50), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.82), col=\"grey\", lty=2, lwd=2)\n  lines(ellipse(x=Sigma[k,,], centre=mu[k,], level=0.95), col=\"grey\", lty=2, lwd=2)\n}\n\n\n\n\n\n\n\n\n\nsample code for classification of the wine dataset using a mixture model with EM algorithm\n\n\nCode\n## Using mixture models for classification in the wine dataset\n## Compare linear and quadratic discriminant analysis and a \n##   (semi-supervised) location and scale mixture model with K normals\n## Comparing only against the EM algorithm\n\n# Semi-supervised, quadratic discriminant analysis\n### Loading data and setting up global variables\nlibrary(MASS)\nlibrary(mvtnorm)\nwine.training = read.table(\"data/wine_training.txt\", sep=\",\", header=TRUE)\nwine.test = read.table(\"data/wine_test.txt\", sep=\",\", header=TRUE)\nn = dim(wine.training)[1]  # Size of the training set\nm = dim(wine.test)[1]      # Size of the test set\nx = rbind(as.matrix(wine.training[,-1]), as.matrix(wine.test[,-1]))   # Create dataset of observations, first n belong to the training set, and the rest belong to the test set\np       = dim(x)[2]              # Number of features\nKK      = 3\nepsilon = 0.00001\n\npar(mfrow=c(1,1))\npar(mar=c(2,2,2,2)+0.1)\ncolscale = c(\"black\",\"red\",\"blue\")\npairs(wine.training[,-1], col=colscale[wine.training[,1]], pch=wine.training[,1])\n\n\n\n\n\n\n\n\n\nCode\n# Initialize the parameters of the algorithm\nset.seed(63252)\nw   = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu  = rmvnorm(KK, apply(x,2,mean), var(x))   #Cluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\nSigma[3,,] = var(x)/KK\n\nsw     = FALSE\nKL     = -Inf\nKL.out = NULL\ns      = 0\n\nwhile(!sw){\n  ## E step\n  v = array(0, dim=c(n+m,KK))\n  for(k in 1:KK){  #Compute the log of the weights\n    v[1:n,k] = ifelse(wine.training[,1]==k,0,-Inf)  # Training set\n    v[(n+1):(n+m),k] = log(w[k]) + mvtnorm::dmvnorm(x[(n+1):(n+m),], mu[k,], Sigma[k,,],log=TRUE)  # Test set\n  }\n  for(i in 1:(n+m)){\n    v[i,] = exp(v[i,] - max(v[i,]))/sum(exp(v[i,] - max(v[i,])))  #Go from logs to actual weights in a numerically stable manner\n  }\n  \n  ## M step\n  w = apply(v,2,mean)\n  mu = matrix(0, nrow=KK, ncol=p)\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      mu[k,]    = mu[k,] + v[i,k]*x[i,]\n    }\n    mu[k,] = mu[k,]/sum(v[,k])\n  }\n  Sigma = array(0,dim=c(KK,p,p))\n  for(k in 1:KK){\n    for(i in 1:(n+m)){\n      Sigma[k,,] = Sigma[k,,] + v[i,k]*(x[i,] - mu[k,])%*%t(x[i,] - mu[k,])\n    }\n    Sigma[k,,] = Sigma[k,,]/sum(v[,k])\n  }\n  \n  ##Check convergence\n  KLn = 0\n  for(i in 1:(n+m)){\n    for(k in 1:KK){\n      KLn = KLn + v[i,k]*(log(w[k]) + mvtnorm::dmvnorm(x[i,],mu[k,],Sigma[k,,],log=TRUE))\n    }\n  }\n  if(abs(KLn-KL)/abs(KLn)&lt;epsilon){\n    sw=TRUE\n  }\n  KL = KLn\n  KL.out = c(KL.out, KL)\n  s = s + 1\n  print(paste(s, KLn))\n}\n\n\n[1] \"1 -3146.58419305226\"\n[1] \"2 -2942.48222029706\"\n[1] \"3 -2873.76499310479\"\n[1] \"4 -2852.76768638231\"\n[1] \"5 -2796.247735428\"\n[1] \"6 -2791.29098585679\"\n[1] \"7 -2791.23059641487\"\n[1] \"8 -2791.14094416728\"\n[1] \"9 -2791.05612416221\"\n[1] \"10 -2790.99254414223\"\n[1] \"11 -2790.95228067601\"\n[1] \"12 -2790.92945838389\"\n\n\nCode\n## Predicted labels\napply(v, 1, which.max)[(n+1):(n+m)]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## True labels\nwine.test[,1]\n\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 3 3 3 3 3 3\n\n\nCode\n## Comparison\napply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1]\n\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nCode\nsum(!(apply(v, 1, which.max)[(n+1):(n+m)] == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# Using the qda and lda functions in R\n# qda\nmodqda = qda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredqda = predict(modqda,newdata=wine.test[,-1])\nsum(!(ccpredqda$class == wine.test[,1])) # One error\n\n\n[1] 1\n\n\nCode\n# lda\nmodlda = lda(grouping=wine.training[,1], x=wine.training[,-1], method=\"mle\")\nccpredlda = predict(modlda,newdata=wine.test[,-1])\nsum(!(ccpredlda$class == wine.test[,1])) # No errors!!!\n\n\n[1] 0",
    "crumbs": [
      "3. Mixture Models",
      "Bayesian Mixture Models for Classification of Banknotes"
    ]
  },
  {
    "objectID": "C3-L04-Ex3.html#solution",
    "href": "C3-L04-Ex3.html#solution",
    "title": "Bayesian Mixture Models for Classification of Banknotes",
    "section": "2 Solution",
    "text": "2 Solution\n\n\nCode\nlibrary(MASS)\nlibrary(mvtnorm)\nlibrary(MCMCpack)\n\nload(\"data/banknoteclassification.Rdata\")\n\n\nProvide an MCMC algorithm to fit a semisupervised Bayesian quadratic discriminant model to the banknote data.\n\n\nCode\n# Combine data for semi-supervised setup\nn = nrow(banknote.training)\nm = nrow(banknote.test)\nx = rbind(banknote.training, banknote.test)\np = ncol(banknote.training)\nK = 2  # Two classes: genuine/counterfeit\n\n# Convert labels to numeric (1/2)\nlabel_map = setNames(1:2, c(\"genuine\", \"counterfeit\"))\ntrain_labels = label_map[banknote.training.labels]\ntest_labels  = label_map[banknote.test.labels]\n\n# Priors from empirical Bayes\naa = rep(1, K)\ndd = colMeans(x)\nDD = 10 * var(x)\nnu = p\nSS = var(x) / 3\n\n# Initial values\nw    = rep(1, K) / K\nmu   = rmvnorm(K, dd, var(x))\nSigma = array(0, dim=c(K, p, p))\nfor (k in 1:K) Sigma[k,,] = var(x) / K\ncc = c(train_labels, sample(1:K, m, replace=TRUE))\n\n# MCMC settings\niters = 1000\nburn  = 500\n\ncc.out = array(0, dim=c(iters, n+m))\nfor (s in 1:iters) {\n  # 1. Sample class indicators (cc)\n  # - Fixed for training set, update for test set\n  for (i in (n+1):(n+m)) {\n    logp = sapply(1:K, function(k)\n      log(w[k]) + dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE))\n    p_i = exp(logp - max(logp)); p_i = p_i / sum(p_i)\n    cc[i] = sample(1:K, 1, prob=p_i)\n  }\n  # 2. Update weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=K)))\n  # 3. Update means\n  for (k in 1:K) {\n    idx = which(cc == k)\n    mk = length(idx)\n    DD_st = solve(mk * solve(Sigma[k,,]) + solve(DD))\n    dd_st = DD_st %*% (solve(Sigma[k,,]) %*% colSums(x[idx,,drop=FALSE]) + solve(DD) %*% dd)\n    mu[k,] = as.vector(rmvnorm(1, dd_st, DD_st))\n  }\n  # 4. Update covariances\n  for (k in 1:K) {\n    idx = which(cc == k)\n    mk = length(idx)\n    xcensumk = matrix(0, p, p)\n    for (i in idx) {\n      d = x[i,] - mu[k,]\n      xcensumk = xcensumk + d %*% t(d)\n    }\n    Sigma[k,,] = riwish(nu + mk, SS + xcensumk)\n  }\n  cc.out[s,] = cc\n}\n\n\nWhat is the classification error for the test set?\n\n[] Is the classification error for the “genuine” class generated by the algorithm correct? should be 0\n[] Is the classification error for the “counterfeit” class generated by the algorithm correct? should be 0\n\n\n\nCode\n# Posterior prediction: for each test sample, majority vote of assignments\ncc.test.posterior = cc.out[burn:iters, (n+1):(n+m), drop=FALSE]\ncc.test.pred = apply(cc.test.posterior, 2, function(z) as.integer(names(which.max(table(z)))))\n\nclassification_error = mean(cc.test.pred != test_labels)\ncat(\"MCMC Test Classification Error:\", classification_error, \"\\n\")\n\n\nMCMC Test Classification Error: 0 \n\n\n\n[] Is the R function qda (which implements classical quadratic discriminant analysis) is used to classify the observations in the test set, what is the classification error?\n[] Is the classification error for the “genuine” class generated by the algorithm correct? should be 0 out of 85\n[] Is the classification error for the “counterfeit” class generated by the algorithm correct? should be 3 out of 85 i.e. 3.52%\n\n\n\nCode\nmod_qda = qda(x=banknote.training, grouping=banknote.training.labels, method=\"mle\")\nqda_pred = predict(mod_qda, banknote.test)$class\n\nqda_error = mean(qda_pred != banknote.test.labels)\ncat(\"QDA Test Classification Error:\", qda_error, \"\\n\")\n\n\nQDA Test Classification Error: 0.01764706 \n\n\n\n\n\n\n\n\nNoteSolution code\n\n\n\n\n\n\n\nCode\n#### Semisupervised classification for the banknote dataset\nrm(list=ls())\nlibrary(mvtnorm)\nlibrary(MCMCpack)\n\n## Load data\nload(\"data/banknoteclassification.Rdata\")\n#load(\"banknoteclassification.Rdata\")\nx = rbind(banknote.training,banknote.test)\n\n## Generate data from a mixture with 3 components\nKK      = length(unique(banknote.training.labels))\np       = dim(banknote.training)[2]\nn       = dim(banknote.training)[1]\nm       = dim(unique(banknote.test))[1]\n\n## Initialize the parameters\nw          = rep(1,KK)/KK  #Assign equal weight to each component to start with\nmu         = rmvnorm(KK, apply(x,2,mean), var(x))   #RandomCluster centers randomly spread over the support of the data\nSigma      = array(0, dim=c(KK,p,p))  #Initial variances are assumed to be the same\nSigma[1,,] = var(x)/KK  \nSigma[2,,] = var(x)/KK\ncc         = c(as.numeric(banknote.training.labels), sample(1:KK, m, replace=TRUE, prob=w))\n\n# Priors\naa = rep(1, KK)\ndd = apply(x,2,mean)\nDD = 10*var(x)\nnu = p+1\nSS = var(x)/3\n\n# Number of iteration of the sampler\nrrr  = 11000\nburn = 1000\n\n# Storing the samples\ncc.out    = array(0, dim=c(rrr, n+m))\nw.out     = array(0, dim=c(rrr, KK))\nmu.out    = array(0, dim=c(rrr, KK, p))\nSigma.out = array(0, dim=c(rrr, KK, p, p))\nlogpost   = rep(0, rrr)\n\nfor(s in 1:rrr){\n  # Sample the indicators\n  for(i in (n+1):(n+m)){\n    v = rep(0,KK)\n    for(k in 1:KK){\n      v[k] = log(w[k]) + dmvnorm(x[i,], mu[k,], Sigma[k,,], log=TRUE)  #Compute the log of the weights\n    }\n    v = exp(v - max(v))/sum(exp(v - max(v)))\n    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)\n  }\n  \n  # Sample the weights\n  w = as.vector(rdirichlet(1, aa + tabulate(cc)))\n  \n  # Sample the means\n  DD.st = matrix(0, nrow=p, ncol=p)\n  for(k in 1:KK){\n    mk    = sum(cc==k)\n    xsumk = apply(x[cc==k,], 2, sum)\n    DD.st = solve(mk*solve(Sigma[k,,]) + solve(DD))\n    dd.st = DD.st%*%(solve(Sigma[k,,])%*%xsumk + solve(DD)%*%dd)\n    mu[k,] = as.vector(rmvnorm(1,dd.st,DD.st))\n  }\n  \n  # Sample the variances\n  xcensumk = array(0, dim=c(KK,p,p))\n  for(i in 1:(n+m)){\n    xcensumk[cc[i],,] = xcensumk[cc[i],,] + (x[i,] - mu[cc[i],])%*%t(x[i,] - mu[cc[i],])\n  }\n  for(k in 1:KK){\n    Sigma[k,,] = riwish(nu + sum(cc==k), SS + xcensumk[k,,])\n  }\n  \n  # Store samples\n  cc.out[s,]      = cc\n  w.out[s,]       = w\n  mu.out[s,,]     = mu\n  Sigma.out[s,,,] = Sigma\n  for(i in 1:n){\n    logpost[s] = logpost[s] + log(w[cc[i]]) + dmvnorm(x[i,], mu[cc[i],], Sigma[cc[i],,], log=TRUE)\n  }\n  logpost[s] = logpost[s] + ddirichlet(w, aa)\n  for(k in 1:KK){\n    logpost[s] = logpost[s] + dmvnorm(mu[k,], dd, DD)\n    logpost[s] = logpost[s] + diwish(Sigma[k,,], nu, SS)\n  }\n  \n  if(s/250==floor(s/250)){\n    print(paste(\"s = \", s))\n  }\n}\n\n\n[1] \"s =  250\"\n[1] \"s =  500\"\n[1] \"s =  750\"\n[1] \"s =  1000\"\n[1] \"s =  1250\"\n[1] \"s =  1500\"\n[1] \"s =  1750\"\n[1] \"s =  2000\"\n[1] \"s =  2250\"\n[1] \"s =  2500\"\n[1] \"s =  2750\"\n[1] \"s =  3000\"\n[1] \"s =  3250\"\n[1] \"s =  3500\"\n[1] \"s =  3750\"\n[1] \"s =  4000\"\n[1] \"s =  4250\"\n[1] \"s =  4500\"\n[1] \"s =  4750\"\n[1] \"s =  5000\"\n[1] \"s =  5250\"\n[1] \"s =  5500\"\n[1] \"s =  5750\"\n[1] \"s =  6000\"\n[1] \"s =  6250\"\n[1] \"s =  6500\"\n[1] \"s =  6750\"\n[1] \"s =  7000\"\n[1] \"s =  7250\"\n[1] \"s =  7500\"\n[1] \"s =  7750\"\n[1] \"s =  8000\"\n[1] \"s =  8250\"\n[1] \"s =  8500\"\n[1] \"s =  8750\"\n[1] \"s =  9000\"\n[1] \"s =  9250\"\n[1] \"s =  9500\"\n[1] \"s =  9750\"\n[1] \"s =  10000\"\n[1] \"s =  10250\"\n[1] \"s =  10500\"\n[1] \"s =  10750\"\n[1] \"s =  11000\"\n\n\n\n\nCode\nprobgenuine = rep(NA, m)\nfor(i in 1:m){\n  probgenuine[i] = sum(cc.out[-seq(1,burn),n+i]==2)/(rrr-burn)\n}\n\n\n\nprobcounterfeit = rep(NA, m)\nfor(i in 1:m){\n   probcounterfeit[i] = sum(cc.out[-seq(1,burn),n+i]==1)/(rrr-burn)\n} \n\n# Confusion matrix using threshold 0.5\npredicted_class &lt;- ifelse(probcounterfeit &gt; 0.5, 1, 2)  # 1 = counterfeit, 2 = genuine\n\n# Compare with true labels (already converted to numeric in your setup)\ntable(True = banknote.test.labels, Pred = predicted_class)\n\n\n             Pred\nTrue           1  2\n  counterfeit 85  0\n  genuine      0 85\n\n\nclassification_error_genuine = 0 classification_error_counterfit = 0\nfor (i in 1:m){ if (banknote.test.labels[i] == “genuine” && probgenuine[i] &lt; 0.5) { classification_error_genuine = classification_error_genuine + 1 } if (banknote.test.labels[i] == “counterfeit” && probcounterfeit[i] &lt; 0.5) { classification_error_counterfit = classification_error_counterfit + 1 } }\nclassification_error = (classification_error_genuine + classification_error_counterfit) / m\nprint(paste(“Genuine error count:”, classification_error_genuine)) print(paste(“Genuine error rate:”, classification_error_genuine/m)) print(c(“Counterfeit error count:”, classification_error_counterfit)) print(paste(“Counterfeit error rate:”, classification_error_counterfit/n)) print(paste(“Overall classification error”,classification_error))\n\n::: {.cell}\n\n```{.r .cell-code}\nbanknote.qda = qda(x=banknote.training, grouping=banknote.training.labels, method=\"mle\")\nqda_preds = predict(banknote.qda, banknote.test)$class\n\ntable(True = banknote.test.labels, Pred = qda_preds)\n\n             Pred\nTrue          counterfeit genuine\n  counterfeit          82       3\n  genuine               0      85\n\n\n\n\nqda_classification_error_genuine = 0 qda_classification_error_counterfit = 0\nfor (i in 1:m){ if (banknote.test.labels[i] == “genuine” && qda_preds[i] == “counterfeit”) { qda_classification_error_genuine = qda_classification_error_genuine + 1 } if (banknote.test.labels[i] == “counterfeit” && qda_preds[i] == “genuine”) { qda_classification_error_counterfit = qda_classification_error_counterfit + 1 } }\nprint(paste(“QDA genuine error count:”, qda_classification_error_genuine)) print(paste(“QDA genuine error rate:”,qda_classification_error_genuine/m)) print(paste(“QDA counterfeit error count:”, qda_classification_error_counterfit)) print(paste(“QDA counterfeit error rate:”, qda_classification_error_counterfit/m))\n\n\nCode\nprobgenuine = rep(NA, m)\n\nfor(i in 1:m){\n  probgenuine[i] = sum(cc.out[-seq(1,burn),n+i]==2)/(rrr-burn)\n}\n\npredicted_class &lt;- ifelse(probgenuine &gt; 0.5, 2, 1)  # 1 = counterfeit, 2 = genuine\nlabmap &lt;- c(\"counterfeit\", \"genuine\")\npredicted_labels &lt;- labmap[predicted_class]\n\ntab_mcmc &lt;- table(True = banknote.test.labels, Pred = predicted_labels)\n\n# Per-class error rates\ngenuine_error     &lt;- 1 - tab_mcmc[\"genuine\", \"genuine\"] / sum(tab_mcmc[\"genuine\", ])\ncounterfeit_error &lt;- 1 - tab_mcmc[\"counterfeit\", \"counterfeit\"] / sum(tab_mcmc[\"counterfeit\", ])\n\nprint(paste(\"genuine: \", round(100 * genuine_error,2)))\n\n\n[1] \"genuine:  0\"\n\n\nCode\nprint(paste(\"counterfeit: \", round(100 * counterfeit_error, 2)))\n\n\n[1] \"counterfeit:  0\"\n\n\nbanknote.qda = qda(x=banknote.training, grouping=banknote.training.labels, method=“mle”) qda_preds = predict(banknote.qda, banknote.test)$class tab_qda &lt;- table(True = banknote.test.labels, Pred = qda_preds) # Per-class error rates genuine_error &lt;- 1 - tab_qda[“genuine”, “genuine”] / sum(tab_qda[“genuine”, ]) counterfeit_error &lt;- 1 - tab_qda[“counterfeit”, “counterfeit”] / sum(tab_qda[“counterfeit”, ]) print(paste(“genuine:”, round(100 * genuine_error,2))) print(paste(“counterfeit:”, round(100 * counterfeit_error, 2)))",
    "crumbs": [
      "3. Mixture Models",
      "Bayesian Mixture Models for Classification of Banknotes"
    ]
  },
  {
    "objectID": "C2-L09-Ex1.html",
    "href": "C2-L09-Ex1.html",
    "title": "",
    "section": "",
    "text": "2. Techniques and ModelsHomework on Logistic Regression CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "2. Techniques and Models",
      "Homework on Logistic Regression"
    ]
  },
  {
    "objectID": "C2-L09-Ex1.html#homework-on-logistic-regression",
    "href": "C2-L09-Ex1.html#homework-on-logistic-regression",
    "title": "",
    "section": "1 Homework on Logistic Regression",
    "text": "1 Homework on Logistic Regression\n\nExercise 1  What is the advantage of using a link function such as the logit transform for logistic regression?Logistic Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nIt ensures that the success probability (\\mathbb{E}[y] if y is Bernoulli) is between 0 and 1 without requiring any constraints on the x variables or the \\beta coefficients.\nIt ensures that \\beta_0+\\beta_1x_1+…+\\beta_kx_k is between 0 and 1 using log transformations of the coefficients.\nIt makes the \\beta coefficients interpretable directly as probabilities.\nIt ensures that the \\beta coefficients lie between 0 and 1 for all values of predictors x.\n\nThis is a categorical predictor.\n\n\n\n\nExercise 2  Logistic regression works with binomial likelihoods in addition to Bernoulli likelihoods. If the response y_i is a number of successes in n_i independent trials each with \\phi_i success probability, we can still model \\phi_i with a linear model using the logit transformation.Logistic Regression\nAs an example, consider the OME data in the MASS package in R. The data consist of experimental results from tests of auditory perception in children. Under varying conditions and for multiple trials under each condition, children either correctly or incorrectly identified the source of changing signals.\nAlthough the independence of the trails and results are questionable, we’ll try fitting a logistic regression to these data. First, we’ll explore the relationships briefly with the following code:\n\n\n\n\nListing 1: EDA of the OME dataset\n\n\n\nCode\nlibrary(\"MASS\")\ndata(\"OME\")\n?OME # background on the data\nhead(OME)\n\n\n\n\n\n  ID Age OME Loud      Noise Correct Trials\n1  1  30 low   35   coherent       1      4\n2  1  30 low   35 incoherent       4      5\n3  1  30 low   40   coherent       0      3\n4  1  30 low   40 incoherent       1      1\n5  1  30 low   45   coherent       2      4\n6  1  30 low   45 incoherent       2      2\n\n\n\n\nListing 2: EDA of the OME dataset\n\n\n\nCode\nany(is.na(OME)) # check for missing values\n\n\n\n\n\n[1] FALSE\n\n\n\n\nListing 3: EDA of the OME dataset\n\n\n\nCode\ndat = subset(OME, OME != \"N/A\") # manually remove OME missing values identified with \"N/A\"\ndat$OME = factor(dat$OME)\nstr(dat)\n\n\n\n\n\n'data.frame':   712 obs. of  7 variables:\n $ ID     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Age    : int  30 30 30 30 30 30 30 30 30 30 ...\n $ OME    : Factor w/ 2 levels \"high\",\"low\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Loud   : int  35 35 40 40 45 45 50 50 55 55 ...\n $ Noise  : Factor w/ 2 levels \"coherent\",\"incoherent\": 1 2 1 2 1 2 1 2 1 2 ...\n $ Correct: int  1 4 0 1 2 2 3 4 3 2 ...\n $ Trials : int  4 5 3 1 4 2 3 4 3 2 ...\n\n\n\n\nListing 4: EDA of the OME dataset\n\n\n\nCode\nplot(dat$Age, dat$Correct / dat$Trials )\nplot(dat$OME, dat$Correct / dat$Trials )\nplot(dat$Loud, dat$Correct / dat$Trials )\nplot(dat$Noise, dat$Correct / dat$Trials )\n\n\n\n\n\n\n\n\n\nage vs success\n\n\n\n\n\n\nOME vs success\n\n\n\n\n\n\nLoud vs success\n\n\n\n\n\n\nNoise vs success\n\n\n\n\n\nEDA of the OME dataset\n\nWe are interested how these variables relate to the probability of successfully identifying the source of changes in sound. Of these four variables, which appears to have the weakest association with the probability of success?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nAge in months\nOME: degree of otitis media with effusion (low or high)\nLoudness of stimulus in decibels\nNoise: stimulus type (coherent or incoherent)\n\nWith a Bernoulli likelihood, E(y) is the probability of success, which should be a proper probability. If the likelihood is Binomial, then the expected value of y is the the number of trials times the success probability. Here we would still use a logit likelihood on the success probability.\n\n\n\n\nExercise 3  Next, we’ll fit a reference logistic regression model with non-informative prior in R. We can do this with the glm function, providing the model formula as with the usual lm, except now the response is the observed proportion of correct responses. We must also indicate how many trials were run for each experiment using the weights argument.Logistic Regression\n\n\n\n\nListing 5: OME GLM\n\n\n\nCode\nmod_glm = glm(Correct/Trials ~ Age + OME + Loud + Noise, data=dat, weights=Trials, family=\"binomial\")\nsummary(mod_glm)\n\n\n\n\n\n\nCall:\nglm(formula = Correct/Trials ~ Age + OME + Loud + Noise, family = \"binomial\", \n    data = dat, weights = Trials)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -7.294441   0.434928 -16.772  &lt; 2e-16 ***\nAge              0.018896   0.003767   5.016 5.28e-07 ***\nOMElow          -0.237150   0.123257  -1.924   0.0544 .  \nLoud             0.171682   0.008880  19.333  &lt; 2e-16 ***\nNoiseincoherent  1.576304   0.115236  13.679  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1431.12  on 711  degrees of freedom\nResidual deviance:  732.38  on 707  degrees of freedom\nAIC: 1262.6\n\nNumber of Fisher Scoring iterations: 5\n\n\nTo get an idea of how the model fits, we can create residual (using a special type of residual for non-normal likelihoods) and in-sample prediction plots.\n\nCode\nplot(residuals(mod_glm, type=\"deviance\"))\nplot(fitted(mod_glm), dat$Correct/dat$Trials)\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: residuals plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: in-sample prediction plots\n\n\n\n\n\nIt appears from the second plot that the model is not very precise (some model predictions were far from the observed proportion of correct responses). Nevertheless, it can be informative about the relationships among the variables.\nReport the posterior mode estimate of the coefficient for low OME.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n-0.24\n\n\n\n\nExercise 4  Next, we will fit a similar model in JAGS. To make the results comparable to those of the reference model, we will use the same configuration of covariates. We can extract this information from the reference model using model.matrix.Logistic Regression\n\n\nCode\nX = model.matrix(mod_glm)[,-1] # -1 removes the column of 1s for the intercept\nhead(X)\n\n\n  Age OMElow Loud Noiseincoherent\n1  30      1   35               0\n2  30      1   35               1\n3  30      1   40               0\n4  30      1   40               1\n5  30      1   45               0\n6  30      1   45               1\n\n\nThe data include categorical covariates which R codes as dummy variables (as with ANOVA). Hence we have an indicator variable for whether OME is at its low level and another indicating whether the Noise is incoherent. The intercept is then associated with this baseline group. Ignoring the continuous variables Age and Loud, what are the characteristics of this baseline group?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nChildren with low OME exposed to incoherent sound.\nChildren with high OME exposed to incoherent sound.\nChildren with low OME exposed to coherent sound.\nChildren with high OME exposed to coherent sound.\n\n\n\n\n\nExercise 5  Now complete the following code (as well as the code from previous questions) to fit the JAGS model with the fairly non-informative priors given. Use three chains with at least 5,000 iterations in each.Raftery and Lewis diagnostic\n\n\n\n\nListing 6: Jags logistic regression model\n\n\n\nCode\nmod1_string = \" model {\n    for (i in 1:length(y)) {\n        y[i] ~ dbin(phi[i], n[i])\n        logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n    }\n    \n    b0 ~ dnorm(0.0, 1.0/5.0^2)\n    for (j in 1:4) {\n        b[j] ~ dnorm(0.0, 1.0/4.0^2)\n    }\n} \"\n\ndata_jags = as.list(as.data.frame(X))\n1data_jags$y = dat$Correct\ndata_jags$n = dat$Trials\n2str(data_jags)\n\nparams = c(\"b0\", \"b\")\n\nmod1 = jags.model(textConnection(mod1_string), data=data_jags, n.chains=3)\n3update(mod1, 1e3)\n\n4mod1_sim = coda.samples(model=mod1, variable.names=params,  n.iter=5e3)\nmod1_csim = as.mcmc(do.call(rbind, mod1_sim))\n\n\n\n\n\n\n1\n\nthis will not work if there are missing values in dat (because they would be ignored by model.matrix). Always make sure that the data are accurately pre-processed for JAGS.\n\n2\n\nensure all variables have the same number of observations (712).\n\n3\n\nburn in for 1k iterations\n\n4\n\nsim at least 5k iterations\n\n\n\n\nList of 6\n $ Age            : num [1:712] 30 30 30 30 30 30 30 30 30 30 ...\n $ OMElow         : num [1:712] 1 1 1 1 1 1 1 1 1 1 ...\n $ Loud           : num [1:712] 35 35 40 40 45 45 50 50 55 55 ...\n $ Noiseincoherent: num [1:712] 0 1 0 1 0 1 0 1 0 1 ...\n $ y              : int [1:712] 1 4 0 1 2 2 3 4 3 2 ...\n $ n              : int [1:712] 4 5 3 1 4 2 3 4 3 2 ...\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 712\n   Unobserved stochastic nodes: 5\n   Total graph size: 4377\n\nInitializing model\n\n\n\nCode\n## convergence diagnostics\nplot(mod1_sim,auto.layout = FALSE)\n\n\n\n\n\n\n\n\nb[1] trace - age\n\n\n\n\n\n\n\nb[1] density - age\n\n\n\n\n\n\n\n\n\nb[2] trace - OME\n\n\n\n\n\n\n\nb[2] density - OME\n\n\n\n\n\n\n\n\n\nb[3] trace - Loud\n\n\n\n\n\n\n\nb[3] density - Loud\n\n\n\n\n\n\n\n\n\nb[4] trace - incoherent\n\n\n\n\n\n\n\nb[4] density - incoherent\n\n\n\n\n\n\n\n\n\nb[0] trace - intercept\n\n\n\n\n\n\n\nb[0] density - intercept\n\n\n\n\n\n\nTrace plots\n\n\n\n\nCode\ngelman.diag(mod1_sim)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\nb[1]       1.00       1.01\nb[2]       1.00       1.00\nb[3]       1.03       1.06\nb[4]       1.00       1.00\nb0         1.03       1.05\n\nMultivariate psrf\n\n1.01\n\n\nCode\nautocorr.diag(mod1_sim)\n\n\n             b[1]         b[2]      b[3]       b[4]        b0\nLag 0  1.00000000  1.000000000 1.0000000 1.00000000 1.0000000\nLag 1  0.91025675  0.811156528 0.9826686 0.47753038 0.9870584\nLag 5  0.65090315  0.390115800 0.9215882 0.05882189 0.9356891\nLag 10 0.43901249  0.192422571 0.8532552 0.04455740 0.8760773\nLag 50 0.01764607 -0.002023693 0.4654191 0.03018729 0.4760548\n\n\n\nCode\nautocorr.plot(mod1_csim,auto.layout = FALSE)\n\n\n\n\n\n\n\n\nb[1] ac - age\n\n\n\n\n\n\n\nb[2] ac - OME\n\n\n\n\n\n\n\n\n\nb[3] ac - loud\n\n\n\n\n\n\n\nb[4] ac - incoherent\n\n\n\n\n\n\n\n\n\nb[0] ac - intercept\n\n\n\n\nMCMC auto-correlation\n\n\n\n\nCode\neffectiveSize(mod1_sim)\n#| label: 'lst-Logistic-Regression-5-5'\n1dic1 = dic.samples(mod1, n.iter=1e3)\n\n\n\n1\n\ncalculate DIC\n\n\n\n\n      b[1]       b[2]       b[3]       b[4]         b0 \n 618.09894 1420.13206  120.95215 3839.42600   99.65829 \n\n\nBecause there are many data points, the MCMC will take some time to run.\nBefore analyzing the results, perform some MCMC diagnostic checks. What does the Raftery and Lewis diagnostic (raftery.diag()) suggest about these chains?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nlibrary(\"coda\")\n(raftery.diag(mod1))\n\n\n\nQuantile (q) = 0.025\nAccuracy (r) = +/- 0.005\nProbability (s) = 0.95 \n\nYou need a sample size of at least 3746 with these values of q, r and s\n\n\n\nThe dependence factor for many of the variables is large (&gt;5.0), indicating weak autocorrelation in the chains. We would not require a large number of iterations to reliably produce 95% probability intervals for the parameters.\nThe scale reduction factor for many variables is large (&gt;5.0), indicating that the different chains are exploring the same space. We have used a sufficient burn-in time.\nThe dependence factor for many of the variables is large (&gt;5.0), indicating strong autocorrelation in the chains. We would require a large number of iterations to reliably produce 95% probability intervals for the parameters.\nThe scale reduction factor for many variables is large (&gt;5.0), indicating that the different chains are not exploring the same space yet. We need to run a longer burn-in period.\n\nThe Raftery and Lewis diagnostic estimates how many iterations of the current chain would be required to reliably estimate the outer quantiles of the posterior.\n\n\n\n\nExercise 6  Although OMElow is the predictor with weakest statistical association to probability of correct responses, the posterior probability that its coefficient \\beta_2 is negative is still greater than 0.9. How do we interpret this (most likely) negative coefficient in the context of our model?Logistic Regression\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nWhile holding all other predictors constant, low OME is associated with a decrease of magnitude ∣\\beta_2∣ in the probability of correct responses while high OME is associated with an increase ∣\\beta_2∣.\nWhile holding all other predictors constant, low OME is associated with a higher probability of correct responses than high OME.\nWhile holding all other predictors constant, low OME is associated with a lower probability of correct responses than high OME.\nWhile holding all other predictors constant, low OME is associated with an increase of magnitude ∣\\beta_2∣ in the probability of correct responses while high OME is associated with a decrease of \\beta_2∣.\n\nSince low OME is coded with a one and has a negative coefficient, low OME is associated with lower log-odds and consequently lower probability.\nIt may also be interesting to try a model that includes interaction terms to see if, for example, the effect of low/high OME is different for different Age groups.\n\n\n\n\nExercise 7  Using the posterior mean estimates of the model coefficients, create a point estimate of the probability of correct responses for a child of age 60 months, with high OME, using a coherent stimulus of 50 decibels. Round your answer to two decimal places.Logistic Regression\n\n\n\n\n\n\nNoteHint:\n\n\n\nFirst calculate the linear part by multiplying the variables by the coefficients and adding them up (call this xb). Once you have that, apply the inverse of the link function to transform it into a probability estimate. Recall that the inverse of the logit transformation is \\phi=\\frac{1}{1+e^{−xb}}.\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n# logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n\n1A=X[,1]==60\n2B=X[,2]==0\n3C=X[,3]==50\n4D=X[,4]==0\n5ABCD = X[A & B & C & D, c(1,2,3,4)]\n6pm_coef = colMeans(mod1_csim)\n7pm_Xb = pm_coef[\"b0\"] + ABCD  %*% pm_coef[1:4]\n8phat = 1.0 / (1.0 + exp(-pm_Xb))\n9mean(phat)\n\n\n\n1\n\nchild of age 60 months\n\n2\n\nwith high OME,\n\n\n3\n\nusing a coherent\n\n4\n\nstimulus of 50 decibels\n\n5\n\ncombining\n\n6\n\ninfer mean for parameters from MCMC samples\n\n7\n\nmultiplying the variables by the coefficients\n\n8\n\ninverse of the link function to transform\n\n9\n\npoint estimate\n\n\n\n\n[1] 0.9180176\n\n\n\n\n\n\nExercise 8  Use the posterior mean estimates of the model coefficients to create point estimates of the probability of correct responses for each observation in the original data. To do this, follow the steps outlined in the lesson to create a vector of these probabilities called phat (using our notation from this quiz, it would be \\hat\\phi).Logistic Regression\nOnce you have phat, calculate the proportion of in-sample observations that are correctly classified according to the following criterion: the model prediction and observed correct response rate are either both higher than 0.7 or both lower than 0.7. Round your answer to two decimal places.\n\n\n\n\n\n\nNoteHint:\n\n\n\nUse the following code:\n\n\nCode\n# recall:   logit(phi[i]) = b0 + b[1]*Age[i] + b[2]*OMElow[i] + b[3]*Loud[i] + b[4]*Noiseincoherent[i]\n\n(pm_coef = colMeans(mod1_csim))\n\n\n       b[1]        b[2]        b[3]        b[4]          b0 \n 0.01851805 -0.24664798  0.17009688  1.57064915 -7.20021444 \n\n\n\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\npm_Xb = pm_coef[\"b0\"] + X[,c(1,2,3,4)] %*% pm_coef[1:4]\nphat = 1.0 / (1.0 + exp(-pm_Xb))\nhead(phat)\n\n\n       [,1]\n1 0.2813186\n2 0.6531057\n3 0.4781525\n4 0.8150559\n5 0.6820131\n6 0.9116289\n\n\nCode\n(tab0.7 = table(phat &gt; 0.7, (dat$Correct / dat$Trials) &gt; 0.7))\n\n\n       \n        FALSE TRUE\n  FALSE   182   48\n  TRUE     63  419\n\n\nCode\nsum(diag(tab0.7)) / sum(tab0.7)\n\n\n[1] 0.8441011\n\n\n0.84\nIt appears that the accurate cases (high probability of correct responses) are well captured by the model.\nIn this exercise, we obtained a point estimate of the coefficients and used that to obtain a point estimate of the probabilities. If we want posterior distributions for the probabilities, we could apply the inverse link transformation to each iteration of the coefficients.",
    "crumbs": [
      "2. Techniques and Models",
      "Homework on Logistic Regression"
    ]
  },
  {
    "objectID": "C2-L05-Ex1.html",
    "href": "C2-L05-Ex1.html",
    "title": "",
    "section": "",
    "text": "2. Techniques and ModelsHW - Gibbs-Sampling algorithm CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "2. Techniques and Models",
      "HW - Gibbs-Sampling algorithm"
    ]
  },
  {
    "objectID": "C2-L05-Ex1.html#hw---gibbs-sampling-algorithm",
    "href": "C2-L05-Ex1.html#hw---gibbs-sampling-algorithm",
    "title": "",
    "section": "1 HW - Gibbs-Sampling algorithm",
    "text": "1 HW - Gibbs-Sampling algorithm\n\nExercise 1  Which of the following descriptions matches the process of Gibbs sampling for multiple random variables?Gibbs\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nCycle through the variables, drawing a sample from the full conditional distribution of each variable while substituting in the current values of all other variables. Repeat this cycle for many iterations.\nDraw candidates for all J variables simultaneously using a multivariate proposal distribution. For each variable, calculate the acceptance ratio αj using the joint (unnormalized) density. Accept each candidate with probability min{1,\\alpha_j} \\ for \\  j=1,\\ldots,J. Repeat this cycle for many iterations.\nCycle through the variables, drawing from a proposal distribution for each variable and accepting the candidate with probability equal to the ratio of the candidate draw to the old value of the variable. Repeat this cycle for many iterations.\nDraw candidates for all variables simultaneously using a multivariate proposal distribution. Calculate the acceptance ratio α using the joint (unnormalized) density. Accept the candidates with probability min{1,\\alpha}. Repeat this step for many iterations. Correct\n\nGibbs sampling allows us to perform the updates one-at-a-time using full conditional distributions.\n\n\n\n\nExercise 2  Suppose we have a joint probability distribution for four variables, p(w,x,y,z) . Which of the following expresses the full conditional distribution for variable x?Gibbs\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\np(x \\mid y)\np(x)\np(w,y,z \\mid x)\np(x \\mid w,y,z)\n\nIt is the distribution of x, conditional on all other variables. It is proportional to p(w,x,y,z), where we consider w,y, and z as fixed constants.\n\n\n\n\nExercise 3  Suppose we have the following joint distribution for x,y, and z:Gibbs\n\np(x,y,z) = 5e^{-5z} I_{z\\ge0} \\frac{\\Gamma(z+3)}{\\Gamma(z) \\Gamma(3)} y^{z-1} (1-y)^{2} I_{0&lt;y&lt;1} { 10 \\choose x} y^x (1-y)^{10-x} I_{x\\in\\{1,\\ldots,10 \\}}\n\nThe density for the full conditional distribution of z is proportional to which of the following?\n\n\n\n\n\n\n\nImportant\n\n\n\nHint: The full conditional for z is proportional to the full joint distribution p(x,y,z) where x and y are just constants.\n\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\np(z \\mid x, y) \\propto 5e^{-5z} I_{z\\ge0}\np(z \\mid x, y) \\propto y^{z-1} (1-y)^{2} y^x (1-y)^{10-x} I_{0&lt;y&lt;1}\np(z \\mid x, y) \\propto e^{-5z} \\frac{\\Gamma(z+3)}{\\Gamma(z)} y^{z-1} I_{z\\ge0}\np(z \\mid x, y) \\propto { 10 \\choose x} y^x (1-y)^{10-x} I_{x\\in\\{1,\\ldots,10 \\}}\n\nThis could also be written as p(z \\mid x, y) = C \\cdot e^{-5z} \\frac{\\Gamma(z+3)}{\\Gamma(z)} y^{z-1} I_{z\\ge0} where C is some constant number not involving z.\n\n\n\n\nExercise 4  The full conditional distribution in Question 3 is not a standard distribution that we can easily sample. Fortunately, it turns out that we can do a Metropolis-Hastings step inside our Gibbs sampler step for z.Gibbs\nIf we employ that strategy in a Gibbs sampler for y and z (always conditioning on x), then the algorithm would look like this:\nFor iteration i in 1 to m, repeat:\n\n  1. \n    a) Draw z* from a proposal distribution q.\n    b) Calculate the acceptance ratio (alpha) using the full\n        conditional distribution for z|x,y and the candidate distribution q, plugging in the previous iteration's value y_{i-1} for y.\n    c) Accept the candidate with probability min{1, alpha} and\n        set the value for z_i accordingly.\n\n  2. ___________________________.\nWhat would go in step 2 to complete the Gibbs sampler?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nDraw y_i from the marginal distribution p(y).\nDraw y_i from the full conditional p(y \\mid x,z), plugging in the value z_i just drawn in step 1 for z.\nDraw y_i from the full conditional p(y \\mid x,z), plugging in the previous iteration’s value z_{i−1} for z.\nDraw y_i from the full conditional p(y \\mid x,z), plugging in the candidate z^∗ for z.\n\n\n\n\n\nExercise 5  Suppose we have a joint probability distribution for three variables: p(x,y,z) . Identify the algorithm to perform Gibbs sampling for all three variables. 1 pointGibbs\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n[ ]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw candidates x*, y*, z* from a joint proposal\n      distribution q.\n\n  2. Calculate the acceptance ratio alpha using\n      $g(x,y,z) = p(x|y,z)p(y|x,z)p(z|x,y) and q.\n\n  3. Accept the candidates with probability min{1,alpha}\n      and set x_i, y_i, z_i accordingly.\n\nend.\n\n[ ]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw x_i from the full conditional distribution for\n      x|y,z, plugging in the previous iteration's values\n      y_{i-1}, z_{i-1} for y and z.\n\n  2. Draw y_i from the full conditional distribution for\n      y|x,z, plugging in the previous iteration's values\n      x_{i-1}, z_{i-1} for x and z.\n\n  3. Draw z_i from the full conditional distribution for\n      z|x,y, plugging in the previous iteration's values\n      x_{i-1}, y_{i-1} for x and y.\n\nend.\n\n[ ]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw candidates x*, y*, z* from a joint proposal\n      distribution q.\n\n  2. a) i) Calculate the acceptance ratio alpha_x using\n            the full conditional p(x|y,z) and q, plugging in the candidates y*, z* for y and z.\n\n        ii) Accept x* with probability min{1,alpha_x}\n            and set x_i accordingly.\n\n     b) i) Calculate the acceptance ratio alpha_y using\n            the full conditional p(y|x,z) and q, plugging in x_i, z* for x and z.\n\n        ii) Accept y* with probability min{1,alpha_y}\n            and set y_i accordingly.\n\n     c) i) Calculate the acceptance ratio alpha_z using\n            the full conditional p(z|x,y) and q, plugging in x_i, y_i for x and y.\n\n        ii) Accept z* with probability min{1,alpha_z}\n            and set z_i accordingly.\nend.\n\n[x]\n\nFor iteration i in 1 to m, repeat:\n\n  1. Draw x_i from the full conditional distribution for\n      x|y,z, plugging in the previous iteration's values\n      y_{i-1}, z_{i-1} for y and z.\n\n  2. Draw y_i from the full conditional distribution for\n      y|x,z, plugging in the previous iteration's value\n      z_{i-1} for z and this iteration's value x_i for x.\n\n  3. Draw z_i from the full conditional distribution for\n      z|x,y, plugging in this iteration's values\n      x_i, y_i for x and y.\n\nend. \nThis is an extension of Gibbs sampling to three variables. The algorithm can be expanded to accommodate as many variables as you need.\n\n\n\nFor Questions 6 to 8, consider the example from the lesson where the data are percent change in total personnel since last year for n=10 companies.\n\nExercise 6  In our model with normal likelihood and unknown mean \\mu and unknown variance \\sigma^2 , we chose a normal prior for the mean and an inverse-gamma prior for the variance.Gibbs\nWhat was the major advantage of selecting these particular priors?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nBecause these priors are conjugate for their respective parameters, they guarantee the smallest possible Monte Carlo standard error for posterior mean estimates.\nBecause these priors are conjugate for their respective parameters, they guarantee the most accurate posterior distribution possible for the given likelihood.\nThese priors allowed us to bypass MCMC, providing a joint conjugate posterior for \\mu and \\sigma^2 .\nEach prior was conjugate in the case where the other parameter was known, causing the full conditional distributions to come from the same distribution families as the priors (and therefore easy to sample).\n\nIn hierarchical models, selecting conjugate priors at any level will result in a simple Gibbs update for the parameter involved. The other claims are false or exaggerations.\n\n\n\n\nExercise 7  Suppose we repeat the analysis for n=6 companies in another industry and the data are:Gibbs\nRe-run the Gibbs sampler in R for these new data (5000 iterations using the same priors and initial values as in the Lesson) and report the posterior mean for \\mu. Round your answer to two decimal places.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\nlibrary(\"coda\")\nsummary(as.mcmc(post))\n\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nmu   -0.9976 0.6624 0.009368        0.01015\nsig2  4.5219 3.2775 0.046352        0.05135\n\n2. Quantiles for each variable:\n\n       2.5%    25%    50%     75%   97.5%\nmu   -2.218 -1.444 -1.042 -0.5762  0.4013\nsig2  1.419  2.506  3.596  5.4003 13.0080\n\n\n\n\nCode\n#' update_mu\n#'\n#' @param n - sample size\n#' @param ybar - sample mean\n#' @param sig2 - current sigma squared\n#' @param mu_0 - mean hyper-parameter\n#' @param sig2_0 - variance  hyper-parameter\n#' \n#' @output - updated  value for mu the mean\nupdate_mu = function(n, ybar, sig2, mu_0, sig2_0) {\n  sig2_1 = 1.0 / (n / sig2 + 1.0 / sig2_0)\n  mu_1 = sig2_1 * (n * ybar / sig2 + mu_0 / sig2_0)\n  rnorm(n=1, mean=mu_1, sd=sqrt(sig2_1))\n}\n\n#' update_sig2\n#'\n#' @param n - sample size\n#' @param y - the data\n#' @param nu_0 - nu hyper-parameter\n#' @param beta_0 - beta hyper-parameter\n#' \n#' @output - updated  value for sigma2 the variance\nupdate_sig2 = function(n, y, mu, nu_0, beta_0) {\n  nu_1 = nu_0 + n / 2.0\n  sumsq = sum( (y - mu)^2 )\n  beta_1 = beta_0 + sumsq / 2.0\n  out_gamma = rgamma(n=1, shape=nu_1, rate=beta_1)\n  1.0 / out_gamma\n}\n\ngibbs = function(y, n_iter, init, prior) {\n  ybar = mean(y)\n  n = length(y)\n  \n  ## initialize\n  mu_out = numeric(n_iter)\n  sig2_out = numeric(n_iter)\n  \n  mu_now = init$mu\n  \n  ## Gibbs sampler\n  for (i in 1:n_iter) {\n    sig2_now = update_sig2(n=n, y=y, mu=mu_now, nu_0=prior$nu_0, beta_0=prior$beta_0)\n    mu_now = update_mu(n=n, ybar=ybar, sig2=sig2_now, mu_0=prior$mu_0, sig2_0=prior$sig2_0)\n    \n    sig2_out[i] = sig2_now\n    mu_out[i] = mu_now\n  }\n  \n  cbind(mu=mu_out, sig2=sig2_out)\n}\n\ny = c(-0.2, -1.5, -5.3, 0.3, -0.8, -2.2)\nybar = mean(y)\nn = length(y)\n\n## prior\nprior = list()\nprior$mu_0 = 0.0\nprior$sig2_0 = 1.0\nprior$n_0 = 2.0 # prior effective sample size for sig2\nprior$s2_0 = 1.0 # prior point estimate for sig2\nprior$nu_0 = prior$n_0 / 2.0 # prior parameter for inverse-gamma\nprior$beta_0 = prior$n_0 * prior$s2_0 / 2.0 # prior parameter for inverse-gamma\n\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dnorm(x=x, mean = prior$mu_0, sd=sqrt(prior$sig2_0)), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nCode\nset.seed(53)\n\ninit = list()\ninit$mu = 0.0\n\npost = gibbs(y=y, n_iter=5e3, init=init, prior=prior)\n\n\n\n\n\n\nExercise 8 Gibbs\nAn industry expert is surprised by your results from Question 7 and insists that growth in this sector should be positive on average. To accommodate this expert’s prior beliefs, you adjust the prior for μ to be normal with a mean 1.0 and variance 1.0. This is a fairly informative and optimistic prior (the prior probability that \\mu &gt;0 is about 0.84).\nWhat happens to the posterior mean of μ? Re-run the analysis on the new data with this new prior. Again, use 5000 iterations and the same prior for σ2 and initial values as before).\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ny = c(-0.2, -1.5, -5.3, 0.3, -0.8, -2.2)\nybar = mean(y)\nn = length(y)\n\n## prior\nprior = list()\nprior$mu_0 = 1.0\nprior$sig2_0 = 1.0\nprior$n_0 = 2.0 # prior effective sample size for sig2\nprior$s2_0 = 1.0 # prior point estimate for sig2\nprior$nu_0 = prior$n_0 / 2.0 # prior parameter for inverse-gamma\nprior$beta_0 = prior$n_0 * prior$s2_0 / 2.0 # prior parameter for inverse-gamma\n\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dnorm(x=x, mean = prior$mu_0, sd=sqrt(prior$sig2_0)), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nCode\nset.seed(53)\n\ninit = list()\ninit$mu = 0.0\n\npost = gibbs(y=y, n_iter=5e3, init=init, prior=prior)\n\n\n\n\nCode\nlibrary(\"coda\")\nsummary(as.mcmc(post))\n\n\n\nIterations = 1:5000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n        Mean     SD Naive SE Time-series SE\nmu   -0.5071 0.7549  0.01068        0.01334\nsig2  5.4989 4.3818  0.06197        0.07592\n\n2. Quantiles for each variable:\n\n       2.5%    25%     50%      75%  97.5%\nmu   -1.828 -1.028 -0.5676 -0.03787  1.118\nsig2  1.536  2.870  4.2764  6.60483 17.002\n\n\n\nThe posterior mean for μ is less than −0.25, suggesting that despite the optimistic prior, the data strongly favor estimating growth to be negative in this industry.\nThe posterior mean for μ is between −0.25 and 0.25, suggesting that the data are not as optimistic about growth as the prior, but we are inconclusive about whether growth is positive or negative.\nThe posterior mean for μ is between 0.25 and 1.0, suggesting that the data are not informative enough to contradict this expert’s opinion.\nThe posterior mean for μ is above 1.0, suggesting that the optimistic prior was actually not optimistic enough.",
    "crumbs": [
      "2. Techniques and Models",
      "HW - Gibbs-Sampling algorithm"
    ]
  },
  {
    "objectID": "C3-L05-Ex1.html",
    "href": "C3-L05-Ex1.html",
    "title": "Computational considerations for Mixture Models",
    "section": "",
    "text": "Consider a mixture of three Gaussian distribution with common identity covariance matrix and means\n\n\n\\begin{aligned}\n\\mu_1 &= (0,0)' \\\\\n\\mu_2 &= (1/3,1/3)' \\\\\n\\mu_3 &= (-2/3,1/3)'\n\\end{aligned}\n For an observation x_i = (31,−23)' what is the value of v_{i,2}, the probability of the observation being generated by the second component (rounded to three decimal places)?\n\n0.928\n1.000\n0.072\n\n\nTrue or False: The starting value for the parameters of the mixture model in the EM algorithm could have an impact on the solution you obtain.\n\n\nTrue\nFalse\n\n\nTrue or False: Consider a Bayesian formulation of a Mixture Model that uses informative priors for all the parameters. A Markov chain Monte Carlo (MCMC) algorithm for fitting such model will fail to work if no observations are allocated to a component of the mixture.\n\n\nTrue\nFalse",
    "crumbs": [
      "3. Mixture Models",
      "Computational considerations for Mixture Models"
    ]
  },
  {
    "objectID": "C3-L05-Ex1.html#hw---computational-considerations-for-mixture-models",
    "href": "C3-L05-Ex1.html#hw---computational-considerations-for-mixture-models",
    "title": "Computational considerations for Mixture Models",
    "section": "",
    "text": "Consider a mixture of three Gaussian distribution with common identity covariance matrix and means\n\n\n\\begin{aligned}\n\\mu_1 &= (0,0)' \\\\\n\\mu_2 &= (1/3,1/3)' \\\\\n\\mu_3 &= (-2/3,1/3)'\n\\end{aligned}\n For an observation x_i = (31,−23)' what is the value of v_{i,2}, the probability of the observation being generated by the second component (rounded to three decimal places)?\n\n0.928\n1.000\n0.072\n\n\nTrue or False: The starting value for the parameters of the mixture model in the EM algorithm could have an impact on the solution you obtain.\n\n\nTrue\nFalse\n\n\nTrue or False: Consider a Bayesian formulation of a Mixture Model that uses informative priors for all the parameters. A Markov chain Monte Carlo (MCMC) algorithm for fitting such model will fail to work if no observations are allocated to a component of the mixture.\n\n\nTrue\nFalse",
    "crumbs": [
      "3. Mixture Models",
      "Computational considerations for Mixture Models"
    ]
  },
  {
    "objectID": "C1-L10-Ex1.html",
    "href": "C1-L10-Ex1.html",
    "title": "",
    "section": "",
    "text": "1. From Concept to Data AnalysisHomework Normal data CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Homework Normal data"
    ]
  },
  {
    "objectID": "C1-L10-Ex1.html#sec-homework-normal-data",
    "href": "C1-L10-Ex1.html#sec-homework-normal-data",
    "title": "",
    "section": "1 Homework Normal data",
    "text": "1 Homework Normal data\n\nExercise 1 See ?@exm-themometer-calibration thermometer calibration problem\nSuppose you are trying to calibrate a thermometer by testing the temperature it reads when water begins to boil. Because of natural variation, you take n independent measurements (experiments) to estimate \\theta, the mean temperature  reading for this thermometer at the boiling point. Assume a normal likelihood for these data, with mean \\theta and known variance \\sigma^2=0.25 (which corresponds to a standard deviation of 0.5^\\circ Celsius). \\theta := boiling point\\mathcal{L}(\\theta\\mid Y)=N(\\theta,0.25)\nSuppose your prior for \\theta is (conveniently) the conjugate normal. You know that at sea level, water should boil at 100^\\circ Celsius, so you set the prior mean at m_0 =100. f(\\theta)=N(100,s_0^2)\nIf you specify a prior variance s^2_0 for \\theta, which of the following accurately describes the model for your measurements Y_i\\qquad \\forall i\\in\\{1,…,n\\}?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nwe are told Y is IID with normal likelihood with \\mu=\\theta and \\sigma^2=0.25 so\n\nY_i \\mid\\theta \\stackrel{iid}\\sim N(\\theta,0.25) \\qquad (\\text{likelihood})\n\nwe are also told the prior is a conjugate normal with \\mu=100 and \\sigma^2=s^2_0\n\nf(\\theta) \\sim N(100,s^2_0) \\qquad (\\text{prior})\n\n\nY_i \\mid θ \\stackrel{iid}\\sim N(θ,0.25) ; \\theta ∼N(100,s_0^2)\n\n\n\n\n\nExercise 2 See ?@exm-themometer-calibration thermometer calibration problem\nYou decide you want the prior to be equivalent (in effective sample size) to one measurement.\nWhat value should you select for s^2_0 the prior variance of θ?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nby ?@eq-normal-posterior-mean-ess\n\n1 = \\frac{\\sigma_0^2}{s_0^2} =  \\frac{0.25 }{0.25 } \\therefore s_0^2=0.25\n\n\n\n\n\nExercise 3 See ?@exm-themometer-calibration thermometer calibration problem\nYou collect the following n=5 measurements: (94.6, 95.4, 96.2, 94.9, 95.9).\nWhat is the posterior distribution for \\theta?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nso the key point is to realize is that there prior mean is also a a point. n=5\n\\bar{y}=94.6\nPlugging all relevant quantities (including \\bar{y} =95.4) into the update formula in Lesson 10.1, the posterior mean is \\frac{2308}{24} and the posterior variance is \\frac{1}{24}\n\ns_0=0.25\n\n\n\\sigma_0=0.445\n\n\n\nCode\nlibrary(testit)\ny &lt;- c(94.6, 95.4, 96.2, 94.9, 95.9)\nsample_mean = mean(y)\nn=5.0\nassert('sample_mean',sample_mean==95.4)\nsample_var = sum( (y-sample_mean)^2)/(length(y)-1)\nsample_var= var(y)\npop_var=0.25\nprint(paste('sample_var=',sample_var))\n\n\n[1] \"sample_var= 0.445000000000003\"\n\n\nCode\nassert('sample_var',round(sample_var,1)==0.4)\n\nprior_var=0.25\nprior_mean=100.0\npost_mean= (n * sample_mean/pop_var + prior_mean/prior_var ) / ( n / pop_var + 1./prior_var)\nprint(paste('post_mean',round(post_mean,2),'expected result',round(2308/24,2),digits = 7))\n\n\n[1] \"post_mean 96.17 expected result 96.17 7\"\n\n\nCode\nassert('post_mu',round(post_mean,2) == round(2308/24,2))\npost_variance = round(1/(n/pop_var + 1/prior_var),3)\nprint(paste('post_variance',post_variance,'expected result',round(1/24,3),digits = 7))\n\n\n[1] \"post_variance 0.042 expected result 0.042 7\"\n\n\nCode\nassert('post_variance', post_variance == round(1/24,3))\nprint(paste('n(',post_mean,',',post_variance,')'))\n\n\n[1] \"n( 96.1666666666667 , 0.042 )\"\n\n\nresulting in N(96.17,0.0417)\n\n\n\n\nExercise 4 See ?@exm-themometer-calibration thermometer calibration problem\nUse R or Excel to find the upper end of a 95% equal-tailed credible interval for \\theta\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=96.17\nb=0.042\nqnorm(p=0.975, mean=a, sd=sqrt(b))\n\n\n[1] 96.57167\n\n\nThis is the 0.975 quantile of the posterior distribution.\n\n\n\n\nExercise 5 After collecting these data, is it reasonable to conclude that the thermometer is biased toward low values?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\na=96.17\nb=0.042\npnorm(q=100, mean=a, sd=sqrt(b))\n\n\n[1] 1\n\n\nYes, we have P(\\theta &lt;100 \\mid y) &gt; 0.9999.\n\n\n\n\nExercise 6 What is the posterior predictive distribution of a single future observation Y^*\nThis is the posterior distribution for θ. Use the expression given at the end of Lesson 10.1, using the posterior parameters in place of m_0 and s_0^2\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nwe have\n\nlikelihood Y \\mid \\theta,\\sigma^2\\sim N(\\mu=\\theta,\\sigma^2=0.25)\nprior \\theta \\sim N(m_0=100,s^2_0=0.25)\nposterior N(96.17,0,0.42)\n\nwe need to ‘plug’ this into N(m_0,s_0^2)\nThis is the posterior distribution for θ. Use the expression given at the end of Lesson 10.1, using the posterior parameters in place of m0 and s02.\nN(96.17,0.042+0.25) N(96.17,0.292)\n\n\n\n\nExercise 7 Restaurants\nFor Questions 7-10, consider the following scenario:\nYour friend moves from City A to City B and is delighted to find her favorite restaurant chain at her new location. After several meals, however, she suspects that the restaurant in City B is less generous. She decides to investigate.\nShe orders the main dish on 30 randomly selected days throughout the year and records each meal’s weight in grams. You still live in city A, so you assist by performing the same experiment at your restaurant. Assume that the dishes are served on identical plates (measurements subtract the plate’s weight) and that your scale and your friend’s scale are consistent.\nThe following histogram shows the 30 measurements from Restaurant B taken by your friend\nIs it reasonable to assume that these data are normally distributed?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nNo, there appear to be a few extreme observations (outliers).\nThe three points above 700 are about five (sample) standard deviations above the (sample) mean.\n\n\n\n\nExercise 8 Restaurants\nYour friend investigates the three observations above 700 grams and discovers that she had ordered the incorrect meal on those dates. She removes these observations from the data set and proceeds with the analysis using n=27.\nShe assumes a normal likelihood for the data with unknown mean μ and unknown variance σ^2. She uses the model presented in ?@sec-normal-likelihood-with-expectation-and-variance-unknown where, conditional on σ^2, the prior for \\mu is normal with mean m and variance \\sigma^2/w. Next, the marginal prior for \\sigma^2 is \\text{Inverse-Gamma}(a,b).\nYour friend’s prior guess on the mean dish weight is 500 grams, so we set m=500. She is not very confident with this guess, so we set the prior effective sample size w=0.1. Finally, she sets a=3 and b=200.\nWe can learn more about this inverse-gamma prior by simulating draws from it. If a random variable X follows a \\text{Gamma}(a,b) distribution, then 1/X follows an \\text{Inverse-Gamma}(a,b) distribution. Hence, we can simulate draws from a gamma distribution and take their reciprocals, which will be draws from an inverse-gamma.\nTo simulate 1000 draws in R (replace a and b with their actual values):\nSimulate a large number of draws (at least 300) from the prior for σ^2 and report your approximate prior mean from these draws. It does not need to be exact.\nwhere\n\na' = a + \\frac{n}{2} = 3 + \\frac{27}{2} = 16.5\n\n\nb' = b + \\frac{n-1}{2} s^2 + \\frac{wn}{2(w+n)}(\\bar{y}-m)^2 = 200 + \\frac{27-1}{2} 401.8 + \\frac{0.1\\cdot 27}{2(0.1+27)}(609.7-500)^2 = 6022.9\n\n\nm' = \\frac{n\\bar{y} + wm}{w + n} =  \\frac{27\\cdot 609.7 + 0.1\\cdot 500}{0.1 + 27} = 609.3\n\nw=0.1\nw+n=27.1\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\n#liklihood N(mu,sigma_sq)=N(m,sigma_sq/w)\nm=500 # mean dish wight\nw=0.1 # effective sample size\n#with sigma_sq prior IG(a,b)\na=3\nb=200\nz &lt;- rgamma(n=1000, shape=a, rate=b) #prior for variance square\nx &lt;- 1/z\nmean(x)\n\n\n[1] 99.84031\n\n\n\nThe actual prior mean for \\sigma^2=b/a-1 = 200/2=100\nThe prior variance for \\sigma^2=b^2/((a-1)^2(a-2))=10000\n\n\n\n\n\nExercise 9 Restaurants\nWith the n=27 data points, your friend calculates the sample mean \\bar{y} = 609.7 and sample variance s^2 = 1\\frac{1}{n-1} \\sim (y_i-\\hat{y})^2 = 401.8\nUsing the update formulas from Lesson 10.2, she calculates the following posterior distributions:\n\n\\sigma \\mid y \\sim \\mathrm{Inverse-Gamma}(a',b')\n\n\ny \\mid \\sigma^2,y \\sim \\mathcal{N}(m', \\frac{\\sigma^2}{w+n})\n\nTo simulate draws from this posterior, begin by drawing values for \\sigma^2 from its posterior using the method from the preceding question. Then, plug these values for \\sigma^2 into the posterior for μ and draw from that normal distribution.\nTo simulate 1000 draws in R:\n\n\nCode\nz &lt;- rgamma(1000, shape=16.5, rate=6022.9)\nsig2 &lt;- 1/z\nmu &lt;- rnorm(1000, mean=609.3, sd=sqrt(sig2/27.1))\n\n\nWe can use these simulated draws to help us approximate inferences for μ and σ^2.\nFor example, we can obtain a 95% equal-tailed credible for μ by calculating the quantiles/percentiles of the simulated values.\n\n\nCode\nquantile(x=mu, probs=c(0.025, 0.975))\n\n\n    2.5%    97.5% \n601.5315 616.5874 \n\n\nPerform the posterior simulation described above and compute your approximate 95% equal-tailed credible interval for μ. Based on your simulation, which of the following appears to be the actual interval?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nI got this part wrong many times so I figured out how to add assertions to verify the numbers were what I expected. Since R was rounding off some numbers and not others.\n\n\nCode\n1library(testit)\n2n &lt;- 27.0\n3y_hat &lt;- 609.7\n4s_sq &lt;- 401.8\n5a &lt;- 3.0\n6b &lt;- 200.0\n7w &lt;- 0.1\n8a_tag&lt;- a + n / 2.\nassert(\"a_tag\", a_tag == 16.5)\n9m=500.0\nb_tag = round(b + (n-1)*s_sq *0.5 + (w*n)/2/(w + n)*(y_hat-m)^2,1)  \nprint( b_tag,digits = 7)\nassert(\"b_tag\", b_tag == 6022.9)\nm_tag = round(((n * y_hat) + (w*m)) / (w+n),1)\nprint(m_tag,digits = 7)\nassert(\"m_tag\",m_tag == 609.3)\n\n\n\n1\n\nsupport for assertions\n\n2\n\nn is n is the sample size after removing the outliers.\n\n3\n\ny_hat is \\bar{y}, the sample mean\n\n4\n\ns^2 or s_sq is the sample variance\n\n5\n\na is the initial a.\n\n6\n\nb is the initial b.\n\n7\n\nw is the confidence level used in the denominator of the prior variance.\n\n8\n\na_tag is a', the updated value of a. We are given a value of 16.5\n\n9\n\nm is the prior dish weight from Exercise 8\n\n\n\n\n[1] 6022.9\n[1] 609.3\n\n\n\n\nCode\nz &lt;- rgamma(1000, shape=16.5, rate=6022.9)\nsig2 &lt;- 1/z\nmu &lt;- rnorm(1000, mean=609.3, sd=sqrt(sig2/27.1))\nquantile(x=mu, probs=c(0.025, 0.975))\n\n\n    2.5%    97.5% \n602.0278 616.9477 \n\n\n(602,617)\nThis is the actual interval, calculated from the exact marginal posterior (t distribution) for \\mu\n\n\n\n\nExercise 10 Restaurants\nYou complete your experiment at Restaurant A with m=30 data points, which appear to be normally distributed. You calculate the sample mean \\hat{y} = 622.8 and sample variance s^2=\\frac{1}{n-1}\\sum{(y_i-\\bar{y})^2}=403.1\nRepeat the analysis from Question 9 using the same priors and draw samples from the posterior distribution of \\sigma^2_A and \\mu_A (where the A denotes that these parameters are for Restaurant A).\nTreating the data from Restaurant A as independent from Restaurant B, we can now attempt to answer your friend’s original question: is restaurant A more generous? To do so, we can compute posterior probabilities of hypotheses like \\mu_A&gt; \\mu_B. This is a simple task if we have simulated draws for \\mu_A and \\mu_B. For i=1,…,N (the number of simulations drawn for each parameter), make the comparison \\mu_A&gt; \\mu_B using the ith draw for \\mu_A and \\mu_B. Then count how many of these return a TRUE value and divide by N, the total number of simulations.\nIn R (using 1000 simulated values):\n\n\nCode\n# sum( muA &gt; muB ) / 1000\n\n\nWould you conclude that the main dish from restaurant A weighs more than the main dish from restaurant B on average?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\nI first wanted to replicate the derivation of the numbers given as they seemed rather arbitrary. I thought I would need this in the simulation but then I understood that we need to use the same priors and all that changes in the simulation is the mean \\mu for each restaurant.\nThis R code for the actual simulation is as follows:\n\n\nCode\n1z &lt;- rgamma(1000, shape=18, rate=6796.4)\n2sig2 &lt;- 1/z\n3muA &lt;- rnorm(1000, mean=622.4, sd=sqrt(sig2/30.1))\nz &lt;- rgamma(1000, shape=16.5, rate=6022.9)\nsig2 &lt;- 1/z\n4muB &lt;- rnorm(1000, mean=609.3, sd=sqrt(sig2/27.1))\n5sum( muA &gt; muB ) / 1000\n\n\n\n1\n\nsample from \\sigma^2 from gamma prior\n\n2\n\ninvert since we need inverse-gamma\n\n3\n\nsample form \\mu_A\n\n4\n\nsample form \\mu_B\n\n5\n\nsum the comparison \\mu_A &gt; \\mu_B\n\n\n\n\n[1] 0.986\n\n\nYes, the posterior probability that \\mu_A &gt; \\mu_B is at least 0.95.\nThis is fairly strong evidence that the mean weight of the dish from Restaurant A is greater than the mean weight of the dish from Restaurant B.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Homework Normal data"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "",
    "section": "",
    "text": "6. AppendicesSummary Code\n\n\n\n\n\n\n1 Summary\nIn summary, this Specialization we covered a wide array of Bayesian methods.",
    "crumbs": [
      "6. Appendices",
      "Summary"
    ]
  },
  {
    "objectID": "C4-L00.html",
    "href": "C4-L00.html",
    "title": "Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "",
    "text": "I decided to migrate some material that is auxiliary to the course:",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Introductions to time series analysis and the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L00.html#course-card",
    "href": "C4-L00.html#course-card",
    "title": "Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "1 Course Card",
    "text": "1 Course Card\n\nCourse: Bayesian Statistics: Time Series\nOffered by: University of California, Santa Cruz\nInstructor: Raquel Prado\nCertificate: Yes\nLevel: Graduate\nCommitment: 4 weeks of study, 3-4 hours/week",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Introductions to time series analysis and the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L00.html#overview-of-the-course",
    "href": "C4-L00.html#overview-of-the-course",
    "title": "Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "2 Overview of the course",
    "text": "2 Overview of the course\nThis course seems very similar to classic basic time series course without the Bayesian part. (AR, MA, ARMA, ARIMA, SARIMA, DLM etc.)\nOne of the questions I had when I started this course was what is the difference between a Bayesian approach to time series analysis and a classical approach. The following is a summary of what I found:\n\n\n\n\n\n\nImportantAre we Being Bayesian ?\n\n\n\nThe Bayesian approach presents primarily in:\n\nSections on Bayesian inference where we do inference on the parameters of the models.\nBayesian prediction unlike an MLE prediction is a distribution of predictions not just a point estimate, and therefore is useful for quantifying uncertainty.\nWe also cover some material on model selection - this again is where the Bayesian approach to optimization presents more powerful tools than the classical approach.\nWhen we want to quantify the uncertainty in our model we have four sources of uncertainty:\n\nUncertainty due to using the correct model (structure).\n\nI consider this is an epistemic uncertainty -\nOne could reduce it by collecting more data, then applying the Bayesian model selection to choose the best model.\n\nUncertainty due to the estimation of the model parameters. This is an epistemic uncertainty - we can reduce it by collecting more data reducing the plausible intervals for these parameters under the bayesian approach.\nUncertainty due to random shocks \\epsilon_t. for the period being predicted. This is an aleatory uncertainty.\nUncertainty in the forecasted values X_{t+h} Items 2-3 can be quantified using a plausible interval in the Bayesian approach and as we predict further into the future the interval will grow.\n\nModel selection is a big part of the Bayesian approach. We can use the DIC, WAIC, and LOO to compare models.\n\n\n\n\nThe book by Professor Prado is very comprehensive and covers plenty of additional models and references lots of recent research. These including VAR, VARMA models, Kalman filters, SMC/Particle filters, etc. These are useful for the continuous control flavours of RL. But you will need to learn it on your own.\nIn the capstone project that is the next course in the specialization the teacher adds another layer of sophistication by introducing mixtures of TS models.\nHowever unlike some courses I took we dive deep enough and get sufficient examples to understand how to put all the bits together into more sophisticated time series models.\n\n\n2.1 Mathematical Review\n\nThere is a issues with mathematics most of the results and techniques are so rarely useful that students will soon forget most but a few very useful results. Having a good memory is a great asset in mathematics but is rarely enough. I like to review some mathematical results from my undergraduate days every five years or so. This helps me keep many of the results fresh in my mind and also makes reading new mathematics easier. Fundamentals in mathematics can fo a very long way. This is material from topology, determinants and solving linear equations, numerical methods for decomposing matrices, and so on. Definitions of certain groups.\nOne reason this and other Bayesian courses and books can be challenging and even overwhelming is that they can use lots of mathematics. This can range from high school material like complex numbers and quadratics formulas to intermediate results like finding root of characteristic polynomials, eigenvalues, Topelitz matrices, jordan forms, and advanced topics like the Durbin-Levinson recursion and certain results from functional analysis theory.\n\nNote that I have not even touched on probability and statistics in that list.\nRather than complain I see this as an opportunity to review/learn some mathematics and statistics that can be useful to a data scientist. During my last sting in Data science I often was able to write formulas but more often then not felt that I lacked sufficient mathematical tools to manipulate them to get the kind of results I wanted. Rather then learning lots of mathematics I wanted to find the most practical and useful results for wrangling maths. When I was a physics undergraduate these might be trigonometric identities, completing the square, being familiar with many integrals and Taylor or Maclaurin series approximations and a few useful inequalities occasionally we use l’Hopital’s rule. Familiarity with some ODEs was also greatly beneficial as these come up in many physical models. Later on hermitian and unitary matrices, fourier expansions, spectral theory, and some results from functional analysis were useful.\nFor statistics we have the variants of the law of large numbers and the central limit theorem, convergence theorems, manipulations of the normal distribution, linear properties of expectation can get you along way. But you have to remember lots of definitions and there are lots of results and theorems that seem to be stepping stones to other results rather than any practical use.\nOn the other hand conjugacy of certain distributions as demonstrated by Herbert Lee and other instructors in this specialization are often very challenging. Charts of Convergence of distributions to other distributions under certain conditions are neat but. There is Hoeffding’s inequality and the Markov’s inequality which can be useful but like most results in mathematics I never had a where they might be used. Then there are certain results - convergence of Markov chains, doubly stochastic matrices. De Finetti’s theorem in statistics.\nI have found that the more I learn the more I can understand and appreciate the material.\n\nThe autoregressive process gives rise to Toeplitz matrices which can be solved using the Durbin-Levinson recursion mentioned many times in the course.\nDurbin-Levinson recursion - is an advanced topic not covered in Numerical Analysis courses or Algebra courses I took.\nTo use it with time series we also need to understand the Yule-Walker equations.\nar(p) require some linear algebra concepts like eigenvalues and Eigenvectors, and characteristic polynomials.\nThe AR(p) the Wold decomposition theorem to get to the infinite order moving average representation and this is not a result I recall learning in my functional analysis course. We also use some complex numbers and Fourier analysis and spectral density functions.\n\nSummarize some of the extra curricular material I found useful in the course.\n\nComplex numbers\nEigenvalues, Eigenvectors and characteristic polynomials\nDurbin-Levinson recursion\nYule-Walker equations\nWiener process (Random walk)\nBrownian motion (Continuous Random walk with drift)\nMarkov Chains ()\nMartingales ()\nStopping theorem\nKalman filter\nWold’s theorem\nDe Finetti’s theorem\nCholesky decomposition\n\n\n\n2.2 Complex Numbers (Review)\nWhen we wish to find the roots of real valued polynomials we will often encounter complex numbers. In this course such polynomials arise naturally in the characteristic polynomials of AR(p) processes.\nWe will need the polar form of complex numbers to represent some variants of AR(p) process.\nThe numbers in the Complex field z \\in \\mathbb{C} numbers are numbers that can be expressed in the form z = a + bi, where a,b\\in\\mathbb{R} and i is the imaginary unit. The imaginary unit i is defined as the square root of -1. Complex numbers can be added, subtracted, multiplied, and divided just like real numbers.\nThe complex conjugate  of a complex number z = a + bi is denoted by \\bar{z} = a - bi. The magnitude of a complex number z = a + bi is denoted by |z| = \\sqrt{a^2 + b^2}. This is sometimes called the modulus of the complex number in this course. The argument of a complex number z = a + bi is denoted by \\text{arg}(z) = \\tan^{-1}(b/a). The polar form of a complex number is given by z = r e^{i \\theta}, where r = |z| and \\theta = \\text{arg}(z).complex conjugate\nThe polar form of a complex number is given by:\n\n\\begin{aligned}\nz &= \\mid z\\mid e^{i \\theta} \\\\\n  &= r (\\cos(\\theta) + i \\sin(\\theta))\n\\end{aligned}\n\\tag{1}\nwhere:\n\n|z| is the magnitude of the complex number, i.e. the distance from the origin to the point in the complex plane.\n\\theta is the angle of the complex number.\n\nI think we will also need the unit roots.\n\n\n2.3 Eigenvalues, Eigenvectors the characteristic polynomials and Unit roots\nThe Eigenvalues of a matrix are the roots of the characteristic polynomial of the matrix. The characteristic polynomial of a matrix A is defined as:\n\n\\begin{aligned}\n\\text{det}(A - \\lambda I) = 0\n\\end{aligned}\n\nwhere \\lambda is the Eigenvalue and I is the identity matrix. The eigenvectors of a matrix are the vectors that satisfy the equation:\n\n\\begin{aligned}\nA v = \\lambda v\n\\end{aligned}\n\nwhere v is the eigenvector and \\lambda is the eigenvalue. The eigenvalues and eigenvectors of a matrix are used in many applications in mathematics and physics, including the diagonalization of matrices, the solution of differential equations, and the analysis of dynamical systems.\n\n2.3.1 Unit Roots\nA unit root is a root of the characteristic polynomial of an autoregressive model that is equal to 1. The presence of a unit root in an autoregressive model indicates that the model is not stationary. The unit root test is a statistical test that is used to determine whether a time series is stationary or non-stationary. The unit root test is based on the null hypothesis that the time series has a unit root, and the alternative hypothesis that the time series is stationary. The unit root test is used to determine whether a time series is stationary or non-stationary, and is an important tool in time series analysis.\n\n\n\n2.4 Spectral analysis (1898)\nThe power spectrum of a signal is the squared absolute value of its Fourier transform. If it is estimated from the discrete Fourier transform it is also called periodogram. Usually estimated using the a fast Fourier transform (FFT) algorithm.\n\n\n2.5 Yule-Walker Equations (1932)\n\n\n2.6 Durbin-Levinson recursion (Off-Course Reading)\nLike me, you might be curious about the Durbin-Levinson recursion mentioned above. This is not covered in the course, and turned out to be an enigma wrapped in a mystery.\nI present my finding in the note below - much of it is due to (Wikipedia contributors 2024b) and (Wikipedia contributors 2024a)\nIn (Yule 1927) and (Walker 1931), Yule and Walker proposed a method for estimating the parameters of an autoregressive model. The method is based on the Yule-Walker equations which are a set of linear equations that can be used to estimate the parameters of an autoregressive model.\nDue to the autoregressive nature of the model, the equations are take a special form called a Toeplitz matrix. However at the time they probably had to use the numerically unstable Gauss-Jordan elimination to solve these equations which is O(n^3) in time complexity.\nA decade or two later in (Levinson 1946) and (Durbin 1960) the authors came up for with a weakly stable yet more efficient algorithm for solving these autocorrelated system of equations which requires only O(n^2) in time complexity. Later their work was further refined in (Trench 1964) and (Zohar 1969) to just 3\\times n^2 multiplication. A cursory search reveals that Toeplitz matrix inversion is still an area of active research with papers covering parallel algorithms and stability studies. Not surprising as man of the more interesting deep learning models, including LLMs are autoregressive.\nSo the Durbin-Levinson recursion is just an elegant bit of linear algebra for solving the Yule-Walker equations more efficiently.\nHere is what I dug up:\n\n\n2.7 Durbin-Levinson and the Yule-Walker equations (Off-Course Reading)\nThe Durbin-Levinson recursion is a method in linear algebra for computing the solution to an equation involving a Toeplitz matrix AKA a diagonal-constant matrix where descending diagonals are constant. The recursion runs in O(n^2) time rather then O(n^3) time required by Gauss-Jordan elimination.\nThe recursion can be used to compute the coefficients of the autoregressive model of a stationary time series. It is based on the Yule-Walker equations and is used to compute the PACF of a time series.\nThe Yule-Walker equations can be stated as follows for an AR(p) process:\n\n\\gamma_m = \\sum_{k=1}^p \\phi_k \\gamma_{m-k} + \\sigma_\\epsilon^2\\delta_{m,0} \\qquad \\text{(Yule-Walker equations)}\n\\tag{2}\nwhere:\n\n\\gamma_m is the autocovariance function of the time series,\n\\phi_k are the AR coefficients,\n\\sigma_\\epsilon^2 is the variance of the white noise process, and\n\\delta_{m,0} is the Kronecker delta function.\n\nwhen m=0 the equation simplifies to:\n\n\\gamma_0 = \\sum_{k=1}^p \\phi_k \\gamma_{-k} + \\sigma_\\epsilon^2 \\qquad \\text{(Yule-Walker equations for m=0)}\n\\tag{3}\nfor m &gt; 0 the equation simplifies to:\n \\begin{bmatrix}\n    \\gamma_1 \\newline\n    \\gamma_2 \\newline\n    \\gamma_3 \\newline\n    \\vdots \\newline\n    \\gamma_p \\newline\n\\end{bmatrix} =  \\begin{bmatrix}\n    \\gamma_0     & \\gamma_{-1}  & \\gamma_{-2}  & \\cdots \\newline\n    \\gamma_1     & \\gamma_0     & \\gamma_{-1}  & \\cdots \\newline\n    \\gamma_2     & \\gamma_1     & \\gamma_0     & \\cdots \\newline\n    \\vdots       & \\vdots       & \\vdots       & \\ddots \\newline\n    \\gamma_{p-1} & \\gamma_{p-2} & \\gamma_{p-3} & \\cdots \\newline\n\\end{bmatrix}  \\begin{bmatrix}\n    \\phi_{1} \\newline\n    \\phi_{2} \\newline\n    \\phi_{3} \\newline\n    \\vdots \\newline\n    \\phi_{p} \\newline\n\\end{bmatrix}\n\nand since this matrix is Toeplitz, we can use Durbin-Levinson recursion to efficiently solve the system for \\phi_k \\forall k.\nOnce \\{\\phi_m ; m=1,2, \\dots ,p \\} are known, we can consider m=0 and solved for \\sigma_\\epsilon^2 by substituting the \\phi_k into Equation 3 Yule-Walker equations.\nOf course the Durbin-Levinson recursion is not the last word on solving this system of equations. There are today numerous improvements which are both faster and more numerically stable.\nThe Yule-Walker equations are a set of p linear equations in the p unknowns \\phi_1, \\phi_2, \\ldots, \\phi_p that can be used to estimate the parameters of an autoregressive model of order p. The Yule-Walker equations are derived by setting the sample autocorrelation function equal to the theoretical autocorrelation function of an AR(p) model and then solving for the unknown parameters. The Yule-Walker equations are given by:\n\n\\begin{aligned}\n\\gamma(0) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(2) + \\ldots + \\phi_p \\gamma(p) \\\\\n\\gamma(1) & = \\phi_1 \\gamma(0) + \\phi_2 \\gamma(1) + \\ldots + \\phi_p \\gamma(p-1) \\\\\n\\gamma(2) & = \\phi_1 \\gamma(1) + \\phi_2 \\gamma(0) + \\ldots + \\phi_p \\gamma(p-2) \\\\\n\\vdots \\\\\n\\gamma(p) & = \\phi_1 \\gamma(p-1) + \\phi_2 \\gamma(p-2) + \\ldots + \\phi_p \\gamma(0) \\\\\n\\end{aligned}\n\nwhere \\gamma(k) is the sample autocorrelation function at lag k. The Yule-Walker equations can be solved using matrix algebra to obtain the estimates of the AR parameters \\phi_1, \\phi_2, \\ldots, \\phi_p.\n\n\n2.8 Wold’s theorem - (extra curricular) circa 1939\nIn the 1920 Yule and Eugen Slutsky were researching time series and they came up with two different ways to represent a time series.\n\nYule’s researches led to the notion of the autoregressive scheme. \n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t}\n\\end{aligned}\n\\tag{4}\nSlutsky’s researches led to the notion of a moving average scheme. \n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{5}\n\nwe can use the two schemes together and get the ARMA(p,q) model:\n\n\\begin{aligned}\nY_{t} & = \\sum _{j=1}^{p} \\phi _{j} Y_{t-j} + u_{t} + \\sum _{j=0}^{q} \\theta _{j} u_{t-j}\n\\end{aligned}\n\\tag{6}\nwhere:\nThe following is extracted from: the wikipedia at https://en.wikipedia.org/wiki/Wold%27s_theorem\nWold’s decomposition AKA called the Wold representation theorem states that:\n\nEvery covariance-stationary time series Y_{t} can be written as the sum of two time series, one deterministic and one stochastic.\n\nFormally:\n\n\\begin{aligned}\nY_{t} & =\\sum _{j=0}^{\\infty }  \\underbrace{b_{j}\\epsilon _{t-j}}_{\\text{stochastic}} + \\underbrace{\\eta _{t}}_{\\text{deterministic}} \\\\\n&= \\sum _{j=0}^{\\infty } b_{j}\\epsilon _{t-j} + \\phi_{j} y_{t-j}\n\\end{aligned}\n\nwhere:\n\n{Y_{t}} is the time series being considered,\n{\\epsilon _{t}} is an white noise sequence called innovation process that acts as an input to the linear filter {\\{b_{j}\\}}.\n{b} is the possibly infinite vector of moving average weights (coefficients or parameters)\n{\\eta _{t}} is a “deterministic” time series, in the sense that it is completely determined as a linear combination of its past values It may include “deterministic terms” like sine/cosine waves of {t}, but it is a stochastic process and it is also covariance-stationary, it cannot be an arbitrary deterministic process that violates stationarity.\n\nThe moving average coefficients have these properties:\n\nStable, that is, square summable \\sum _{j=1}^{\\infty } \\mid b_{j}|^{2} &lt; \\infty\nCausal (i.e. there are no terms with j &lt; 0)\nMinimum delay\nConstant (b_j independent of t)\nIt is conventional to define b_0=1\n\nAny stationary process has this seemingly special representation. Not only is the existence of such a simple linear and exact representation remarkable, but even more so is the special nature of the moving average model.\nThis result is used without stating its name in the course when we are show the AR(p) representation in terms of moving averages.",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Introductions to time series analysis and the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L00.html#kalman-filter-1960",
    "href": "C4-L00.html#kalman-filter-1960",
    "title": "Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "3 Kalman Filter (1960)",
    "text": "3 Kalman Filter (1960)\n\n\\begin{aligned}\nx_{t} & = F_{t} x_{t-1} + G_{t} u_{t} + w_{t} && \\text{(transition equation)} \\\\\ny_{t} & = H_{t} x_{t} + v_{t} && \\text{(observation equation)}\n\\end{aligned}\n\\tag{7}\nwhere:\n\nx_{t} is the state vector at time t,\nF_{t} is the state transition matrix,\nG_{t} is the control input matrix,\nu_{t} is the control vector,\nw_{t} is the process noise vector,\ny_{t} is the observation vector at time t,\nH_{t} is the observation matrix,\nv_{t} is the observation noise vector.\n\nThe Kalman filter is a recursive algorithm that estimates the state of a linear dynamic system from a series of noisy observations. The Kalman filter is based on a linear dynamical system model that is defined by two equations: the state transition equation and the observation equation. The state transition equation describes how the state of the system evolves over time, while the observation equation describes how the observations are generated from the state of the system. The Kalman filter uses these two equations to estimate the state of the system at each time step, based on the observations received up to that time step. This could be implemented in real time in the 1960s and was used in the Apollo missions.\nThe Extended Kalman Filter (EKF) is an extension of the Kalman filter that can be used to estimate the state of a nonlinear dynamic system. The EKF linearizes the nonlinear system model at each time step and then applies the Kalman filter to the linearized system. The EKF is an approximation to the true nonlinear system, and its accuracy depends on how well the linearized system approximates the true system.\n\n3.1 Box Jenkins Method (1970)\nsee Box Jenkins Method\nA five step process for identifying, selecting and assessing ARMA (and similar) models.\n\nThere are three courses on Stochastic Processes on MIT OCW that I found useful:\n\nIntroduction to Stochastic Processes\nDiscrete Stochastic Processes\nhas lecture videos and notes\npoisson processes\nAdvanced Stochastic Processes\nmartingales\nito calculus",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Introductions to time series analysis and the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L00.html#bayesian-time-series-bibliography",
    "href": "C4-L00.html#bayesian-time-series-bibliography",
    "title": "Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "4 Bayesian Time Series Bibliography",
    "text": "4 Bayesian Time Series Bibliography\nWe start with some books from the course, I collected here both the recommended books and some others that I found useful.\n\n4.1 Time Series: Modeling, Computation, and Inference\nc.f. (Prado, Ferreira, and West 2023)\n - Title:Time Series: Modeling, Computation, and Inference - ISBN:9781032040042, 1032040041 - Page count:452 - Published:September 2023 - Format:Paperback - Publisher:CRC Press - Authors: Raquel Prado, Marco A. R. Ferreira, Mike West\n(Prado, Ferreira, and West 2023) “Time Series: Modeling, Computation, and Inference” by course instructor Raquel Prado. This book, now in its second edition is a comprehensive introduction to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nWhile learning this course I found some of the material harder to follow than I expected. The books helped to clarify definitions and so on however the book is\nrather comprehensive and mathematically advanced unlike some other books on statistics.\nThe teacher frequently point out that many aspects of Times series and are beyond the scope of the course. Yet this book covers much more ground like unequally spaced time series and vector valued time series.\nFor example we look at EKG data which the authors have been working on for years. However we look at it in this course in terms of a univariate time series while in reality EKG is usually sampled at 12 sites simultaneously yielding a multi-variate time series.\nOnce this course is done I will probably want to dive deeper into the subject and try to devote more time to other models in the book.\n\n\n\n4.2 Bayesian Forecasting and Dynamic Models\nc.f. (West and Harrison 2013)\n - Title:Bayesian Forecasting and Dynamic Models - ISBN:9781475770971, 1475770979 - Page count:682 - Published:March 17, 2013 - Format:Paperback - Publisher:Springer New York - Author:Mike West, Jeff Harrison\n(West and Harrison 2013) “Bayesian Forecasting and Dynamic Models” by Mike West and Jeff Harrison. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian forecasting and dynamic models. The following is the description from the publisher:\n\nThe use of dynamic models in the forecasting of time series data has a long history, with the development of autoregressive integrated moving average (ARIMA) models and state space models. However, the use of Bayesian methods in the development of dynamic models is a relatively recent development. This book provides a comprehensive introduction to the use of Bayesian methods in the development of dynamic models for forecasting time series data. The book covers a wide range of topics, including the use of dynamic models in the analysis of time series data, the use of Bayesian methods in the development of dynamic models, and the use of dynamic models in the forecasting of time series data.\n\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n\n\n\n4.3 Practical Time Series Analysis\nc.f. (Nielsen 2019)\n - Title:Practical Time Series Analysis: Prediction with Statistics and Machine Learning - ISBN:1492041602, 9781492041603 - Page count:504 - Published:2019 - Format:Paperback - Publisher:O’Reilly Media, Inc.\n\n(Nielsen 2019) “Practical Time Series Analysis: Prediction with Statistics and Machine Learning” by Aileen Nielsen. Is a good resource for parctionars getting started with time series analysis. I also recommend any videos by Aileen Nielsen on the subject.\n\n\nPractical Times Series Analysis by Aileen Nielsen is a good book for beginners. It is a practical guide to time series analysis and covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for beginners in statistics, computer science, and related fields.\nTime series data analysis is increasingly important due to the massive production of such data through the internet of things, the digitalization of healthcare, and the rise of smart cities. As continuous monitoring and data collection become more common, the need for competent time series analysis with both statistical and machine learning techniques will increase.\nCovering innovations in time series data analysis and use cases from the real world, this practical guide will help you solve the most common data engineering and analysis challenges in time series, using both traditional statistical and modern machine learning techniques. Author Aileen Nielsen offers an accessible, well-rounded introduction to time series in both R and Python that will have data scientists, software engineers, and researchers up and running quickly.\nYou’ll get the guidance you need to confidently:\n\nFind and wrangle time series data\nUndertake exploratory time series data analysis\nStore temporal data\nSimulate time series data\nGenerate and select features for a time series\nMeasure error\nForecast and classify time series with machine or deep learning\nEvaluate accuracy and performance\n\n\n\n\n4.3.1 “Machine Learning: A Bayesian and Optimization Perspective” by Sergios Theodoridis.\nc.f. (Theodoridis 2015)\n - Title:Machine Learning: A Bayesian and Optimization Perspective - ISBN:0128015225, 9780128015223 - Page count:1062 - Published:2015 - Format:Hardcover - Publisher:Academic Press - Authors: Sergios Theodoridis\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks like a good book on machine learning. The following is the description from the publisher:\n\nThis tutorial text gives a unifying perspective on machine learning by covering both probabilistic and deterministic approaches -which are based on optimization techniques - together with the Bayesian inference approach, whose essence lies in the use of a hierarchy of probabilistic models. The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts.\nThe book builds carefully from the basic classical methods to the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models.\n\nAll major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods.\nThe latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling.\nCase studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied.\nMATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code.\n\n\n\n\n\n4.3.2 Statistical Analysis in Climate Research\nc.f.(Storch and Zwiers 2002)\n - Title:Statistical Analysis in Climate Research - ISBN:1139425099, 9781139425094 - Page count:484 - Published:2002 - Format:Paperback - Publisher:Cambridge University Press - Authors: Hans von Storch, Francis W. Zwiers\nI came across this book while looking into the Durban-Levinson recursion and the Yule-Walker equations. So far I haven’t had time to read it but it looks promising. Here is the description from the publisher:\n\nClimatology is, to a large degree, the study of the statistics of our climate. The powerful tools of mathematical statistics therefore find wide application in climatological research. The purpose of this book is to help the climatologist understand the basic precepts of the statistician’s art and to provide some of the background needed to apply statistical methodology correctly and usefully. The book is self contained: introductory material, standard advanced techniques, and the specialised techniques used specifically by climatologists are all contained within this one source. There are a wealth of real-world examples drawn from the climate literature to demonstrate the need, power and pitfalls of statistical analysis in climate research. Suitable for graduate courses on statistics for climatic, atmospheric and oceanic science, this book will also be valuable as a reference source for researchers in climatology, meteorology, atmospheric science, and oceanography.\n\nHans von Storch is Director of the Institute of Hydrophysics of the GKSS Research Centre in Geesthacht, Germany and a Professor at the Meteorological Institute of the University of Hamburg.\nFrancis W. Zwiers is Chief of the Canadian Centre for Climate Modelling and Analysis, Atmospheric Environment Service, Victoria, Canada, and an Adjunct Professor at the Department of Mathematicw and Statistics of the University of Victoria.\n\n\n\n\n\n\n4.4 Bayesian Modeling and Computation in Python\nc.f. (Martin, Kumar, and Lao 2021)\n This is a great resource for translating what we learned to Python. The book is available at Bayesian Modeling and Computation in Python\nI found the chapter on state space modeling and the Kalman filter particularly useful. The book is a great resource for translating what we learned in the course to Python. The book is suitable for undergraduate students in statistics, computer science, and related fields.\n\n\n\n4.5 Bayesian Data Analysis\nc.f. (Gelman et al. 2013)\n - Title:Bayesian Data Analysis - ISBN:1439840954, 9781439840955 - Page count:675 - Published:2013 - Format:Hardcover - Publisher:Chapman and Hall/CRC - Authors: Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, Donald B. Rubin\n(Gelman et al. 2013) “Bayesian Data Analysis” is probably the most famous book on Bayesian statistics. This book is a classic text on Bayesian statistics and covers a wide range of topics in Bayesian data analysis. Although this is not a time series book, the authors have been intersted in the domain of political election prediction and have used time series data in their research and some of that is covered in the book’s examples.\n\nAudience: The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nAn electronic version of the third eddition book is available at Bayesian Data Analysis\n\n\n\n\n4.6 Introductory Time Series with R c.f. (Cowpertwait and Metcalfe 2009)\n (Cowpertwait and Metcalfe 2009) “Introductory Time Series with R” by Cowpertwait and Metcalfe, and the second is\n\nYearly global mean temperature and ocean levels, daily share prices, and the signals transmitted back to Earth by the Voyager space craft are all examples of sequential observations over time known as time series. This book gives you a step-by-step introduction to analysing time series using the open source software R. Each time series model is motivated with practical applications, and is defined in mathematical notation. Once the model has been introduced it is used to generate synthetic data, using R code, and these generated data are then used to estimate its parameters. This sequence enhances understanding of both the time series model and the R function used to fit the model to data. Finally, the model is used to analyse observed data taken from a practical application. By using R, the whole procedure can be reproduced by the reader.\nAll the data sets used in the book are available on the website at datasets\nThe book is written for undergraduate students of mathematics, economics, business and finance, geography, engineering and related disciplines, and postgraduate students who may need to analyse time series as part of their taught programme or their research.\n\nPaul Cowpertwait is an associate professor in mathematical sciences (analytics) at Auckland University of Technology with a substantial research record in both the theory and applications of time series and stochastic models.\nAndrew Metcalfe is an associate professor in the School of Mathematical Sciences at the University of Adelaide, and an author of six statistics text books and numerous research papers. Both authors have extensive experience of teaching time series to students at all levels.\n\n\n\n\n\n4.7 Analysis of Integrated and Cointegrated Time Series with R c.f.\n (Pfaff 2008) “Analysis of Integrated and Cointegrated Time Series with R” by Bernhard Pfaff. Its been a long time since I read this book and rather than do it an injustice I direct you to the review by Dirk Eddelbuettel in the Journal of Statistical Software is avaoilable at review. Or the book’s website at Analysis of Integrated and Cointegrated Time Series with R.\n\nThe analysis of integrated and co-integrated time series can be considered as the main methodology employed in applied econometrics. This book not only introduces the reader to this topic but enables him to conduct the various unit root tests and co-integration methods on his own by utilizing the free statistical programming environment R. The book encompasses seasonal unit roots, fractional integration, coping with structural breaks, and multivariate time series models. The book is enriched by numerous programming examples to artificial and real data so that it is ideally suited as an accompanying text book to computer lab classes.\nThe second edition adds a discussion of vector auto-regressive, structural vector auto-regressive, and structural vector error-correction models.\n\n\n\n4.8 Bayesian Analysis of Time Series by Lyle D. Broemeling\n(Broemeling 2019)\n\ncovers pretty much the material in the course.\nuses winbugs and R\nmodels considered include\n\nwhite noise\nWiener process (random walk)\nAR(p)\nARMA(p,q)\nARIMA\nRegression\nRegression with MA and Seasonal effects\nDLM\nTAR\n\n\n\n\n4.9 Bayesian Inference for Stochastic Processes by Lyle D. Broemeling\n - The code for R and WinBUGS is available at code - IT is based on WinBUGS which is a bit dated but still useful. - This books seems a bit dated but it covers a lot of the material in the course.\n\n\n4.10 Dynamic Time Series Models using R-INLA: An Applied Perspective\n(Ravishanker, Raman, and Soyer 2022) is a new book that covers the use of the R-INLA package for fitting dynamic time series models. The book is available online gitbook\n\n\n\n\nDynamic Time Series Models using R-INLA: An Applied Perspective\n\nThis is a very interesting book which covers a new approach to fitting time series models using the R-INLA package. INLA stands for Integrated Nested Laplace Approximation and is a method for fitting Bayesian models that is faster than MCMC. The book covers a wide range of topics in time series modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\n\n\n4.11 Statistics for Spatio-Temporal Data\n\n\n\n\nStatistics for Spatio-Temporal Data\n\n(Cressie and Wikle 2011) is a book I came across when I tried to understand the NDLM model. NLDMs have a two level hierarcial form and it seems possible to extend this formulation will non-normaly distributed shocks and possibly non linear relation. In this book the authors take an interesting approch of not only looking at NDLM as a heirarchical model but they also extend the time series model into a spatio-temporal model.\nThis book is a comprehensive introduction to the analysis of spatio-temporal data and covers a wide range of topics in spatio-temporal statistics. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Introductions to time series analysis and the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L00.html#bayesian-analysis-of-stochastic-process-models",
    "href": "C4-L00.html#bayesian-analysis-of-stochastic-process-models",
    "title": "Week 0: Introductions to time series analysis and the AR(1) process",
    "section": "5 Bayesian Analysis of Stochastic Process Models",
    "text": "5 Bayesian Analysis of Stochastic Process Models\nc.f. (Rios Insua, Ruggeri, and Wiper 2012)\n David Rios Insua, Fabrizio Ruggeri, Michael P. Wiper\nThis book is a comprehensive introduction to the analysis of stochastic process models using Bayesian methods. The book covers a wide range of topics in stochastic process modeling, computation, and inference. The book is suitable for graduate students and researchers in statistics, computer science, and related fields.\nThere are also a number of books on NDLM that I’ve come accross:\n\nDynamic linear model tutorial matlab\nForecasting, structural time series and the Kalman filter by Andrew C. Harvey\nDynamic Linear Models with R by Giovanni Petris Sonia Petrone Patrizia Campagnoli\nTime Series Analysis by State Space Methods by J. Durbin and S.J. Koopman",
    "crumbs": [
      "4. Time series Models",
      "Week 0: Introductions to time series analysis and the AR(1) process"
    ]
  },
  {
    "objectID": "C2-L04.html",
    "href": "C2-L04.html",
    "title": "Metropolis-Hastings",
    "section": "",
    "text": "Metropolis-Hastings (M-H) is an algorithm that allows us to sample from a generic probability distribution (which we will call the target distribution), even if we do not know the normalizing constant. To do this, we construct and sample from a Markov chain whose stationary distribution is the target distribution. It consists of picking an arbitrary starting value and iteratively accepting or rejecting candidate samples drawn from another distribution, one that is easy to sample.\n\n\n\n\n\n\nImportantWhy use M-H or MCMC?\n\n\n\nWe will use M-H or other MCMC methods if there is no easy way to simulate independent draws from the target distribution. This can be due to non-conjugate priors, challenges in evaluating the normalizing constant or multiple explanatory variables.",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#the-metropolis-hastings-algorithm",
    "href": "C2-L04.html#the-metropolis-hastings-algorithm",
    "title": "Metropolis-Hastings",
    "section": "",
    "text": "Metropolis-Hastings (M-H) is an algorithm that allows us to sample from a generic probability distribution (which we will call the target distribution), even if we do not know the normalizing constant. To do this, we construct and sample from a Markov chain whose stationary distribution is the target distribution. It consists of picking an arbitrary starting value and iteratively accepting or rejecting candidate samples drawn from another distribution, one that is easy to sample.\n\n\n\n\n\n\nImportantWhy use M-H or MCMC?\n\n\n\nWe will use M-H or other MCMC methods if there is no easy way to simulate independent draws from the target distribution. This can be due to non-conjugate priors, challenges in evaluating the normalizing constant or multiple explanatory variables.",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#the-m-h-algorithm",
    "href": "C2-L04.html#the-m-h-algorithm",
    "title": "Metropolis-Hastings",
    "section": "0.2 The M-H Algorithm",
    "text": "0.2 The M-H Algorithm\n Let’s say we wish to produce samples from a target distribution p(\\theta) \\propto g(\\theta), where we don’t know the normalizing constant (since \\int g(\\theta)d\\theta is hard or impossible to compute), so we only have g(\\theta), the unnormalized joint probability to work with. The Metropolis-Hastings algorithm proceeds as follows.\n\nSelect an initial value \\theta_0.\nFor i=1,\\dots,m repeat the following steps:\n\nDraw a candidate sample \\theta^∗ from a proposal distribution  q(\\theta^* \\mid \\theta_{i−1}) .\nCompute the ratio \\alpha = \\frac{g(\\theta^*) / q(\\theta^* \\mid \\theta_{i-1}) }{g(\\theta_{i-1}) / q(\\theta_{i-1} \\mid \\theta^*)} = \\frac{g(\\theta^*)q(\\theta_{i-1} \\mid \\theta^*)}{g(\\theta_{i-1})q(\\theta^* \\mid \\theta_{i-1})}\n\nIf \\alpha\\ge 1, then accept \\theta^∗ and set \\theta_i=\\theta^∗.\nIf 0&lt;\\alpha&lt;1:\n\naccept \\theta^∗ and set \\theta_i=\\theta^∗ with probability \\alpha,\nreject \\theta^∗ and set \\theta_i=\\theta_{i−1} with probability 1−\\alpha.\n\n\n\n\nproposal distribution q\n\n\n\n\n\nImportantCorrection to the proposal distribution\n\n\n\nSteps 2.b and 2.c act as a correction  since the proposal distribution is not the target distribution. At each step in the chain, we draw a random candidate value of the parameter and decide whether to “move” the chain there or remain where we are. If the proposed move to the candidate is “advantageous,” (\\alpha \\ge 1) we “move” there and if it is not “advantageous,” we still might move there, but only with probability \\alpha. Since our decision to “move” to the candidate only depends on where the chain currently is, this is a Markov chain.\n\n\ncorrection",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#proposal-distribution-q",
    "href": "C2-L04.html#proposal-distribution-q",
    "title": "Metropolis-Hastings",
    "section": "0.3 Proposal distribution q",
    "text": "0.3 Proposal distribution q\nOne careful choice we must make is the candidate generating distribution q(\\theta^∗\\mid\\theta_{i−1}). It may or may not depend on the previous iteration’s value of \\theta.\n\n\n\n\n\n\nImportantIndependent Metropolis-Hastings\n\n\n\nThe simpler case is when the proposal distribution q does not depend on the previous value. We then write it as q(\\theta^∗). This arises if it is always the same distribution. We call this case independent Metropolis-Hastings. If we use independent M-H, q(\\theta) should be as similar as possible to p(\\theta).\n\n\n\n\n\n\n\n\nImportantRandom-Walk Metropolis-Hastings\n\n\n\nIn the more general case, the proposal distribution takes the form q(\\theta^∗\\mid\\theta_{i−1}) with dependence on the previous iteration, is Random-Walk Metropolis-Hastings. Here, the proposal distribution is centered on \\theta_{i−1}.\nFor instance, it might be a Normal distribution with mean \\theta_{i−1}. Because the Normal distribution is symmetric, this example comes with another advantage: q(\\theta^* \\mid \\theta_{i−1})=q(\\theta_{i−1}∣\\theta^*) causing it to cancel out when we calculate \\alpha.\nThus, in Random-Walk M-H where the candidate is drawn from a Normal with mean \\theta_{i−1} and constant variance, the acceptance ratio is simply \\alpha=g(\\theta^∗)/g(\\theta_{i−1}).",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#acceptance-rate-α",
    "href": "C2-L04.html#acceptance-rate-α",
    "title": "Metropolis-Hastings",
    "section": "0.4 Acceptance rate α",
    "text": "0.4 Acceptance rate α\nClearly, not all candidate draws are accepted, so our Markov chain sometimes “stays” where it is, possibly for many iterations. How often you want the chain to accept candidates depends on the type of algorithm you use. If you approximate p(\\theta) with q(\\theta^∗) and always draw candidates from that, accepting candidates often is good; it means q(\\theta^∗) is approximating p(\\theta) well. However, you still may want q to have a larger variance than p and see some rejection of candidates as an assurance that q is covering the space well.\nAs we will see in coming examples, a high acceptance rate for the Random-Walk Metropolis-Hastings sampler is not a good thing. If the random walk is taking too small of steps, it will accept often but will take a very long time to fully explore the posterior. If the random walk is taking too large of steps, many of its proposals will have a low probability and the acceptance rate will be low, wasting many draws. Ideally, a random walk sampler should accept somewhere between 23% and 50% of the candidates proposed.\nIn the next segment, we will see a demonstration of this algorithm used in a discrete case, where we can show mathematically that the Markov chain converges to the target distribution. In the following segment, we will demonstrate coding a Random-Walk Metropolis-Hastings algorithm in R to solve one of the problems from the end of Lesson 2.",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#demonstration-of-a-discrete-case",
    "href": "C2-L04.html#demonstration-of-a-discrete-case",
    "title": "Metropolis-Hastings",
    "section": "0.5 Demonstration of a Discrete case",
    "text": "0.5 Demonstration of a Discrete case\n\n\n\n\nMCMC Coin Flip Example\n\nThe following segment is by Herbert Lee, a professor of statistics and applied mathematics at the University of California, Santa Cruz.\nThe following is a demonstration of using Markov chain Monte Carlo, used to estimate posterior probabilities in a simplified case, where we can actually work out the correct answer in closed form. We demonstrate that the Metropolis-Hastings algorithm is indeed working, and giving us the right answer.\nIf you recall from the previous course, the example where your brother or maybe your sister, has a loaded coin that you know will come up heads 70% of the time. But they come to you with some coin, you’re not sure if it’s the loaded coin or a fair coin, and they want to make a bet with you. And you have to figure out which coin this is.\nSuppose you have a prior probability that it’s a 60% probability, that they’ll bring a loaded coin to you. They let you flip it five times, and you get two heads and three tails.\nAnd then you need to figure out, what’s your posterior probability that this is a loaded coin.\nOur unknown parameter \\theta, can either take the values fair or loaded.\n\n\\theta = \\{\\text{fair, loaded} \\}\n\\tag{1}\nOur prior for \\theta is the probability of theta equals loaded, is 0.6.\n\nP(\\theta=\\text{loaded})=0.6 \\qquad  \\text{(prior)}\n\\tag{2}\nOur likelihood will follow a Binomial distribution, depending upon the value of \\theta.\n\nf(x\\mid \\theta) = {5 \\choose x} \\frac{1}{2}^5\\mathbb{I}_{\\theta=\\text{fair}}+  {5 \\choose x} (.7)^x(.3)^{5-x}\\mathbb{I}_{\\theta=\\text{loaded}}  \\qquad  \\text{(likelihood)}\n\\tag{3}\nOur posterior then, we can look at posterior for theta, given that we saw x=2 equals two heads, posterior is the likelihood times the prior, divided by a normalizing constant.\n\n  \\begin{aligned}\n    f(\\theta \\mid X=2) &=\n      \\frac{ \\frac{1}{2}^5(0.4)\\mathbb{I}_{(\\theta=\\text{fair})} + (.7)^2(.3)^{3}(.6)\\mathbb{I}_{(\\theta=\\text{loaded})}}\n           { \\frac{1}{2}^5(0.4) + (.7)^2(.3)^{3}(.6)}  \n  \\\\&=\\frac{ 0.0125 \\mathbb{I}_{(\\theta=\\text{fair})} + 0.00794 \\mathbb{I}_{(\\theta=\\text{loaded})}}\n           { 0.0125 + 0.00794}\n  \\\\&= 0.612 \\mathbb{I}_{(\\theta=\\text{fair})} + 0.388 \\mathbb{I}_{(\\theta=\\text{loaded})}\n  \\qquad  \\text{(posterior) }\n  \\end{aligned}\n\\tag{4}\nIn this case, we can work out the binomial and our prior. And we see that we get these expressions at the end. We get posterior probability of \\theta is loaded given that we saw two heads, to be 0.388.\n\n\\therefore p(\\theta=\\text{loaded}\\mid X=2) = 0.388 \\qquad  \\text{(posterior conditional probability ) }\n\\tag{5}\nThis is all review from the previous course so far.\nBut suppose we had a more complicated problem, where we couldn’t work this all out in closed form? We’ll know the likelihood and the prior, but we may not be able to get this normalizing constant. Can we instead do this by simulation? And indeed, yes we can.\nWe can do this with Markov chain Monte Carlo. In particular, using the Metropolis-Hastings algorithm. What we’ll do is, we’ll set up a Markov chain whose equilibrium distribution has this posterior distribution. So we’ll consider a Markov chain with two states, theta equals fair and theta equals loaded. And we’ll allow the chain to move between those two states, with certain transition probabilities. We set this up using this using the Metropolis-Hastings algorithm.\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\nSo under the Metropolis-Hastings algorithm, step one is we start at an arbitrary location. And in this case, we can\n\nstart at either \\theta \\ne \\text{fair}, or \\theta \\ne \\text{loaded}.\n\nIt does not really matter where we start, we’ll be moving back and forth and we’re going to look at the long-term running average, the long-term simulations.\nSo the key is we’ll be simulating.\n\nRun m simulations and in each iteration, we’ll propose a candidate and either accept it or reject it.\n\n\nSo the first part is we’re proposing a new candidate. We’ll call this candidate \\theta^*, and we’re going to propose it be the other state compared to where we are now. Where we are now is \\theta_{i-1}, and so we’ll propose to move to \\theta^*.\n\nIf our current state is fair, we’ll propose \\theta^*=\\text{loaded}.\nIf our current state is loaded, we’ll propose \\theta^*=\\text{fair}.\n\n\nwhat’s our acceptance probability alpha?\nThe general form for \\alpha is:\n\n\\begin {aligned}\n\\alpha &= {\n            { g(\\theta^*)     / q(\\theta^*     \\mid  \\theta_{i-1}) }\n      \\over {g(\\theta_{i-1}) / q(\\theta_{i-1} \\mid  \\theta^*)     }\n      }\n\\\\      &= {\n            { f(x=2 \\mid \\theta^*) f(\\theta^*)     / 1 }\n      \\over { f(x=2 \\mid \\theta_{i-1})f(\\theta_{i-1}) / 1    }\n} \\qquad \\text {(sub. g,q)}\n\\end{aligned}\n\\tag{6}\nIn this case,\n\ng() is our un-normalized likelihood times prior\nq(), the proposal distribution, is, in this case, since we always accept the opposite state deterministically i.e. \\theta^*=\\neg \\theta{i_1} with P=1\nIf \\theta^* = \\text{loaded} \\implies \\alpha = {0.00794 \\over 0.0125}=0.635\nIf \\theta^* = \\text{fair} \\implies \\alpha = { 0.0125 \\over 0.00794}=1.574\n\n\n\n\n\nThe Metropolis-Hastings Algorithm\n\nGiven these probabilities, we then can do the acceptance or rejection step.\n\n\\begin{cases}\n\\text{ accept } \\theta^* \\text { and set } \\theta_i=\\text{fair} & \\text{If } \\theta^*=\\text{fair,  } \\alpha&gt;1\n\\\\ \\begin {cases}\n   \\text{ accept } \\theta^* \\text{  and set } \\theta_i=\\text{loaded} &  \\text{ With probability } 0.635\n\\\\ \\text{ reject } \\theta^* \\text{ and set } \\theta_i=\\text{fair}     &  \\text{ Otherwise }\n\\end{cases} & \\text{If } \\theta^*=\\text{loaded, } \\alpha=.635\n\\end{cases}\n\nIf the \\theta^*=\\text{loaded} \\implies \\alpha=0.635. So we accept theta star with probability 0.635. And if we accept it. Set \\theta_i=\\text{loaded} Otherwise, set \\theta_i = \\theta_{i- 1}, if we do not accept, it stays in that same old fair state.\nWe can draw this out as a Markov chain with two states, Fair and ‘loaded’. If it’s in the ‘loaded’ state, it will move with probability one to the fair state. If it’s in the fair state, it will move with a probability of 0.635 to the ‘loaded’ state. And with a probability of 0.365 it will stay in the fair state.\n\n\n\n\nstate diagram\n\nAnd so here’s a little diagram for this Markov chain with two states. In which case it will move back and forth with certain probabilities.\nThus, if we wanted to find our posterior probability , f(\\theta=\\text{loaded} \\mid x=2). We can simulate from this Markov chain using these transition probabilities. And observe the fraction of time that it spends in the state theta equals ‘loaded’. And this gives us a good estimate of the posterior probability that it’s the ‘loaded’ coin. In this particular case, we can also show that this gives us the theoretical right answer.\nIf you’ve seen a little bit of the theory of Markov chains. We can say that a Markov chain with transition probability capital P, has stationary distribution \\Pi.\n\n\\pi P = \\pi \\qquad \\text{(def. stationary distribution)}\n\\tag{7}\nHere we have a transition probability matrix P, where we can think about ‘fair’ and ‘loaded’. Moving from the ‘fair’ state, remaining in the ‘fair’ state happens with a probability of 0.365 and it moves from ‘fair’ to ‘loaded’, with a probability of 0.635. If it’s in the ‘loaded’ state, we’ll move to the ‘fair’ state with probability one, and it will stay in the ‘loaded’ state with probability 0.\n\nP=\\begin{bmatrix}\n   0.365 & 0.635\n\\\\ 1 & 0\n\\end{bmatrix}\n\nIn this case, we want our stationary distribution to be the posterior probabilities.\n\n\\Pi=\\begin{bmatrix}\n0.612 & 0.388 \\\\\n\\end{bmatrix}\n\nWhich you can recall are 0.612 of being ‘fair’ and 0.388 of being ‘loaded’. And so indeed, if you do just the minimal amount of matrix algebra, you can see that 0.612, 0.388 Multiplied by this matrix, 0.365, 0.635, 1, 0, does indeed give you 0.612 and 0.388, at least to within rounding error.\n\n\\begin{aligned}\n  \\Pi P &=\n  \\begin{bmatrix} 0.612 & 0.388 \\end{bmatrix}\n  \\begin{bmatrix} 0.365 & 0.635 \\\\ 1 & 0 \\end{bmatrix}\n  \\\\&= \\begin{bmatrix}0.612 & 0.388 \\end{bmatrix}\n  \\\\&= \\Pi\n\\end{aligned}\n\\tag{8}\nThus in this case we can see, that we do get the correct stationary distribution for the Markov chain using the Metropolis–Hastings algorithm. And that when we simulate it, we do get correct estimates then of the posterior probabilities.\nThis is a nice simple example where we can work out the posterior probabilities in closed form. We don’t need to run Markov chain Monte Carlo. But this method is very powerful because all we need is to be able to evaluate the likelihood and the prior, we don’t need to evaluate the full posterior and get that normalizing constant. And so this applies to a much broader range of more complicated problems. Where we can use Markov chain Monte Carlo to simulate, to be able to get these probabilities. We’ll make good use of this in the rest of this course.",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#random-walk-with-normal-likelihood-t-prior",
    "href": "C2-L04.html#random-walk-with-normal-likelihood-t-prior",
    "title": "Metropolis-Hastings",
    "section": "0.6 Random walk with Normal likelihood, t prior",
    "text": "0.6 Random walk with Normal likelihood, t prior\nRecall the model from the last segment of Lesson 2 where the data are the percent change in total personnel from last year to this year for n=10 companies. We used a normal likelihood with known variance and t distribution for the prior on the unknown mean. Suppose the values are y=(1.2,1.4,−0.5,0.3,0.9,2.3,1.0,0.1,1.3,1.9). Because this model is not conjugate, the posterior distribution is not in a standard form that we can easily sample. To obtain posterior samples, we will set up a Markov chain whose stationary distribution is this posterior distribution.\nRecall that the posterior distribution is\n\np(\\mu \\mid y_1, \\ldots, y_n) \\propto \\frac{\\exp[ n ( \\bar{y} \\mu - \\mu^2/2)]}{1 + \\mu^2}\n\nThe posterior distribution on the left is our target distribution and the expression on the right is our g(\\mu).\nThe first thing we can do in R is write a function to evaluate g(\\mu). Because posterior distributions include likelihoods (the product of many numbers that are potentially small), g(\\mu) might evaluate to such a small number that to the computer, it is effectively zero. This will cause a problem when we evaluate the acceptance ratio \\alpha. To avoid this problem, we can work on the log scale, which will be more numerically stable. Thus, we will write a function to evaluate\n\n\\log(g(\\mu)) = n ( \\bar{y} \\mu - \\mu^2/2) - \\log(1 + \\mu^2)\n\nThis function will require three arguments, \\mu, \\bar{y}, and n.\n\n\nCode\nlg = function(mu, n, ybar) {\n  mu2 = mu^2\n  n * (ybar * mu - mu2 / 2.0) - log(1 + mu2)\n}\n\n\nNext, let’s write a function to execute the Random-Walk Metropolis-Hastings sampler with Normal proposals.\n\n\nCode\nmh = function(n, ybar, n_iter, mu_init, cand_sd) {\n  ## Random-Walk Metropolis-Hastings algorithm\n  \n  ## Step 1, initialize\n  mu_out = numeric(n_iter)\n  accpt = 0\n  mu_now = mu_init\n  lg_now = lg(mu=mu_now, n=n, ybar=ybar)\n  \n  ## Step 2, iterate\n  for (i in 1:n_iter) {\n    ## step 2a\n    mu_cand = rnorm(n=1, mean=mu_now, sd=cand_sd) # draw a candidate\n    \n    ## Step 2b\n    lg_cand = lg(mu=mu_cand, n=n, ybar=ybar) # evaluate log of g with the candidate\n    lalpha = lg_cand - lg_now # log of acceptance ratio\n    alpha = exp(lalpha)\n    \n    ## step 2c\n    u = runif(1) # draw a uniform variable which will be less than alpha with probability min(1, alpha)\n    if (u &lt; alpha) { # then accept the candidate\n      mu_now = mu_cand\n      accpt = accpt + 1 # to keep track of acceptance\n      lg_now = lg_cand\n    }\n    \n    ## collect results\n    mu_out[i] = mu_now # save this iteration's value of mu\n  }\n  \n  ## return a list of output\n  list(mu=mu_out, accpt=accpt/n_iter)\n}\n\n\nNow, let’s set up the problem.\n\n\nCode\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nybar = mean(y)\nn = length(y)\nhist(y, freq=FALSE, xlim=c(-1.0, 3.0)) # histogram of the data\ncurve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\npoints(y, rep(0,n), pch=1) # individual data points\npoints(ybar, 0, pch=19) # sample mean\n\n\n\n\n\n\n\n\n\nFinally, we’re ready to run the sampler! Let’s use m=1000 iterations and proposal standard deviation (which controls the proposal step size) 3.0, and initial value at the prior median 0.\n\n\nCode\nset.seed(43) # set the random seed for reproducibility\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=3.0)\nstr(post)\n\n\nList of 2\n $ mu   : num [1:1000] -0.113 1.507 1.507 1.507 1.507 ...\n $ accpt: num 0.122\n\n\n\n\nCode\nlibrary(\"coda\")\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nThis last plot is called a trace plot. It shows the history of the chain and provides basic feedback about whether the chain has reached its stationary distribution.\nIt appears our proposal step size was too large (acceptance rate below 23%). Let’s try another.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.05)\npost$accpt\n\n\n[1] 0.946\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nOops, the acceptance rate is too high (above 50%). Let’s try something in between.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.9)\npost$accpt\n\n\n[1] 0.38\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nWhich looks good. Just for fun, let’s see what happens if we initialize the chain at some far-off value.\n\n\nCode\npost = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=30.0, cand_sd=0.9)\npost$accpt\n\n\n[1] 0.387\n\n\n\n\nCode\ntraceplot(as.mcmc(post$mu))\n\n\n\n\n\n\n\n\n\nIt took awhile to find the stationary distribution, but it looks like we succeeded! If we discard the first 100 or so values, it appears like the rest of the samples come from the stationary distribution, our posterior distribution! Let’s plot the posterior density against the prior to see how the data updated our belief about \\mu.\n\n\nCode\npost$mu_keep = post$mu[-c(1:100)] # discard the first 200 samples\nplot(density(post$mu_keep, adjust=2.0), main=\"\", xlim=c(-1.0, 3.0), xlab=expression(mu)) # plot density estimate of the posterior\ncurve(dt(x=x, df=1), lty=2, add=TRUE) # prior for mu\npoints(ybar, 0, pch=19) # sample mean\n\ncurve(0.017*exp(lg(mu=x, n=n, ybar=ybar)), from=-1.0, to=3.0, add=TRUE, col=\"blue\") # approximation to the true posterior in blue\n\n\n\n\n\n\n\n\n\nThese results are encouraging, but they are preliminary. We still need to investigate more formally whether our Markov chain has converged to the stationary distribution. We will explore this in a future lesson.\nObtaining posterior samples using the Metropolis-Hastings algorithm can be time-consuming and require some fine-tuning, as we’ve just seen. The good news is that we can rely on software to do most of the work for us. In the next couple of videos, we’ll introduce a program that will make posterior sampling easy.",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#setup",
    "href": "C2-L04.html#setup",
    "title": "Metropolis-Hastings",
    "section": "1.1 Setup",
    "text": "1.1 Setup\n\n1.1.1 Introduction to JAGS\nThere are several software packages available that will handle the details of MCMC for us. See the supplementary material for a brief overview of options.\nThe package we will use in this course is JAGS (Just Another Gibbs Sampler) by Martyn Plummer. The program is free, and runs on Mac OS, Windows, and Linux. Better yet, the program can be run using R with the rjags and R2jags packages.\nIn JAGS, we can specify models and run MCMC samplers in just a few lines of code; JAGS does the rest for us, so we can focus more on the statistical modeling aspect and less on the implementation. It makes powerful Bayesian machinery available to us as we can fit a wide variety of statistical models with relative ease.\n\n\n1.1.2 Installation and setup\nThe starting place for JAGS users is mcmc-jags.sourceforge.net. At this site, you can find news about the features of the latest release of JAGS, links to program documentation, as well as instructions for installation.\nThe documentation is particularly important. It is available under the files page link in the Manuals folder.\nAlso under the files page, you will find the JAGS folder where you can download and install the latest version of JAGS. Select the version and operating system, and follow the instructions for download and installation.\nOnce JAGS is installed, we can immediately run it from R using the rjags package. The next segment will show how this is done.",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C2-L04.html#modeling-in-jags",
    "href": "C2-L04.html#modeling-in-jags",
    "title": "Metropolis-Hastings",
    "section": "1.2 Modeling in JAGS",
    "text": "1.2 Modeling in JAGS\nThere are four steps to implementing a model in JAGS through R:\n\nSpecify the model.\nSet up the model.\nRun the MCMC sampler.\nPost-processing.\n\nWe will demonstrate these steps with our running example with the data are the percent change in total personnel from last year to this year for n=10 companies. We used a normal likelihood with known variance and t distribution for the prior on the unknown mean.\n\n1.2.1 1. Specify the model\nIn this step, we give JAGS the hierarchical structure of the model, assigning distributions to the data (the likelihood) and parameters (priors). The syntax for this step is very similar to R, but there are some key differences.\n\n\nCode\nlibrary(\"rjags\")\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\nCode\nmod_string = \" model {\n  for (i in 1:n) {\n    y[i] ~ dnorm(mu, 1.0/sig2)\n  }\n  mu ~ dt(0.0, 1.0/1.0, 1.0) # location, inverse scale, degrees of freedom\n  sig2 = 1.0\n} \"\n\n\nOne of the primary differences between the syntax of JAGS and R is how the distributions are parameterized. Note that the normal distribution uses the mean and precision (instead of variance). When specifying distributions in JAGS, it is always a good idea to check the JAGS user manual here in the chapter on Distributions.\n\n\n1.2.2 2. Set up the model\n\n\nCode\nset.seed(50)\ny = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)\nn = length(y)\n\ndata_jags = list(y=y, n=n)\nparams = c(\"mu\")\n\ninits = function() {\n  inits = list(\"mu\"=0.0)\n} # optional (and fixed)\n\nmod = jags.model(textConnection(mod_string), data=data_jags, inits=inits)\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 10\n   Unobserved stochastic nodes: 1\n   Total graph size: 15\n\nInitializing model\n\n\nThere are multiple ways to specify initial values here. They can be explicitly set, as we did here, or they can be random, i.e., list(\"mu\"=rnorm(1)). Also, we can omit the initial values, and JAGS will provide them.\n\n\n1.2.3 3. Run the MCMC sampler\n\n\nCode\nupdate(mod, 500) # burn-in\n\nmod_sim = coda.samples(model=mod, variable.names=params, n.iter=1000)\n\n\nWe will discuss more options to the coda.samples function in coming examples.\n\n\n1.2.4 4. Post-processing\n\n\nCode\nsummary(mod_sim)\n\n\n\nIterations = 1501:2500\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n      0.897235       0.300281       0.009496       0.010676 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n0.3389 0.6840 0.8924 1.0941 1.5151 \n\n\n\n\nCode\nlibrary(\"coda\")\nplot(mod_sim)\n\n\n\n\n\n\n\n\n\nWe will discuss post processing further, including convergence diagnostics, in a coming lesson.",
    "crumbs": [
      "2. Techniques and Models",
      "Metropolis-Hastings"
    ]
  },
  {
    "objectID": "C4-L01.html",
    "href": "C4-L01.html",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "",
    "text": "NoteLearning Objectives\n\n\n\n\n\n\nList the goals of the course\nidentify the basics of the R environment.\nExplain stationary time series processes\nDefine auto-correlation function (ACF) and partial auto-correlation function (PACF) and use R to plot the sample ACF and sample PACF of a time series\nExplain the concepts of differencing and smoothing via moving averages to remove/highlight trends and seasonal components in a time series\nDefine the zero-mean autoregressive process of order one or AR(1) and use R to obtain samples from this type of process\nPerform maximum likelihood estimation for the full and conditional likelihood in an AR(1)\nPerform Bayesian inference for the AR(1) under the conditional likelihood and the reference prior\n\n\n\n\n\n\n\n\n\nObligatory introduction to the course and the instructors.\nRaquel Prado is a professor of statistics in the Baskin School of Engineering at the University of California, Santa Cruz. She was the recipient 2022 Zellner Medal, see Weckerle (2022).\n\n\n\n\n\nIntroduction to R\n\n\n\n\n\nBefore diving into the material here is a brief overview of the notations for timer series.\n\n\n\n\n\n\nTip 1: Notation\n\n\n\n\n\\{y_t\\} - the time series process, where each y_t is a univariate random variable and t are the time points that are equally spaced.\ny_{1:T} or y_1, y_2, \\ldots, y_T - the observed data.\nYou will see the use of ’ to denote the transpose of a matrix,\nand the use of \\sim to denote a distribution.\nunder tildes \\utilde{y} are used to denote estimates of the true values y.\nE matrix of eigenvalues\n\\Lambda = diagonal(\\alpha_1, \\alpha_2, \\ldots , \\alpha_p) is a diagonal matrix with the eigenvalues of \\Sigma on the diagonal.\nJ_p(1) = a p by p Jordan form matrix with 1 on the super-diagonal\n\nalso see (Prado, Ferreira, and West 2023, 2–3)\n\n\n\n\n\n\n\n\nstrong and weak stationarity\n\nStationarity c.f. (Prado, Ferreira, and West 2023, sec. 1.2) is a fundamental concept in time series analysis.\n\n\n\n\n\n\nImportantTL;DR – Stationarity\n\n\n\n\nStationarity\n\n\n\n\nA time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.\n\n\n\nWe make this definition more formal in the definitions of strong and weak stationarity below.\n\n\n\nStationarityStationarity is a key concept in time series analysis. A time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.\n\nDefinition 1 (Strong Stationarity)  Let y_t be a time series. We say that y_t is stationary if the following conditions hold:Strong Stationarity\nLet \\{y_t\\} \\quad \\forall n&gt;0 be a time series and h &gt; 0 be a lag. If for any subsequence the distribution of y_t, y_{t+1}, \\ldots, y_{t+n} is the same as the distribution of y_{t+h}, y_{t+h+1}, \\ldots, y_{t+h+n} we call the series strongly stationary.\n\nAs it’s difficult to verify strong stationarity in practice, we will often use the following weaker notion of stationarity.\n\nDefinition 2 (Weak Stationarity)   The mean, variance, and auto-covariance are constant over time.Weak StationaritySecond-order Stationarity\n\n\\begin{aligned}\n\\mathbb{E}[y_t] &= \\mu \\quad \\forall t \\\\\n\\mathbb{V}ar[y_t] &= \\nu =\\sigma^2 \\quad \\forall t \\\\\n\\mathbb{C}ov[y_t , y_s ] &= γ(t − s)\n\\end{aligned}\n\\tag{1}\n\n\nStrong stationarity \\implies Weak stationarity, but\nThe converse is not true.\nIn this course when we deal with a Gaussian process, our typical use case, they are equivalent!\n\n\n\n\n\n\n\nCautionCheck your understanding\n\n\n\nQ. Can you explain with an example when a time series is weakly stationary but not strongly stationary?\n\n\n\n\n\n The autocorrelation is simply how correlated a time series is with itself at different lags.\n\nCorrelation in general is defined in terms of covariance of two variables.\nThe covariance is a measure of the joint variability of two random variables.\n\n\n\n\n\n\n\nImportant\n\n\n\nRecall that the Covariance between two random variables y_t and y_s is defined as:\n\n\\begin{aligned}\n\\mathbb{C}ov[y_t, y_s] &= \\mathbb{E}[(y_t-\\mathbb{E}[y_t])(y_s-\\mathbb{E}[y_s])] \\\\\n              &= \\mathbb{E}[(y_t-\\mu_t)(y_s-\\mu_s)] \\\\\n              &= E[y_t y_s] - \\mu_t \\times \\mu_s\n\\end{aligned} \\qquad\n\\tag{2}\nWe get the second line by substituting \\mu_t = \\mathbb{E}(y_t) and \\mu_s = \\mathbb{E}(y_s) using the definition of the mean of a RV. the third line is by multiplying out and using the linearity of the expectation operator.\n\n\n\n\n\n\n\n\nTip 2: AFC notation\n\n\n\nWe will frequently use the notation \\gamma(h) to denote the autocovariance for a lag h i.e. between y_t and y_{t+h}\n\n\\gamma(h) = \\mathbb{C}ov[y_t, y_{t+h}] \\qquad\n\\tag{3}\n\n\nWhen the time series is stationary, then the covariance only depends on the lag h = |t-s| and we can write the covariance as \\gamma(h).\nLet \\{y_t\\} be a time series. Recall that the covariance between two random variables y_t and y_s is defined as:\n\n\\gamma(t,s)=\\mathbb{C}ov[y_t, y_s] = \\mathbb{E}[(y_t-\\mu_t)(y_s-\\mu_s)] \\qquad\n\\tag{4}\nwhere \\mu_t = \\mathbb{E}(y_t) and \\mu_s = \\mathbb{E}(y_s) are the means of y_t and y_s respectively.\n\n\\mu_t = \\mathbb{E}(y_t) \\qquad \\mu_s = \\mathbb{E}(y_s)\n\\tag{5}\n\n\\text{Stationarity} \\implies \\mathbb{E}[y_t] = \\mu \\quad \\forall t \\qquad \\therefore \\quad \\gamma(t,s)=\\gamma(|t-s|)\n\nIf h&gt;0 \\qquad \\gamma(h)=\\mathbb{C}ov[y_t,y_{t-h}]\n\n\n\n\n\n\nImportantAutocorrelation Function (AFC)\n\n\n\n\n\n\\rho(t,s) = \\frac{\\gamma(t,s)}{\\sqrt{\\gamma(t,t)\\gamma(s,s)}}\n\\tag{6}\n\n\nauto-correlation AFC\n\\text{Stationarity} \\implies \\rho(h)=\\frac{\\gamma(h)}{\\gamma(o)} \\qquad \\gamma(0)=Var(y_t)\n\n \ny_{1:T}\n\\tag{7}\n\n\n\n\n\n\nImportantThe sample AFC\n\n\n\n\n\\hat\\gamma(h)= \\frac{1}{T} \\sum_{t=1}^{T-h}(y_{t+h}-\\bar y )(y_t-\\hat y)\n\\tag{8}\nwhere \\bar y is the sample mean of the time series y_{1:T}, and \\hat y is the sample mean of the time series y_{1:T-h}.\n\n\n\n\\bar y = \\frac{1}{T} \\sum_{t=1}^{T}y_t\n\\tag{9}\n\n\\hat \\rho = \\frac{\\hat\\gamma(h)}{\\hat\\gamma(o)}\n\\tag{10}\n\n\n\n\nDefinition 3 (Partial Auto-correlation Function (PAFC)) Let {y_t} be a zero-mean stationary process, and let\n\n\\hat{y}_t^{h-1} = \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + \\ldots + \\beta_{h-1} y_{t-(h-1)}\n\\tag{11}\nbe the best linear predictor of y_t based on the previous h − 1 values \\{y_{t−1}, \\ldots , y_{t−h+1}\\}. The best linear predictor of y_t based on the previous h − 1 values of the process is the linear predictor that minimizes\n\nE[(y_t − \\hat{y}_y^{h-1})^2]\n\\tag{12}\nThe partial autocorrelation of this process at lag h, denoted by \\phi(h, h) is defined as: partial auto-correlation PAFC\n\n\\phi(h, h) = Corr(y_{t+h} − \\hat{y}_{t+h}^{h-1}, y_t − \\hat{y}_t^{h-1})\n\\tag{13}\nfor h \\ge 2 and \\phi(1, 1) = Corr(y_{t+1}, y_{t}) = \\rho(1).\n\nThe partial autocorrelation function can also be computed via the Durbin-Levinson recursion for stationary processes as \\phi(0, 0) = 0,\n\n\\phi(n, n) = \\frac{\\rho(n) − \\sum_{h=1}^{n-1} \\phi(n − 1, h)\\rho(n − h)}{1- \\sum_{h=1}^{n-1}\\phi(n − 1, h)\\rho(h)}\n\\tag{14}\nfor n \\ge 1, and\n\n\\phi(n, h) = \\phi(n − 1, h) − \\phi(n, n)\\phi(n − 1, n − h),\n\\tag{15}\nfor n \\ge 2, and h = 1, \\ldots , (n − 1).\nNote that the sample PACF can be obtained by substituting the sample autocorrelations and the sample auto-covariances in the Durbin-Levinson recursion.\n\n\n\nDifferencing and smoothing are techniques used to remove trends and seasonality in time series data. They are covered in the (Prado, Ferreira, and West 2023, sec. 1.4).\nMany synthetic time series models are built under the assumption of stationarity. However, in the real world time series data often present non-stationary features such as trends or seasonality. These features render such a time series non-stationary, and therefore, not suitable for analysis using the tools and methods we have discussed so far. However practitioners can use techniques for detrending, deseasonalizing and smoothing that when applied to such observed data transforms it into a new time series that is consistent with the stationarity assumption.\nWe briefly discuss two methods that are commonly used in practice for detrending and smoothing.\n\n\nDifferencing, is a method which removes the trend from a time series data. The first difference of a time series is defined in terms of the difference operator, denoted as D, that produces the transformation differencing operator D\n\nDy_t \\doteqdot y_t - y_{t-1}.\n\\tag{16}\nHigher order differences are obtained by successively applying the operator D. For example,\n\nD^2y_t = D(Dy_t) = D(y_t - y_{t-1}) = y_t - 2y_{t-1} + y_{t-2}.\n\\tag{17}\nDifferencing can also be written in terms of the so called back-shift operator B, with back-shift operator B\n\nBy_t \\doteqdot y_{t-1},\n\\tag{18}\nso that\n\nDy_t \\doteqdot (1 - B) y_t\n\\tag{19}\nand\n\nD^dy_t \\doteqdot (1 - B)^d y_t.\n\\tag{20}\nthis notation lets us write the differences in by referencing items backwards in time, which is often more intuitive and also useful, for example, when we will want to write the differencing operator in terms of a polynomial.\n\n\n\nMoving averages, which is commonly used to “smooth” a time series by removing certain features (e.g., seasonality) to highlight other features (e.g., trends).\nA moving average is a weighted average of the time series around a particular time t. In general, if we have data y_{1:T}, we could obtain a new time series such that moving average\n\nz_t = \\sum_{j=-q}^{p} w_j y_{t+j} \\qquad\n\\tag{21}\nfor t = (q + 1) : (T − p), with weights w_j \\ge 0 and \\sum^p_{j=−q} w_j = 1\nWe will frequently work with moving averages for which\n\np = q \\qquad \\text{(centered)}\n\nand\n\nw_j = w_{−j} \\forall j  \\text{(symmetric)}\n\nAssume we have periodic data with period d. Then, symmetric and centered moving averages can be used to remove such periodicity as follows:\n\nIf d = 2q :\n\n\nz_t =  \\frac{1}{d} \\left(\\frac{1}{2} y_{t−q} + y_{t−q+1} + \\ldots + y_{t+q−1} + \\frac{1}{2} y_{t+q}\\right )\n\\tag{22}\n\nif d = 2q + 1 :\n\n\nz_t = \\frac{1}{d} \\left( y_{t−q} + y_{t−q+1} + \\ldots + y_{t+q−1} + y_{t+q}\\right )\n\\tag{23}\n\nExample 1 (Seasonal Moving Average) To remove seasonality in monthly data (i.e., seasonality with a period of d = 12 months), we use a moving average with p = q = 6, a_6 = a_{−6} = 1/24, and a_j = a_{−j} = 1/12 for j = 0, \\ldots , 5 , resulting in:\n\nz_t = \\frac{1}{24} y_{t−6} + \\frac{1}{12}y_{t−5} + \\ldots + \\frac{1}{12}y_{t+5} + \\frac{1}{24}y_{t+6}\n\\tag{24}\n\n\n\n\n\nThis video walks us through the code snippets in Listing 1 and Listing 2 below and provides examples of how to compute the ACF and PACF of a time series, how to use differencing to remove trends, and how to use moving averages to remove seasonality.\n\nOutline:\n\nWe begin by simulating data using the code in Section 1.2.7\nWe simulates white noise data using the rnorm(1:2000,mean=0,sd=1) function in R\nWe plot the white noise data which we can see lacks a temporal structure.\nWe plot the ACF using the acf function in R:\n\nwe specify the number of lags using the lag.max=20\nwe shows a confidence interval for the ACF values\n\nWe plot the PACF using the pacf function in R\nNext we define some time series objects in R using the ts function\n\nwe define and plot monthly data starting in January 1960\nwe define and plot yearly data with one observation per year starting in 1960\nwe define and plot yearly data with four observations per year starting in 1960\n\nWe move on to smoothing and differencing in Section 1.2.6\nWe load the CO2 dataset in R and plot it\nwe plot the ACF and PACF of the CO2 dataset\nwe use the filter function in R to remove the seasonal component of the CO2 dataset we plot the resulting time series highlighting the trend.\nTo remove the trend we use the diff function in R to take the first and second differences of the CO2 dataset\n\nthe diff function takes a parameter differences which specifies the number of differences to take\n\nwe plot the resulting time series after taking the first and second differences\nthe ACF and PACF of the resulting time series are plotted, they look different, in that they no longer have the slow decay characteristic of time series with a trend.\n\n\nThe r-code for the examples is provided below.\n\n\n\n\n\n\n\nListing 1: R code: for Differencing and filtering via moving averages\n\n\n\nCode\n# Load the CO2 dataset in R\ndata(co2) \n\n# Take first differences to remove the trend \nco2_1stdiff=diff(co2,differences=1)\n\n# Filter via moving averages to remove the seasonality \nco2_ma=filter(co2,filter=c(1/24,rep(1/12,11),1/24),sides=2)\n\npar(mfrow=c(3,1), cex.lab=1.2,cex.main=1.2)\nplot(co2) # plot the original data \nplot(co2_1stdiff) # plot the first differences (removes trend, highlights seasonality)\nplot(co2_ma) # plot the filtered series via moving averages (removes the seasonality, highlights the trend)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 2: R Code: Simulate data from a white noise process\n\n\n\nCode\n#\n# Simulate data with no temporal structure (white noise)\n#\nset.seed(2021)\nT=200\nt =1:T\ny_white_noise=rnorm(T, mean=0, sd=1)\n#\n# Define a time series object in R: \n# Assume the data correspond to annual observations starting in January 1960 \n#\nyt=ts(y_white_noise, start=c(1960), frequency=1)\n#\n# plot the simulated time series, their sample ACF and their sample PACF\n#\npar(mfrow = c(1, 3), cex.lab = 1.3, cex.main = 1.3)\nyt=ts(y_white_noise, start=c(1960), frequency=1)\nplot(yt, type = 'l', col='red', xlab = 'time (t)', ylab = \"Y(t)\")\nacf(yt, lag.max = 20, xlab = \"lag\",\n    ylab = \"Sample ACF\",ylim=c(-1,1),main=\"\")\npacf(yt, lag.max = 20,xlab = \"lag\",\n     ylab = \"Sample PACF\",ylim=c(-1,1),main=\"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nomitted per coursera requirements\n\n\n\n\nWe will next introduce the autoregressive process of order one, or AR(1) process, which is a fundamental model in time series analysis. We will discuss the definition of the AR(1) process, its properties, and how to simulate data from an AR(1) process.\n\n\n\n\n\n\nAR(1)\n\n\n\n\nAR(1) properties\n\n\n\n\n\nIt is possible to show that the PACF of an autoregressive process of order one is zero after the first lag. We can use the Durbin-Levinson recursion to show this.\nFor lag n = 0 we have \\phi(0, 0) = 0\nFor lag n = 1 we have:\n\n\\phi(1, 1) =  \\rho(1) = \\phi\n\nFor lag n = 2 we compute \\phi(2, 2) as:\n\n\\phi(2, 2) = \\frac{(\\rho(2) − \\phi(1, 1)\\rho(1))}{ (1 − \\phi(1, 1)\\rho(1))} = \\frac{\\phi^2-\\phi^2}{1- \\phi^2}=0\n\nand we also obtain\n\n\\phi(2, 1) = \\phi(1, 1) − \\phi(2, 2)\\phi(1, 1) = \\phi.\n\nFor lag n = 3 we compute \\phi(3, 3) as\n\n\\begin{aligned}\n\\phi(3, 3) &= \\frac{(\\rho(3) − \\sum_{h=1}^2 \\phi(2, h)\\rho(3 − h))}{1 − \\sum_{h=1}^2 \\phi(2, h)\\rho(h)} \\newline\n&= \\frac{\\phi^3 - \\phi(2,1) \\rho(2) - \\phi(2,2) \\rho(1)}{1 - \\phi(2,1)\\rho(1) - \\phi(2,2)\\rho(2)} \\newline\n&= \\frac{\\phi^3 - \\phi^3 - 0}{1 - \\phi^2 } \\newline\n&= 0\n\\end{aligned}\n\nand we also obtain\n\n\\phi(3, 1) = \\phi(2, 1) − \\phi(3, 3)\\phi(2, 2) = \\phi\n\n\n\\phi(3, 2) = \\phi(2, 2) − \\phi(3, 3)\\phi(2, 1) = 0\n\nWe can prove by induction that in the case of an AR(1), for any lag n,\n\\phi(n, h) = 0, \\phi(n, 1) = \\phi and \\phi(n, h) = 0 for h \\ge 2 and n \\ge 2.\nThen, the PACF of an AR(1) is zero for any lag above 1 and the PACF coefficient at lag 1 is equal to the AR coefficient \\phi\n\n\n\nThis video walks through the code snippet below and provides examples of how to sample data from an AR(1) process and plot the ACF and PACF functions of the resulting time series.\n\n\n\n\n\nCode\n# sample data from 2 ar(1) processes and plot their ACF and PACF functions\n#\nset.seed(2021)\nT=500 # number of time points\n#\n# sample data from an ar(1) with ar coefficient phi = 0.9 and variance 1\n#\nv=1.0 # innovation variance\nsd=sqrt(v) #innovation stantard deviation\nphi1=0.9 # ar coefficient\nyt1=arima.sim(n = T, model = list(ar = phi1), sd = sd)\n#\n# sample data from an ar(1) with ar coefficient phi = -0.9 and variance 1\n#\nphi2=-0.9 # ar coefficient\nyt2=arima.sim(n = T, model = list(ar = phi2), sd = sd)\n\npar(mfrow = c(2, 1), cex.lab = 1.3)\nplot(yt1,main=expression(phi==0.9))\nplot(yt2,main=expression(phi==-0.9))\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(3, 2), cex.lab = 1.3)\nlag.max=50 # max lag\n#\n## plot true ACFs for both processes\n#\ncov_0=sd^2/(1-phi1^2) # compute auto-covariance at h=0\ncov_h=phi1^(0:lag.max)*cov_0 # compute auto-covariance at h\nplot(0:lag.max, cov_h/cov_0, pch = 1, type = 'h', col = 'red',\n     ylab = \"true ACF\", xlab = \"Lag\",ylim=c(-1,1), main=expression(phi==0.9))\n\ncov_0=sd^2/(1-phi2^2) # compute auto-covariance at h=0\ncov_h=phi2^(0:lag.max)*cov_0 # compute auto-covariance at h\n# Plot autocorrelation function (ACF)\nplot(0:lag.max, cov_h/cov_0, pch = 1, type = 'h', col = 'red',\n     ylab = \"true ACF\", xlab = \"Lag\",ylim=c(-1,1),main=expression(phi==-0.9))\n\n## plot sample ACFs for both processes\n#\nacf(yt1, lag.max = lag.max, type = \"correlation\", ylab = \"sample ACF\",\n    lty = 1, ylim = c(-1, 1), main = \" \")\nacf(yt2, lag.max = lag.max, type = \"correlation\", ylab = \"sample ACF\",\n    lty = 1, ylim = c(-1, 1), main = \" \")\n## plot sample PACFs for both processes\n#\npacf(yt1, lag.ma = lag.max, ylab = \"sample PACF\", ylim=c(-1,1),main=\"\")\npacf(yt2, lag.ma = lag.max, ylab = \"sample PACF\", ylim=c(-1,1),main=\"\")\n\n\n\n\n\n\n\n\n\n\n\n\nOmitted per Coursera honor code requirements.",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#introduction",
    "href": "C4-L01.html#introduction",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "",
    "text": "Obligatory introduction to the course and the instructors.\nRaquel Prado is a professor of statistics in the Baskin School of Engineering at the University of California, Santa Cruz. She was the recipient 2022 Zellner Medal, see Weckerle (2022).\n\n\n\n\n\nIntroduction to R",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#stationarity-the-acf-and-the-pacf",
    "href": "C4-L01.html#stationarity-the-acf-and-the-pacf",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "",
    "text": "Before diving into the material here is a brief overview of the notations for timer series.\n\n\n\n\n\n\nTip 1: Notation\n\n\n\n\n\\{y_t\\} - the time series process, where each y_t is a univariate random variable and t are the time points that are equally spaced.\ny_{1:T} or y_1, y_2, \\ldots, y_T - the observed data.\nYou will see the use of ’ to denote the transpose of a matrix,\nand the use of \\sim to denote a distribution.\nunder tildes \\utilde{y} are used to denote estimates of the true values y.\nE matrix of eigenvalues\n\\Lambda = diagonal(\\alpha_1, \\alpha_2, \\ldots , \\alpha_p) is a diagonal matrix with the eigenvalues of \\Sigma on the diagonal.\nJ_p(1) = a p by p Jordan form matrix with 1 on the super-diagonal\n\nalso see (Prado, Ferreira, and West 2023, 2–3)\n\n\n\n\n\n\n\n\nstrong and weak stationarity\n\nStationarity c.f. (Prado, Ferreira, and West 2023, sec. 1.2) is a fundamental concept in time series analysis.\n\n\n\n\n\n\nImportantTL;DR – Stationarity\n\n\n\n\nStationarity\n\n\n\n\nA time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.\n\n\n\nWe make this definition more formal in the definitions of strong and weak stationarity below.\n\n\n\nStationarityStationarity is a key concept in time series analysis. A time series is said to be stationary if its statistical properties such as mean, variance, and auto-correlation do not change over time.\n\nDefinition 1 (Strong Stationarity)  Let y_t be a time series. We say that y_t is stationary if the following conditions hold:Strong Stationarity\nLet \\{y_t\\} \\quad \\forall n&gt;0 be a time series and h &gt; 0 be a lag. If for any subsequence the distribution of y_t, y_{t+1}, \\ldots, y_{t+n} is the same as the distribution of y_{t+h}, y_{t+h+1}, \\ldots, y_{t+h+n} we call the series strongly stationary.\n\nAs it’s difficult to verify strong stationarity in practice, we will often use the following weaker notion of stationarity.\n\nDefinition 2 (Weak Stationarity)   The mean, variance, and auto-covariance are constant over time.Weak StationaritySecond-order Stationarity\n\n\\begin{aligned}\n\\mathbb{E}[y_t] &= \\mu \\quad \\forall t \\\\\n\\mathbb{V}ar[y_t] &= \\nu =\\sigma^2 \\quad \\forall t \\\\\n\\mathbb{C}ov[y_t , y_s ] &= γ(t − s)\n\\end{aligned}\n\\tag{1}\n\n\nStrong stationarity \\implies Weak stationarity, but\nThe converse is not true.\nIn this course when we deal with a Gaussian process, our typical use case, they are equivalent!\n\n\n\n\n\n\n\nCautionCheck your understanding\n\n\n\nQ. Can you explain with an example when a time series is weakly stationary but not strongly stationary?\n\n\n\n\n\n The autocorrelation is simply how correlated a time series is with itself at different lags.\n\nCorrelation in general is defined in terms of covariance of two variables.\nThe covariance is a measure of the joint variability of two random variables.\n\n\n\n\n\n\n\nImportant\n\n\n\nRecall that the Covariance between two random variables y_t and y_s is defined as:\n\n\\begin{aligned}\n\\mathbb{C}ov[y_t, y_s] &= \\mathbb{E}[(y_t-\\mathbb{E}[y_t])(y_s-\\mathbb{E}[y_s])] \\\\\n              &= \\mathbb{E}[(y_t-\\mu_t)(y_s-\\mu_s)] \\\\\n              &= E[y_t y_s] - \\mu_t \\times \\mu_s\n\\end{aligned} \\qquad\n\\tag{2}\nWe get the second line by substituting \\mu_t = \\mathbb{E}(y_t) and \\mu_s = \\mathbb{E}(y_s) using the definition of the mean of a RV. the third line is by multiplying out and using the linearity of the expectation operator.\n\n\n\n\n\n\n\n\nTip 2: AFC notation\n\n\n\nWe will frequently use the notation \\gamma(h) to denote the autocovariance for a lag h i.e. between y_t and y_{t+h}\n\n\\gamma(h) = \\mathbb{C}ov[y_t, y_{t+h}] \\qquad\n\\tag{3}\n\n\nWhen the time series is stationary, then the covariance only depends on the lag h = |t-s| and we can write the covariance as \\gamma(h).\nLet \\{y_t\\} be a time series. Recall that the covariance between two random variables y_t and y_s is defined as:\n\n\\gamma(t,s)=\\mathbb{C}ov[y_t, y_s] = \\mathbb{E}[(y_t-\\mu_t)(y_s-\\mu_s)] \\qquad\n\\tag{4}\nwhere \\mu_t = \\mathbb{E}(y_t) and \\mu_s = \\mathbb{E}(y_s) are the means of y_t and y_s respectively.\n\n\\mu_t = \\mathbb{E}(y_t) \\qquad \\mu_s = \\mathbb{E}(y_s)\n\\tag{5}\n\n\\text{Stationarity} \\implies \\mathbb{E}[y_t] = \\mu \\quad \\forall t \\qquad \\therefore \\quad \\gamma(t,s)=\\gamma(|t-s|)\n\nIf h&gt;0 \\qquad \\gamma(h)=\\mathbb{C}ov[y_t,y_{t-h}]\n\n\n\n\n\n\nImportantAutocorrelation Function (AFC)\n\n\n\n\n\n\\rho(t,s) = \\frac{\\gamma(t,s)}{\\sqrt{\\gamma(t,t)\\gamma(s,s)}}\n\\tag{6}\n\n\nauto-correlation AFC\n\\text{Stationarity} \\implies \\rho(h)=\\frac{\\gamma(h)}{\\gamma(o)} \\qquad \\gamma(0)=Var(y_t)\n\n \ny_{1:T}\n\\tag{7}\n\n\n\n\n\n\nImportantThe sample AFC\n\n\n\n\n\\hat\\gamma(h)= \\frac{1}{T} \\sum_{t=1}^{T-h}(y_{t+h}-\\bar y )(y_t-\\hat y)\n\\tag{8}\nwhere \\bar y is the sample mean of the time series y_{1:T}, and \\hat y is the sample mean of the time series y_{1:T-h}.\n\n\n\n\\bar y = \\frac{1}{T} \\sum_{t=1}^{T}y_t\n\\tag{9}\n\n\\hat \\rho = \\frac{\\hat\\gamma(h)}{\\hat\\gamma(o)}\n\\tag{10}\n\n\n\n\nDefinition 3 (Partial Auto-correlation Function (PAFC)) Let {y_t} be a zero-mean stationary process, and let\n\n\\hat{y}_t^{h-1} = \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + \\ldots + \\beta_{h-1} y_{t-(h-1)}\n\\tag{11}\nbe the best linear predictor of y_t based on the previous h − 1 values \\{y_{t−1}, \\ldots , y_{t−h+1}\\}. The best linear predictor of y_t based on the previous h − 1 values of the process is the linear predictor that minimizes\n\nE[(y_t − \\hat{y}_y^{h-1})^2]\n\\tag{12}\nThe partial autocorrelation of this process at lag h, denoted by \\phi(h, h) is defined as: partial auto-correlation PAFC\n\n\\phi(h, h) = Corr(y_{t+h} − \\hat{y}_{t+h}^{h-1}, y_t − \\hat{y}_t^{h-1})\n\\tag{13}\nfor h \\ge 2 and \\phi(1, 1) = Corr(y_{t+1}, y_{t}) = \\rho(1).\n\nThe partial autocorrelation function can also be computed via the Durbin-Levinson recursion for stationary processes as \\phi(0, 0) = 0,\n\n\\phi(n, n) = \\frac{\\rho(n) − \\sum_{h=1}^{n-1} \\phi(n − 1, h)\\rho(n − h)}{1- \\sum_{h=1}^{n-1}\\phi(n − 1, h)\\rho(h)}\n\\tag{14}\nfor n \\ge 1, and\n\n\\phi(n, h) = \\phi(n − 1, h) − \\phi(n, n)\\phi(n − 1, n − h),\n\\tag{15}\nfor n \\ge 2, and h = 1, \\ldots , (n − 1).\nNote that the sample PACF can be obtained by substituting the sample autocorrelations and the sample auto-covariances in the Durbin-Levinson recursion.\n\n\n\nDifferencing and smoothing are techniques used to remove trends and seasonality in time series data. They are covered in the (Prado, Ferreira, and West 2023, sec. 1.4).\nMany synthetic time series models are built under the assumption of stationarity. However, in the real world time series data often present non-stationary features such as trends or seasonality. These features render such a time series non-stationary, and therefore, not suitable for analysis using the tools and methods we have discussed so far. However practitioners can use techniques for detrending, deseasonalizing and smoothing that when applied to such observed data transforms it into a new time series that is consistent with the stationarity assumption.\nWe briefly discuss two methods that are commonly used in practice for detrending and smoothing.\n\n\nDifferencing, is a method which removes the trend from a time series data. The first difference of a time series is defined in terms of the difference operator, denoted as D, that produces the transformation differencing operator D\n\nDy_t \\doteqdot y_t - y_{t-1}.\n\\tag{16}\nHigher order differences are obtained by successively applying the operator D. For example,\n\nD^2y_t = D(Dy_t) = D(y_t - y_{t-1}) = y_t - 2y_{t-1} + y_{t-2}.\n\\tag{17}\nDifferencing can also be written in terms of the so called back-shift operator B, with back-shift operator B\n\nBy_t \\doteqdot y_{t-1},\n\\tag{18}\nso that\n\nDy_t \\doteqdot (1 - B) y_t\n\\tag{19}\nand\n\nD^dy_t \\doteqdot (1 - B)^d y_t.\n\\tag{20}\nthis notation lets us write the differences in by referencing items backwards in time, which is often more intuitive and also useful, for example, when we will want to write the differencing operator in terms of a polynomial.\n\n\n\nMoving averages, which is commonly used to “smooth” a time series by removing certain features (e.g., seasonality) to highlight other features (e.g., trends).\nA moving average is a weighted average of the time series around a particular time t. In general, if we have data y_{1:T}, we could obtain a new time series such that moving average\n\nz_t = \\sum_{j=-q}^{p} w_j y_{t+j} \\qquad\n\\tag{21}\nfor t = (q + 1) : (T − p), with weights w_j \\ge 0 and \\sum^p_{j=−q} w_j = 1\nWe will frequently work with moving averages for which\n\np = q \\qquad \\text{(centered)}\n\nand\n\nw_j = w_{−j} \\forall j  \\text{(symmetric)}\n\nAssume we have periodic data with period d. Then, symmetric and centered moving averages can be used to remove such periodicity as follows:\n\nIf d = 2q :\n\n\nz_t =  \\frac{1}{d} \\left(\\frac{1}{2} y_{t−q} + y_{t−q+1} + \\ldots + y_{t+q−1} + \\frac{1}{2} y_{t+q}\\right )\n\\tag{22}\n\nif d = 2q + 1 :\n\n\nz_t = \\frac{1}{d} \\left( y_{t−q} + y_{t−q+1} + \\ldots + y_{t+q−1} + y_{t+q}\\right )\n\\tag{23}\n\nExample 1 (Seasonal Moving Average) To remove seasonality in monthly data (i.e., seasonality with a period of d = 12 months), we use a moving average with p = q = 6, a_6 = a_{−6} = 1/24, and a_j = a_{−j} = 1/12 for j = 0, \\ldots , 5 , resulting in:\n\nz_t = \\frac{1}{24} y_{t−6} + \\frac{1}{12}y_{t−5} + \\ldots + \\frac{1}{12}y_{t+5} + \\frac{1}{24}y_{t+6}\n\\tag{24}\n\n\n\n\n\nThis video walks us through the code snippets in Listing 1 and Listing 2 below and provides examples of how to compute the ACF and PACF of a time series, how to use differencing to remove trends, and how to use moving averages to remove seasonality.\n\nOutline:\n\nWe begin by simulating data using the code in Section 1.2.7\nWe simulates white noise data using the rnorm(1:2000,mean=0,sd=1) function in R\nWe plot the white noise data which we can see lacks a temporal structure.\nWe plot the ACF using the acf function in R:\n\nwe specify the number of lags using the lag.max=20\nwe shows a confidence interval for the ACF values\n\nWe plot the PACF using the pacf function in R\nNext we define some time series objects in R using the ts function\n\nwe define and plot monthly data starting in January 1960\nwe define and plot yearly data with one observation per year starting in 1960\nwe define and plot yearly data with four observations per year starting in 1960\n\nWe move on to smoothing and differencing in Section 1.2.6\nWe load the CO2 dataset in R and plot it\nwe plot the ACF and PACF of the CO2 dataset\nwe use the filter function in R to remove the seasonal component of the CO2 dataset we plot the resulting time series highlighting the trend.\nTo remove the trend we use the diff function in R to take the first and second differences of the CO2 dataset\n\nthe diff function takes a parameter differences which specifies the number of differences to take\n\nwe plot the resulting time series after taking the first and second differences\nthe ACF and PACF of the resulting time series are plotted, they look different, in that they no longer have the slow decay characteristic of time series with a trend.\n\n\nThe r-code for the examples is provided below.\n\n\n\n\n\n\n\nListing 1: R code: for Differencing and filtering via moving averages\n\n\n\nCode\n# Load the CO2 dataset in R\ndata(co2) \n\n# Take first differences to remove the trend \nco2_1stdiff=diff(co2,differences=1)\n\n# Filter via moving averages to remove the seasonality \nco2_ma=filter(co2,filter=c(1/24,rep(1/12,11),1/24),sides=2)\n\npar(mfrow=c(3,1), cex.lab=1.2,cex.main=1.2)\nplot(co2) # plot the original data \nplot(co2_1stdiff) # plot the first differences (removes trend, highlights seasonality)\nplot(co2_ma) # plot the filtered series via moving averages (removes the seasonality, highlights the trend)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nListing 2: R Code: Simulate data from a white noise process\n\n\n\nCode\n#\n# Simulate data with no temporal structure (white noise)\n#\nset.seed(2021)\nT=200\nt =1:T\ny_white_noise=rnorm(T, mean=0, sd=1)\n#\n# Define a time series object in R: \n# Assume the data correspond to annual observations starting in January 1960 \n#\nyt=ts(y_white_noise, start=c(1960), frequency=1)\n#\n# plot the simulated time series, their sample ACF and their sample PACF\n#\npar(mfrow = c(1, 3), cex.lab = 1.3, cex.main = 1.3)\nyt=ts(y_white_noise, start=c(1960), frequency=1)\nplot(yt, type = 'l', col='red', xlab = 'time (t)', ylab = \"Y(t)\")\nacf(yt, lag.max = 20, xlab = \"lag\",\n    ylab = \"Sample ACF\",ylim=c(-1,1),main=\"\")\npacf(yt, lag.max = 20,xlab = \"lag\",\n     ylab = \"Sample PACF\",ylim=c(-1,1),main=\"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nomitted per coursera requirements",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#the-ar1-process-definition-and-properties",
    "href": "C4-L01.html#the-ar1-process-definition-and-properties",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "",
    "text": "We will next introduce the autoregressive process of order one, or AR(1) process, which is a fundamental model in time series analysis. We will discuss the definition of the AR(1) process, its properties, and how to simulate data from an AR(1) process.\n\n\n\n\n\n\nAR(1)\n\n\n\n\nAR(1) properties\n\n\n\n\n\nIt is possible to show that the PACF of an autoregressive process of order one is zero after the first lag. We can use the Durbin-Levinson recursion to show this.\nFor lag n = 0 we have \\phi(0, 0) = 0\nFor lag n = 1 we have:\n\n\\phi(1, 1) =  \\rho(1) = \\phi\n\nFor lag n = 2 we compute \\phi(2, 2) as:\n\n\\phi(2, 2) = \\frac{(\\rho(2) − \\phi(1, 1)\\rho(1))}{ (1 − \\phi(1, 1)\\rho(1))} = \\frac{\\phi^2-\\phi^2}{1- \\phi^2}=0\n\nand we also obtain\n\n\\phi(2, 1) = \\phi(1, 1) − \\phi(2, 2)\\phi(1, 1) = \\phi.\n\nFor lag n = 3 we compute \\phi(3, 3) as\n\n\\begin{aligned}\n\\phi(3, 3) &= \\frac{(\\rho(3) − \\sum_{h=1}^2 \\phi(2, h)\\rho(3 − h))}{1 − \\sum_{h=1}^2 \\phi(2, h)\\rho(h)} \\newline\n&= \\frac{\\phi^3 - \\phi(2,1) \\rho(2) - \\phi(2,2) \\rho(1)}{1 - \\phi(2,1)\\rho(1) - \\phi(2,2)\\rho(2)} \\newline\n&= \\frac{\\phi^3 - \\phi^3 - 0}{1 - \\phi^2 } \\newline\n&= 0\n\\end{aligned}\n\nand we also obtain\n\n\\phi(3, 1) = \\phi(2, 1) − \\phi(3, 3)\\phi(2, 2) = \\phi\n\n\n\\phi(3, 2) = \\phi(2, 2) − \\phi(3, 3)\\phi(2, 1) = 0\n\nWe can prove by induction that in the case of an AR(1), for any lag n,\n\\phi(n, h) = 0, \\phi(n, 1) = \\phi and \\phi(n, h) = 0 for h \\ge 2 and n \\ge 2.\nThen, the PACF of an AR(1) is zero for any lag above 1 and the PACF coefficient at lag 1 is equal to the AR coefficient \\phi\n\n\n\nThis video walks through the code snippet below and provides examples of how to sample data from an AR(1) process and plot the ACF and PACF functions of the resulting time series.\n\n\n\n\n\nCode\n# sample data from 2 ar(1) processes and plot their ACF and PACF functions\n#\nset.seed(2021)\nT=500 # number of time points\n#\n# sample data from an ar(1) with ar coefficient phi = 0.9 and variance 1\n#\nv=1.0 # innovation variance\nsd=sqrt(v) #innovation stantard deviation\nphi1=0.9 # ar coefficient\nyt1=arima.sim(n = T, model = list(ar = phi1), sd = sd)\n#\n# sample data from an ar(1) with ar coefficient phi = -0.9 and variance 1\n#\nphi2=-0.9 # ar coefficient\nyt2=arima.sim(n = T, model = list(ar = phi2), sd = sd)\n\npar(mfrow = c(2, 1), cex.lab = 1.3)\nplot(yt1,main=expression(phi==0.9))\nplot(yt2,main=expression(phi==-0.9))\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(3, 2), cex.lab = 1.3)\nlag.max=50 # max lag\n#\n## plot true ACFs for both processes\n#\ncov_0=sd^2/(1-phi1^2) # compute auto-covariance at h=0\ncov_h=phi1^(0:lag.max)*cov_0 # compute auto-covariance at h\nplot(0:lag.max, cov_h/cov_0, pch = 1, type = 'h', col = 'red',\n     ylab = \"true ACF\", xlab = \"Lag\",ylim=c(-1,1), main=expression(phi==0.9))\n\ncov_0=sd^2/(1-phi2^2) # compute auto-covariance at h=0\ncov_h=phi2^(0:lag.max)*cov_0 # compute auto-covariance at h\n# Plot autocorrelation function (ACF)\nplot(0:lag.max, cov_h/cov_0, pch = 1, type = 'h', col = 'red',\n     ylab = \"true ACF\", xlab = \"Lag\",ylim=c(-1,1),main=expression(phi==-0.9))\n\n## plot sample ACFs for both processes\n#\nacf(yt1, lag.max = lag.max, type = \"correlation\", ylab = \"sample ACF\",\n    lty = 1, ylim = c(-1, 1), main = \" \")\nacf(yt2, lag.max = lag.max, type = \"correlation\", ylab = \"sample ACF\",\n    lty = 1, ylim = c(-1, 1), main = \" \")\n## plot sample PACFs for both processes\n#\npacf(yt1, lag.ma = lag.max, ylab = \"sample PACF\", ylim=c(-1,1),main=\"\")\npacf(yt2, lag.ma = lag.max, ylab = \"sample PACF\", ylim=c(-1,1),main=\"\")\n\n\n\n\n\n\n\n\n\n\n\n\nOmitted per Coursera honor code requirements.",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#review-of-maximum-likelihood-and-bayesian-inference-in-regression",
    "href": "C4-L01.html#review-of-maximum-likelihood-and-bayesian-inference-in-regression",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "2.1 Review of maximum likelihood and Bayesian inference in regression",
    "text": "2.1 Review of maximum likelihood and Bayesian inference in regression\n\n2.1.1 Regression Models: Maximum Likelihood Estimation\nAssume a regression model with the following structure: \ny_i = \\beta_1x_{i,1} + \\ldots + \\beta_kx_{i,k} + \\epsilon_i,\n\nfor i = 1, \\ldots, n and \\epsilon_i independent random variables with \\epsilon_i \\sim N(0, v) \\forall i. This model can be written in matrix form as:\n\ny = X \\beta + \\epsilon, \\epsilon \\sim N (0, vI), \\qquad\n\nwhere:\n\ny = (y_1, \\ldots, y_n)′ is an n-dimensional vector of responses,\nX is an n × k matrix containing the explanatory variables,\n\\beta = (\\beta_1, \\ldots, \\beta_k)′ is the k-dimensional vector of regression coefficients,\n\\epsilon = (\\epsilon_1, \\ldots, \\epsilon_n)′ is the n-dimensional vector of errors,\nI is an n × n identity matrix.\n\nIf X is a full rank matrix with rank k the maximum likelihood estimator for \\beta, denoted as \\hat\\beta_{MLE} is given by:\n\n\\hat\\beta_{MLE} = (X′X)^{−1}X′y,\n\nand the MLE for v is given by\n\n\\hat v_{MLE} = \\frac{1}{n} (y − X \\hat\\beta_{MLE})′(y − X \\hat\\beta_{MLE})\n\n\\hat v_{MLE} is not an unbiased estimator of v, therefore, the following unbiased estimator of v is typically used:\n\ns^2 = \\frac{1}{n-k}(y − X \\hat\\beta_{MLE} )′(y − X \\hat\\beta_{MLE} )\n\n\n\n2.1.2 Regression Models: Bayesian Inference\nAssume once again we have a model with the structure in (1), which results in a likelihood of the form\n\np(y \\mid \\beta , v) = \\frac{1}{(2\\pi v)^{n/2}}\\exp \\left\\{ -\\frac{1}{2} (y − X\\beta)′(y − X\\beta) \\right\\}\n\nIf a prior of the form\n\np(\\beta, v) \\propto \\frac{1}{v}\n\nis used, we obtain that the posterior distribution is given by\n\np(\\beta,v \\mid y) \\propto \\frac{1}{v^{n/2+1}}\\exp \\left\\{ -\\frac{1}{2v} (y − X\\beta)′(y − X\\beta) \\right\\}\n\nIn addition it can be shown that\n\n(\\beta\\mid v, y) \\sim N (\\hat \\beta_{MLE} , v(X′X)−1)\n(v\\mid y) \\sim \\text{IG}((n − k)/2, d/2) with\n\n\nd = (y − X \\hat \\beta_{MLE} )′(y − \\hat \\beta_{MLE} )\n\nwith k = dim(\\beta).\nGiven that p(\\beta, v \\mid y) = p(\\beta \\mid v, y)p(v \\mid y) the equations above provide a way to directly sample from the posterior distribution of \\beta and v by first sampling v from the inverse-gamma distribution above and then conditioning on this sampled value of v, sampling \\beta from the normal distribution above.",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#maximum-likelihood-estimation-in-the-ar1-video",
    "href": "C4-L01.html#maximum-likelihood-estimation-in-the-ar1-video",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "2.2 Maximum likelihood estimation in the AR(1) (video)",
    "text": "2.2 Maximum likelihood estimation in the AR(1) (video)\n\n\n\n\nslide 1\n\n\n\n\nslide 2\n\n\n\n\nslide 3",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#r-code-mle-for-the-ar1-examples-reading",
    "href": "C4-L01.html#r-code-mle-for-the-ar1-examples-reading",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "2.3 R code: MLE for the AR(1), examples (reading)",
    "text": "2.3 R code: MLE for the AR(1), examples (reading)\nThe following code allows you to compute the MLE of the AR coefficient \\psi, the unbiased estimator of v, s^2 , and the MLE of v based on a dataset simulated from an AR(1) process and using the conditional likelihood.\n\n\nCode\nset.seed(2021)\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n## Case 1: Conditional likelihood\ny=as.matrix(yt[2:T]) # response\nX=as.matrix(yt[1:(T-1)]) # design matrix\nphi_MLE=as.numeric((t(X)%*%y)/sum(X^2)) # MLE for phi\ns2=sum((y - phi_MLE*X)^2)/(length(y) - 1) # Unbiased estimate for v \nv_MLE=s2*(length(y)-1)/(length(y)) # MLE for v\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_MLE, \"\\n\",\n    \"MLE for the variance v: \", v_MLE, \"\\n\", \n    \"Estimate s2 for the variance v: \", s2, \"\\n\")\n\n\n\n MLE of conditional likelihood for phi:  0.9261423 \n MLE for the variance v:  1.048 \n Estimate s2 for the variance v:  1.050104 \n\n\nThis code allows you to compute estimates of the AR(1) coefficient and the variance using the arima function in R. The first case uses the conditional sum of squares, the second and third cases use the full likelihood with different starting points for the numerical optimization required to compute the MLE with the full likelihood.\n\n\nCode\n# Obtaining parameter estimates using the arima function in R\nset.seed(2021)\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n#Using conditional sum of squares, equivalent to conditional likelihood \narima_CSS=arima(yt,order=c(1,0,0),method=\"CSS\",n.cond=1,include.mean=FALSE)\ncat(\"AR estimates with conditional sum of squares (CSS) for phi and v:\", arima_CSS$coef,arima_CSS$sigma2,\n\"\\n\")\n\n\nAR estimates with conditional sum of squares (CSS) for phi and v: 0.9261423 1.048 \n\n\nCode\n#Uses ML with full likelihood \narima_ML=arima(yt,order=c(1,0,0),method=\"ML\",include.mean=FALSE)\ncat(\"AR estimates with full likelihood for phi and v:\", arima_ML$coef,arima_ML$sigma2,\n\"\\n\")\n\n\nAR estimates with full likelihood for phi and v: 0.9265251 1.048434 \n\n\nCode\n#Default: uses conditional sum of squares to find the starting point for ML and \n#         then uses ML \narima_CSS_ML=arima(yt,order=c(1,0,0),method=\"CSS-ML\",n.cond=1,include.mean=FALSE)\ncat(\"AR estimates with CSS to find starting point for ML for phi and v:\", \narima_CSS_ML$coef,arima_CSS_ML$sigma2,\"\\n\")\n\n\nAR estimates with CSS to find starting point for ML for phi and v: 0.9265252 1.048434 \n\n\nThis code shows you how to compute the MLE for \\psi using the full likelihood and the function optimize in R.\n\n\nCode\nset.seed(2021)\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n## MLE, full likelihood AR(1) with v=1 assumed known \n# log likelihood function\nlog_p &lt;- function(phi, yt){\n  0.5*(log(1-phi^2) - sum((yt[2:T] - phi*yt[1:(T-1)])^2) - yt[1]^2*(1-phi^2))\n}\n\n# Use a built-in optimization method to obtain maximum likelihood estimates\nresult =optimize(log_p, c(-1, 1), tol = 0.0001, maximum = TRUE, yt = yt)\ncat(\"\\n MLE of full likelihood for phi: \", result$maximum)\n\n\n\n MLE of full likelihood for phi:  0.9265928",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#bayesian-inference-in-the-ar1",
    "href": "C4-L01.html#bayesian-inference-in-the-ar1",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "2.4 Bayesian inference in the AR(1)",
    "text": "2.4 Bayesian inference in the AR(1)\n ## Bayesian inference in the AR(1): Conditional likelihood example (video)\nThis video walks through the code snippet below and provides examples of how to sample from the posterior distribution of the AR coefficient \\psi and the variance v using the conditional likelihood and a reference prior.",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#r-code-ar1-bayesian-inference-conditional-likelihood-example-reading",
    "href": "C4-L01.html#r-code-ar1-bayesian-inference-conditional-likelihood-example-reading",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "2.5 R Code: AR(1) Bayesian inference, conditional likelihood example (reading)",
    "text": "2.5 R Code: AR(1) Bayesian inference, conditional likelihood example (reading)\n\n\nCode\n####################################################\n#####             MLE for AR(1)               ######\n####################################################\nset.seed(2021)\nphi=0.9 # ar coefficient\nsd=1 # innovation standard deviation\nT=200 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) # sample stationary AR(1) process\n\ny=as.matrix(yt[2:T]) # response\nX=as.matrix(yt[1:(T-1)]) # design matrix\nphi_MLE=as.numeric((t(X)%*%y)/sum(X^2)) # MLE for phi\ns2=sum((y - phi_MLE*X)^2)/(length(y) - 1) # Unbiased estimate for v\nv_MLE=s2*(length(y)-1)/(length(y)) # MLE for v \n\nprint(c(phi_MLE,s2))\n\n\n[1] 0.9178472 1.0491054\n\n\nCode\n#######################################################\n######     Posterior inference, AR(1)               ###\n######     Conditional Likelihood + Reference Prior ###\n######     Direct sampling                          ###\n#######################################################\n\nn_sample=3000   # posterior sample size\n\n## step 1: sample posterior distribution of v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2)/2, sum((yt[2:T] - phi_MLE*yt[1:(T-1)])^2)/2)\n\n## step 2: sample posterior distribution of phi from normal distribution\nphi_sample=rep(0,n_sample)\nfor (i in 1:n_sample){\nphi_sample[i]=rnorm(1, mean = phi_MLE, sd=sqrt(v_sample[i]/sum(yt[1:(T-1)]^2)))}\n\n## plot histogram of posterior samples of phi and v\npar(mfrow = c(1, 2), cex.lab = 1.3)\nhist(phi_sample, xlab = bquote(phi), \n     main = bquote(\"Posterior for \"~phi),xlim=c(0.75,1.05), col='lightblue')\nabline(v = phi, col = 'red')\nhist(v_sample, xlab = bquote(v), col='lightblue', main = bquote(\"Posterior for \"~v))\nabline(v = sd, col = 'red')",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#quizz---mle-and-bayesian-inference-in-the-ar1",
    "href": "C4-L01.html#quizz---mle-and-bayesian-inference-in-the-ar1",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "2.6 Quizz - MLE and Bayesian inference in the AR(1)",
    "text": "2.6 Quizz - MLE and Bayesian inference in the AR(1)\nOmitted per Coursera honor code",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C4-L01.html#practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1",
    "href": "C4-L01.html#practice-graded-assignment-mle-and-bayesian-inference-in-the-ar1",
    "title": "Introductions to Time Series analysis & the AR(1) process",
    "section": "2.7 Practice Graded Assignment: MLE and Bayesian inference in the AR(1)",
    "text": "2.7 Practice Graded Assignment: MLE and Bayesian inference in the AR(1)\nThis peer-reviewed activity is highly recommended. It does not figure into your grade for this course, but it does provide you with the opportunity to apply what you’ve learned in R and prepare you for your data analysis project in week 5.\n\nConsider the R code below: MLE for the AR(1)\n\n\n\nCode\n####################################################\n#####             MLE for AR(1)               ######\n####################################################\nphi=0.9 # ar coefficient\nv=1\nsd=sqrt(v) # innovation standard deviation\nT=500 # number of time points\nyt=arima.sim(n = T, model = list(ar = phi), sd = sd) \n\n## Case 1: Conditional likelihood\ny=as.matrix(yt[2:T]) # response\nX=as.matrix(yt[1:(T-1)]) # design matrix\nphi_MLE=as.numeric((t(X)%*%y)/sum(X^2)) # MLE for phi\ns2=sum((y - phi_MLE*X)^2)/(length(y) - 1) # Unbiased estimate for v \nv_MLE=s2*(length(y)-1)/(length(y)) # MLE for v\n\ncat(\"\\n MLE of conditional likelihood for phi: \", phi_MLE, \"\\n\",\n    \"MLE for the variance v: \", v_MLE, \"\\n\", \n    \"Estimate s2 for the variance v: \", s2, \"\\n\")\n\n\n\n MLE of conditional likelihood for phi:  0.9048951 \n MLE for the variance v:  1.084559 \n Estimate s2 for the variance v:  1.086737 \n\n\nModify the code above to sample 800 observations from an AR(1) with AR coefficient \\psi = -0.8 and variance v = 2. Plot your simulated data. Obtain the MLE for \\psi based on the conditional likelihood and the unbiased estimate s^2 for the variance v.\n\nConsider the R code below: AR(1) Bayesian inference, conditional likelihood\n\n\n\n\n\nListing 3: R Code: AR(1) Bayesian inference, conditional likelihood example\n\n\n\nCode\n#######################################################\n######     Posterior inference, AR(1)               ###\n######     Conditional Likelihood + Reference Prior ###\n######     Direct sampling                          ###\n#######################################################\n\nn_sample=3000   # posterior sample size\n\n## step 1: sample posterior distribution of v from inverse gamma distribution\nv_sample=1/rgamma(n_sample, (T-2)/2, sum((yt[2:T] - phi_MLE*yt[1:(T-1)])^2)/2)\n\n## step 2: sample posterior distribution of phi from normal distribution\nphi_sample=rep(0,n_sample)\nfor (i in 1:n_sample){\nphi_sample[i]=rnorm(1, mean = phi_MLE, sd=sqrt(v_sample[i]/sum(yt[1:(T-1)]^2)))}\n\n## plot histogram of posterior samples of phi and v\npar(mfrow = c(1, 2), cex.lab = 1.3)\nhist(phi_sample, xlab = bquote(phi), \n     main = bquote(\"Posterior for \"~phi),xlim=c(0.75,1.05), col='lightblue')\nabline(v = phi, col = 'red')\nhist(v_sample, xlab = bquote(v), col='lightblue', main = bquote(\"Posterior for \"~v))\nabline(v = sd, col = 'red')\n\n\n\n\n\n\n\n\n\n\n\n\nUsing your simulated data from part 1 modify the code above to summarize your posterior inference for \\psi and v based on 5000 samples from the joint posterior distribution of \\psi and v.\n\n\n\n\n\n\nTipGrading Criteria\n\n\n\nThe responses should follow the same template as the sample code provided above but you will submit your code lines in plain text. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect that :\n\nyou generate 800 time points from the AR(1) rather than 500 and plot your simulated data.\nyour simulated data is from an AR(1) with AR cofficient \\psi = -0.8 and variance v = 2 rather than AR(1) with AR coefficient \\psi = 0.9 and variance v = 1 and\nyou obtain 5000 rather than 3000 samples from the posterior distribution from the new simulated process.\n\n\n\n\n2.7.1 Bayesian Inference in the AR(1), : full likelihood example (reading)\nWe consider a prior distribution that assumes that \\phi and v are independent:\n\np(v) \\propto \\frac{1}{v},\n\n\np(\\phi) = \\frac{1}{2}, \\quad \\text{for } \\phi \\in (-1, 1),\n\ni.e., we assume a Uniform prior for \\phi \\in (-1, 1). Combining this prior with the full likelihood in the AR(1) case, we obtain the following posterior density:\n\np(\\phi, v \\mid y_{1:T}) \\propto \\frac{(1 - \\phi^2)^{1/2} }{v^{T/2 + 1}} \\exp\\left(-\\frac{Q^*(\\phi)}{2v}\\right), \\quad -1 &lt; \\phi &lt; 1,\n\nwith\n\nQ^*(\\phi) = y_1^2(1 - \\phi^2) + \\sum_{t=2}^{T} (y_t - \\phi y_{t-1})^2.\n\nIt is not possible to get a closed-form expression for this posterior or to perform direct simulation. Therefore, we use simulation-based Markov Chain Monte Carlo (MCMC) methods to obtain samples from the posterior distribution.\n\n\n2.7.2 Transformation of \\phi\nWe first consider the following transformation on \\phi:\n\n\\eta = \\log\\left(\\frac{1 - \\phi}{\\phi + 1}\\right),\n\nso that \\eta \\in (-\\infty, \\infty). The inverse transformation on \\eta is:\n\n\\phi = \\frac{1 - \\exp(\\eta)}{1 + \\exp(\\eta)}.\n\nWriting down the posterior density for \\eta and v, we obtain\n\np(\\eta, v \\mid y_{1:T}) \\propto\\frac{ (1 - \\phi^2)^{1/2} }{v^{T/2 + 1}} \\exp\\left(-\\frac{Q^*(\\phi)}{2v}\\right) \\cdot \\frac{2 \\exp(\\eta)}{(1 + \\exp(\\eta))^2},\n\nwith \\phi written as a function of \\eta. We proceed to obtain samples from this posterior distribution using the MCMC algorithm outlined below. Once we have obtained M samples from \\eta and v after convergence, we can use the inverse transformation above to obtain posterior samples for \\phi.\n\n\n2.7.3 MCMC Algorithm: Bayesian Inference for AR(1), Full Likelihood\nAlgorithm:\n\nInitialize \\eta^{(0)} and \\beta^{(0)}.\nFor m in 1:M do:\n\nSample v^{(m)} \\sim \\text{IG}\\left(\\frac{T}{2}, \\frac{Q^*(\\phi^{(m-1)})}{2}\\right).\nSample \\eta^{(m)} using Metropolis-Hastings:\n\nSample \\eta^* \\sim N(\\eta^{(m-1)}, c), where c is a tuning parameter.\nCompute the importance ratio:\n\n\n\n\n        r = \\frac{p(\\eta^*, v^{(m)} \\mid y_{1:T})}{p(\\eta^{(m-1)}, v^{(m)} \\mid y_{1:T})}.\n\n\nSet:\n\n\n        \\eta^{(m)} =\n        \\begin{cases}\n        \\eta^* & \\text{with probability } \\min(r, 1), \\\\\n        \\eta^{(m-1)} & \\text{otherwise}.\n        \\end{cases}",
    "crumbs": [
      "4. Time series Models",
      "Introductions to Time Series analysis & the AR(1) process"
    ]
  },
  {
    "objectID": "C2-L03.html",
    "href": "C2-L03.html",
    "title": "Monte Carlo estimation",
    "section": "",
    "text": "Before we learn how to simulate from complicated posterior distributions, let’s review some of the basics of Monte Carlo estimation.\nMonte Carlo estimation refers to simulating hypothetical draws from a probability distribution in order to calculate important quantities. By “important quantities,” we mean things like the mean, the variance, or the probability of some event or distributional property.\nAll of these calculations involve integration, which except for the simplest distributions, may range from very difficult to impossible :-) .\nSuppose we have a random variable \\theta that follows a \\Gamma distribution\n\n\\theta \\sim \\mathrm{Gamma}(a,b) \\qquad\n\\tag{1}\nLet’s say a=2 and b=\\frac{1}{3} , where a is the shape parameter and b is the rate parameter.\n\n  a=2 \\qquad b=1/3 \\qquad\n\\tag{2}\nTo calculate the mean of this distribution, we would need to compute the following integral. It is possible to compute this integral, and the answer is \\frac{a}{b} (6 in this case).\n\n\\mathbb{E}[\\theta] = \\int_0^\\infty \\theta f(\\theta) d\\theta = \\int_0^\\infty \\theta \\frac{b^a}{\\Gamma(a)}\\theta^{a-1}e^{-b\\theta} d\\theta = \\frac{a}{b} \\qquad\n\\tag{3}\nHowever, we could verify this answer through Monte Carlo estimation.\nTo do so, we would simulate a large number of draws (call them \\theta^∗_i \\quad (i=1,\\ldots ,m) ) from this gamma distribution and calculate their sample mean.\nWhy can we do this?\nRecall from the previous course that if we have a random sample from a distribution, the average of those samples converges in probability to the true mean of that distribution by the Law of Large Numbers.\nFurthermore, by the Central Limit Theorem (CLT), this sample mean \\bar{\\theta}^* = \\frac{1}{m}\\sum_{i=1}^m \\theta_i^* approximately follows a normal distribution with mean \\mathbb{E}[\\theta] and variance \\mathbb{V}ar[\\theta]/m .\nThe theoretical variance of \\theta is the following integral:\n\n\\text{Var}[\\theta] = \\int_0^\\infty (\\theta-\\mathbb{E}(\\theta))^2 f(\\theta) d\\theta \\qquad\n\\tag{4}\nJust like we did with the mean, we could approximate this variance with the sample variance\n\n\\text{Var}[\\theta^*] = \\frac{1}{m}\\sum_{i=1}^m (\\theta_i^* - \\bar{\\theta}^*)^2 \\qquad\n\\tag{5}",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#sec-monte-carlo-integration",
    "href": "C2-L03.html#sec-monte-carlo-integration",
    "title": "Monte Carlo estimation",
    "section": "",
    "text": "Before we learn how to simulate from complicated posterior distributions, let’s review some of the basics of Monte Carlo estimation.\nMonte Carlo estimation refers to simulating hypothetical draws from a probability distribution in order to calculate important quantities. By “important quantities,” we mean things like the mean, the variance, or the probability of some event or distributional property.\nAll of these calculations involve integration, which except for the simplest distributions, may range from very difficult to impossible :-) .\nSuppose we have a random variable \\theta that follows a \\Gamma distribution\n\n\\theta \\sim \\mathrm{Gamma}(a,b) \\qquad\n\\tag{1}\nLet’s say a=2 and b=\\frac{1}{3} , where a is the shape parameter and b is the rate parameter.\n\n  a=2 \\qquad b=1/3 \\qquad\n\\tag{2}\nTo calculate the mean of this distribution, we would need to compute the following integral. It is possible to compute this integral, and the answer is \\frac{a}{b} (6 in this case).\n\n\\mathbb{E}[\\theta] = \\int_0^\\infty \\theta f(\\theta) d\\theta = \\int_0^\\infty \\theta \\frac{b^a}{\\Gamma(a)}\\theta^{a-1}e^{-b\\theta} d\\theta = \\frac{a}{b} \\qquad\n\\tag{3}\nHowever, we could verify this answer through Monte Carlo estimation.\nTo do so, we would simulate a large number of draws (call them \\theta^∗_i \\quad (i=1,\\ldots ,m) ) from this gamma distribution and calculate their sample mean.\nWhy can we do this?\nRecall from the previous course that if we have a random sample from a distribution, the average of those samples converges in probability to the true mean of that distribution by the Law of Large Numbers.\nFurthermore, by the Central Limit Theorem (CLT), this sample mean \\bar{\\theta}^* = \\frac{1}{m}\\sum_{i=1}^m \\theta_i^* approximately follows a normal distribution with mean \\mathbb{E}[\\theta] and variance \\mathbb{V}ar[\\theta]/m .\nThe theoretical variance of \\theta is the following integral:\n\n\\text{Var}[\\theta] = \\int_0^\\infty (\\theta-\\mathbb{E}(\\theta))^2 f(\\theta) d\\theta \\qquad\n\\tag{4}\nJust like we did with the mean, we could approximate this variance with the sample variance\n\n\\text{Var}[\\theta^*] = \\frac{1}{m}\\sum_{i=1}^m (\\theta_i^* - \\bar{\\theta}^*)^2 \\qquad\n\\tag{5}",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#calculating-probabilities",
    "href": "C2-L03.html#calculating-probabilities",
    "title": "Monte Carlo estimation",
    "section": "0.2 Calculating probabilities",
    "text": "0.2 Calculating probabilities\n\n\n\n\nMonte Carlo Integration\n\nThis method can be used to calculate many different integrals. Say h(\\theta) is any function and we want to calculate\n\n\\int h(\\theta) p(\\theta) d\\theta = \\mathbb{E}(h(\\theta)) \\approx \\frac{1}{m}\\sum_{i=1}^m h(\\theta_i^*) \\qquad\n\\tag{6}\nwhere p(\\theta) is the probability density function of \\theta and h(\\theta) is any function of \\theta.\nThis integral is precisely what is meant by \\mathbb{E}[h(\\theta)] , so we can conveniently approximate it by taking the sample mean of h(\\theta_i^*). That is, we apply the function h to each simulated sample from the distribution, and take the average of all the results.\nOne extremely useful example of an h function is is the indicator I_A(\\theta) where A is some logical condition about the value of \\theta. To demonstrate, suppose h(\\theta)=I_{[\\theta&lt;5]}(\\theta), which will give a 1 if \\theta &lt;5 and return a 0 otherwise.\nWhat is \\mathbb{E}(h(\\theta))?\nThis is the integral:\n\n\\begin{aligned}\n\\mathbb{E}[h(\\theta)] &= \\int_0^\\infty \\mathbb{I}_{[\\theta&lt;5]}(\\theta) p(\\theta) d\\theta \\\\\n&= \\int_0^5 1 \\cdot p(\\theta) d\\theta + \\int_5^\\infty 0 \\cdot p(\\theta) d\\theta \\\\\n&= P(\\theta &lt; 5) \\qquad\n\\end{aligned}\n\\tag{7}\nSo what does this mean?\nIt means we can approximate the probability that \\theta &lt; 5 by drawing many samples \\theta^∗_i , and approximating this integral with \\frac{1}{m} \\sum_{i=1}^m I_{\\theta^* &lt; 5} (\\theta_i^*). This expression is simply counting how many of those samples come out to be less than 5 , and dividing by the total number of simulated samples.\nThat’s convenient!\nLikewise, we can approximate quantiles of a distribution. If we are looking for the value z such that P(\\theta &lt; z) = 0.9 , we simply arrange the samples \\theta^∗_i in ascending order and find the smallest drawn value that is greater than 90% of the others.",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#monte-carlo-error-and-marginalization",
    "href": "C2-L03.html#monte-carlo-error-and-marginalization",
    "title": "Monte Carlo estimation",
    "section": "0.3 Monte Carlo Error and Marginalization",
    "text": "0.3 Monte Carlo Error and Marginalization\n\n\n\n\nMonte Carlo Error and Marginalization\n\nHow good is an approximation by Monte Carlo sampling?\nAgain we can turn to the CLT, which tells us that the variance of our estimate is controlled in part by m. For a better estimate, we want larger m.\nFor example, if we seek \\mathbb{E}[\\theta] , then the sample mean \\bar\\theta^∗ approximately follows a normal distribution with mean \\mathbb{E}[\\theta] and variance Var[\\theta]/m .\nThe variance tells us how far our estimate might be from the true value.\nOne way to approximate Var[\\theta] is to replace it with the sample variance.\nThe standard deviation of our Monte Carlo estimate is the square root of that, or the sample standard deviation divided by \\sqrt{m} .\nIf m is large, it is reasonable to assume that the true value will likely be within about two standard deviations of your Monte Carlo estimate.",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#marginalization",
    "href": "C2-L03.html#marginalization",
    "title": "Monte Carlo estimation",
    "section": "0.4 Marginalization",
    "text": "0.4 Marginalization\nWe can also obtain Monte Carlo samples from hierarchical models.\nAs a simple example, let’s consider a binomial random variable where y\\mid\\phi\\sim Bin(10,\\phi) and further suppose \\phi is random (as if it had a prior) and is distributed beta \\phi \\sim Beta(2,2) .\nGiven any hierarchical model, we can always write the joint distribution of y and \\phi as p(y,\\phi) = p(y \\mid \\phi)p(\\phi) using the chain rule of probability.\nTo simulate from this joint distribution, repeat these steps for a large number m :\n\nSimulate \\phi^∗_i from its Beta(2,2) distribution.\nGiven the drawn \\phi^∗_i , simulate y^∗_i from Bin(10,\\phi^*_i) .\n\nThis will produce m independent pairs of (y^∗,\\phi^∗)_i drawn from their joint distribution.\nOne major advantage of Monte Carlo simulation is that marginalizing is easy. Calculating the marginal distribution of y , p(y)=\\int^1_0 p(y,\\phi)d\\phi, might be challenging. But if we have draws from the joint distribution, we can just discard the \\phi^∗_i draws and use the y^∗_i as samples from their marginal distribution.\nThis is also called the prior predictive distribution introduced in the previous course.\nIn the next segment, we will demonstrate some of these principles.\nRemember, we do not yet know how to sample from the complicated posterior distributions introduced in the previous lesson.\nBut once we learn that, we will be able to use the principles from this lesson to make approximate inferences from those posterior distributions.",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#computing-examples",
    "href": "C2-L03.html#computing-examples",
    "title": "Monte Carlo estimation",
    "section": "0.5 Computing Examples",
    "text": "0.5 Computing Examples\nMonte Carlo simulation from the most common distributions is very straightforward in R.\nLet’s start with the example from the previous segment, where \\theta \\sim Gamma(a,b) with a=2, b=1/3 . This could represent the posterior distribution of \\theta if our data came from a Poisson distribution with mean \\theta and we had used a conjugate gamma prior. Let’s start with m=100 .\n\n\nCode\nset.seed(32) # Initializes the random number generator so we can replicate these results. To get different random numbers, change the seed. \nm = 100 \na = 2.0 \nb = 1.0 / 3.0 \n\n\nTo simulate m independent samples, use the rgamma function.\n\n\nCode\ntheta &lt;- rgamma(n=m, shape = a, rate=b) \n\n\nWe can plot a histogram of the generated data, and compare that to the true density.\n\n\nCode\nhist(theta, freq=FALSE) \ncurve(dgamma(x=x, shape=a, rate=b), col=\"blue\", add=TRUE)\n\n\n\n\n\n\n\n\nFigure 1: Histogram of simulated gamma samples with true density\n\n\n\n\n\nTo find our Monte Carlo approximation to \\mathbb{E}(\\theta) , let’s take the average of our sample (and compare it with the truth).\n\n\nCode\nsum(theta) / m # sample mean \n\n\n[1] 5.514068\n\n\n\n\nCode\nmean(theta) # sample mean \n\n\n[1] 5.514068\n\n\n\n\nCode\na / b # true expected value\n\n\n[1] 6\n\n\nNot bad, but we can do better if we increase m to say, 10,000.\n\n\nCode\nm = 1e4 \ntheta = rgamma(n=m, shape=a, rate=b) \nmean(theta)\n\n\n[1] 6.023273\n\n\nHow about the variance of \\theta ?\n\n\nCode\nvar(theta) # sample variance\n\n\n[1] 18.04318\n\n\n\n\nCode\na / b^2 # true variance of Gamma(a,b) \n\n\n[1] 18\n\n\nWe can also approximate the probability that \\theta &lt; 5 .\n\n\nCode\nind = theta &lt; 5.0 # set of indicators, TRUE if theta_i &lt; 5 \nmean(ind)         # automatically converts FALSE/TRUE to 0/1 \n\n\n[1] 0.497\n\n\n\n\nCode\npgamma(q=5.0, shape=a, rate=b) # true value of Pr( theta &lt; 5 )\n\n\n[1] 0.4963317\n\n\nWhat is the 0.9 quantile (90th percentile) of \\theta ? We can use the quantile function which will order the samples for us and find the appropriate sample quantile.\n\n\nCode\nquantile(x=theta, probs=0.9) \n\n\n     90% \n11.74338 \n\n\n\n\nCode\nqgamma(p=0.9, shape=a, rate=b) # true value of 0.9 quantile\n\n\n[1] 11.66916",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#monte-carlo-error",
    "href": "C2-L03.html#monte-carlo-error",
    "title": "Monte Carlo estimation",
    "section": "0.6 Monte Carlo error",
    "text": "0.6 Monte Carlo error\nWe can use the CLT to approximate how accurate our Monte Carlo estimates are. For example, if we seek E(\\theta) , then the sample mean \\bar\\theta^∗ approximately follows a normal distribution with mean \\mathbb{E}(\\theta) and variance Var(\\theta)/m . We will use the sample standard deviation divided by the square root of m to approximate the Monte Carlo standard deviation.\n\n\nCode\nse = sd(theta) / sqrt(m) \n2.0 * se # we are reasonably confident that the Monte Carlo estimate is no more than this far from the truth\n\n\n[1] 0.08495454\n\n\nThese numbers give us a reasonable range for the quantity we are estimating with Monte Carlo. The same applies for other Monte Carlo estimates, like the probability that \\theta &lt; 5.\n\n\nCode\nind = theta &lt; 5.0 \nse = sd(ind) / sqrt(m)\n2.0 * se # we are reasonably confident that the Monte Carlo estimate is no more than this far from the truth \n\n\n[1] 0.01000032",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#marginalization-1",
    "href": "C2-L03.html#marginalization-1",
    "title": "Monte Carlo estimation",
    "section": "0.7 Marginalization",
    "text": "0.7 Marginalization\nLet’s also do the second example of simulating a hierarchical model. In our example from the previous segment, we had a binomial random variable where y \\mid \\phi \\overset{\\text{iid}}{\\sim}\\text{Binomial}(10,\\phi), and \\phi \\sim Beta(2,2). To simulate from this joint distribution, repeat these steps for a large number m :\n\nSimulate \\phi_i from its Beta(2,2) distribution.\nGiven the drawn \\phi_i , simulate y_i from Bin(10,\\phi_i) .\n\n\n\nCode\nm = 10e4\n\ny = numeric(m) # create the vectors we will fill in with simulations \nphi = numeric(m)\n\nfor (i in 1:m) {\n  phi[i] = rbeta(n=1, shape1=2.0, shape2=2.0)\n  y[i] = rbinom(n=1, size=10, prob=phi[i]) \n} \n# which is equivalent to the following 'vectorized' code \nphi = rbeta(n=m, shape1=2.0, shape2=2.0) \ny = rbinom(n=m, size=10, prob=phi)\n\n\nIf we are interested only in the marginal distribution of y , we can just ignore the draws for \\phi and treat the draws of y as a sample from its marginal distribution.\n\n\nCode\nmean(y) \n\n\n[1] 5.00008\n\n\n\n\nCode\nplot(prop.table(table(y)), ylab=\"P(y)\", main=\"Marginal distribution of y\")\n\n\n\n\n\n\n\n\nFigure 2",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#definition",
    "href": "C2-L03.html#definition",
    "title": "Monte Carlo estimation",
    "section": "1.1 Definition",
    "text": "1.1 Definition\nIf we have a sequence of random variables X_1,X_2,\\dots X_n where the indices 1,2,\\dots,n represent successive points in time, we can use the chain rule of probability to calculate the probability of the entire sequence:\n\np(X_1, X_2, \\ldots X_n) = p(X_1) \\cdot p(X_2 \\mid X_1) \\cdot p(X_3 \\mid X_2, X_1) \\cdot \\ldots \\cdot p(X_n \\mid X_{n-1}, X_{n-2}, \\ldots, X_2, X_1) \\qquad\n\\tag{8}\nMarkov chains simplify this expression by using the Markov assumption. The assumption is that given the entire past history, the probability distribution for the random variable at the next time step only depends on the current variable. Mathematically, the assumption is written like this:\n\np(X_{t+1} \\mid X_t, X_{t-1}, \\ldots, X_2, X_1 ) = p(X_{t+1} \\mid X_t) \\qquad\n\\tag{9}\nfor all t=2,\\dots,n. Under this assumption, we can write the first expression as\n\np(X_1, X_2, \\ldots X_n) = p(X_1) \\cdot p(X_2 \\mid X_1) \\cdot p(X_3 \\mid X_2) \\cdot p(X_4 \\mid X_3) \\cdot \\ldots \\cdot p(X_n \\mid X_{n-1}) \\qquad\n\\tag{10}\nwhich is much simpler than the original. It consists of an initial distribution for the first variable, p(X1), and n−1 transition probabilities. We usually make one more assumption: that the transition probabilities do not change with time. Hence, the transition from time t to time t+1 depends only on the value of Xt.",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#examples-of-markov-chains",
    "href": "C2-L03.html#examples-of-markov-chains",
    "title": "Monte Carlo estimation",
    "section": "1.2 Examples of Markov chains",
    "text": "1.2 Examples of Markov chains\n\n1.2.1 Discrete Markov chain\nSuppose you have a secret number (make it an integer) between 1 and 5. We will call it your initial number at step 1. Now for each time step, your secret number will change according to the following rules:\n\nFlip a coin.\n\nIf the coin turns up heads, then increase your secret number by one (5 increases to 1).\nIf the coin turns up tails, then decrease your secret number by one (1 decreases to 5).\n\nRepeat n times, and record the evolving history of your secret number.\n\nBefore the experiment, we can think of the sequence of secret numbers as a sequence of random variables, each taking on a value in \\{1,2,3,4,5\\}. Assume that the coin is fair, so that with each flip, the probability of heads and tails are both 0.5.\nDoes this game qualify as a true Markov chain? Suppose your secret number is currently 4 and that the history of your secret numbers is (2,1,2,3). What is the probability that on the next step, your secret number will be 5? What about the other four possibilities? Because of the rules of this game, the probability of the next transition will depend only on the fact that your current number is 4. The numbers further back in your history are irrelevant, so this is a Markov chain.\nThis is an example of a discrete Markov chain, where the possible values of the random variables come from a discrete set. Those possible values (secret numbers in this example) are called states of the chain. The states are usually numbers, as in this example, but they can represent anything. In one common example, the states describe the weather on a particular day, which could be labeled as 1-fair, 2-poor.\n\n\n1.2.2 Random walk (continuous)\nNow let’s look at a continuous example of a Markov chain. Say X_t=0 and we have the following transition model:\n\np(X_{t+1}\\mid X_t=x_t)=N(x_t,1) \\qquad\n\\tag{11}\nThat is, the probability distribution for the next state is Normal with variance 1 and mean equal to the current state. This is often referred to as a “random walk.” Clearly, it is a Markov chain because the transition to the next state Xt+1 only depends on the current state Xt.\nThis example is straightforward to code in R:\n\n\nCode\nset.seed(34)\n\nn = 100\nx = numeric(n)\n\nfor (i in 2:n) {\n  x[i] = rnorm(1, mean=x[i-1], sd=1.0)\n}\n\nplot.ts(x)",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#transition-matrix",
    "href": "C2-L03.html#transition-matrix",
    "title": "Monte Carlo estimation",
    "section": "1.3 Transition matrix",
    "text": "1.3 Transition matrix\nLet’s return to our example of the discrete Markov chain. If we assume that transition probabilities do not change with time, then there are a total of 25 (52) potential transition probabilities. Potential transition probabilities would be from State 1 to State 2, State 1 to State 3, and so forth. These transition probabilities can be arranged into a matrix Q:\n\nQ =\n\\begin{pmatrix}\n0 & .5 & 0 & 0 & .5 \\\\\n.5 & 0 & .5 & 0 & 0 \\\\\n0 & .5 & 0 & .5 & 0 \\\\\n0 & 0 & .5 & 0 & .5 \\\\\n.5 & 0 & 0 & .5 & 0 \\\\\n\\end{pmatrix} \\qquad\n\\tag{12}\nwhere the transitions from State 1 are in the first row, the transitions from State 2 are in the second row, etc. For example, the probability p(Xt+1=5∣Xt=4) can be found in the fourth row, fifth column.\nThe transition matrix is especially useful if we want to find the probabilities associated with multiple steps of the chain. For example, we might want to know p(Xt+2=3∣Xt=1), the probability of your secret number being 3 two steps from now, given that your number is currently 1. We can calculate this as ∑k=15p(Xt+2=3∣Xt+1=k)⋅p(Xt+1=k∣Xt=1), which conveniently is found in the first row and third column of Q2.\nWe can perform this matrix multiplication easily in R:\n\n\nCode\nQ = matrix(c(0.0, 0.5, 0.0, 0.0, 0.5,\n             0.5, 0.0, 0.5, 0.0, 0.0,\n             0.0, 0.5, 0.0, 0.5, 0.0,\n             0.0, 0.0, 0.5, 0.0, 0.5,\n             0.5, 0.0, 0.0, 0.5, 0.0), \n           nrow=5, byrow=TRUE)\n\nQ %*% Q # Matrix multiplication in R. This is Q^2.\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,] 0.50 0.00 0.25 0.25 0.00\n[2,] 0.00 0.50 0.00 0.25 0.25\n[3,] 0.25 0.00 0.50 0.00 0.25\n[4,] 0.25 0.25 0.00 0.50 0.00\n[5,] 0.00 0.25 0.25 0.00 0.50\n\n\n\n\nCode\n(Q %*% Q)[1,3]\n\n\n[1] 0.25\n\n\nTherefore, if your secret number is currently 1, the probability that the number will be 3 two steps from now is .25.",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C2-L03.html#stationary-distribution",
    "href": "C2-L03.html#stationary-distribution",
    "title": "Monte Carlo estimation",
    "section": "1.4 Stationary distribution",
    "text": "1.4 Stationary distribution\nSuppose we want to know the probability distribution of the your secret number in the distant future, say p(X_{t+h} \\mid X_t) where h is a large number. Let’s calculate this for a few different values of h.\n\n\nCode\nQ5 = Q %*% Q %*% Q %*% Q %*% Q # h=5 steps in the future\nround(Q5, 3)\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 0.062 0.312 0.156 0.156 0.312\n[2,] 0.312 0.062 0.312 0.156 0.156\n[3,] 0.156 0.312 0.062 0.312 0.156\n[4,] 0.156 0.156 0.312 0.062 0.312\n[5,] 0.312 0.156 0.156 0.312 0.062\n\n\n\n\nCode\nQ10 = Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q %*% Q # h=10 steps in the future\nround(Q10, 3)\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 0.248 0.161 0.215 0.215 0.161\n[2,] 0.161 0.248 0.161 0.215 0.215\n[3,] 0.215 0.161 0.248 0.161 0.215\n[4,] 0.215 0.215 0.161 0.248 0.161\n[5,] 0.161 0.215 0.215 0.161 0.248\n\n\n\n\nCode\nQ30 = Q\nfor (i in 2:30) {\n  Q30 = Q30 %*% Q\n}\nround(Q30, 3) # h=30 steps in the future\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 0.201 0.199 0.200 0.200 0.199\n[2,] 0.199 0.201 0.199 0.200 0.200\n[3,] 0.200 0.199 0.201 0.199 0.200\n[4,] 0.200 0.200 0.199 0.201 0.199\n[5,] 0.199 0.200 0.200 0.199 0.201\n\n\nNotice that as the future horizon gets more distant, the transition distributions appear to converge. The state you are currently in becomes less important in determining the more distant future. If we let h get really large, and take it to the limit, all the rows of the long-range transition matrix will become equal to (.2,.2,.2,.2,.2). That is, if you run the Markov chain for a very long time, the probability that you will end up in any particular state is 1/5=.2 for each of the five states. These long-range probabilities are equal to what is called the stationary distribution of the Markov chain.\nThe stationary distribution of a chain is the initial state distribution for which performing a transition will not change the probability of ending up in any given state. That is,\n\n\nCode\nc(0.2, 0.2, 0.2, 0.2, 0.2) %*% Q\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]  0.2  0.2  0.2  0.2  0.2\n\n\nOne consequence of this property is that once a chain reaches its stationary distribution, the stationary distribution will remain the distribution of the states thereafter.\nWe can also demonstrate the stationary distribution by simulating a long chain from this example.\n\n\nCode\nn = 5000\nx = numeric(n)\nx[1] = 1 # fix the state as 1 for time 1\nfor (i in 2:n) {\n  x[i] = sample.int(5, size=1, prob=Q[x[i-1],]) # draw the next state from the intergers 1 to 5 with probabilities from the transition matrix Q, based on the previous value of X.\n}\n\n\nNow that we have simulated the chain, let’s look at the distribution of visits to the five states.\n\nCode\ntable(x) / n\n\n\n\n\nTable 1\n\n\n\nx\n     1      2      3      4      5 \n0.1996 0.2020 0.1980 0.1994 0.2010 \n\n\n\n\nThe overall distribution of the visits to the states is approximately equal to the stationary distribution.\nAs we have just seen, if you simulate a Markov chain for many iterations, the samples can be used as a Monte Carlo sample from the stationary distribution. This is exactly how we are going to use Markov chains for Bayesian inference. In order to simulate from a complicated posterior distribution, we will set up and run a Markov chain whose stationary distribution is the posterior distribution.\nIt is important to note that the stationary distribution doesn’t always exist for any given Markov chain. The Markov chain must have certain properties, which we won’t discuss here. However, the Markov chain algorithms we’ll use in future lessons for Monte Carlo estimation are guaranteed to produce stationary distributions.\n\n1.4.1 Continuous example\nThe continuous random walk example we gave earlier does not have a stationary distribution. However, we can modify it so that it does have a stationary distribution.\nLet the transition distribution be p(X_{t + 1}\\mid X_t = x_t)=N(\\phi x_t,1) where -1 &lt; \\phi &lt; 1. That is, the probability distribution for the next state is Normal with variance 1 and mean equal to ϕ times the current state. As long as \\phi is between −1 and 1, then the stationary distribution will exist for this model.\nLet’s simulate this chain for \\phi=−0.6.\n\n\nCode\nset.seed(38)\n\nn = 1500\nx = numeric(n)\nphi = -0.6\n\nfor (i in 2:n) {\n  x[i] = rnorm(1, mean=phi*x[i-1], sd=1.0)\n}\n\nplot.ts(x)\n\n\n\n\n\n\n\n\nFigure 3: Simulated AR(1) process with phi=-0.6\n\n\n\n\n\nThe theoretical stationary distribution for this chain is normal with mean 0 and variance 1/(1−\\phi^2), which in our example approximately equals 1.562. Let’s look at a histogram of our chain and compare that with the theoretical stationary distribution.\n\n\\text{Var}_{\\text{stationary}} = \\frac{1}{1-\\phi^2} \\qquad\n\\tag{13}\n\n\nCode\nhist(x, freq=FALSE)\ncurve(dnorm(x, mean=0.0, sd=sqrt(1.0/(1.0-phi^2))), col=\"red\", add=TRUE)\nlegend(\"topright\", legend=\"theoretical stationary\\ndistribution\", col=\"red\", lty=1, bty=\"n\")\n\n\n\n\n\n\n\n\nFigure 4: Histogram of simulated AR(1) process with theoretical stationary distribution\n\n\n\n\n\nIt appears that the chain has reached the stationary distribution. Therefore, we could treat this simulation from the chain like a Monte Carlo sample from the stationary distribution, a normal with mean 0 and variance 1.562.\nBecause most posterior distributions we will look at are continuous, our Monte Carlo simulations with Markov chains will be similar to this example.",
    "crumbs": [
      "2. Techniques and Models",
      "Monte Carlo estimation"
    ]
  },
  {
    "objectID": "C1-L08.html",
    "href": "C1-L08.html",
    "title": "Poisson Data",
    "section": "",
    "text": "Figure 1: Poisson likelihood with a Gamma prior\n\n\n\n\n0.1 Poisson - Chocolate Chip Cookie\nIn mass-produced chocolate chip cookies, they make a large amount of dough; mix in a large number of chips; then chunk out the individual cookies. In this process, the number of chips per cookie approximately follows a Poisson distribution.\nIf we were to assume that chips have no volume, then this would be exactly a Poisson process and follow exactly a Poisson distribution. In practice, since chips are not that small, so they follow approximately a Poisson distribution for the number of chips per cookie.\n\n\n\nY_i \\sim \\mathrm{Poisson}(\\lambda)\n\\tag{1}\n The likelihood of the data is given by the Poisson distribution.What is the likelihood of the data?\n\n\\begin{aligned}\n{\\color{red}f(y \\mid \\lambda) = \\frac{\\lambda^{\\sum{y_i}}e^{-n\\lambda}}{\\prod_{i = 1}^n{y_i!}}} \\quad \\forall (\\lambda &gt; 0) && \\text{ Poisson Likelihood }\n\\end{aligned}\n\n It would be convenient if we could put a conjugate prior. What distribution looks like \\lambda raised to a power and e raised to a negative power?What type of prior should we put on \\lambda ?\nFor this, we’re going to use a Gamma prior.\n\n\\begin{aligned} \\lambda &\\sim \\mathrm{Gamma}(\\alpha, \\beta) && \\text{Gamma Prior} \\\\ \\color{green}{ f(\\lambda)} &= \\color{green}{\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\lambda^{\\alpha - 1}e^{-\\beta\\lambda}} && \\text{subst. Gamma PDF} \\end{aligned}\n\\tag{2}\n We can use Bayes theorem to find the posterior.What is the posterior?\n\n\\begin{aligned} {\\color{blue}f(\\lambda \\mid y)} &\\propto \\color{red}{ f(y \\mid \\lambda)} \\color{green}{ f(\\lambda)} && \\text{Bayes without the denominator} \\\\ &\\propto \\color{red}{\\lambda^{\\sum{y_i}}e^{-n\\lambda}}\\color{green}{\\lambda^{\\alpha - 1}e^{-\\beta \\lambda} } && \\text{subst. Likelihood and Prior}\n\\\\ & \\propto { \\color{blue} \\lambda^{\\alpha + \\sum{y_i} - 1}e^{-(\\beta + n)\\lambda} } && \\text{collecting terms}\n\\\\ & \\propto { \\color{blue} \\mathrm{Gamma}(\\alpha + \\sum{y_i}, \\beta + n)}\n\\end{aligned}\n\\tag{3}\n The posterior is a Gamma distribution with parameters \\alpha + \\sum{y_i} and \\beta + n.What is the posterior distribution?\nThus we can see that the posterior is a Gamma Distribution\n\n\\lambda \\mid y \\sim \\mathrm{Gamma}(\\alpha + \\sum{y_i}, \\beta + n)\n\\tag{4}\n The posterior mean of a Gamma distribution is given byWhat is the posterior mean?\nThe mean of Gamma under this parameterization is: \\frac{\\alpha}{\\beta}\nThe posterior mean is going to be\n\n\\begin{aligned}\n{\\color{blue}\\mu_{\\lambda}} &= \\frac{\\alpha + \\sum{y_i}}{\\beta + n} && \\text{(Posterior Mean)} \\\\\nposterior_{\\mu}\n&= \\frac{\\alpha + \\sum{y_i}}{\\beta + n} \\\\\n&= \\frac{\\beta}{\\beta + n}\\frac{\\alpha}{\\beta} + \\frac{n}{\\beta + n}\\frac{\\sum{y_i}}{n} \\\\\n& \\propto  \\beta \\cdot \\mu_\\text{prior} + n\\cdot \\mu_\\text{data}\n\\end{aligned}\n\\tag{5}\n The posterior variance of a Gamma distribution is given byWhat is the posterior variance?\nAs you can see here the posterior mean of the Gamma distribution is also the weighted average of the prior mean and the data mean.\nTherefore, the effective sample size (ESS) of the Gamma prior is \\beta\n\n\n\n\n\n\nTipPrior Elicitation of Gamma Hyper-parameters\n\n\n\nHere are two strategies for choose the hyper-parameters \\alpha and \\beta\n\nAn informative prior with a prior mean guess of \\mu=\\frac{a}{b} e.g. what is the average number of chips per cookie?\n\nNext we need another piece of knowledge to pinpoint both parameters.\nCan you estimate the error for the mean? I.e. what do you think the standard deviation is? Since for the Gamma prior\nWhat is the effective sample size \\text{ESS}=\\beta ?\nHow many units of information do you think we have in our prior v.s. our data points ? \\sigma = \\frac{ \\sqrt{\\alpha} }{\\beta}\n\nA vague prior refers to one that’s relatively flat across much of the space.\n\nFor a Gamma prior we can choose \\Gamma(\\epsilon, \\epsilon) where \\epsilon is small and strictly positive. This would create a distribution with a \\mu = 1 and a huge \\sigma stretching across the whole space. And the effective sample size will also be \\epsilon Hence the posterior will be largely driven by the data and very little by the prior.\n\n\n\n\nThe first strategy with a mean and an ESS will be used in numerous models going forward so it is best to remember these two strategies!",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Poisson Data"
    ]
  },
  {
    "objectID": "C1-L12-Ex2.html",
    "href": "C1-L12-Ex2.html",
    "title": "",
    "section": "",
    "text": "1. From Concept to Data AnalysisHonnors Homework On Regression CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Honnors Homework On Regression"
    ]
  },
  {
    "objectID": "C1-L12-Ex2.html#honnors-homework-on-regression",
    "href": "C1-L12-Ex2.html#honnors-homework-on-regression",
    "title": "",
    "section": "1 Honnors Homework On Regression",
    "text": "1 Honnors Homework On Regression\n\nExercise 1 Golf\nThe data are found at pgalpga2008.dat and consist of season statistics for individual golfers on the United States LPGA and PGA tours. The first column reports each player’s average driving distance in yards. The second column reports the percentage of the player’s drives that finish in the fairway, measuring their accuracy. The third and final column has a 1 to denote a female golfer (on the LPGA tour), and a 2 to denote male golfer (on the PGA tour).\nNow consider a multiple regression on the full data set, including both female and male golfers. Modify the third variable to be a 0 if the golfer is female and 1 if the golfer is male and fit the following regression:\n\n\\mathbb{E}[y] = b_0 + b_1x_1 + b_2x_2\n\nwhere\n\nx_1 is the average driving distance and\nx_2 is the indicator that the golfer is male.\n\nWhat is the posterior mean estimate of b_0 ? Round your answer to the nearest whole number.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\n\nCode\ndat=read.table(\"data/pgalpga2008.dat.txt\", header=T)\n# Note that attaching this masks T which is originally TRUE\nattach(dat)\ncolnames(dat) &lt;- c('distance','accuracy','gender')\n\ndat$gender = dat$gender -1\nmod2 &lt;- lm(accuracy ~ distance + gender, data=dat)\nsummary(mod2)\n\n\n\nCall:\nlm(formula = accuracy ~ distance + gender, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.0871  -2.8427   0.4869   3.3746  12.0241 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 147.3354     7.0460  20.911  &lt; 2e-16 ***\ndistance     -0.3231     0.0285 -11.334  &lt; 2e-16 ***\ngender        8.9468     1.2714   7.037 1.04e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.803 on 350 degrees of freedom\nMultiple R-squared:  0.359, Adjusted R-squared:  0.3553 \nF-statistic:    98 on 2 and 350 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nExercise 2  The posterior mean estimates of the other two coefficients are \\hat{b}_1=−0.323, and \\hat{b}_2=8.94. What is the interpretation of \\hat{b}_1?Golf\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nHolding all else constant, being male is associated with a 0.323 increase in drive accuracy percentage.\nHolding all else constant, each additional yard of distance is associated with a 0.323 increase in drive accuracy percentage.\nHolding all else constant, each additional yard of distance is associated with a 0.323 decrease in drive accuracy percentage.\nHolding all else constant, being male is associated with a 0.323 decrease in drive accuracy percentage.\n\n\n\n\n\nExercise 3 Golf\nThe standard error for b_1 (which we can think of as marginal posterior standard deviation in this case) is roughly 1/10 times the magnitude of the posterior mean estimate \\hat{b}_1=−0.323. In other words, the posterior mean is more than 10 posterior standard deviations from 0. What does this suggest?\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe posterior probability that b_1&lt;0 is very low, suggesting a negative relationship between driving distance and accuracy.\nThe posterior probability that b_1&lt;0 is about 0.5, suggesting no evidence for an association between driving distance and accuracy.\nThe posterior probability that b_1&lt;0 is very high, suggesting a negative relationship between driving distance and accuracy.\n\n\n\n\n\nExercise 4 Golf\nThe estimated value of b_2 would typically be interpreted to mean that holding all else constant (for a fixed driving distance), golfers on the PGA tour are about 9% more accurate with their drives on average than golfers on the LPGA tour. However, if you explore the data, you will find that the PGA tour golfers’ average drives are 40+ yards longer than LPGA tour golfers’ average drives, and that the LPGA tour golfers are actually more accurate on average. Thus b_2 , while a vital component of the model, is actually a correction for the discrepancy in driving distances. Although model fitting can be easy (especially with software), interpreting the results requires a thoughtful approach.\nIt would also be prudent to check that the model fits the data well. One of the primary tools in regression analysis is the residual plot. Residuals are defined as the observed values y minus their predicted values \\hat{y} . Patterns in the plot of \\hat{y} versus residuals, for example, can indicate an inadequacy in the model. These plots are easy to produce.\n\n\nCode\nplot(fitted(mod2), residuals(mod2))\nabline(lm(residuals(mod2)~fitted(mod2)), col=\"red\") # regression line (y~x)\n\n\n\n\n\n\n\n\n\nwhere “mod” is the model object fitted with the lm() command.\n\n\n\n\n\n\n\nTipSolution:\n\n\n\n\n\n\nThe residuals appear to be random and lack any patterns or trends. There are no outliers (extreme observations).\nThe residuals appear to be random and lack any patterns or trends. However, there is at least one outlier (extreme observation) that we may want to investigate.\nThe residuals appear to be more spread apart for smaller predicted values \\hat{y} . There are no outliers (extreme observations).\nThe residuals appear to exhibit a curved trend. There is at least one outlier (extreme observation) that we may want to investigate.",
    "crumbs": [
      "1. From Concept to Data Analysis",
      "Honnors Homework On Regression"
    ]
  },
  {
    "objectID": "C4-L05.html",
    "href": "C4-L05.html",
    "title": "Final Project",
    "section": "",
    "text": "In this final project you will use normal dynamic linear models to analyze a time series dataset downloaded from Google trend.\n\n\n\n\n\n\nNoteObjectives\n\n\n\n\nUse R for analysis and forecasting of time series using NDLM (case of known observational and system variances)\nUse R for analysis and forecasting of time series using the NDLM (cases of known or unknown observational variance and unknown system variance specified using a discount factor)\n\n\n\n\n\n\n\n\n\nNoteInstructions\n\n\n\nSo far in this course, we have discussed the following aspects of Bayesian time series models:\n\nConcepts of stationarity, the autocorrelation function, definition and properties of autoregressive (AR) models;\nMaximum likelihood and Bayesian conjugate analysis of AR models;\nDetermination of the order of AR models using AIC or BIC as criteria;\nDefinition of Normal Dynamic Linear Models (NDLMs);\nNDLM building using polynomial trend, seasonal and regression components via the superposition principle;\nBayesian filtering, smoothing and forecasting in the NDLM with known observational variances and known system covariance matrices;\nBayesian filtering, smoothing and forecasting in the NDLM with unknown but constant observational variance and known system covariance matrix;\nBayesian filtering, smoothing and forecasting in the NDLM with known observational variances and unknown system covariance matrices using discount factors;\nBayesian filtering, smoothing and forecasting in the NDLM with unknown but constant observational variance and unknown system covariance matrices using discount factors.\n\nIn this project, you will download a dataset from Google trends. In order to do this you can type a term/terms of interest in Google trends, just like we did with the example with the term “time series” analyzed in the course. You could use any term such as “flu”, “cranberry” or any other term(s). Here is a tutorial on how to download data from Google trends:",
    "crumbs": [
      "4. Time series Models",
      "Final Project"
    ]
  },
  {
    "objectID": "C4-L04.html",
    "href": "C4-L04.html",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "",
    "text": "NoteLearning Objectives\n\n\n\n\n\n\nUse R for analysis and forecasting of time series using the NDLM (cases of known or unknown observational variance and unknown system variance specified using a discount factor)\nDerive the equations to obtain posterior inference and forecasting in the NDLM with unknown observational variance and system variance specified via discount factors\nDefine seasonal NDLMs\nApply the NDLM superposition principle and explain the role of the forecast function",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#seasonal-ndlms",
    "href": "C4-L04.html#seasonal-ndlms",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "",
    "text": "NoteLearning Objectives\n\n\n\n\n\n\nUse R for analysis and forecasting of time series using the NDLM (cases of known or unknown observational variance and unknown system variance specified using a discount factor)\nDerive the equations to obtain posterior inference and forecasting in the NDLM with unknown observational variance and system variance specified via discount factors\nDefine seasonal NDLMs\nApply the NDLM superposition principle and explain the role of the forecast function",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#fourier-representation-video",
    "href": "C4-L04.html#fourier-representation-video",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "0.2 Fourier representation (Video)",
    "text": "0.2 Fourier representation (Video)\nTranscript:\n\nI will now describe how to incorporate seasonal components in a normal dynamic linear model. What we will do is we will first talk about the so-called single Fourier component representation . Just in case you have a single frequency and how to incorporate that single frequency in your model for the seasonality. Then using the superposition principle, you can incorporate several frequencies or a single frequency and the corresponding harmonics in your model.single Fourier component representation\nThere are other seasonal representations as well clarification needed. We will focus on the Fourier representation as is is flexible without needing too many parameters. E.g. if you want to consider, a fundamental frequency but you don’t want all the harmonics of that frequency. The Fourier representation, if you happen to have a single frequency.\nWe will discuss two cases with different component representations:\n\n\\omega \\in (0,\\pi)\n\\omega = \\pi \\implies \\{ 1,1,\\cdot, \\cdot\\}\n\nIn the case of any frequency \\omega \\in (0,\\pi), we will have a DLM that has this structure:\n\n\\{ \\underbrace {E_2}_{F},  \\underbrace {J_2(1,\\omega)}_{G}, \\underbrace{\\cdot}_{v_t}, \\underbrace{\\cdot}_{W_t}\\}\n\\tag{1}\nWe will have the F vector the 2-dimensional vector: \nE_2=(1,0)'\n\\tag{2}\nAs usual and the G matrix will be the 2 by 2 matrix:\n\nJ_2(1, \\omega) =\n\\begin{pmatrix}\n\\cos(\\omega) & \\sin(\\omega) \\\\\n-\\sin(\\omega) & \\cos(\\omega)\n\\end{pmatrix},\n\\tag{3}\nwhere \\omega is the frequency that we are considering.\nSince this is a 2 by 2 matrix the our state parameter vector will also be a vector of dimension 2.\nIf we think about the forecast function, f_t(h) h-steps ahead, (you are at time t and you want to look for h steps ahead).\nLet’s recall: the way we work with this is F* G^h * a_t\ngoing to be your E_2', then you have to take this G matrix, which is just this J_2(1,\\omega)^h, and then you have a vector, I’m going to call a_t and b_t, which is just going to be this vector value of your Theta t vector given the information up to the time t. It’s going to have two components, I’m just going to generically call them a_t and b_t. When you take this to the power of h using just trigonometric results, you’re going to get that J_2(1,\\omega)^h, is just going to give you cosine of Omega h sine of Omega h minus sine of Omega h cosine of Omega h. When you look at this expression, you get something that looks like this, and then you have, again, times these a_t, b_t.\n\n\\begin{aligned}\nf_t(h) &= E_2' [J_2(1, \\omega)]^h \\underbrace{\\begin{pmatrix} a_t \\\\ b_t \\end{pmatrix}}_{\\mathbb{E}[\\theta\\mid \\mathcal{D}]} \\\\\n&= (1,0) \\begin{pmatrix} \\cos(\\omega h) & \\sin(\\omega h) \\\\ -\\sin(\\omega h) & \\cos(\\omega h) \\end{pmatrix} \\begin{pmatrix} a_t \\\\ b_t \\end{pmatrix} \\\\\n&= a_t \\cos(\\omega h) + b_t \\sin(\\omega h) \\\\\n&= A_t \\cos(\\omega h + B_t).\n\\end{aligned}\n\\tag{4}\n\nYou’re going to have the cosine and sine only multiplied by this. In the end, you’re going to have something that looks like this.\nYou have this sinusoidal form with the period Omega in your forecast function. You can also write this down in terms of an amplitude that I’m going to call A_t and then a phase that is B_t. Here again, you have your periodicity that appears in this cosine wave. This is again for the case in which you have a single frequency and the frequencies in this range. There was a second case that I mentioned, and that case is the case in which the Omega is exactly Pi. In this case, your Fourier representation is going to be your model that has a state vector that is just one dimensional. In the case where Omega is between zero and Pi, you have a two-dimensional state, vector here you’re going to have a one-dimensional state vector.\nThis is going to be your F and your G. Then you have again whatever you want to put here as your v_t and W_t. This gives me, if I think about the forecast function, h steps ahead is just going to be something that has the form -1^h \\times a_t. Now I have a single component here, is uni-dimensional. This is going to have an oscillatory behavior between a_t and -a_t if I were to look h steps ahead forward when I’m at time t. These two forms give me the single component Fourier representation and using the superposition principle, we will see that we can combine a single frequency and the corresponding harmonics or several different frequencies just using the superposition principle in the normal dynamic linear model. You can also incorporate more than one component in a full Fourier representation. Usually the way this works is you have a fundamental period, let’s say p. For example, if you are recording monthly data, p could be 12 and then you are going to incorporate in the model the fundamental frequency, and then all the harmonics that go with that fundamental frequency related to the period p.\n\n\n\n\n\nslide 1\n\n\nHere p, is the period and in this case, we are going to discuss essentially two different situations. One is when p is an odd number, the other one is when p is an even number. Let’s begin with the case of p is odd and in this particular scenario, we can write down p as 2 times m minus 1 for some value of m. This gives me a period that is odd. How many frequencies I’m going to incorporate in this model? I’m going to be able to write down \\omega_j = 2 \\pi \\times j / p, which is the fundamental period. j here goes from one all the way to m minus 1. Now we can use the superposition principle thinking we have a component DLM representation for each of these frequencies. They are all going to be between 0 and Pi. For each of them I’m going to have that two-dimensional DLM representation in terms of the state vector and then I can use the superposition principle to concatenate them all and get a model that has all these frequencies, the one related to the fundamental period and all the harmonics for that. Again, if I think about what is my F and my G here, I’m not writing down the t because both F and G are going to be constant over time. So my F is going to be again, I concatenate as many E_2 as I have frequencies in here. I’m going to have E_2 transpose and so on and I’m going to have m minus one of those. Times 2 gives me the dimension of \\theta_t. The vector here is 2 times m minus 1 dimensional vector.\nMy G is going to have that block diagonal structure where we are going to just have all those J_{2,1} \\omega_1, all the way down to the last harmonic. Each of these blocks is a two-by-two matrix and I’m going to put them together in a block diagonal form. This gives me the representation when the period is odd, what is the structure of the forecast function? Again, using the superposition principle, the forecast function is going to be just the sum of m minus 1 components, where each of those components is going to have an individual forecast function that has that cosine wave representation that we discussed before. Again, if I think about the forecast function at time t h steps ahead, I will be able to write it down like this.\nThis should be a B. B_{t,j}. Again here, I have an amplitude for each of the components and a phase for each of the components so it depends on time but does not depend on h. The h enters here, and this is my forecast function. In the case of P even the situation is slightly different. But again, it’s the same in terms of using the superposition principle. In this case, we can write down P as 2 times m because it’s an even number. Now I can write down these Omega j’s as a function of the fundamental period. Again, this goes from 1 up to m minus 1. But there is a last frequency here. When j is equal to m, this simplifies to be the Nyquist frequency. In this case, I have my Omega is equal to Pi. In this particular case, when I concatenate everything, I’m going to have again an F and a G that look like this. Once again, I concatenate all of these up to the component m minus 1. Then I have this 1 for the last frequency. Then my G is going to be the block diagonal.\nFor the last frequency I have that minus 1. This determines the dimension of the state vector, in this case I’m going to have 2 times m minus 1 plus 1.\nMy f function, my forecast function, is again a function of the number of steps ahead. I’m going to have the same structure I had before for the m minus 1 components. Then I have to add one more component that corresponds to the frequency Pi. This one appears with the power of h. As you can see, I’m using once again the superposition principle to go from component representation to the full Fourier representation. In practice, once we set the period, we can use a model that has the fundamental period and all the harmonics related to that fundamental period. We could also use, discard some of those harmonics and use a subset of them. This is one of the things that the Fourier representation allows. It allows you to be flexible in terms of how many components you want to add in this model. There are other representations that are also used in practice. One of them is the seasonal factors representation. In that case, you’re going to have a model in which the state vector has dimension p for a given period. It uses a G matrix that is a permutation matrix. There is a correspondence between this parameterization using the Fourier representation and that other parameterization. If you want to use that parameterization, the way to interpret the components of this state vector, since you have P of those, is going to be a representation in terms of factors. For example, if you think about monthly data, you will have the say January factor, February factor, March factor, and so on. You could think about those effects and do a correspondence with this particular model. We will always work in this class with these representations because it’s more flexible. But again, you can go back and forth between one and the other.\n\n\n\n\n\nslide 2",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#fourier-representation-example-1-reading",
    "href": "C4-L04.html#fourier-representation-example-1-reading",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "0.3 Fourier Representation: Example 1 (Reading)",
    "text": "0.3 Fourier Representation: Example 1 (Reading)\n\n0.3.1 Seasonal Models\nExample: Full Fourier Model with p=5\nIn this case the Fourier frequencies are\n\nω_1 = 2π/5 and\nω_2 = 4π/5 and so\np = 2 × 3 − 1. Then,\nm = 3 and\n\\theta_t = (\\theta_{t,1}, \\ldots , \\theta_{t,4})′,\nF = (1, 0, 1, 0),\nG is given by:\n\n\nG = \\begin{bmatrix}\n\\cos(2\\pi/5) & \\sin(2\\pi/5) & 0 & 0 \\\\\n\\cos(4\\pi/5) & \\sin(4\\pi/5) & 0 & 0 \\\\\n0 & 0 & \\cos(2\\pi/5) & \\sin(2\\pi/5) \\\\\n0 & 0 & \\cos(4\\pi/5) & \\sin(4\\pi/5) \\\\\n0 & 0 & 0 & 0\n\\end{bmatrix}\n\nand the forecast function is:\n\nf_t(h) = A_{t,1} \\cos(2\\pi h/5 + \\gamma_t) + A_{t,2} \\cos(4\\pi h /5 + \\gamma_{t,2}) \\qquad\n\\tag{5}",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#building-ndlms-with-multiple-components-examples-video",
    "href": "C4-L04.html#building-ndlms-with-multiple-components-examples-video",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "0.4 Building NDLMs with multiple components: Examples (Video)",
    "text": "0.4 Building NDLMs with multiple components: Examples (Video)\n\n\n\n\ntwo component model\n\n\nIn this second example, we are going to have two components; a linear trend plus a seasonal component where the fundamental period is four. The way to build this model, again, is using the superposition principle.\nFirst we need to think “what structure do we need, to get a linear trend in the forecast function?”\nThe linear trend is a linear function on the number of steps ahead.\nWhenever you have that structure, you will get a DLM that is the so-called polynomial model of order 2. So let’s discuss first the linear. Let’s say the linear trend part, and in this case, we have an F and a G, I’m going to call them 1, F_1 and G_1 to denote that this is the first component in the model.\nF_1 is just going to be 1, 0 transpose, and the G_1 is that upper triangular matrix, it’s a 2 by 2 matrix that has 1, 1 in the first row, 0, 1 in the second row, so this gives me a linear trend.\nMy forecast function, let’s call it f_{1,t} in terms of the number of steps ahead is just a linear function on h, is a linear polynomial order 1. Let’s say it’s a constant of K but depends on t0 plus K_{t_1}^h. This is the structure of the first component. Then I have to think about the seasonal component with period of four. If we are going to incorporate all the harmonics, we have to think again, is this an even period or a not period? In this example, this is an even period. I can write p, which is 4, as 2 times 2, so this gives me that m. I’m going to have one frequency, the first one, Omega 1, is related to the fundamental period of 4, so is 2 Pi over 4, which I can simplify and write down this as Pi over 2. This is the first frequency. The last one is going to correspond to the Nyquist.\nWe could obtain that doing 4Pi over 4, which is just Pi. As you remember, this component is going to require a two-dimensional DLM component model, this one is going to require a one-dimensional DLM component model in terms of the dimension here is the dimension of the state vectors. When we build this concatenating these components, we are going to have, again, let’s call it F_2 and G_2 for this particular component. I had called this here a, let’s call this b. My F_2 has that E_2 transpose and a 1, which gives me just 1, 0, 1. My G matrix is going to be a 3 by 3 matrix. The first component is\nthe component associated to that fundamental period. It’s a block diagonal again, and I’m going to have that J_2, 1 Omega 1, and then I have my minus 1 here. What this means is if I write this down as a matrix, let me write it here, G_2 is going to be cosine of that Pi halves,\nand then I have zeros here, I have my minus 1 here, 0, and 0. I can further simplify these to have this structure. The cosine of Pi halves is 0, the sine is 1, so I can write this down as 0, 1, 0, minus 1, 0, 0, and 0, 0 minus 1. Now if I want to go back to just having a model that has both components, I use the superposition principle again and combine this component with this component. The linear plus seasonal\nis a model that is going to have the representation F, G, with F is going to be just concatenate F_1 and F_2. G now has that block diagonal form again.\nIf I look at what I have, I have this block that is a 2 by 2, this block that is a 3 by 3. Therefore my model is going to be a five-dimensional model in terms of the state parameter vector, so this G is a 5 by 5, and this one is also a five-dimensional vector. Finally, if I think about the forecast function in this case, if I call here the forecast function f_{2,t} for the component that is seasonal, I’m going to have my A_t1 cosine of Pi halves h plus B_{t,1}, and then I have my A_{t,2} minus 1^h. My forecast function for the final model is going to be just the sum of these two components.\nYou can see how I can now put together all these blocks, so I have a block that is seasonal and a block that is a linear polynomial model, and I can put them together in a single model just to create a more flexible structure. You could add regression components, you could add autoregressive components and put together as many components as you need for the forecast function to have the form that you expect it to have. All of these models are using, again, the superposition principle and the fact that we’re working with a linear and Gaussian structure in terms of doing the posterior inference later.",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#summary-dlm-fourier-representation-reading",
    "href": "C4-L04.html#summary-dlm-fourier-representation-reading",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "0.5 Summary: DLM Fourier representation (Reading)",
    "text": "0.5 Summary: DLM Fourier representation (Reading)\n\n0.5.1 Seasonal Models: Fourier Representation\nFor any frequency \\omega \\in (0, \\pi), a model of the form \\{E_2, J_2(1, \\omega), \\cdot, \\cdot\\} with a 2-dimensional state vector \\theta_t = (\\theta_{t,1}, \\theta_{t,2})' and\n\nJ_2(1, \\omega) =\n\\begin{pmatrix}\n\\cos(\\omega) & \\sin(\\omega) \\\\\n-\\sin(\\omega) & \\cos(\\omega)\n\\end{pmatrix},\n\nhas a forecast function\n\n\\begin{aligned}\nf_t(h) &= (1, 0) J_2^h(1, \\omega) (a_t, b_t) \\\\\n       &= a_t \\cos(\\omega h) + b_t \\sin(\\omega h) \\\\\n       &= A_t \\cos(\\omega h + B_t).\n\\end{aligned}\n\nFor \\omega = \\pi, the NDLM is \\{1, -1, \\cdot, \\cdot\\} and has a forecast function of the form\n\nf_t(h) = (-1)^h m_t\n\nThese are component Fourier models. Now, for a given period p, we can build a model that contains components for the fundamental period and all the harmonics of such a period using the superposition principle as follows:\n\n\n0.5.2 Case: p = 2m - 1 (odd)\nLet \\omega_j = 2\\pi j / p for j = 1 : (m - 1), F a (p - 1)-dimensional vector, or equivalently, a 2(m - 1)-dimensional vector, and G a (p - 1) \\times (p - 1) matrix with F = (E_2', E_2', \\dots, E_2')',\n\nG = \\text{blockdiag}[J_2(1, \\omega_1), \\dots, J_2(1, \\omega_{m-1})].\n\n\n\n0.5.3 Case: p = 2m (even)\nIn this case, F is again a (p - 1)-dimensional vector (or equivalently a (2m - 1)-dimensional vector), and G is a (p - 1) \\times (p - 1) matrix such that F = (E_2', \\dots, E_2', 1)' and\n\nG = \\text{blockdiag}[J_2(1, \\omega_1), \\dots, J_2(1, \\omega_{m-1}), -1].\n\nIn both cases, the forecast function has the general form:\n\nf_t(h) = \\sum_{j=1}^{m-1} A_{t,j} \\cos(\\omega_j h + \\gamma_{t,j}) + (-1)^h A_{t,m},\n\nwith A_{t,m} = 0 if p is odd.",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#examples",
    "href": "C4-L04.html#examples",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "0.6 Examples",
    "text": "0.6 Examples\n\n0.6.1 Fourier Representation, p = 12:\nIn this case, p = 2 \\times 6 so \\theta_t is an 11-dimensional state vector,\n\nF = (1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1)',\n\nthe Fourier frequencies are \\omega_1 = 2\\pi/12, \\omega_2 = 4\\pi/12 = 2\\pi/6, \\omega_3 = 6\\pi/12 = 2\\pi/4, \\omega_4 = 8\\pi/12 = 2\\pi/3, \\omega_5 = 10\\pi/12 = 5\\pi/6, and \\omega_6 = 12\\pi/12 = \\pi (the Nyquist frequency).\n\nG = \\text{blockdiag}(J_2(1, \\omega_1), \\dots, J_2(1, \\omega_5), 1)\n\nand the forecast function is given by:\n\nf_t(h) = \\sum_{j=1}^{5} A_{t,j} \\cos(2\\pi j / 12 + \\gamma_{t,j}) + (-1)^h A_{t,6}.\n\n\n\n0.6.2 Linear Trend + Seasonal Component with p = 4\nWe can use the superposition principle to build more sophisticated models. For instance, assume that we want a model with the following 2 components:\n\nLinear trend: \\{F_1, G_1, \\cdot, \\cdot\\} with F_1 = (1, 0)',\n\n\nG_1 = J_2(1) =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}.\n\n\nFull seasonal model with p = 4: \\{F_2, G_2, \\cdot, \\cdot\\}, p = 2 \\times 2 so m = 2 and \\omega = 2\\pi / 4 = \\pi / 2,\n\n\nF_2 = (1, 0, 1)',\n\nand\n\nG_2 =\n\\begin{pmatrix}\n\\cos(\\pi / 2) & \\sin(\\pi / 2) & 0 \\\\\n-\\sin(\\pi / 2) & \\cos(\\pi / 2) & 0 \\\\\n0 & 0 & -1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 & 1 & 0 \\\\\n-1 & 0 & 0 \\\\\n0 & 0 & -1\n\\end{pmatrix}.\n\nThe resulting DLM is a 5-dimensional model \\{F, G, \\cdot, \\cdot\\} with\n\nF = (1, 0, 1, 0, 1)',\n\nand\n\nG =\n\\begin{pmatrix}\n1 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & -1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & -1\n\\end{pmatrix}.\n\nThe forecast function is:\n\nf_t(h) = (k_{t,1} + k_{t,2} h) + k_{t,3} \\cos(\\pi h / 2) + k_{t,4} \\sin(\\pi h / 2) + k_{t,5} (-1)^h.",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#quiz-seasonal-models-and-superposition",
    "href": "C4-L04.html#quiz-seasonal-models-and-superposition",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "0.7 Quiz: Seasonal Models and Superposition",
    "text": "0.7 Quiz: Seasonal Models and Superposition\nThis is omitted due to the Coursera honor code.",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#filtering-smoothing-and-forecasting-unknown-observational-variance-video",
    "href": "C4-L04.html#filtering-smoothing-and-forecasting-unknown-observational-variance-video",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "1.1 Filtering, Smoothing and Forecasting: Unknown observational variance (Video)",
    "text": "1.1 Filtering, Smoothing and Forecasting: Unknown observational variance (Video)\nIn this video we cover the following material aslo provided as a handout:\nInference in the NDLM with unknown but constant observational variance:\nLet v_t = v for all t, with v unknown and consider a DLM with the following structure: \n\\begin{aligned}\ny_t &= \\mathbf{F}_t' \\mathbf{\\theta}_t + \\nu_t, &\\nu_t &\\sim N (0, v)\\\\\n\\mathbf{\\theta}_t &= \\mathbf{G}_t \\mathbf{\\theta}_{t-1} + \\mathbf{\\omega}_t, & \\mathbf{\\omega}_t &\\sim N (0, v \\mathbf{W}^*_t)\n\\end{aligned}\n\\tag{6}\nwith conjugate prior distributions: \n(\\mathbf{\\theta}_0 \\mid D_0, v) \\sim N (\\mathbf{m}_0, v\\mathbf{C}^*_0), \\qquad (v \\mid D_0) \\sim IG(\\frac{n_0}{2}, \\frac{d_0}{2}),\n\\tag{7} and d_0 = n_0s_0\n\n1.1.1 Filtering\nAssuming (\\theta_{t-1} \\mid D_{t-1}, v) \\sim N (m_{t-1}, vC^*_{t-1}), we have the following results:\n\n(\\theta_t \\mid D_{t-1}, v) \\sim N (a_t, vR^*_t) with a_t = G_t m_{t-1} and R^*_t = G_t C^*_{t-1} G'_t + W^*_t, and unconditional on v, (\\theta_t \\mid D_{t-1}) \\sim T_{n_{t-1}} (a_t, R_t), with R_t = s_{t-1} R^*_t. The expression for s_t for all t is given below.\n(y_t \\mid D_{t-1}, v) \\sim N (f_t, vq^*_t), with f_t = F'_t a_t, and q^*_t = (1 + F'_t R^*_t F_t) and unconditional on v we have (y_t \\mid D_{t-1}) \\sim T_{n_{t-1}} (f_t, q_t), with q_t = s_{t-1} q^*_t.\n(v \\mid D_t) \\sim IG(n_t/2, s_t/2), with n_t = n_{t-1} + 1 and \ns_t = s_{t-1} + \\frac{s_{t-1}}{n_t} \\left ( \\frac{e^2_t}{q^*_t} - 1 \\right ),\n\\tag{8}\nwhere e_t = y_t - f_t\nθt|Dt, v) ∼ N (mt, vC∗ t ), with mt = at + Atet, and C∗ t = R∗ t − AtA′ tq∗ t . Similarly, unconditional on v we have (θt|Dt) ∼ Tnt (mt, Ct), with Ct = stC∗ t",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#summary-of-filtering-smoothing-and-forecasting-distributions-ndlm-unknown-observational-variance-reading",
    "href": "C4-L04.html#summary-of-filtering-smoothing-and-forecasting-distributions-ndlm-unknown-observational-variance-reading",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "1.2 Summary of Filtering, Smoothing and Forecasting Distributions, NDLM unknown observational variance (Reading)",
    "text": "1.2 Summary of Filtering, Smoothing and Forecasting Distributions, NDLM unknown observational variance (Reading)",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#specifying-the-system-covariance-matrix-via-discount-factors-video",
    "href": "C4-L04.html#specifying-the-system-covariance-matrix-via-discount-factors-video",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "1.3 Specifying the system covariance matrix via discount factors (Video)",
    "text": "1.3 Specifying the system covariance matrix via discount factors (Video)",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#ndlm-unknown-observational-variance-example-video",
    "href": "C4-L04.html#ndlm-unknown-observational-variance-example-video",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "1.4 NDLM, Unknown Observational Variance: Example (Video)",
    "text": "1.4 NDLM, Unknown Observational Variance: Example (Video)\nThis is a walk though of the R code for the example bellow.",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#rcode-ndlm-unknown-observational-variance-example-reading",
    "href": "C4-L04.html#rcode-ndlm-unknown-observational-variance-example-reading",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "1.5 Rcode: NDLM, Unknown Observational Variance Example (Reading)",
    "text": "1.5 Rcode: NDLM, Unknown Observational Variance Example (Reading)\nThis code allows time-varying F_t, G_t and W_t matrices and assumes an unknown but constant \\nu. It also allows the user to specify W_t using a discount factor \\delta \\in (0,1] or assume W_t known.\n\n\nCode\n## create list for matrices\nset_up_dlm_matrices_unknown_v &lt;- function(Ft, Gt, Wt_star){\n  if(!is.array(Gt)){\n    Stop(\"Gt and Ft should be array\")\n  }\n  if(missing(Wt_star)){\n    return(list(Ft=Ft, Gt=Gt))\n  }else{\n    return(list(Ft=Ft, Gt=Gt, Wt_star=Wt_star))\n  }\n}\n\n\n## create list for initial states\nset_up_initial_states_unknown_v &lt;- function(m0, C0_star, n0, S0){\n  return(list(m0=m0, C0_star=C0_star, n0=n0, S0=S0))\n}\n\nforward_filter_unknown_v &lt;- function(data, matrices, \n                              initial_states, delta){\n  ## retrieve dataset\n  yt &lt;- data$yt\n  T&lt;- length(yt)\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  ## retrieve initial state\n  m0 &lt;- initial_states$m0\n  C0_star &lt;- initial_states$C0_star\n  n0 &lt;- initial_states$n0\n  S0 &lt;- initial_states$S0\n  C0 &lt;- S0*C0_star\n  \n  ## create placeholder for results\n  d &lt;- dim(Gt)[1]\n  at &lt;- matrix(0, nrow=T, ncol=d)\n  Rt &lt;- array(0, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(0, nrow=T, ncol=d)\n  Ct &lt;- array(0, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  nt &lt;- numeric(T)\n  St &lt;- numeric(T)\n  dt &lt;- numeric(T)\n  \n  # moments of priors at t\n  for(i in 1:T){\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , i] %*% m0\n      Pt &lt;- Gt[, , i] %*% C0 %*% t(Gt[, , i])\n      Pt &lt;- 0.5*Pt + 0.5*t(Pt)\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i]*S0\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n      \n    }else{\n      at[i, ] &lt;- Gt[, , i] %*% t(mt[i-1, , drop=FALSE])\n      Pt &lt;- Gt[, , i] %*% Ct[, , i-1] %*% t(Gt[, , i])\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i] * St[i-1]\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i]=0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(Ft[, , i]) %*% t(at[i, , drop=FALSE]) \n    Qt[i] &lt;- t(Ft[, , i]) %*% Rt[, , i] %*% Ft[, , i] + \n      ifelse(i==1, S0, St[i-1])\n    et[i] &lt;- yt[i] - ft[i]\n    \n    nt[i] &lt;- ifelse(i==1, n0, nt[i-1]) + 1\n    St[i] &lt;- ifelse(i==1, S0, \n                    St[i-1])*(1 + 1/nt[i]*(et[i]^2/Qt[i]-1))\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% Ft[, , i] / Qt[i]\n    \n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- St[i]/ifelse(i==1, S0, \n                  St[i-1])*(Rt[, , i] - Qt[i] * At %*% t(At))\n    Ct[,,i] &lt;- 0.5*Ct[,,i]+0.5*t(Ct[,,i])\n  }\n  cat(\"Forward filtering is completed!\\n\")\n  return(list(mt = mt, Ct = Ct,  at = at, Rt = Rt, \n              ft = ft, Qt = Qt,  et = et, \n              nt = nt, St = St))\n}\n\n### smoothing function ###\nbackward_smoothing_unknown_v &lt;- function(data, matrices, \n                                posterior_states,delta){\n  ## retrieve data \n  yt &lt;- data$yt\n  T &lt;- length(yt) \n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  Rt &lt;- posterior_states$Rt\n  nt &lt;- posterior_states$nt\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  \n  for(i in T:1){\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n    }else{\n      if(missing(delta)){\n        inv_Rtp1 &lt;- chol2inv(chol(Rt[, , i+1]))\n        Bt &lt;- Ct[, , i] %*% t(Gt[, , i+1]) %*% inv_Rtp1\n        mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n        Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i+1] - \n                                    Rt[, , i+1]) %*% t(Bt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }else{\n        inv_Gt &lt;- solve(Gt[, , i+1])\n        mnt[i, ] &lt;- (1-delta)*mt[i, ] + \n                delta*inv_Gt %*% t(mnt[i+1, ,drop=FALSE])\n        Cnt[, , i] &lt;- (1-delta)*Ct[, , i] + \n                delta^2*inv_Gt %*% Cnt[, , i + 1]  %*% t(inv_Gt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }\n    }\n    fnt[i] &lt;- t(Ft[, , i]) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(Ft[, , i]) %*% t(Cnt[, , i]) %*% Ft[, , i]\n  }\n  for(i in 1:T){\n     Cnt[,,i]=St[T]*Cnt[,,i]/St[i] \n     Qnt[i]=St[T]*Qnt[i]/St[i]\n  }\n  cat(\"Backward smoothing is completed!\\n\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n## Forecast Distribution for k step\nforecast_function_unknown_v &lt;- function(posterior_states, k, \n                                        matrices, delta){\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , T+i] %*% t(mt[T, , drop=FALSE])\n      \n      if(missing(delta)){\n       Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n         t(Gt[, , T+i]) + St[T]*Wt_star[, , T+i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      \n    }else{\n      at[i, ] &lt;- Gt[, , T+i] %*% t(at[i-1, , drop=FALSE])\n      if(missing(delta)){\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i]) + St[T]*Wt_star[, , T + i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n    }\n    \n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(Ft[, , T+i]) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(Ft[, , T+i]) %*% Rt[, , i] %*% Ft[, , T+i] + \n      St[T]\n  }\n  cat(\"Forecasting is completed!\\n\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval_unknown_v &lt;- function(ft, Qt, nt, \n                                   quantile = c(0.025, 0.975)){\n  bound &lt;- matrix(0, nrow=length(ft), ncol=2)\n\n  if ((length(nt)==1)){\n   for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt)\n      bound[t, 1] &lt;- ft[t] + t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt)\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }else{\n  # lower bound of 95% credible interval\n    for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt[t])\n      bound[t, 1] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt[t])\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }\n  return(bound)\n\n}\n\n\n\n## Example: Nile River Level (in 10^8 m^3), 1871-1970 \n## Model: First order polynomial DLM\nplot(Nile) \n\n\n\n\n\n\n\n\n\nCode\nn=length(Nile) #n=100 observations \nk=5\nT=n-k\ndata_T=Nile[1:T]\ntest_data=Nile[(T+1):n]\ndata=list(yt = data_T)\n\n\n## set up matrices for first order polynomial model \nFt=array(1, dim = c(1, 1, n))\nGt=array(1, dim = c(1, 1, n))\nWt_star=array(1, dim = c(1, 1, n))\nm0=as.matrix(800)\nC0_star=as.matrix(10)\nn0=1\nS0=10\n\n## wrap up all matrices and initial values\nmatrices = set_up_dlm_matrices_unknown_v(Ft, Gt, Wt_star)\ninitial_states = set_up_initial_states_unknown_v(m0, \n                                      C0_star, n0, S0)\n\n## filtering \nresults_filtered = forward_filter_unknown_v(data, matrices, \n                                            initial_states)\n\n\nForward filtering is completed!\n\n\nCode\nci_filtered=get_credible_interval_unknown_v(results_filtered$mt, \n                                    results_filtered$Ct, \n                                     results_filtered$nt)\n\n## smoothing\nresults_smoothed=backward_smoothing_unknown_v(data, matrices, \n                                             results_filtered)\n\n\nBackward smoothing is completed!\n\n\nCode\nci_smoothed=get_credible_interval_unknown_v(results_smoothed$mnt, \n                                         results_smoothed$Cnt, \n                                         results_filtered$nt[T])\n\n## one-step ahead forecasting\nresults_forecast=forecast_function_unknown_v(results_filtered, \n                                                k,  matrices)\n\n\nForecasting is completed!\n\n\nCode\nci_forecast=get_credible_interval_unknown_v(results_forecast$ft, \n                                          results_forecast$Qt, \n                                     results_filtered$nt[T])\n\n\n## plot results\nindex=seq(1871, 1970, length.out = length(Nile))\nindex_filt=index[1:T]\nindex_forecast=index[(T+1):(T+k)]\n\nplot(index, Nile, main = \"Nile River Level \",type='l',\n     xlab=\"time\",ylab=\"feet\",lty=3,ylim=c(400,1500))\npoints(index,Nile,pch=20)\n\nlines(index_filt,results_filtered$mt, type='l', col='red',lwd=2)\nlines(index_filt,ci_filtered[, 1], type='l', col='red', lty=2)\nlines(index_filt,ci_filtered[, 2], type='l', col='red', lty=2)\nlines(index_filt,results_smoothed$mnt, type='l', col='blue',lwd=2)\nlines(index_filt, ci_smoothed[, 1], type='l', col='blue', lty=2)\nlines(index_filt, ci_smoothed[, 2], type='l', col='blue', lty=2)\n\nlines(index_forecast, results_forecast$ft, type='l', \n      col='green',lwd=2)\nlines(index_forecast, ci_forecast[, 1], type='l', \n      col='green', lty=2)\nlines(index_forecast, ci_forecast[, 2], type='l', \n      col='green', lty=2)",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#practice-graded-assignment-ndlm-data-analysis",
    "href": "C4-L04.html#practice-graded-assignment-ndlm-data-analysis",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "1.6 Practice Graded Assignment: NDLM data analysis",
    "text": "1.6 Practice Graded Assignment: NDLM data analysis\nThis peer-reviewed activity is highly recommended. It does not figure into your grade for this course, but it does provide you with the opportunity to apply what you’ve learned in R and prepare you for your data analysis project in week 5.\nThe R code below fits a Normal Dynamic Linear Model to the monthly time series of Google trends “hits” for the term “time series”. The model has two components: (a) a polynomial model of order 2 and (b) a seasonal component with 4 frequencies: ω_1=2π/12, (annual cycle) ω_2=2π/6 (6 months cycle), ω_3=2π/4 and ω_4=2π/3. The model assumes that the observational variance v is unknown and the system variance-covariance matrix W_t is specified using a single discount factor. The discount factor is chosen using an optimality criterion as explained in the course.\nYou will be asked to modify the code in order to consider a DLM with two components: (a) a polynomial model of order 1 and (b) a seasonal component that contains a fundamental period of p = 12 and 2 additional harmonics for a total of 3 frequencies: ω1=2π/12, ω2=2π/6 and ω3=2π/4. You will also need to optimize the choice of the discount factor for this model. You will be asked to upload pictures summarizing your results.\nR code to fit the model: requires R packages gtrends,and dlm as well as the files “all_dlm_functions_unknown_v.R” and “discountfactor_selection_functions.R” also provided below.\n#| label: code-gtrendsR-data-analysis\n# download data \nlibrary(gtrendsR)\ntimeseries_data &lt;- gtrends(\"time series\",time=\"all\")\nplot(timeseries_data)\nnames(timeseries_data)\n\ntimeseries_data=timeseries_data$interest_over_time\ndata=list(yt=timeseries_data$hits)\n\nlibrary(dlm)\nmodel_seasonal=dlmModTrig(s=12,q=4,dV=0,dW=1)\nmodel_trend=dlmModPoly(order=2,dV=10,dW=rep(1,2),m0=c(40,0))\nmodel=model_trend+model_seasonal\nmodel$C0=10*diag(10)\nn0=1\nS0=10\nk=length(model$m0)\nT=length(data$yt)\n\nFt=array(0,c(1,k,T))\nGt=array(0,c(k,k,T))\nfor(t in 1:T){\n   Ft[,,t]=model$FF\n   Gt[,,t]=model$GG\n}\n\nsource('all_dlm_functions_unknown_v.R')\nsource('discountfactor_selection_functions.R')\n\nmatrices=set_up_dlm_matrices_unknown_v(Ft=Ft,Gt=Gt)\ninitial_states=set_up_initial_states_unknown_v(model$m0,\n                                               model$C0,n0,S0)\n\ndf_range=seq(0.9,1,by=0.005)\n\n## fit discount DLM\n## MSE\nresults_MSE &lt;- adaptive_dlm(data, matrices, \n               initial_states, df_range,\"MSE\",forecast=FALSE)\n\n## print selected discount factor\nprint(paste(\"The selected discount factor:\",results_MSE$df_opt))\n\n## retrieve filtered results\nresults_filtered &lt;- results_MSE$results_filtered\nci_filtered &lt;- get_credible_interval_unknown_v(\n  results_filtered$ft,results_filtered$Qt,results_filtered$nt)\n\n## retrieve smoothed results\nresults_smoothed &lt;- results_MSE$results_smoothed\nci_smoothed &lt;- get_credible_interval_unknown_v(\n  results_smoothed$fnt, results_smoothed$Qnt, \n  results_filtered$nt[length(results_smoothed$fnt)])\n\n## plot smoothing results \npar(mfrow=c(1,1))\nindex &lt;- timeseries_data$date\nplot(index, data$yt, ylab='Google hits',\n     main = \"Google Trends: time series\", type = 'l',\n     xlab = 'time', lty=3,ylim=c(0,100))\nlines(index, results_smoothed$fnt, type = 'l', col='blue', \n      lwd=2)\nlines(index, ci_smoothed[, 1], type='l', col='blue', lty=2)\nlines(index, ci_smoothed[, 2], type='l', col='blue', lty=2)\n\n# Plot trend and rate of change \npar(mfrow=c(2,1))\nplot(index,data$yt,pch=19,cex=0.3,col='lightgray',xlab=\"time\",\n     ylab=\"Google hits\",main=\"trend\")\nlines(index,results_smoothed$mnt[,1],lwd=2,col='magenta')\nplot(index,results_smoothed$mnt[,2],col='darkblue',lwd=2,\n     type='l', ylim=c(-0.6,0.6), xlab=\"time\",\n     ylab=\"rate of change\")\nabline(h=0,col='red',lty=2)\n\n# Plot seasonal components \npar(mfrow=c(2,2))\nplot(index,results_smoothed$mnt[,3],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=12\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,5],lwd=2,col=\"darkgreen\",\n     type='l',xlab=\"time\",ylab=\"\",main=\"period=6\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,7],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=4\",\n     ylim=c(-12,12))\nplot(index,results_smoothed$mnt[,9],lwd=2,col=\"darkgreen\",\n     type='l', xlab=\"time\",ylab=\"\",main=\"period=3\",\n     ylim=c(-12,12))\n\n#Estimate for the observational variance: St[T]\nresults_filtered$St[T]\n\n1.6.1 All dlm functions unknown v\n\n\nCode\n## create list for matrices\nset_up_dlm_matrices_unknown_v &lt;- function(Ft, Gt, Wt_star){\n  if(!is.array(Gt)){\n    Stop(\"Gt and Ft should be array\")\n  }\n  if(missing(Wt_star)){\n    return(list(Ft=Ft, Gt=Gt))\n  }else{\n    return(list(Ft=Ft, Gt=Gt, Wt_star=Wt_star))\n  }\n}\n\n\n## create list for initial states\nset_up_initial_states_unknown_v &lt;- function(m0, C0_star, n0, S0){\n  return(list(m0=m0, C0_star=C0_star, n0=n0, S0=S0))\n}\n\nforward_filter_unknown_v &lt;- function(data, matrices, \n                              initial_states, delta){\n  ## retrieve dataset\n  yt &lt;- data$yt\n  T&lt;- length(yt)\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  ## retrieve initial state\n  m0 &lt;- initial_states$m0\n  C0_star &lt;- initial_states$C0_star\n  n0 &lt;- initial_states$n0\n  S0 &lt;- initial_states$S0\n  C0 &lt;- S0*C0_star\n  \n  ## create placeholder for results\n  d &lt;- dim(Gt)[1]\n  at &lt;- matrix(0, nrow=T, ncol=d)\n  Rt &lt;- array(0, dim=c(d, d, T))\n  ft &lt;- numeric(T)\n  Qt &lt;- numeric(T)\n  mt &lt;- matrix(0, nrow=T, ncol=d)\n  Ct &lt;- array(0, dim=c(d, d, T))\n  et &lt;- numeric(T)\n  nt &lt;- numeric(T)\n  St &lt;- numeric(T)\n  dt &lt;- numeric(T)\n  \n  # moments of priors at t\n  for(i in 1:T){\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , i] %*% m0\n      Pt &lt;- Gt[, , i] %*% C0 %*% t(Gt[, , i])\n      Pt &lt;- 0.5*Pt + 0.5*t(Pt)\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i]*S0\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n      \n    }else{\n      at[i, ] &lt;- Gt[, , i] %*% t(mt[i-1, , drop=FALSE])\n      Pt &lt;- Gt[, , i] %*% Ct[, , i-1] %*% t(Gt[, , i])\n      if(missing(delta)){\n        Wt &lt;- Wt_star[, , i] * St[i-1]\n        Rt[, , i] &lt;- Pt + Wt\n        Rt[,,i]=0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }else{\n        Rt[, , i] &lt;- Pt/delta\n        Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      }\n    }\n    \n    # moments of one-step forecast:\n    ft[i] &lt;- t(Ft[, , i]) %*% t(at[i, , drop=FALSE]) \n    Qt[i] &lt;- t(Ft[, , i]) %*% Rt[, , i] %*% Ft[, , i] + \n      ifelse(i==1, S0, St[i-1])\n    et[i] &lt;- yt[i] - ft[i]\n    \n    nt[i] &lt;- ifelse(i==1, n0, nt[i-1]) + 1\n    St[i] &lt;- ifelse(i==1, S0, \n                    St[i-1])*(1 + 1/nt[i]*(et[i]^2/Qt[i]-1))\n    \n    # moments of posterior at t:\n    At &lt;- Rt[, , i] %*% Ft[, , i] / Qt[i]\n    \n    mt[i, ] &lt;- at[i, ] + t(At) * et[i]\n    Ct[, , i] &lt;- St[i]/ifelse(i==1, S0, \n                  St[i-1])*(Rt[, , i] - Qt[i] * At %*% t(At))\n    Ct[,,i] &lt;- 0.5*Ct[,,i]+0.5*t(Ct[,,i])\n  }\n  cat(\"Forward filtering is completed!\\n\")\n  return(list(mt = mt, Ct = Ct,  at = at, Rt = Rt, \n              ft = ft, Qt = Qt,  et = et, \n              nt = nt, St = St))\n}\n\n### smoothing function ###\nbackward_smoothing_unknown_v &lt;- function(data, matrices, \n                                posterior_states,delta){\n  ## retrieve data \n  yt &lt;- data$yt\n  T &lt;- length(yt) \n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  \n  ## retrieve matrices\n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  Rt &lt;- posterior_states$Rt\n  nt &lt;- posterior_states$nt\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## create placeholder for posterior moments \n  mnt &lt;- matrix(NA, nrow = dim(mt)[1], ncol = dim(mt)[2])\n  Cnt &lt;- array(NA, dim = dim(Ct))\n  fnt &lt;- numeric(T)\n  Qnt &lt;- numeric(T)\n  \n  for(i in T:1){\n    if(i == T){\n      mnt[i, ] &lt;- mt[i, ]\n      Cnt[, , i] &lt;- Ct[, , i]\n    }else{\n      if(missing(delta)){\n        inv_Rtp1 &lt;- chol2inv(chol(Rt[, , i+1]))\n        Bt &lt;- Ct[, , i] %*% t(Gt[, , i+1]) %*% inv_Rtp1\n        mnt[i, ] &lt;- mt[i, ] + Bt %*% (mnt[i+1, ] - at[i+1, ])\n        Cnt[, , i] &lt;- Ct[, , i] + Bt %*% (Cnt[, , i+1] - \n                                    Rt[, , i+1]) %*% t(Bt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }else{\n        inv_Gt &lt;- solve(Gt[, , i+1])\n        mnt[i, ] &lt;- (1-delta)*mt[i, ] + \n                delta*inv_Gt %*% t(mnt[i+1, ,drop=FALSE])\n        Cnt[, , i] &lt;- (1-delta)*Ct[, , i] + \n                delta^2*inv_Gt %*% Cnt[, , i + 1]  %*% t(inv_Gt)\n        Cnt[,,i] &lt;- 0.5*Cnt[,,i]+0.5*t(Cnt[,,i])\n      }\n    }\n    fnt[i] &lt;- t(Ft[, , i]) %*% t(mnt[i, , drop=FALSE])\n    Qnt[i] &lt;- t(Ft[, , i]) %*% t(Cnt[, , i]) %*% Ft[, , i]\n  }\n  for(i in 1:T){\n     Cnt[,,i]=St[T]*Cnt[,,i]/St[i] \n     Qnt[i]=St[T]*Qnt[i]/St[i]\n  }\n  cat(\"Backward smoothing is completed!\\n\")\n  return(list(mnt = mnt, Cnt = Cnt, fnt=fnt, Qnt=Qnt))\n}\n\n## Forecast Distribution for k step\nforecast_function_unknown_v &lt;- function(posterior_states, k, \n                                        matrices, delta){\n  \n  ## retrieve matrices\n  Ft &lt;- matrices$Ft\n  Gt &lt;- matrices$Gt\n  if(missing(delta)){\n    Wt_star &lt;- matrices$Wt_star\n  }\n  \n  mt &lt;- posterior_states$mt\n  Ct &lt;- posterior_states$Ct\n  St &lt;- posterior_states$St\n  at &lt;- posterior_states$at\n  \n  ## set up matrices\n  T &lt;- dim(mt)[1] # time points\n  d &lt;- dim(mt)[2] # dimension of state parameter vector\n  \n  ## placeholder for results\n  at &lt;- matrix(NA, nrow = k, ncol = d)\n  Rt &lt;- array(NA, dim=c(d, d, k))\n  ft &lt;- numeric(k)\n  Qt &lt;- numeric(k)\n  \n  for(i in 1:k){\n    ## moments of state distribution\n    if(i == 1){\n      at[i, ] &lt;- Gt[, , T+i] %*% t(mt[T, , drop=FALSE])\n      \n      if(missing(delta)){\n       Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n         t(Gt[, , T+i]) + St[T]*Wt_star[, , T+i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Ct[, , T] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n      \n    }else{\n      at[i, ] &lt;- Gt[, , T+i] %*% t(at[i-1, , drop=FALSE])\n      if(missing(delta)){\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i]) + St[T]*Wt_star[, , T + i]\n      }else{\n        Rt[, , i] &lt;- Gt[, , T+i] %*% Rt[, , i-1] %*% \n          t(Gt[, , T+i])/delta\n      }\n      Rt[,,i] &lt;- 0.5*Rt[,,i]+0.5*t(Rt[,,i])\n    }\n    \n    \n    ## moments of forecast distribution\n    ft[i] &lt;- t(Ft[, , T+i]) %*% t(at[i, , drop=FALSE])\n    Qt[i] &lt;- t(Ft[, , T+i]) %*% Rt[, , i] %*% Ft[, , T+i] + \n      St[T]\n  }\n  cat(\"Forecasting is completed!\\n\") # indicator of completion\n  return(list(at=at, Rt=Rt, ft=ft, Qt=Qt))\n}\n\n## obtain 95% credible interval\nget_credible_interval_unknown_v &lt;- function(ft, Qt, nt, \n                                   quantile = c(0.025, 0.975)){\n  bound &lt;- matrix(0, nrow=length(ft), ncol=2)\n\n  if ((length(nt)==1)){\n   for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt)\n      bound[t, 1] &lt;- ft[t] + t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt)\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }else{\n  # lower bound of 95% credible interval\n    for (t in 1:length(ft)){\n      t_quantile &lt;- qt(quantile[1], df = nt[t])\n      bound[t, 1] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t])) \n  \n  # upper bound of 95% credible interval\n      t_quantile &lt;- qt(quantile[2], df = nt[t])\n      bound[t, 2] &lt;- ft[t] + \n        t_quantile*sqrt(as.numeric(Qt[t]))}\n  }\n  return(bound)\n\n}\n\n\n\n\n1.6.2 Discount factor selection functions\n\n\nCode\n##################################################\n##### using discount factor ##########\n##################################################\n## compute measures of forecasting accuracy\n## MAD: mean absolute deviation\n## MSE: mean square error\n## MAPE: mean absolute percentage error\n## Neg LL: Negative log-likelihood of disc,\n##         based on the one step ahead forecast distribution\nmeasure_forecast_accuracy &lt;- function(et, yt, Qt=NA, nt=NA, type){\n  if(type == \"MAD\"){\n    measure &lt;- mean(abs(et))\n  }else if(type == \"MSE\"){\n    measure &lt;- mean(et^2)\n  }else if(type == \"MAPE\"){\n    measure &lt;- mean(abs(et)/yt)\n  }else if(type == \"NLL\"){\n    measure &lt;- log_likelihood_one_step_ahead(et, Qt, nt)\n  }else{\n    stop(\"Wrong type!\")\n  }\n  return(measure)\n}\n\n\n## compute log likelihood of one step ahead forecast function\nlog_likelihood_one_step_ahead &lt;- function(et, Qt, nt){\n  ## et:the one-step-ahead error\n  ## Qt: variance of one-step-ahead forecast function\n  ## nt: degrees freedom of t distribution\n  T &lt;- length(et)\n  aux=0\n  for (t in 1:T){\n    zt=et[t]/sqrt(Qt[t])\n    aux=(dt(zt,df=nt[t],log=TRUE)-log(sqrt(Qt[t]))) + aux \n  } \n  return(-aux)\n}\n\n## Maximize log density of one-step-ahead forecast function to select discount factor\nadaptive_dlm &lt;- function(data, matrices, initial_states, df_range, type, \n                         forecast=TRUE){\n  measure_best &lt;- NA\n  measure &lt;- numeric(length(df_range))\n  valid_data &lt;- data$valid_data\n  df_opt &lt;- NA\n  j &lt;- 0\n  ## find the optimal discount factor\n  for(i in df_range){\n    j &lt;- j + 1\n    results_tmp &lt;- forward_filter_unknown_v(data, matrices, initial_states, i)\n     \n    measure[j] &lt;- measure_forecast_accuracy(et=results_tmp$et, yt=data$yt,\n                                  Qt=results_tmp$Qt, \n                                  nt=c(initial_states$n0,results_tmp$nt), type=type)\n    \n    \n    if(j == 1){\n      measure_best &lt;- measure[j]\n      results_filtered &lt;- results_tmp\n      df_opt &lt;- i\n    }else if(measure[j] &lt; measure_best){\n      measure_best &lt;- measure[j]\n      results_filtered &lt;- results_tmp\n      df_opt &lt;- i\n    }\n  }\n  results_smoothed &lt;- backward_smoothing_unknown_v(data, matrices, results_filtered, delta = df_opt)\n  if(forecast){\n    results_forecast &lt;- forecast_function(results_filtered, length(valid_data), \n                                          matrices, df_opt)\n    return(list(results_filtered=results_filtered, \n                results_smoothed=results_smoothed, \n                results_forecast=results_forecast, \n                df_opt = df_opt, measure=measure))\n  }else{\n    return(list(results_filtered=results_filtered, \n                results_smoothed=results_smoothed, \n                df_opt = df_opt, measure=measure))\n  }\n  \n}\n\n\n\n\n1.6.3 Grading Criteria\nThe assignment will be graded based on the uploaded pictures summarizing the results. Estimates of some of the model parameters and additional discussion will also be requested.",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#eeg-data",
    "href": "C4-L04.html#eeg-data",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "2.1 EEG data",
    "text": "2.1 EEG data",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C4-L04.html#google-trends",
    "href": "C4-L04.html#google-trends",
    "title": "Normal Dynamic Linear Models, Part 2",
    "section": "2.2 Google Trends",
    "text": "2.2 Google Trends",
    "crumbs": [
      "4. Time series Models",
      "Normal Dynamic Linear Models, Part 2"
    ]
  },
  {
    "objectID": "C1-L05-alt.html",
    "href": "C1-L05-alt.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "C1-L05-alt.html#two-coin-example",
    "href": "C1-L05-alt.html#two-coin-example",
    "title": "",
    "section": "1 Two Coin Example",
    "text": "1 Two Coin Example\nSuppose your brother has a coin which you know to be loaded so that it comes up heads 70% of the time. He then comes to you with some coin, you’re not sure which one and he wants to make a bet with you. Betting money that it’s going to come up heads.\nYou’re not sure if it’s the loaded coin or if it’s just a fair one. So he gives you a chance to flip it 5 times to check it out.\nYou flip it five times and get 2 heads and 3 tails. Which coin do you think it is and how sure are you about that?\nWe’ll start by defining the unknown parameter \\theta, this is either that the coin is fair or it’s a loaded coin.\n\n\\theta = \\{\\text{fair} ,\\text{loaded}\\}\n\n\nX \\sim Bin(5, ?)\n\n\nf(x\\mid\\theta) = \\begin{cases}\n      {5 \\choose x}(\\frac{1}{2})^5            & \\theta = \\text{fair} \\\\\n      {5 \\choose x} (.7)^x (.3)^{5 - x}       & \\theta = \\text{loaded}\\\\\n   \\end{cases}\n\nWe can also rewrite f(x \\mid \\theta) with indicator functions\n\nf(x\\mid\\theta) = {5\\choose x}(.5)^5I_{\\{\\theta= \\text{fair}\\}} + {5 \\choose x}(.7)^x(.3)^{5 - x}I_{\\{\\theta = \\text{loaded}\\}}\n\nIn this case, we observed that x = 2\n\nf(\\theta \\mid x = 2) = \\begin{cases}\n    0.3125 & \\theta = \\text{fair} \\\\\n    0.1323 & \\theta = \\text{loaded}\n\\end{cases}\n\nMLE \\hat{\\theta} = \\text{fair}\nThat’s a good point estimate, but then how do we answer the question, how sure are you?\nThis is not a question that’s easily answered in the frequentest paradigm. Another question is that we might like to know what is the probability that theta equals fair, give, we observe two heads.\n\nP(\\theta = \\text{fair} \\mid x = 2) = ?\n In the frequentest paradigm, the coin is a physical quantity. It’s a fixed coin, and therefore it has a fixed probability of coining up heads. It is either the fair coin, or it’s the loaded coin.\n\nP(\\theta =  \\text{fair}) = \\{0,1\\}\n\n\n1.1 Bayesian Approach to the Problem\nAn advantage of the Bayesian approach is that it allows you to easily incorporate prior information, when you know something in advance of the looking at the data. This is difficult to do under the Frequentest paradigm.\nIn this case, we’re talking about your brother. You probably know him pretty well. So suppose you think that before you’ve looked at the coin, there’s a 60% probability that this is the loaded coin.\nThis case, we put this into our prior. Our prior is that the probability the coin is loaded is 0.6. We can update our prior with the data to get our posterior beliefs, and we can do this using Bayes theorem.\nPrior: P(loaded) = 0.6\n\nf(\\theta\\mid x) = \\frac{f(x\\mid\\theta)f(\\theta)}{\\sum_\\theta{f(x\\mid\\theta)f(\\theta)}}\n\n\nf(\\theta \\mid x) = \\frac{{5\\choose x} [(\\frac{1}{2})^5(.4)I_{\\{\\theta = \\text{fair}\\}} + (.7)^x (.3)^{5-x}(.6)I_{\\{\\theta = \\text{loaded}\\}}  ] }\n{{5\\choose x} [(\\frac{1}{2})^5(.4) + (.7)^x (.3)^{5-x}(0.6)  ] }\n\n\nf(\\theta \\mid x=2)= \\frac{0.0125I_{\\{\\theta=\\text{fair}\\}}  + 0.0079I_{\\{\\theta=\\text{loaded}\\}} }{0.0125+0.0079}\n\n\nf(\\theta\\mid x=2) = 0.612I_{\\{\\theta=\\text{fair}\\}} + 0.388I_{\\{\\theta = \\text{loaded}\\}}\n\nAs you can see in the calculation here, we have the likelihood times the prior in the numerator, and in the denominator, we have a normalizing constant, so that when we divide by this, we’ll get answer that add up to one. These numbers match exactly in this case, because it’s a very simple problem. But this is a concept that goes on, what’s in the denominator here is always a normalizing constant.\n\nP(\\theta = \\text{loaded} \\mid x = 2) = 0.388\n\nThis here updates our beliefs after seeing some data about what the probability might be.\nWe can also examine what would happen under different choices of prior.\n\nP(\\theta = \\text{loaded}) = \\frac{1}{2} \\implies P(\\theta = \\text{loaded} \\mid x = 2) = 0.297\n\n\nP(\\theta = \\text{loaded}) = 0.9 \\implies P(\\theta = \\text{loaded} \\mid x = 2) = 0.792\n\nIn this case, the Bayesian approach is inherently subjective. It represents your own personal perspective, and this is an important part of the paradigm. If you have a different perspective, you will get different answers, and that’s okay. It’s all done in a mathematically vigorous framework, and it’s all mathematically consistent and coherent.\nAnd in the end, we get results that are interpretable"
  },
  {
    "objectID": "C1-L05-alt.html#continuous-bayes",
    "href": "C1-L05-alt.html#continuous-bayes",
    "title": "",
    "section": "2 Continuous Bayes",
    "text": "2 Continuous Bayes\n \n\\begin{aligned}\nf(\\theta \\mid y) &= \\frac{f(y \\mid \\theta)f(\\theta)}{f(y)}\n\\\\ &= \\frac{f(y\\mid\\theta) f(\\theta)} {\\int{f(y\\mid\\theta) f(\\theta) d\\theta}}\n\\\\ &= \\frac{\\text{likelihood} \\times \\text{prior}}{\\text{normalization}}\n\\\\ & \\propto \\text{likelihood} \\times text{prior}\n\\end{aligned}\n #{eq-continuous-bayes-theorem-derivation}\nIn practice, sometimes the integral \\int{f(y\\mid\\theta) f(\\theta) d\\theta} can be a pain to compute. So, we may prefer to use the proportionality of the likelihood times the prior. And if we can figure out its form we may be able to reintroduce the appropriate normalizing constant on at the end, we don’t necessarily have to compute this integral.\n\nExample 1 (Bayesian Coin Toss) So for example, suppose we’re looking at a coin and it has unknown probability \\theta of coming up heads. Suppose we express ignorance about the value of \\theta by assigning it a uniform distribution.\n\n\\theta \\sim U[0, 1]\n\\tag{1}\n\nf(\\theta) = I_{\\{0 \\le \\theta\\le 1\\}}\n\\tag{2}\n\n\\begin{aligned}\n  f(\\theta \\mid Y = 1) &= \\frac{\\theta^1(1-\\theta)^0\\ \\mathbb{I}_{\\{0 \\le \\theta\\le1\\}}}{\\int_{-\\infty}^\\infty{\\theta^1(1-\\theta)^0\\ \\mathbb{I}_{\\{0\\le \\theta \\le 1\\}}}}\n\\\\ &= \\frac{\\theta\\ \\mathbb{I}_{\\{0\\le\\theta\\le 1\\}}}{\\int_0^1{\\theta d\\theta}}\n\\\\ &= 2\\theta\\ \\mathbb{I}_{\\{0\\le\\theta\\le1\\}}\n\\end{aligned}\n\\tag{3}\nNow if we didn’t want to take the integral we could have used this approach:\n\n\\begin{aligned}\n  f(\\theta \\mid Y=1) &\\propto f(y\\mid\\theta)\\ f(\\theta)\n  \\\\ &\\propto \\theta\\ \\mathbb{I}_{\\{0\\le\\theta\\le1\\}}\n  \\\\ &= \\mathbb{I}_{\\{0\\le\\theta\\le1\\}}\n\\end{aligned}\n\\tag{4}\nWhich then we need to find the constant such that it’s a proper PMF. In this case, it’s 2.\n\nSo this is the same type of approach, we get to the same answer. We stick the normalizing constant on at the end, if we can recognize what this is at the end.\nIn some cases later, this will turn out much easier to just use the proportionality approach rather than a full equality approach and trying to work out the integral."
  },
  {
    "objectID": "C1-L05-alt.html#normalizing-constants-and-proportionality",
    "href": "C1-L05-alt.html#normalizing-constants-and-proportionality",
    "title": "",
    "section": "3 Normalizing Constants and Proportionality",
    "text": "3 Normalizing Constants and Proportionality\nThe full expression for a posterior distribution of some parameter θ is given by\n\n\\frac{f(x\\mid\\theta) f(\\theta)} {\\int_{-\\infty}^{\\infty}{f(x\\mid\\theta)\\ f(\\theta)\\ d\\theta}}\n\nAs we will see in coming lessons, it is often more convenient to work with the numerator only: f(\\theta\\mid x) \\propto f(x\\mid\\theta)f(\\theta), which is the likelihood times the prior. The symbol \\propto stands for “is proportional to.” We can multiply a function of \\theta by any constant and maintain proportionality. For example, if f(\\theta) = 5\\theta, then f(\\theta) \\propto \\theta. However, f(\\theta) is not proportional to \\theta + 1. We maintain proportionality only by modifying constants which are multiplied by the entire function f(\\theta). Hence 5(\\theta + 1) \\propto \\theta + 1.\nThe reason we can write f(\\theta\\mid x) \\propto f(x \\mid \\theta)f(\\theta) is because the denominator \\int_{-\\infty}^{\\infty} f(x\\mid\\theta)\\ f(\\theta)\\ d\\theta is free of \\theta. It is just a normalizing constant. Therefore, we can ignore any multiplicative terms not involving θ. For example, if θ ∼ N(m, s2), then\n\\begin{aligned}\nf(\\theta) &= \\frac{1}{\\sqrt{2πs^2}}\nexp \\left [ − \\frac{1}{2s^2}(\\theta − m)^2 \\right ]\n\\\\ &\\propto exp \\left [ − \\frac{1}{2s^2}(\\theta − m)^2 \\right ]\n\\end{aligned}\n\\tag{5}\nClearly, the expression in the bottom of Equation 5 does not integrate to 1 (it integrates to \\sqrt{2πs^2} ). Although it is not a PDF, it is proportional to the N(m, s^2) PDF and can be normalized to represent the N(m, s^2) distribution only. Likewise, the posterior f(θ\\mid x) maintains its uniqueness as long as we specify it up to a proportionality constant.\nTo evaluate posterior quantities such as posterior probabilities, we will eventually need to find the normalizing constant. If the integral required is not tractable, we can often still simulate draws from the posterior and approximate posterior quantities. In some cases, we can identify f(x\\mid θ)f(θ) as being proportional to the PDF of some known distribution. This will be a major topic of Lesson 6."
  },
  {
    "objectID": "C1-L05-alt.html#bayesian-confidence-intervals",
    "href": "C1-L05-alt.html#bayesian-confidence-intervals",
    "title": "",
    "section": "4 Bayesian Confidence Intervals",
    "text": "4 Bayesian Confidence Intervals\n ### Prior Interval Estimates\nSince the prior is a proper PMF, we can perform interval probabilities as well. This is called Prior interval estimates.\n\n\\begin{aligned}\nP(0.025 &lt;\\theta &lt; 0.975) &= \\int_{0.025}^{0.975}{1 d \\theta} \\\\&= \\theta |_{0.025}^{0.975} \\\\&= 0.975-0.025 \\\\&= 0.95\n\\end{aligned}\n\\tag{6}\n\nP(\\theta &gt; 0.05) = 1 - 0.05 = 0.95\n\\tag{7}\n\n4.1 Posterior Interval Estimates\nSince the posterior is a proper PMF, we can perform interval probabilities as well. This is called Posterior interval estimates.\n\n\\begin{align}\nP(0.025 &lt; \\theta &lt; 0.975) &= \\int_{0.025}^{0.975}{2\\theta\\ d \\theta} \\\\&= \\theta^2 |_{0.025}^{0.975} \\\\&= (0.975)^2 - (0.025)^2 \\\\&= 0.95\n\\end{align}\n\\tag{8}\n\nP(\\theta &gt; 0.05) = 1 - (0.05)^2 = 0.9975\n\\tag{9}\nThese are the sort of intervals we would get from the prior and then ask what is their posterior probability.\nIn other cases, we may want to ask, what is the posterior interval of interest? What’s an interval that contains 95% of posterior probability in some meaningful way? This would be equivalent then to a frequentest confidence interval.\nWe can do this in several different ways, two main ways that we make Bayesian Posterior intervals or credible intervals are:\n\nequal-tailed intervals and\nhighest posterior density intervals HDPI.\n\n\n\n4.2 Equal-tailed Interval Estimates\nIn the case of an equal-tailed interval, we put the equal amount of probability in each tail. So to make a 95% interval we’ll put 0.025 in each tail.\nTo be able to do this, we’re going to have to figure out what the quantiles are. So we’re going to need some value, q, so that\n\nP(\\theta &lt; q \\mid Y = 1) = \\int_0^9{2\\theta d\\theta} = q^2\n\\tag{10}\n\nP(\\sqrt{0.025} &lt; \\theta &lt; \\sqrt{0.975}) = P(0.158 &lt; \\theta &lt; 0.987) = 0.95\n\\tag{11}\nThis is an equal tailed interval in that the probability that \\theta is less than 0.18 is the same as the probability that \\theta is greater than 0.987. We can say that under the posterior, there’s a 95% probability that \\theta is in this interval.\n\n\n4.3 Highest Posterior Density (HPD)\nHere we want to ask where in the density function is it highest? Theoretically this will be the shortest possible interval that contains the given probability, in this case a 95% probability.\n\nP(\\theta &gt; \\sqrt{0.05} \\mid Y = 1) = P(\\theta &gt; 0.224 \\mid Y = 1) = 0.95\n\\tag{12}\nThis is the shortest possible interval, that under the posterior has a probability 0.95. it’s \\theta going from 0.224 up to 1.\nThe posterior distribution describes our understanding of our uncertainty combining our prior beliefs and the data. It does this with a probability density function, so at the end of the day, we can make intervals and talk about probabilities of data being in the interval.\nThis is different from the frequentest approach, where we get confidence intervals. But we can’t say a whole lot about the actual parameter relative to the confidence interval. We can only make long run frequency statements about hypothetical intervals.\nIn this case, we can legitimately say that the posterior probability that \\theta is bigger than 0.05 is 0.9975. We can also say that we believe there’s a 95% probability that \\theta is in between 0.158 and 0.987.\n\n\n4.4 Discussion of Bayesians and Frequentist interpretation of CIs\nBayesian represent uncertainty with probabilities, so that the coin itself is a physical quantity. It may have a particular value for \\theta.\nIt may be fixed, but because we don’t know what that value is, we represent our uncertainty about that value with a distribution. And at the end of the day, we can represent our uncertainty, collect it with the data, and get a posterior distribution and make intuitive statements.\nFrequentist confidence intervals have the interpretation that “If you were to repeat many times the process of collecting data and computing a 95% confidence interval, then on average about 95% of those intervals would contain the true parameter value; however, once you observe data and compute an interval the true value is either in the interval or it is not, but you can’t tell which.”\nBayesian credible intervals have the interpretation that “Your posterior probability that the parameter is in a 95% credible interval is 95%.”"
  },
  {
    "objectID": "C3-L01.html#sec-mixture-gaussians",
    "href": "C3-L01.html#sec-mixture-gaussians",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "Here we will look at a few examples of mixtures of Gaussians which display different properties not available in a single Gaussian distribution.\n\n\n\nRpython\n\n\n\n\nCode\n# Mixture of univariate Gaussians, bimodal\nx = seq(-5, 12, length=100)\ny = 0.6*dnorm(x, 0, 1) + 0.4*dnorm(x, 5, 2)\n\n\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\n# set the title\ntitle(\"Bimodal Mixture of Gaussians\")\n\n\n\n\n\n\n\n\nFigure 8: Bimodal Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# title: Mixture of univariate Gaussians, bimodal\nfrom scipy.stats import norm\n\n# Values to sample\nx = np.linspace(-5, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nstd_1 = 1\nr_n1 = norm.pdf(x,loc = mu_1, scale = std_1)\n# Normal 2 Distribution\nmu_2 = 5\nstd_2 = 2\nr_n2 = norm.pdf(x, loc = mu_2, scale = std_2)\n\n### computing mixture model\nmixture_model = (0.6 * r_n1) + (0.4 * r_n2)\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=mixture_model)\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of two Gaussians')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9: Bimodal Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()\n\n\n\n\n\n\n\n\n\nf(x) = 0.55 \\times \\mathcal{N}(0, 2) + 0.45 \\times \\mathcal{N}(3, 4) \\qquad\n\\tag{7}\n\nRpython\n\n\n\n\nCode\nx = seq(-5, 12, length=100)\ny = 0.55*dnorm(x, 0, sqrt(2)) + 0.45*dnorm(x, 3, 4)\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\n\n\n\n\n\n\n\n\nFigure 10: Uni-modal Skewed Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# Values to sample\nx = np.linspace(-5, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nvar_1 = 2\nr_n1 = norm.pdf(loc = mu_1, scale = np.sqrt(var_1), x = x)\n# Normal 2 Distribution\nmu_2 = 3\nvar_2 = 16\nr_n2 = norm.pdf(loc = mu_2, scale = np.sqrt(var_2), x = x)\n\n### computing mixture model\nmixture_model = (0.55 * r_n1) + (0.45 * r_n2)\n\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=mixture_model)\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of two Gaussians Skewed')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 11: Uni-modal Skewed Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()\n\n\n\n\n\n\n\n\n\nf(x) = 0.40 \\times \\mathcal{N}(0, 2) + 0.40 \\times \\mathcal{N}(0, 4) + 0.20 \\times \\mathcal{N}(0, 5) \\qquad\n\\tag{8}\n\nRpython\n\n\n\n\nCode\n# simulate Mixture of univariate Gaussians, unimodal heavy tail\n\nx = seq(-12, 12, length=100)\ny = 0.40 * dnorm(x, 0, sqrt(2)) + \n    0.40 * dnorm(x, 0, sqrt(16)) + \n    0.20 * dnorm(x, 0, sqrt(20))\nz = dnorm(x, 0, sqrt(0.4*2 + 0.4*16 + 0.2*20))\n\n\n\n\nCode\npar(mar=c(4,4,1,1)+0.1)\nplot(x, y, type=\"l\", ylab=\"Density\", las=1, lwd=2)\nlines(x, z, lty=2, lwd=2)\nlegend(2, 0.16, c(\"Mixture\",\"Gaussian\"), lty=c(1,2), bty=\"n\", cex=0.77, lwd=c(2,2))\n\n\n\n\n\n\n\n\nFigure 12: Unimodal Heavy Tailed Mixture of Gaussians\n\n\n\n\n\n\n\n\n\nCode\n# Values to sample\nx = np.linspace(-12.0, 12.0, num = 100)\n# Normal 1 distribution\nmu_1 = 0\nvar_1 = 2\nr_n1 = norm.pdf(loc = mu_1, scale = np.sqrt(var_1), x = x)\n# Normal 2 Distribution\nmu_2 = 0\nvar_2 = 16\nr_n2 = norm.pdf(loc = mu_2, scale = np.sqrt(var_2), x = x)\n# Normal 3 Distribution\nmu_3 = 0\nvar_3 = 20\nr_n3 = norm.pdf(loc = mu_3, scale = np.sqrt(var_3), x = x)\n\n### computing mixture model\ny = (0.4 * r_n1) + (0.4 * r_n2) + (0.2 * r_n3)\nz = norm.pdf(loc = 0, scale = np.sqrt(0.4 * 2 + 0.4 * 16 + 0.2 * 20), x = x)\n\n\n\n\nCode\n# Plotting the mixture models\nfig, ax = plt.subplots(1, 1)\nsns.lineplot(x=x, y=y)\nax.plot(x, z, '--')\nplt.xlabel('Data')\nplt.ylabel('Density')\nplt.title('Mixture of gaussians heavy tailed')\nplt.legend(['Mixture', 'Gaussian'])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 13: Unimodal Heavy Tailed Mixture of Gaussians\n\n\n\n\n\nCode\nplt.close()",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  },
  {
    "objectID": "C3-L01.html#parameter-identifiability",
    "href": "C3-L01.html#parameter-identifiability",
    "title": "Basic Concepts of Mixture Models",
    "section": "",
    "text": "Figure 25: Identifiability - Label switching\n\n\n\n\n\n\n\n\nFigure 26: identifiability - split weights\n\n\n\n\n\n\n\n\nFigure 27: identifiability - zero weights\n\n\n\n\nA probability model is identifiable if and only if different values of the parameters generate different probability distributions of the observable variables.\nOne challenge involved in working with mixture models is that they are not fully identifiable.\nThe problem is that different representations exists for the same mixture.\nQuestion: Is there a “Canonical representation” which fixes this, essentially a convention like:\n1. picking the representation with the least components (no zero weights)\n2. ordered with descending w_i\n\n\nThe labels used to distinguish the components in the mixture are not identifiable. The literature sometimes refers to this type of lack of identifiability as the label switching “problem”. Whether label switching is an actual problem or not depends on the computational algorithm being used to fit the model, and the task we are attempting to complete in any particular case. For example, label switching tends to not be an issue for the purpose of density estimation or classification problems, but it can lead to serious difficulties in clustering problems.",
    "crumbs": [
      "3. Mixture Models",
      "Basic Concepts of Mixture Models"
    ]
  }
]