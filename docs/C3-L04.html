<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="keywords" content="Mixture Models, MCMC, Markov Chain Monte Carlo, notes">

<title>71&nbsp; MCMC for Mixture Models - M4L1 â€“ Bayesian Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C3-L04-Ex1.html" rel="next">
<link href="./C3-L03-Ex2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-923206e44a13b4518db4dede9f4ebdc9.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-987387ce273b62b48f1747d606bce1d5.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(images/banner_deep.jpg);
background-size: cover;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./C3-L04.html"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">MCMC for Mixture Models - M4L1</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">MCMC for Mixture Models - M4L1</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
            <p class="subtitle lead">Bayesian Statistics: Mixture Models</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian Statistics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>Mixture Models, MCMC, Markov Chain Monte Carlo, notes</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Statistics</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Bayesian Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Paradigms of probability - M1L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayesâ€™ Theorem - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Conditional Probability and Bayesâ€™ Law - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Probability and Bayesâ€™ Theorem - M1L2HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Distributions - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Random Variables - M1L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework on Distributions - M1L3HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Frequentist Inference - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Frequentist MLE - M2L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bayesian Inference - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Homework on Likelihoods and MLEs - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Homework on Bayesian Inference - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Priors - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Homework Posterior Probabilities - M3L6HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">M3L7 - Binomial Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Homework on Priors - M2L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Poisson Data - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Homework on Poisson Data - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Beta Bernoulli - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">M4L9 - Exponential Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Homework on Exponential Data - M4L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Normally distributed Data - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Homework on Normal Data - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Non-Informative Priors - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Homework Alternative Priors - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Brief Review of Regression - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Statistical Modeling - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">M1L2 - Bayesian Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Monte Carlo estimation - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Metropolis-Hastings - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Homework on the Metropolis-Hastings algorithm - M2L4HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Gibbs sampling - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Homework Gibbs-Sampling algorithm - M2L22HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Assessing Convergence - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Homework on the Gibbs-Sampling algorithm - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Homework on M-H algorithm M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Linear regression - M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Homework on Linear Regression Model Part 1 - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Homework on Deviance information criterion - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">ANOVA - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Homework on ANOVA - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Homework on Multiple Factor ANOVA - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Logistic regression - M3L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Homework on Logistic Regression - M3L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Poisson regression - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Homework on Poisson regression - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Hierarchical modeling - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Homework on Hierarchical Models - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Homework on Non-Normal Hierarchical Models - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Capstone Project - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Homework on Predictive distributions and mixture models - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Definitions of Mixture Models - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex1-Basic-Definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Basic Concepts of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex2-Gaussian-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Mixtures of Gaussians</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex3-Zero-Inflated-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Zero inflated distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex4-Def-mixture-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Definition of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Likelihood functions for Mixture Models - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Homework The Likelihood function - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Homework Identifiability - M1L2HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Homework The likelihood function M1L2HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Homework on simulating from a Poisson Mixture Model - M1L2HW4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">HW - Simulation of Poisson mixture model - M1L2HW5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Homework Sim mixture of exponential distributions - M1L2HW6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">M2L3 - The EM algorithm for Mixture models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">The EM algorithm for Zero-Inflated Mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">MCMC for Mixture Models - M4L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">The MCMC algorithm for Zero-Inflated Mixtures - M4L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Markov chain Monte Carlo algorithms for Mixture Models - M4L1HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Density Estimation - M4L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Clustering - M4L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Classification - M4L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the EM algorithm - M4L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the MCMC algorithms - M4L7HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Homework on Bayesian Mixture Models for Classification of Banknotes - M4L7HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Computational Considerations - M5L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Computational considerations for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Determining the number of components - M5L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Homework on Bayesian Information Criteria (BIC) - M5L09HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">Homework on Estimating the number of components in Bayesian settings - M5L09HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Homework on Estimating the partition structure in Bayesian models - M5L09HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Homework on BIC for zero-inflated mixtures - M5L09HW4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Week 0: Introductions to time series analysis and the AR(1) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Stationarity, The ACF and the PCF M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">The AR(1) process: definitions and properties - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">The AR(1): MLE and Bayesian inference - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">The AR(p) process - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Bayesian Inference in the AR(p) - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Normal Dynamic Linear Models, Part 1 - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">Bayesian Inference in the NDLM: Part 1 M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">Seasonal NDLMs M4L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">96</span>&nbsp; <span class="chapter-title">Bayesian Inference in the NDLM: Part 2 - M4L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">97</span>&nbsp; <span class="chapter-title">Final Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">98</span>&nbsp; <span class="chapter-title">Week 0: Feynman Notebook on Bayesian Time Series Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">99</span>&nbsp; <span class="chapter-title">Appendix: Notation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">100</span>&nbsp; <span class="chapter-title">Appendix: Discrete Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">101</span>&nbsp; <span class="chapter-title">Appendix: Continuous Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">102</span>&nbsp; <span class="chapter-title">Appendix: Exponents &amp; Logarithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">103</span>&nbsp; <span class="chapter-title">Appendix: The Law of Large Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">Appendix: The Central Limit Theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">105</span>&nbsp; <span class="chapter-title">Appendix: Conjugate Priors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">106</span>&nbsp; <span class="chapter-title">Appendix: Link Function</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">107</span>&nbsp; <span class="chapter-title">Appendix: Bayes by backprop</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">108</span>&nbsp; <span class="chapter-title">Bayesian Books in R &amp; Python</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">109</span>&nbsp; <span class="chapter-title">Appendix: Yule-Walker Equations &amp; Durbin-Levinson Recursion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">110</span>&nbsp; <span class="chapter-title">Moore-Penrose Inversion &amp; Cholesky Decomposition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">111</span>&nbsp; <span class="chapter-title">Appendix: Inequalities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">112</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#mcmc-algorithm-for-mixture-models" id="toc-mcmc-algorithm-for-mixture-models" class="nav-link active" data-scroll-target="#mcmc-algorithm-for-mixture-models"><span class="header-section-number">72</span> MCMC algorithm for Mixture Models</a>
  <ul class="collapse">
  <li><a href="#markov-chain-monte-carlo-algorithms-part-1" id="toc-markov-chain-monte-carlo-algorithms-part-1" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-algorithms-part-1"><span class="header-section-number">72.1</span> Markov Chain Monte Carlo algorithms part 1</a></li>
  <li><a href="#markov-chain-monte-carlo-algorithms-part-2" id="toc-markov-chain-monte-carlo-algorithms-part-2" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-algorithms-part-2"><span class="header-section-number">72.2</span> Markov Chain Monte Carlo algorithms part 2</a></li>
  <li><a href="#mcmc-for-location-mixtures-of-normals-part-1" id="toc-mcmc-for-location-mixtures-of-normals-part-1" class="nav-link" data-scroll-target="#mcmc-for-location-mixtures-of-normals-part-1"><span class="header-section-number">72.3</span> MCMC for location mixtures of normals Part 1</a></li>
  <li><a href="#mcmc-for-location-mixtures-of-normals-part-2" id="toc-mcmc-for-location-mixtures-of-normals-part-2" class="nav-link" data-scroll-target="#mcmc-for-location-mixtures-of-normals-part-2"><span class="header-section-number">72.4</span> MCMC for location mixtures of normals Part 2</a></li>
  <li><a href="#mcmc-example-1" id="toc-mcmc-example-1" class="nav-link" data-scroll-target="#mcmc-example-1"><span class="header-section-number">72.5</span> MCMC Example 1</a></li>
  <li><a href="#sample-code-for-mcmc-example-1" id="toc-sample-code-for-mcmc-example-1" class="nav-link" data-scroll-target="#sample-code-for-mcmc-example-1"><span class="header-section-number">72.6</span> Sample code for MCMC example 1</a></li>
  <li><a href="#mcmc-example-2" id="toc-mcmc-example-2" class="nav-link" data-scroll-target="#mcmc-example-2"><span class="header-section-number">72.7</span> MCMC Example 2</a></li>
  <li><a href="#sample-code-for-mcmc-example-2" id="toc-sample-code-for-mcmc-example-2" class="nav-link" data-scroll-target="#sample-code-for-mcmc-example-2"><span class="header-section-number">72.8</span> Sample code for MCMC example 2</a></li>
  <li><a href="#practice-graded-assignment-the-mcmc-algorithm-for-zero-inflated-mixtures" id="toc-practice-graded-assignment-the-mcmc-algorithm-for-zero-inflated-mixtures" class="nav-link" data-scroll-target="#practice-graded-assignment-the-mcmc-algorithm-for-zero-inflated-mixtures"><span class="header-section-number">72.9</span> Practice Graded Assignment: The MCMC algorithm for zero-inflated mixtures</a></li>
  <li><a href="#honors-peer-graded-assignment-markov-chain-monte-carlo-algorithms-for-mixture-models" id="toc-honors-peer-graded-assignment-markov-chain-monte-carlo-algorithms-for-mixture-models" class="nav-link" data-scroll-target="#honors-peer-graded-assignment-markov-chain-monte-carlo-algorithms-for-mixture-models"><span class="header-section-number">72.10</span> Honors Peer-graded Assignment: Markov chain Monte Carlo algorithms for Mixture Models</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<section id="mcmc-algorithm-for-mixture-models" class="level1 page-columns page-full" data-number="72">
<h1 data-number="72"><span class="header-section-number">72</span> MCMC algorithm for Mixture Models</h1>
<p> Markov chain Monte Carlo (MCMC) algorithm are typically used to perform Bayesian inference in complex models. In MCMC algorithms we repeatedly sample from the full conditional distributions of each block of parameters given fixed values for the rest. After an appropriate burn-in period, they generate samples that are dependent but identically distributed according to the posterior distribution of interest.</p>
<section id="markov-chain-monte-carlo-algorithms-part-1" class="level2 page-columns page-full" data-number="72.1">
<h2 data-number="72.1" class="anchored" data-anchor-id="markov-chain-monte-carlo-algorithms-part-1"><span class="header-section-number">72.1</span> Markov Chain Monte Carlo algorithms part 1</h2>

<div class="no-row-height column-margin column-container"><div id="fig-s_01" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-01-mcmc-part1.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.1: MCMC - Priors of convenience"><img src="images/c3l3-ss-01-mcmc-part1.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.1: MCMC - Priors of convenience
</figcaption>
</figure>
</div><div id="fig-s_02" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-02-mcmc-part1.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.2: MCMC - Complete data Likelihood"><img src="images/c3l3-ss-02-mcmc-part1.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.2: MCMC - Complete data Likelihood
</figcaption>
</figure>
</div></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Notation
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>under tildes signify a vector or collection.</li>
<li><span class="math inline">\{i:c_i=l\}</span> mean the sum over the indices for a specific component <span class="math inline">k</span>. We are regrouping the rows by their components</li>
<li>The double product mean we are iterating over the data rows times their likelihoods. (as usual)</li>
<li>The indicator in the exponent mean we are only taking one term per row which is picked using the component for which the latent indicator is true.</li>
</ol>
</div>
</div>
<p>The model takes the form : <span id="eq-mixture-model"><span class="math display">
f(x\mid \theta) = \sum_{k=1}^K w_k g(x \mid \theta_k)
\tag{72.1}</span></span></p>
<p>The model is defined by the parameters <span class="math inline">\theta = (\theta_1, \ldots, \theta_K)</span> and the weights <span class="math inline">w = (w_1, \ldots, w_K)</span>.</p>
<p>In the Bayesian setting we also need priors for the weights and the parameters of each components.</p>
<p><span id="eq-parameter-prior"><span class="math display">
(w_1, \ldots, w_K) \sim Dirichlet(\alpha_1, \ldots, \alpha_K) \qquad \mathbb{E}[w_k] = \frac{\alpha_k}{\sum_{k=1}^K \alpha_k}
\tag{72.2}</span></span></p>
<p>also if we use <span class="math inline">a_1 = a_2 = ... a_k=1</span> we end up with a uniform prior on the simplex.</p>
<ul>
<li><span class="math inline">\tilde{\theta}_k</span> if they admit a conjugate prior, we can use the conjugate prior for the parameters of the component <span class="math inline">k</span>. Even though it wonâ€™t be conjugate for the whole model, it will be conjugate for the component <span class="math inline">k</span>, at least given the sampling scheme outlined in <a href="#eq-complete-data-likelihood-sampling-scheme" class="quarto-xref">Equation&nbsp;<span>72.4</span></a>.</li>
</ul>
<p><span id="eq-dirichlet-prior"><span class="math display">
\mathbb{P}r(w) = \frac{\Gamma(\sum_{k=1}^K \alpha_k)}{\prod_{k=1}^K \Gamma(\alpha_k)} \prod_{k=1}^K w_k^{\alpha_k - 1} \qquad \sum_{k=1}^K w_k = 1
\tag{72.3}</span></span></p>
<p>To develop a MCMC algorithm for mixture models we will use the hierarchical representation of the likelihood,</p>
<p>Complete data likelihood:</p>
<p><span id="eq-complete-data-likelihood-sampling-scheme"><span class="math display">
\begin{aligned}
\mathbb{P}r(\mathbf{x}, \mathbf{c}, \mid \mathbf{\omega}, \mathbf{\theta})  &amp;= \prod_{i=1}^n \prod_{k=1}^K (\omega_k\ g_k(x_i \mid \theta_k))^{\mathbb{1}(c_i = k)} &amp;
\\&amp; = \left[\prod_{k=1}^K \prod_{\{i:c=k\}}^n g_k(x_i \mid \theta_k)\right] &amp;&amp; \left [\prod_{k=1}^n \omega_{k}^{\sum \mathbb{1}(c_i = k)}\right ]
\\&amp; = \mathbb{P}r(\mathbf{x} \mid \mathbf{c}, \mathbf{\omega}, \mathbf{\theta}) &amp;&amp; \mathbb{P}r(\mathbf{c} \mid \mathbf{\omega}, \mathbf{\theta})
\\&amp; = \mathbb{P}r(\mathbf{x} \mid \mathbf{c}, \mathbf{\theta}) &amp;&amp; \mathbb{P}r(\mathbf{c} \mid \mathbf{\omega})
\end{aligned}
\tag{72.4}</span></span></p>
<p>The logic in this derivation is that we can rewrite the complete data likelihood as a product of two terms where we separate the weight from the other parameters.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Unclear !?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Iâ€™m not sure this is 100% correct, we seem to be trying to write out the fact that each component is conditionally independent given the weights and the component parameters. This step from the first line to the second line is based on regrouping the terms in the product based on component <span class="math inline">k</span>.</p>
<p>Another issue now that Iâ€™ve made an effort to clarify the notation is that the selection of the term in the product is based on picking the kernel from just one component. But it seems that we donâ€™t know how to infer which component the data point belongs to.</p>
</div>
</div>
</div>
<p>In the third line we reinterpreting :</p>
<ul>
<li>the left product in line 2 as a product of the likelihoods of the data if we know given their component, weights and parameters.</li>
<li>the right product in line 2 as the distribution of the indicators given the weights and parameters.</li>
</ul>
<p>In the last line we remove <span class="math inline">\omega</span> on from the left term based on independence. And we remove <span class="math inline">\theta</span> from the right term based on independence.</p>
<!-- TODO: extract transcript to external file and summarize -->
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Video transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><mark>In previous lectures, we discussed the expectation maximization algorithm for fitting mixture models. In this lecture, we are going to discuss Markov Chain Monte Carlo for Bayesian inference in mixture models.</mark></p>
<p><mark>Weâ€™re going to move from frequentist inference which we were interested only on finding the point estimate for the parameters in the model to a situation in which we are going to try to explore a full posterior distribution for those parameters.</mark></p>
<p><mark>Recall that the mixture model we are working with is going to take the form or the density of that mixture model.</mark> It is going to take the form of f of x is the sum over k components of weight multiplied by the components in the mixture. Those components are indexed by this parameter theta k, and we may have components that are all belong to the same family or that they belong to different families. If we are going to do Bayesian inference for this model, we need to compliment this density that is going to give us the likelihood with priors on the unknown parameters. In particular, weâ€™re going to need priors for the weights, and we are going to need priors for the data suitcase. What is typically done in these situations is to use a priors of convenience.</p>
<p>Where are those priors of convenience? <mark>Well, first for the weights remember that we have a constraint that the sum of the weights needs to be equal to one.</mark></p>
<p><mark>Obviously each one of them individually needs to be between zero and one. So a natural prior for that type of parameters is a Dirichlet prior and that is precisely what we are going to use.</mark> So weâ€™re going to assume that the prior for the vector that includes all these weights just follows a Dirichlet distribution, with parameters a1 all the way to <span class="math inline">a_k</span>. Just as a quick reminder they expected value of each one of these parameters individually is just given by the corresponding a divided by the sum of the aâ€™s. <mark>So in other words, the values of the aâ€™s just constrains a prior that is the relative size of the different weights.</mark> In particular if you make them all the same, then you are saying that a prior you believe that all the weights are the same. We also know that as a special case if you make <span class="math inline">a_1=a_2= \ldots = a_k</span> and in particular equal to one then we just have the Uniform distribution on the simplex.</p>
<p>Which is actually one of the typical choices used for the hyperparameters when fearing mixture models. Now, this is our priori of convenience for the omegas and we will see that in addition to having a very nice interpretation it will also allow us to do computation in a very straight forward manner. Now, the other set of priors that we need is the priors for the data case. What is typically done here is that if they admit a conjugate prior under gk then that prior is used.</p>
<p><mark>The reason for that is that even though for the full mixture this conjugate prior on the <span class="math inline">g_k1</span> conjugate for the full model it will be conditionally conjugate under our sampling scheme that we will derive in a minute.</mark> So it will make computation for the parameters theta k much simpler if we can find that conjugate prior under theta k. After we have set up priors for the model the next thing that we need to do before deriving our Gibbs sampler is to write down the complete data likelihood in a slightly more convenient way. If you remember the complete data likelihood that we used extensively for deriving the EM Algorithm has the form of the distribution of the data in all those indicators CSU either just tells you which component you belong to conditional on the weight, and all the Thetas is just going to take the form of a double product. So the product over the observations followed by the product over the components of omega sub k g sub k of x sub y given Theta k raised to the indicator function of ci equals to k. In other words, rather than write the complete sum that we had before, we replaced that completes sum by a product where each one of the terms is now raised to this indicator function that just depends on whether the component was generated, the observation was generated by the k component in the mixture. This complete data likelihood that we use extensively can now be written in a couple of different ways, and one that is going to be particularly helpful for us involves breaking this expression into two pieces, one that has to do with their omegaâ€™s, and one that has to do with gâ€™s. So let me start with a piece that starts with the gâ€™s. The way in which Iâ€™m going to do it is first Iâ€™m going to reverse the order of this products. So I am going to consider first the product over the components. Next Iâ€™m going to consider the product over the observations. But before I write exploration explicitly, let me interpret this expression up here a little bit. So what weâ€™re doing here with this double product or one way to think about what weâ€™re doing with a double product is to think about computing a bunch of terms that are in here in particular in this piece, that can be positioned onto a matrix where one dimension corresponds to the index i, and the second dimension corresponds to the index k. The entries of this matrix are just g of x i given theta k. So different combinations of i and different combinations of k gives you the values that you are going to put into this matrix. Now, what is this important? Because if you think about what they indicator or function up here is doing is itâ€™s telling you well you need to compute the whole matrix but youâ€™re actually not going to use the full matrix, you are just going to pick a few elements of it, and in particular you are going to pick one element in each row according to what the value of ci case. So for example, if the first observation belongs to the second component youâ€™d be picking this value, second observation the first component you will pick this value, third observation with third component here and so on. So the values of the ci can be interpreted as giving you a way to select elements in this matrix, and in particular one per row. <mark>So another way to write the product over all the observations is used to think about grouping rows together according to which column is being selected. In particular, for example, we could put all the observations that have the first column being selected together, then all the observations that have the second column being selected together and so on.</mark></p>
<p>One way to write that mathematically is to say that weâ€™re going to do a product over the iâ€™s but grouped together according to the value of k. Then we can get rid of the indicator and the numerator and write this as g sub k, xi given theta sub k. So this is one piece of this expression up here or one way to rewrite this expression up here or one piece of it that involves the g subcase. Of course we have a second piece that involves the omegas, that second piece that involves the omegas we can write as the product. Again, Iâ€™m going to consider the product over the case first. Then for a given k, omega k is exactly the same argument for all of them. So I can just write omega k and the product of omega k to the indicators just becomes omega k raised to the sum of the indicators.</p>
<p>Well, once I have written the expression in this way, I can essentially think about this piece as being the distribution of the observations if I knew the indicators, the omegas, and the thetas. It so happens that this expression in particular doesnâ€™t depend on the omegas. So for this model this is the same as p of x given c and the theta. In this expression here you can interpret as the distribution of the câ€™s given the omegas and the thetaâ€™s.</p>
<p>Again, in the particular structure of this model this happens to just depend on the weights omega. So we know that the product of these two quantities is just by the total law of probability the expression that we wanted in the beginning that is the distribution of the Theta and indicators together. So this particular form for the distribution is going to be particularly useful in terms of deriving the posterior distribution that we need for the Gibbs sampler. One last observation that I want to make that will be useful in the future is that if you think about what is the form of this piece down here the distribution or the Indicators even the weights, what you have is a form that resembles the kernel of multinomial distribution. So this is similar to the kernel of a multinomial.</p>
<p>In particular, itâ€™s not only similar but itâ€™s proportional to it. So it will be particularly useful in terms of deriving the algorithm using the fact that this looks like a multinomial distribution.</p>
</div>
</div>
</div>
</section>
<section id="markov-chain-monte-carlo-algorithms-part-2" class="level2 page-columns page-full" data-number="72.2">
<h2 data-number="72.2" class="anchored" data-anchor-id="markov-chain-monte-carlo-algorithms-part-2"><span class="header-section-number">72.2</span> Markov Chain Monte Carlo algorithms part 2</h2>

<div class="no-row-height column-margin column-container"><div id="fig-s_03" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-03-mcmc-part2.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.3: posterior distribution - weights"><img src="images/c3l3-ss-03-mcmc-part2.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.3: posterior distribution - weights
</figcaption>
</figure>
</div><div id="fig-s_04" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-04-mcmc-part2.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.4: posterior distribution - components"><img src="images/c3l3-ss-04-mcmc-part2.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.4: posterior distribution - components
</figcaption>
</figure>
</div><div id="fig-s_05" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-05-mcmc-part2.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.5: posterior distribution - parameters"><img src="images/c3l3-ss-05-mcmc-part2.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.5: posterior distribution - parameters
</figcaption>
</figure>
</div></div>

<p>Now that we have a structure for the likelihood function that we and the prior distributions for all of our parameters, we can can derive the posterior distribution for our model.</p>
<p>So we want to write down the joint posterior distribution. In that joint posterior distribution includes, the weights and the parameters of the components, but it also involves the vector of indicators C, that we have introduced to simplify the structure of the likelihood, and by definition, this quantity is proportional to the distribution of the data, given all the parameters, multiplied by the distribution of the missing data parameters, given Omega and Theta, multiplied by the prior distribution on the parameters, multiplied by the prior distribution on the base.</p>
<p><span id="eq-posterior-distribution"><span class="math display">
\mathbb{P}r(c, \theta, \omega \mid x) \propto \left \{ \prod_{i=1}^n \mathbb{P}r(x | c, \theta, \omega) \right \} \left \{ \prod_{i=1}^n\prod_{k=1}^K \mathbb{P}r(c \mid \omega, \theta) \right \}\ \mathbb{P}r(\omega)\ \mathbb{P}r(\theta)
\tag{72.5}</span></span></p>
<p>Each of the full conditional distributions can be derived from this joint posterior by retaining the terms that involve the parameter of interest, and recognizing the product of the selected terms as the kernel of a known family of distributions.</p>
<!-- TODO: extract transcript to external file and summarize -->
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Video transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><mark>Now that we have a clear structure for the likelihood function that we will be using and we have prior distributions for all of our parameters, we can proceed to derive the posterior distribution that we will be working with.</mark></p>
<p>We want to write down the joint posterior distribution. In that joint posterior distribution includes, of course, the weights and the parameters of the components, but it also involves the vector of indicators <span class="math inline">C</span>, that we have introduced to simplify the structure of the likelihood, and by definition, this quantity is proportional to the distribution of the data, given all the parameters, multiplied by the distribution of the missing data parameters, given <span class="math inline">\omega</span> and <span class="math inline">\theta</span>, multiplied by the prior distribution on the parameters, multiplied by the prior distribution on the base.</p>
<p>So this is the general expression, the general form, for that posterior distribution. Now, we have already seen what the form of the different terms is. In particular, this joint distribution of the data can be written as a double product. First-order components, and then over the groups of observations that belong to each one of those components of <span class="math inline">g_k</span> <span class="math inline">x_i</span>, given <span class="math inline">\theta_k</span>. So that is the first piece that weâ€™re interested in. The second piece, we have already seen also how to write it down. This is going to be the product from k equals one, to capital k of <span class="math inline">\omega_k</span>. Some of these indicators of <span class="math inline">c_i</span> is equal to k from one to n.&nbsp;This is our second piece. Then we discussed using a Dirichlet distribution for this. So ignoring some proportionality constants, this becomes the product from k equals one to capital k of <span class="math inline">\omega_k</span> raised to the <span class="math inline">a_k - 1</span>. Thatâ€™s this piece. Then finally, weâ€™re going to have another product. So typically, we use independent priors for each one of the data case. As I said, weâ€™ll typically try to pick them so that they are conjugate to this kernel, <span class="math inline">g_k()</span>, but for now, Iâ€™m going to write it in general form by writing this as <span class="math inline">p_k(\theta_k)</span>, and thatâ€™s what the last term in the expression is. So we have written down a full expression for this. Now, it should be more or less clear how we need to proceed. So we need full conditionals for all the parameters in the model. In particular, we are going to need a full conditional for <span class="math inline">\omega</span>, given all the other parameters, weâ€™re going to need a full conditional for each one of the <span class="math inline">c_i</span>â€™s given the rest of the parameters, and weâ€™re going to need a full conditional for each one of the data cases, given the rest of the parameters.</p>
<p>So to derive these full conditionals, what we will do is we will pick particular pieces from this expressions to retain and to construct this particular four conditionals.</p>
<p>Letâ€™s proceed now to derive each one of the four conditionals that we need to derive a Gibbs sampler or a Markov Chain Monte Carlo algorithm for this problem. Letâ€™s just start with the full posterior distribution for the weights, and please note that weâ€™re going to work with all the weights as a block, so weâ€™re going to try to sample them all together, and rather than looking at each one of them at a time. o this full conditional distribution is made up of the terms in this full posterior distribution that involves <span class="math inline">\omega_k</span>, and if you look at this expression carefully, you will see that this piece doesnâ€™t depend on <span class="math inline">\omega_k</span> anyway, and that this piece doesnâ€™t depend on any of the <span class="math inline">\omega_k</span> either, so itâ€™s just this two pieces in the middle that we need to consider. Furthermore, the two pieces are very similar, so both in both products over K of the weight raised to some power, so we can actually combine the two expressions together and just write them as the product from one to capital k of <span class="math inline">\omega_k</span> raised to the sum of these indicator functions, plus a_k minus 1. This looks exactly like the prior that we used, except that now, we have updated parameters. So I could write this as the product of <span class="math inline">\omega_k</span> raised to the <span class="math inline">a_k</span>, call them stars, minus one, where a_k a star, is just the original <span class="math inline">a_k</span> plus the sum from one to n of the indicators of <span class="math inline">c_i</span> equals to k.</p>
<p><mark>So just doing this little change, makes it very clear that the form of the posterior is exactly the same form as the prior.</mark></p>
<p><mark>In other words, this a conditionally conjugate prior for our problem, and that just means that <span class="math inline">\omega</span> is going to be distributed as a Dirichlet, given all the other parameters, but with this updated parameters, a_1 star all the way to a_k star, and this is very interesting because essentially, a posteriori, we know that the expected value of <span class="math inline">\omega</span> given all the other parameters, so this is the expected value of the full conditional. This is not expected value of the marginal posterior, but this is the expected value of the full conditional</mark> that is going to be a_k star divided by the sum from L equals one to k of a sub L, a star, but this is just a_k plus the sum from one to n of these indicators, <span class="math inline">c_i</span> equals to k, divided by n plus the sum from L equals one to capital K of the a_l. N just comes from the fact that if I sum over all the components, then the sum of those values is going to be n.&nbsp;</p>
<p>So this is just the number of observations that are currently assigned to the case component, and if the values of a, k are small, then this is just roughly speaking.</p>
<p><mark>So approximately, the proportion of observations in component K. This has a very nice analogy with the computations that we did in the EM algorithm.</mark></p>
<p><mark>If you remember the way in which we computed the weights in that case, or the MLE for the weights, was by essentially computing a quantity that could also be interpreted as, roughly speaking, the proportion of observations in that step of the algorithm that were assigned to that component.</mark></p>
<p><mark>So this provides a mirror image to what we did with the EM algorithm, but that has a Bayesian flavor rather than a frequentist flavor. Letâ€™s continue now with the full conditional posterior distribution for the indicators, for the c_is. Iâ€™m interested in the probability that c_i is equal to K given the data.</mark></p>
<p>As before, this is going to be proportional to just the terms in this large product that depends on <span class="math inline">c_i</span>, and if you look at it carefully, <span class="math inline">c_i</span> only appears in this two terms of the product. These have nothing to do with <span class="math inline">c_i.</span> In particular, it appears in a single term within this really large product and in a single term within this product. So the term that depends on <span class="math inline">c_i</span> being equal to <span class="math inline">k</span> in here is <span class="math inline">\omega_k</span>. The term that depends on <span class="math inline">c_i</span> equal to <span class="math inline">k</span> in here, itâ€™s just <span class="math inline">g_k(x_i \mid \theta_k)</span>, and this is true for every <span class="math inline">k</span> from one to capital <span class="math inline">K</span>. Remember that <span class="math inline">c_i</span> is a discrete random variable, taking values between one and <span class="math inline">k</span> because it indicates which component generated the observation. So if I want to get rid of the proportionality sign and actually being able to write what the probability is, I just need to normalize this by dividing over the sum of these quantities over <span class="math inline">k</span>. So that means that <span class="math inline">p(c_i = k \mid \text{all other parameters}) = \frac{\omega_k g_k(x_i \mid \theta_k)}{\sum_{l=1}^{K} \omega_l g_l(x_i \mid \theta_l)}</span>. If you look at this expression carefully, you will realize that it is very similar to the expression that we used when computing in the EM algorithm, the weights associated which is one of the observations. In fact, it is the same expression, and this is just what we called in the EM algorithm, <span class="math inline">V_{ik}</span>. Finally, letâ€™s consider the full conditional posterior distribution for the data case. So we need <span class="math inline">p(\theta_k \mid \text{all other parameters})</span>. Again, we just pick from this whole product the terms that have to do with <span class="math inline">\theta_k</span>, in this case, it is the two in the middle that do not depend on it, and within this big expression, we just have a few terms that contain <span class="math inline">\theta_k</span>, and those correspond to the observations that are currently assigned to that particular component. So this expression is proportional to the product over the <span class="math inline">i</span>â€™s that have been assigned to the <span class="math inline">k</span> th component of <span class="math inline">g_k(x_i \mid \theta_k)</span>, and among this product, again, there is a single term that belongs to <span class="math inline">\theta_k</span>. So the form of the full conditional posterior distribution for the parameter <span class="math inline">\theta_k</span> is simply this. Now, without a specific choice of <span class="math inline">G</span> and <span class="math inline">P</span>, it is hard to further simplify this expression. But what I do want to note here is that if this prior <span class="math inline">p_k</span> is conjugate to this kernel <span class="math inline">g_k</span>, then we typically know what family this posterior distribution will belong to, and that will make computation much simpler because you will typically be able to sample from that full posterior conditional distribution in using a direct sampler. This will become a little bit more clear once we do an example with mixture models, which is what weâ€™re going to do next.</p>
</div>
</div>
</div>
</section>
<section id="mcmc-for-location-mixtures-of-normals-part-1" class="level2 page-columns page-full" data-number="72.3">
<h2 data-number="72.3" class="anchored" data-anchor-id="mcmc-for-location-mixtures-of-normals-part-1"><span class="header-section-number">72.3</span> MCMC for location mixtures of normals Part 1</h2>

<div class="no-row-height column-margin column-container"><div id="fig-s_06" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-06-mcmc-for-location-mixtures-of-normals-part-1.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.6: location mixture of Normals - priors"><img src="images/c3l3-ss-06-mcmc-for-location-mixtures-of-normals-part-1.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.6: location mixture of Normals - priors
</figcaption>
</figure>
</div><div id="fig-s_07" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-07-mcmc-for-location-mixtures-of-normals-part-1.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.7: location mixture of Normals - marginals"><img src="images/c3l3-ss-07-mcmc-for-location-mixtures-of-normals-part-1.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.7: location mixture of Normals - marginals
</figcaption>
</figure>
</div><div id="fig-s_08" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-08-mcmc-for-location-mixtures-of-normals-part-1.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.8: location mixture of Normals weights"><img src="images/c3l3-ss-08-mcmc-for-location-mixtures-of-normals-part-1.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.8: location mixture of Normals weights
</figcaption>
</figure>
</div><div id="fig-s_09" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_09-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-09-mcmc-for-location-mixtures-of-normals-part-1.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.9: location mixture of Normals - components"><img src="images/c3l3-ss-09-mcmc-for-location-mixtures-of-normals-part-1.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_09-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.9: location mixture of Normals - components
</figcaption>
</figure>
</div><div id="fig-s_10" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-10-mcmc-for-location-mixtures-of-normals-part-1.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.10: location mixture of Normals - \sigma^2"><img src="images/c3l3-ss-10-mcmc-for-location-mixtures-of-normals-part-1.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.10: location mixture of Normals - <span class="math inline">\sigma^2</span>
</figcaption>
</figure>
</div></div>



<p>As in the previous module we derive the full conditional distributions for the mixture of two univariate normals.</p>
<p><span class="math display">
f(x | Ï‰, Î¼1, Î¼2, Ïƒ) = \omega \frac{1}{\sqrt{2\pi\sigma}} \exp\left\{-\frac{(x - \mu_1)^2}{2\sigma^2}\right\} + (1- \omega) \frac{1}{\sqrt{2\pi\sigma}} \exp\left\{-\frac{(x - \mu_2)^2}{2\sigma^2}\right\}
</span></p>
<p>we use a beta distribution with <span class="math inline">a_1=1</span> and <span class="math inline">a_2=1</span> for <span class="math inline">\omega</span> which corresponds to a uniform distribution and is a special case of a Dirichlet for <span class="math inline">K=2</span>.</p>
<p><span class="math inline">\mu_k \sim \mathcal{N}(\eta,\tau^2)</span></p>
<p>Inverse Gamma for <span class="math inline">\sigma^2</span> with shape parameter <span class="math inline">a</span> and scale parameter <span class="math inline">b</span>.</p>
<p>An empirical approach to priors:</p>
<p> In the absence of real prior information we typically employ the observed data to guide the selection of the hyperparameter <span class="math inline">Î·</span>, <span class="math inline">Ï„^2</span>, <span class="math inline">d</span> and <span class="math inline">q</span>, in an approach that is reminiscent of empirical Bayes. In particular, we attempt to make the means of the different component lie in the same support of the observed data, so we take <span class="math inline">Î·</span> to be approximately equal the mean (or median) of the observations, and <span class="math inline">Ï„^2</span> to be roughly equal to their variance. Similarly, for the prior on the variance <span class="math inline">Ïƒ^2</span> we set <span class="math inline">d = 2</span> (which implies that <span class="math inline">\mathbb{E}(Ïƒ^2) = q</span> and an infinite prior variance) and <span class="math inline">q</span> to be roughly equal to the variance of the observations. <mark>Posteriors are often not very sensitive to changes on the prior means that remain within an order of magnitude of the values suggested above.</mark></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Overthinking the priors
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It seems that since this is a hierarchical model, we set the priors for different components from shared hyper-priors. This way the parameters can also be inferred and we can reduce the number of parameters we need to estimate !</p>
</div>
</div>
</div>
</section>
<section id="mcmc-for-location-mixtures-of-normals-part-2" class="level2 page-columns page-full" data-number="72.4">
<h2 data-number="72.4" class="anchored" data-anchor-id="mcmc-for-location-mixtures-of-normals-part-2"><span class="header-section-number">72.4</span> MCMC for location mixtures of normals Part 2</h2>

<div class="no-row-height column-margin column-container"><div id="fig-s_11" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-11-mcmc-for-location-mixtures-of-normals-part-2.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.11: location mixture of Normals \mu"><img src="images/c3l3-ss-11-mcmc-for-location-mixtures-of-normals-part-2.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.11: location mixture of Normals <span class="math inline">\mu</span>
</figcaption>
</figure>
</div><div id="fig-s_12" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-12-mcmc-for-location-mixtures-of-normals-part-2.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.12: location mixture of Normals \mu continued 1"><img src="images/c3l3-ss-12-mcmc-for-location-mixtures-of-normals-part-2.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.12: location mixture of Normals <span class="math inline">\mu</span> continued 1
</figcaption>
</figure>
</div><div id="fig-s_13" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-s_13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c3l3-ss-13-mcmc-for-location-mixtures-of-normals-part-2.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;72.13: location mixture of Normals \mu continued 2"><img src="images/c3l3-ss-13-mcmc-for-location-mixtures-of-normals-part-2.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-s_13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.13: location mixture of Normals <span class="math inline">\mu</span> continued 2
</figcaption>
</figure>
</div></div>

</section>
<section id="mcmc-example-1" class="level2" data-number="72.5">
<h2 data-number="72.5" class="anchored" data-anchor-id="mcmc-example-1"><span class="header-section-number">72.5</span> MCMC Example 1</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="do">#### Example of an MCMC algorithm for fitting a location mixture of 2 Gaussian components</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="do">#### The algorithm is tested using simulated data</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Clear the environment and load required libraries</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: coda</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: MASS</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>##
## Markov Chain Monte Carlo Package (MCMCpack)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>## Copyright (C) 2003-2025 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>##
## Support provided by the U.S. National Science Foundation</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>## (Grants SES-0350646 and SES-0350613)
##</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">81196</span>)  <span class="co"># So that results are reproducible</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate data from a mixture with 2 components</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>KK         <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>w.true     <span class="ot">=</span> <span class="fl">0.6</span>  <span class="co"># True weights associated with the components</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>mu.true    <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, KK)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">1</span>] <span class="ot">=</span> <span class="dv">0</span>   <span class="co"># True mean for the first component</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">2</span>] <span class="ot">=</span> <span class="dv">5</span>   <span class="co"># True mean for the second component</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>sigma.true <span class="ot">=</span> <span class="dv">1</span>   <span class="co"># True standard deviation of all components</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>n          <span class="ot">=</span> <span class="dv">120</span>         <span class="co"># Number of observations to be generated</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>cc.true <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, n, <span class="at">replace=</span>T, <span class="at">prob=</span><span class="fu">c</span>(w.true,<span class="dv">1</span><span class="sc">-</span>w.true))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>x  <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, n)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  x[i] <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu.true[cc.true[i]], sigma.true)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the true density</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>xx.true <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">11</span>,<span class="at">length=</span><span class="dv">200</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>yy.true <span class="ot">=</span> w.true<span class="sc">*</span><span class="fu">dnorm</span>(xx.true, mu.true[<span class="dv">1</span>], sigma.true) <span class="sc">+</span> </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">1</span><span class="sc">-</span>w.true)<span class="sc">*</span><span class="fu">dnorm</span>(xx.true, mu.true[<span class="dv">2</span>], sigma.true) </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xx.true, yy.true, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"True density"</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="fu">rep</span>(<span class="dv">0</span>,n), <span class="at">col=</span>cc.true)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mcmc-true-density" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mcmc-true-density-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C3-L04_files/figure-html/fig-mcmc-true-density-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure&nbsp;72.14: True density and data points"><img src="C3-L04_files/figure-html/fig-mcmc-true-density-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mcmc-true-density-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.14: True density and data points
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Initialize the parameters</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>w     <span class="ot">=</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>                         <span class="co">#Assign equal weight to each component to start with</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">=</span> <span class="fu">rnorm</span>(KK, <span class="fu">mean</span>(x), <span class="fu">sd</span>(x))   <span class="co">#Random cluster centers randomly spread over the support of the data</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fu">sd</span>(x)                       <span class="co">#Initial standard deviation</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the initial guess for the density</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>xx <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">11</span>,<span class="at">length=</span><span class="dv">200</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>yy <span class="ot">=</span> w<span class="sc">*</span><span class="fu">dnorm</span>(xx, mu[<span class="dv">1</span>], sigma) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>w)<span class="sc">*</span><span class="fu">dnorm</span>(xx, mu[<span class="dv">2</span>], sigma)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xx, yy, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">max</span>(yy)), <span class="at">xlab=</span><span class="st">"x"</span>, </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Initial density"</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="fu">rep</span>(<span class="dv">0</span>,n), <span class="at">col=</span>cc.true)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C3-L04_files/figure-html/lbl-mcmc-algorithm-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="C3-L04_files/figure-html/lbl-mcmc-algorithm-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="do">## The actual MCMC algorithm starts here</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Priors</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>aa  <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>,KK)  <span class="co"># Uniform prior on w</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>eta <span class="ot">=</span> <span class="dv">0</span>          <span class="co"># Mean 0 for the prior on mu_k</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>tau <span class="ot">=</span> <span class="dv">5</span>          <span class="co"># Standard deviation 5 on the prior for mu_l</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>dd  <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>qq  <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of iterations of the sampler</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>rrr   <span class="ot">=</span> <span class="dv">6000</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>burn  <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Storing the samples</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>cc.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, n))</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>w.out     <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>mu.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK))</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>sigma.out <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>logpost   <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co"># MCMC iterations</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rrr){</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the indicators</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  cc <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,KK)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    v[<span class="dv">1</span>] <span class="ot">=</span> <span class="fu">log</span>(w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">1</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)  <span class="co">#Compute the log of the weights</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    v[<span class="dv">2</span>] <span class="ot">=</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">2</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)  <span class="co">#Compute the log of the weights</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v))<span class="sc">/</span><span class="fu">sum</span>(<span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v)))</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    cc[i] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, <span class="dv">1</span>, <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span>v)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the weights</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>  w <span class="ot">=</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, aa[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">1</span>), aa[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">2</span>))</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the means</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    nk    <span class="ot">=</span> <span class="fu">sum</span>(cc<span class="sc">==</span>k)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    xsumk <span class="ot">=</span> <span class="fu">sum</span>(x[cc<span class="sc">==</span>k])</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    tau2.hat <span class="ot">=</span> <span class="dv">1</span><span class="sc">/</span>(nk<span class="sc">/</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>tau<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>    mu.hat  <span class="ot">=</span> tau2.hat<span class="sc">*</span>(xsumk<span class="sc">/</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> eta<span class="sc">/</span>tau<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>    mu[k]   <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu.hat, <span class="fu">sqrt</span>(tau2.hat))</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the variances</span></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>  dd.star <span class="ot">=</span> dd <span class="sc">+</span> n<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>  qq.star <span class="ot">=</span> qq <span class="sc">+</span> <span class="fu">sum</span>((x <span class="sc">-</span> mu[cc])<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">=</span> <span class="fu">sqrt</span>(<span class="fu">rinvgamma</span>(<span class="dv">1</span>, dd.star, qq.star))</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store samples</span></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>  cc.out[s,]   <span class="ot">=</span> cc</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>  w.out[s]     <span class="ot">=</span> w</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>  mu.out[s,]   <span class="ot">=</span> mu</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>  sigma.out[s] <span class="ot">=</span> sigma</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the log posterior</span></span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(cc[i]<span class="sc">==</span><span class="dv">1</span>){</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>      logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">1</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>      logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">2</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>  logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">dbeta</span>(w, aa[<span class="dv">1</span>], aa[<span class="dv">2</span>],<span class="at">log =</span> T)</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">dnorm</span>(mu[k], eta, tau, <span class="at">log =</span> T)</span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>  logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(<span class="fu">dinvgamma</span>(sigma<span class="sc">^</span><span class="dv">2</span>, dd, <span class="dv">1</span><span class="sc">/</span>qq))</span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print s every 500 iterations</span></span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(s<span class="sc">/</span><span class="dv">500</span><span class="sc">==</span><span class="fu">floor</span>(s<span class="sc">/</span><span class="dv">500</span>)){</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"s ="</span>,s))</span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "s = 500"
[1] "s = 1000"
[1] "s = 1500"
[1] "s = 2000"
[1] "s = 2500"
[1] "s = 3000"
[1] "s = 3500"
[1] "s = 4000"
[1] "s = 4500"
[1] "s = 5000"
[1] "s = 5500"
[1] "s = 6000"</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the logposterior distribution for various samples</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(logpost, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">xlab=</span><span class="st">"Iterations"</span>, <span class="at">ylab=</span><span class="st">"Log posterior"</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>xx <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">11</span>,<span class="at">length=</span><span class="dv">200</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>density.posterior <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr<span class="sc">-</span>burn,<span class="fu">length</span>(xx)))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(rrr<span class="sc">-</span>burn)){</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  density.posterior[s,] <span class="ot">=</span> density.posterior[s,] <span class="sc">+</span> w.out[s<span class="sc">+</span>burn]<span class="sc">*</span><span class="fu">dnorm</span>(xx,mu.out[s<span class="sc">+</span>burn,<span class="dv">1</span>],sigma.out[s<span class="sc">+</span>burn]) <span class="sc">+</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                                                  (<span class="dv">1</span><span class="sc">-</span>w.out[s<span class="sc">+</span>burn])<span class="sc">*</span><span class="fu">dnorm</span>(xx,mu.out[s<span class="sc">+</span>burn,<span class="dv">2</span>],sigma.out[s<span class="sc">+</span>burn])</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mcmc-plot-logpost" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mcmc-plot-logpost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C3-L04_files/figure-html/fig-mcmc-plot-logpost-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Figure&nbsp;72.15: Log posterior distribution for various samples"><img src="C3-L04_files/figure-html/fig-mcmc-plot-logpost-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mcmc-plot-logpost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.15: Log posterior distribution for various samples
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="do">## report the posterior mean and 95% credible interval</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>density.posterior.m <span class="ot">=</span> <span class="fu">apply</span>(density.posterior , <span class="dv">2</span>, mean)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>density.posterior.lq <span class="ot">=</span> <span class="fu">apply</span>(density.posterior, <span class="dv">2</span>, quantile, <span class="fl">0.025</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>density.posterior.uq <span class="ot">=</span> <span class="fu">apply</span>(density.posterior, <span class="dv">2</span>, quantile, <span class="fl">0.975</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the posterior density estimate</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xx, density.posterior.m, <span class="at">type=</span><span class="st">"n"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(density.posterior.uq)), <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"Density"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="fu">c</span>(xx,<span class="fu">rev</span>(xx)), <span class="fu">c</span>(density.posterior.lq, <span class="fu">rev</span>(density.posterior.uq)), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">border=</span><span class="st">"grey"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xx, density.posterior.m, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="fu">rep</span>(<span class="dv">0</span>,n), <span class="at">col=</span>cc.true)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mcmc-plot-density" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mcmc-plot-density-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C3-L04_files/figure-html/fig-mcmc-plot-density-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Figure&nbsp;72.16: Posterior density estimate"><img src="C3-L04_files/figure-html/fig-mcmc-plot-density-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mcmc-plot-density-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;72.16: Posterior density estimate
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sample-code-for-mcmc-example-1" class="level2" data-number="72.6">
<h2 data-number="72.6" class="anchored" data-anchor-id="sample-code-for-mcmc-example-1"><span class="header-section-number">72.6</span> Sample code for MCMC example 1</h2>
</section>
<section id="mcmc-example-2" class="level2" data-number="72.7">
<h2 data-number="72.7" class="anchored" data-anchor-id="mcmc-example-2"><span class="header-section-number">72.7</span> MCMC Example 2</h2>
</section>
<section id="sample-code-for-mcmc-example-2" class="level2" data-number="72.8">
<h2 data-number="72.8" class="anchored" data-anchor-id="sample-code-for-mcmc-example-2"><span class="header-section-number">72.8</span> Sample code for MCMC example 2</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="do">#### Example of an MCMC algorithm for fitting a mixtures of K p-variate Gaussian components</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="do">#### The algorithm is tested using simulated data</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Clear the environment and load required libraries</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ellipse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'ellipse'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:graphics':

    pairs</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate data from a mixture with 3 components</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>KK      <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>p       <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>w.true <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>)  <span class="co"># True weights associated with the components</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>mu.true     <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p))</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">1</span>,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)   <span class="co">#True mean for the first component</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">2</span>,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)   <span class="co">#True mean for the second component</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">3</span>,] <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">7</span>)   <span class="co">#True mean for the third component</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>Sigma.true      <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p,p))</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>Sigma.true[<span class="dv">1</span>,,] <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>),p,p)   <span class="co">#True variance for the first component</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>Sigma.true[<span class="dv">2</span>,,] <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="fl">0.9</span>,<span class="fl">0.9</span>,<span class="dv">1</span>),p,p)   <span class="co">#True variance for the second component</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>Sigma.true[<span class="dv">3</span>,,] <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="sc">-</span><span class="fl">0.9</span>,<span class="sc">-</span><span class="fl">0.9</span>,<span class="dv">4</span>),p,p)   <span class="co">#True variance for the third component</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">63252</span>)    <span class="co">#Keep seed the same so that we can reproduce results</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>n  <span class="ot">=</span> <span class="dv">120</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>cc.true <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, n, <span class="at">replace=</span>T, <span class="at">prob=</span>w.true)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>x  <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(n,p))</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>  x[i,] <span class="ot">=</span> <span class="fu">rmvnorm</span>(<span class="dv">1</span>, mu.true[cc.true[i],], Sigma.true[cc.true[i],,])</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="at">col=</span>cc.true, <span class="at">xlab=</span><span class="fu">expression</span>(x[<span class="dv">1</span>]), <span class="at">ylab=</span><span class="fu">expression</span>(x[<span class="dv">2</span>]), <span class="at">type=</span><span class="st">"n"</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="fu">seq</span>(<span class="dv">1</span>,n), <span class="at">col=</span>cc.true, <span class="at">cex=</span><span class="fl">0.6</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma.true[k,,], <span class="at">centre=</span>mu.true[k,], <span class="at">level=</span><span class="fl">0.50</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma.true[k,,], <span class="at">centre=</span>mu.true[k,], <span class="at">level=</span><span class="fl">0.82</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma.true[k,,], <span class="at">centre=</span>mu.true[k,], <span class="at">level=</span><span class="fl">0.95</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Data + True Components"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C3-L04_files/figure-html/lbl-mcmc-example-2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="C3-L04_files/figure-html/lbl-mcmc-example-2-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Initialize the parameters</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>w          <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>,KK)<span class="sc">/</span>KK  <span class="co">#Assign equal weight to each component to start with</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>mu         <span class="ot">=</span> <span class="fu">rmvnorm</span>(KK, <span class="fu">apply</span>(x,<span class="dv">2</span>,mean), <span class="fu">var</span>(x))   <span class="co">#RandomCluster centers randomly spread over the support of the data</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>Sigma      <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p,p))  <span class="co">#Initial variances are assumed to be the same</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>Sigma[<span class="dv">1</span>,,] <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span>KK  </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>Sigma[<span class="dv">2</span>,,] <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span>KK</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>Sigma[<span class="dv">3</span>,,] <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span>KK</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>cc         <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, n, <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span>w)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="at">col=</span>cc.true, <span class="at">xlab=</span><span class="fu">expression</span>(x[<span class="dv">1</span>]), <span class="at">ylab=</span><span class="fu">expression</span>(x[<span class="dv">2</span>]))</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.50</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.82</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.95</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Initial estimate + Observations"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C3-L04_files/figure-html/lbl-mcmc-example-2-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="C3-L04_files/figure-html/lbl-mcmc-example-2-2.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Priors</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>aa <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>, KK)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">=</span> <span class="fu">apply</span>(x,<span class="dv">2</span>,mean)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>DD <span class="ot">=</span> <span class="dv">10</span><span class="sc">*</span><span class="fu">var</span>(x)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>nu <span class="ot">=</span> p</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span><span class="dv">3</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of iteration of the sampler</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>rrr <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Storing the samples</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>cc.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, n))</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>w.out     <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK))</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>mu.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK, p))</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>Sigma.out <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK, p, p))</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>logpost   <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rrr){</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the indicators</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,KK)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>      v[k] <span class="ot">=</span> <span class="fu">log</span>(w[k]) <span class="sc">+</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(x[i,], mu[k,], Sigma[k,,], <span class="at">log=</span><span class="cn">TRUE</span>)  <span class="co">#Compute the log of the weights</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v))<span class="sc">/</span><span class="fu">sum</span>(<span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v)))</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    cc[i] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, <span class="dv">1</span>, <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span>v)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the weights</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>  w <span class="ot">=</span> <span class="fu">as.vector</span>(<span class="fu">rdirichlet</span>(<span class="dv">1</span>, aa <span class="sc">+</span> <span class="fu">tabulate</span>(cc)))</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the means</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>  DD.st <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow=</span>p, <span class="at">ncol=</span>p)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    mk    <span class="ot">=</span> <span class="fu">sum</span>(cc<span class="sc">==</span>k)</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    xsumk <span class="ot">=</span> <span class="fu">apply</span>(x[cc<span class="sc">==</span>k,], <span class="dv">2</span>, sum)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    DD.st <span class="ot">=</span> <span class="fu">solve</span>(mk<span class="sc">*</span><span class="fu">solve</span>(Sigma[k,,]) <span class="sc">+</span> <span class="fu">solve</span>(DD))</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>    dd.st <span class="ot">=</span> DD.st<span class="sc">%*%</span>(<span class="fu">solve</span>(Sigma[k,,])<span class="sc">%*%</span>xsumk <span class="sc">+</span> <span class="fu">solve</span>(DD)<span class="sc">%*%</span>dd)</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>    mu[k,] <span class="ot">=</span> <span class="fu">as.vector</span>(<span class="fu">rmvnorm</span>(<span class="dv">1</span>,dd.st,DD.st))</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the variances</span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>  xcensumk <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p,p))</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>    xcensumk[cc[i],,] <span class="ot">=</span> xcensumk[cc[i],,] <span class="sc">+</span> (x[i,] <span class="sc">-</span> mu[cc[i],])<span class="sc">%*%</span><span class="fu">t</span>(x[i,] <span class="sc">-</span> mu[cc[i],])</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>    Sigma[k,,] <span class="ot">=</span> <span class="fu">riwish</span>(nu <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span>k), SS <span class="sc">+</span> xcensumk[k,,])</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store samples</span></span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>  cc.out[s,]      <span class="ot">=</span> cc</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>  w.out[s,]       <span class="ot">=</span> w</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>  mu.out[s,,]     <span class="ot">=</span> mu</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>  Sigma.out[s,,,] <span class="ot">=</span> Sigma</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(w[cc[i]]) <span class="sc">+</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(x[i,], mu[cc[i],], Sigma[cc[i],,], <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>  logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">ddirichlet</span>(w, aa)</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(mu[k,], dd, DD, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(<span class="fu">diwish</span>(Sigma[k,,], nu, SS))</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(s<span class="sc">/</span><span class="dv">250</span><span class="sc">==</span><span class="fu">floor</span>(s<span class="sc">/</span><span class="dv">250</span>)){</span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"s = "</span>, s))</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "s =  250"
[1] "s =  500"
[1] "s =  750"
[1] "s =  1000"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the logposterior distribution for various samples</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(logpost, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">xlab=</span><span class="st">"Iterations"</span>, <span class="at">ylab=</span><span class="st">"Log posterior"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C3-L04_files/figure-html/lbl-mcmc-example-2-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="C3-L04_files/figure-html/lbl-mcmc-example-2-3.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the density estimate for the last iteration of the MCMC</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="at">col=</span>cc.true, <span class="at">main=</span><span class="fu">paste</span>(<span class="st">"s ="</span>,s,<span class="st">"   logpost ="</span>, <span class="fu">round</span>(logpost[s],<span class="dv">4</span>)), <span class="at">xlab=</span><span class="fu">expression</span>(x[<span class="dv">1</span>]), <span class="at">ylab=</span><span class="fu">expression</span>(x[<span class="dv">2</span>]))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.50</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.82</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.95</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C3-L04_files/figure-html/lbl-mcmc-example-2-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="C3-L04_files/figure-html/lbl-mcmc-example-2-4.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="practice-graded-assignment-the-mcmc-algorithm-for-zero-inflated-mixtures" class="level2" data-number="72.9">
<h2 data-number="72.9" class="anchored" data-anchor-id="practice-graded-assignment-the-mcmc-algorithm-for-zero-inflated-mixtures"><span class="header-section-number">72.9</span> Practice Graded Assignment: The MCMC algorithm for zero-inflated mixtures</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">81196</span>)  <span class="co"># So that results are reproducible</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loading</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"./data/nestsize.csv"</span>)[[<span class="dv">1</span>]]</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># The actual MCMC algorithm starts here</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="do">## MCMC iterations of the sampler</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>iterations <span class="ot">&lt;-</span> <span class="dv">6000</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>burn <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Initialize the parameters</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>cc         <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">2</span>, n)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>cc[x <span class="sc">==</span> <span class="dv">0</span>] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="fu">sum</span>(x <span class="sc">==</span> <span class="dv">0</span>), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Priors</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>aa <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)  <span class="co"># Uniform prior on w</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>w     <span class="ot">=</span> <span class="fl">0.2</span> <span class="co"># fewer zeros</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">=</span> <span class="fu">mean</span>(x[x <span class="sc">&gt;</span> <span class="dv">0</span>])  <span class="co"># Initial lambda from nonzero data</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Storing the samples</span></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>w.out      <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, iterations)</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>cc.out     <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(iterations, n))</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>lambda.out <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(iterations, n))</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a><span class="co"># logpost    = rep(0, iterations)</span></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a><span class="co"># MCMC iterations</span></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>iterations) {</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample latent indicators c_i</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>  cc <span class="ot">=</span> <span class="fu">numeric</span>(n)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (x[i] <span class="sc">==</span> <span class="dv">0</span>) {</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>      logp1 <span class="ot">=</span> <span class="fu">log</span>(w)</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>      logp2 <span class="ot">=</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> w) <span class="sc">+</span> <span class="fu">dpois</span>(<span class="dv">0</span>, lambda, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>      probs <span class="ot">=</span> <span class="fu">exp</span>(<span class="fu">c</span>(logp1, logp2) <span class="sc">-</span> <span class="fu">max</span>(logp1, logp2))</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>      probs <span class="ot">=</span> probs <span class="sc">/</span> <span class="fu">sum</span>(probs)</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>      cc[i] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="at">prob =</span> probs)</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>      cc[i] <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the weights</span></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>  w <span class="ot">=</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, aa[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">1</span>), aa[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">2</span>))</span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>  lambda <span class="ot">=</span> <span class="fu">rgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">sum</span>(x[cc <span class="sc">==</span> <span class="dv">2</span>]), <span class="at">rate =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">sum</span>(cc <span class="sc">==</span> <span class="dv">2</span>))</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store samples</span></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>  w.out[s] <span class="ot">=</span>  w</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>  lambda.out[s]  <span class="ot">=</span> lambda</span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>  cc.out[s,] <span class="ot">=</span> cc</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior summaries</span></span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>w.post <span class="ot">=</span> w.out[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span>burn)]</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>lambda.post <span class="ot">=</span> lambda.out[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span>burn)]</span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Posterior mean of w:"</span>, <span class="fu">mean</span>(w.post), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Posterior mean of w: 0.399678 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Posterior mean of lambda:"</span>, <span class="fu">mean</span>(lambda.post), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Posterior mean of lambda: 0.008477621 </code></pre>
</div>
</div>
</section>
<section id="honors-peer-graded-assignment-markov-chain-monte-carlo-algorithms-for-mixture-models" class="level2" data-number="72.10">
<h2 data-number="72.10" class="anchored" data-anchor-id="honors-peer-graded-assignment-markov-chain-monte-carlo-algorithms-for-mixture-models"><span class="header-section-number">72.10</span> Honors Peer-graded Assignment: Markov chain Monte Carlo algorithms for Mixture Models</h2>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/âŒ˜/g, 'âŒƒ');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C3-L03-Ex2.html" class="pagination-link" aria-label="The EM algorithm for Mixture Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C3-L04-Ex1.html" class="pagination-link" aria-label="The MCMC algorithm for Zero-Inflated Mixtures - M4L1HW1">
        <span class="nav-page-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">The MCMC algorithm for Zero-Inflated Mixtures - M4L1HW1</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb29" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="an">title :</span><span class="co"> 'MCMC for Mixture Models - M4L1'</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle :</span><span class="co"> 'Bayesian Statistics: Mixture Models'</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - Bayesian Statistics</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Mixture Models</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - MCMC</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - Markov Chain Monte Carlo</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - notes</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="fu"># MCMC algorithm for Mixture Models</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>\index{mixture!MCMC algorithm}</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>Markov chain Monte Carlo (MCMC) algorithm are typically used to perform Bayesian inference in complex models. </span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>In MCMC algorithms we repeatedly sample from the full conditional distributions of each block of parameters given fixed values for the rest. </span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>After an appropriate burn-in period, they generate samples that are dependent but identically distributed according to the posterior distribution of interest.</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## Markov Chain Monte Carlo algorithms part 1</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="al">![MCMC - Priors of convenience](images/c3l3-ss-01-mcmc-part1.png)</span>{#fig-s_01 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="al">![MCMC - Complete data Likelihood](images/c3l3-ss-02-mcmc-part1.png)</span>{#fig-s_02 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Notation</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>under tildes signify a vector or collection.</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$<span class="sc">\{</span>i:c_i=l<span class="sc">\}</span>$ mean the sum over the indices for a specific component $k$. We are regrouping the rows by their components</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>The double product mean we are iterating over the data rows times their likelihoods. (as usual)</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>The indicator in the exponent mean we are only taking one term per row which is picked using the component for which the latent indicator is true.</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>The model takes the form :</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>f(x\mid \theta) = \sum_{k=1}^K w_k g(x \mid \theta_k)</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mixture-model}</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>The model is defined by the parameters $\theta = (\theta_1, \ldots, \theta_K)$ and the weights $w = (w_1, \ldots, w_K)$.</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a>In the Bayesian setting we also need priors for the weights and the parameters of each components.</span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>(w_1, \ldots, w_K) \sim Dirichlet(\alpha_1, \ldots, \alpha_K) \qquad \mathbb{E}<span class="co">[</span><span class="ot">w_k</span><span class="co">]</span> = \frac{\alpha_k}{\sum_{k=1}^K \alpha_k}</span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>$$ {#eq-parameter-prior}</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>also if we use $a_1 = a_2 = ... a_k=1$ we end up with a uniform prior on the simplex.</span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\tilde{\theta}_k$ if they admit a conjugate prior, we can use the conjugate prior for the parameters of the component $k$. Even though it won't be conjugate for the whole model, it will be conjugate for the component $k$, at least given the sampling scheme outlined in <span class="co">[</span><span class="ot">@eq-complete-data-likelihood-sampling-scheme</span><span class="co">]</span>.</span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(w) = \frac{\Gamma(\sum_{k=1}^K \alpha_k)}{\prod_{k=1}^K \Gamma(\alpha_k)} \prod_{k=1}^K w_k^{\alpha_k - 1} \qquad \sum_{k=1}^K w_k = 1</span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a>$$ {#eq-dirichlet-prior}</span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>To develop a MCMC algorithm for mixture models we will use the hierarchical representation of the likelihood,</span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a>Complete data likelihood:</span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a> \mathbb{P}r(\mathbf{x}, \mathbf{c}, \mid \mathbf{\omega}, \mathbf{\theta})  &amp;= \prod_{i=1}^n \prod_{k=1}^K (\omega_k\ g_k(x_i \mid \theta_k))^{\mathbb{1}(c_i = k)} &amp;</span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span>&amp; = \left<span class="co">[</span><span class="ot">\prod_{k=1}^K \prod_{\{i:c=k\}}^n g_k(x_i \mid \theta_k)\right</span><span class="co">]</span> &amp;&amp; \left <span class="co">[</span><span class="ot">\prod_{k=1}^n \omega_{k}^{\sum \mathbb{1}(c_i = k)}\right </span><span class="co">]</span> </span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span>&amp; = \mathbb{P}r(\mathbf{x} \mid \mathbf{c}, \mathbf{\omega}, \mathbf{\theta}) &amp;&amp; \mathbb{P}r(\mathbf{c} \mid \mathbf{\omega}, \mathbf{\theta}) </span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span>&amp; = \mathbb{P}r(\mathbf{x} \mid \mathbf{c}, \mathbf{\theta}) &amp;&amp; \mathbb{P}r(\mathbf{c} \mid \mathbf{\omega}) </span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a>$$ {#eq-complete-data-likelihood-sampling-scheme}</span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a>The logic in this derivation is that we can rewrite the complete data likelihood as a product of two terms where we separate the weight from the other parameters. </span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning collapse="true"}</span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a><span class="fu">## Unclear !? {.unnumbered .unlisted}</span></span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a>I'm not sure this is 100% correct, we seem to be trying to write out the fact that each component is conditionally independent given the weights and the component parameters.</span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a>This step from the first line to the second line is based on regrouping the terms in the product based on component $k$.</span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>Another issue now that I've made an effort to clarify the notation is that the selection of the term in the product is based on picking the kernel from just one component. </span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a>But it seems that we don't know how to infer which component the data point belongs to.</span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a>In the third line we reinterpreting :</span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the left product in line 2 as a product of the likelihoods of the data if we know given their component, weights and parameters.</span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the right product in line 2 as the distribution of the indicators given the weights and parameters.</span>
<span id="cb29-91"><a href="#cb29-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-92"><a href="#cb29-92" aria-hidden="true" tabindex="-1"></a>In the last line we remove $\omega$ on from the left term based on independence. And we remove $\theta$ from the right term based on independence.</span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">TODO</span><span class="co">: extract transcript to external file and summarize --&gt;</span></span>
<span id="cb29-95"><a href="#cb29-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-96"><a href="#cb29-96" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb29-97"><a href="#cb29-97" aria-hidden="true" tabindex="-1"></a><span class="fu">## Video transcript {.unnumbered .unlisted}</span></span>
<span id="cb29-98"><a href="#cb29-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-99"><a href="#cb29-99" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">In previous lectures, we discussed the expectation maximization algorithm for fitting mixture models. In this lecture, we are going to discuss Markov Chain Monte Carlo for Bayesian inference in mixture models.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-100"><a href="#cb29-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-101"><a href="#cb29-101" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">We're going to move from frequentist inference which we were interested only on finding the point estimate for the parameters in the model to a situation in which we are going to try to explore a full posterior distribution for those parameters.</span><span class="co">]</span>{.mark} </span>
<span id="cb29-102"><a href="#cb29-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-103"><a href="#cb29-103" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Recall that the mixture model we are working with is going to take the form or the density of that mixture model.</span><span class="co">]</span>{.mark} It is going to take the form of f of x is the sum over k components of weight multiplied by the components in the mixture. Those components are indexed by this parameter theta k, and we may have components that are all belong to the same family or that they belong to different families. If we are going to do Bayesian inference for this model, we need to compliment this density that is going to give us the likelihood with priors on the unknown parameters. In particular, we're going to need priors for the weights, and we are going to need priors for the data suitcase. What is typically done in these situations is to use a priors of convenience.</span>
<span id="cb29-104"><a href="#cb29-104" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb29-105"><a href="#cb29-105" aria-hidden="true" tabindex="-1"></a>Where are those priors of convenience? </span>
<span id="cb29-106"><a href="#cb29-106" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Well, first for the weights remember that we have a constraint that the sum of the weights needs to be equal to one.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-107"><a href="#cb29-107" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb29-108"><a href="#cb29-108" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Obviously each one of them individually needs to be between zero and one. So a natural prior for that type of parameters is a Dirichlet prior and that is precisely what we are going to use.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-109"><a href="#cb29-109" aria-hidden="true" tabindex="-1"></a>So we're going to assume that the prior for the vector that includes all these weights just follows a Dirichlet distribution, with parameters a1 all the way to $a_k$. Just as a quick reminder they expected value of each one of these parameters individually is just given by the corresponding a divided by the sum of the a's. </span>
<span id="cb29-110"><a href="#cb29-110" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">So in other words, the values of the a's just constrains a prior that is the relative size of the different weights. </span><span class="co">]</span>{.mark}</span>
<span id="cb29-111"><a href="#cb29-111" aria-hidden="true" tabindex="-1"></a>In particular if you make them all the same, then you are saying that a prior you believe that all the weights are the same. We also know that as a special case if you make $a_1=a_2= \ldots = a_k$ and in particular equal to one then we just have the Uniform distribution on the simplex.</span>
<span id="cb29-112"><a href="#cb29-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-113"><a href="#cb29-113" aria-hidden="true" tabindex="-1"></a>Which is actually one of the typical choices used for the hyperparameters when fearing mixture models. Now, this is our priori of convenience for the omegas and we will see that in addition to having a very nice interpretation it will also allow us to do computation in a very straight forward manner. Now, the other set of priors that we need is the priors for the data case. What is typically done here is that if they admit a conjugate prior under gk then that prior is used.</span>
<span id="cb29-114"><a href="#cb29-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-115"><a href="#cb29-115" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">The reason for that is that even though for the full mixture this conjugate prior on the $g_k1$ conjugate for the full model it will be conditionally conjugate under our sampling scheme that we will derive in a minute.</span><span class="co">]</span>{.mark} </span>
<span id="cb29-116"><a href="#cb29-116" aria-hidden="true" tabindex="-1"></a>So it will make computation for the parameters theta k much simpler if we can find that conjugate prior under theta k. </span>
<span id="cb29-117"><a href="#cb29-117" aria-hidden="true" tabindex="-1"></a>After we have set up priors for the model the next thing that we need to do before deriving our Gibbs sampler is to write down the complete data likelihood in a slightly more convenient way. </span>
<span id="cb29-118"><a href="#cb29-118" aria-hidden="true" tabindex="-1"></a>If you remember the complete data likelihood that we used extensively for deriving the EM Algorithm has the form of the distribution of the data in all those indicators CSU either just tells you which component you belong to conditional on the weight, and all the Thetas is just going to take the form of a double product. </span>
<span id="cb29-119"><a href="#cb29-119" aria-hidden="true" tabindex="-1"></a>So the product over the observations followed by the product over the components of omega sub k g sub k of x sub y given Theta k raised to the indicator function of ci equals to k. </span>
<span id="cb29-120"><a href="#cb29-120" aria-hidden="true" tabindex="-1"></a>In other words, rather than write the complete sum that we had before, we replaced that completes sum by a product where each one of the terms is now raised to this indicator function that just depends on whether the component was generated, the observation was generated by the k component in the mixture. </span>
<span id="cb29-121"><a href="#cb29-121" aria-hidden="true" tabindex="-1"></a>This complete data likelihood that we use extensively can now be written in a couple of different ways, and one that is going to be particularly helpful for us involves breaking this expression into two pieces, one that has to do with their omega's, and one that has to do with g's. </span>
<span id="cb29-122"><a href="#cb29-122" aria-hidden="true" tabindex="-1"></a>So let me start with a piece that starts with the g's. </span>
<span id="cb29-123"><a href="#cb29-123" aria-hidden="true" tabindex="-1"></a>The way in which I'm going to do it is first I'm going to reverse the order of this products. </span>
<span id="cb29-124"><a href="#cb29-124" aria-hidden="true" tabindex="-1"></a>So I am going to consider first the product over the components. </span>
<span id="cb29-125"><a href="#cb29-125" aria-hidden="true" tabindex="-1"></a>Next I'm going to consider the product over the observations. </span>
<span id="cb29-126"><a href="#cb29-126" aria-hidden="true" tabindex="-1"></a>But before I write exploration explicitly, let me interpret this expression up here a little bit. </span>
<span id="cb29-127"><a href="#cb29-127" aria-hidden="true" tabindex="-1"></a>So what we're doing here with this double product or one way to think about what we're doing with a double product is to think about computing a bunch of terms that are in here in particular in this piece, that can be positioned onto a matrix where one dimension corresponds to the index i, and the second dimension corresponds to the index k. </span>
<span id="cb29-128"><a href="#cb29-128" aria-hidden="true" tabindex="-1"></a>The entries of this matrix are just g of x i given theta k. </span>
<span id="cb29-129"><a href="#cb29-129" aria-hidden="true" tabindex="-1"></a>So different combinations of i and different combinations of k gives you the values that you are going to put into this matrix. </span>
<span id="cb29-130"><a href="#cb29-130" aria-hidden="true" tabindex="-1"></a>Now, what is this important? </span>
<span id="cb29-131"><a href="#cb29-131" aria-hidden="true" tabindex="-1"></a>Because if you think about what they indicator or function up here is doing is it's telling you well you need to compute the whole matrix but you're actually not going to use the full matrix, you are just going to pick a few elements of it, and in particular you are going to pick one element in each row according to what the value of ci case. </span>
<span id="cb29-132"><a href="#cb29-132" aria-hidden="true" tabindex="-1"></a>So for example, if the first observation belongs to the second component you'd be picking this value, second observation the first component you will pick this value, third observation with third component here and so on. So the values of the ci can be interpreted as giving you a way to select elements in this matrix, and in particular one per row. </span>
<span id="cb29-133"><a href="#cb29-133" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">So another way to write the product over all the observations is used to think about grouping rows together according to which column is being selected. In particular, for example, we could put all the observations that have the first column being selected together, then all the observations that have the second column being selected together and so on.  </span><span class="co">]</span>{.mark}</span>
<span id="cb29-134"><a href="#cb29-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-135"><a href="#cb29-135" aria-hidden="true" tabindex="-1"></a>One way to write that mathematically is to say that we're going to do a product over the i's but grouped together according to the value of k. </span>
<span id="cb29-136"><a href="#cb29-136" aria-hidden="true" tabindex="-1"></a>Then we can get rid of the indicator and the numerator and write this as g sub k, xi given theta sub k. </span>
<span id="cb29-137"><a href="#cb29-137" aria-hidden="true" tabindex="-1"></a>So this is one piece of this expression up here or one way to rewrite this expression up here or one piece of it that involves the g subcase. </span>
<span id="cb29-138"><a href="#cb29-138" aria-hidden="true" tabindex="-1"></a>Of course we have a second piece that involves the omegas, that second piece that involves the omegas we can write as the product. </span>
<span id="cb29-139"><a href="#cb29-139" aria-hidden="true" tabindex="-1"></a>Again, I'm going to consider the product over the case first. Then for a given k, omega k is exactly the same argument for all of them. </span>
<span id="cb29-140"><a href="#cb29-140" aria-hidden="true" tabindex="-1"></a>So I can just write omega k and the product of omega k to the indicators just becomes omega k raised to the sum of the indicators.</span>
<span id="cb29-141"><a href="#cb29-141" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb29-142"><a href="#cb29-142" aria-hidden="true" tabindex="-1"></a>Well, once I have written the expression in this way, I can essentially think about this piece as being the distribution of the observations if I knew the indicators, the omegas, and the thetas. </span>
<span id="cb29-143"><a href="#cb29-143" aria-hidden="true" tabindex="-1"></a>It so happens that this expression in particular doesn't depend on the omegas. </span>
<span id="cb29-144"><a href="#cb29-144" aria-hidden="true" tabindex="-1"></a>So for this model this is the same as p of x given c and the theta. </span>
<span id="cb29-145"><a href="#cb29-145" aria-hidden="true" tabindex="-1"></a>In this expression here you can interpret as the distribution of the c's given the omegas and the theta's. </span>
<span id="cb29-146"><a href="#cb29-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-147"><a href="#cb29-147" aria-hidden="true" tabindex="-1"></a>Again, in the particular structure of this model this happens to just depend on the weights omega. </span>
<span id="cb29-148"><a href="#cb29-148" aria-hidden="true" tabindex="-1"></a>So we know that the product of these two quantities is just by the total law of probability the expression that we wanted in the beginning that is the distribution of the Theta and indicators together. </span>
<span id="cb29-149"><a href="#cb29-149" aria-hidden="true" tabindex="-1"></a>So this particular form for the distribution is going to be particularly useful in terms of deriving the posterior distribution that we need for the Gibbs sampler. </span>
<span id="cb29-150"><a href="#cb29-150" aria-hidden="true" tabindex="-1"></a>One last observation that I want to make that will be useful in the future is that if you think about what is the form of this piece down here the distribution or the Indicators even the weights, what you have is a form that resembles the kernel of multinomial distribution. </span>
<span id="cb29-151"><a href="#cb29-151" aria-hidden="true" tabindex="-1"></a>So this is similar to the kernel of a multinomial.</span>
<span id="cb29-152"><a href="#cb29-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-153"><a href="#cb29-153" aria-hidden="true" tabindex="-1"></a>In particular, it's not only similar but it's proportional to it. </span>
<span id="cb29-154"><a href="#cb29-154" aria-hidden="true" tabindex="-1"></a>So it will be particularly useful in terms of deriving the algorithm using the fact that this looks like a multinomial distribution.</span>
<span id="cb29-155"><a href="#cb29-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-156"><a href="#cb29-156" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb29-157"><a href="#cb29-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-158"><a href="#cb29-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-159"><a href="#cb29-159" aria-hidden="true" tabindex="-1"></a><span class="fu">## Markov Chain Monte Carlo algorithms part 2</span></span>
<span id="cb29-160"><a href="#cb29-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-161"><a href="#cb29-161" aria-hidden="true" tabindex="-1"></a><span class="al">![posterior distribution - weights](images/c3l3-ss-03-mcmc-part2.png)</span>{#fig-s_03 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-162"><a href="#cb29-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-163"><a href="#cb29-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-164"><a href="#cb29-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-165"><a href="#cb29-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-166"><a href="#cb29-166" aria-hidden="true" tabindex="-1"></a><span class="al">![posterior distribution - components](images/c3l3-ss-04-mcmc-part2.png)</span>{#fig-s_04 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-167"><a href="#cb29-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-168"><a href="#cb29-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-169"><a href="#cb29-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-170"><a href="#cb29-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-171"><a href="#cb29-171" aria-hidden="true" tabindex="-1"></a><span class="al">![posterior distribution - parameters](images/c3l3-ss-05-mcmc-part2.png)</span>{#fig-s_05 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-172"><a href="#cb29-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-173"><a href="#cb29-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-174"><a href="#cb29-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-175"><a href="#cb29-175" aria-hidden="true" tabindex="-1"></a>Now that we have a structure for the likelihood function that we and the prior distributions for all of our parameters, we can can derive the posterior distribution for our model.</span>
<span id="cb29-176"><a href="#cb29-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-177"><a href="#cb29-177" aria-hidden="true" tabindex="-1"></a>So we want to write down the joint posterior distribution. </span>
<span id="cb29-178"><a href="#cb29-178" aria-hidden="true" tabindex="-1"></a>In that joint posterior distribution includes, the weights and the parameters of the components, but it also involves the vector of indicators C, that we have introduced to simplify the structure of the likelihood, and by definition, this quantity is proportional to the distribution of the data, given all the parameters, multiplied by the distribution of the missing data parameters, given Omega and Theta, multiplied by the prior distribution on the parameters, multiplied by the prior distribution on the base.</span>
<span id="cb29-179"><a href="#cb29-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-180"><a href="#cb29-180" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-181"><a href="#cb29-181" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(c, \theta, \omega \mid x) \propto \left <span class="sc">\{</span> \prod_{i=1}^n \mathbb{P}r(x | c, \theta, \omega) \right <span class="sc">\}</span> \left <span class="sc">\{</span> \prod_{i=1}^n\prod_{k=1}^K \mathbb{P}r(c \mid \omega, \theta) \right <span class="sc">\}</span>\ \mathbb{P}r(\omega)\ \mathbb{P}r(\theta)</span>
<span id="cb29-182"><a href="#cb29-182" aria-hidden="true" tabindex="-1"></a>$$ {#eq-posterior-distribution}</span>
<span id="cb29-183"><a href="#cb29-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-184"><a href="#cb29-184" aria-hidden="true" tabindex="-1"></a>Each of the full conditional distributions can be derived from this joint posterior by retaining the terms that involve the parameter of interest, and recognizing the product of the selected terms as the kernel of a known family of distributions.</span>
<span id="cb29-185"><a href="#cb29-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-186"><a href="#cb29-186" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">TODO</span><span class="co">: extract transcript to external file and summarize --&gt;</span></span>
<span id="cb29-187"><a href="#cb29-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-188"><a href="#cb29-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-189"><a href="#cb29-189" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb29-190"><a href="#cb29-190" aria-hidden="true" tabindex="-1"></a><span class="fu">## Video transcript {.unnumbered .unlisted}</span></span>
<span id="cb29-191"><a href="#cb29-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-192"><a href="#cb29-192" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Now that we have a clear structure for the likelihood function that we will be using and we have prior distributions for all of our parameters, we can proceed to derive the posterior distribution that we will be working with.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-193"><a href="#cb29-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-194"><a href="#cb29-194" aria-hidden="true" tabindex="-1"></a>We want to write down the joint posterior distribution. </span>
<span id="cb29-195"><a href="#cb29-195" aria-hidden="true" tabindex="-1"></a>In that joint posterior distribution includes, of course, the weights and the parameters of the components, but it also involves the vector of indicators $C$, that we have introduced to simplify the structure of the likelihood, and by definition, this quantity is proportional to the distribution of the data, given all the parameters, multiplied by the distribution of the missing data parameters, given $\omega$ and $\theta$, multiplied by the prior distribution on the parameters, multiplied by the prior distribution on the base.</span>
<span id="cb29-196"><a href="#cb29-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-197"><a href="#cb29-197" aria-hidden="true" tabindex="-1"></a>So this is the general expression, the general form, for that posterior distribution. </span>
<span id="cb29-198"><a href="#cb29-198" aria-hidden="true" tabindex="-1"></a>Now, we have already seen what the form of the different terms is. </span>
<span id="cb29-199"><a href="#cb29-199" aria-hidden="true" tabindex="-1"></a>In particular, this joint distribution of the data can be written as a double product. </span>
<span id="cb29-200"><a href="#cb29-200" aria-hidden="true" tabindex="-1"></a>First-order components, and then over the groups of observations that belong to each one of those components of $g_k$ $x_i$, given $\theta_k$. </span>
<span id="cb29-201"><a href="#cb29-201" aria-hidden="true" tabindex="-1"></a>So that is the first piece that we're interested in. </span>
<span id="cb29-202"><a href="#cb29-202" aria-hidden="true" tabindex="-1"></a>The second piece, we have already seen also how to write it down. </span>
<span id="cb29-203"><a href="#cb29-203" aria-hidden="true" tabindex="-1"></a>This is going to be the product from k equals one, to capital k of $\omega_k$. </span>
<span id="cb29-204"><a href="#cb29-204" aria-hidden="true" tabindex="-1"></a>Some of these indicators of $c_i$ is equal to k from one to n. This is our second piece. </span>
<span id="cb29-205"><a href="#cb29-205" aria-hidden="true" tabindex="-1"></a>Then we discussed using a Dirichlet distribution for this. So ignoring some proportionality constants, this becomes the product from k equals one to capital k of $\omega_k$ raised to the $a_k - 1$. </span>
<span id="cb29-206"><a href="#cb29-206" aria-hidden="true" tabindex="-1"></a>That's this piece. </span>
<span id="cb29-207"><a href="#cb29-207" aria-hidden="true" tabindex="-1"></a>Then finally, we're going to have another product. </span>
<span id="cb29-208"><a href="#cb29-208" aria-hidden="true" tabindex="-1"></a>So typically, we use independent priors for each one of the data case. </span>
<span id="cb29-209"><a href="#cb29-209" aria-hidden="true" tabindex="-1"></a>As I said, we'll typically try to pick them so that they are conjugate to this kernel, $g_k()$, but for now, I'm going to write it in general form by writing this as $p_k(\theta_k)$, and that's what the last term in the expression is. So we have written down a full expression for this. </span>
<span id="cb29-210"><a href="#cb29-210" aria-hidden="true" tabindex="-1"></a>Now, it should be more or less clear how we need to proceed. </span>
<span id="cb29-211"><a href="#cb29-211" aria-hidden="true" tabindex="-1"></a>So we need full conditionals for all the parameters in the model. </span>
<span id="cb29-212"><a href="#cb29-212" aria-hidden="true" tabindex="-1"></a>In particular, we are going to need a full conditional for $\omega$, given all the other parameters, we're going to need a full conditional for each one of the $c_i$'s given the rest of the parameters, and we're going to need a full conditional for each one of the data cases, given the rest of the parameters. </span>
<span id="cb29-213"><a href="#cb29-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-214"><a href="#cb29-214" aria-hidden="true" tabindex="-1"></a>So to derive these full conditionals, what we will do is we will pick particular pieces from this expressions to retain and to construct this</span>
<span id="cb29-215"><a href="#cb29-215" aria-hidden="true" tabindex="-1"></a>particular four conditionals. </span>
<span id="cb29-216"><a href="#cb29-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-217"><a href="#cb29-217" aria-hidden="true" tabindex="-1"></a>Let's proceed now to derive each one of the four conditionals that we need to derive a Gibbs sampler or a Markov Chain Monte Carlo algorithm for this problem.</span>
<span id="cb29-218"><a href="#cb29-218" aria-hidden="true" tabindex="-1"></a>Let's just start with the full posterior distribution for the weights, and please note that we're going to work with all the weights as a block, so we're going to try to sample them all together, and rather than looking at each one of them at a time. o this full conditional distribution is made up of the terms in this full posterior distribution that involves $\omega_k$, and if you look at this expression carefully, you will see that this piece doesn't depend on $\omega_k$ anyway, and that this piece doesn't depend on any of the $\omega_k$ either, so it's just this two pieces in the middle that we need to consider.</span>
<span id="cb29-219"><a href="#cb29-219" aria-hidden="true" tabindex="-1"></a>Furthermore, the two pieces are very similar, so both in both products over K of the weight raised to some power, so we can actually combine the two expressions together and just write them as the product from one to capital k of $\omega_k$ raised to the sum of these indicator functions, plus a_k minus 1. This looks exactly like</span>
<span id="cb29-220"><a href="#cb29-220" aria-hidden="true" tabindex="-1"></a>the prior that we used, except that now, we have updated parameters.</span>
<span id="cb29-221"><a href="#cb29-221" aria-hidden="true" tabindex="-1"></a>So I could write this as the product of $\omega_k$ raised to the $a_k$, call them stars, minus one, where a_k a star, is just the original $a_k$ plus the sum from one to n of the indicators of $c_i$ equals to k.</span>
<span id="cb29-222"><a href="#cb29-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-223"><a href="#cb29-223" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">So just doing this little change, makes it very clear that the form of the posterior is exactly the same form as the prior.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-224"><a href="#cb29-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-225"><a href="#cb29-225" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">In other words, this a conditionally conjugate prior for our problem, and that just means that $\omega$ is going to be distributed as a Dirichlet, given all the other parameters, but with this updated parameters, a_1 star all the way to a_k star, and this is very interesting because essentially, a posteriori, we know that the expected value of $\omega$ given all the other parameters, so this is the expected value of the full conditional. This is not expected value of the marginal posterior, but this is the expected value of the full conditional</span><span class="co">]</span>{.mark}</span>
<span id="cb29-226"><a href="#cb29-226" aria-hidden="true" tabindex="-1"></a>that is going to be a_k star divided by the sum from L equals</span>
<span id="cb29-227"><a href="#cb29-227" aria-hidden="true" tabindex="-1"></a>one to k of a sub L, a star, but this is just a_k plus the sum from one</span>
<span id="cb29-228"><a href="#cb29-228" aria-hidden="true" tabindex="-1"></a>to n of these indicators, $c_i$ equals to k, divided by n plus the sum from L equals one to capital K of the a_l. N just comes from the fact that if I sum over all the components, then the sum of those values</span>
<span id="cb29-229"><a href="#cb29-229" aria-hidden="true" tabindex="-1"></a>is going to be n. </span>
<span id="cb29-230"><a href="#cb29-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-231"><a href="#cb29-231" aria-hidden="true" tabindex="-1"></a>So this is just the number of observations that are currently assigned to the case component, and if the values of a, k are small, then this is just roughly speaking. </span>
<span id="cb29-232"><a href="#cb29-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-233"><a href="#cb29-233" aria-hidden="true" tabindex="-1"></a>[So approximately, the proportion of observations in component K. </span>
<span id="cb29-234"><a href="#cb29-234" aria-hidden="true" tabindex="-1"></a>This has a very nice analogy with the computations that we did in the EM algorithm.]{.mark} </span>
<span id="cb29-235"><a href="#cb29-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-236"><a href="#cb29-236" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">If you remember the way in which we computed the weights in that case, or the MLE for the weights, was by essentially computing a quantity that could also be interpreted as, roughly speaking, the proportion of observations in that step of the algorithm that were assigned to that component.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-237"><a href="#cb29-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-238"><a href="#cb29-238" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">So this provides a mirror image to what we did with the EM algorithm, but that has a Bayesian flavor rather than a frequentist flavor. Let's continue now with the full conditional posterior distribution for the indicators, for the c_is. I'm interested in the probability that c_i is equal to K given the data.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-239"><a href="#cb29-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-240"><a href="#cb29-240" aria-hidden="true" tabindex="-1"></a>As before, this is going to be proportional to just the terms in this large product that depends on $c_i$, and if you look at it carefully, $c_i$ only appears in this two terms of the product. </span>
<span id="cb29-241"><a href="#cb29-241" aria-hidden="true" tabindex="-1"></a>These have nothing to do with $c_i.$ </span>
<span id="cb29-242"><a href="#cb29-242" aria-hidden="true" tabindex="-1"></a>In particular, it appears in a single term within this really large product and in a single term within this product. </span>
<span id="cb29-243"><a href="#cb29-243" aria-hidden="true" tabindex="-1"></a>So the term that depends on $c_i$ being equal to $k$ in here is $\omega_k$. </span>
<span id="cb29-244"><a href="#cb29-244" aria-hidden="true" tabindex="-1"></a>The term that depends on</span>
<span id="cb29-245"><a href="#cb29-245" aria-hidden="true" tabindex="-1"></a>$c_i$ equal to $k$ in here, it's just $g_k(x_i \mid \theta_k)$, and this is true for</span>
<span id="cb29-246"><a href="#cb29-246" aria-hidden="true" tabindex="-1"></a>every $k$ from one to capital $K$. </span>
<span id="cb29-247"><a href="#cb29-247" aria-hidden="true" tabindex="-1"></a>Remember that $c_i$ is a discrete</span>
<span id="cb29-248"><a href="#cb29-248" aria-hidden="true" tabindex="-1"></a>random variable, taking values between one and $k$ because it indicates which component generated the observation. </span>
<span id="cb29-249"><a href="#cb29-249" aria-hidden="true" tabindex="-1"></a>So if I want to get rid of the proportionality sign and actually being able to write what the probability is, I just need to normalize this by dividing over the sum of these quantities over $k$. </span>
<span id="cb29-250"><a href="#cb29-250" aria-hidden="true" tabindex="-1"></a>So that means that $p(c_i = k \mid \text{all other parameters}) = \frac{\omega_k g_k(x_i \mid \theta_k)}{\sum_{l=1}^{K} \omega_l g_l(x_i \mid \theta_l)}$. </span>
<span id="cb29-251"><a href="#cb29-251" aria-hidden="true" tabindex="-1"></a>If you look at this expression carefully, you will realize that it is very similar to the expression that we used when computing in the EM algorithm, the weights associated which is one of the observations. </span>
<span id="cb29-252"><a href="#cb29-252" aria-hidden="true" tabindex="-1"></a>In fact, it is the same expression, and this is just what we called in the EM algorithm, $V_{ik}$. Finally, let's consider the full conditional posterior distribution for the data case. </span>
<span id="cb29-253"><a href="#cb29-253" aria-hidden="true" tabindex="-1"></a>So we need $p(\theta_k \mid \text{all other parameters})$. </span>
<span id="cb29-254"><a href="#cb29-254" aria-hidden="true" tabindex="-1"></a>Again, we just pick from this whole product the terms that have to do with $\theta_k$, in this case, it is the two in the middle that do</span>
<span id="cb29-255"><a href="#cb29-255" aria-hidden="true" tabindex="-1"></a>not depend on it, and within this big expression, we just have a few terms</span>
<span id="cb29-256"><a href="#cb29-256" aria-hidden="true" tabindex="-1"></a>that contain $\theta_k$, and those correspond to the observations that are currently assigned to that particular component. </span>
<span id="cb29-257"><a href="#cb29-257" aria-hidden="true" tabindex="-1"></a>So this expression is proportional to the product over the $i$'s that have been assigned to the $k$ th component of $g_k(x_i \mid \theta_k)$, and among this product, again, there is a single term that belongs to $\theta_k$. </span>
<span id="cb29-258"><a href="#cb29-258" aria-hidden="true" tabindex="-1"></a>So the form of the full conditional posterior distribution for the parameter $\theta_k$ is simply this. </span>
<span id="cb29-259"><a href="#cb29-259" aria-hidden="true" tabindex="-1"></a>Now, without a specific choice of $G$ and $P$, it is hard to further simplify this expression. </span>
<span id="cb29-260"><a href="#cb29-260" aria-hidden="true" tabindex="-1"></a>But what I do want to note here is that if this prior $p_k$ is conjugate to this kernel $g_k$, then we typically know what family this posterior</span>
<span id="cb29-261"><a href="#cb29-261" aria-hidden="true" tabindex="-1"></a>distribution will belong to, and that will make computation much simpler because you will typically be able to sample from that full posterior conditional distribution in using a direct sampler. </span>
<span id="cb29-262"><a href="#cb29-262" aria-hidden="true" tabindex="-1"></a>This will become a little bit more clear once we do an example with mixture models, which is what we're going to do next.</span>
<span id="cb29-263"><a href="#cb29-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-264"><a href="#cb29-264" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb29-265"><a href="#cb29-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-266"><a href="#cb29-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-267"><a href="#cb29-267" aria-hidden="true" tabindex="-1"></a><span class="fu">## MCMC for location mixtures of normals Part 1</span></span>
<span id="cb29-268"><a href="#cb29-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-269"><a href="#cb29-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-270"><a href="#cb29-270" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals - priors](images/c3l3-ss-06-mcmc-for-location-mixtures-of-normals-part-1.png)</span>{#fig-s_06 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-271"><a href="#cb29-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-272"><a href="#cb29-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-273"><a href="#cb29-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-274"><a href="#cb29-274" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals - marginals ](images/c3l3-ss-07-mcmc-for-location-mixtures-of-normals-part-1.png)</span>{#fig-s_07 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-275"><a href="#cb29-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-276"><a href="#cb29-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-277"><a href="#cb29-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-278"><a href="#cb29-278" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals weights](images/c3l3-ss-08-mcmc-for-location-mixtures-of-normals-part-1.png)</span>{#fig-s_08 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-279"><a href="#cb29-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-280"><a href="#cb29-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-281"><a href="#cb29-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-282"><a href="#cb29-282" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals - components](images/c3l3-ss-09-mcmc-for-location-mixtures-of-normals-part-1.png)</span>{#fig-s_09 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-283"><a href="#cb29-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-284"><a href="#cb29-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-285"><a href="#cb29-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-286"><a href="#cb29-286" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals - $\sigma^2$](images/c3l3-ss-10-mcmc-for-location-mixtures-of-normals-part-1.png)</span>{#fig-s_10 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-287"><a href="#cb29-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-288"><a href="#cb29-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-289"><a href="#cb29-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-290"><a href="#cb29-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-291"><a href="#cb29-291" aria-hidden="true" tabindex="-1"></a>As in the previous module we derive the full conditional distributions for the mixture of two univariate normals.</span>
<span id="cb29-292"><a href="#cb29-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-293"><a href="#cb29-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-294"><a href="#cb29-294" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-295"><a href="#cb29-295" aria-hidden="true" tabindex="-1"></a>f(x | Ï‰, Î¼1, Î¼2, Ïƒ) = \omega \frac{1}{\sqrt{2\pi\sigma}} \exp\left<span class="sc">\{</span>-\frac{(x - \mu_1)^2}{2\sigma^2}\right<span class="sc">\}</span> + (1- \omega) \frac{1}{\sqrt{2\pi\sigma}} \exp\left<span class="sc">\{</span>-\frac{(x - \mu_2)^2}{2\sigma^2}\right<span class="sc">\}</span></span>
<span id="cb29-296"><a href="#cb29-296" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-297"><a href="#cb29-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-298"><a href="#cb29-298" aria-hidden="true" tabindex="-1"></a>we use a beta distribution with $a_1=1$ and $a_2=1$ for $\omega$</span>
<span id="cb29-299"><a href="#cb29-299" aria-hidden="true" tabindex="-1"></a>which corresponds to a uniform distribution and is a special case of a Dirichlet for $K=2$.</span>
<span id="cb29-300"><a href="#cb29-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-301"><a href="#cb29-301" aria-hidden="true" tabindex="-1"></a>$\mu_k \sim \mathcal{N}(\eta,\tau^2)$</span>
<span id="cb29-302"><a href="#cb29-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-303"><a href="#cb29-303" aria-hidden="true" tabindex="-1"></a>Inverse Gamma for $\sigma^2$ with shape parameter $a$ and scale parameter $b$.</span>
<span id="cb29-304"><a href="#cb29-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-305"><a href="#cb29-305" aria-hidden="true" tabindex="-1"></a>An empirical approach to priors:</span>
<span id="cb29-306"><a href="#cb29-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-307"><a href="#cb29-307" aria-hidden="true" tabindex="-1"></a>\index{empirical Bayes}</span>
<span id="cb29-308"><a href="#cb29-308" aria-hidden="true" tabindex="-1"></a>In the absence of real prior information we typically employ the observed data to guide the selection of the hyperparameter $Î·$, $Ï„^2$, $d$ and $q$, in an approach that is reminiscent of empirical Bayes. In particular, we attempt to make the means of the different component lie in the same support of the observed data, so we take $Î·$ to be  approximately equal the mean (or median) of the observations, and $Ï„^2$ to be roughly equal to their variance. Similarly, for the prior on the variance $Ïƒ^2$ we set $d = 2$ (which implies that $\mathbb{E}(Ïƒ^2) = q$ and an infinite prior variance) and $q$ to be roughly equal to the variance of the observations. <span class="co">[</span><span class="ot">Posteriors are often not very sensitive to changes on the prior means that remain within an order of magnitude of the values suggested above.</span><span class="co">]</span>{.mark}</span>
<span id="cb29-309"><a href="#cb29-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-310"><a href="#cb29-310" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb29-311"><a href="#cb29-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-312"><a href="#cb29-312" aria-hidden="true" tabindex="-1"></a><span class="fu">## Overthinking the priors</span></span>
<span id="cb29-313"><a href="#cb29-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-314"><a href="#cb29-314" aria-hidden="true" tabindex="-1"></a>It seems that since this is a hierarchical model, we set the priors for different components from shared hyper-priors. This way the parameters can also be inferred and we can reduce the number of parameters we need to estimate !</span>
<span id="cb29-315"><a href="#cb29-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-316"><a href="#cb29-316" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb29-317"><a href="#cb29-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-318"><a href="#cb29-318" aria-hidden="true" tabindex="-1"></a><span class="fu">## MCMC for location mixtures of normals Part 2</span></span>
<span id="cb29-319"><a href="#cb29-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-320"><a href="#cb29-320" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals $\mu$](images/c3l3-ss-11-mcmc-for-location-mixtures-of-normals-part-2.png)</span>{#fig-s_11 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-321"><a href="#cb29-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-322"><a href="#cb29-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-323"><a href="#cb29-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-324"><a href="#cb29-324" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals $\mu$ continued 1](images/c3l3-ss-12-mcmc-for-location-mixtures-of-normals-part-2.png)</span>{#fig-s_12 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-325"><a href="#cb29-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-326"><a href="#cb29-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-327"><a href="#cb29-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-328"><a href="#cb29-328" aria-hidden="true" tabindex="-1"></a><span class="al">![location mixture of Normals $\mu$ continued 2](images/c3l3-ss-13-mcmc-for-location-mixtures-of-normals-part-2.png)</span>{#fig-s_13 .column-margin width="53mm" group="slides"}</span>
<span id="cb29-329"><a href="#cb29-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-330"><a href="#cb29-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-331"><a href="#cb29-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-332"><a href="#cb29-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-333"><a href="#cb29-333" aria-hidden="true" tabindex="-1"></a><span class="fu">## MCMC Example 1</span></span>
<span id="cb29-334"><a href="#cb29-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-337"><a href="#cb29-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-338"><a href="#cb29-338" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lbl-mcmc-setup</span></span>
<span id="cb29-339"><a href="#cb29-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-340"><a href="#cb29-340" aria-hidden="true" tabindex="-1"></a><span class="do">#### Example of an MCMC algorithm for fitting a location mixture of 2 Gaussian components</span></span>
<span id="cb29-341"><a href="#cb29-341" aria-hidden="true" tabindex="-1"></a><span class="do">#### The algorithm is tested using simulated data</span></span>
<span id="cb29-342"><a href="#cb29-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-343"><a href="#cb29-343" aria-hidden="true" tabindex="-1"></a><span class="do">## Clear the environment and load required libraries</span></span>
<span id="cb29-344"><a href="#cb29-344" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span>
<span id="cb29-345"><a href="#cb29-345" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb29-346"><a href="#cb29-346" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">81196</span>)  <span class="co"># So that results are reproducible</span></span>
<span id="cb29-347"><a href="#cb29-347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-350"><a href="#cb29-350" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-351"><a href="#cb29-351" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lbl-mcmc-generate-data</span></span>
<span id="cb29-352"><a href="#cb29-352" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate data from a mixture with 2 components</span></span>
<span id="cb29-353"><a href="#cb29-353" aria-hidden="true" tabindex="-1"></a>KK         <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb29-354"><a href="#cb29-354" aria-hidden="true" tabindex="-1"></a>w.true     <span class="ot">=</span> <span class="fl">0.6</span>  <span class="co"># True weights associated with the components</span></span>
<span id="cb29-355"><a href="#cb29-355" aria-hidden="true" tabindex="-1"></a>mu.true    <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, KK)</span>
<span id="cb29-356"><a href="#cb29-356" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">1</span>] <span class="ot">=</span> <span class="dv">0</span>   <span class="co"># True mean for the first component</span></span>
<span id="cb29-357"><a href="#cb29-357" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">2</span>] <span class="ot">=</span> <span class="dv">5</span>   <span class="co"># True mean for the second component</span></span>
<span id="cb29-358"><a href="#cb29-358" aria-hidden="true" tabindex="-1"></a>sigma.true <span class="ot">=</span> <span class="dv">1</span>   <span class="co"># True standard deviation of all components</span></span>
<span id="cb29-359"><a href="#cb29-359" aria-hidden="true" tabindex="-1"></a>n          <span class="ot">=</span> <span class="dv">120</span>         <span class="co"># Number of observations to be generated</span></span>
<span id="cb29-360"><a href="#cb29-360" aria-hidden="true" tabindex="-1"></a>cc.true <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, n, <span class="at">replace=</span>T, <span class="at">prob=</span><span class="fu">c</span>(w.true,<span class="dv">1</span><span class="sc">-</span>w.true))</span>
<span id="cb29-361"><a href="#cb29-361" aria-hidden="true" tabindex="-1"></a>x  <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, n)</span>
<span id="cb29-362"><a href="#cb29-362" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb29-363"><a href="#cb29-363" aria-hidden="true" tabindex="-1"></a>  x[i] <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu.true[cc.true[i]], sigma.true)</span>
<span id="cb29-364"><a href="#cb29-364" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-365"><a href="#cb29-365" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-366"><a href="#cb29-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-369"><a href="#cb29-369" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-370"><a href="#cb29-370" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mcmc-true-density</span></span>
<span id="cb29-371"><a href="#cb29-371" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "True density and data points"</span></span>
<span id="cb29-372"><a href="#cb29-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-373"><a href="#cb29-373" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the true density</span></span>
<span id="cb29-374"><a href="#cb29-374" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb29-375"><a href="#cb29-375" aria-hidden="true" tabindex="-1"></a>xx.true <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">11</span>,<span class="at">length=</span><span class="dv">200</span>)</span>
<span id="cb29-376"><a href="#cb29-376" aria-hidden="true" tabindex="-1"></a>yy.true <span class="ot">=</span> w.true<span class="sc">*</span><span class="fu">dnorm</span>(xx.true, mu.true[<span class="dv">1</span>], sigma.true) <span class="sc">+</span> </span>
<span id="cb29-377"><a href="#cb29-377" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">1</span><span class="sc">-</span>w.true)<span class="sc">*</span><span class="fu">dnorm</span>(xx.true, mu.true[<span class="dv">2</span>], sigma.true) </span>
<span id="cb29-378"><a href="#cb29-378" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xx.true, yy.true, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"True density"</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-379"><a href="#cb29-379" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="fu">rep</span>(<span class="dv">0</span>,n), <span class="at">col=</span>cc.true)</span>
<span id="cb29-380"><a href="#cb29-380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-381"><a href="#cb29-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-384"><a href="#cb29-384" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-385"><a href="#cb29-385" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lbl-mcmc-algorithm</span></span>
<span id="cb29-386"><a href="#cb29-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-387"><a href="#cb29-387" aria-hidden="true" tabindex="-1"></a><span class="do">## Initialize the parameters</span></span>
<span id="cb29-388"><a href="#cb29-388" aria-hidden="true" tabindex="-1"></a>w     <span class="ot">=</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>                         <span class="co">#Assign equal weight to each component to start with</span></span>
<span id="cb29-389"><a href="#cb29-389" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">=</span> <span class="fu">rnorm</span>(KK, <span class="fu">mean</span>(x), <span class="fu">sd</span>(x))   <span class="co">#Random cluster centers randomly spread over the support of the data</span></span>
<span id="cb29-390"><a href="#cb29-390" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fu">sd</span>(x)                       <span class="co">#Initial standard deviation</span></span>
<span id="cb29-391"><a href="#cb29-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-392"><a href="#cb29-392" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the initial guess for the density</span></span>
<span id="cb29-393"><a href="#cb29-393" aria-hidden="true" tabindex="-1"></a>xx <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">11</span>,<span class="at">length=</span><span class="dv">200</span>)</span>
<span id="cb29-394"><a href="#cb29-394" aria-hidden="true" tabindex="-1"></a>yy <span class="ot">=</span> w<span class="sc">*</span><span class="fu">dnorm</span>(xx, mu[<span class="dv">1</span>], sigma) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>w)<span class="sc">*</span><span class="fu">dnorm</span>(xx, mu[<span class="dv">2</span>], sigma)</span>
<span id="cb29-395"><a href="#cb29-395" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xx, yy, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">max</span>(yy)), <span class="at">xlab=</span><span class="st">"x"</span>, </span>
<span id="cb29-396"><a href="#cb29-396" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Initial density"</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-397"><a href="#cb29-397" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="fu">rep</span>(<span class="dv">0</span>,n), <span class="at">col=</span>cc.true)</span>
<span id="cb29-398"><a href="#cb29-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-399"><a href="#cb29-399" aria-hidden="true" tabindex="-1"></a><span class="do">## The actual MCMC algorithm starts here</span></span>
<span id="cb29-400"><a href="#cb29-400" aria-hidden="true" tabindex="-1"></a><span class="co"># Priors</span></span>
<span id="cb29-401"><a href="#cb29-401" aria-hidden="true" tabindex="-1"></a>aa  <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>,KK)  <span class="co"># Uniform prior on w</span></span>
<span id="cb29-402"><a href="#cb29-402" aria-hidden="true" tabindex="-1"></a>eta <span class="ot">=</span> <span class="dv">0</span>          <span class="co"># Mean 0 for the prior on mu_k</span></span>
<span id="cb29-403"><a href="#cb29-403" aria-hidden="true" tabindex="-1"></a>tau <span class="ot">=</span> <span class="dv">5</span>          <span class="co"># Standard deviation 5 on the prior for mu_l</span></span>
<span id="cb29-404"><a href="#cb29-404" aria-hidden="true" tabindex="-1"></a>dd  <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb29-405"><a href="#cb29-405" aria-hidden="true" tabindex="-1"></a>qq  <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb29-406"><a href="#cb29-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-407"><a href="#cb29-407" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of iterations of the sampler</span></span>
<span id="cb29-408"><a href="#cb29-408" aria-hidden="true" tabindex="-1"></a>rrr   <span class="ot">=</span> <span class="dv">6000</span></span>
<span id="cb29-409"><a href="#cb29-409" aria-hidden="true" tabindex="-1"></a>burn  <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb29-410"><a href="#cb29-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-411"><a href="#cb29-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-412"><a href="#cb29-412" aria-hidden="true" tabindex="-1"></a><span class="co"># Storing the samples</span></span>
<span id="cb29-413"><a href="#cb29-413" aria-hidden="true" tabindex="-1"></a>cc.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, n))</span>
<span id="cb29-414"><a href="#cb29-414" aria-hidden="true" tabindex="-1"></a>w.out     <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb29-415"><a href="#cb29-415" aria-hidden="true" tabindex="-1"></a>mu.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK))</span>
<span id="cb29-416"><a href="#cb29-416" aria-hidden="true" tabindex="-1"></a>sigma.out <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb29-417"><a href="#cb29-417" aria-hidden="true" tabindex="-1"></a>logpost   <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb29-418"><a href="#cb29-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-419"><a href="#cb29-419" aria-hidden="true" tabindex="-1"></a><span class="co"># MCMC iterations</span></span>
<span id="cb29-420"><a href="#cb29-420" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rrr){</span>
<span id="cb29-421"><a href="#cb29-421" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the indicators</span></span>
<span id="cb29-422"><a href="#cb29-422" aria-hidden="true" tabindex="-1"></a>  cc <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb29-423"><a href="#cb29-423" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb29-424"><a href="#cb29-424" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,KK)</span>
<span id="cb29-425"><a href="#cb29-425" aria-hidden="true" tabindex="-1"></a>    v[<span class="dv">1</span>] <span class="ot">=</span> <span class="fu">log</span>(w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">1</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)  <span class="co">#Compute the log of the weights</span></span>
<span id="cb29-426"><a href="#cb29-426" aria-hidden="true" tabindex="-1"></a>    v[<span class="dv">2</span>] <span class="ot">=</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">2</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)  <span class="co">#Compute the log of the weights</span></span>
<span id="cb29-427"><a href="#cb29-427" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v))<span class="sc">/</span><span class="fu">sum</span>(<span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v)))</span>
<span id="cb29-428"><a href="#cb29-428" aria-hidden="true" tabindex="-1"></a>    cc[i] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, <span class="dv">1</span>, <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span>v)</span>
<span id="cb29-429"><a href="#cb29-429" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-430"><a href="#cb29-430" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-431"><a href="#cb29-431" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the weights</span></span>
<span id="cb29-432"><a href="#cb29-432" aria-hidden="true" tabindex="-1"></a>  w <span class="ot">=</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, aa[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">1</span>), aa[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">2</span>))</span>
<span id="cb29-433"><a href="#cb29-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-434"><a href="#cb29-434" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the means</span></span>
<span id="cb29-435"><a href="#cb29-435" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-436"><a href="#cb29-436" aria-hidden="true" tabindex="-1"></a>    nk    <span class="ot">=</span> <span class="fu">sum</span>(cc<span class="sc">==</span>k)</span>
<span id="cb29-437"><a href="#cb29-437" aria-hidden="true" tabindex="-1"></a>    xsumk <span class="ot">=</span> <span class="fu">sum</span>(x[cc<span class="sc">==</span>k])</span>
<span id="cb29-438"><a href="#cb29-438" aria-hidden="true" tabindex="-1"></a>    tau2.hat <span class="ot">=</span> <span class="dv">1</span><span class="sc">/</span>(nk<span class="sc">/</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>tau<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb29-439"><a href="#cb29-439" aria-hidden="true" tabindex="-1"></a>    mu.hat  <span class="ot">=</span> tau2.hat<span class="sc">*</span>(xsumk<span class="sc">/</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> eta<span class="sc">/</span>tau<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb29-440"><a href="#cb29-440" aria-hidden="true" tabindex="-1"></a>    mu[k]   <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu.hat, <span class="fu">sqrt</span>(tau2.hat))</span>
<span id="cb29-441"><a href="#cb29-441" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-442"><a href="#cb29-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-443"><a href="#cb29-443" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the variances</span></span>
<span id="cb29-444"><a href="#cb29-444" aria-hidden="true" tabindex="-1"></a>  dd.star <span class="ot">=</span> dd <span class="sc">+</span> n<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb29-445"><a href="#cb29-445" aria-hidden="true" tabindex="-1"></a>  qq.star <span class="ot">=</span> qq <span class="sc">+</span> <span class="fu">sum</span>((x <span class="sc">-</span> mu[cc])<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb29-446"><a href="#cb29-446" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">=</span> <span class="fu">sqrt</span>(<span class="fu">rinvgamma</span>(<span class="dv">1</span>, dd.star, qq.star))</span>
<span id="cb29-447"><a href="#cb29-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-448"><a href="#cb29-448" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store samples</span></span>
<span id="cb29-449"><a href="#cb29-449" aria-hidden="true" tabindex="-1"></a>  cc.out[s,]   <span class="ot">=</span> cc</span>
<span id="cb29-450"><a href="#cb29-450" aria-hidden="true" tabindex="-1"></a>  w.out[s]     <span class="ot">=</span> w</span>
<span id="cb29-451"><a href="#cb29-451" aria-hidden="true" tabindex="-1"></a>  mu.out[s,]   <span class="ot">=</span> mu</span>
<span id="cb29-452"><a href="#cb29-452" aria-hidden="true" tabindex="-1"></a>  sigma.out[s] <span class="ot">=</span> sigma</span>
<span id="cb29-453"><a href="#cb29-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-454"><a href="#cb29-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-455"><a href="#cb29-455" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the log posterior</span></span>
<span id="cb29-456"><a href="#cb29-456" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb29-457"><a href="#cb29-457" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(cc[i]<span class="sc">==</span><span class="dv">1</span>){</span>
<span id="cb29-458"><a href="#cb29-458" aria-hidden="true" tabindex="-1"></a>      logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">1</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb29-459"><a href="#cb29-459" aria-hidden="true" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb29-460"><a href="#cb29-460" aria-hidden="true" tabindex="-1"></a>      logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>w) <span class="sc">+</span> <span class="fu">dnorm</span>(x[i], mu[<span class="dv">2</span>], sigma, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb29-461"><a href="#cb29-461" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb29-462"><a href="#cb29-462" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-463"><a href="#cb29-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-464"><a href="#cb29-464" aria-hidden="true" tabindex="-1"></a>  logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">dbeta</span>(w, aa[<span class="dv">1</span>], aa[<span class="dv">2</span>],<span class="at">log =</span> T)</span>
<span id="cb29-465"><a href="#cb29-465" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-466"><a href="#cb29-466" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">dnorm</span>(mu[k], eta, tau, <span class="at">log =</span> T)</span>
<span id="cb29-467"><a href="#cb29-467" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-468"><a href="#cb29-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-469"><a href="#cb29-469" aria-hidden="true" tabindex="-1"></a>  logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(<span class="fu">dinvgamma</span>(sigma<span class="sc">^</span><span class="dv">2</span>, dd, <span class="dv">1</span><span class="sc">/</span>qq))</span>
<span id="cb29-470"><a href="#cb29-470" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-471"><a href="#cb29-471" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print s every 500 iterations</span></span>
<span id="cb29-472"><a href="#cb29-472" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(s<span class="sc">/</span><span class="dv">500</span><span class="sc">==</span><span class="fu">floor</span>(s<span class="sc">/</span><span class="dv">500</span>)){</span>
<span id="cb29-473"><a href="#cb29-473" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"s ="</span>,s))</span>
<span id="cb29-474"><a href="#cb29-474" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-475"><a href="#cb29-475" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-476"><a href="#cb29-476" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-477"><a href="#cb29-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-480"><a href="#cb29-480" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-481"><a href="#cb29-481" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mcmc-plot-logpost</span></span>
<span id="cb29-482"><a href="#cb29-482" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Log posterior distribution for various samples"</span></span>
<span id="cb29-483"><a href="#cb29-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-484"><a href="#cb29-484" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the logposterior distribution for various samples</span></span>
<span id="cb29-485"><a href="#cb29-485" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb29-486"><a href="#cb29-486" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb29-487"><a href="#cb29-487" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(logpost, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">xlab=</span><span class="st">"Iterations"</span>, <span class="at">ylab=</span><span class="st">"Log posterior"</span>)</span>
<span id="cb29-488"><a href="#cb29-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-489"><a href="#cb29-489" aria-hidden="true" tabindex="-1"></a>xx <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">11</span>,<span class="at">length=</span><span class="dv">200</span>)</span>
<span id="cb29-490"><a href="#cb29-490" aria-hidden="true" tabindex="-1"></a>density.posterior <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr<span class="sc">-</span>burn,<span class="fu">length</span>(xx)))</span>
<span id="cb29-491"><a href="#cb29-491" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(rrr<span class="sc">-</span>burn)){</span>
<span id="cb29-492"><a href="#cb29-492" aria-hidden="true" tabindex="-1"></a>  density.posterior[s,] <span class="ot">=</span> density.posterior[s,] <span class="sc">+</span> w.out[s<span class="sc">+</span>burn]<span class="sc">*</span><span class="fu">dnorm</span>(xx,mu.out[s<span class="sc">+</span>burn,<span class="dv">1</span>],sigma.out[s<span class="sc">+</span>burn]) <span class="sc">+</span></span>
<span id="cb29-493"><a href="#cb29-493" aria-hidden="true" tabindex="-1"></a>                                                  (<span class="dv">1</span><span class="sc">-</span>w.out[s<span class="sc">+</span>burn])<span class="sc">*</span><span class="fu">dnorm</span>(xx,mu.out[s<span class="sc">+</span>burn,<span class="dv">2</span>],sigma.out[s<span class="sc">+</span>burn])</span>
<span id="cb29-494"><a href="#cb29-494" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-495"><a href="#cb29-495" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-496"><a href="#cb29-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-499"><a href="#cb29-499" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-500"><a href="#cb29-500" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mcmc-plot-density</span></span>
<span id="cb29-501"><a href="#cb29-501" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Posterior density estimate"</span></span>
<span id="cb29-502"><a href="#cb29-502" aria-hidden="true" tabindex="-1"></a><span class="do">## report the posterior mean and 95% credible interval</span></span>
<span id="cb29-503"><a href="#cb29-503" aria-hidden="true" tabindex="-1"></a>density.posterior.m <span class="ot">=</span> <span class="fu">apply</span>(density.posterior , <span class="dv">2</span>, mean)</span>
<span id="cb29-504"><a href="#cb29-504" aria-hidden="true" tabindex="-1"></a>density.posterior.lq <span class="ot">=</span> <span class="fu">apply</span>(density.posterior, <span class="dv">2</span>, quantile, <span class="fl">0.025</span>)</span>
<span id="cb29-505"><a href="#cb29-505" aria-hidden="true" tabindex="-1"></a>density.posterior.uq <span class="ot">=</span> <span class="fu">apply</span>(density.posterior, <span class="dv">2</span>, quantile, <span class="fl">0.975</span>)</span>
<span id="cb29-506"><a href="#cb29-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-507"><a href="#cb29-507" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the posterior density estimate</span></span>
<span id="cb29-508"><a href="#cb29-508" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb29-509"><a href="#cb29-509" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb29-510"><a href="#cb29-510" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xx, density.posterior.m, <span class="at">type=</span><span class="st">"n"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(density.posterior.uq)), <span class="at">xlab=</span><span class="st">"x"</span>, <span class="at">ylab=</span><span class="st">"Density"</span>)</span>
<span id="cb29-511"><a href="#cb29-511" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="fu">c</span>(xx,<span class="fu">rev</span>(xx)), <span class="fu">c</span>(density.posterior.lq, <span class="fu">rev</span>(density.posterior.uq)), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">border=</span><span class="st">"grey"</span>)</span>
<span id="cb29-512"><a href="#cb29-512" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xx, density.posterior.m, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-513"><a href="#cb29-513" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="fu">rep</span>(<span class="dv">0</span>,n), <span class="at">col=</span>cc.true)</span>
<span id="cb29-514"><a href="#cb29-514" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-515"><a href="#cb29-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-516"><a href="#cb29-516" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sample code for MCMC example 1</span></span>
<span id="cb29-517"><a href="#cb29-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-518"><a href="#cb29-518" aria-hidden="true" tabindex="-1"></a><span class="fu">## MCMC Example 2</span></span>
<span id="cb29-519"><a href="#cb29-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-520"><a href="#cb29-520" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sample code for MCMC example 2</span></span>
<span id="cb29-521"><a href="#cb29-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-524"><a href="#cb29-524" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-525"><a href="#cb29-525" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lbl-mcmc-example-2</span></span>
<span id="cb29-526"><a href="#cb29-526" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb29-527"><a href="#cb29-527" aria-hidden="true" tabindex="-1"></a><span class="do">#### Example of an MCMC algorithm for fitting a mixtures of K p-variate Gaussian components</span></span>
<span id="cb29-528"><a href="#cb29-528" aria-hidden="true" tabindex="-1"></a><span class="do">#### The algorithm is tested using simulated data</span></span>
<span id="cb29-529"><a href="#cb29-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-530"><a href="#cb29-530" aria-hidden="true" tabindex="-1"></a><span class="do">## Clear the environment and load required libraries</span></span>
<span id="cb29-531"><a href="#cb29-531" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span>
<span id="cb29-532"><a href="#cb29-532" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm)</span>
<span id="cb29-533"><a href="#cb29-533" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ellipse)</span>
<span id="cb29-534"><a href="#cb29-534" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb29-535"><a href="#cb29-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-536"><a href="#cb29-536" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate data from a mixture with 3 components</span></span>
<span id="cb29-537"><a href="#cb29-537" aria-hidden="true" tabindex="-1"></a>KK      <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb29-538"><a href="#cb29-538" aria-hidden="true" tabindex="-1"></a>p       <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb29-539"><a href="#cb29-539" aria-hidden="true" tabindex="-1"></a>w.true <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>)  <span class="co"># True weights associated with the components</span></span>
<span id="cb29-540"><a href="#cb29-540" aria-hidden="true" tabindex="-1"></a>mu.true     <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p))</span>
<span id="cb29-541"><a href="#cb29-541" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">1</span>,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)   <span class="co">#True mean for the first component</span></span>
<span id="cb29-542"><a href="#cb29-542" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">2</span>,] <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)   <span class="co">#True mean for the second component</span></span>
<span id="cb29-543"><a href="#cb29-543" aria-hidden="true" tabindex="-1"></a>mu.true[<span class="dv">3</span>,] <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">7</span>)   <span class="co">#True mean for the third component</span></span>
<span id="cb29-544"><a href="#cb29-544" aria-hidden="true" tabindex="-1"></a>Sigma.true      <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p,p))</span>
<span id="cb29-545"><a href="#cb29-545" aria-hidden="true" tabindex="-1"></a>Sigma.true[<span class="dv">1</span>,,] <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>),p,p)   <span class="co">#True variance for the first component</span></span>
<span id="cb29-546"><a href="#cb29-546" aria-hidden="true" tabindex="-1"></a>Sigma.true[<span class="dv">2</span>,,] <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="fl">0.9</span>,<span class="fl">0.9</span>,<span class="dv">1</span>),p,p)   <span class="co">#True variance for the second component</span></span>
<span id="cb29-547"><a href="#cb29-547" aria-hidden="true" tabindex="-1"></a>Sigma.true[<span class="dv">3</span>,,] <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="sc">-</span><span class="fl">0.9</span>,<span class="sc">-</span><span class="fl">0.9</span>,<span class="dv">4</span>),p,p)   <span class="co">#True variance for the third component</span></span>
<span id="cb29-548"><a href="#cb29-548" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">63252</span>)    <span class="co">#Keep seed the same so that we can reproduce results</span></span>
<span id="cb29-549"><a href="#cb29-549" aria-hidden="true" tabindex="-1"></a>n  <span class="ot">=</span> <span class="dv">120</span></span>
<span id="cb29-550"><a href="#cb29-550" aria-hidden="true" tabindex="-1"></a>cc.true <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, n, <span class="at">replace=</span>T, <span class="at">prob=</span>w.true)</span>
<span id="cb29-551"><a href="#cb29-551" aria-hidden="true" tabindex="-1"></a>x  <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(n,p))</span>
<span id="cb29-552"><a href="#cb29-552" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb29-553"><a href="#cb29-553" aria-hidden="true" tabindex="-1"></a>  x[i,] <span class="ot">=</span> <span class="fu">rmvnorm</span>(<span class="dv">1</span>, mu.true[cc.true[i],], Sigma.true[cc.true[i],,])</span>
<span id="cb29-554"><a href="#cb29-554" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-555"><a href="#cb29-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-556"><a href="#cb29-556" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb29-557"><a href="#cb29-557" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="at">col=</span>cc.true, <span class="at">xlab=</span><span class="fu">expression</span>(x[<span class="dv">1</span>]), <span class="at">ylab=</span><span class="fu">expression</span>(x[<span class="dv">2</span>]), <span class="at">type=</span><span class="st">"n"</span>)</span>
<span id="cb29-558"><a href="#cb29-558" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="fu">seq</span>(<span class="dv">1</span>,n), <span class="at">col=</span>cc.true, <span class="at">cex=</span><span class="fl">0.6</span>)</span>
<span id="cb29-559"><a href="#cb29-559" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-560"><a href="#cb29-560" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma.true[k,,], <span class="at">centre=</span>mu.true[k,], <span class="at">level=</span><span class="fl">0.50</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb29-561"><a href="#cb29-561" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma.true[k,,], <span class="at">centre=</span>mu.true[k,], <span class="at">level=</span><span class="fl">0.82</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb29-562"><a href="#cb29-562" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma.true[k,,], <span class="at">centre=</span>mu.true[k,], <span class="at">level=</span><span class="fl">0.95</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb29-563"><a href="#cb29-563" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-564"><a href="#cb29-564" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Data + True Components"</span>)</span>
<span id="cb29-565"><a href="#cb29-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-566"><a href="#cb29-566" aria-hidden="true" tabindex="-1"></a><span class="do">## Initialize the parameters</span></span>
<span id="cb29-567"><a href="#cb29-567" aria-hidden="true" tabindex="-1"></a>w          <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>,KK)<span class="sc">/</span>KK  <span class="co">#Assign equal weight to each component to start with</span></span>
<span id="cb29-568"><a href="#cb29-568" aria-hidden="true" tabindex="-1"></a>mu         <span class="ot">=</span> <span class="fu">rmvnorm</span>(KK, <span class="fu">apply</span>(x,<span class="dv">2</span>,mean), <span class="fu">var</span>(x))   <span class="co">#RandomCluster centers randomly spread over the support of the data</span></span>
<span id="cb29-569"><a href="#cb29-569" aria-hidden="true" tabindex="-1"></a>Sigma      <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p,p))  <span class="co">#Initial variances are assumed to be the same</span></span>
<span id="cb29-570"><a href="#cb29-570" aria-hidden="true" tabindex="-1"></a>Sigma[<span class="dv">1</span>,,] <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span>KK  </span>
<span id="cb29-571"><a href="#cb29-571" aria-hidden="true" tabindex="-1"></a>Sigma[<span class="dv">2</span>,,] <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span>KK</span>
<span id="cb29-572"><a href="#cb29-572" aria-hidden="true" tabindex="-1"></a>Sigma[<span class="dv">3</span>,,] <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span>KK</span>
<span id="cb29-573"><a href="#cb29-573" aria-hidden="true" tabindex="-1"></a>cc         <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, n, <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span>w)</span>
<span id="cb29-574"><a href="#cb29-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-575"><a href="#cb29-575" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb29-576"><a href="#cb29-576" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="at">col=</span>cc.true, <span class="at">xlab=</span><span class="fu">expression</span>(x[<span class="dv">1</span>]), <span class="at">ylab=</span><span class="fu">expression</span>(x[<span class="dv">2</span>]))</span>
<span id="cb29-577"><a href="#cb29-577" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-578"><a href="#cb29-578" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.50</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-579"><a href="#cb29-579" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.82</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-580"><a href="#cb29-580" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.95</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-581"><a href="#cb29-581" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-582"><a href="#cb29-582" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Initial estimate + Observations"</span>)</span>
<span id="cb29-583"><a href="#cb29-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-584"><a href="#cb29-584" aria-hidden="true" tabindex="-1"></a><span class="co"># Priors</span></span>
<span id="cb29-585"><a href="#cb29-585" aria-hidden="true" tabindex="-1"></a>aa <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>, KK)</span>
<span id="cb29-586"><a href="#cb29-586" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">=</span> <span class="fu">apply</span>(x,<span class="dv">2</span>,mean)</span>
<span id="cb29-587"><a href="#cb29-587" aria-hidden="true" tabindex="-1"></a>DD <span class="ot">=</span> <span class="dv">10</span><span class="sc">*</span><span class="fu">var</span>(x)</span>
<span id="cb29-588"><a href="#cb29-588" aria-hidden="true" tabindex="-1"></a>nu <span class="ot">=</span> p</span>
<span id="cb29-589"><a href="#cb29-589" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">=</span> <span class="fu">var</span>(x)<span class="sc">/</span><span class="dv">3</span></span>
<span id="cb29-590"><a href="#cb29-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-591"><a href="#cb29-591" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of iteration of the sampler</span></span>
<span id="cb29-592"><a href="#cb29-592" aria-hidden="true" tabindex="-1"></a>rrr <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb29-593"><a href="#cb29-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-594"><a href="#cb29-594" aria-hidden="true" tabindex="-1"></a><span class="co"># Storing the samples</span></span>
<span id="cb29-595"><a href="#cb29-595" aria-hidden="true" tabindex="-1"></a>cc.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, n))</span>
<span id="cb29-596"><a href="#cb29-596" aria-hidden="true" tabindex="-1"></a>w.out     <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK))</span>
<span id="cb29-597"><a href="#cb29-597" aria-hidden="true" tabindex="-1"></a>mu.out    <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK, p))</span>
<span id="cb29-598"><a href="#cb29-598" aria-hidden="true" tabindex="-1"></a>Sigma.out <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(rrr, KK, p, p))</span>
<span id="cb29-599"><a href="#cb29-599" aria-hidden="true" tabindex="-1"></a>logpost   <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, rrr)</span>
<span id="cb29-600"><a href="#cb29-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-601"><a href="#cb29-601" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rrr){</span>
<span id="cb29-602"><a href="#cb29-602" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the indicators</span></span>
<span id="cb29-603"><a href="#cb29-603" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb29-604"><a href="#cb29-604" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>,KK)</span>
<span id="cb29-605"><a href="#cb29-605" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-606"><a href="#cb29-606" aria-hidden="true" tabindex="-1"></a>      v[k] <span class="ot">=</span> <span class="fu">log</span>(w[k]) <span class="sc">+</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(x[i,], mu[k,], Sigma[k,,], <span class="at">log=</span><span class="cn">TRUE</span>)  <span class="co">#Compute the log of the weights</span></span>
<span id="cb29-607"><a href="#cb29-607" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb29-608"><a href="#cb29-608" aria-hidden="true" tabindex="-1"></a>    v <span class="ot">=</span> <span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v))<span class="sc">/</span><span class="fu">sum</span>(<span class="fu">exp</span>(v <span class="sc">-</span> <span class="fu">max</span>(v)))</span>
<span id="cb29-609"><a href="#cb29-609" aria-hidden="true" tabindex="-1"></a>    cc[i] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>KK, <span class="dv">1</span>, <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span>v)</span>
<span id="cb29-610"><a href="#cb29-610" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-611"><a href="#cb29-611" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-612"><a href="#cb29-612" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the weights</span></span>
<span id="cb29-613"><a href="#cb29-613" aria-hidden="true" tabindex="-1"></a>  w <span class="ot">=</span> <span class="fu">as.vector</span>(<span class="fu">rdirichlet</span>(<span class="dv">1</span>, aa <span class="sc">+</span> <span class="fu">tabulate</span>(cc)))</span>
<span id="cb29-614"><a href="#cb29-614" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-615"><a href="#cb29-615" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the means</span></span>
<span id="cb29-616"><a href="#cb29-616" aria-hidden="true" tabindex="-1"></a>  DD.st <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow=</span>p, <span class="at">ncol=</span>p)</span>
<span id="cb29-617"><a href="#cb29-617" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-618"><a href="#cb29-618" aria-hidden="true" tabindex="-1"></a>    mk    <span class="ot">=</span> <span class="fu">sum</span>(cc<span class="sc">==</span>k)</span>
<span id="cb29-619"><a href="#cb29-619" aria-hidden="true" tabindex="-1"></a>    xsumk <span class="ot">=</span> <span class="fu">apply</span>(x[cc<span class="sc">==</span>k,], <span class="dv">2</span>, sum)</span>
<span id="cb29-620"><a href="#cb29-620" aria-hidden="true" tabindex="-1"></a>    DD.st <span class="ot">=</span> <span class="fu">solve</span>(mk<span class="sc">*</span><span class="fu">solve</span>(Sigma[k,,]) <span class="sc">+</span> <span class="fu">solve</span>(DD))</span>
<span id="cb29-621"><a href="#cb29-621" aria-hidden="true" tabindex="-1"></a>    dd.st <span class="ot">=</span> DD.st<span class="sc">%*%</span>(<span class="fu">solve</span>(Sigma[k,,])<span class="sc">%*%</span>xsumk <span class="sc">+</span> <span class="fu">solve</span>(DD)<span class="sc">%*%</span>dd)</span>
<span id="cb29-622"><a href="#cb29-622" aria-hidden="true" tabindex="-1"></a>    mu[k,] <span class="ot">=</span> <span class="fu">as.vector</span>(<span class="fu">rmvnorm</span>(<span class="dv">1</span>,dd.st,DD.st))</span>
<span id="cb29-623"><a href="#cb29-623" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-624"><a href="#cb29-624" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-625"><a href="#cb29-625" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the variances</span></span>
<span id="cb29-626"><a href="#cb29-626" aria-hidden="true" tabindex="-1"></a>  xcensumk <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(KK,p,p))</span>
<span id="cb29-627"><a href="#cb29-627" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb29-628"><a href="#cb29-628" aria-hidden="true" tabindex="-1"></a>    xcensumk[cc[i],,] <span class="ot">=</span> xcensumk[cc[i],,] <span class="sc">+</span> (x[i,] <span class="sc">-</span> mu[cc[i],])<span class="sc">%*%</span><span class="fu">t</span>(x[i,] <span class="sc">-</span> mu[cc[i],])</span>
<span id="cb29-629"><a href="#cb29-629" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-630"><a href="#cb29-630" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-631"><a href="#cb29-631" aria-hidden="true" tabindex="-1"></a>    Sigma[k,,] <span class="ot">=</span> <span class="fu">riwish</span>(nu <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span>k), SS <span class="sc">+</span> xcensumk[k,,])</span>
<span id="cb29-632"><a href="#cb29-632" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-633"><a href="#cb29-633" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-634"><a href="#cb29-634" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store samples</span></span>
<span id="cb29-635"><a href="#cb29-635" aria-hidden="true" tabindex="-1"></a>  cc.out[s,]      <span class="ot">=</span> cc</span>
<span id="cb29-636"><a href="#cb29-636" aria-hidden="true" tabindex="-1"></a>  w.out[s,]       <span class="ot">=</span> w</span>
<span id="cb29-637"><a href="#cb29-637" aria-hidden="true" tabindex="-1"></a>  mu.out[s,,]     <span class="ot">=</span> mu</span>
<span id="cb29-638"><a href="#cb29-638" aria-hidden="true" tabindex="-1"></a>  Sigma.out[s,,,] <span class="ot">=</span> Sigma</span>
<span id="cb29-639"><a href="#cb29-639" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb29-640"><a href="#cb29-640" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(w[cc[i]]) <span class="sc">+</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(x[i,], mu[cc[i],], Sigma[cc[i],,], <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb29-641"><a href="#cb29-641" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-642"><a href="#cb29-642" aria-hidden="true" tabindex="-1"></a>  logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">ddirichlet</span>(w, aa)</span>
<span id="cb29-643"><a href="#cb29-643" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-644"><a href="#cb29-644" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(mu[k,], dd, DD, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb29-645"><a href="#cb29-645" aria-hidden="true" tabindex="-1"></a>    logpost[s] <span class="ot">=</span> logpost[s] <span class="sc">+</span> <span class="fu">log</span>(<span class="fu">diwish</span>(Sigma[k,,], nu, SS))</span>
<span id="cb29-646"><a href="#cb29-646" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-647"><a href="#cb29-647" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-648"><a href="#cb29-648" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(s<span class="sc">/</span><span class="dv">250</span><span class="sc">==</span><span class="fu">floor</span>(s<span class="sc">/</span><span class="dv">250</span>)){</span>
<span id="cb29-649"><a href="#cb29-649" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"s = "</span>, s))</span>
<span id="cb29-650"><a href="#cb29-650" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb29-651"><a href="#cb29-651" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-652"><a href="#cb29-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-653"><a href="#cb29-653" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the logposterior distribution for various samples</span></span>
<span id="cb29-654"><a href="#cb29-654" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb29-655"><a href="#cb29-655" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb29-656"><a href="#cb29-656" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(logpost, <span class="at">type=</span><span class="st">"l"</span>, <span class="at">xlab=</span><span class="st">"Iterations"</span>, <span class="at">ylab=</span><span class="st">"Log posterior"</span>)</span>
<span id="cb29-657"><a href="#cb29-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-658"><a href="#cb29-658" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the density estimate for the last iteration of the MCMC</span></span>
<span id="cb29-659"><a href="#cb29-659" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb29-660"><a href="#cb29-660" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>)<span class="sc">+</span><span class="fl">0.1</span>)</span>
<span id="cb29-661"><a href="#cb29-661" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x[,<span class="dv">1</span>], x[,<span class="dv">2</span>], <span class="at">col=</span>cc.true, <span class="at">main=</span><span class="fu">paste</span>(<span class="st">"s ="</span>,s,<span class="st">"   logpost ="</span>, <span class="fu">round</span>(logpost[s],<span class="dv">4</span>)), <span class="at">xlab=</span><span class="fu">expression</span>(x[<span class="dv">1</span>]), <span class="at">ylab=</span><span class="fu">expression</span>(x[<span class="dv">2</span>]))</span>
<span id="cb29-662"><a href="#cb29-662" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>KK){</span>
<span id="cb29-663"><a href="#cb29-663" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.50</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-664"><a href="#cb29-664" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.82</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-665"><a href="#cb29-665" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">ellipse</span>(<span class="at">x=</span>Sigma[k,,], <span class="at">centre=</span>mu[k,], <span class="at">level=</span><span class="fl">0.95</span>), <span class="at">col=</span><span class="st">"grey"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb29-666"><a href="#cb29-666" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-667"><a href="#cb29-667" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-668"><a href="#cb29-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-669"><a href="#cb29-669" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice Graded Assignment: The MCMC algorithm for zero-inflated mixtures</span></span>
<span id="cb29-670"><a href="#cb29-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-673"><a href="#cb29-673" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-674"><a href="#cb29-674" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: mcmc_zero_inflated</span></span>
<span id="cb29-675"><a href="#cb29-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-676"><a href="#cb29-676" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span>
<span id="cb29-677"><a href="#cb29-677" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb29-678"><a href="#cb29-678" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">81196</span>)  <span class="co"># So that results are reproducible</span></span>
<span id="cb29-679"><a href="#cb29-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-680"><a href="#cb29-680" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loading</span></span>
<span id="cb29-681"><a href="#cb29-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-682"><a href="#cb29-682" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"./data/nestsize.csv"</span>)[[<span class="dv">1</span>]]</span>
<span id="cb29-683"><a href="#cb29-683" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb29-684"><a href="#cb29-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-685"><a href="#cb29-685" aria-hidden="true" tabindex="-1"></a><span class="co"># The actual MCMC algorithm starts here</span></span>
<span id="cb29-686"><a href="#cb29-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-687"><a href="#cb29-687" aria-hidden="true" tabindex="-1"></a><span class="do">## MCMC iterations of the sampler</span></span>
<span id="cb29-688"><a href="#cb29-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-689"><a href="#cb29-689" aria-hidden="true" tabindex="-1"></a>iterations <span class="ot">&lt;-</span> <span class="dv">6000</span></span>
<span id="cb29-690"><a href="#cb29-690" aria-hidden="true" tabindex="-1"></a>burn <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb29-691"><a href="#cb29-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-692"><a href="#cb29-692" aria-hidden="true" tabindex="-1"></a><span class="do">## Initialize the parameters</span></span>
<span id="cb29-693"><a href="#cb29-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-694"><a href="#cb29-694" aria-hidden="true" tabindex="-1"></a>cc         <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">2</span>, n)</span>
<span id="cb29-695"><a href="#cb29-695" aria-hidden="true" tabindex="-1"></a>cc[x <span class="sc">==</span> <span class="dv">0</span>] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="fu">sum</span>(x <span class="sc">==</span> <span class="dv">0</span>), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb29-696"><a href="#cb29-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-697"><a href="#cb29-697" aria-hidden="true" tabindex="-1"></a><span class="do">## Priors</span></span>
<span id="cb29-698"><a href="#cb29-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-699"><a href="#cb29-699" aria-hidden="true" tabindex="-1"></a>aa <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)  <span class="co"># Uniform prior on w</span></span>
<span id="cb29-700"><a href="#cb29-700" aria-hidden="true" tabindex="-1"></a>w     <span class="ot">=</span> <span class="fl">0.2</span> <span class="co"># fewer zeros</span></span>
<span id="cb29-701"><a href="#cb29-701" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">=</span> <span class="fu">mean</span>(x[x <span class="sc">&gt;</span> <span class="dv">0</span>])  <span class="co"># Initial lambda from nonzero data</span></span>
<span id="cb29-702"><a href="#cb29-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-703"><a href="#cb29-703" aria-hidden="true" tabindex="-1"></a><span class="co"># Storing the samples</span></span>
<span id="cb29-704"><a href="#cb29-704" aria-hidden="true" tabindex="-1"></a>w.out      <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, iterations)</span>
<span id="cb29-705"><a href="#cb29-705" aria-hidden="true" tabindex="-1"></a>cc.out     <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(iterations, n))</span>
<span id="cb29-706"><a href="#cb29-706" aria-hidden="true" tabindex="-1"></a>lambda.out <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span><span class="fu">c</span>(iterations, n))</span>
<span id="cb29-707"><a href="#cb29-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-708"><a href="#cb29-708" aria-hidden="true" tabindex="-1"></a><span class="co"># logpost    = rep(0, iterations)</span></span>
<span id="cb29-709"><a href="#cb29-709" aria-hidden="true" tabindex="-1"></a><span class="co"># MCMC iterations</span></span>
<span id="cb29-710"><a href="#cb29-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-711"><a href="#cb29-711" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>iterations) {</span>
<span id="cb29-712"><a href="#cb29-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-713"><a href="#cb29-713" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample latent indicators c_i</span></span>
<span id="cb29-714"><a href="#cb29-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-715"><a href="#cb29-715" aria-hidden="true" tabindex="-1"></a>  cc <span class="ot">=</span> <span class="fu">numeric</span>(n)</span>
<span id="cb29-716"><a href="#cb29-716" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb29-717"><a href="#cb29-717" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (x[i] <span class="sc">==</span> <span class="dv">0</span>) {</span>
<span id="cb29-718"><a href="#cb29-718" aria-hidden="true" tabindex="-1"></a>      logp1 <span class="ot">=</span> <span class="fu">log</span>(w)</span>
<span id="cb29-719"><a href="#cb29-719" aria-hidden="true" tabindex="-1"></a>      logp2 <span class="ot">=</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> w) <span class="sc">+</span> <span class="fu">dpois</span>(<span class="dv">0</span>, lambda, <span class="at">log=</span><span class="cn">TRUE</span>)</span>
<span id="cb29-720"><a href="#cb29-720" aria-hidden="true" tabindex="-1"></a>      probs <span class="ot">=</span> <span class="fu">exp</span>(<span class="fu">c</span>(logp1, logp2) <span class="sc">-</span> <span class="fu">max</span>(logp1, logp2))</span>
<span id="cb29-721"><a href="#cb29-721" aria-hidden="true" tabindex="-1"></a>      probs <span class="ot">=</span> probs <span class="sc">/</span> <span class="fu">sum</span>(probs)</span>
<span id="cb29-722"><a href="#cb29-722" aria-hidden="true" tabindex="-1"></a>      cc[i] <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="at">prob =</span> probs)</span>
<span id="cb29-723"><a href="#cb29-723" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb29-724"><a href="#cb29-724" aria-hidden="true" tabindex="-1"></a>      cc[i] <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb29-725"><a href="#cb29-725" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb29-726"><a href="#cb29-726" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb29-727"><a href="#cb29-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-728"><a href="#cb29-728" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample the weights</span></span>
<span id="cb29-729"><a href="#cb29-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-730"><a href="#cb29-730" aria-hidden="true" tabindex="-1"></a>  w <span class="ot">=</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, aa[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">1</span>), aa[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">sum</span>(cc<span class="sc">==</span><span class="dv">2</span>))</span>
<span id="cb29-731"><a href="#cb29-731" aria-hidden="true" tabindex="-1"></a>  lambda <span class="ot">=</span> <span class="fu">rgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">sum</span>(x[cc <span class="sc">==</span> <span class="dv">2</span>]), <span class="at">rate =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">sum</span>(cc <span class="sc">==</span> <span class="dv">2</span>))</span>
<span id="cb29-732"><a href="#cb29-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-733"><a href="#cb29-733" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store samples</span></span>
<span id="cb29-734"><a href="#cb29-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-735"><a href="#cb29-735" aria-hidden="true" tabindex="-1"></a>  w.out[s] <span class="ot">=</span>  w</span>
<span id="cb29-736"><a href="#cb29-736" aria-hidden="true" tabindex="-1"></a>  lambda.out[s]  <span class="ot">=</span> lambda</span>
<span id="cb29-737"><a href="#cb29-737" aria-hidden="true" tabindex="-1"></a>  cc.out[s,] <span class="ot">=</span> cc</span>
<span id="cb29-738"><a href="#cb29-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-739"><a href="#cb29-739" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-740"><a href="#cb29-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-741"><a href="#cb29-741" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior summaries</span></span>
<span id="cb29-742"><a href="#cb29-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-743"><a href="#cb29-743" aria-hidden="true" tabindex="-1"></a>w.post <span class="ot">=</span> w.out[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span>burn)]</span>
<span id="cb29-744"><a href="#cb29-744" aria-hidden="true" tabindex="-1"></a>lambda.post <span class="ot">=</span> lambda.out[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span>burn)]</span>
<span id="cb29-745"><a href="#cb29-745" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Posterior mean of w:"</span>, <span class="fu">mean</span>(w.post), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-746"><a href="#cb29-746" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Posterior mean of lambda:"</span>, <span class="fu">mean</span>(lambda.post), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-747"><a href="#cb29-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-748"><a href="#cb29-748" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-749"><a href="#cb29-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-750"><a href="#cb29-750" aria-hidden="true" tabindex="-1"></a><span class="fu">## Honors Peer-graded Assignment: Markov chain Monte Carlo algorithms for Mixture Models</span></span>
<span id="cb29-751"><a href="#cb29-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-754"><a href="#cb29-754" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-755"><a href="#cb29-755" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"bottom","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>