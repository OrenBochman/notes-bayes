<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="keywords" content="Distributions, Bernoulli Distribution, Binomial Distribution">
<meta name="description" content="Outline of distributions">

<title>7&nbsp; M1L3 - Distributions – Bayesian Specialization Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C1-L03-Ex1.html" rel="next">
<link href="./C1-L02-Ex2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-923206e44a13b4518db4dede9f4ebdc9.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-987387ce273b62b48f1747d606bce1d5.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./C1-L03.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">M1L3 - Distributions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Specialization Notes</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Bayesian Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Paradigms of probability - M1L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayes’ Theorem - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">M1L2HW1 - Conditional Probability and Bayes’ Law</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">M1L2HW2 - Probability and Bayes’ Theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">M1L3 - Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Random Variables - M1L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework on Distributions - M1L3HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">M2L4 - Frequentist Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Frequentist MLE - M2L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bayesian Inference - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Homework on Likelihoods and MLEs - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Homework on Bayesian Inference - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Priors - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Homework Posterior Probabilities - M3L6HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">M3L7 - Binomial Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Homework on Priors - M2L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Poisson Data - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Homework on Poisson Data - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Beta Bernoulli - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">M4L9 - Exponential Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Homework on Exponential Data - M4L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Normally distributed Data - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Homework on Normal Data - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Non-Informative Priors - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Homework Alternative Priors - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Brief Review of Regression - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">M1L1 - Statistical Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">M1L2 - Bayesian Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">M1L3 - Monte Carlo estimation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">M2L4 - Metropolis-Hastings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Homework on the Metropolis-Hastings algorithm</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Gibbs sampling - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Homework Gibbs-Sampling algorithm - M2L22HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Assessing Convergence - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Homework on the Gibbs-Sampling algorithm - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Homework on M-H algorithm M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Linear regression - M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Homework on Linear Regression Model Part 1 - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Homework on Deviance information criterion - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">ANOVA - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Homework on ANOVA - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Homework on Multiple Factor ANOVA - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">M3L9 - Logistic regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Homework on Logistic Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">M4L10 - Poisson regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Homework on Poisson regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Hierarchical modeling - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Homework on Hierarchical Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Homework on Non-Normal Hierarchical Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">M4L12 - Capstone Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Homework Predictive distributions and mixture models - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">M1L1 - Definitions of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex1-Basic-Definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Basic Concepts of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex2-Gaussian-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Mixtures of Gaussians</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex3-Zero-Inflated-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Zero inflated distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex4-Def-mixture-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Definition of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Likelihood functions for Mixture Models - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Homework The Likelihood function - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Homework Identifiability - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Homework The likelihood function M1L2HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">HW - Simulating from a Mixture Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">HW - Simulation of Poisson mixture model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">HW+ - Sim mixture of exponential distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">M2L3 - The EM algorithm for Mixture models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">The EM algorithm for Zero-Inflated Mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">M4L1 - MCMC for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">The MCMC algorithm for Zero-Inflated Mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Markov chain Monte Carlo algorithms for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">M4L5 - Density Estimation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">M4L6 - Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">M4L7 -Classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the EM algorithm</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the MCMC algorithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Bayesian Mixture Models for Classification of Banknotes</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Computational Considerations - M5L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Computational considerations for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Determining the number of components - M5L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">M5HW2 - Bayesian Information Criteria (BIC)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">M5HW2 - Estimating the number of components in Bayesian settings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">M5HW3 - Estimating the partition structure in Bayesian models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">M5HW4 - BIC for zero-inflated mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Week 0: Introductions to time series analysis and the AR(1) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Introductions to Time Series analysis &amp; the AR(1) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">The AR(p) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">Normal Dynamic Linear Models, Part 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">Normal Dynamic Linear Models, Part 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Final Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Week 0: Feynman Notebook on Bayesian Time Series Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">Appendix: Notation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">Appendix: Discrete Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">96</span>&nbsp; <span class="chapter-title">Appendix: Continuous Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">97</span>&nbsp; <span class="chapter-title">Appendix: Exponents &amp; Logarithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">98</span>&nbsp; <span class="chapter-title">Appendix: The Law of Large Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">99</span>&nbsp; <span class="chapter-title">Appendix: The Central Limit Theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">100</span>&nbsp; <span class="chapter-title">Appendix: Conjugate Priors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">101</span>&nbsp; <span class="chapter-title">Appendix: Link Function</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">102</span>&nbsp; <span class="chapter-title">Bayes by backprop</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">103</span>&nbsp; <span class="chapter-title">Bayesian Books in R &amp; Python</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">About</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">105</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-distributions" id="toc-sec-distributions" class="nav-link active" data-scroll-target="#sec-distributions"><span class="header-section-number">7.1</span> Distributions</a></li>
  <li><a href="#sec-the-bernoulli--binomial-distribution" id="toc-sec-the-bernoulli--binomial-distribution" class="nav-link" data-scroll-target="#sec-the-bernoulli--binomial-distribution"><span class="header-section-number">7.2</span> The Bernoulli &amp; Binomial Distribution</a>
  <ul class="collapse">
  <li><a href="#sec-the-bernoulli-distribution" id="toc-sec-the-bernoulli-distribution" class="nav-link" data-scroll-target="#sec-the-bernoulli-distribution"><span class="header-section-number">7.2.1</span> The Bernoulli Distribution</a></li>
  <li><a href="#the-binomial-distribution" id="toc-the-binomial-distribution" class="nav-link" data-scroll-target="#the-binomial-distribution"><span class="header-section-number">7.2.2</span> The Binomial Distribution</a></li>
  <li><a href="#the-discrete-uniform-distribution" id="toc-the-discrete-uniform-distribution" class="nav-link" data-scroll-target="#the-discrete-uniform-distribution"><span class="header-section-number">7.2.3</span> The Discrete Uniform Distribution</a></li>
  <li><a href="#the-continuous-uniform-distribution" id="toc-the-continuous-uniform-distribution" class="nav-link" data-scroll-target="#the-continuous-uniform-distribution"><span class="header-section-number">7.2.4</span> The Continuous Uniform Distribution</a></li>
  </ul></li>
  <li><a href="#sec-the-normal-z-t-distributions" id="toc-sec-the-normal-z-t-distributions" class="nav-link" data-scroll-target="#sec-the-normal-z-t-distributions"><span class="header-section-number">7.3</span> The Normal, Z, t Distributions</a>
  <ul class="collapse">
  <li><a href="#sec-the-standard-normal-distribution" id="toc-sec-the-standard-normal-distribution" class="nav-link" data-scroll-target="#sec-the-standard-normal-distribution"><span class="header-section-number">7.3.1</span> The Standard Normal distribution</a></li>
  <li><a href="#the-normal-distribution" id="toc-the-normal-distribution" class="nav-link" data-scroll-target="#the-normal-distribution"><span class="header-section-number">7.3.2</span> The Normal distribution</a></li>
  <li><a href="#the-t-distribution" id="toc-the-t-distribution" class="nav-link" data-scroll-target="#the-t-distribution"><span class="header-section-number">7.3.3</span> The t-Distribution</a></li>
  </ul></li>
  <li><a href="#the-exponential-distribution" id="toc-the-exponential-distribution" class="nav-link" data-scroll-target="#the-exponential-distribution"><span class="header-section-number">7.4</span> The Exponential Distribution</a></li>
  <li><a href="#additional-discrete-distributions" id="toc-additional-discrete-distributions" class="nav-link" data-scroll-target="#additional-discrete-distributions"><span class="header-section-number">8</span> Additional Discrete Distributions</a>
  <ul class="collapse">
  <li><a href="#sec-the-geometric-distribution" id="toc-sec-the-geometric-distribution" class="nav-link" data-scroll-target="#sec-the-geometric-distribution"><span class="header-section-number">8.1</span> The Geometric Distribution</a></li>
  <li><a href="#sec-the-multinomial-distribution" id="toc-sec-the-multinomial-distribution" class="nav-link" data-scroll-target="#sec-the-multinomial-distribution"><span class="header-section-number">8.2</span> The Multinomial Distribution</a></li>
  <li><a href="#sec-the-poisson-distribution" id="toc-sec-the-poisson-distribution" class="nav-link" data-scroll-target="#sec-the-poisson-distribution"><span class="header-section-number">8.3</span> The Poisson Distribution</a>
  <ul class="collapse">
  <li><a href="#relations" id="toc-relations" class="nav-link" data-scroll-target="#relations"><span class="header-section-number">8.3.1</span> Relations</a></li>
  </ul></li>
  <li><a href="#hypergeometric-distribution" id="toc-hypergeometric-distribution" class="nav-link" data-scroll-target="#hypergeometric-distribution"><span class="header-section-number">8.4</span> Hypergeometric Distribution</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">M1L3 - Distributions</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Bayesian Statistics: From Concept to Data Analysis</p>
  <div class="quarto-categories">
    <div class="quarto-category">Bayesian Statistics</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Oren Bochman </p>
          </div>
  </div>
    
  
    
  </div>
  

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>Distributions, Bernoulli Distribution, Binomial Distribution</p>
  </div>
</div>

</header>


<section id="sec-distributions" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="sec-distributions"><span class="header-section-number">7.1</span> Distributions</h2>
</section>
<section id="sec-the-bernoulli--binomial-distribution" class="level2 page-columns page-full" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="sec-the-bernoulli--binomial-distribution"><span class="header-section-number">7.2</span> The Bernoulli &amp; Binomial Distribution</h2>

<div class="no-row-height column-margin column-container"><div id="fig-slide-l03-s01" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-slide-l03-s01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c1l03-ss-01-bernoulli-and-binomial-distributions.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;7.1: Bernoulli and Binomial Distributions"><img src="images/c1l03-ss-01-bernoulli-and-binomial-distributions.png" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-slide-l03-s01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: Bernoulli and Binomial Distributions
</figcaption>
</figure>
</div></div><p>These two distributions are built on a trial of a coin toss (possibly biased).</p>
<ul>
<li>We use the Bernoulli distribution to model a random variable for the probability of such a coin toss trial.</li>
<li>We use the Binomial distribution to model a random variable for the probability of getting <span class="math inline">k</span> heads in <span class="math inline">N</span> independent trials.</li>
</ul>
<section id="sec-the-bernoulli-distribution" class="level3 page-columns page-full" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="sec-the-bernoulli-distribution"><span class="header-section-number">7.2.1</span> The Bernoulli Distribution</h3>
<p>Arises when modeling events with two possible outcomes, <strong>Success</strong> and <strong>Failure</strong> for a coin toss these can be <strong>Heads</strong> and <strong>Tails</strong></p>
<p><span id="eq-l3-bernoulli-rv"><span class="math display">
X \sim \text{Bernoulli}(p) =
\begin{cases}
   \mathbb{P}r(X=1) = p &amp; \text{success} \\
   \mathbb{P}r(X=0)=1-p &amp; \text{failure}
\end{cases}
\tag{7.1}</span></span></p>
<p>Where parameter p is the probability of getting heads.</p>
<p>The probability for the two events is:</p>
<p>Notation:</p>
<ul>
<li>we use (Roman) p if its value is known.<br>
</li>
<li>we use (Greek) <span class="math inline">\theta</span> when its value is unknown.</li>
</ul>
<p>This is a probability mass function since it is discrete. But we call it a Probability Density Function (PDF) in the measure-theoretic sense.</p>
<p><span id="eq-l3-bernoulli-pmf"><span class="math display">
f(X=x\mid p) = p^x(1-p)^x \mathbb{I}_{[0,1]}(x)
\tag{7.2}</span></span></p>
<p><span id="eq-l3-bernoulli-expectation"><span class="math display">
\mathbb{E}(x)= p
\tag{7.3}</span></span></p>
<p><span id="eq-l3-bernoulli-variance"><span class="math display">
\text{Var}(x)= \mathbb{P}r(1-p)
\tag{7.4}</span></span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> bernoulli</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> bernoulli.stats(p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=0.30, var=0.21, skew=0.87, kurt=-1.24</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(bernoulli.ppf(<span class="fl">0.01</span>, p),</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>              bernoulli.ppf(<span class="fl">0.99</span>, p))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>ax.plot(x, bernoulli.pmf(x, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'bernoulli pmf'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, bernoulli.pmf(x, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> bernoulli(p)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="C1-L03_files/figure-html/bernoulli-distribution-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Bernoulli distribution"><img src="C1-L03_files/figure-html/bernoulli-distribution-1.png" class="img-fluid figure-img" width="672" alt="Bernoulli distribution"></a></p>
<figcaption>Bernoulli distribution</figcaption>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Generate random numbers</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> bernoulli.rvs(p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0])</code></pre>
</div>
</div>

<div class="no-row-height column-margin column-container"><div id="fig-bio-bernoulli" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bio-bernoulli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/bio-bernoulli.jpg" class="lightbox" data-gallery="slides" title="Figure&nbsp;7.2: Jacob Bernoulli"><img src="images/bio-bernoulli.jpg" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bio-bernoulli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: Jacob Bernoulli
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Biographical note on Jacob Bernoulli
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>It seems that to make a correct conjecture about any event whatever, it is necessary to calculate exactly the number of possible cases and then to determine how much more likely it is that one case will occur than another. <span class="citation" data-cites="bernoulli1713ars">(<a href="#ref-bernoulli1713ars" role="doc-biblioref">Bernoulli 1713</a>)</span></p>
</blockquote>
<p>The Bernoulli distribution as well as The Binomial distribution are due to Jacob Bernoulli (1655-1705) who was a prominent mathematicians in the Bernoulli family. He discovered the fundamental mathematical constant e. However, his most important contribution was in the field of probability, where he derived the first version of the law of large numbers.</p>
<p>for a fuller <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Bernoulli_Jacob/">biography see</a></p>
</div>
</div>
</section>
<section id="the-binomial-distribution" class="level3 page-columns page-full" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="the-binomial-distribution"><span class="header-section-number">7.2.2</span> The Binomial Distribution</h3>
<p><span id="eq-l3-bernoulli-experiment"><span class="math display">
\overbrace{\underbrace{\fbox{0}\ \ldots \fbox{0}}_{N_0}\ \underbrace{\fbox{1}\ \ldots \fbox{1}}_{N_1}}^N
\tag{7.5}</span></span></p>
<p>The Binomial distribution models <code>counts</code> of successes in independent Bernoulli trials . It arises when we need to consider the summing N independent and identically distributed Bernoulli RV with the same probability of success <span class="math inline">\theta</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Conditions
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Discrete data</li>
<li>Two possible outcomes for each trial</li>
<li>Each trial is independent</li>
<li>The probability of success/failure is the same in each trial</li>
</ul>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="C1-L03_files/figure-html/Binomial-reparams-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Binomial reparams mindmap"><img src="C1-L03_files/figure-html/Binomial-reparams-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" alt="Binomial reparams mindmap"></a></p>
</figure>
</div>
<figcaption>Binomial reparams mindmap</figcaption>
</figure>
</div>
</div>
</div>
<p><span id="eq-l3-binomial-rv"><span class="math display">
X \sim Bin[n,p]
\tag{7.6}</span></span></p>
<p>the probability function</p>
<p><span id="eq-l3-binomial-pmf"><span class="math display">
f(X=x \mid \theta) = {n \choose x} \theta^x(1-\theta)^{n-x}
\tag{7.7}</span></span></p>
<p><span id="eq-l3-binomial-likelihood"><span class="math display">
\mathcal{L}(\theta)=\prod_{i=1}^{n} {n\choose x_i}  \theta ^ {x_i} (1− \theta) ^ {(n−x_i)}
\tag{7.8}</span></span></p>
<p><span id="eq-l3-binomial-log-likelihood"><span class="math display">
\begin{aligned}
\ell( \theta) &amp;= \log \mathcal{L}( \theta) \\
              &amp;= \sum_{i=1}^n \left[\log {n\choose x_i} + x_i \log  \theta + (n-x_i)\log (1- \theta) \right]
\end{aligned}
\tag{7.9}</span></span></p>
<p><span id="eq-l3-binomial-expectation"><span class="math display">
\mathbb{E}[X]= N \times  \theta
\tag{7.10}</span></span></p>
<p><span id="eq-l3-binomial-variance"><span class="math display">
\mathbb{V}ar[X]=N \cdot \theta \cdot (1-\theta)
\tag{7.11}</span></span></p>
<p><span id="eq-l3-binomial-entropy"><span class="math display">
\mathbb{H}(X) = \frac{1}{2}\log_2 \left (2\pi n \theta(1 - \theta)\right) + O(\frac{1}{n})
\tag{7.12}</span></span></p>
<p><span id="eq-l3-binomial-information"><span class="math display">
\mathcal{I}(\theta)=\frac{n}{ \theta \cdot (1- \theta)}
\tag{7.13}</span></span></p>
<section id="relationships" class="level4 page-columns page-full" data-number="7.2.2.1">
<h4 data-number="7.2.2.1" class="anchored" data-anchor-id="relationships"><span class="header-section-number">7.2.2.1</span> Relationships</h4>

<div class="no-row-height column-margin column-container"><div id="fig-dbinomial" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dbinomial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/dbinomial.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;7.3: binomial distribution relations"><img src="images/dbinomial.png" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dbinomial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: binomial distribution relations
</figcaption>
</figure>
</div></div><p>The Binomial Distribution is related to:</p>
<ul>
<li>the <strong>Geometric distribution</strong>,</li>
<li>The <strong>Multinomial distribution</strong> with two categories is the binomial.</li>
<li>the <strong>Poisson distribution</strong> distribution. If <span class="math inline">X \sim \mathrm{Binomial}(n, p)</span> rv and <span class="math inline">Y \sim \mathrm{Poisson}(np)</span> distribution then <span class="math inline">\mathbb{P}r(X = n) \approx \mathbb{P}r(Y = n)</span> for large <span class="math inline">n</span> and small <span class="math inline">np</span>.</li>
<li>the <strong>Bernoulli distribution</strong> If <span class="math inline">X \sim \mathrm{Binomial}(n, p)</span> RV with <span class="math inline">n = 1</span>, <span class="math inline">X \sim Bernoulli(p)</span> RV.</li>
<li>the <strong>Normal distribution</strong> If <span class="math inline">X \sim \mathrm{Binomial}(n, p)</span> RV and <span class="math inline">Y \sim Normal(\mu=np,\sigma=n\mathbb{P}r(1-p))</span> then for integers j and k, <span class="math inline">\mathbb{P}r(j \le X \le k) \approx \mathbb{P}r(j – {1 \over 2} \le Y \le k + {1 \over 2})</span>. The approximation is better when <span class="math inline">p ≈ 0.5</span> and when n is large. For more information, see normal approximation to binomial</li>
<li><strong>Hypergeometric</strong>: The difference between a binomial distribution and a hypergeometric distribution is the difference between sampling with replacement and sampling without replacement. As the population size increases relative to the sample size, the difference becomes negligible. So If <span class="math inline">X \sim Binomial(n, p)</span> RV and <span class="math inline">Y \sim HyperGeometric(N,a,b)</span> then</li>
</ul>
<p><span class="math display">
\lim_{n\to \infty} X = Y
</span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> binom</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> binom.stats(n, p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=2.00, var=1.20, skew=0.18, kurt=-0.37</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(binom.ppf(<span class="fl">0.01</span>, n, p), binom.ppf(<span class="fl">0.99</span>, n, p))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>ax.plot(x, binom.pmf(x, n, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'binom pmf'</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, binom.pmf(x, n, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> binom(n, p)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C1-L03_files/figure-html/binomial-distribution-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="C1-L03_files/figure-html/binomial-distribution-3.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">## generate random numbers</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> binom.rvs(n, p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>array([3, 2, 3, 2, 2, 2, 2, 1, 1, 3])</code></pre>
</div>
</div>

<div class="no-row-height column-margin column-container"><div id="vid-bernoulli-distribution" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-vid figure">
<div aria-describedby="vid-bernoulli-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p></p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sn-mp_ESSMc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div> The Bernoulli Distribution<p></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-vid quarto-uncaptioned" id="vid-bernoulli-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Video&nbsp;7.1
</figcaption>
</figure>
</div></div></section>
</section>
<section id="the-discrete-uniform-distribution" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="the-discrete-uniform-distribution"><span class="header-section-number">7.2.3</span> The Discrete Uniform Distribution</h3>
<p><span id="eq-l3-discrete-uniform-rv"><span class="math display">
X \sim U[0,1]
\tag{7.14}</span></span></p>
<p><span id="eq-l3-uniform-pmf"><span class="math display">
    f(x)=
    \begin{cases}
      1, &amp; \text{if}\ x \in [0,1] \\
      0, &amp; \text{otherwise}
    \end{cases}
    = \mathbb{I}_{\{0 \le x \le 1\}}(x)
\tag{7.15}</span></span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> uniform</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> uniform.stats(moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=0.50, var=0.08, skew=0.00, kurt=-1.20</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># we use ppf to get the domain from a range of (0.01,0.99)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(uniform.ppf(<span class="fl">0.01</span>), uniform.ppf(<span class="fl">0.99</span>), <span class="dv">100</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>ax.plot(x, uniform.pdf(x), <span class="st">'r-'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'uniform pdf'</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> uniform()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>ax.plot(x, rv.pdf(x), <span class="st">'k-'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'frozen pdf'</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">## generate random numbers</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> uniform.rvs(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># And compare the histogram:</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>ax.hist(r, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="st">'auto'</span>, histtype<span class="op">=</span><span class="st">'stepfilled'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(array([0.97089651, 1.02606108, 1.10329149, 0.95986359, 0.91573193,
       0.91573193, 1.13639023, 1.07019274, 0.98192942, 1.04812691,
       0.90469902]), array([0.00226389, 0.09290177, 0.18353965, 0.27417753, 0.3648154 ,
       0.45545328, 0.54609116, 0.63672904, 0.72736692, 0.8180048 ,
       0.90864268, 0.99928056]), [&lt;matplotlib.patches.Polygon object at 0x725e1dc1e6b0&gt;])</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([x[<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(0.01, 0.99)</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C1-L03_files/figure-html/uniform-distribution-5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="C1-L03_files/figure-html/uniform-distribution-5.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-continuous-uniform-distribution" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="the-continuous-uniform-distribution"><span class="header-section-number">7.2.4</span> The Continuous Uniform Distribution</h3>
<p><span id="eq-l3-uniform-rv"><span class="math display">
X \sim \mathrm{Uniform}[\theta_1,\theta_2]
\tag{7.16}</span></span></p>
<p><span id="eq-l3-uniform-pdf"><span class="math display">
f(x)= \frac{1}{\theta_2-\theta_1} \mathbb{I}_{\{\theta_1 \le x \le \theta_2\}}(x)
\tag{7.17}</span></span></p>
</section>
</section>
<section id="sec-the-normal-z-t-distributions" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="sec-the-normal-z-t-distributions"><span class="header-section-number">7.3</span> The Normal, Z, t Distributions</h2>
<p> The <em>normal</em>, AKA <em>Gaussian distribution</em> is one of the most important distributions in statistics.</p>
<p>It arises as the limiting distribution of sums (and averages) of random variables. This is due to the <a href="#sec-cl-theorem" class="quarto-xref"><span class="quarto-unresolved-ref">sec-cl-theorem</span></a>. Because of this property, the normal distribution is often used to model the “errors,” or unexplained variations of individual observations in regression models.</p>
<section id="sec-the-standard-normal-distribution" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="sec-the-standard-normal-distribution"><span class="header-section-number">7.3.1</span> The Standard Normal distribution</h3>
<p> The standard normal distribution is given by</p>
<p><span id="eq-l3-z-rv"><span class="math display">
\mathcal{Z} \sim \mathcal{N}[1,0]
\tag{7.18}</span></span></p>
<p><span id="eq-l3-z-pdf"><span class="math display">
f(z) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{z^2}{2}}
\tag{7.19}</span></span></p>
<p><span id="eq-l3-z-expectation"><span class="math display">
\mathbb{E}[\mathcal{Z}] = 0
\tag{7.20}</span></span></p>
<p><span id="eq-l3-z-variance"><span class="math display">
\mathbb{V}ar[\mathcal{Z}]= 1
\tag{7.21}</span></span></p>
</section>
<section id="the-normal-distribution" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="the-normal-distribution"><span class="header-section-number">7.3.2</span> The Normal distribution</h3>
<p> Now consider <span class="math inline">X = \sigma \mathcal{Z}+\mu</span> where <span class="math inline">\sigma &gt; 0</span> and <span class="math inline">\mu</span> is any real constant. Then <span class="math inline">\mathbb{E}(X) = \mathbb{E}(\sigma \mathcal{Z}+\mu) = \sigma \mathbb{E}(\mathcal{Z}) + \mu = \sigma \times 0 + \mu = \mu</span> and <span class="math inline">Var(X) = Var(\sigma^2 + \mu) = \sigma^2 Var(\mathcal{Z}) + 0 = \sigma^2 \cdot 1 = \sigma^2</span></p>
<p>Then, X follows a normal distribution with mean <span class="math inline">\mu</span> and variance <span class="math inline">\sigma^2</span> (standard deviation <span class="math inline">\sigma</span>) denoted as</p>
<p><span id="eq-l3-normal-rv"><span class="math display">
X \sim \mathcal{N}[\mu,\sigma^2]
\tag{7.22}</span></span></p>
<p><span id="eq-l3-normal-pdf"><span class="math display">
f(x\mid \mu,\sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}}  e^{-\frac{1}{\sqrt{2 \pi \sigma^2}}(x-\mu)^2}
\tag{7.23}</span></span></p>
<p><span id="eq-l3-normal-expectation"><span class="math display">
\mathbb{E}[x]= \mu
\tag{7.24}</span></span></p>
<p><span id="eq-l3-normal-variance"><span class="math display">
\mathbb{V}ar[x]= \sigma^2
\tag{7.25}</span></span></p>
<ul>
<li>The normal distribution is symmetric about the mean <span class="math inline">\mu</span> and is often described as a <code>bell-shaped</code> curve.</li>
<li>Although X can take on any real value (positive or negative), more than 99% of the probability mass is concentrated within three standard deviations of the mean.</li>
</ul>
<p>The normal distribution has several desirable properties.</p>
<p>One is that if <span class="math inline">X_1 \sim \mathcal{N}(\mu_1, \sigma^2_1)</span> and <span class="math inline">X_2 \sim \mathcal{N}(\mu_2, \sigma^2_2)</span> are independent, then <span class="math inline">X_1+X_2 \sim \mathcal{N}(\mu_1+\mu_2, \sigma^2_1+\sigma^2_2)</span>.</p>
<p>Consequently, if we take the average of n Independent and Identically Distributed (IID) normal random variables we have</p>
<p><span id="eq-l3-normal-sum"><span class="math display">
\bar X = \frac{1}{n}\sum_{i=1}^n X_i \sim \mathcal{N}(\mu, \frac{\sigma^2}{n})
\tag{7.26}</span></span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> norm.stats(moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=0.00, var=1.00, skew=0.00, kurt=0.00</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(norm.ppf(<span class="fl">0.01</span>),</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>                norm.ppf(<span class="fl">0.99</span>), <span class="dv">100</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>ax.plot(x, norm.pdf(x),</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>       <span class="st">'r-'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'norm pdf'</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> norm()</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>ax.plot(x, rv.pdf(x), <span class="st">'k-'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'frozen pdf'</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> norm.rvs(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>ax.hist(r, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="st">'auto'</span>, histtype<span class="op">=</span><span class="st">'stepfilled'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(array([0.01110758, 0.01851263, 0.03332273, 0.05183536, 0.05183536,
       0.11848082, 0.22215154, 0.22215154, 0.3184172 , 0.39246772,
       0.40727782, 0.3184172 , 0.34803741, 0.33692983, 0.31471468,
       0.21844901, 0.1295884 , 0.07405051, 0.07034799, 0.02591768,
       0.00740505, 0.00370253, 0.00370253, 0.00370253]), array([-2.98387099, -2.71378508, -2.44369918, -2.17361327, -1.90352736,
       -1.63344145, -1.36335554, -1.09326963, -0.82318372, -0.55309781,
       -0.2830119 , -0.01292599,  0.25715992,  0.52724583,  0.79733174,
        1.06741765,  1.33750356,  1.60758946,  1.87767537,  2.14776128,
        2.41784719,  2.6879331 ,  2.95801901,  3.22810492,  3.49819083]), [&lt;matplotlib.patches.Polygon object at 0x725e1dc387f0&gt;])</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([x[<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(-2.3263478740408408, 2.3263478740408408)</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C1-L03_files/figure-html/normal-distribution-7.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="C1-L03_files/figure-html/normal-distribution-7.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-t-distribution" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="the-t-distribution"><span class="header-section-number">7.3.3</span> The t-Distribution</h3>
<p> If we have normal data, we can use (<a href="#eq-normal-sum" class="quarto-xref">Equation&nbsp;<span class="quarto-unresolved-ref">eq-normal-sum</span></a>) to help us estimate the mean <span class="math inline">\mu</span>. Reversing the transformation from the previous section, we get</p>
<p><span id="eq-l3-t-transform"><span class="math display">
\frac {\hat X - \mu}{\sigma / \sqrt(n)} \sim N(0, 1)
\tag{7.27}</span></span></p>
<p>However, we may not know the value of <span class="math inline">\sigma</span>. If we estimate it from data, we can replace it with <span class="math inline">S = \sqrt{\sum_i \frac{(X_i-\hat X)^2}{n-1}}</span>, the sample standard deviation. This causes the expression (<a href="#eq-t-transform" class="quarto-xref">Equation&nbsp;<span class="quarto-unresolved-ref">eq-t-transform</span></a>) to no longer be distributed as a Standard Normal; but as a standard <em>t-distribution</em> with <span class="math inline">ν = n − 1</span> <code>degrees of freedom</code></p>
<p><span id="eq-l3-t-rv"><span class="math display">
X \sim t[\nu]
\tag{7.28}</span></span></p>
<p><span id="eq-l3-t-pdf-gamma"><span class="math display">
f(t\mid\nu) = \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\sqrt{\nu\pi}}\left (1 + \frac{t^2}{\nu}\right)^{-(\frac{\nu+1}{2})}\mathbb{I}_{t\in\mathbb{R}} \qquad \text{(PDF)}
\tag{7.29}</span></span></p>
<p><span class="math display">
\text{where }\Gamma(w)=\int_{0}^{\infty}t^{w-1}e^{-t}\mathrm{d}t \text{ is the gamma function}
</span></p>
<p><span id="eq-l3-t-pdf-beta"><span class="math display">
f(t\mid\nu)={\frac {1}{{\sqrt {\nu }}\,\mathrm {B} ({\frac {1}{2}},{\frac {\nu }{2}})}}\left(1+{\frac {t^{2}}{\nu }}\right)^{-(\nu +1)/2}\mathbb{I}_{t\in\mathbb{R}} \qquad \text{(PDF)}
\tag{7.30}</span></span></p>
<p><span class="math display">
\text{where } B(u,v)=\int_{0}^{1}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the beta function}
</span></p>
<p><span id="eq-l3-t-expectation-xyz"><span class="math display">
\mathbb{E}[Y] = 0 \qquad \text{ if } \nu &gt; 1
\tag{7.31}</span></span></p>
<p><span id="eq-l3-t-variance"><span class="math display">
\mathbb{V}ar[Y] = \frac{\nu}{\nu - 2} \qquad \text{ if } \nu &gt; 2
\tag{7.32}</span></span></p>
<p>The t distribution is symmetric and resembles the Normal Distribution but with thicker tails. As the degrees of freedom increase, the t distribution looks more and more like the standard normal distribution.</p>
</section>
</section>
<section id="the-exponential-distribution" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="the-exponential-distribution"><span class="header-section-number">7.4</span> The Exponential Distribution</h2>
<p> The <strong>Exponential distribution</strong> models the waiting time between events for events with a rate <span class="math inline">\lambda</span>. Those events, typically, come from a <strong>Poisson</strong> process.</p>
<p>The <strong>Exponential distribution</strong> is often used to model the <code>waiting time between random events</code>. Indeed, if the waiting times between successive events are independent then they form an <span class="math inline">\exp(r(\lambda)</span> distribution. Then for any fixed time window of length t, the number of events occurring in that window will follow a <code>Poisson distribution</code> with mean <span class="math inline">t\lambda</span>.</p>
<p><span id="eq-l3-exponential-rv"><span class="math display">
X \sim Exp[\lambda]
\tag{7.33}</span></span></p>
<p><span id="eq-l3-exponential-pdf"><span class="math display">
f(x \mid \lambda) = \frac{1}{\lambda} e^{- \frac{x}{\lambda}}(x)\mathbb{I}_{\lambda\in\mathbb{R}^+ } \mathbb{I}_{x\in\mathbb{R}^+_0 } \quad \text{(PDF)}
\tag{7.34}</span></span></p>
<p><span id="eq-l3-exponential-expectation"><span class="math display">
\mathbb{E}(x)= \lambda
\tag{7.35}</span></span></p>
<p><span id="eq-l3-exponential-variance"><span class="math display">
\mathbb{V}ar[X]= \lambda^2
\tag{7.36}</span></span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> expon</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> expon.stats(moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=1.00, var=1.00, skew=2.00, kurt=6.00</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(expon.ppf(<span class="fl">0.01</span>), expon.ppf(<span class="fl">0.99</span>), <span class="dv">100</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>ax.plot(x, expon.pdf(x), <span class="st">'r-'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'expon pdf'</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> expon()</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>ax.plot(x, rv.pdf(x), <span class="st">'k-'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'frozen pdf'</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> expon.rvs(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>ax.hist(r, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="st">'auto'</span>, histtype<span class="op">=</span><span class="st">'stepfilled'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(array([0.88212488, 0.83158647, 0.55592245, 0.41349604, 0.39052403,
       0.29404163, 0.27566402, 0.20215362, 0.13323761, 0.10567121,
       0.08729361, 0.11486001, 0.0551328 , 0.05972721, 0.0367552 ,
       0.022972  , 0.0321608 , 0.0137832 , 0.0091888 , 0.0137832 ,
       0.0091888 , 0.        , 0.0045944 , 0.0045944 , 0.0137832 ,
       0.0045944 , 0.        , 0.0045944 , 0.0091888 , 0.        ,
       0.0045944 , 0.        , 0.0045944 , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.0045944 ]), array([4.79108724e-05, 2.17704169e-01, 4.35360428e-01, 6.53016686e-01,
       8.70672945e-01, 1.08832920e+00, 1.30598546e+00, 1.52364172e+00,
       1.74129798e+00, 1.95895424e+00, 2.17661050e+00, 2.39426675e+00,
       2.61192301e+00, 2.82957927e+00, 3.04723553e+00, 3.26489179e+00,
       3.48254805e+00, 3.70020430e+00, 3.91786056e+00, 4.13551682e+00,
       4.35317308e+00, 4.57082934e+00, 4.78848560e+00, 5.00614186e+00,
       5.22379811e+00, 5.44145437e+00, 5.65911063e+00, 5.87676689e+00,
       6.09442315e+00, 6.31207941e+00, 6.52973566e+00, 6.74739192e+00,
       6.96504818e+00, 7.18270444e+00, 7.40036070e+00, 7.61801696e+00,
       7.83567321e+00, 8.05332947e+00, 8.27098573e+00, 8.48864199e+00,
       8.70629825e+00, 8.92395451e+00, 9.14161077e+00, 9.35926702e+00,
       9.57692328e+00, 9.79457954e+00, 1.00122358e+01]), [&lt;matplotlib.patches.Polygon object at 0x725e1db27400&gt;])</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([x[<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(0.010050335853501442, 4.605170185988091)</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C1-L03_files/figure-html/exponential-distribution-9.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="C1-L03_files/figure-html/exponential-distribution-9.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="additional-discrete-distributions" class="level1 page-columns page-full" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Additional Discrete Distributions</h1>
<section id="sec-the-geometric-distribution" class="level2 page-columns page-full" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="sec-the-geometric-distribution"><span class="header-section-number">8.1</span> The Geometric Distribution</h2>
<p> The <strong>Geometric distribution</strong> arises when we want to know “What is the number of Bernoulli trials required to get the first success?”, i.e., the number of Bernoulli events until a success is observed, such as the probability of getting the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).</p>

<div class="no-row-height column-margin column-container"><div id="vid-geometric-distribution" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-vid figure">
<div aria-describedby="vid-geometric-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/-vvtrsS4rkA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-vid" id="vid-geometric-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Video&nbsp;8.1: The Geometric Distribution
</figcaption>
</figure>
</div></div><p><span id="eq-l3-geom-rv"><span class="math display">
X \sim \mathrm{Geo}(p)
\tag{8.1}</span></span></p>
<p><span id="eq-l3-geom-pmf"><span class="math display">
\mathbb{P}r(X = x\mid p) = \mathbb{P}r(1-p)^{x-1} \qquad \forall x \in N;\quad 0\le p \le 1
\tag{8.2}</span></span></p>
<p><span id="eq-l3-geom-expectation"><span class="math display">
\mathbb{E}[X] = \frac{1}{p}
\tag{8.3}</span></span></p>
<p><span id="eq-l3-geom-variance"><span class="math display">
\mathbb{V}ar[X]=\frac{1-p}{p^2}
\tag{8.4}</span></span></p>
<p><span id="eq-l3-geom-mgf"><span class="math display">
\mathbb{M}_X[t] = \frac{pe^t}{1-(1-p)e^t} \qquad t &lt; -log(1-p)
\tag{8.5}</span></span></p>
</section>
<section id="sec-the-multinomial-distribution" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="sec-the-multinomial-distribution"><span class="header-section-number">8.2</span> The Multinomial Distribution</h2>
<p>Another generalization of the Bernoulli distribution and the Binomial distribution is the <strong>Multinomial distribution</strong> , which sums the successes of Bernoulli trials when there are n different possible outcomes. Suppose we have n trials and there are k different possible outcomes that occur with probabilities <span class="math inline">p_1, \ldots, p_k</span>. For example, we are rolling a six-sided die that might be loaded so that the sides are not equally likely, then n is the total number of rolls, <span class="math inline">k = 6</span>, <span class="math inline">p_1</span> is the probability of rolling a one, and we denote by <span class="math inline">x_1, \ldots, x_6</span> a possible outcome for the number of times we observe rolls of each of one through six, where</p>
<p><span class="math display">
X \sim \mathrm{Multinomial}(p_1,...p_k)
</span></p>
<p><span class="math display">
P (X = x \mid p_1,\ldots,p_k) = \frac{n!}{x_1! \cdot \cdot \cdot x_k! } \prod_i p_i^{x_i}
</span></p>
</section>
<section id="sec-the-poisson-distribution" class="level2 page-columns page-full" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="sec-the-poisson-distribution"><span class="header-section-number">8.3</span> The Poisson Distribution</h2>
<p>The <strong>Poisson distribution</strong> arises when modeling <strong>count</strong> data. The parameter <span class="math inline">\lambda &gt; 0</span> is the <code>rate</code> at which we expect to observe the thing we are counting. We write this as <span class="math inline">X \sim \mathrm{Poisson}(\lambda)</span></p>
<p><span id="eq-l3-poisson-PMF"><span class="math display">
\mathbb{P}r(X = x \mid \lambda) = \frac{\lambda^x e^{−\lambda}}{x!} \qquad \forall x \in \mathbb{N}_0 \qquad \text{PDF}
\tag{8.6}</span></span></p>
<p><span id="eq-l3-poisson-expectation"><span class="math display">
\mathbb{E}[X] = \lambda \qquad \text{Expectation}
\tag{8.7}</span></span></p>
<p><span id="eq-l3-poisson-variance"><span class="math display">
\mathbb{V}ar[X] = \lambda \qquad \text{Variance}
\tag{8.8}</span></span></p>
<p><span id="eq-l3-poisson-mgf"><span class="math display">
\mathbb{M}_X(t) = \exp[\lambda(e^t-1)] \qquad \text{Moment Generating fn.}
\tag{8.9}</span></span></p>
<p><span id="eq-l3-poisson-fisher-information"><span class="math display">
\mathcal{I}_X(t) = \frac{1}{\lambda}
\tag{8.10}</span></span></p>
<section id="relations" class="level3 page-columns page-full" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="relations"><span class="header-section-number">8.3.1</span> Relations</h3>

<div class="no-row-height column-margin column-container"><div id="fig-dPoisson" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dPoisson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/dpoisson.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;8.1: Relations of the Poisson distribution"><img src="images/dpoisson.png" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dPoisson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1: Relations of the Poisson distribution
</figcaption>
</figure>
</div></div><p> A <em>Poisson process</em> is a process wherein events occur on average at rate <span class="math inline">\mathbb{E}</span>, events occur one at a time, and events occur independently of each other.</p>

<div class="no-row-height column-margin column-container"><div id="fig-bio-Poisson" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bio-Poisson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/bio-SimeonDenisPoisson.jpg" class="lightbox" data-gallery="slides" title="Figure&nbsp;8.2: Siméon Denis Poisson"><img src="images/bio-SimeonDenisPoisson.jpg" class="img-fluid figure-img" width="200"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bio-Poisson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.2: Siméon Denis Poisson
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Biographical Note on The Siméon Denis Poisson
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Poisson distribution is due to Baron Siméon Denis Poisson (1781-1840) see <span class="citation" data-cites="poisson2019english">(<a href="#ref-poisson2019english" role="doc-biblioref">Poisson 2019, 205–7</a>)</span> was a French mathematician and physicist who worked on statistics, complex analysis, partial differential equations, the calculus of variations, analytical mechanics, electricity and magnetism, thermodynamics, elasticity, and fluid mechanics.</p>
<p>for a fuller <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Poisson/">biography see</a></p>
</div>
</div>
</section>
</section>
<section id="hypergeometric-distribution" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="hypergeometric-distribution"><span class="header-section-number">8.4</span> Hypergeometric Distribution</h2>
<p></p>
<p>Consider an urn with <span class="math inline">a</span> white balls and <span class="math inline">b</span> black balls. Draw <span class="math inline">N</span> balls from this urn without replacement. The number white balls drawn, <span class="math inline">n</span> is Hypergeometrically distributed.</p>
<p><span class="math display">
X \sim \mathrm{Hypergeometric}(n \mid N,a,b)
</span></p>
<p><span id="eq-l3-Hypergeometric-pdf"><span class="math display">
\mathrm{Hypergeometric}(n\mid N,a,b) = \frac{\normalsize{\binom{a}{n} \binom{b}{N - n}}} {\normalsize{\binom{a + b}{N}}} \quad \text{(PDF)}
\tag{8.11}</span></span></p>
<p><span id="eq-l3-Hypergeometric-expectation"><span class="math display">
\mathbb{E}[X]=N\frac{a}{a+b} \qquad \text{(expectation)}
\tag{8.12}</span></span></p>
<p><span id="eq-l3-Hypergeometric-variance"><span class="math display">
\mathbb{V}ar[X]=N\,\frac{ab}{(a + b)^2}\,\frac{a+b-N}{a+b-1} \qquad \text{(variance)}
\tag{8.13}</span></span></p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bernoulli1713ars" class="csl-entry" role="listitem">
Bernoulli, J. 1713. <em>Ars Conjectandi [the Art of Conjecturing]</em>. Impensis Thurnisiorum. <a href="https://books.google.co.il/books?id=Ba5DAAAAcAAJ">https://books.google.co.il/books?id=Ba5DAAAAcAAJ</a>.
</div>
<div id="ref-poisson2019english" class="csl-entry" role="listitem">
Poisson, S. -D. 2019. <span>“English Translation of Poisson’s "Recherches Sur La Probabilité Des Jugements En Matière Criminelle Et En Matière Civile" / "Researches into the Probabilities of Judgements in Criminal and Civil Cases".”</span> <a href="https://arxiv.org/abs/1902.02782">https://arxiv.org/abs/1902.02782</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C1-L02-Ex2.html" class="pagination-link" aria-label="M1L2HW2 - Probability and Bayes' Theorem">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">M1L2HW2 - Probability and Bayes’ Theorem</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C1-L03-Ex1.html" class="pagination-link" aria-label="Random Variables - M1L3HW1">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Random Variables - M1L3HW1</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb32" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "M1L3 - Distributions"</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Bayesian Statistics: From Concept to Data Analysis"</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="an">subject:</span><span class="co"> "Bayesian Statistics"</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Outline of distributions"</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Bayesian Statistics</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co">  </span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - Distributions</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - Bernoulli Distribution</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - Binomial Distribution</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Distributions {#sec-distributions}</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a><span class="co">#import pandas as pd</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Bernoulli &amp; Binomial Distribution {#sec-the-bernoulli--binomial-distribution}</span></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="al">![Bernoulli and Binomial Distributions](images/c1l03-ss-01-bernoulli-and-binomial-distributions.png)</span>{#fig-slide-l03-s01 .column-margin width="200px" group="slides"}</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>These two distributions are built on a trial of a coin toss (possibly biased).</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We use the Bernoulli distribution to model a random variable for the probability of such a coin toss trial.</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We use the Binomial distribution to model a random variable for the probability of getting $k$ heads in $N$ independent trials.</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Bernoulli Distribution {#sec-the-bernoulli-distribution}</span></span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>Arises when modeling events with two possible outcomes, **Success** and **Failure** for a coin toss these can be **Heads** and **Tails**</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a><span class="in">```{r include=FALSE}</span></span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Necessary for using dvisvgm on macOS</span></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a><span class="co"># See https://www.andrewheiss.com/blog/2021/08/27/tikz-knitr-html-svg-fun/</span></span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="at">LIBGS =</span> <span class="st">"/usr/local/share/ghostscript/9.53.3/lib/libgs.dylib.9.53"</span>)</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>font_opts <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">dvisvgm.opts =</span> <span class="st">"--font-format=woff"</span>)</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>X \sim \text{Bernoulli}(p) = </span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>\begin{cases} </span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>   \mathbb{P}r(X=1) = p &amp; \text{success} <span class="sc">\\</span></span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>   \mathbb{P}r(X=0)=1-p &amp; \text{failure}</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-bernoulli-rv}</span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>Where parameter p is the probability of getting heads.</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>The probability for the two events is:</span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>Notation:</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>we use (Roman) p if its value is known.\</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>we use (Greek) $\theta$ when its value is unknown.</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a>This is a probability mass function since it is discrete. But we call it a Probability Density Function (PDF) in the measure-theoretic sense.</span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>f(X=x\mid p) = p^x(1-p)^x \mathbb{I}_{<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>}(x)</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-bernoulli-pmf}</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(x)= p </span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-bernoulli-expectation}</span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>\text{Var}(x)= \mathbb{P}r(1-p)</span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-bernoulli-variance}</span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "bernoulli-distribution"</span></span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Bernoulli distribution"</span></span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> bernoulli</span>
<span id="cb32-85"><a href="#cb32-85" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-86"><a href="#cb32-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-87"><a href="#cb32-87" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb32-88"><a href="#cb32-88" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb32-89"><a href="#cb32-89" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> bernoulli.stats(p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb32-90"><a href="#cb32-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb32-91"><a href="#cb32-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-92"><a href="#cb32-92" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(bernoulli.ppf(<span class="fl">0.01</span>, p),</span>
<span id="cb32-93"><a href="#cb32-93" aria-hidden="true" tabindex="-1"></a>              bernoulli.ppf(<span class="fl">0.99</span>, p))</span>
<span id="cb32-94"><a href="#cb32-94" aria-hidden="true" tabindex="-1"></a>ax.plot(x, bernoulli.pmf(x, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'bernoulli pmf'</span>)</span>
<span id="cb32-95"><a href="#cb32-95" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, bernoulli.pmf(x, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb32-96"><a href="#cb32-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-97"><a href="#cb32-97" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> bernoulli(p)</span>
<span id="cb32-98"><a href="#cb32-98" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb32-99"><a href="#cb32-99" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb32-100"><a href="#cb32-100" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-101"><a href="#cb32-101" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-102"><a href="#cb32-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-103"><a href="#cb32-103" aria-hidden="true" tabindex="-1"></a><span class="co">## Generate random numbers</span></span>
<span id="cb32-104"><a href="#cb32-104" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> bernoulli.rvs(p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-105"><a href="#cb32-105" aria-hidden="true" tabindex="-1"></a>r</span>
<span id="cb32-106"><a href="#cb32-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-107"><a href="#cb32-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-108"><a href="#cb32-108" aria-hidden="true" tabindex="-1"></a><span class="al">![Jacob Bernoulli](images/bio-bernoulli.jpg)</span>{#fig-bio-bernoulli .column-margin width="200px" group="slides"}</span>
<span id="cb32-109"><a href="#cb32-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-110"><a href="#cb32-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-111"><a href="#cb32-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-112"><a href="#cb32-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-113"><a href="#cb32-113" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb32-114"><a href="#cb32-114" aria-hidden="true" tabindex="-1"></a><span class="fu">### Biographical note on Jacob Bernoulli </span></span>
<span id="cb32-115"><a href="#cb32-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-116"><a href="#cb32-116" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It seems that to make a correct conjecture about any event whatever, it is necessary to calculate exactly the number of possible cases and then to determine how much more likely it is that one case will occur than another. </span><span class="co">[</span><span class="ot">@bernoulli1713ars</span><span class="co">]</span></span>
<span id="cb32-117"><a href="#cb32-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-118"><a href="#cb32-118" aria-hidden="true" tabindex="-1"></a>The Bernoulli distribution as well as The Binomial distribution are due to Jacob Bernoulli (1655-1705) who was a prominent mathematicians in the Bernoulli family. He discovered the fundamental mathematical constant e. However, his most important contribution was in the field of probability, where he derived the first version of the law of large numbers.</span>
<span id="cb32-119"><a href="#cb32-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-120"><a href="#cb32-120" aria-hidden="true" tabindex="-1"></a>for a fuller <span class="co">[</span><span class="ot">biography see</span><span class="co">](https://mathshistory.st-andrews.ac.uk/Biographies/Bernoulli_Jacob/)</span></span>
<span id="cb32-121"><a href="#cb32-121" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-122"><a href="#cb32-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-123"><a href="#cb32-123" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Binomial Distribution</span></span>
<span id="cb32-124"><a href="#cb32-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-125"><a href="#cb32-125" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-126"><a href="#cb32-126" aria-hidden="true" tabindex="-1"></a>\overbrace{\underbrace{\fbox{0}\ \ldots \fbox{0}}_{N_0}\ \underbrace{\fbox{1}\ \ldots \fbox{1}}_{N_1}}^N </span>
<span id="cb32-127"><a href="#cb32-127" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-bernoulli-experiment}</span>
<span id="cb32-128"><a href="#cb32-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-129"><a href="#cb32-129" aria-hidden="true" tabindex="-1"></a>The Binomial distribution models <span class="in">`counts`</span> of successes in independent Bernoulli trials \index{Bernoulli trial}. It arises when we need to consider the summing N independent and identically distributed Bernoulli RV with the same probability of success $\theta$.</span>
<span id="cb32-130"><a href="#cb32-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-131"><a href="#cb32-131" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb32-132"><a href="#cb32-132" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Conditions</span></span>
<span id="cb32-133"><a href="#cb32-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-134"><a href="#cb32-134" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Discrete data</span>
<span id="cb32-135"><a href="#cb32-135" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Two possible outcomes for each trial</span>
<span id="cb32-136"><a href="#cb32-136" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Each trial is independent</span>
<span id="cb32-137"><a href="#cb32-137" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The probability of success/failure is the same in each trial</span>
<span id="cb32-138"><a href="#cb32-138" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-139"><a href="#cb32-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-140"><a href="#cb32-140" aria-hidden="true" tabindex="-1"></a><span class="in">```{tikz Binomial-reparams, engine.opts=font_opts}</span></span>
<span id="cb32-141"><a href="#cb32-141" aria-hidden="true" tabindex="-1"></a><span class="in">#| echo: false</span></span>
<span id="cb32-142"><a href="#cb32-142" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Binomial reparams mindmap"</span></span>
<span id="cb32-143"><a href="#cb32-143" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-align: center</span></span>
<span id="cb32-144"><a href="#cb32-144" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-ext: png</span></span>
<span id="cb32-145"><a href="#cb32-145" aria-hidden="true" tabindex="-1"></a><span class="in">#| out-width: 100%</span></span>
<span id="cb32-146"><a href="#cb32-146" aria-hidden="true" tabindex="-1"></a><span class="in">\usetikzlibrary {mindmap,backgrounds,calc}</span></span>
<span id="cb32-147"><a href="#cb32-147" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{tikzpicture}[</span></span>
<span id="cb32-148"><a href="#cb32-148" aria-hidden="true" tabindex="-1"></a><span class="in">  mindmap,</span></span>
<span id="cb32-149"><a href="#cb32-149" aria-hidden="true" tabindex="-1"></a><span class="in">  concept color=red!30, </span></span>
<span id="cb32-150"><a href="#cb32-150" aria-hidden="true" tabindex="-1"></a><span class="in">     every node/.style = {concept}, </span></span>
<span id="cb32-151"><a href="#cb32-151" aria-hidden="true" tabindex="-1"></a><span class="in">    grow cyclic,</span></span>
<span id="cb32-152"><a href="#cb32-152" aria-hidden="true" tabindex="-1"></a><span class="in">    level 1/.append style = {</span></span>
<span id="cb32-153"><a href="#cb32-153" aria-hidden="true" tabindex="-1"></a><span class="in">        level distance = 4.5cm,</span></span>
<span id="cb32-154"><a href="#cb32-154" aria-hidden="true" tabindex="-1"></a><span class="in">        sibling angle = 45</span></span>
<span id="cb32-155"><a href="#cb32-155" aria-hidden="true" tabindex="-1"></a><span class="in">    },</span></span>
<span id="cb32-156"><a href="#cb32-156" aria-hidden="true" tabindex="-1"></a><span class="in">    level 2/.append style = {</span></span>
<span id="cb32-157"><a href="#cb32-157" aria-hidden="true" tabindex="-1"></a><span class="in">        level distance = 3cm,</span></span>
<span id="cb32-158"><a href="#cb32-158" aria-hidden="true" tabindex="-1"></a><span class="in">        sibling angle = 45</span></span>
<span id="cb32-159"><a href="#cb32-159" aria-hidden="true" tabindex="-1"></a><span class="in">    },</span></span>
<span id="cb32-160"><a href="#cb32-160" aria-hidden="true" tabindex="-1"></a><span class="in">    every annotation/.append style = {</span></span>
<span id="cb32-161"><a href="#cb32-161" aria-hidden="true" tabindex="-1"></a><span class="in">        fill = yellow!20,</span></span>
<span id="cb32-162"><a href="#cb32-162" aria-hidden="true" tabindex="-1"></a><span class="in">        text width = 2cm</span></span>
<span id="cb32-163"><a href="#cb32-163" aria-hidden="true" tabindex="-1"></a><span class="in">    }</span></span>
<span id="cb32-164"><a href="#cb32-164" aria-hidden="true" tabindex="-1"></a><span class="in">      ]</span></span>
<span id="cb32-165"><a href="#cb32-165" aria-hidden="true" tabindex="-1"></a><span class="in">      </span></span>
<span id="cb32-166"><a href="#cb32-166" aria-hidden="true" tabindex="-1"></a><span class="in">\node (Reparams)[concept color = blue!30]{Binomial} </span></span>
<span id="cb32-167"><a href="#cb32-167" aria-hidden="true" tabindex="-1"></a><span class="in">    child{node (Binomial1)[concept] {Binomial(n,p)}}</span></span>
<span id="cb32-168"><a href="#cb32-168" aria-hidden="true" tabindex="-1"></a><span class="in">    child{node (Binomial2)[concept] {Binomial(n,$\alpha$)}};</span></span>
<span id="cb32-169"><a href="#cb32-169" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb32-170"><a href="#cb32-170" aria-hidden="true" tabindex="-1"></a><span class="in">\node[annotation] at ($(Binomial2.south) + (0,0.25)$) { $\alpha = \log({p/1-p})$};</span></span>
<span id="cb32-171"><a href="#cb32-171" aria-hidden="true" tabindex="-1"></a><span class="in">\node[annotation] at ($(Binomial2.north) - (0,0.25)$) { $Logit$};</span></span>
<span id="cb32-172"><a href="#cb32-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-173"><a href="#cb32-173" aria-hidden="true" tabindex="-1"></a><span class="in">\end{tikzpicture}</span></span>
<span id="cb32-174"><a href="#cb32-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-175"><a href="#cb32-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-176"><a href="#cb32-176" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-177"><a href="#cb32-177" aria-hidden="true" tabindex="-1"></a>X \sim Bin<span class="co">[</span><span class="ot">n,p</span><span class="co">]</span></span>
<span id="cb32-178"><a href="#cb32-178" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-rv}</span>
<span id="cb32-179"><a href="#cb32-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-180"><a href="#cb32-180" aria-hidden="true" tabindex="-1"></a>the probability function</span>
<span id="cb32-181"><a href="#cb32-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-182"><a href="#cb32-182" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-183"><a href="#cb32-183" aria-hidden="true" tabindex="-1"></a>f(X=x \mid \theta) = {n \choose x} \theta^x(1-\theta)^{n-x}</span>
<span id="cb32-184"><a href="#cb32-184" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-pmf}</span>
<span id="cb32-185"><a href="#cb32-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-186"><a href="#cb32-186" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-187"><a href="#cb32-187" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\theta)=\prod_{i=1}^{n} {n\choose x_i}  \theta ^ {x_i} (1− \theta) ^ {(n−x_i)}</span>
<span id="cb32-188"><a href="#cb32-188" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-likelihood}</span>
<span id="cb32-189"><a href="#cb32-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-190"><a href="#cb32-190" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-191"><a href="#cb32-191" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb32-192"><a href="#cb32-192" aria-hidden="true" tabindex="-1"></a>\ell( \theta) &amp;= \log \mathcal{L}( \theta) <span class="sc">\\</span></span>
<span id="cb32-193"><a href="#cb32-193" aria-hidden="true" tabindex="-1"></a>              &amp;= \sum_{i=1}^n \left<span class="co">[</span><span class="ot">\log {n\choose x_i} + x_i \log  \theta + (n-x_i)\log (1- \theta) \right</span><span class="co">]</span></span>
<span id="cb32-194"><a href="#cb32-194" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb32-195"><a href="#cb32-195" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-log-likelihood}</span>
<span id="cb32-196"><a href="#cb32-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-197"><a href="#cb32-197" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-198"><a href="#cb32-198" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span>= N \times  \theta </span>
<span id="cb32-199"><a href="#cb32-199" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-expectation}</span>
<span id="cb32-200"><a href="#cb32-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-201"><a href="#cb32-201" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-202"><a href="#cb32-202" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span>=N \cdot \theta \cdot (1-\theta)</span>
<span id="cb32-203"><a href="#cb32-203" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-variance}</span>
<span id="cb32-204"><a href="#cb32-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-205"><a href="#cb32-205" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-206"><a href="#cb32-206" aria-hidden="true" tabindex="-1"></a>\mathbb{H}(X) = \frac{1}{2}\log_2 \left (2\pi n \theta(1 - \theta)\right) + O(\frac{1}{n})</span>
<span id="cb32-207"><a href="#cb32-207" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-entropy}</span>
<span id="cb32-208"><a href="#cb32-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-209"><a href="#cb32-209" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-210"><a href="#cb32-210" aria-hidden="true" tabindex="-1"></a>\mathcal{I}(\theta)=\frac{n}{ \theta \cdot (1- \theta)}</span>
<span id="cb32-211"><a href="#cb32-211" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-binomial-information}</span>
<span id="cb32-212"><a href="#cb32-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-213"><a href="#cb32-213" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Relationships</span></span>
<span id="cb32-214"><a href="#cb32-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-215"><a href="#cb32-215" aria-hidden="true" tabindex="-1"></a><span class="al">![binomial distribution relations](images/dbinomial.png)</span>{#fig-dbinomial .column-margin width="200px" group="slides"}</span>
<span id="cb32-216"><a href="#cb32-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-217"><a href="#cb32-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-218"><a href="#cb32-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-219"><a href="#cb32-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-220"><a href="#cb32-220" aria-hidden="true" tabindex="-1"></a>The Binomial Distribution is related to:</span>
<span id="cb32-221"><a href="#cb32-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-222"><a href="#cb32-222" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the **Geometric distribution**,</span>
<span id="cb32-223"><a href="#cb32-223" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **Multinomial distribution** \index{Multinomial} with two categories is the binomial.</span>
<span id="cb32-224"><a href="#cb32-224" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the **Poisson distribution** \index{Poisson} distribution. If $X \sim \mathrm{Binomial}(n, p)$ rv and $Y \sim \mathrm{Poisson}(np)$ distribution then $\mathbb{P}r(X = n) \approx \mathbb{P}r(Y = n)$ for large $n$ and small $np$.</span>
<span id="cb32-225"><a href="#cb32-225" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the **Bernoulli distribution** If $X \sim \mathrm{Binomial}(n, p)$ RV with $n = 1$, $X \sim Bernoulli(p)$ RV.</span>
<span id="cb32-226"><a href="#cb32-226" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the **Normal distribution** If $X \sim \mathrm{Binomial}(n, p)$ RV and $Y \sim Normal(\mu=np,\sigma=n\mathbb{P}r(1-p))$ then for integers j and k, $\mathbb{P}r(j \le X \le k) \approx \mathbb{P}r(j – {1 \over 2} \le Y \le k + {1 \over 2})$. The approximation is better when $p ≈ 0.5$ and when n is large. For more information, see normal approximation to binomial</span>
<span id="cb32-227"><a href="#cb32-227" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Hypergeometric**: The difference between a binomial distribution and a hypergeometric distribution is the difference between sampling with replacement and sampling without replacement. As the population size increases relative to the sample size, the difference becomes negligible. So If $X \sim Binomial(n, p)$ RV and $Y \sim HyperGeometric(N,a,b)$ then </span>
<span id="cb32-228"><a href="#cb32-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-229"><a href="#cb32-229" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-230"><a href="#cb32-230" aria-hidden="true" tabindex="-1"></a>\lim_{n\to \infty} X = Y </span>
<span id="cb32-231"><a href="#cb32-231" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-232"><a href="#cb32-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-235"><a href="#cb32-235" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-236"><a href="#cb32-236" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "binomial-distribution"</span></span>
<span id="cb32-237"><a href="#cb32-237" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-238"><a href="#cb32-238" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> binom</span>
<span id="cb32-239"><a href="#cb32-239" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-240"><a href="#cb32-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-241"><a href="#cb32-241" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb32-242"><a href="#cb32-242" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb32-243"><a href="#cb32-243" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> binom.stats(n, p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb32-244"><a href="#cb32-244" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb32-245"><a href="#cb32-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-246"><a href="#cb32-246" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(binom.ppf(<span class="fl">0.01</span>, n, p), binom.ppf(<span class="fl">0.99</span>, n, p))</span>
<span id="cb32-247"><a href="#cb32-247" aria-hidden="true" tabindex="-1"></a>ax.plot(x, binom.pmf(x, n, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'binom pmf'</span>)</span>
<span id="cb32-248"><a href="#cb32-248" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, binom.pmf(x, n, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb32-249"><a href="#cb32-249" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> binom(n, p)</span>
<span id="cb32-250"><a href="#cb32-250" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb32-251"><a href="#cb32-251" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb32-252"><a href="#cb32-252" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-253"><a href="#cb32-253" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-254"><a href="#cb32-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-255"><a href="#cb32-255" aria-hidden="true" tabindex="-1"></a><span class="co">## generate random numbers</span></span>
<span id="cb32-256"><a href="#cb32-256" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> binom.rvs(n, p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-257"><a href="#cb32-257" aria-hidden="true" tabindex="-1"></a>r</span>
<span id="cb32-258"><a href="#cb32-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-259"><a href="#cb32-259" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-260"><a href="#cb32-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-261"><a href="#cb32-261" aria-hidden="true" tabindex="-1"></a>:::: {.content-hidden when-format="pdf"}</span>
<span id="cb32-262"><a href="#cb32-262" aria-hidden="true" tabindex="-1"></a>::: {#vid-bernoulli-distribution .column-margin}</span>
<span id="cb32-263"><a href="#cb32-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-264"><a href="#cb32-264" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://youtu.be/sn-mp_ESSMc &gt;}}</span>
<span id="cb32-265"><a href="#cb32-265" aria-hidden="true" tabindex="-1"></a>The Bernoulli Distribution  </span>
<span id="cb32-266"><a href="#cb32-266" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb32-267"><a href="#cb32-267" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb32-268"><a href="#cb32-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-269"><a href="#cb32-269" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Discrete Uniform Distribution</span></span>
<span id="cb32-270"><a href="#cb32-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-271"><a href="#cb32-271" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-272"><a href="#cb32-272" aria-hidden="true" tabindex="-1"></a>X \sim U<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span></span>
<span id="cb32-273"><a href="#cb32-273" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-discrete-uniform-rv}</span>
<span id="cb32-274"><a href="#cb32-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-275"><a href="#cb32-275" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-276"><a href="#cb32-276" aria-hidden="true" tabindex="-1"></a>    f(x)=</span>
<span id="cb32-277"><a href="#cb32-277" aria-hidden="true" tabindex="-1"></a>    \begin{cases}</span>
<span id="cb32-278"><a href="#cb32-278" aria-hidden="true" tabindex="-1"></a>      1, &amp; \text{if}\ x \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb32-279"><a href="#cb32-279" aria-hidden="true" tabindex="-1"></a>      0, &amp; \text{otherwise}</span>
<span id="cb32-280"><a href="#cb32-280" aria-hidden="true" tabindex="-1"></a>    \end{cases}</span>
<span id="cb32-281"><a href="#cb32-281" aria-hidden="true" tabindex="-1"></a>    = \mathbb{I}_{<span class="sc">\{</span>0 \le x \le 1<span class="sc">\}</span>}(x)</span>
<span id="cb32-282"><a href="#cb32-282" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-uniform-pmf}</span>
<span id="cb32-283"><a href="#cb32-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-286"><a href="#cb32-286" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-287"><a href="#cb32-287" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "uniform-distribution"</span></span>
<span id="cb32-288"><a href="#cb32-288" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-289"><a href="#cb32-289" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> uniform</span>
<span id="cb32-290"><a href="#cb32-290" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-291"><a href="#cb32-291" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb32-292"><a href="#cb32-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-293"><a href="#cb32-293" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb32-294"><a href="#cb32-294" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> uniform.stats(moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb32-295"><a href="#cb32-295" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb32-296"><a href="#cb32-296" aria-hidden="true" tabindex="-1"></a><span class="co"># we use ppf to get the domain from a range of (0.01,0.99)</span></span>
<span id="cb32-297"><a href="#cb32-297" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(uniform.ppf(<span class="fl">0.01</span>), uniform.ppf(<span class="fl">0.99</span>), <span class="dv">100</span>)</span>
<span id="cb32-298"><a href="#cb32-298" aria-hidden="true" tabindex="-1"></a>ax.plot(x, uniform.pdf(x), <span class="st">'r-'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'uniform pdf'</span>)</span>
<span id="cb32-299"><a href="#cb32-299" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> uniform()</span>
<span id="cb32-300"><a href="#cb32-300" aria-hidden="true" tabindex="-1"></a>ax.plot(x, rv.pdf(x), <span class="st">'k-'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'frozen pdf'</span>)</span>
<span id="cb32-301"><a href="#cb32-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-302"><a href="#cb32-302" aria-hidden="true" tabindex="-1"></a><span class="co">## generate random numbers</span></span>
<span id="cb32-303"><a href="#cb32-303" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> uniform.rvs(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb32-304"><a href="#cb32-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-305"><a href="#cb32-305" aria-hidden="true" tabindex="-1"></a><span class="co"># And compare the histogram:</span></span>
<span id="cb32-306"><a href="#cb32-306" aria-hidden="true" tabindex="-1"></a>ax.hist(r, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="st">'auto'</span>, histtype<span class="op">=</span><span class="st">'stepfilled'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb32-307"><a href="#cb32-307" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([x[<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb32-308"><a href="#cb32-308" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-309"><a href="#cb32-309" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-310"><a href="#cb32-310" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-311"><a href="#cb32-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-312"><a href="#cb32-312" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Continuous Uniform Distribution</span></span>
<span id="cb32-313"><a href="#cb32-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-314"><a href="#cb32-314" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-315"><a href="#cb32-315" aria-hidden="true" tabindex="-1"></a>X \sim \mathrm{Uniform}<span class="co">[</span><span class="ot">\theta_1,\theta_2</span><span class="co">]</span> </span>
<span id="cb32-316"><a href="#cb32-316" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-uniform-rv}</span>
<span id="cb32-317"><a href="#cb32-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-318"><a href="#cb32-318" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-319"><a href="#cb32-319" aria-hidden="true" tabindex="-1"></a>f(x)= \frac{1}{\theta_2-\theta_1} \mathbb{I}_{<span class="sc">\{</span>\theta_1 \le x \le \theta_2<span class="sc">\}</span>}(x) </span>
<span id="cb32-320"><a href="#cb32-320" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-uniform-pdf}</span>
<span id="cb32-321"><a href="#cb32-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-322"><a href="#cb32-322" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Normal, Z, t Distributions {#sec-the-normal-z-t-distributions}</span></span>
<span id="cb32-323"><a href="#cb32-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-324"><a href="#cb32-324" aria-hidden="true" tabindex="-1"></a>\index{Normal distribution}</span>
<span id="cb32-325"><a href="#cb32-325" aria-hidden="true" tabindex="-1"></a>\index{Gaussian distribution|\see{Normal distribution}}</span>
<span id="cb32-326"><a href="#cb32-326" aria-hidden="true" tabindex="-1"></a>The *normal*, AKA *Gaussian distribution* is one of the most important distributions in statistics.</span>
<span id="cb32-327"><a href="#cb32-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-328"><a href="#cb32-328" aria-hidden="true" tabindex="-1"></a>It arises as the limiting distribution of sums (and averages) of random variables. This is due to the @sec-cl-theorem. Because of this property, the normal distribution is often used to model the "errors," or unexplained variations of individual observations in regression models.</span>
<span id="cb32-329"><a href="#cb32-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-330"><a href="#cb32-330" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Standard Normal distribution {#sec-the-standard-normal-distribution}</span></span>
<span id="cb32-331"><a href="#cb32-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-332"><a href="#cb32-332" aria-hidden="true" tabindex="-1"></a>\index{Standard normal distribution}</span>
<span id="cb32-333"><a href="#cb32-333" aria-hidden="true" tabindex="-1"></a>The standard normal distribution is given by</span>
<span id="cb32-334"><a href="#cb32-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-335"><a href="#cb32-335" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-336"><a href="#cb32-336" aria-hidden="true" tabindex="-1"></a>\mathcal{Z} \sim \mathcal{N}<span class="co">[</span><span class="ot">1,0</span><span class="co">]</span></span>
<span id="cb32-337"><a href="#cb32-337" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-z-rv}</span>
<span id="cb32-338"><a href="#cb32-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-339"><a href="#cb32-339" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-340"><a href="#cb32-340" aria-hidden="true" tabindex="-1"></a>f(z) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{z^2}{2}}</span>
<span id="cb32-341"><a href="#cb32-341" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-z-pdf}</span>
<span id="cb32-342"><a href="#cb32-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-343"><a href="#cb32-343" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-344"><a href="#cb32-344" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">\mathcal{Z}</span><span class="co">]</span> = 0</span>
<span id="cb32-345"><a href="#cb32-345" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-z-expectation}</span>
<span id="cb32-346"><a href="#cb32-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-347"><a href="#cb32-347" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-348"><a href="#cb32-348" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">\mathcal{Z}</span><span class="co">]</span>= 1</span>
<span id="cb32-349"><a href="#cb32-349" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-z-variance}</span>
<span id="cb32-350"><a href="#cb32-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-351"><a href="#cb32-351" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Normal distribution</span></span>
<span id="cb32-352"><a href="#cb32-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-353"><a href="#cb32-353" aria-hidden="true" tabindex="-1"></a>\index{Normal distribution}</span>
<span id="cb32-354"><a href="#cb32-354" aria-hidden="true" tabindex="-1"></a>Now consider $X = \sigma \mathcal{Z}+\mu$ where $\sigma &gt; 0$ and $\mu$ is any real constant. </span>
<span id="cb32-355"><a href="#cb32-355" aria-hidden="true" tabindex="-1"></a>Then $\mathbb{E}(X) = \mathbb{E}(\sigma \mathcal{Z}+\mu) = \sigma \mathbb{E}(\mathcal{Z}) + \mu = \sigma \times 0 + \mu = \mu$ and $Var(X) = Var(\sigma^2 + \mu) = \sigma^2 Var(\mathcal{Z}) + 0 = \sigma^2 \cdot 1 = \sigma^2$</span>
<span id="cb32-356"><a href="#cb32-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-357"><a href="#cb32-357" aria-hidden="true" tabindex="-1"></a>Then, X follows a normal distribution with mean $\mu$ and variance $\sigma^2$ (standard deviation $\sigma$) denoted as</span>
<span id="cb32-358"><a href="#cb32-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-359"><a href="#cb32-359" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-360"><a href="#cb32-360" aria-hidden="true" tabindex="-1"></a>X \sim \mathcal{N}<span class="co">[</span><span class="ot">\mu,\sigma^2</span><span class="co">]</span></span>
<span id="cb32-361"><a href="#cb32-361" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-normal-rv}</span>
<span id="cb32-362"><a href="#cb32-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-363"><a href="#cb32-363" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-364"><a href="#cb32-364" aria-hidden="true" tabindex="-1"></a>f(x\mid \mu,\sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}}  e^{-\frac{1}{\sqrt{2 \pi \sigma^2}}(x-\mu)^2}</span>
<span id="cb32-365"><a href="#cb32-365" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-normal-pdf}</span>
<span id="cb32-366"><a href="#cb32-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-367"><a href="#cb32-367" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-368"><a href="#cb32-368" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">x</span><span class="co">]</span>= \mu </span>
<span id="cb32-369"><a href="#cb32-369" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-normal-expectation}</span>
<span id="cb32-370"><a href="#cb32-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-371"><a href="#cb32-371" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-372"><a href="#cb32-372" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">x</span><span class="co">]</span>= \sigma^2</span>
<span id="cb32-373"><a href="#cb32-373" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-normal-variance}</span>
<span id="cb32-374"><a href="#cb32-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-375"><a href="#cb32-375" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The normal distribution is symmetric about the mean $\mu$ and is often described as a <span class="in">`bell-shaped`</span> curve.</span>
<span id="cb32-376"><a href="#cb32-376" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Although X can take on any real value (positive or negative), more than 99% of the probability mass is concentrated within three standard deviations of the mean.</span>
<span id="cb32-377"><a href="#cb32-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-378"><a href="#cb32-378" aria-hidden="true" tabindex="-1"></a>The normal distribution has several desirable properties.</span>
<span id="cb32-379"><a href="#cb32-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-380"><a href="#cb32-380" aria-hidden="true" tabindex="-1"></a>One is that if $X_1 \sim \mathcal{N}(\mu_1, \sigma^2_1)$ and $X_2 \sim \mathcal{N}(\mu_2, \sigma^2_2)$ are independent, then $X_1+X_2 \sim \mathcal{N}(\mu_1+\mu_2, \sigma^2_1+\sigma^2_2)$.</span>
<span id="cb32-381"><a href="#cb32-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-382"><a href="#cb32-382" aria-hidden="true" tabindex="-1"></a>Consequently, if we take the average of n Independent and Identically Distributed (IID) normal random variables we have</span>
<span id="cb32-383"><a href="#cb32-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-384"><a href="#cb32-384" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-385"><a href="#cb32-385" aria-hidden="true" tabindex="-1"></a>\bar X = \frac{1}{n}\sum_{i=1}^n X_i \sim \mathcal{N}(\mu, \frac{\sigma^2}{n})</span>
<span id="cb32-386"><a href="#cb32-386" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-normal-sum}</span>
<span id="cb32-387"><a href="#cb32-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-390"><a href="#cb32-390" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-391"><a href="#cb32-391" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "normal-distribution"</span></span>
<span id="cb32-392"><a href="#cb32-392" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-393"><a href="#cb32-393" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb32-394"><a href="#cb32-394" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-395"><a href="#cb32-395" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb32-396"><a href="#cb32-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-397"><a href="#cb32-397" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb32-398"><a href="#cb32-398" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> norm.stats(moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb32-399"><a href="#cb32-399" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb32-400"><a href="#cb32-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-401"><a href="#cb32-401" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(norm.ppf(<span class="fl">0.01</span>),</span>
<span id="cb32-402"><a href="#cb32-402" aria-hidden="true" tabindex="-1"></a>                norm.ppf(<span class="fl">0.99</span>), <span class="dv">100</span>)</span>
<span id="cb32-403"><a href="#cb32-403" aria-hidden="true" tabindex="-1"></a>ax.plot(x, norm.pdf(x),</span>
<span id="cb32-404"><a href="#cb32-404" aria-hidden="true" tabindex="-1"></a>       <span class="st">'r-'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'norm pdf'</span>)</span>
<span id="cb32-405"><a href="#cb32-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-406"><a href="#cb32-406" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> norm()</span>
<span id="cb32-407"><a href="#cb32-407" aria-hidden="true" tabindex="-1"></a>ax.plot(x, rv.pdf(x), <span class="st">'k-'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'frozen pdf'</span>)</span>
<span id="cb32-408"><a href="#cb32-408" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> norm.rvs(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb32-409"><a href="#cb32-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-410"><a href="#cb32-410" aria-hidden="true" tabindex="-1"></a>ax.hist(r, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="st">'auto'</span>, histtype<span class="op">=</span><span class="st">'stepfilled'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb32-411"><a href="#cb32-411" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([x[<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb32-412"><a href="#cb32-412" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-413"><a href="#cb32-413" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-414"><a href="#cb32-414" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-415"><a href="#cb32-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-416"><a href="#cb32-416" aria-hidden="true" tabindex="-1"></a><span class="fu">### The t-Distribution</span></span>
<span id="cb32-417"><a href="#cb32-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-418"><a href="#cb32-418" aria-hidden="true" tabindex="-1"></a>\index{t-distribution}</span>
<span id="cb32-419"><a href="#cb32-419" aria-hidden="true" tabindex="-1"></a>If we have normal data, we can use (@eq-normal-sum) to help us estimate the mean $\mu$. Reversing the transformation from the previous section, we get</span>
<span id="cb32-420"><a href="#cb32-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-421"><a href="#cb32-421" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-422"><a href="#cb32-422" aria-hidden="true" tabindex="-1"></a>\frac {\hat X - \mu}{\sigma / \sqrt(n)} \sim N(0, 1)</span>
<span id="cb32-423"><a href="#cb32-423" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-t-transform}</span>
<span id="cb32-424"><a href="#cb32-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-425"><a href="#cb32-425" aria-hidden="true" tabindex="-1"></a>However, we may not know the value of $\sigma$. If we estimate it from data, we can replace it with $S = \sqrt{\sum_i \frac{(X_i-\hat X)^2}{n-1}}$, the sample standard deviation. This causes the expression (@eq-t-transform) to no longer be distributed as a Standard Normal; but as a standard *t-distribution* with $ν = n − 1$ <span class="in">`degrees of freedom`</span></span>
<span id="cb32-426"><a href="#cb32-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-427"><a href="#cb32-427" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-428"><a href="#cb32-428" aria-hidden="true" tabindex="-1"></a>X \sim t<span class="co">[</span><span class="ot">\nu</span><span class="co">]</span></span>
<span id="cb32-429"><a href="#cb32-429" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-t-rv}</span>
<span id="cb32-430"><a href="#cb32-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-431"><a href="#cb32-431" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-432"><a href="#cb32-432" aria-hidden="true" tabindex="-1"></a>f(t\mid\nu) = \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\sqrt{\nu\pi}}\left (1 + \frac{t^2}{\nu}\right)^{-(\frac{\nu+1}{2})}\mathbb{I}_{t\in\mathbb{R}} \qquad \text{(PDF)}</span>
<span id="cb32-433"><a href="#cb32-433" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-t-pdf-gamma}</span>
<span id="cb32-434"><a href="#cb32-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-435"><a href="#cb32-435" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-436"><a href="#cb32-436" aria-hidden="true" tabindex="-1"></a>\text{where }\Gamma(w)=\int_{0}^{\infty}t^{w-1}e^{-t}\mathrm{d}t \text{ is the gamma function}</span>
<span id="cb32-437"><a href="#cb32-437" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-438"><a href="#cb32-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-439"><a href="#cb32-439" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-440"><a href="#cb32-440" aria-hidden="true" tabindex="-1"></a>f(t\mid\nu)={\frac {1}{{\sqrt {\nu }}\,\mathrm {B} ({\frac {1}{2}},{\frac {\nu }{2}})}}\left(1+{\frac {t^{2}}{\nu }}\right)^{-(\nu +1)/2}\mathbb{I}_{t\in\mathbb{R}} \qquad \text{(PDF)}</span>
<span id="cb32-441"><a href="#cb32-441" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-t-pdf-beta}</span>
<span id="cb32-442"><a href="#cb32-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-443"><a href="#cb32-443" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-444"><a href="#cb32-444" aria-hidden="true" tabindex="-1"></a>\text{where } B(u,v)=\int_{0}^{1}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the beta function}</span>
<span id="cb32-445"><a href="#cb32-445" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-446"><a href="#cb32-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-447"><a href="#cb32-447" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-448"><a href="#cb32-448" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">Y</span><span class="co">]</span> = 0 \qquad \text{ if } \nu &gt; 1</span>
<span id="cb32-449"><a href="#cb32-449" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-t-expectation-xyz}</span>
<span id="cb32-450"><a href="#cb32-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-451"><a href="#cb32-451" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-452"><a href="#cb32-452" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">Y</span><span class="co">]</span> = \frac{\nu}{\nu - 2} \qquad \text{ if } \nu &gt; 2</span>
<span id="cb32-453"><a href="#cb32-453" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-t-variance}</span>
<span id="cb32-454"><a href="#cb32-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-455"><a href="#cb32-455" aria-hidden="true" tabindex="-1"></a>The t distribution is symmetric and resembles the Normal Distribution but with thicker tails. As the degrees of freedom increase, the t distribution looks more and more like the standard normal distribution.</span>
<span id="cb32-456"><a href="#cb32-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-457"><a href="#cb32-457" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Exponential Distribution </span></span>
<span id="cb32-458"><a href="#cb32-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-459"><a href="#cb32-459" aria-hidden="true" tabindex="-1"></a>\index{Exponential distribution}</span>
<span id="cb32-460"><a href="#cb32-460" aria-hidden="true" tabindex="-1"></a>The **Exponential distribution** models the waiting time between events for events with a rate $\lambda$. Those events, typically, come from a **Poisson** process.</span>
<span id="cb32-461"><a href="#cb32-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-462"><a href="#cb32-462" aria-hidden="true" tabindex="-1"></a>The **Exponential distribution** is often used to model the <span class="in">`waiting time between random events`</span>. Indeed, if the waiting times between successive events are independent then they form an $\exp(r(\lambda)$ distribution. Then for any fixed time window of length t, the number of events occurring in that window will follow a <span class="in">`Poisson distribution`</span> with mean $t\lambda$.</span>
<span id="cb32-463"><a href="#cb32-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-464"><a href="#cb32-464" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-465"><a href="#cb32-465" aria-hidden="true" tabindex="-1"></a>X \sim Exp<span class="co">[</span><span class="ot">\lambda</span><span class="co">]</span></span>
<span id="cb32-466"><a href="#cb32-466" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-exponential-rv}</span>
<span id="cb32-467"><a href="#cb32-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-468"><a href="#cb32-468" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-469"><a href="#cb32-469" aria-hidden="true" tabindex="-1"></a>f(x \mid \lambda) = \frac{1}{\lambda} e^{- \frac{x}{\lambda}}(x)\mathbb{I}_{\lambda\in\mathbb{R}^+ } \mathbb{I}_{x\in\mathbb{R}^+_0 } \quad \text{(PDF)}</span>
<span id="cb32-470"><a href="#cb32-470" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-exponential-pdf}</span>
<span id="cb32-471"><a href="#cb32-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-472"><a href="#cb32-472" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-473"><a href="#cb32-473" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(x)= \lambda</span>
<span id="cb32-474"><a href="#cb32-474" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-exponential-expectation}</span>
<span id="cb32-475"><a href="#cb32-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-476"><a href="#cb32-476" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-477"><a href="#cb32-477" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span>= \lambda^2</span>
<span id="cb32-478"><a href="#cb32-478" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-exponential-variance}</span>
<span id="cb32-479"><a href="#cb32-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-482"><a href="#cb32-482" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-483"><a href="#cb32-483" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "exponential-distribution"</span></span>
<span id="cb32-484"><a href="#cb32-484" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-485"><a href="#cb32-485" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> expon</span>
<span id="cb32-486"><a href="#cb32-486" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-487"><a href="#cb32-487" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb32-488"><a href="#cb32-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-489"><a href="#cb32-489" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb32-490"><a href="#cb32-490" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> expon.stats(moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb32-491"><a href="#cb32-491" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb32-492"><a href="#cb32-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-493"><a href="#cb32-493" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(expon.ppf(<span class="fl">0.01</span>), expon.ppf(<span class="fl">0.99</span>), <span class="dv">100</span>)</span>
<span id="cb32-494"><a href="#cb32-494" aria-hidden="true" tabindex="-1"></a>ax.plot(x, expon.pdf(x), <span class="st">'r-'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'expon pdf'</span>)</span>
<span id="cb32-495"><a href="#cb32-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-496"><a href="#cb32-496" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> expon()</span>
<span id="cb32-497"><a href="#cb32-497" aria-hidden="true" tabindex="-1"></a>ax.plot(x, rv.pdf(x), <span class="st">'k-'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'frozen pdf'</span>)</span>
<span id="cb32-498"><a href="#cb32-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-499"><a href="#cb32-499" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> expon.rvs(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb32-500"><a href="#cb32-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-501"><a href="#cb32-501" aria-hidden="true" tabindex="-1"></a>ax.hist(r, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="st">'auto'</span>, histtype<span class="op">=</span><span class="st">'stepfilled'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb32-502"><a href="#cb32-502" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([x[<span class="dv">0</span>], x[<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb32-503"><a href="#cb32-503" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-504"><a href="#cb32-504" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-505"><a href="#cb32-505" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-506"><a href="#cb32-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-507"><a href="#cb32-507" aria-hidden="true" tabindex="-1"></a><span class="fu"># Additional Discrete Distributions</span></span>
<span id="cb32-508"><a href="#cb32-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-509"><a href="#cb32-509" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Geometric Distribution {#sec-the-geometric-distribution}</span></span>
<span id="cb32-510"><a href="#cb32-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-511"><a href="#cb32-511" aria-hidden="true" tabindex="-1"></a>\index{Geometric distribution}</span>
<span id="cb32-512"><a href="#cb32-512" aria-hidden="true" tabindex="-1"></a>The **Geometric distribution** arises when we want to know "What is the number of Bernoulli trials required to get the first success?", i.e., the number of Bernoulli events until a success is observed, such as the probability of getting the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).</span>
<span id="cb32-513"><a href="#cb32-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-514"><a href="#cb32-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-515"><a href="#cb32-515" aria-hidden="true" tabindex="-1"></a>:::: {.content-hidden when-format="pdf"}</span>
<span id="cb32-516"><a href="#cb32-516" aria-hidden="true" tabindex="-1"></a>::: {#vid-geometric-distribution .column-margin}</span>
<span id="cb32-517"><a href="#cb32-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-518"><a href="#cb32-518" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://youtu.be/-vvtrsS4rkA &gt;}}</span>
<span id="cb32-519"><a href="#cb32-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-520"><a href="#cb32-520" aria-hidden="true" tabindex="-1"></a>The Geometric Distribution</span>
<span id="cb32-521"><a href="#cb32-521" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-522"><a href="#cb32-522" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb32-523"><a href="#cb32-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-524"><a href="#cb32-524" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-525"><a href="#cb32-525" aria-hidden="true" tabindex="-1"></a>X \sim \mathrm{Geo}(p)</span>
<span id="cb32-526"><a href="#cb32-526" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-geom-rv}</span>
<span id="cb32-527"><a href="#cb32-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-528"><a href="#cb32-528" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-529"><a href="#cb32-529" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(X = x\mid p) = \mathbb{P}r(1-p)^{x-1} \qquad \forall x \in N;\quad 0\le p \le 1 </span>
<span id="cb32-530"><a href="#cb32-530" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-geom-pmf}</span>
<span id="cb32-531"><a href="#cb32-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-532"><a href="#cb32-532" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-533"><a href="#cb32-533" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span> = \frac{1}{p}</span>
<span id="cb32-534"><a href="#cb32-534" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-geom-expectation}</span>
<span id="cb32-535"><a href="#cb32-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-536"><a href="#cb32-536" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-537"><a href="#cb32-537" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span>=\frac{1-p}{p^2}</span>
<span id="cb32-538"><a href="#cb32-538" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-geom-variance}</span>
<span id="cb32-539"><a href="#cb32-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-540"><a href="#cb32-540" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-541"><a href="#cb32-541" aria-hidden="true" tabindex="-1"></a>\mathbb{M}_X<span class="co">[</span><span class="ot">t</span><span class="co">]</span> = \frac{pe^t}{1-(1-p)e^t} \qquad t &lt; -log(1-p)</span>
<span id="cb32-542"><a href="#cb32-542" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-geom-mgf}</span>
<span id="cb32-543"><a href="#cb32-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-544"><a href="#cb32-544" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Multinomial Distribution {#sec-the-multinomial-distribution}</span></span>
<span id="cb32-545"><a href="#cb32-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-546"><a href="#cb32-546" aria-hidden="true" tabindex="-1"></a>Another generalization of the Bernoulli distribution and the Binomial distribution is the **Multinomial distribution** \index{Multinomial distribution}, which sums the successes of Bernoulli trials when there are n different possible outcomes. Suppose we have n trials and there are k different possible outcomes that occur with probabilities $p_1, \ldots, p_k$. For example, we are rolling a six-sided die that might be loaded so that the sides are not equally likely, then n is the total number of rolls, $k = 6$, $p_1$ is the probability of rolling a one, and we denote by $x_1, \ldots, x_6$ a possible outcome for the number of times we observe rolls of each of one through six, where</span>
<span id="cb32-547"><a href="#cb32-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-548"><a href="#cb32-548" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-549"><a href="#cb32-549" aria-hidden="true" tabindex="-1"></a>X \sim \mathrm{Multinomial}(p_1,...p_k)</span>
<span id="cb32-550"><a href="#cb32-550" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-551"><a href="#cb32-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-552"><a href="#cb32-552" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-553"><a href="#cb32-553" aria-hidden="true" tabindex="-1"></a>P (X = x \mid p_1,\ldots,p_k) = \frac{n!}{x_1! \cdot \cdot \cdot x_k! } \prod_i p_i^{x_i}</span>
<span id="cb32-554"><a href="#cb32-554" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-555"><a href="#cb32-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-556"><a href="#cb32-556" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Poisson Distribution {#sec-the-poisson-distribution}</span></span>
<span id="cb32-557"><a href="#cb32-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-558"><a href="#cb32-558" aria-hidden="true" tabindex="-1"></a>The **Poisson distribution** \index{Poisson distribution} arises when modeling **count** data. The parameter $\lambda &gt; 0$ is the <span class="in">`rate`</span> at which we expect to observe the thing we are counting. We write this as $X \sim \mathrm{Poisson}(\lambda)$</span>
<span id="cb32-559"><a href="#cb32-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-560"><a href="#cb32-560" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-561"><a href="#cb32-561" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(X = x \mid \lambda) = \frac{\lambda^x e^{−\lambda}}{x!} \qquad \forall x \in \mathbb{N}_0 \qquad \text{PDF}</span>
<span id="cb32-562"><a href="#cb32-562" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-poisson-PMF}</span>
<span id="cb32-563"><a href="#cb32-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-564"><a href="#cb32-564" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-565"><a href="#cb32-565" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span> = \lambda \qquad \text{Expectation}</span>
<span id="cb32-566"><a href="#cb32-566" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-poisson-expectation}</span>
<span id="cb32-567"><a href="#cb32-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-568"><a href="#cb32-568" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-569"><a href="#cb32-569" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span> = \lambda \qquad \text{Variance}</span>
<span id="cb32-570"><a href="#cb32-570" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-poisson-variance}</span>
<span id="cb32-571"><a href="#cb32-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-572"><a href="#cb32-572" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-573"><a href="#cb32-573" aria-hidden="true" tabindex="-1"></a>\mathbb{M}_X(t) = \exp<span class="co">[</span><span class="ot">\lambda(e^t-1)</span><span class="co">]</span> \qquad \text{Moment Generating fn.}</span>
<span id="cb32-574"><a href="#cb32-574" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-poisson-mgf}</span>
<span id="cb32-575"><a href="#cb32-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-576"><a href="#cb32-576" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-577"><a href="#cb32-577" aria-hidden="true" tabindex="-1"></a>\mathcal{I}_X(t) = \frac{1}{\lambda}</span>
<span id="cb32-578"><a href="#cb32-578" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-poisson-fisher-information}</span>
<span id="cb32-579"><a href="#cb32-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-580"><a href="#cb32-580" aria-hidden="true" tabindex="-1"></a><span class="fu">### Relations</span></span>
<span id="cb32-581"><a href="#cb32-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-582"><a href="#cb32-582" aria-hidden="true" tabindex="-1"></a><span class="al">![Relations of the Poisson distribution](images/dpoisson.png)</span>{#fig-dPoisson .column-margin width="200px" group="slides"}</span>
<span id="cb32-583"><a href="#cb32-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-584"><a href="#cb32-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-585"><a href="#cb32-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-586"><a href="#cb32-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-587"><a href="#cb32-587" aria-hidden="true" tabindex="-1"></a>\index{Poisson process}</span>
<span id="cb32-588"><a href="#cb32-588" aria-hidden="true" tabindex="-1"></a>A *Poisson process* is a process wherein events occur on average at rate $\mathbb{E}$, events occur one at a time, and events occur independently of each other.</span>
<span id="cb32-589"><a href="#cb32-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-590"><a href="#cb32-590" aria-hidden="true" tabindex="-1"></a><span class="al">![Siméon Denis Poisson](images/bio-SimeonDenisPoisson.jpg)</span>{#fig-bio-Poisson .column-margin width="200px" group="slides"}</span>
<span id="cb32-591"><a href="#cb32-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-592"><a href="#cb32-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-593"><a href="#cb32-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-594"><a href="#cb32-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-595"><a href="#cb32-595" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb32-596"><a href="#cb32-596" aria-hidden="true" tabindex="-1"></a><span class="fu">### Biographical Note on The Siméon Denis Poisson</span></span>
<span id="cb32-597"><a href="#cb32-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-598"><a href="#cb32-598" aria-hidden="true" tabindex="-1"></a>The Poisson distribution is due to Baron Siméon Denis Poisson (1781-1840) see <span class="co">[</span><span class="ot">@poisson2019english pp. 205-207</span><span class="co">]</span> was a French mathematician and physicist who worked on statistics, complex analysis, partial differential equations, the calculus of variations, analytical mechanics, electricity and magnetism, thermodynamics, elasticity, and fluid mechanics.</span>
<span id="cb32-599"><a href="#cb32-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-600"><a href="#cb32-600" aria-hidden="true" tabindex="-1"></a>for a fuller <span class="co">[</span><span class="ot">biography see</span><span class="co">](https://mathshistory.st-andrews.ac.uk/Biographies/Poisson/)</span></span>
<span id="cb32-601"><a href="#cb32-601" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-602"><a href="#cb32-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-603"><a href="#cb32-603" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hypergeometric Distribution</span></span>
<span id="cb32-604"><a href="#cb32-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-605"><a href="#cb32-605" aria-hidden="true" tabindex="-1"></a>\index{Hypergeometric Distribution}</span>
<span id="cb32-606"><a href="#cb32-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-607"><a href="#cb32-607" aria-hidden="true" tabindex="-1"></a>Consider an urn with $a$ white balls and $b$ black balls. Draw $N$ balls from this urn without replacement. The number white balls drawn, $n$ is Hypergeometrically distributed.</span>
<span id="cb32-608"><a href="#cb32-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-609"><a href="#cb32-609" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-610"><a href="#cb32-610" aria-hidden="true" tabindex="-1"></a>X \sim \mathrm{Hypergeometric}(n \mid N,a,b)</span>
<span id="cb32-611"><a href="#cb32-611" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-612"><a href="#cb32-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-613"><a href="#cb32-613" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-614"><a href="#cb32-614" aria-hidden="true" tabindex="-1"></a>\mathrm{Hypergeometric}(n\mid N,a,b) = \frac{\normalsize{\binom{a}{n} \binom{b}{N - n}}} {\normalsize{\binom{a + b}{N}}} \quad \text{(PDF)}</span>
<span id="cb32-615"><a href="#cb32-615" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-Hypergeometric-pdf}</span>
<span id="cb32-616"><a href="#cb32-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-617"><a href="#cb32-617" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-618"><a href="#cb32-618" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span>=N\frac{a}{a+b} \qquad \text{(expectation)}</span>
<span id="cb32-619"><a href="#cb32-619" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-Hypergeometric-expectation}</span>
<span id="cb32-620"><a href="#cb32-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-621"><a href="#cb32-621" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-622"><a href="#cb32-622" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span>=N\,\frac{ab}{(a + b)^2}\,\frac{a+b-N}{a+b-1} \qquad \text{(variance)}</span>
<span id="cb32-623"><a href="#cb32-623" aria-hidden="true" tabindex="-1"></a>$$ {#eq-l3-Hypergeometric-variance}</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"bottom","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>