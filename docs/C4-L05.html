<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="dcterms.date" content="2024-11-05">
<meta name="keywords" content="time series, stability, order of an AR process, characteristic lag polynomial, autocorrelation function, ACF, partial autocorrelation function, PACF, smoothing, State Space Model, ARMA process, ARIMA, moving average, AR(p) process, R code">
<meta name="description" content="The AR(P) process, its state-space representation, the characteristic polynomial, and the forecast function">

<title>92&nbsp; Bayesian Inference in the AR(p) - M2L5 – Bayesian Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C4-L05-Ex1.html" rel="next">
<link href="./C4-L04.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-923206e44a13b4518db4dede9f4ebdc9.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-987387ce273b62b48f1747d606bce1d5.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(images/banner_deep.jpg);
background-size: cover;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./C4-L05.html"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Bayesian Inference in the AR(p) - M2L5</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Bayesian Inference in the AR(p) - M2L5</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
            <p class="subtitle lead">Time Series Analysis</p>
                  <div>
        <div class="description">
          The AR(P) process, its state-space representation, the characteristic polynomial, and the forecast function
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Coursera</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">Bayesian Statistics</div>
                <div class="quarto-category">Autoregressive Models</div>
                <div class="quarto-category">Time Series</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 5, 2024</p>
      </div>
    </div>
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>time series, stability, order of an AR process, characteristic lag polynomial, autocorrelation function, ACF, partial autocorrelation function, PACF, smoothing, State Space Model, ARMA process, ARIMA, moving average, AR(p) process, R code</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Statistics</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Bayesian Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Paradigms of probability - M1L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayes’ Theorem - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Conditional Probability and Bayes’ Law - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Probability and Bayes’ Theorem - M1L2HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Distributions - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Random Variables - M1L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework on Distributions - M1L3HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Frequentist Inference - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Frequentist MLE - M2L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bayesian Inference - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Homework on Likelihoods and MLEs - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Homework on Bayesian Inference - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Priors - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Homework Posterior Probabilities - M3L6HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">M3L7 - Binomial Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Homework on Priors - M2L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Poisson Data - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Homework on Poisson Data - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Beta Bernoulli - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">M4L9 - Exponential Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Homework on Exponential Data - M4L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Normally distributed Data - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Homework on Normal Data - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Non-Informative Priors - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Homework Alternative Priors - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Brief Review of Regression - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Statistical Modeling - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">M1L2 - Bayesian Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Monte Carlo estimation - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Metropolis-Hastings - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Homework on the Metropolis-Hastings algorithm - M2L4HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Gibbs sampling - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Homework Gibbs-Sampling algorithm - M2L22HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Assessing Convergence - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Homework on the Gibbs-Sampling algorithm - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Homework on M-H algorithm M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Linear regression - M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Homework on Linear Regression Model Part 1 - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Homework on Deviance information criterion - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">ANOVA - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Homework on ANOVA - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Homework on Multiple Factor ANOVA - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Logistic regression - M3L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Homework on Logistic Regression - M3L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Poisson regression - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Homework on Poisson regression - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Hierarchical modeling - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Homework on Hierarchical Models - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Homework on Non-Normal Hierarchical Models - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Capstone Project - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Homework on Predictive distributions and mixture models - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Definitions of Mixture Models - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex1-Basic-Definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Basic Concepts of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex2-Gaussian-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Mixtures of Gaussians</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex3-Zero-Inflated-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Zero inflated distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex4-Def-mixture-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Definition of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Likelihood functions for Mixture Models - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Homework The Likelihood function - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Homework Identifiability - M1L2HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Homework The likelihood function M1L2HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Homework on simulating from a Poisson Mixture Model - M1L2HW4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">HW - Simulation of Poisson mixture model - M1L2HW5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Homework Sim mixture of exponential distributions - M1L2HW6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture models - M2L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">The EM algorithm for Zero-Inflated Mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">MCMC for Mixture Models - M4L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">The MCMC algorithm for Zero-Inflated Mixtures - M4L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Markov chain Monte Carlo algorithms for Mixture Models - M4L1HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Density Estimation - M4L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Clustering - M4L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Classification - M4L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the EM algorithm - M4L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the MCMC algorithms - M4L7HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Homework on Bayesian Mixture Models for Classification of Banknotes - M4L7HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Computational Considerations - M5L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Computational considerations for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Determining the number of components - M5L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Homework on Bayesian Information Criteria (BIC) - M5L09HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">Homework on Estimating the number of components in Bayesian settings - M5L09HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Homework on Estimating the partition structure in Bayesian models - M5L09HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Homework on BIC for zero-inflated mixtures - M5L09HW4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Week 0: Introductions to time series analysis and the AR(1) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Stationarity, The ACF and the PCF M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">The AR(1) process: definitions and properties - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">The AR(1): MLE and Bayesian inference - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">The AR(p) process - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Bayesian Inference in the AR(p) - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Quiz: Spectral representation of the AR(p) - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">Graded Assignment: Bayesian analysis of an EEG dataset using an AR(p) - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">Normal Dynamic Linear Models, Part 1 - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">96</span>&nbsp; <span class="chapter-title">Bayesian Inference in the NDLM: Part 1 M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">97</span>&nbsp; <span class="chapter-title">Seasonal NDLMs M4L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">98</span>&nbsp; <span class="chapter-title">Bayesian Inference in the NDLM: Part 2 - M4L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">99</span>&nbsp; <span class="chapter-title">Final Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">100</span>&nbsp; <span class="chapter-title">Week 0: Feynman Notebook on Bayesian Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">101</span>&nbsp; <span class="chapter-title">Appendix: Notation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">102</span>&nbsp; <span class="chapter-title">Appendix: Discrete Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">103</span>&nbsp; <span class="chapter-title">Appendix: Continuous Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">Appendix: Exponents &amp; Logarithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">105</span>&nbsp; <span class="chapter-title">Appendix: The Law of Large Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">106</span>&nbsp; <span class="chapter-title">Appendix: The Central Limit Theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">107</span>&nbsp; <span class="chapter-title">Appendix: Conjugate Priors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">108</span>&nbsp; <span class="chapter-title">Appendix: Link Function</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">109</span>&nbsp; <span class="chapter-title">Appendix: Bayes by backprop</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">110</span>&nbsp; <span class="chapter-title">Bayesian Books in R &amp; Python</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">111</span>&nbsp; <span class="chapter-title">Appendix: Yule-Walker Equations &amp; Durbin-Levinson Recursion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">112</span>&nbsp; <span class="chapter-title">Moore-Penrose Inversion &amp; Cholesky Decomposition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">113</span>&nbsp; <span class="chapter-title">Appendix: Inequalities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">114</span>&nbsp; <span class="chapter-title">Appendix: Wold’s theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">115</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#bayesian-inference-in-the-arp-reference-prior-conditional-likelihood" id="toc-bayesian-inference-in-the-arp-reference-prior-conditional-likelihood" class="nav-link active" data-scroll-target="#bayesian-inference-in-the-arp-reference-prior-conditional-likelihood"><span class="header-section-number">92.1</span> Bayesian inference in the AR(p): Reference prior, conditional likelihood 🎥</a>
  <ul class="collapse">
  <li><a href="#model-setup" id="toc-model-setup" class="nav-link" data-scroll-target="#model-setup"><span class="header-section-number">92.1.1</span> Model Setup</a></li>
  <li><a href="#conditional-likelihood" id="toc-conditional-likelihood" class="nav-link" data-scroll-target="#conditional-likelihood"><span class="header-section-number">92.1.2</span> Conditional likelihood</a></li>
  <li><a href="#regression-formulation" id="toc-regression-formulation" class="nav-link" data-scroll-target="#regression-formulation"><span class="header-section-number">92.1.3</span> Regression Formulation</a></li>
  <li><a href="#reference-prior-and-posterior-distribution" id="toc-reference-prior-and-posterior-distribution" class="nav-link" data-scroll-target="#reference-prior-and-posterior-distribution"><span class="header-section-number">92.1.4</span> Reference prior and posterior distribution</a></li>
  <li><a href="#simulation-based-inference" id="toc-simulation-based-inference" class="nav-link" data-scroll-target="#simulation-based-inference"><span class="header-section-number">92.1.5</span> Simulation-based Inference</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">92.1.6</span> Summary</a></li>
  </ul></li>
  <li><a href="#r-code-maximum-likelihood-estimation-arp-conditional-likelihood" id="toc-r-code-maximum-likelihood-estimation-arp-conditional-likelihood" class="nav-link" data-scroll-target="#r-code-maximum-likelihood-estimation-arp-conditional-likelihood"><span class="header-section-number">92.2</span> R code: Maximum likelihood estimation, AR(p), conditional likelihood 📖</a></li>
  <li><a href="#model-order-selection" id="toc-model-order-selection" class="nav-link" data-scroll-target="#model-order-selection"><span class="header-section-number">92.3</span> Model order selection 🎥</a>
  <ul class="collapse">
  <li><a href="#goal" id="toc-goal" class="nav-link" data-scroll-target="#goal"><span class="header-section-number">92.3.1</span> Goal</a></li>
  <li><a href="#step-1-define-a-candidate-set-of-model-orders" id="toc-step-1-define-a-candidate-set-of-model-orders" class="nav-link" data-scroll-target="#step-1-define-a-candidate-set-of-model-orders"><span class="header-section-number">92.3.2</span> Step 1: Define a candidate set of model orders</a></li>
  <li><a href="#step-2-estimate-residual-variance-for-each-model" id="toc-step-2-estimate-residual-variance-for-each-model" class="nav-link" data-scroll-target="#step-2-estimate-residual-variance-for-each-model"><span class="header-section-number">92.3.3</span> Step 2: Estimate residual variance for each model</a></li>
  <li><a href="#step-3-compute-model-selection-criteria" id="toc-step-3-compute-model-selection-criteria" class="nav-link" data-scroll-target="#step-3-compute-model-selection-criteria"><span class="header-section-number">92.3.4</span> Step 3: Compute model selection criteria</a></li>
  </ul></li>
  <li><a href="#example-bayesian-inference-in-the-arp-conditional-likelihood" id="toc-example-bayesian-inference-in-the-arp-conditional-likelihood" class="nav-link" data-scroll-target="#example-bayesian-inference-in-the-arp-conditional-likelihood"><span class="header-section-number">92.4</span> Example: Bayesian inference in the AR(p), conditional likelihood 🎥</a></li>
  <li><a href="#sec-arp-bayesian-inference" id="toc-sec-arp-bayesian-inference" class="nav-link" data-scroll-target="#sec-arp-bayesian-inference"><span class="header-section-number">92.5</span> code: Bayesian inference, AR(p), conditional likelihood 📖 ℛ</a>
  <ul class="collapse">
  <li><a href="#simulate-300-observations-from-an-ar2-with-one-pair-of-complex-valued-roots" id="toc-simulate-300-observations-from-an-ar2-with-one-pair-of-complex-valued-roots" class="nav-link" data-scroll-target="#simulate-300-observations-from-an-ar2-with-one-pair-of-complex-valued-roots"><span class="header-section-number">92.5.1</span> Simulate 300 observations from an AR(2) with one pair of complex-valued roots</a></li>
  <li><a href="#compute-the-mle-of-phi-and-the-unbiased-estimator-of-v-using-the-conditional-likelihood" id="toc-compute-the-mle-of-phi-and-the-unbiased-estimator-of-v-using-the-conditional-likelihood" class="nav-link" data-scroll-target="#compute-the-mle-of-phi-and-the-unbiased-estimator-of-v-using-the-conditional-likelihood"><span class="header-section-number">92.5.2</span> Compute the MLE of phi and the unbiased estimator of v using the conditional likelihood</a></li>
  <li><a href="#posterior-inference-conditional-likelihood-reference-prior-via-direct-sampling" id="toc-posterior-inference-conditional-likelihood-reference-prior-via-direct-sampling" class="nav-link" data-scroll-target="#posterior-inference-conditional-likelihood-reference-prior-via-direct-sampling"><span class="header-section-number">92.5.3</span> Posterior inference, conditional likelihood + reference prior via direct sampling</a></li>
  <li><a href="#graph-posterior-for-modulus-and-period" id="toc-graph-posterior-for-modulus-and-period" class="nav-link" data-scroll-target="#graph-posterior-for-modulus-and-period"><span class="header-section-number">92.5.4</span> Graph posterior for modulus and period</a></li>
  </ul></li>
  <li><a href="#sec-ar-2-model-order-selection" id="toc-sec-ar-2-model-order-selection" class="nav-link" data-scroll-target="#sec-ar-2-model-order-selection"><span class="header-section-number">92.6</span> code: Model order selection 📖 ℛ</a>
  <ul class="collapse">
  <li><a href="#simulate-data-from-an-ar2" id="toc-simulate-data-from-an-ar2" class="nav-link" data-scroll-target="#simulate-data-from-an-ar2"><span class="header-section-number">92.6.1</span> Simulate data from an AR(2)</a></li>
  <li><a href="#compute-mle-for-different-arps" id="toc-compute-mle-for-different-arps" class="nav-link" data-scroll-target="#compute-mle-for-different-arps"><span class="header-section-number">92.6.2</span> compute MLE for different AR(p)s</a></li>
  <li><a href="#compute-aic-and-bic-for-different-arps-based-on-simulated-data" id="toc-compute-aic-and-bic-for-different-arps-based-on-simulated-data" class="nav-link" data-scroll-target="#compute-aic-and-bic-for-different-arps-based-on-simulated-data"><span class="header-section-number">92.6.3</span> Compute AIC and BIC for different AR(p)s based on simulated data</a></li>
  <li><a href="#draw-plot-of-aic-bic-and-the-marginal-likelihood" id="toc-draw-plot-of-aic-bic-and-the-marginal-likelihood" class="nav-link" data-scroll-target="#draw-plot-of-aic-bic-and-the-marginal-likelihood"><span class="header-section-number">92.6.4</span> draw plot of AIC, BIC, and the marginal likelihood</a></li>
  </ul></li>
  <li><a href="#spectral-representation-of-the-arp" id="toc-spectral-representation-of-the-arp" class="nav-link" data-scroll-target="#spectral-representation-of-the-arp"><span class="header-section-number">92.7</span> Spectral representation of the AR(p) 🎥</a></li>
  <li><a href="#spectral-representation-of-the-arp-example" id="toc-spectral-representation-of-the-arp-example" class="nav-link" data-scroll-target="#spectral-representation-of-the-arp-example"><span class="header-section-number">92.8</span> Spectral representation of the AR(p): Example 🎥</a></li>
  <li><a href="#code-spectral-density-of-arp-ℛ" id="toc-code-spectral-density-of-arp-ℛ" class="nav-link" data-scroll-target="#code-spectral-density-of-arp-ℛ"><span class="header-section-number">92.9</span> code: Spectral density of AR(p) 📖 ℛ</a></li>
  <li><a href="#arima-processes" id="toc-arima-processes" class="nav-link" data-scroll-target="#arima-processes"><span class="header-section-number">92.10</span> ARIMA processes 📖</a>
  <ul class="collapse">
  <li><a href="#spectral-density-of-arma-processes" id="toc-spectral-density-of-arma-processes" class="nav-link" data-scroll-target="#spectral-density-of-arma-processes"><span class="header-section-number">92.10.1</span> Spectral Density of ARMA Processes</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<section id="bayesian-inference-in-the-arp-reference-prior-conditional-likelihood" class="level2 page-columns page-full" data-number="92.1">
<h2 data-number="92.1" class="anchored" data-anchor-id="bayesian-inference-in-the-arp-reference-prior-conditional-likelihood"><span class="header-section-number">92.1</span> Bayesian inference in the AR(p): Reference prior, conditional likelihood 🎥</h2>

<div class="no-row-height column-margin column-container"><div id="fig-ar-p-process" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-p-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/m2_0031.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;92.1: inference for AR(p)"><img src="images/m2_0031.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-p-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.1: inference for AR(p)
</figcaption>
</figure>
</div></div><section id="model-setup" class="level3" data-number="92.1.1">
<h3 data-number="92.1.1" class="anchored" data-anchor-id="model-setup"><span class="header-section-number">92.1.1</span> Model Setup</h3>
<p>we start with an AR(p) model as we define in the previous lesson: <span id="eq-arp-inf-model"><span class="math display">
y_t = \phi_1 y_{t-1} + \ldots + \phi_p y_{t-p} + \varepsilon_t \qquad \varepsilon_t \stackrel{iid}{\sim} \mathcal{N}(0, v)
\tag{92.1}</span></span></p>
<p>but now we wish to infer:</p>
<ul>
<li><span class="math inline">\phi_i</span> the <em>AR(p)</em> coefficients and</li>
<li><span class="math inline">v</span> the innovation variance.</li>
</ul>
</section>
<section id="conditional-likelihood" class="level3" data-number="92.1.2">
<h3 data-number="92.1.2" class="anchored" data-anchor-id="conditional-likelihood"><span class="header-section-number">92.1.2</span> Conditional likelihood</h3>
<p>We make use of the autoregressive structure and rewrite <span class="math inline">y_t</span> conditionally on the previous <span class="math inline">p</span> values of the process and the parameters:</p>
<p><span id="eq-arp-inf-cond"><span class="math display">
(y_t \mid y_{t-1}, \ldots, y_{t-p}, \phi_1, \ldots, \phi_p) \sim \mathcal{N}\left (\sum_{j=1}^{p} \phi_j y_{t-j}, v\right )
\tag{92.2}</span></span></p>
<p>We condition on the first <span class="math inline">p</span> values of the process. The conditional distribution of <span class="math inline">y_t</span> given the previous <span class="math inline">p</span> values and parameters is normal with mean given by the weighted sum <span class="math inline">\sum \phi_j y_{t-j}</span> and variance <span class="math inline">v</span>.</p>
<p>the density for the first <span class="math inline">p</span> observations is given by: <span id="eq-arp-inf-full-cond-likelihood"><span class="math display">
p(y_{(p+1):T}\mid y_{1:p}, \phi_1, \ldots, \phi_p, v) = \prod_{t=p+1}^{T} p(y_t | y_{t-1}, \ldots, y_{t-p}, \phi_1, \ldots, \phi_p, v)
\tag{92.3}</span></span></p>
<p>This product of conditionals yields the full conditional likelihood. Each term is Gaussian and independent, given the past values and parameters.</p>
</section>
<section id="regression-formulation" class="level3" data-number="92.1.3">
<h3 data-number="92.1.3" class="anchored" data-anchor-id="regression-formulation"><span class="header-section-number">92.1.3</span> Regression Formulation</h3>
<p>This is recast as a linear regression: response vector <span class="math inline">\mathbf{y}</span> starting from <span class="math inline">y_{p+1}</span> to <span class="math inline">y_T</span>, design matrix <span class="math inline">\mathbb{X}</span> built from lagged values, and <span class="math inline">\boldsymbol\beta</span> as the AR coefficients <span class="math inline">\phi_j</span>.</p>
<p><span id="eq-arp-inf-regression"><span class="math display">
\mathbf{y}= \mathbb{X}\boldsymbol \beta + \boldsymbol \varepsilon \qquad \varepsilon \sim \mathcal{N}(0, vI)
\tag{92.4}</span></span></p>
<p><span class="math display">
\mathbf{y} = \begin{pmatrix} y_{p+1} \\ y_{p+2} \\ \vdots \\ y_T \end{pmatrix}, \quad
\boldsymbol \beta = \begin{pmatrix} \phi_1 \\ \phi_2 \\ \vdots \\ \phi_p \end{pmatrix}, \quad
\mathbb{X} = \begin{pmatrix} y_{p} &amp; y_{p-1} &amp; \cdots &amp; y_{1} \\ y_{p+1} &amp; y_{p} &amp; \cdots &amp; y_{2} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ y_{T-1} &amp; y_{T-2} &amp; \cdots &amp; y_{T-p} \end{pmatrix}
</span></p>
<p>In the design matrix <span class="math inline">\mathbb{X}</span> each row corresponds to lagged observations used to predict the next value. This setup enables applying linear regression machinery.</p>
<p>we can now infer the parameters by using the left generalized Moore Penrose inverse of <span class="math inline">\mathbb{X}</span> to obtain the maximum likelihood estimator (MLE) of the AR coefficients <span class="math inline">\boldsymbol \beta</span> Assuming full-rank <span class="math inline">\mathbb{X}</span>, this is the MLE.</p>
<p><span id="eq-arp-inf-regression-mle"><span class="math display">
\boldsymbol \beta_{MLE} = (\mathbb{X}^\top \mathbb{X})^{-1} \mathbb{X}^\top \mathbf{y}
\tag{92.5}</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\mathbb{X}</span> is the design matrix,</li>
<li><span class="math inline">\boldsymbol \beta</span> is the vector of AR coefficients, and</li>
<li><span class="math inline">\mathbf{y}</span> is the response vector.</li>
</ul>
<p>It matches the usual OLS solution in linear regression.</p>
</section>
<section id="reference-prior-and-posterior-distribution" class="level3" data-number="92.1.4">
<h3 data-number="92.1.4" class="anchored" data-anchor-id="reference-prior-and-posterior-distribution"><span class="header-section-number">92.1.4</span> Reference prior and posterior distribution</h3>
<p>The reference prior reflects non-informative beliefs. This yields a conjugate posterior due to the Gaussian likelihood.</p>
<p><span id="eq-arp-inf-prior"><span class="math display">
p(\beta,v) \propto 1/v
\tag{92.6}</span></span></p>
<p><span id="eq-arp-inf-posterior-beta"><span class="math display">
(\boldsymbol \beta | \mathbf{y}_{:T}, v) \sim \mathcal{N}(\boldsymbol \beta_{MLE}, v (\mathbb{X}^\top \mathbb{X})^{-1})
\tag{92.7}</span></span></p>
<p>The posterior is Gaussian with mean <span class="math inline">\boldsymbol \beta_{MLE}</span> and scaled covariance <span class="math inline">v(\mathbb{X}^\top \mathbb{X})^{-1}</span>, analogous to the OLS variance.</p>
<p><span id="eq-arp-inf-posterior-v"><span class="math display">
(v | \mathbf{y}_{:T}) \sim \text{Inverse-Gamma}\left(\frac{T - 2p}{2}, \frac{S^2}{2}\right)
\tag{92.8}</span></span></p>
<p>where:</p>
<ul>
<li><span class="math inline">S^2 = \sum_{t=p+1}^{T} (y_t - \mathbb{X} \boldsymbol \beta_{MLE})^2</span> is the unbiased estimator of the variance <span class="math inline">v</span>.</li>
<li><span class="math inline">T</span> is the total number of observations.</li>
</ul>
<p>Posterior for <span class="math inline">v</span> is inverse gamma. The shape parameter is <span class="math inline">(T - 2p)/2</span> because the number of residual degrees of freedom is <span class="math inline">T - 2p</span> (residual = <span class="math inline">T-p</span> obs minus <span class="math inline">p</span> params). Scale is half the sum of squared residuals.</p>
</section>
<section id="simulation-based-inference" class="level3" data-number="92.1.5">
<h3 data-number="92.1.5" class="anchored" data-anchor-id="simulation-based-inference"><span class="header-section-number">92.1.5</span> Simulation-based Inference</h3>
<p>Posterior sampling:</p>
<ul>
<li>Draw <span class="math inline">v</span> from the inverse gamma posterior.</li>
<li>Plug <span class="math inline">v</span> into the posterior of <span class="math inline">\boldsymbol\beta</span> and sample from the Gaussian.</li>
</ul>
<p>This gives full Bayesian posterior samples of <span class="math inline">(\boldsymbol\beta, v)</span>.</p>
</section>
<section id="summary" class="level3" data-number="92.1.6">
<h3 data-number="92.1.6" class="anchored" data-anchor-id="summary"><span class="header-section-number">92.1.6</span> Summary</h3>
<ul>
<li>In this lesson, we discussed the Bayesian inference for the AR(p) process using the conditional likelihood and reference prior.</li>
<li>We have established a connection between the AR(p) process and a regression model, allowing us to use standard regression techniques to estimate the parameters.</li>
<li>The posterior distribution can be derived, and we can perform simulation-based inference to obtain samples from the posterior distribution of the AR coefficients and variance.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<!-- TODO: summarize this transcript -->
<p>We can now think about Bayesian in the general case of an AR(P) process. In the Bayesian in case, we have two choices to make first what kind of likelihood we are going to be using and then what kind of prior distribution we’re going to be using for the model parameters. I’m going to discuss the case in which we use the conditional likelihood. We have to condition this time on the first p values of the process. And then I’m also going to discuss the case in which we use the reference prior for the model parameters. As in the AR(1) case, there is a correspondence between that conditional likelihood setting and the regression model. So recall we can write down the process, Like this. So, And the assumption is that the epsilon t are iid normally distributed random variables with zero mean and variance v. So that’s the variance of the process. The parameters of the process are going to be all the phi’s, And the variance of the process. So we want to make inference on those parameters. What we know given the conditional dependency structure and past values of the series, is that if I think about the distribution of yt, given yt -1 all the way to y t-p.&nbsp;And then also given the phi’s, And v, this is a normally distributed, Random variable with the mean is going to be the sum, Of these. Past values weighted by the phi’s, And then I have variance v here. So now that I use this conditionally independent structure, I can write a likelihood function as the product of these terms. So if I think about my density here for y p+1 all the way to capital T. So let’s assume that we have capital T, we have observed capital T. Data points and then we are conditioning on y1. And p, all the first p observations and all the phi’s again and v. I can write this as the product of all these terms. All these are are going to have a normal density given by this expression. So as we said before, there is a correspondence between this likelihood function, the conditional likelihood and a regression model of the form y=Xbeta +epsilon. Where y here is a vector, X matrix, beta is a vector and epsilon is another vector with this vector being multivariate normal. And then we’re going to have a v times the identity. So I can write down this expression and make a a connection with this model by simply setting y. Again, because I’m conditioning on the first p values. I’m going to start with yp+1, yp+2 and so on all the way to yT. Then here my beta is the vector that goes with the coefficients. In this case, the linear component has to do with the phi’s. So it’s going to be my beta with all the phi’s. And those are the AR parameters that we want to estimate. And then I’m going to have an X matrix. The design matrix here for the linear regression in the case of an AR(P), again, if I think about the first row is going to be related to the yp+1. So we are regressing on the past p values. So it’s going to go from yp, All the way, so that’s the first row, to y1. Then for y p+2, I’m going to have something similar and then I go all the way down to yT. And so I’m going to have yT -1, -2 all the way to yT-p.&nbsp;So this is my X matrix. So as you know, I can find my maximum likelihood estimator for this process. Which I’m just simply going to call beta hat, its going to be assuming that the design matrix is full rank. We can write it down like this. So we can simply just plug in this X and this y vector to obtain the maximum likelihood estimator of the model parameters for the AR coefficients. And then using these results, we can also write the posterior distribution using a reference prior. So again, this gives me the likelihood. The reference prior assumes that we are going to use a prior of this form. And in this case, the Bayesian inference can be done by writing down the density of the beta given all the y’s and v. This is going to be normally distributed. The mean it’s going to be beta hat, which is the maximum likelihood estimator. And then I have my v times X transpose X inverse. And then I have my marginal distribution for v given all the observations here, it’s going to be an inverse gamma. And then the parameters for the inverse gamma distribution are going to be related to, again, you think about what is the dimension of the vector here y. In the case of the AR(p) I have something that is dimension T- p.&nbsp;So that’s the first dimension that we are going to consider. But then we also have to subtract the dimension of the beta vector which is p.&nbsp;So I’m going to have T -p-p, which gives me my 2p here. And then I have the other component is my s square over 2. So once again, if I want to do simulation based posterior inference, I can simply get a sample of v from this inverse gamma distribution. And then I plug in that sample here and I get a sample for the AR coefficients. So I can get full posterior inference in this way.</p>
</div>
</div>
</div>
</section>
</section>
<section id="r-code-maximum-likelihood-estimation-arp-conditional-likelihood" class="level2" data-number="92.2">
<h2 data-number="92.2" class="anchored" data-anchor-id="r-code-maximum-likelihood-estimation-arp-conditional-likelihood"><span class="header-section-number">92.2</span> R code: Maximum likelihood estimation, AR(p), conditional likelihood 📖</h2>
<p></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate 300 observations from an AR(2) with one pair of complex-valued reciprocal roots </span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>]<span class="ot">=</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># generate stationary AR(2) process</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Compute the MLE for phi and the unbiased estimator for v using the conditional likelihood</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>p<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(p<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>p),T<span class="sc">-</span>p)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>p<span class="dv">-1</span>)),<span class="fu">rep</span>(p,T<span class="sc">-</span>p)))],p,T<span class="sc">-</span>p));</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>XtX<span class="ot">=</span><span class="fu">t</span>(X)<span class="sc">%*%</span>X</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>XtX_inv<span class="ot">=</span><span class="fu">solve</span>(XtX)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span>XtX_inv<span class="sc">%*%</span><span class="fu">t</span>(X)<span class="sc">%*%</span>y <span class="co"># MLE for phi</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> p) <span class="co">#unbiased estimate for v</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of conditional likelihood for phi: "</span>, phi_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate for v: "</span>, s2, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
 MLE of conditional likelihood for phi:  1.65272 -0.9189823 
 Estimate for v:  0.9901292 </code></pre>
</div>
</div>
</section>
<section id="model-order-selection" class="level2 page-columns page-full" data-number="92.3">
<h2 data-number="92.3" class="anchored" data-anchor-id="model-order-selection"><span class="header-section-number">92.3</span> Model order selection 🎥</h2>

<div class="no-row-height column-margin column-container"><div id="fig-ar-p-model-order-selection" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-p-model-order-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/m2_0032.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;92.2: model order selection"><img src="images/m2_0032.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-p-model-order-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.2: model order selection
</figcaption>
</figure>
</div></div><section id="goal" class="level3" data-number="92.3.1">
<h3 data-number="92.3.1" class="anchored" data-anchor-id="goal"><span class="header-section-number">92.3.1</span> Goal</h3>
<p>Determine the best model order <span class="math inline">p</span> for an AR(<span class="math inline">p</span>) process by comparing candidate models.</p>
</section>
<section id="step-1-define-a-candidate-set-of-model-orders" class="level3" data-number="92.3.2">
<h3 data-number="92.3.2" class="anchored" data-anchor-id="step-1-define-a-candidate-set-of-model-orders"><span class="header-section-number">92.3.2</span> Step 1: Define a candidate set of model orders</h3>
<p><span class="math display">
p^* \qquad p=1:p^*
</span></p>
<p>You choose a maximum order <span class="math inline">p^*</span> (e.g., 20), then evaluate AR models of each order <span class="math inline">p \in {1, \dots, p^*}</span>.</p>
</section>
<section id="step-2-estimate-residual-variance-for-each-model" class="level3" data-number="92.3.3">
<h3 data-number="92.3.3" class="anchored" data-anchor-id="step-2-estimate-residual-variance-for-each-model"><span class="header-section-number">92.3.3</span> Step 2: Estimate residual variance for each model</h3>
<p><span class="math display">
S^2_p \qquad y_{(p^*+1):T}
</span></p>
<p>For each model of order <span class="math inline">p</span>, compute <span class="math inline">S_p^2</span> as the residual sum of squares (RSS) using a fixed evaluation window: <span class="math inline">t = p^*+1</span> to <span class="math inline">T</span>, to ensure all models are evaluated on the same data subset.</p>
</section>
<section id="step-3-compute-model-selection-criteria" class="level3" data-number="92.3.4">
<h3 data-number="92.3.4" class="anchored" data-anchor-id="step-3-compute-model-selection-criteria"><span class="header-section-number">92.3.4</span> Step 3: Compute model selection criteria</h3>
<p>AIC balances fit (log-likelihood) with complexity (number of parameters). The first term measures model fit using <span class="math inline">\log(S_p^2)</span>, and the second term penalizes complexity with <span class="math inline">2p</span>.</p>
<p><span class="math display">
AIC_p = (T-p^*) \log(S_p^2) + 2p
</span></p>
<p>BIC uses the same fit term but a heavier penalty: <span class="math inline">p \log(T - p^*)</span>, which increases with sample size. This often leads BIC to favor smaller models than AIC.</p>
<p><span class="math display">
BIC_p = (T-p^*) \log(S_p^2) + p \log(T-p^*)
</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>One of the big questions when you’re working with autoregressive processes is what model order you should use for your particular data. One thing that you can do is you can look at the sample ACF and PACF of the data that you have and try to begin with a model order that reflects, the behavior that you see in those sample ACF’s and PACF’s. But you can also have a more formal approach in which you consider using model order selection criteria. Model selection criteria to pick the model order. You could even also be more sophisticated and assume that the model order is also uncertain and consider that as a random variable. Put a prior on that random variable, and then perform Bayesian inference. I’m going to just discuss here how we can use two model selection criteria. One is the AIC, Akaike’s Information Criterion, and the other one is BIC, to choose the model order. These are usually implemented in software packages in R and you can use them in practice for your given data. The first thing is if you’re working with the conditional likelihood, you can also work with the full likelihood. But if you’re working with the conditional likelihood, you have to evaluate these model selection criteria using the same data. Let’s say that you have a set candidate of models. You have to pick a maximum model order, I’m going to call that p-star. For example, you could have p-star to be 20. Then you’re going to consider all the possible orders from 0-20. So your model orders that you will be considering go from one or from zero all the way to p-star. Here for each of those model orders that you consider, if you’re working with a conditional likelihood, you’re going to have estimates of the model parameters. You’re going to have your phi hats using maximum likelihood estimation. For each of those model orders, you’re going to have Sp, I’m going to call it Sp square. It’s your S square that you get from each of those model orders. Now p here, I’m putting that subscript there just to indicate that this is related to the model with model order p.&nbsp;Then you can evaluate everything using your data and your data for evaluation here is going to go from p star plus 1 all the way to T. It’s important that you just use this data when you’re computing your regressions so that you evaluate everything on the same set of data points. You can write down the Akaike’s Information Criterion in this case, is a function that is going to have two components. One has to do with how good is the fit of the model. The other one is penalizing the number of parameters you have in the model. Usually in these model selection criteria, we have those two components. You can write this down as the number of observations you have, which is, again, we’re conditioning on the first p star observations. We’re only going to evaluate this on the Data starting from p star plus 1 up to T. Then you’re going to have the log of that Sp squared. That’s the part of the AIC that has to do with the goodness of fit. Then there is a penalty for the number of parameters. In this case, AIC uses a penalty of two times p.&nbsp;What you do is you fit all these model orders. It can go from one to p star, from zero to p star if you want to incorporate the white noise component as well. Then you just get an AIC for each of these, and then you compare all of those. There is going to be essentially a value for each of these p.&nbsp;Then you look at the optimal value is the one that minimizes that AIC expression. You look at those values, you pick the model order that minimizes the AIC. You can also use BIC. In the BIC, you’re going to have the same component here related to the goodness of fit. You’re going to have the same piece. But now BIC is going to penalize the number of parameters in the model in a different way. You’re going to have something that looks like p log of the T minus p star. Here we had a penalty. We had two times the number of parameters. Here we have the number of parameters times something that depends on the number of observations you have. It’s a different penalty. You may get different results again here you evaluate your BIC for each of the model orders you are considering, and then you pick the model order that minimizes this expression. As you can see, what happens is there is a balance usually between the more parameters you consider, the better is going to be your model fit. But you have that penalty that you are overfitting, you maybe overfitting, you have too many parameters in your model. These model selection criteria try to balance those components and give a penalty for the number of parameters. When you run things in practice, you may get the same model order, the same optimal model order for AIC or BIC, or you may get different numbers. You can also look at other quantities. You can look at posterior predictive distributions and see how well the model does in terms of those posterior predictive densities. You can, as I said before, think about considering p as another variable in your model. We will stay simple here, and we will consider just these model selection criteria.</p>
</div>
</div>
</div>
</section>
</section>
<section id="example-bayesian-inference-in-the-arp-conditional-likelihood" class="level2" data-number="92.4">
<h2 data-number="92.4" class="anchored" data-anchor-id="example-bayesian-inference-in-the-arp-conditional-likelihood"><span class="header-section-number">92.4</span> Example: Bayesian inference in the AR(p), conditional likelihood 🎥</h2>
<p>This video demonstrates walks through the code in the next section.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We now talk about how to obtain maximum likelihood estimation and Bayesian inference using the conditional likelihood function in this case of the AR2 process. In this particular example is the a AR2. Here I’m first again, just sampling from a specific AR2 process so that we have the data here. I’m using an AR2 with one pair of complex reciprocal roots. The modulus of the reciprocal root is 0.95 and the period is 12, so we’re going to observe this quasi-periodicity in the sampled time series. Then these are 300 observations, the standard deviation of the innovation is one, and we are using the arima.sim function as before. As you recall, in the case of the conditional likelihood we have a correspondence between the conditional likelihood and the equations of the linear regression model. Here I’m just applying the equations we discussed before and we can write everything in terms of a regression model in vector form. So we have a response y and X design matrix and then we obtain, just reading in, so I’m looking at as a conditional likelihood so I’m going to condition on the first P observations. P in this particular case is two and I have my X matrix and my maximum likelihood estimator for Phi is just obtained using the equation X transpose X_inverse times X transpose y. This is my MLE for the AR coefficients, and then I have the unbiased estimator for v which we called S2 here using again, the equations that we discussed before. If you look at the estimates, again the AR coefficients, the true values of the AR coefficients, we can compare with the estimated AR coefficients so the true values are here in the Phi and the true value is for the AR coefficient in the first lag. The Phi 1 is about 1.65 which is what we obtain also in the maximum likelihood estimate using the conditional likelihood, and then the second coefficient is around negative 0.9 which is again close to what we get in terms of the estimate of the maximum likelihood estimator. s square is an estimate for v and here the true variance is one. Again this is based estimator using all these is based on these data that we simulated. Now we can just run in the case of the AR2 we can obtain posterior inference using these conditional likelihood and the reference prior, and in that case we can do everything using direct sampling. I’m going to use the library MASS here just to use the functions to sample random variables from that library. If you recall the form of the posterior distribution is such that the marginal for the variance given the data is just an inverse Gamma distribution so we can sample from this inverse Gamma using the function rgamma and then taking the inverse of that with the corresponding parameters that we have discussed again, the equations before. In the step 2, conditional on v, we can sample Phi from a normal distribution in this case is a multivariate normal bivariate in this case since we have an AR2, and here I’m just simply obtaining samples from that distribution. I set the number of samples to be 1,000. You can choose as many or as few posterior samples as you want. Then based on these we can look at posterior estimates in terms of graphical representations of those like we can look at these histograms of the samples for Phi and the variance. Here we can see if we zoom in here I have three histograms, the first one is the histogram that corresponds to the samples of the first AR coefficient Phi_1, the red line corresponds to the true value and this is just the posterior distribution for Phi_1. Similarly this histogram gives me representation of the posterior distribution for Phi_2 based on those 1,000 samples from the posterior distribution. Then I have also the samples for the v and then the true value which is one. We can see that we’re getting those estimates and we can then look also at graphical representations for functions of those parameters. For example, we could also summarize the posterior distribution for the modulus and the period of the reciprocal roots of the characteristic polynomial. So in this case, the good thing with simulation-based posterior sampling is that if we have the samples of the AR coefficients and the variance, we can simply just do any transformations for any functions of those and obtain the posterior summaries of those transform values. In this case, the modulus, we can obtain it using a transformation of the Phi_2 coefficients so if we have samples of those we can just look at those, and then for the period we can also do the same so this is a function now of the modulus and this first coefficient so we just look at that and then can obtain just the summaries of those histograms for the posterior distribution of the modulus. We can see here the true value was 0.95 and this is a histogram with the posterior samples for that modulus based on those 1,000 samples from the posterior, and this is what I get in terms of the histogram for the period. The true value for the period was 12 in this particular example. This gives you also uncertainty quantification for those parameters of the distribution. Another thing we discussed is we can fix the model order and then obtain posterior inference but in practice we usually also have uncertainty on the model order and we said, well, we can use different procedures to try to look at that problem. One of the methods that we can use is just pick the model order using some model selection criteria. This code just looks at how you can use AIC and BIC for finding the optimal model order and then conditional on that optimal model order then you can proceed with your posterior inference. In this case, again, this is for the simulated dataset, I’m going to assume that I don’t know the model order and we’re going to set the maximum model order to be 10. I’m going to be searching for the optimal model order in AR models that have a maximum model order of 10 and then we will see what happens here. For each of those model orders I can just keep all the matrices, the X matrix and the Y matrix just to proceed with the maximum likelihood inference, and the maximum likelihood inference is just using I just created this function here to compute the MLE and it returns essentially all the quantities that we need to have here, the degrees of freedom, the residuals, the MLE, and so on for a given model order with a given structure in terms of the X which depends on the data that you have and the Y that also depends on the data that you have. There is this AIC BIC function that simply uses calls this MLE function and then computes the AIC and the BIC with different penalties. As we said, if you look a little bit inside this function you will see that the AIC has a penalty in terms of the number of parameters in the model which is 2 times P and in this case we have a log N times P, so this is just how to compute this AIC. So it’s just again computing those. Based on this information that we have we can plot the AIC and the BIC for different values of the model orders and highlight in this case we’re looking at the minimizes, so is the difference between the value and the minimum value of the AIC. In this case, we want to look at the value that minimizes this quantity and we see that the model order for both the AIC and the BIC, the optimal model order happens to be two. Once we have that optimal model order we can then say, well, I can choose the model order that minimizes one of the two criteria and then in this case I’m choosing BIC. For this particular example, both model selection criteria are giving me the same answer in terms of the model order, this doesn’t have to be the case for all the datasets so you will have different answers in terms of what AIC is telling you is the optimal model order and what BIC is telling you that is the optimal model order. In this example, they gives you the same answer. Then you can proceed with the posterior mean, the maximum likelihood estimation, the reference and the posterior mean, and the posterior mean of the standard deviation, and then you can look at estimates also based on those posterior means of the AR coefficients, you can obtain the estimate for the modulus and the period of the reciprocal roots, so I’m just here using that optimal model order looking at estimates of those based on the posterior distribution. Here again, you can just pick one of the two model selection criteria to obtain your optimal model order and then do your inference conditional on that.</p>
</div>
</div>
</div>
</section>
<section id="sec-arp-bayesian-inference" class="level2" data-number="92.5">
<h2 data-number="92.5" class="anchored" data-anchor-id="sec-arp-bayesian-inference"><span class="header-section-number">92.5</span> code: Bayesian inference, AR(p), conditional likelihood 📖 ℛ</h2>
<section id="simulate-300-observations-from-an-ar2-with-one-pair-of-complex-valued-roots" class="level3" data-number="92.5.1">
<h3 data-number="92.5.1" class="anchored" data-anchor-id="simulate-300-observations-from-an-ar2-with-one-pair-of-complex-valued-roots"><span class="header-section-number">92.5.1</span> Simulate 300 observations from an AR(2) with one pair of complex-valued roots</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>]<span class="ot">=</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># generate stationary AR(2) process</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-ar-bayesian-inference" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-bayesian-inference-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C4-L05_files/figure-html/fig-ar-bayesian-inference-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;92.3: Simulated AR(2) process with complex-valued roots"><img src="C4-L05_files/figure-html/fig-ar-bayesian-inference-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-bayesian-inference-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.3: Simulated AR(2) process with complex-valued roots
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="compute-the-mle-of-phi-and-the-unbiased-estimator-of-v-using-the-conditional-likelihood" class="level3" data-number="92.5.2">
<h3 data-number="92.5.2" class="anchored" data-anchor-id="compute-the-mle-of-phi-and-the-unbiased-estimator-of-v-using-the-conditional-likelihood"><span class="header-section-number">92.5.2</span> Compute the MLE of phi and the unbiased estimator of v using the conditional likelihood</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>p<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(p<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>p),T<span class="sc">-</span>p)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>p<span class="dv">-1</span>)),<span class="fu">rep</span>(p,T<span class="sc">-</span>p)))],p,T<span class="sc">-</span>p));</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>XtX<span class="ot">=</span><span class="fu">t</span>(X)<span class="sc">%*%</span>X</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>XtX_inv<span class="ot">=</span><span class="fu">solve</span>(XtX)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span>XtX_inv<span class="sc">%*%</span><span class="fu">t</span>(X)<span class="sc">%*%</span>y <span class="co"># MLE for phi</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>phi_MLE</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]
[1,]  1.6527203
[2,] -0.9189823</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> p) <span class="co">#unbiased estimate for v</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>s2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9901292</code></pre>
</div>
</div>
</section>
<section id="posterior-inference-conditional-likelihood-reference-prior-via-direct-sampling" class="level3" data-number="92.5.3">
<h3 data-number="92.5.3" class="anchored" data-anchor-id="posterior-inference-conditional-likelihood-reference-prior-via-direct-sampling"><span class="header-section-number">92.5.3</span> Posterior inference, conditional likelihood + reference prior via direct sampling</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">1000</span> <span class="co"># posterior sample size</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample v from inverse gamma distribution</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span><span class="sc">*</span>p)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((y<span class="sc">-</span>X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample phi conditional on v from normal distribution</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n_sample, <span class="at">ncol =</span> p)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  phi_sample[i, ]<span class="ot">=</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>,phi_MLE,<span class="at">Sigma=</span>v_sample[i]<span class="sc">*</span>XtX_inv)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>),  <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="do">## plot histogram of posterior samples of phi and v</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>){</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hist</span>(phi_sample[, i], <span class="at">xlab =</span> <span class="fu">bquote</span>(phi), </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Histogram of "</span><span class="sc">~</span>phi[.(i)]),<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v =</span> phi[i], <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(v_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(nu), <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Histogram of "</span><span class="sc">~</span>v),<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> sd, <span class="at">col =</span> <span class="st">'red'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-ar-bayesian-inference-posterior" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-bayesian-inference-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C4-L05_files/figure-html/fig-ar-bayesian-inference-posterior-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;92.4: Posterior distributions of AR(2) parameters"><img src="C4-L05_files/figure-html/fig-ar-bayesian-inference-posterior-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-bayesian-inference-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.4: Posterior distributions of AR(2) parameters
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="graph-posterior-for-modulus-and-period" class="level3" data-number="92.5.4">
<h3 data-number="92.5.4" class="anchored" data-anchor-id="graph-posterior-for-modulus-and-period"><span class="header-section-number">92.5.4</span> Graph posterior for modulus and period</h3>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>r_sample<span class="ot">=</span><span class="fu">sqrt</span>(<span class="sc">-</span>phi_sample[,<span class="dv">2</span>])</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>lambda_sample<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="fu">acos</span>(phi_sample[,<span class="dv">1</span>]<span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span>r_sample))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(r_sample,<span class="at">xlab=</span><span class="st">"modulus"</span>,<span class="at">main=</span><span class="st">""</span>,<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fl">0.95</span>,<span class="at">col=</span><span class="st">'red'</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(lambda_sample,<span class="at">xlab=</span><span class="st">"period"</span>,<span class="at">main=</span><span class="st">""</span>,<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">12</span>,<span class="at">col=</span><span class="st">'red'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ar-bayesian-inference-roots" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-bayesian-inference-roots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ar-bayesian-inference-roots" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ar-bayesian-inference-roots-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ar-bayesian-inference-roots-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C4-L05_files/figure-html/fig-ar-bayesian-inference-roots-1.png" class="lightbox" data-gallery="fig-ar-bayesian-inference-roots" title="Figure&nbsp;92.5&nbsp;(a): modulus"><img src="C4-L05_files/figure-html/fig-ar-bayesian-inference-roots-1.png" class="img-fluid figure-img" data-ref-parent="fig-ar-bayesian-inference-roots" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ar-bayesian-inference-roots-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) modulus
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ar-bayesian-inference-roots" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ar-bayesian-inference-roots-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ar-bayesian-inference-roots-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C4-L05_files/figure-html/fig-ar-bayesian-inference-roots-2.png" class="lightbox" data-gallery="fig-ar-bayesian-inference-roots" title="Figure&nbsp;92.5&nbsp;(b): period"><img src="C4-L05_files/figure-html/fig-ar-bayesian-inference-roots-2.png" class="img-fluid figure-img" data-ref-parent="fig-ar-bayesian-inference-roots" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ar-bayesian-inference-roots-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) period
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-bayesian-inference-roots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.5: Posterior distributions of AR(2) roots
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-ar-2-model-order-selection" class="level2" data-number="92.6">
<h2 data-number="92.6" class="anchored" data-anchor-id="sec-ar-2-model-order-selection"><span class="header-section-number">92.6</span> code: Model order selection 📖 ℛ</h2>
<section id="simulate-data-from-an-ar2" class="level3" data-number="92.6.1">
<h3 data-number="92.6.1" class="anchored" data-anchor-id="simulate-data-from-an-ar2"><span class="header-section-number">92.6.1</span> Simulate data from an AR(2)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>]<span class="ot">=</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># generate stationary AR(2) process</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-ar-2-model-order-selection-simulation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-2-model-order-selection-simulation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C4-L05_files/figure-html/fig-ar-2-model-order-selection-simulation-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;92.6: Simulated AR(2) process with complex-valued roots"><img src="C4-L05_files/figure-html/fig-ar-2-model-order-selection-simulation-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-2-model-order-selection-simulation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.6: Simulated AR(2) process with complex-valued roots
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="compute-mle-for-different-arps" class="level3" data-number="92.6.2">
<h3 data-number="92.6.2" class="anchored" data-anchor-id="compute-mle-for-different-arps"><span class="header-section-number">92.6.2</span> compute MLE for different AR(p)s</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>pmax<span class="ot">=</span><span class="dv">10</span> <span class="co"># the maximum of model order</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>Xall<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>pmax),T<span class="sc">-</span>pmax)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>pmax<span class="dv">-1</span>)),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>              <span class="fu">rep</span>(pmax,T<span class="sc">-</span>pmax)))], pmax, T<span class="sc">-</span>pmax));</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(pmax<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T])</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>n_cond<span class="ot">=</span><span class="fu">length</span>(y) <span class="co"># (number of total time points - the maximum of model order)</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="do">## compute MLE</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>my_MLE <span class="ot">&lt;-</span> <span class="cf">function</span>(y, Xall, p){</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  n<span class="ot">=</span><span class="fu">length</span>(y)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span>Xall[,<span class="dv">1</span><span class="sc">:</span>p]</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  a<span class="ot">=</span><span class="fu">solve</span>(<span class="fu">t</span>(x) <span class="sc">%*%</span>x)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  a<span class="ot">=</span>(a <span class="sc">+</span> <span class="fu">t</span>(a))<span class="sc">/</span><span class="dv">2</span> <span class="co"># for numerical stability </span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  b<span class="ot">=</span>a<span class="sc">%*%</span><span class="fu">t</span>(x)<span class="sc">%*%</span>y <span class="co"># mle for ar coefficients</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  r<span class="ot">=</span>y <span class="sc">-</span> x<span class="sc">%*%</span>b <span class="co"># residuals </span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  nu<span class="ot">=</span>n <span class="sc">-</span> p <span class="co"># degrees freedom</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  R<span class="ot">=</span><span class="fu">sum</span>(r<span class="sc">*</span>r) <span class="co"># SSE</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  s<span class="ot">=</span>R<span class="sc">/</span>nu <span class="co">#MSE</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">b =</span> b, <span class="at">s =</span> s, <span class="at">R =</span> R, <span class="at">nu =</span> nu))</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="compute-aic-and-bic-for-different-arps-based-on-simulated-data" class="level3" data-number="92.6.3">
<h3 data-number="92.6.3" class="anchored" data-anchor-id="compute-aic-and-bic-for-different-arps-based-on-simulated-data"><span class="header-section-number">92.6.3</span> Compute AIC and BIC for different AR(p)s based on simulated data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="do">## function for AIC and BIC computation </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>AIC_BIC <span class="ot">&lt;-</span> <span class="cf">function</span>(y, Xall, p){</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="do">## number of time points</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute MLE</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  tmp<span class="ot">=</span><span class="fu">my_MLE</span>(y, Xall, p)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  <span class="do">## retrieve results</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  R<span class="ot">=</span>tmp<span class="sc">$</span>R</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute likelihood</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  likl<span class="ot">=</span> n<span class="sc">*</span><span class="fu">log</span>(R)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute AIC and BIC</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  aic <span class="ot">=</span>likl <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(p)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  bic <span class="ot">=</span>likl <span class="sc">+</span> <span class="fu">log</span>(n)<span class="sc">*</span>(p)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">aic =</span> aic, <span class="at">bic =</span> bic))</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute AIC, BIC </span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>aic <span class="ot">=</span><span class="fu">numeric</span>(pmax)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>bic <span class="ot">=</span><span class="fu">numeric</span>(pmax)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(p <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>pmax){</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">=</span><span class="fu">AIC_BIC</span>(y,Xall, p)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>  aic[p] <span class="ot">=</span>tmp<span class="sc">$</span>aic</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  bic[p] <span class="ot">=</span>tmp<span class="sc">$</span>bic</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">c</span>(p, aic[p], bic[p])) <span class="co"># print AIC and BIC by model order</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]    1.000 2166.793 2170.463
[1]    2.000 1635.816 1643.156
[1]    3.000 1637.527 1648.536
[1]    4.000 1639.059 1653.738
[1]    5.000 1640.743 1659.093
[1]    6.000 1641.472 1663.491
[1]    7.000 1643.457 1669.147
[1]    8.000 1645.370 1674.729
[1]    9.000 1646.261 1679.290
[1]   10.000 1647.915 1684.614</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="do">## compute difference between the value and its minimum</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>aic <span class="ot">=</span>aic<span class="sc">-</span><span class="fu">min</span>(aic) </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>aic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 530.977092   0.000000   1.710562   3.242352   4.927067   5.655454
 [7]   7.641270   9.553690  10.444845  12.099207</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>bic <span class="ot">=</span>bic<span class="sc">-</span><span class="fu">min</span>(bic) </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>bic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 527.307211   0.000000   5.380443  10.582114  15.936709  20.334978
 [7]  25.990674  31.572975  36.134011  41.458254</code></pre>
</div>
</div>
</section>
<section id="draw-plot-of-aic-bic-and-the-marginal-likelihood" class="level3" data-number="92.6.4">
<h3 data-number="92.6.4" class="anchored" data-anchor-id="draw-plot-of-aic-bic-and-the-marginal-likelihood"><span class="header-section-number">92.6.4</span> draw plot of AIC, BIC, and the marginal likelihood</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">matplot</span>(<span class="dv">1</span><span class="sc">:</span>pmax,<span class="fu">matrix</span>(<span class="fu">c</span>(aic,bic),pmax,<span class="dv">2</span>),<span class="at">ylab=</span><span class="st">'value'</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">'AR order p'</span>,<span class="at">pch=</span><span class="st">"ab"</span>, <span class="at">col =</span> <span class="st">'black'</span>, <span class="at">main =</span> <span class="st">"AIC and BIC"</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># highlight the model order selected by AIC</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fu">which.min</span>(aic), aic[<span class="fu">which.min</span>(aic)], <span class="st">"a"</span>, <span class="at">col =</span> <span class="st">'red'</span>) </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># highlight the model order selected by BIC</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fu">which.min</span>(bic), bic[<span class="fu">which.min</span>(bic)], <span class="st">"b"</span>, <span class="at">col =</span> <span class="st">'red'</span>) </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="do">########################################################</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">which.min</span>(bic) <span class="co"># We set up the moder order</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste0</span>(<span class="st">"The chosen model order by BIC: "</span>, p))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "The chosen model order by BIC: 2"</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-ar-2-model-order-selection-plot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-2-model-order-selection-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="C4-L05_files/figure-html/fig-ar-2-model-order-selection-plot-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;92.7: AIC and BIC for different AR(p)s"><img src="C4-L05_files/figure-html/fig-ar-2-model-order-selection-plot-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-2-model-order-selection-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.7: AIC and BIC for different AR(p)s
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="spectral-representation-of-the-arp" class="level2 page-columns page-full" data-number="92.7">
<h2 data-number="92.7" class="anchored" data-anchor-id="spectral-representation-of-the-arp"><span class="header-section-number">92.7</span> Spectral representation of the AR(p) 🎥</h2>

<div class="no-row-height column-margin column-container"><div id="fig-ar-p-spectral-representation" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ar-p-spectral-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/C4-L05-T03.png" class="lightbox" data-gallery="slides" title="Figure&nbsp;92.8: Spectral representation of the AR(p)"><img src="images/C4-L05-T03.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ar-p-spectral-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;92.8: Spectral representation of the AR(p)
</figcaption>
</figure>
</div></div><p>The spectral representation of the AR(p) process is a powerful tool for understanding the frequency domain properties of the process. It allows us to analyze how the process behaves at different frequencies and provides insights into its periodicity and persistence.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We now talk about how to obtain maximum likelihood estimation and Bayesian inference using the conditional likelihood function in this case of the AR2 process. In this particular example is the a AR2. Here I’m first again, just sampling from a specific AR2 process so that we have the data here. I’m using an AR2 with one pair of complex reciprocal roots. The modulus of the reciprocal root is 0.95 and the period is 12, so we’re going to observe this quasi-periodicity in the sampled time series. Then these are 300 observations, the standard deviation of the innovation is one, and we are using the arima.sim function as before. As you recall, in the case of the conditional likelihood we have a correspondence between the conditional likelihood and the equations of the linear regression model. Here I’m just applying the equations we discussed before and we can write everything in terms of a regression model in vector form. So we have a response y and X design matrix and then we obtain, just reading in, so I’m looking at as a conditional likelihood so I’m going to condition on the first P observations. P in this particular case is two and I have my X matrix and my maximum likelihood estimator for Phi is just obtained using the equation X transpose X_inverse times X transpose y. This is my MLE for the AR coefficients, and then I have the unbiased estimator for v which we called S2 here using again, the equations that we discussed before. If you look at the estimates, again the AR coefficients, the true values of the AR coefficients, we can compare with the estimated AR coefficients so the true values are here in the Phi and the true value is for the AR coefficient in the first lag. The Phi 1 is about 1.65 which is what we obtain also in the maximum likelihood estimate using the conditional likelihood, and then the second coefficient is around negative 0.9 which is again close to what we get in terms of the estimate of the maximum likelihood estimator. s square is an estimate for v and here the true variance is one. Again this is based estimator using all these is based on these data that we simulated. Now we can just run in the case of the AR2 we can obtain posterior inference using these conditional likelihood and the reference prior, and in that case we can do everything using direct sampling. I’m going to use the library MASS here just to use the functions to sample random variables from that library. If you recall the form of the posterior distribution is such that the marginal for the variance given the data is just an inverse Gamma distribution so we can sample from this inverse Gamma using the function rgamma and then taking the inverse of that with the corresponding parameters that we have discussed again, the equations before. In the step 2, conditional on v, we can sample Phi from a normal distribution in this case is a multivariate normal bivariate in this case since we have an AR2, and here I’m just simply obtaining samples from that distribution. I set the number of samples to be 1,000. You can choose as many or as few posterior samples as you want. Then based on these we can look at posterior estimates in terms of graphical representations of those like we can look at these histograms of the samples for Phi and the variance. Here we can see if we zoom in here I have three histograms, the first one is the histogram that corresponds to the samples of the first AR coefficient Phi_1, the red line corresponds to the true value and this is just the posterior distribution for Phi_1. Similarly this histogram gives me representation of the posterior distribution for Phi_2 based on those 1,000 samples from the posterior distribution. Then I have also the samples for the v and then the true value which is one. We can see that we’re getting those estimates and we can then look also at graphical representations for functions of those parameters. For example, we could also summarize the posterior distribution for the modulus and the period of the reciprocal roots of the characteristic polynomial. So in this case, the good thing with simulation-based posterior sampling is that if we have the samples of the AR coefficients and the variance, we can simply just do any transformations for any functions of those and obtain the posterior summaries of those transform values. In this case, the modulus, we can obtain it using a transformation of the Phi_2 coefficients so if we have samples of those we can just look at those, and then for the period we can also do the same so this is a function now of the modulus and this first coefficient so we just look at that and then can obtain just the summaries of those histograms for the posterior distribution of the modulus. We can see here the true value was 0.95 and this is a histogram with the posterior samples for that modulus based on those 1,000 samples from the posterior, and this is what I get in terms of the histogram for the period. The true value for the period was 12 in this particular example. This gives you also uncertainty quantification for those parameters of the distribution. Another thing we discussed is we can fix the model order and then obtain posterior inference but in practice we usually also have uncertainty on the model order and we said, well, we can use different procedures to try to look at that problem. One of the methods that we can use is just pick the model order using some model selection criteria. This code just looks at how you can use AIC and BIC for finding the optimal model order and then conditional on that optimal model order then you can proceed with your posterior inference. In this case, again, this is for the simulated dataset, I’m going to assume that I don’t know the model order and we’re going to set the maximum model order to be 10. I’m going to be searching for the optimal model order in AR models that have a maximum model order of 10 and then we will see what happens here. For each of those model orders I can just keep all the matrices, the X matrix and the Y matrix just to proceed with the maximum likelihood inference, and the maximum likelihood inference is just using I just created this function here to compute the MLE and it returns essentially all the quantities that we need to have here, the degrees of freedom, the residuals, the MLE, and so on for a given model order with a given structure in terms of the X which depends on the data that you have and the Y that also depends on the data that you have. There is this AIC BIC function that simply uses calls this MLE function and then computes the AIC and the BIC with different penalties. As we said, if you look a little bit inside this function you will see that the AIC has a penalty in terms of the number of parameters in the model which is 2 times P and in this case we have a log N times P, so this is just how to compute this AIC. So it’s just again computing those. Based on this information that we have we can plot the AIC and the BIC for different values of the model orders and highlight in this case we’re looking at the minimizes, so is the difference between the value and the minimum value of the AIC. In this case, we want to look at the value that minimizes this quantity and we see that the model order for both the AIC and the BIC, the optimal model order happens to be two. Once we have that optimal model order we can then say, well, I can choose the model order that minimizes one of the two criteria and then in this case I’m choosing BIC. For this particular example, both model selection criteria are giving me the same answer in terms of the model order, this doesn’t have to be the case for all the datasets so you will have different answers in terms of what AIC is telling you is the optimal model order and what BIC is telling you that is the optimal model order. In this example, they gives you the same answer. Then you can proceed with the posterior mean, the maximum likelihood estimation, the reference and the posterior mean, and the posterior mean of the standard deviation, and then you can look at estimates also based on those posterior means of the AR coefficients, you can obtain the estimate for the modulus and the period of the reciprocal roots, so I’m just here using that optimal model order looking at estimates of those based on the posterior distribution. Here again, you can just pick one of the two model selection criteria to obtain your optimal model order and then do your inference conditional on that.</p>
</div>
</div>
</div>
</section>
<section id="spectral-representation-of-the-arp-example" class="level2" data-number="92.8">
<h2 data-number="92.8" class="anchored" data-anchor-id="spectral-representation-of-the-arp-example"><span class="header-section-number">92.8</span> Spectral representation of the AR(p): Example 🎥</h2>
<p>This video walks through the code in the next section.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We now talk about how to obtain maximum likelihood estimation and Bayesian inference using the conditional likelihood function in this case of the AR2 process. In this particular example is the a AR2. Here I’m first again, just sampling from a specific AR2 process so that we have the data here. I’m using an AR2 with one pair of complex reciprocal roots. The modulus of the reciprocal root is 0.95 and the period is 12, so we’re going to observe this quasi-periodicity in the sampled time series. Then these are 300 observations, the standard deviation of the innovation is one, and we are using the arima.sim function as before. As you recall, in the case of the conditional likelihood we have a correspondence between the conditional likelihood and the equations of the linear regression model. Here I’m just applying the equations we discussed before and we can write everything in terms of a regression model in vector form. So we have a response y and X design matrix and then we obtain, just reading in, so I’m looking at as a conditional likelihood so I’m going to condition on the first P observations. P in this particular case is two and I have my X matrix and my maximum likelihood estimator for Phi is just obtained using the equation X transpose X_inverse times X transpose y. This is my MLE for the AR coefficients, and then I have the unbiased estimator for v which we called S2 here using again, the equations that we discussed before. If you look at the estimates, again the AR coefficients, the true values of the AR coefficients, we can compare with the estimated AR coefficients so the true values are here in the Phi and the true value is for the AR coefficient in the first lag. The Phi 1 is about 1.65 which is what we obtain also in the maximum likelihood estimate using the conditional likelihood, and then the second coefficient is around negative 0.9 which is again close to what we get in terms of the estimate of the maximum likelihood estimator. s square is an estimate for v and here the true variance is one. Again this is based estimator using all these is based on these data that we simulated. Now we can just run in the case of the AR2 we can obtain posterior inference using these conditional likelihood and the reference prior, and in that case we can do everything using direct sampling. I’m going to use the library MASS here just to use the functions to sample random variables from that library. If you recall the form of the posterior distribution is such that the marginal for the variance given the data is just an inverse Gamma distribution so we can sample from this inverse Gamma using the function rgamma and then taking the inverse of that with the corresponding parameters that we have discussed again, the equations before. In the step 2, conditional on v, we can sample Phi from a normal distribution in this case is a multivariate normal bivariate in this case since we have an AR2, and here I’m just simply obtaining samples from that distribution. I set the number of samples to be 1,000. You can choose as many or as few posterior samples as you want. Then based on these we can look at posterior estimates in terms of graphical representations of those like we can look at these histograms of the samples for Phi and the variance. Here we can see if we zoom in here I have three histograms, the first one is the histogram that corresponds to the samples of the first AR coefficient Phi_1, the red line corresponds to the true value and this is just the posterior distribution for Phi_1. Similarly this histogram gives me representation of the posterior distribution for Phi_2 based on those 1,000 samples from the posterior distribution. Then I have also the samples for the v and then the true value which is one. We can see that we’re getting those estimates and we can then look also at graphical representations for functions of those parameters. For example, we could also summarize the posterior distribution for the modulus and the period of the reciprocal roots of the characteristic polynomial. So in this case, the good thing with simulation-based posterior sampling is that if we have the samples of the AR coefficients and the variance, we can simply just do any transformations for any functions of those and obtain the posterior summaries of those transform values. In this case, the modulus, we can obtain it using a transformation of the Phi_2 coefficients so if we have samples of those we can just look at those, and then for the period we can also do the same so this is a function now of the modulus and this first coefficient so we just look at that and then can obtain just the summaries of those histograms for the posterior distribution of the modulus. We can see here the true value was 0.95 and this is a histogram with the posterior samples for that modulus based on those 1,000 samples from the posterior, and this is what I get in terms of the histogram for the period. The true value for the period was 12 in this particular example. This gives you also uncertainty quantification for those parameters of the distribution. Another thing we discussed is we can fix the model order and then obtain posterior inference but in practice we usually also have uncertainty on the model order and we said, well, we can use different procedures to try to look at that problem. One of the methods that we can use is just pick the model order using some model selection criteria. This code just looks at how you can use AIC and BIC for finding the optimal model order and then conditional on that optimal model order then you can proceed with your posterior inference. In this case, again, this is for the simulated dataset, I’m going to assume that I don’t know the model order and we’re going to set the maximum model order to be 10. I’m going to be searching for the optimal model order in AR models that have a maximum model order of 10 and then we will see what happens here. For each of those model orders I can just keep all the matrices, the X matrix and the Y matrix just to proceed with the maximum likelihood inference, and the maximum likelihood inference is just using I just created this function here to compute the MLE and it returns essentially all the quantities that we need to have here, the degrees of freedom, the residuals, the MLE, and so on for a given model order with a given structure in terms of the X which depends on the data that you have and the Y that also depends on the data that you have. There is this AIC BIC function that simply uses calls this MLE function and then computes the AIC and the BIC with different penalties. As we said, if you look a little bit inside this function you will see that the AIC has a penalty in terms of the number of parameters in the model which is 2 times P and in this case we have a log N times P, so this is just how to compute this AIC. So it’s just again computing those. Based on this information that we have we can plot the AIC and the BIC for different values of the model orders and highlight in this case we’re looking at the minimizes, so is the difference between the value and the minimum value of the AIC. In this case, we want to look at the value that minimizes this quantity and we see that the model order for both the AIC and the BIC, the optimal model order happens to be two. Once we have that optimal model order we can then say, well, I can choose the model order that minimizes one of the two criteria and then in this case I’m choosing BIC. For this particular example, both model selection criteria are giving me the same answer in terms of the model order, this doesn’t have to be the case for all the datasets so you will have different answers in terms of what AIC is telling you is the optimal model order and what BIC is telling you that is the optimal model order. In this example, they gives you the same answer. Then you can proceed with the posterior mean, the maximum likelihood estimation, the reference and the posterior mean, and the posterior mean of the standard deviation, and then you can look at estimates also based on those posterior means of the AR coefficients, you can obtain the estimate for the modulus and the period of the reciprocal roots, so I’m just here using that optimal model order looking at estimates of those based on the posterior distribution. Here again, you can just pick one of the two model selection criteria to obtain your optimal model order and then do your inference conditional on that.</p>
</div>
</div>
</div>
</section>
<section id="code-spectral-density-of-arp-ℛ" class="level2" data-number="92.9">
<h2 data-number="92.9" class="anchored" data-anchor-id="code-spectral-density-of-arp-ℛ"><span class="header-section-number">92.9</span> code: Spectral density of AR(p) 📖 ℛ</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Simulate 300 observations from an AR(2) prcess with a pair of complex-valued roots </span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from the AR(2) process</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the MLE of phi and the unbiased estimator of v using the conditional likelihood </span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>p<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(p<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T])</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>p),T<span class="sc">-</span>p)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>p<span class="dv">-1</span>)),<span class="fu">rep</span>(p,T<span class="sc">-</span>p)))],p,T<span class="sc">-</span>p));</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>XtX<span class="ot">=</span><span class="fu">t</span>(X)<span class="sc">%*%</span>X</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>XtX_inv<span class="ot">=</span><span class="fu">solve</span>(XtX)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span>XtX_inv<span class="sc">%*%</span><span class="fu">t</span>(X)<span class="sc">%*%</span>y <span class="co"># MLE for phi</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> p) <span class="co">#unbiased estimate for v</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain 200 samples from the posterior distribution under the conditional likelihood and the reference prior </span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">200</span> <span class="co"># posterior sample size</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample v from inverse gamma distribution</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span><span class="sc">*</span>p)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((y<span class="sc">-</span>X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample phi conditional on v from normal distribution</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n_sample, <span class="at">ncol =</span> p)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>  phi_sample[i,]<span class="ot">=</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>,phi_MLE,<span class="at">Sigma=</span>v_sample[i]<span class="sc">*</span>XtX_inv)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="do">### using spec.ar to draw spectral density based on the data assuming an AR(2)</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a><span class="fu">spec.ar</span>(yt, <span class="at">order =</span> <span class="dv">2</span>, <span class="at">main =</span> <span class="st">"yt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L05_files/figure-html/ar-spectral-density-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="C4-L05_files/figure-html/ar-spectral-density-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="do">### using arma.spec from astsa package to draw spectral density</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"astsa"</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="do">## plot spectral density of simulated data with posterior sampled </span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="do">## ar coefficients and innvovation variance</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">#result_MLE=arma.spec(ar=phi_MLE, var.noise = s2, log='yes',main = '')</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>result_MLE<span class="ot">=</span><span class="fu">arma.spec</span>(<span class="at">ar=</span>phi_MLE, <span class="at">var.noise =</span> s2, <span class="at">main =</span> <span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L05_files/figure-html/ar-spectral-density-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="C4-L05_files/figure-html/ar-spectral-density-2.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>freq<span class="ot">=</span>result_MLE<span class="sc">$</span>freq</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>spec<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>,<span class="at">nrow=</span>n_sample,<span class="at">ncol=</span><span class="fu">length</span>(freq))</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>result<span class="ot">=</span><span class="fu">arma.spec</span>(<span class="at">ar=</span>phi_sample[i,], <span class="at">var.noise =</span> v_sample[i],<span class="co"># log='yes',</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">main =</span> <span class="st">''</span>,<span class="at">plot=</span><span class="cn">FALSE</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>spec[i,]<span class="ot">=</span>result<span class="sc">$</span>spec</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>freq,<span class="fu">log</span>(spec[<span class="dv">1</span>,]),<span class="at">type=</span><span class="st">'l'</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">12</span>),<span class="at">ylab=</span><span class="st">"log spectra"</span>,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"frequency"</span>,<span class="at">col=</span><span class="dv">0</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co">#for (i in 1:n_sample){</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>){</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>freq,<span class="fu">log</span>(spec[i,]),<span class="at">col=</span><span class="st">'darkgray'</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>freq,<span class="fu">log</span>(result_MLE<span class="sc">$</span>spec))</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">12</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">'red'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C4-L05_files/figure-html/ar-spectral-density-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="C4-L05_files/figure-html/ar-spectral-density-3.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="arima-processes" class="level2 page-columns page-full" data-number="92.10">
<h2 data-number="92.10" class="anchored" data-anchor-id="arima-processes"><span class="header-section-number">92.10</span> ARIMA processes 📖</h2>
<p>This section introduces the ARMA and ARIMA processes, their definitions, stability, invertibility, and spectral density. It is based on a <a href="handouts/c4-ARIMA.pdf">handout</a> from the course. Ideally it should be expanded with more details and examples and code for simulating ARMA and ARIMA processes. I’m not sure why Prado didn’t go any deeper in the course, but the NDLMs generalize the ARMA and ARIMA processes, so perhaps we will cover them as special cases of the NDLMs in the next lessons.</p>
<p></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>ARMA Model Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>A time series process is a zero-mean autoregressive moving average process if it is given by</p>
<p><span id="eq-arma-definition"><span class="math display">
\operatorname{ARMA}(p,q)= \textcolor{red}
                {\underbrace{\sum_{i=1}^{p} \phi_i y_{t-i}}_{AR(P)}}
      +
      \textcolor{blue}
                {\underbrace{\sum_{j=1}^{q} \theta_j \epsilon_{t-j}}_{MA(Q)}}
      + \epsilon_t
\tag{92.9}</span></span></p>
<p>with <span class="math inline">\epsilon_t \sim N(0, v)</span>.</p>
<ul>
<li>For <span class="math inline">q = 0</span>, we get an AR(p) process.</li>
<li>For <span class="math inline">p = 0</span>, we get a MA(q) i.e.&nbsp;moving average process of order <span class="math inline">q</span>.</li>
</ul>
</div>
</div>
<p>Next we will define the notions of stability and invertibility of an ARMA process. </p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Stability Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>An ARMA process is <strong>stable</strong> if the roots of the AR characteristic polynomial </p>
<p><span class="math display">
\Phi(u) = 1 - \phi_1 u - \phi_2 u^2 - \ldots - \phi_p u^p
</span></p>
<p>lie outside the unit circle, i.e., for all <span class="math inline">u</span> such that <span class="math inline">\Phi(u) = 0</span>, <span class="math inline">|u| &gt; 1</span>.</p>
<p>Equivalently, this happens when the reciprocal roots of the AR polynomial have moduli smaller than 1.</p>
<p>This condition implies stationarity.</p>
</div>
</div>
<div class="no-row-height column-margin column-container"><span class="callout-margin-content">stable</span></div><p></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Invertible ARMA Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>An ARMA process is <strong>invertible</strong> if the roots of the MA <strong>characteristic polynomial</strong> given by </p>
<p><span id="eq-arma-ma-poly"><span class="math display">
\Theta(u) = 1 + \theta_1 u + \ldots + \theta_q u^q,
\tag{92.10}</span></span></p>
<p>lie outside the unit circle.</p>
</div>
</div>
<div class="no-row-height column-margin column-container"><span class="callout-margin-content">invertible</span></div><p>Note that <span class="math inline">\Phi(B) y_t = \Theta(B) \epsilon_t</span>.</p>
<ul>
<li>When an ARMA process is <strong>stable</strong>, it can be written as an infinite order moving average process.</li>
<li>When an ARMA process is <strong>invertible</strong>, it can be written as an infinite order autoregressive process.</li>
</ul>
<p></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>ARIMA Processes
</div>
</div>
<div class="callout-body-container callout-body">
<p>An autoregressive integrated moving average process with orders <span class="math inline">p</span>, <span class="math inline">d</span>, and <span class="math inline">q</span> is a process that can be written as</p>
<p><span id="eq-arima-definition"><span class="math display">
(1 - B)^d y_t = \sum_{i=1}^{p} \phi_i y_{t-i} + \sum_{j=1}^{q} \theta_j \epsilon_{t-j} + \epsilon_t,
\tag{92.11}</span></span></p>
<p>where <span class="math inline">B</span> is the backshift operator, <span class="math inline">d</span> is the order of integration, and <span class="math inline">\epsilon_t \sim N(0, v)</span>.</p>
<p>in other words, <span class="math inline">y_t</span> follows an ARIMA(p, d, q) if the <span class="math inline">d</span> difference of <span class="math inline">y_t</span> follows an ARMA(p, q).</p>
</div>
</div>
<p>Estimation in ARIMA processes can be done via <em>least squares</em>, <em>maximum likelihood</em>, and also <em>in a Bayesian way</em>. We will not discuss Bayesian estimation of ARIMA processes in this course.</p>
<section id="spectral-density-of-arma-processes" class="level3" data-number="92.10.1">
<h3 data-number="92.10.1" class="anchored" data-anchor-id="spectral-density-of-arma-processes"><span class="header-section-number">92.10.1</span> Spectral Density of ARMA Processes</h3>
<p> For a given AR(p) process with AR coefficients <span class="math inline">\phi_1, \dots, \phi_p</span> and variance <span class="math inline">v</span>, we can obtain its <strong>spectral density</strong> as</p>
<p><span id="eq-ar-spectral-density"><span class="math display">
f(\omega) = \frac{v}{2\pi |\Phi(e^{-i\omega})|^2} = \frac{v}{2\pi |1 - \phi_1 e^{-i\omega} - \ldots - \phi_p e^{-ip\omega}|^2},
\tag{92.12}</span></span></p>
<p>with <span class="math inline">\omega</span> a frequency in <span class="math inline">(0, \pi)</span>.</p>
<p>The spectral density provides a frequency-domain representation of the process that is appealing because of its interpretability.</p>
<p>For instance, an AR(2) process that has one pair of complex-valued reciprocal roots with modulus 0.7 and a period of <span class="math inline">\lambda = 12</span>, will show a mode in the spectral density located at a frequency of <span class="math inline">2\pi/12</span>. If we keep the period of the process at the same value of 12 but increase its modulus to 0.95, the spectral density will continue to show a mode at <span class="math inline">2\pi/12</span>, but the value of <span class="math inline">f(2\pi/12)</span> will be higher, indicating a more persistent <em>quasi-periodic</em> behavior.</p>
<p>Similarly, we can obtain the spectral density of an ARMA process with AR characteristic polynomial <span class="math inline">\Phi(u) = 1 - \phi_1 u - \ldots - \phi_p u^p</span> and MA characteristic polynomial <span class="math inline">\Theta(u) = 1 + \theta_1 u + \ldots + \theta_q u^q</span>, and variance <span class="math inline">v</span> as</p>
<p><span id="eq-arma-spectral-density"><span class="math display">
f(\omega) = \frac{v}{2\pi} \frac{|\Theta(e^{-i\omega})|^2}{|\Phi(e^{-i\omega})|^2}.
\tag{92.13}</span></span></p>
<p>Note that if we have posterior estimates or posterior samples of the AR/ARMA coefficients and the variance <span class="math inline">v</span>, we can obtain samples from the spectral density of AR/ARMA processes using the equations above.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
        for (let i=0; i<annoteTargets.length; i++) {
          const annoteTarget = annoteTargets[i];
          const targetCell = annoteTarget.getAttribute("data-target-cell");
          const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
          const contentFn = () => {
            const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            if (content) {
              const tipContent = content.cloneNode(true);
              tipContent.classList.add("code-annotation-tip-content");
              return tipContent.outerHTML;
            }
          }
          const config = {
            allowHTML: true,
            content: contentFn,
            onShow: (instance) => {
              selectCodeLines(instance.reference);
              instance.reference.classList.add('code-annotation-active');
              window.tippy.hideAll();
            },
            onHide: (instance) => {
              unselectCodeLines();
              instance.reference.classList.remove('code-annotation-active');
            },
            maxWidth: 300,
            delay: [50, 0],
            duration: [200, 0],
            offset: [5, 10],
            arrow: true,
            appendTo: function(el) {
              return el.parentElement.parentElement.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'quarto',
            placement: 'right',
            popperOptions: {
              modifiers: [
              {
                name: 'flip',
                options: {
                  flipVariations: false, // true by default
                  allowedAutoPlacements: ['right'],
                  fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                },
              },
              {
                name: 'preventOverflow',
                options: {
                  mainAxis: false,
                  altAxis: false
                }
              }
              ]        
            }      
          };
          window.tippy(annoteTarget, config); 
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C4-L04.html" class="pagination-link" aria-label="The AR(p) process - M2L4">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">The AR(p) process - M2L4</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C4-L05-Ex1.html" class="pagination-link" aria-label="Quiz: Spectral representation of the AR(p) -  M2L5">
        <span class="nav-page-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Quiz: Spectral representation of the AR(p) - M2L5</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2024-11-05</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Bayesian Inference in the AR(p) -  M2L5"</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> Time Series Analysis</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "The AR(P) process, its state-space representation, the characteristic polynomial, and the forecast function"</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> </span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Coursera </span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - notes</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - Bayesian Statistics</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - Autoregressive Models</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - Time Series</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> </span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - time series</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - stability</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">  - order of an AR process </span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co">  - characteristic lag polynomial</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="co">  - autocorrelation function</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co">  - ACF</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">  - partial autocorrelation function</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co">  - PACF</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="co">  - smoothing</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="co">  - State Space Model</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co">  - ARMA process</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co">  - ARIMA</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="co">  - moving average</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="co">  - AR(p) process  </span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co">  - R code</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bayesian inference in the AR(p): Reference prior, conditional likelihood 🎥</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="al">![inference for AR(p)](images/m2_0031.png)</span>{#fig-ar-p-process .column-margin  group="slides" width="53mm"}</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model Setup</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>we start with an AR(p) model as we define in the previous lesson:</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>y_t = \phi_1 y_{t-1} + \ldots + \phi_p y_{t-p} + \varepsilon_t \qquad \varepsilon_t \stackrel{iid}{\sim} \mathcal{N}(0, v)</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-model}</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>but now we wish to infer:</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\phi_i$ the *AR(p)* coefficients and </span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$v$ the innovation variance.</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditional likelihood</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>We make use of the autoregressive structure and rewrite $y_t$ conditionally on the previous $p$ values of the process and the parameters:</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>(y_t \mid y_{t-1}, \ldots, y_{t-p}, \phi_1, \ldots, \phi_p) \sim \mathcal{N}\left (\sum_{j=1}^{p} \phi_j y_{t-j}, v\right )</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-cond}</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>We condition on the first $p$ values of the process. </span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>The conditional distribution of $y_t$ given the previous $p$ values and parameters is normal with mean given by the weighted sum $\sum \phi_j y_{t-j}$ and variance $v$.</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>the density for the first $p$ observations is given by:</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>p(y_{(p+1):T}\mid y_{1:p}, \phi_1, \ldots, \phi_p, v) = \prod_{t=p+1}^{T} p(y_t | y_{t-1}, \ldots, y_{t-p}, \phi_1, \ldots, \phi_p, v)</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-full-cond-likelihood}</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>This product of conditionals yields the full conditional likelihood. </span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>Each term is Gaussian and independent, given the past values and parameters.</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regression Formulation</span></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>This is recast as a linear regression: response vector $\mathbf{y}$ starting from $y_{p+1}$ to $y_T$, design matrix $\mathbb{X}$ built from lagged values, and $\boldsymbol\beta$ as the AR coefficients $\phi_j$.</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>\mathbf{y}= \mathbb{X}\boldsymbol \beta + \boldsymbol \varepsilon \qquad \varepsilon \sim \mathcal{N}(0, vI)</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-regression}</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>\mathbf{y} = \begin{pmatrix} y_{p+1} <span class="sc">\\</span> y_{p+2} <span class="sc">\\</span> \vdots <span class="sc">\\</span> y_T \end{pmatrix}, \quad</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>\boldsymbol \beta = \begin{pmatrix} \phi_1 <span class="sc">\\</span> \phi_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> \phi_p \end{pmatrix}, \quad</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>\mathbb{X} = \begin{pmatrix} y_{p} &amp; y_{p-1} &amp; \cdots &amp; y_{1} <span class="sc">\\</span> y_{p+1} &amp; y_{p} &amp; \cdots &amp; y_{2} <span class="sc">\\</span> \vdots &amp; \vdots &amp; \ddots &amp; \vdots <span class="sc">\\</span> y_{T-1} &amp; y_{T-2} &amp; \cdots &amp; y_{T-p} \end{pmatrix}</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>In the design matrix $\mathbb{X}$ each row corresponds to lagged observations used to predict the next value. This setup enables applying linear regression machinery.</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>we can now infer the parameters by using the left generalized Moore Penrose inverse of $\mathbb{X}$ to obtain the maximum likelihood estimator (MLE) of the AR coefficients $\boldsymbol \beta$ </span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>Assuming full-rank $\mathbb{X}$, this is the MLE. </span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>\boldsymbol \beta_{MLE} = (\mathbb{X}^\top \mathbb{X})^{-1} \mathbb{X}^\top \mathbf{y}</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-regression-mle}</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\mathbb{X}$ is the design matrix, </span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\boldsymbol \beta$ is the vector of AR coefficients, and </span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\mathbf{y}$ is the response vector.</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a>It matches the usual OLS solution in linear regression.</span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reference prior and posterior distribution</span></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>The reference prior reflects non-informative beliefs. This yields a conjugate posterior due to the Gaussian likelihood.</span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a>p(\beta,v) \propto 1/v</span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-prior}</span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>(\boldsymbol \beta | \mathbf{y}_{:T}, v) \sim \mathcal{N}(\boldsymbol \beta_{MLE}, v (\mathbb{X}^\top \mathbb{X})^{-1})</span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-posterior-beta}</span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a>The posterior is Gaussian with mean $\boldsymbol \beta_{MLE}$ and scaled covariance $v(\mathbb{X}^\top \mathbb{X})^{-1}$, analogous to the OLS variance.</span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>(v | \mathbf{y}_{:T}) \sim \text{Inverse-Gamma}\left(\frac{T - 2p}{2}, \frac{S^2}{2}\right)</span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arp-inf-posterior-v}</span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>where:  </span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$S^2 = \sum_{t=p+1}^{T} (y_t - \mathbb{X} \boldsymbol \beta_{MLE})^2$ is the unbiased estimator of the variance $v$.</span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$T$ is the total number of observations.</span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>Posterior for $v$ is inverse gamma. The shape parameter is $(T - 2p)/2$ because the number of residual degrees of freedom is $T - 2p$ (residual = $T-p$ obs minus $p$ params). Scale is half the sum of squared residuals.</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulation-based Inference</span></span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a>Posterior sampling:</span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Draw $v$ from the inverse gamma posterior.</span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Plug $v$ into the posterior of $\boldsymbol\beta$ and sample from the Gaussian.</span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>This gives full Bayesian posterior samples of $(\boldsymbol\beta, v)$.</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>In this lesson, we discussed the Bayesian inference for the AR(p) process using the conditional likelihood and reference prior. </span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We have established a connection between the AR(p) process and a regression model, allowing us to use standard regression techniques to estimate the parameters. </span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The posterior distribution can be derived, and we can perform simulation-based inference to obtain samples from the posterior distribution of the AR coefficients and variance.</span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a><span class="fu">## Video Transcript {.unnumbered}</span></span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">TODO</span><span class="co">: summarize this transcript --&gt;</span></span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a>{{&lt; include _C4-L05-T01.qmd &gt;}}</span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a><span class="fu">## R code: Maximum likelihood estimation, AR(p), conditional likelihood 📖</span></span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a>\index{Maximum Likelihood Estimation}</span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ar-likelihood</span></span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate 300 observations from an AR(2) with one pair of complex-valued reciprocal roots </span></span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>]<span class="ot">=</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a><span class="co"># generate stationary AR(2) process</span></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a><span class="do">## Compute the MLE for phi and the unbiased estimator for v using the conditional likelihood</span></span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a>p<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(p<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>p),T<span class="sc">-</span>p)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>p<span class="dv">-1</span>)),<span class="fu">rep</span>(p,T<span class="sc">-</span>p)))],p,T<span class="sc">-</span>p));</span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>XtX<span class="ot">=</span><span class="fu">t</span>(X)<span class="sc">%*%</span>X</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a>XtX_inv<span class="ot">=</span><span class="fu">solve</span>(XtX)</span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span>XtX_inv<span class="sc">%*%</span><span class="fu">t</span>(X)<span class="sc">%*%</span>y <span class="co"># MLE for phi</span></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> p) <span class="co">#unbiased estimate for v</span></span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st"> MLE of conditional likelihood for phi: "</span>, phi_MLE, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Estimate for v: "</span>, s2, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model order selection 🎥</span></span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a><span class="al">![model order selection](images/m2_0032.png)</span>{#fig-ar-p-model-order-selection .column-margin  group="slides" width="53mm"}</span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a><span class="fu">### Goal</span></span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a>Determine the best model order $p$ for an AR($p$) process by comparing candidate models.</span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 1: Define a candidate set of model orders</span></span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a>p^* \qquad p=1:p^*</span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a>You choose a maximum order $p^*$ (e.g., 20), then evaluate AR models of each order $p \in {1, \dots, p^*}$.</span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 2: Estimate residual variance for each model</span></span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a>S^2_p \qquad y_{(p^*+1):T} </span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a>For each model of order $p$, compute $S_p^2$ as the residual sum of squares (RSS) using a fixed evaluation window: $t = p^*+1$ to $T$, to ensure all models are evaluated on the same data subset.</span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 3: Compute model selection criteria</span></span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a>AIC balances fit (log-likelihood) with complexity (number of parameters).</span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a>The first term measures model fit using $\log(S_p^2)$, and the second term penalizes complexity with $2p$.</span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a>AIC_p = (T-p^*) \log(S_p^2) + 2p</span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a>BIC uses the same fit term but a heavier penalty: $p \log(T - p^*)$, which increases with sample size. This often leads BIC to favor smaller models than AIC.</span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a>BIC_p = (T-p^*) \log(S_p^2) + p \log(T-p^*)</span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a><span class="fu">## Video Transcript {.unnumbered}</span></span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a>{{&lt; include _C4-L05-T02.qmd &gt;}}</span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example: Bayesian inference in the AR(p), conditional likelihood 🎥</span></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a>This video demonstrates walks through the code in the next section.</span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a><span class="fu">## Video Transcript {.unnumbered}</span></span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a>{{&lt; include _C4-L05-T03.qmd &gt;}}</span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a><span class="fu">## code: Bayesian inference, AR(p), conditional likelihood 📖 ℛ{#sec-arp-bayesian-inference}</span></span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulate 300 observations from an AR(2) with one pair of complex-valued roots </span></span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ar-bayesian-inference</span></span>
<span id="cb23-253"><a href="#cb23-253" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Simulated AR(2) process with complex-valued roots</span></span>
<span id="cb23-254"><a href="#cb23-254" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb23-257"><a href="#cb23-257" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb23-258"><a href="#cb23-258" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>]<span class="ot">=</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a><span class="co"># generate stationary AR(2) process</span></span>
<span id="cb23-263"><a href="#cb23-263" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb23-264"><a href="#cb23-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-265"><a href="#cb23-265" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb23-266"><a href="#cb23-266" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt)</span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a><span class="fu">### Compute the MLE of phi and the unbiased estimator of v using the conditional likelihood</span></span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ar-bayesian-inference-mle</span></span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a>p<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb23-275"><a href="#cb23-275" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(p<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T]) <span class="co"># response</span></span>
<span id="cb23-276"><a href="#cb23-276" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>p),T<span class="sc">-</span>p)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>p<span class="dv">-1</span>)),<span class="fu">rep</span>(p,T<span class="sc">-</span>p)))],p,T<span class="sc">-</span>p));</span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a>XtX<span class="ot">=</span><span class="fu">t</span>(X)<span class="sc">%*%</span>X</span>
<span id="cb23-278"><a href="#cb23-278" aria-hidden="true" tabindex="-1"></a>XtX_inv<span class="ot">=</span><span class="fu">solve</span>(XtX)</span>
<span id="cb23-279"><a href="#cb23-279" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span>XtX_inv<span class="sc">%*%</span><span class="fu">t</span>(X)<span class="sc">%*%</span>y <span class="co"># MLE for phi</span></span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a>phi_MLE</span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> p) <span class="co">#unbiased estimate for v</span></span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a>s2</span>
<span id="cb23-283"><a href="#cb23-283" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-284"><a href="#cb23-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a><span class="fu">### Posterior inference, conditional likelihood + reference prior via direct sampling                 </span></span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ar-bayesian-inference-posterior</span></span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Posterior distributions of AR(2) parameters</span></span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">1000</span> <span class="co"># posterior sample size</span></span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample v from inverse gamma distribution</span></span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span><span class="sc">*</span>p)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((y<span class="sc">-</span>X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample phi conditional on v from normal distribution</span></span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n_sample, <span class="at">ncol =</span> p)</span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a>  phi_sample[i, ]<span class="ot">=</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>,phi_MLE,<span class="at">Sigma=</span>v_sample[i]<span class="sc">*</span>XtX_inv)</span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-305"><a href="#cb23-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-306"><a href="#cb23-306" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>),  <span class="at">cex.lab =</span> <span class="fl">1.3</span>)</span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a><span class="do">## plot histogram of posterior samples of phi and v</span></span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>){</span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hist</span>(phi_sample[, i], <span class="at">xlab =</span> <span class="fu">bquote</span>(phi), </span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Histogram of "</span><span class="sc">~</span>phi[.(i)]),<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v =</span> phi[i], <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(v_sample, <span class="at">xlab =</span> <span class="fu">bquote</span>(nu), <span class="at">main =</span> <span class="fu">bquote</span>(<span class="st">"Histogram of "</span><span class="sc">~</span>v),<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> sd, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a><span class="fu">### Graph posterior for modulus and period </span></span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ar-bayesian-inference-roots</span></span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Posterior distributions of AR(2) roots</span></span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-subcap: </span></span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a><span class="co">#| - modulus</span></span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a><span class="co">#| - period</span></span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a><span class="co">#| layout-ncol: 2</span></span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a>r_sample<span class="ot">=</span><span class="fu">sqrt</span>(<span class="sc">-</span>phi_sample[,<span class="dv">2</span>])</span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a>lambda_sample<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="fu">acos</span>(phi_sample[,<span class="dv">1</span>]<span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span>r_sample))</span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(r_sample,<span class="at">xlab=</span><span class="st">"modulus"</span>,<span class="at">main=</span><span class="st">""</span>,<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fl">0.95</span>,<span class="at">col=</span><span class="st">'red'</span>)</span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(lambda_sample,<span class="at">xlab=</span><span class="st">"period"</span>,<span class="at">main=</span><span class="st">""</span>,<span class="at">col=</span><span class="st">'lightblue'</span>)</span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">12</span>,<span class="at">col=</span><span class="st">'red'</span>)</span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-339"><a href="#cb23-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-340"><a href="#cb23-340" aria-hidden="true" tabindex="-1"></a><span class="fu">## code: Model order selection 📖 ℛ {#sec-ar-2-model-order-selection} </span></span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulate data from an AR(2)</span></span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ar-2-model-order-selection-simulation</span></span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Simulated AR(2) process with complex-valued roots</span></span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb23-353"><a href="#cb23-353" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb23-354"><a href="#cb23-354" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">=</span><span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>]<span class="ot">=</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb23-357"><a href="#cb23-357" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb23-358"><a href="#cb23-358" aria-hidden="true" tabindex="-1"></a><span class="co"># generate stationary AR(2) process</span></span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yt)</span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a><span class="fu">###   compute MLE for different AR(p)s</span></span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ar-2-model-order-selection-MLE</span></span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a>pmax<span class="ot">=</span><span class="dv">10</span> <span class="co"># the maximum of model order</span></span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a>Xall<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>pmax),T<span class="sc">-</span>pmax)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>pmax<span class="dv">-1</span>)),</span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a>              <span class="fu">rep</span>(pmax,T<span class="sc">-</span>pmax)))], pmax, T<span class="sc">-</span>pmax));</span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(pmax<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T])</span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a>n_cond<span class="ot">=</span><span class="fu">length</span>(y) <span class="co"># (number of total time points - the maximum of model order)</span></span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a><span class="do">## compute MLE</span></span>
<span id="cb23-377"><a href="#cb23-377" aria-hidden="true" tabindex="-1"></a>my_MLE <span class="ot">&lt;-</span> <span class="cf">function</span>(y, Xall, p){</span>
<span id="cb23-378"><a href="#cb23-378" aria-hidden="true" tabindex="-1"></a>  n<span class="ot">=</span><span class="fu">length</span>(y)</span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span>Xall[,<span class="dv">1</span><span class="sc">:</span>p]</span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a>  a<span class="ot">=</span><span class="fu">solve</span>(<span class="fu">t</span>(x) <span class="sc">%*%</span>x)</span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a>  a<span class="ot">=</span>(a <span class="sc">+</span> <span class="fu">t</span>(a))<span class="sc">/</span><span class="dv">2</span> <span class="co"># for numerical stability </span></span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a>  b<span class="ot">=</span>a<span class="sc">%*%</span><span class="fu">t</span>(x)<span class="sc">%*%</span>y <span class="co"># mle for ar coefficients</span></span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a>  r<span class="ot">=</span>y <span class="sc">-</span> x<span class="sc">%*%</span>b <span class="co"># residuals </span></span>
<span id="cb23-384"><a href="#cb23-384" aria-hidden="true" tabindex="-1"></a>  nu<span class="ot">=</span>n <span class="sc">-</span> p <span class="co"># degrees freedom</span></span>
<span id="cb23-385"><a href="#cb23-385" aria-hidden="true" tabindex="-1"></a>  R<span class="ot">=</span><span class="fu">sum</span>(r<span class="sc">*</span>r) <span class="co"># SSE</span></span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a>  s<span class="ot">=</span>R<span class="sc">/</span>nu <span class="co">#MSE</span></span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">b =</span> b, <span class="at">s =</span> s, <span class="at">R =</span> R, <span class="at">nu =</span> nu))</span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-389"><a href="#cb23-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-390"><a href="#cb23-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a><span class="fu">### Compute AIC and BIC for different AR(p)s based on simulated data</span></span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a><span class="do">## function for AIC and BIC computation </span></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a>AIC_BIC <span class="ot">&lt;-</span> <span class="cf">function</span>(y, Xall, p){</span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a>  <span class="do">## number of time points</span></span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute MLE</span></span>
<span id="cb23-401"><a href="#cb23-401" aria-hidden="true" tabindex="-1"></a>  tmp<span class="ot">=</span><span class="fu">my_MLE</span>(y, Xall, p)</span>
<span id="cb23-402"><a href="#cb23-402" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a>  <span class="do">## retrieve results</span></span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a>  R<span class="ot">=</span>tmp<span class="sc">$</span>R</span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute likelihood</span></span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a>  likl<span class="ot">=</span> n<span class="sc">*</span><span class="fu">log</span>(R)</span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-409"><a href="#cb23-409" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute AIC and BIC</span></span>
<span id="cb23-410"><a href="#cb23-410" aria-hidden="true" tabindex="-1"></a>  aic <span class="ot">=</span>likl <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(p)</span>
<span id="cb23-411"><a href="#cb23-411" aria-hidden="true" tabindex="-1"></a>  bic <span class="ot">=</span>likl <span class="sc">+</span> <span class="fu">log</span>(n)<span class="sc">*</span>(p)</span>
<span id="cb23-412"><a href="#cb23-412" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">aic =</span> aic, <span class="at">bic =</span> bic))</span>
<span id="cb23-413"><a href="#cb23-413" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-414"><a href="#cb23-414" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute AIC, BIC </span></span>
<span id="cb23-415"><a href="#cb23-415" aria-hidden="true" tabindex="-1"></a>aic <span class="ot">=</span><span class="fu">numeric</span>(pmax)</span>
<span id="cb23-416"><a href="#cb23-416" aria-hidden="true" tabindex="-1"></a>bic <span class="ot">=</span><span class="fu">numeric</span>(pmax)</span>
<span id="cb23-417"><a href="#cb23-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-418"><a href="#cb23-418" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(p <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>pmax){</span>
<span id="cb23-419"><a href="#cb23-419" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">=</span><span class="fu">AIC_BIC</span>(y,Xall, p)</span>
<span id="cb23-420"><a href="#cb23-420" aria-hidden="true" tabindex="-1"></a>  aic[p] <span class="ot">=</span>tmp<span class="sc">$</span>aic</span>
<span id="cb23-421"><a href="#cb23-421" aria-hidden="true" tabindex="-1"></a>  bic[p] <span class="ot">=</span>tmp<span class="sc">$</span>bic</span>
<span id="cb23-422"><a href="#cb23-422" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">c</span>(p, aic[p], bic[p])) <span class="co"># print AIC and BIC by model order</span></span>
<span id="cb23-423"><a href="#cb23-423" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-424"><a href="#cb23-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-425"><a href="#cb23-425" aria-hidden="true" tabindex="-1"></a><span class="do">## compute difference between the value and its minimum</span></span>
<span id="cb23-426"><a href="#cb23-426" aria-hidden="true" tabindex="-1"></a>aic <span class="ot">=</span>aic<span class="sc">-</span><span class="fu">min</span>(aic) </span>
<span id="cb23-427"><a href="#cb23-427" aria-hidden="true" tabindex="-1"></a>aic</span>
<span id="cb23-428"><a href="#cb23-428" aria-hidden="true" tabindex="-1"></a>bic <span class="ot">=</span>bic<span class="sc">-</span><span class="fu">min</span>(bic) </span>
<span id="cb23-429"><a href="#cb23-429" aria-hidden="true" tabindex="-1"></a>bic</span>
<span id="cb23-430"><a href="#cb23-430" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-431"><a href="#cb23-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-432"><a href="#cb23-432" aria-hidden="true" tabindex="-1"></a><span class="fu">### draw plot of AIC, BIC, and the marginal likelihood</span></span>
<span id="cb23-433"><a href="#cb23-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-436"><a href="#cb23-436" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-437"><a href="#cb23-437" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ar-2-model-order-selection-plot</span></span>
<span id="cb23-438"><a href="#cb23-438" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: AIC and BIC for different AR(p)s</span></span>
<span id="cb23-439"><a href="#cb23-439" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb23-440"><a href="#cb23-440" aria-hidden="true" tabindex="-1"></a><span class="fu">matplot</span>(<span class="dv">1</span><span class="sc">:</span>pmax,<span class="fu">matrix</span>(<span class="fu">c</span>(aic,bic),pmax,<span class="dv">2</span>),<span class="at">ylab=</span><span class="st">'value'</span>,</span>
<span id="cb23-441"><a href="#cb23-441" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">'AR order p'</span>,<span class="at">pch=</span><span class="st">"ab"</span>, <span class="at">col =</span> <span class="st">'black'</span>, <span class="at">main =</span> <span class="st">"AIC and BIC"</span>)</span>
<span id="cb23-442"><a href="#cb23-442" aria-hidden="true" tabindex="-1"></a><span class="co"># highlight the model order selected by AIC</span></span>
<span id="cb23-443"><a href="#cb23-443" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fu">which.min</span>(aic), aic[<span class="fu">which.min</span>(aic)], <span class="st">"a"</span>, <span class="at">col =</span> <span class="st">'red'</span>) </span>
<span id="cb23-444"><a href="#cb23-444" aria-hidden="true" tabindex="-1"></a><span class="co"># highlight the model order selected by BIC</span></span>
<span id="cb23-445"><a href="#cb23-445" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fu">which.min</span>(bic), bic[<span class="fu">which.min</span>(bic)], <span class="st">"b"</span>, <span class="at">col =</span> <span class="st">'red'</span>) </span>
<span id="cb23-446"><a href="#cb23-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-447"><a href="#cb23-447" aria-hidden="true" tabindex="-1"></a><span class="do">########################################################</span></span>
<span id="cb23-448"><a href="#cb23-448" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">which.min</span>(bic) <span class="co"># We set up the moder order</span></span>
<span id="cb23-449"><a href="#cb23-449" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste0</span>(<span class="st">"The chosen model order by BIC: "</span>, p))</span>
<span id="cb23-450"><a href="#cb23-450" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-451"><a href="#cb23-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-452"><a href="#cb23-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-453"><a href="#cb23-453" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spectral representation of the AR(p) 🎥</span></span>
<span id="cb23-454"><a href="#cb23-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-455"><a href="#cb23-455" aria-hidden="true" tabindex="-1"></a><span class="al">![Spectral representation of the AR(p)](images/C4-L05-T03.png)</span>{#fig-ar-p-spectral-representation .column-margin  group="slides" width="53mm"}</span>
<span id="cb23-456"><a href="#cb23-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-457"><a href="#cb23-457" aria-hidden="true" tabindex="-1"></a>The spectral representation of the AR(p) process is a powerful tool for understanding the frequency domain properties of the process. It allows us to analyze how the process behaves at different frequencies and provides insights into its periodicity and persistence.</span>
<span id="cb23-458"><a href="#cb23-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-459"><a href="#cb23-459" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-460"><a href="#cb23-460" aria-hidden="true" tabindex="-1"></a><span class="fu">## Video Transcript {.unnumbered}</span></span>
<span id="cb23-461"><a href="#cb23-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-462"><a href="#cb23-462" aria-hidden="true" tabindex="-1"></a>{{&lt; include _C4-L05-T03.qmd &gt;}}</span>
<span id="cb23-463"><a href="#cb23-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-464"><a href="#cb23-464" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-465"><a href="#cb23-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-466"><a href="#cb23-466" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spectral representation of the AR(p): Example 🎥</span></span>
<span id="cb23-467"><a href="#cb23-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-468"><a href="#cb23-468" aria-hidden="true" tabindex="-1"></a>This video walks through the code in the next section.</span>
<span id="cb23-469"><a href="#cb23-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-470"><a href="#cb23-470" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-471"><a href="#cb23-471" aria-hidden="true" tabindex="-1"></a><span class="fu">## Video Transcript {.unnumbered}</span></span>
<span id="cb23-472"><a href="#cb23-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-473"><a href="#cb23-473" aria-hidden="true" tabindex="-1"></a>{{&lt; include _C4-L05-T03.qmd &gt;}}</span>
<span id="cb23-474"><a href="#cb23-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-475"><a href="#cb23-475" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-476"><a href="#cb23-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-477"><a href="#cb23-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-478"><a href="#cb23-478" aria-hidden="true" tabindex="-1"></a><span class="fu">## code: Spectral density of AR(p) 📖 ℛ</span></span>
<span id="cb23-479"><a href="#cb23-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-482"><a href="#cb23-482" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-483"><a href="#cb23-483" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ar-spectral-density</span></span>
<span id="cb23-484"><a href="#cb23-484" aria-hidden="true" tabindex="-1"></a><span class="do">### Simulate 300 observations from an AR(2) prcess with a pair of complex-valued roots </span></span>
<span id="cb23-485"><a href="#cb23-485" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb23-486"><a href="#cb23-486" aria-hidden="true" tabindex="-1"></a>r<span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb23-487"><a href="#cb23-487" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">12</span> </span>
<span id="cb23-488"><a href="#cb23-488" aria-hidden="true" tabindex="-1"></a>phi<span class="ot">=</span><span class="fu">numeric</span>(<span class="dv">2</span>) </span>
<span id="cb23-489"><a href="#cb23-489" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">1</span>]<span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span>lambda) </span>
<span id="cb23-490"><a href="#cb23-490" aria-hidden="true" tabindex="-1"></a>phi[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb23-491"><a href="#cb23-491" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">=</span><span class="dv">1</span> <span class="co"># innovation standard deviation</span></span>
<span id="cb23-492"><a href="#cb23-492" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">300</span> <span class="co"># number of time points</span></span>
<span id="cb23-493"><a href="#cb23-493" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from the AR(2) process</span></span>
<span id="cb23-494"><a href="#cb23-494" aria-hidden="true" tabindex="-1"></a>yt<span class="ot">=</span><span class="fu">arima.sim</span>(<span class="at">n =</span> T, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> phi), <span class="at">sd =</span> sd) </span>
<span id="cb23-495"><a href="#cb23-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-496"><a href="#cb23-496" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the MLE of phi and the unbiased estimator of v using the conditional likelihood </span></span>
<span id="cb23-497"><a href="#cb23-497" aria-hidden="true" tabindex="-1"></a>p<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb23-498"><a href="#cb23-498" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rev</span>(yt[(p<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>T])</span>
<span id="cb23-499"><a href="#cb23-499" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">t</span>(<span class="fu">matrix</span>(yt[<span class="fu">rev</span>(<span class="fu">rep</span>((<span class="dv">1</span><span class="sc">:</span>p),T<span class="sc">-</span>p)<span class="sc">+</span><span class="fu">rep</span>((<span class="dv">0</span><span class="sc">:</span>(T<span class="sc">-</span>p<span class="dv">-1</span>)),<span class="fu">rep</span>(p,T<span class="sc">-</span>p)))],p,T<span class="sc">-</span>p));</span>
<span id="cb23-500"><a href="#cb23-500" aria-hidden="true" tabindex="-1"></a>XtX<span class="ot">=</span><span class="fu">t</span>(X)<span class="sc">%*%</span>X</span>
<span id="cb23-501"><a href="#cb23-501" aria-hidden="true" tabindex="-1"></a>XtX_inv<span class="ot">=</span><span class="fu">solve</span>(XtX)</span>
<span id="cb23-502"><a href="#cb23-502" aria-hidden="true" tabindex="-1"></a>phi_MLE<span class="ot">=</span>XtX_inv<span class="sc">%*%</span><span class="fu">t</span>(X)<span class="sc">%*%</span>y <span class="co"># MLE for phi</span></span>
<span id="cb23-503"><a href="#cb23-503" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">=</span><span class="fu">sum</span>((y <span class="sc">-</span> X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(y) <span class="sc">-</span> p) <span class="co">#unbiased estimate for v</span></span>
<span id="cb23-504"><a href="#cb23-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-505"><a href="#cb23-505" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain 200 samples from the posterior distribution under the conditional likelihood and the reference prior </span></span>
<span id="cb23-506"><a href="#cb23-506" aria-hidden="true" tabindex="-1"></a>n_sample<span class="ot">=</span><span class="dv">200</span> <span class="co"># posterior sample size</span></span>
<span id="cb23-507"><a href="#cb23-507" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb23-508"><a href="#cb23-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-509"><a href="#cb23-509" aria-hidden="true" tabindex="-1"></a><span class="do">## step 1: sample v from inverse gamma distribution</span></span>
<span id="cb23-510"><a href="#cb23-510" aria-hidden="true" tabindex="-1"></a>v_sample<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(n_sample, (T<span class="dv">-2</span><span class="sc">*</span>p)<span class="sc">/</span><span class="dv">2</span>, <span class="fu">sum</span>((y<span class="sc">-</span>X<span class="sc">%*%</span>phi_MLE)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb23-511"><a href="#cb23-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-512"><a href="#cb23-512" aria-hidden="true" tabindex="-1"></a><span class="do">## step 2: sample phi conditional on v from normal distribution</span></span>
<span id="cb23-513"><a href="#cb23-513" aria-hidden="true" tabindex="-1"></a>phi_sample<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n_sample, <span class="at">ncol =</span> p)</span>
<span id="cb23-514"><a href="#cb23-514" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb23-515"><a href="#cb23-515" aria-hidden="true" tabindex="-1"></a>  phi_sample[i,]<span class="ot">=</span><span class="fu">mvrnorm</span>(<span class="dv">1</span>,phi_MLE,<span class="at">Sigma=</span>v_sample[i]<span class="sc">*</span>XtX_inv)</span>
<span id="cb23-516"><a href="#cb23-516" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-517"><a href="#cb23-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-518"><a href="#cb23-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-519"><a href="#cb23-519" aria-hidden="true" tabindex="-1"></a><span class="do">### using spec.ar to draw spectral density based on the data assuming an AR(2)</span></span>
<span id="cb23-520"><a href="#cb23-520" aria-hidden="true" tabindex="-1"></a><span class="fu">spec.ar</span>(yt, <span class="at">order =</span> <span class="dv">2</span>, <span class="at">main =</span> <span class="st">"yt"</span>)</span>
<span id="cb23-521"><a href="#cb23-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-522"><a href="#cb23-522" aria-hidden="true" tabindex="-1"></a><span class="do">### using arma.spec from astsa package to draw spectral density</span></span>
<span id="cb23-523"><a href="#cb23-523" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"astsa"</span>)</span>
<span id="cb23-524"><a href="#cb23-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-525"><a href="#cb23-525" aria-hidden="true" tabindex="-1"></a><span class="do">## plot spectral density of simulated data with posterior sampled </span></span>
<span id="cb23-526"><a href="#cb23-526" aria-hidden="true" tabindex="-1"></a><span class="do">## ar coefficients and innvovation variance</span></span>
<span id="cb23-527"><a href="#cb23-527" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>) )</span>
<span id="cb23-528"><a href="#cb23-528" aria-hidden="true" tabindex="-1"></a><span class="co">#result_MLE=arma.spec(ar=phi_MLE, var.noise = s2, log='yes',main = '')</span></span>
<span id="cb23-529"><a href="#cb23-529" aria-hidden="true" tabindex="-1"></a>result_MLE<span class="ot">=</span><span class="fu">arma.spec</span>(<span class="at">ar=</span>phi_MLE, <span class="at">var.noise =</span> s2, <span class="at">main =</span> <span class="st">''</span>)</span>
<span id="cb23-530"><a href="#cb23-530" aria-hidden="true" tabindex="-1"></a>freq<span class="ot">=</span>result_MLE<span class="sc">$</span>freq</span>
<span id="cb23-531"><a href="#cb23-531" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-532"><a href="#cb23-532" aria-hidden="true" tabindex="-1"></a>spec<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>,<span class="at">nrow=</span>n_sample,<span class="at">ncol=</span><span class="fu">length</span>(freq))</span>
<span id="cb23-533"><a href="#cb23-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-534"><a href="#cb23-534" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sample){</span>
<span id="cb23-535"><a href="#cb23-535" aria-hidden="true" tabindex="-1"></a>result<span class="ot">=</span><span class="fu">arma.spec</span>(<span class="at">ar=</span>phi_sample[i,], <span class="at">var.noise =</span> v_sample[i],<span class="co"># log='yes',</span></span>
<span id="cb23-536"><a href="#cb23-536" aria-hidden="true" tabindex="-1"></a>                 <span class="at">main =</span> <span class="st">''</span>,<span class="at">plot=</span><span class="cn">FALSE</span>)</span>
<span id="cb23-537"><a href="#cb23-537" aria-hidden="true" tabindex="-1"></a>spec[i,]<span class="ot">=</span>result<span class="sc">$</span>spec</span>
<span id="cb23-538"><a href="#cb23-538" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-539"><a href="#cb23-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-540"><a href="#cb23-540" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>freq,<span class="fu">log</span>(spec[<span class="dv">1</span>,]),<span class="at">type=</span><span class="st">'l'</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">12</span>),<span class="at">ylab=</span><span class="st">"log spectra"</span>,</span>
<span id="cb23-541"><a href="#cb23-541" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"frequency"</span>,<span class="at">col=</span><span class="dv">0</span>)</span>
<span id="cb23-542"><a href="#cb23-542" aria-hidden="true" tabindex="-1"></a><span class="co">#for (i in 1:n_sample){</span></span>
<span id="cb23-543"><a href="#cb23-543" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>){</span>
<span id="cb23-544"><a href="#cb23-544" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>freq,<span class="fu">log</span>(spec[i,]),<span class="at">col=</span><span class="st">'darkgray'</span>)</span>
<span id="cb23-545"><a href="#cb23-545" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-546"><a href="#cb23-546" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>freq,<span class="fu">log</span>(result_MLE<span class="sc">$</span>spec))</span>
<span id="cb23-547"><a href="#cb23-547" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">12</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">'red'</span>)</span>
<span id="cb23-548"><a href="#cb23-548" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-549"><a href="#cb23-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-550"><a href="#cb23-550" aria-hidden="true" tabindex="-1"></a><span class="fu">## ARIMA processes 📖</span></span>
<span id="cb23-551"><a href="#cb23-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-552"><a href="#cb23-552" aria-hidden="true" tabindex="-1"></a>This section introduces the ARMA and ARIMA processes, their definitions, stability, invertibility, and spectral density. It is based on a <span class="co">[</span><span class="ot">handout</span><span class="co">](handouts/c4-ARIMA.pdf)</span> from the course. Ideally it should be expanded with more details and examples and code for simulating ARMA and ARIMA processes. I'm not sure why Prado didn't go any deeper in the course, but the NDLMs generalize the ARMA and ARIMA processes, so perhaps we will cover them as special cases of the NDLMs in the next lessons.</span>
<span id="cb23-553"><a href="#cb23-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-554"><a href="#cb23-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-555"><a href="#cb23-555" aria-hidden="true" tabindex="-1"></a>\index{ARMA process!definition}</span>
<span id="cb23-556"><a href="#cb23-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-557"><a href="#cb23-557" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb23-558"><a href="#cb23-558" aria-hidden="true" tabindex="-1"></a><span class="fu">## ARMA Model Definition {.unnumbered}</span></span>
<span id="cb23-559"><a href="#cb23-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-560"><a href="#cb23-560" aria-hidden="true" tabindex="-1"></a>A time series process is a zero-mean autoregressive moving average process if it is given by</span>
<span id="cb23-561"><a href="#cb23-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-562"><a href="#cb23-562" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-563"><a href="#cb23-563" aria-hidden="true" tabindex="-1"></a>\operatorname{ARMA}(p,q)= \textcolor{red}</span>
<span id="cb23-564"><a href="#cb23-564" aria-hidden="true" tabindex="-1"></a>                {\underbrace{\sum_{i=1}^{p} \phi_i y_{t-i}}_{AR(P)}}</span>
<span id="cb23-565"><a href="#cb23-565" aria-hidden="true" tabindex="-1"></a><span class="ss">      + </span></span>
<span id="cb23-566"><a href="#cb23-566" aria-hidden="true" tabindex="-1"></a>      \textcolor{blue}</span>
<span id="cb23-567"><a href="#cb23-567" aria-hidden="true" tabindex="-1"></a>                {\underbrace{\sum_{j=1}^{q} \theta_j \epsilon_{t-j}}_{MA(Q)}} </span>
<span id="cb23-568"><a href="#cb23-568" aria-hidden="true" tabindex="-1"></a><span class="ss">      + </span>\epsilon_t </span>
<span id="cb23-569"><a href="#cb23-569" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arma-definition}</span>
<span id="cb23-570"><a href="#cb23-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-571"><a href="#cb23-571" aria-hidden="true" tabindex="-1"></a>with $\epsilon_t \sim N(0, v)$.</span>
<span id="cb23-572"><a href="#cb23-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-573"><a href="#cb23-573" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For $q = 0$, we get an AR(p) process.</span>
<span id="cb23-574"><a href="#cb23-574" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For $p = 0$, we get a MA(q) i.e. moving average process of order $q$.</span>
<span id="cb23-575"><a href="#cb23-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-576"><a href="#cb23-576" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-577"><a href="#cb23-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-578"><a href="#cb23-578" aria-hidden="true" tabindex="-1"></a>Next we will define the notions of stability and invertibility of an ARMA process.</span>
<span id="cb23-579"><a href="#cb23-579" aria-hidden="true" tabindex="-1"></a>\index{ARMA process!stability}</span>
<span id="cb23-580"><a href="#cb23-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-581"><a href="#cb23-581" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb23-582"><a href="#cb23-582" aria-hidden="true" tabindex="-1"></a><span class="fu">## Stability Definition {.unnumbered}</span></span>
<span id="cb23-583"><a href="#cb23-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-584"><a href="#cb23-584" aria-hidden="true" tabindex="-1"></a>An ARMA process is **stable** if the roots of the AR characteristic polynomial <span class="co">[</span><span class="ot">stable</span><span class="co">]</span>{.column-margin}</span>
<span id="cb23-585"><a href="#cb23-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-586"><a href="#cb23-586" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-587"><a href="#cb23-587" aria-hidden="true" tabindex="-1"></a>\Phi(u) = 1 - \phi_1 u - \phi_2 u^2 - \ldots - \phi_p u^p</span>
<span id="cb23-588"><a href="#cb23-588" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-589"><a href="#cb23-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-590"><a href="#cb23-590" aria-hidden="true" tabindex="-1"></a>lie outside the unit circle, i.e., for all $u$ such that $\Phi(u) = 0$, $|u| &gt; 1$.</span>
<span id="cb23-591"><a href="#cb23-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-592"><a href="#cb23-592" aria-hidden="true" tabindex="-1"></a>Equivalently, this happens when the reciprocal roots of the AR polynomial have moduli smaller than 1.</span>
<span id="cb23-593"><a href="#cb23-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-594"><a href="#cb23-594" aria-hidden="true" tabindex="-1"></a>This condition implies stationarity.</span>
<span id="cb23-595"><a href="#cb23-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-596"><a href="#cb23-596" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-597"><a href="#cb23-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-598"><a href="#cb23-598" aria-hidden="true" tabindex="-1"></a>\index{ARMA process!invertibility}</span>
<span id="cb23-599"><a href="#cb23-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-600"><a href="#cb23-600" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb23-601"><a href="#cb23-601" aria-hidden="true" tabindex="-1"></a><span class="fu">## Invertible ARMA Definition {.unnumbered}</span></span>
<span id="cb23-602"><a href="#cb23-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-603"><a href="#cb23-603" aria-hidden="true" tabindex="-1"></a>An ARMA process is **invertible** if the roots of the MA **characteristic polynomial** given by <span class="co">[</span><span class="ot">invertible</span><span class="co">]</span>{.column-margin}</span>
<span id="cb23-604"><a href="#cb23-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-605"><a href="#cb23-605" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-606"><a href="#cb23-606" aria-hidden="true" tabindex="-1"></a>\Theta(u) = 1 + \theta_1 u + \ldots + \theta_q u^q,</span>
<span id="cb23-607"><a href="#cb23-607" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arma-ma-poly}</span>
<span id="cb23-608"><a href="#cb23-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-609"><a href="#cb23-609" aria-hidden="true" tabindex="-1"></a>lie outside the unit circle.</span>
<span id="cb23-610"><a href="#cb23-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-611"><a href="#cb23-611" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-612"><a href="#cb23-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-613"><a href="#cb23-613" aria-hidden="true" tabindex="-1"></a>Note that $\Phi(B) y_t = \Theta(B) \epsilon_t$.</span>
<span id="cb23-614"><a href="#cb23-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-615"><a href="#cb23-615" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When an ARMA process is **stable**, it can be written as an infinite order moving average process.</span>
<span id="cb23-616"><a href="#cb23-616" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When an ARMA process is **invertible**, it can be written as an infinite order autoregressive process.</span>
<span id="cb23-617"><a href="#cb23-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-618"><a href="#cb23-618" aria-hidden="true" tabindex="-1"></a>\index{ARIMA process!definition}</span>
<span id="cb23-619"><a href="#cb23-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-620"><a href="#cb23-620" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb23-621"><a href="#cb23-621" aria-hidden="true" tabindex="-1"></a><span class="fu">## ARIMA Processes {.unnumbered}</span></span>
<span id="cb23-622"><a href="#cb23-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-623"><a href="#cb23-623" aria-hidden="true" tabindex="-1"></a>An autoregressive integrated moving average process with orders $p$, $d$, and $q$ is a process that can be written as</span>
<span id="cb23-624"><a href="#cb23-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-625"><a href="#cb23-625" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-626"><a href="#cb23-626" aria-hidden="true" tabindex="-1"></a>(1 - B)^d y_t = \sum_{i=1}^{p} \phi_i y_{t-i} + \sum_{j=1}^{q} \theta_j \epsilon_{t-j} + \epsilon_t,</span>
<span id="cb23-627"><a href="#cb23-627" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arima-definition}</span>
<span id="cb23-628"><a href="#cb23-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-629"><a href="#cb23-629" aria-hidden="true" tabindex="-1"></a>where $B$ is the backshift operator, $d$ is the order of integration, and $\epsilon_t \sim N(0, v)$.</span>
<span id="cb23-630"><a href="#cb23-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-631"><a href="#cb23-631" aria-hidden="true" tabindex="-1"></a>in other words, $y_t$ follows an ARIMA(p, d, q) if the $d$ difference of $y_t$ follows an ARMA(p, q).</span>
<span id="cb23-632"><a href="#cb23-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-633"><a href="#cb23-633" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-634"><a href="#cb23-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-635"><a href="#cb23-635" aria-hidden="true" tabindex="-1"></a>Estimation in ARIMA processes can be done via *least squares*, *maximum likelihood*, and also *in a Bayesian way*. We will not discuss Bayesian estimation of ARIMA processes in this course.</span>
<span id="cb23-636"><a href="#cb23-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-637"><a href="#cb23-637" aria-hidden="true" tabindex="-1"></a><span class="fu">### Spectral Density of ARMA Processes</span></span>
<span id="cb23-638"><a href="#cb23-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-639"><a href="#cb23-639" aria-hidden="true" tabindex="-1"></a>\index{ARMA process!spectral density}</span>
<span id="cb23-640"><a href="#cb23-640" aria-hidden="true" tabindex="-1"></a>For a given AR(p) process with AR coefficients $\phi_1, \dots, \phi_p$ and variance $v$, we can obtain its **spectral density** as</span>
<span id="cb23-641"><a href="#cb23-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-642"><a href="#cb23-642" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-643"><a href="#cb23-643" aria-hidden="true" tabindex="-1"></a>f(\omega) = \frac{v}{2\pi |\Phi(e^{-i\omega})|^2} = \frac{v}{2\pi |1 - \phi_1 e^{-i\omega} - \ldots - \phi_p e^{-ip\omega}|^2},</span>
<span id="cb23-644"><a href="#cb23-644" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ar-spectral-density}</span>
<span id="cb23-645"><a href="#cb23-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-646"><a href="#cb23-646" aria-hidden="true" tabindex="-1"></a>with $\omega$ a frequency in $(0, \pi)$.</span>
<span id="cb23-647"><a href="#cb23-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-648"><a href="#cb23-648" aria-hidden="true" tabindex="-1"></a>The spectral density provides a frequency-domain representation of the process that is appealing because of its interpretability.</span>
<span id="cb23-649"><a href="#cb23-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-650"><a href="#cb23-650" aria-hidden="true" tabindex="-1"></a>For instance, an AR(2) process that has one pair of complex-valued reciprocal roots with modulus 0.7 and a period of $\lambda = 12$, will show a mode in the spectral density located at a frequency of $2\pi/12$. If we keep the period of the process at the same value of 12 but increase its modulus to 0.95, the spectral density will continue to show a mode at $2\pi/12$, but the value of $f(2\pi/12)$ will be higher, indicating a more persistent *quasi-periodic* behavior.</span>
<span id="cb23-651"><a href="#cb23-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-652"><a href="#cb23-652" aria-hidden="true" tabindex="-1"></a>Similarly, we can obtain the spectral density of an ARMA process with AR characteristic polynomial $\Phi(u) = 1 - \phi_1 u - \ldots - \phi_p u^p$ and MA characteristic polynomial $\Theta(u) = 1 + \theta_1 u + \ldots + \theta_q u^q$, and variance $v$ as</span>
<span id="cb23-653"><a href="#cb23-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-654"><a href="#cb23-654" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-655"><a href="#cb23-655" aria-hidden="true" tabindex="-1"></a>f(\omega) = \frac{v}{2\pi} \frac{|\Theta(e^{-i\omega})|^2}{|\Phi(e^{-i\omega})|^2}.</span>
<span id="cb23-656"><a href="#cb23-656" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arma-spectral-density}</span>
<span id="cb23-657"><a href="#cb23-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-658"><a href="#cb23-658" aria-hidden="true" tabindex="-1"></a>Note that if we have posterior estimates or posterior samples of the AR/ARMA coefficients and the variance $v$, we can obtain samples from the spectral density of AR/ARMA processes using the equations above.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"bottom","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>