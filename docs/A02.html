<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">

<title>Appendix: Discrete Distributions – Bayesian Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-923206e44a13b4518db4dede9f4ebdc9.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-37379e3bbb48fc9e4c504b22bdb22879.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-e12ace95bce8268b44b48d9ebb190a16.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-37379e3bbb48fc9e4c504b22bdb22879.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./A01.html">6. Appendices</a></li><li class="breadcrumb-item"><a href="./A02.html">Appendix: Discrete Distributions</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Statistics</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Intro</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">1. From Concept to Data Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on paradigms of probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayes’ Theorem</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conditional Probability and Bayes’ Law</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conditional Probability and Bayes’ Law</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Frequentist Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework - Frequentist MLE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Likelihoods and MLEs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Bayesian Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Priors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework Posterior Probabilities</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bernoulli/binomial data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Priors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Poisson Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Poisson Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Honors Quiz - Beta Bernoulli</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exponential Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework exponential data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Normal/Gaussian Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework Normal data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Non-Informative Priors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework Alternative Priors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Brief Review of Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">—</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Honnors Homework On Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">2. Techniques and Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Modeling and Monte Carlo estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Modeling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Monte Carlo estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes - Metropolis-Hastings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on the Metropolis-Hastings algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes - Gibbs sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HW - Gibbs-Sampling algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes - Assessing Convergence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on the Gibbs-Sampling algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Honnors Homework on M-H algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes - Linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HW on Linear Regression Model Part 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HW - Deviance information criterion (DIC)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">C2-L08 ANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HW on ANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HW+ - Multiple Factor ANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes - Logistic regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes - Poisson regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Poisson regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes - Hierarchical modeling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Hierarchical Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Non-Normal Hierarchical Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Capstone Project</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework on Predictive distributions and mixture models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">3. Mixture Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Concepts of Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex1-Basic-Definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Concepts of Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex2-Gaussian-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mixtures of Gaussians</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex3-Zero-Inflated-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Definition of Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex4-Def-mixture-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Zero inflated distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Concepts of Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Concepts of Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The EM algorithm for zero-inflated mixtures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The EM algorithm for Zero-Inflated Mixtures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The EM algorithm for Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MCMC for Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The MCMC algorithm for Zero-Inflated Mixtures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Markov chain Monte Carlo algorithms for Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Applications of Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Old Faithful eruptions density estimation with the EM algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Old Faithful eruptions density estimation with the MCMC algorithms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Mixture Models for Classification of Banknotes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Practical Considerations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computational considerations for Mixture Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Information Criteria (BIC)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Estimating the number of components in Bayesian settings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Estimating the partition structure in Bayesian models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05-Ex5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The MCMC algorithm for Zero-Inflated Mixtures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">4. Time series Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 0: Introductions to time series analysis and the AR(1) process</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introductions to Time Series analysis &amp; the AR(1) process</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The AR(p) process</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Normal Dynamic Linear Models, Part 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Normal Dynamic Linear Models, Part 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Final Project</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 0: Feyman Notebook on Bayesian Time Series Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">5. Capstone Project</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
 <span class="menu-text">C5-L01.qmd</span>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">6. Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix: Notation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Appendix: Discrete Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix: Discrete Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Indicator Functions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exponents &amp; Logarithms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The ArgMax function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Law of large numbers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Central Limit Theorem</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conjugate prior - Wikipedia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Link function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayes by backprop</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Books in R &amp; Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#discrete-distributions" id="toc-discrete-distributions" class="nav-link active" data-scroll-target="#discrete-distributions"><span class="header-section-number">1</span> Discrete Distributions</a>
  <ul class="collapse">
  <li><a href="#sec-discrete-uniform" id="toc-sec-discrete-uniform" class="nav-link" data-scroll-target="#sec-discrete-uniform"><span class="header-section-number">1.1</span> Discrete Uniform</a>
  <ul class="collapse">
  <li><a href="#stories" id="toc-stories" class="nav-link" data-scroll-target="#stories"><span class="header-section-number">1.1.1</span> Stories</a></li>
  <li><a href="#moments" id="toc-moments" class="nav-link" data-scroll-target="#moments"><span class="header-section-number">1.1.2</span> Moments</a></li>
  <li><a href="#probability-mass-function-pmf" id="toc-probability-mass-function-pmf" class="nav-link" data-scroll-target="#probability-mass-function-pmf"><span class="header-section-number">1.1.3</span> Probability mass function (PMF)</a></li>
  <li><a href="#cumulative-distribution-function-cdf" id="toc-cumulative-distribution-function-cdf" class="nav-link" data-scroll-target="#cumulative-distribution-function-cdf"><span class="header-section-number">1.1.4</span> Cumulative distribution function (CDF)</a></li>
  <li><a href="#prior" id="toc-prior" class="nav-link" data-scroll-target="#prior"><span class="header-section-number">1.1.5</span> Prior</a></li>
  </ul></li>
  <li><a href="#sec-bernoulli-distribution" id="toc-sec-bernoulli-distribution" class="nav-link" data-scroll-target="#sec-bernoulli-distribution"><span class="header-section-number">1.2</span> Bernoulli Distribution</a>
  <ul class="collapse">
  <li><a href="#stories-1" id="toc-stories-1" class="nav-link" data-scroll-target="#stories-1"><span class="header-section-number">1.2.1</span> Stories</a></li>
  <li><a href="#parameters" id="toc-parameters" class="nav-link" data-scroll-target="#parameters"><span class="header-section-number">1.2.2</span> Parameters</a></li>
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples"><span class="header-section-number">1.2.3</span> Examples</a></li>
  <li><a href="#checklist" id="toc-checklist" class="nav-link" data-scroll-target="#checklist"><span class="header-section-number">1.2.4</span> Checklist</a></li>
  <li><a href="#moments-1" id="toc-moments-1" class="nav-link" data-scroll-target="#moments-1"><span class="header-section-number">1.2.5</span> Moments</a></li>
  <li><a href="#pmf" id="toc-pmf" class="nav-link" data-scroll-target="#pmf"><span class="header-section-number">1.2.6</span> PMF</a></li>
  <li><a href="#cdf" id="toc-cdf" class="nav-link" data-scroll-target="#cdf"><span class="header-section-number">1.2.7</span> CDF</a></li>
  <li><a href="#likelihood" id="toc-likelihood" class="nav-link" data-scroll-target="#likelihood"><span class="header-section-number">1.2.8</span> Likelihood</a></li>
  <li><a href="#entropy-and-information" id="toc-entropy-and-information" class="nav-link" data-scroll-target="#entropy-and-information"><span class="header-section-number">1.2.9</span> Entropy and Information</a></li>
  <li><a href="#usage" id="toc-usage" class="nav-link" data-scroll-target="#usage"><span class="header-section-number">1.2.10</span> Usage</a></li>
  <li><a href="#plots" id="toc-plots" class="nav-link" data-scroll-target="#plots"><span class="header-section-number">1.2.11</span> Plots</a></li>
  </ul></li>
  <li><a href="#sec-binomial-distribution" id="toc-sec-binomial-distribution" class="nav-link" data-scroll-target="#sec-binomial-distribution"><span class="header-section-number">1.3</span> Binomial distribution</a>
  <ul class="collapse">
  <li><a href="#stories-2" id="toc-stories-2" class="nav-link" data-scroll-target="#stories-2"><span class="header-section-number">1.3.1</span> Stories</a></li>
  <li><a href="#parameters-1" id="toc-parameters-1" class="nav-link" data-scroll-target="#parameters-1"><span class="header-section-number">1.3.2</span> Parameters</a></li>
  <li><a href="#conditions" id="toc-conditions" class="nav-link" data-scroll-target="#conditions"><span class="header-section-number">1.3.3</span> Conditions</a></li>
  <li><a href="#examples-1" id="toc-examples-1" class="nav-link" data-scroll-target="#examples-1"><span class="header-section-number">1.3.4</span> Examples</a></li>
  <li><a href="#usage-1" id="toc-usage-1" class="nav-link" data-scroll-target="#usage-1"><span class="header-section-number">1.3.5</span> Usage</a></li>
  <li><a href="#relationships" id="toc-relationships" class="nav-link" data-scroll-target="#relationships"><span class="header-section-number">1.3.6</span> Relationships</a></li>
  <li><a href="#plots-1" id="toc-plots-1" class="nav-link" data-scroll-target="#plots-1"><span class="header-section-number">1.3.7</span> Plots</a></li>
  </ul></li>
  <li><a href="#sec-hypergeometric-distribution" id="toc-sec-hypergeometric-distribution" class="nav-link" data-scroll-target="#sec-hypergeometric-distribution"><span class="header-section-number">1.4</span> Hypergeometric distribution</a>
  <ul class="collapse">
  <li><a href="#story-1---urn-model" id="toc-story-1---urn-model" class="nav-link" data-scroll-target="#story-1---urn-model"><span class="header-section-number">1.4.1</span> story 1 - Urn Model</a></li>
  <li><a href="#examples-2" id="toc-examples-2" class="nav-link" data-scroll-target="#examples-2"><span class="header-section-number">1.4.2</span> Examples</a></li>
  <li><a href="#story" id="toc-story" class="nav-link" data-scroll-target="#story"><span class="header-section-number">1.4.3</span> Story</a></li>
  </ul></li>
  <li><a href="#sec-poisson-distribution" id="toc-sec-poisson-distribution" class="nav-link" data-scroll-target="#sec-poisson-distribution"><span class="header-section-number">1.5</span> Poisson distribution</a>
  <ul class="collapse">
  <li><a href="#stories-3" id="toc-stories-3" class="nav-link" data-scroll-target="#stories-3"><span class="header-section-number">1.5.1</span> Stories</a></li>
  <li><a href="#checklist-1" id="toc-checklist-1" class="nav-link" data-scroll-target="#checklist-1"><span class="header-section-number">1.5.2</span> Checklist</a></li>
  <li><a href="#examples-3" id="toc-examples-3" class="nav-link" data-scroll-target="#examples-3"><span class="header-section-number">1.5.3</span> Examples</a></li>
  <li><a href="#moments-2" id="toc-moments-2" class="nav-link" data-scroll-target="#moments-2"><span class="header-section-number">1.5.4</span> Moments</a></li>
  <li><a href="#probability-mass-function-pmf-1" id="toc-probability-mass-function-pmf-1" class="nav-link" data-scroll-target="#probability-mass-function-pmf-1"><span class="header-section-number">1.5.5</span> Probability mass function (PMF)</a></li>
  <li><a href="#cumulative-distribution-function-cdf-1" id="toc-cumulative-distribution-function-cdf-1" class="nav-link" data-scroll-target="#cumulative-distribution-function-cdf-1"><span class="header-section-number">1.5.6</span> Cumulative distribution function (CDF)</a></li>
  </ul></li>
  <li><a href="#sec-geometric-distribution" id="toc-sec-geometric-distribution" class="nav-link" data-scroll-target="#sec-geometric-distribution"><span class="header-section-number">1.6</span> Geometric distribution</a>
  <ul class="collapse">
  <li><a href="#stories-4" id="toc-stories-4" class="nav-link" data-scroll-target="#stories-4"><span class="header-section-number">1.6.1</span> Stories</a></li>
  <li><a href="#conditions-1" id="toc-conditions-1" class="nav-link" data-scroll-target="#conditions-1"><span class="header-section-number">1.6.2</span> Conditions</a></li>
  <li><a href="#examples-4" id="toc-examples-4" class="nav-link" data-scroll-target="#examples-4"><span class="header-section-number">1.6.3</span> Examples</a></li>
  <li><a href="#moments-3" id="toc-moments-3" class="nav-link" data-scroll-target="#moments-3"><span class="header-section-number">1.6.4</span> Moments</a></li>
  <li><a href="#pmf-1" id="toc-pmf-1" class="nav-link" data-scroll-target="#pmf-1"><span class="header-section-number">1.6.5</span> PMF</a></li>
  <li><a href="#cdf-1" id="toc-cdf-1" class="nav-link" data-scroll-target="#cdf-1"><span class="header-section-number">1.6.6</span> CDF</a></li>
  <li><a href="#memoryless-property" id="toc-memoryless-property" class="nav-link" data-scroll-target="#memoryless-property"><span class="header-section-number">1.6.7</span> Memoryless property</a></li>
  <li><a href="#worked-out-examples" id="toc-worked-out-examples" class="nav-link" data-scroll-target="#worked-out-examples"><span class="header-section-number">1.6.8</span> Worked out Examples</a></li>
  <li><a href="#plots-2" id="toc-plots-2" class="nav-link" data-scroll-target="#plots-2"><span class="header-section-number">1.6.9</span> Plots</a></li>
  </ul></li>
  <li><a href="#sec-negative-binomial-distribution" id="toc-sec-negative-binomial-distribution" class="nav-link" data-scroll-target="#sec-negative-binomial-distribution"><span class="header-section-number">1.7</span> Negative Binomial Distribution</a>
  <ul class="collapse">
  <li><a href="#story-1" id="toc-story-1" class="nav-link" data-scroll-target="#story-1"><span class="header-section-number">1.7.1</span> Story</a></li>
  <li><a href="#parameters-2" id="toc-parameters-2" class="nav-link" data-scroll-target="#parameters-2"><span class="header-section-number">1.7.2</span> Parameters</a></li>
  <li><a href="#conditions-2" id="toc-conditions-2" class="nav-link" data-scroll-target="#conditions-2"><span class="header-section-number">1.7.3</span> Conditions</a></li>
  <li><a href="#examples-5" id="toc-examples-5" class="nav-link" data-scroll-target="#examples-5"><span class="header-section-number">1.7.4</span> Examples</a></li>
  <li><a href="#moments-4" id="toc-moments-4" class="nav-link" data-scroll-target="#moments-4"><span class="header-section-number">1.7.5</span> Moments</a></li>
  <li><a href="#probability-mass-function-pmf-2" id="toc-probability-mass-function-pmf-2" class="nav-link" data-scroll-target="#probability-mass-function-pmf-2"><span class="header-section-number">1.7.6</span> Probability mass function (PMF)</a></li>
  <li><a href="#cumulative-distribution-function-cdf-2" id="toc-cumulative-distribution-function-cdf-2" class="nav-link" data-scroll-target="#cumulative-distribution-function-cdf-2"><span class="header-section-number">1.7.7</span> Cumulative distribution function (CDF)</a></li>
  </ul></li>
  <li><a href="#sec-multinomial-distribution" id="toc-sec-multinomial-distribution" class="nav-link" data-scroll-target="#sec-multinomial-distribution"><span class="header-section-number">1.8</span> Multinomial Distribution</a>
  <ul class="collapse">
  <li><a href="#story-2" id="toc-story-2" class="nav-link" data-scroll-target="#story-2"><span class="header-section-number">1.8.1</span> Story</a></li>
  <li><a href="#examples-6" id="toc-examples-6" class="nav-link" data-scroll-target="#examples-6"><span class="header-section-number">1.8.2</span> Examples</a></li>
  <li><a href="#moments-5" id="toc-moments-5" class="nav-link" data-scroll-target="#moments-5"><span class="header-section-number">1.8.3</span> Moments</a></li>
  <li><a href="#probability-mass-function-pmf-3" id="toc-probability-mass-function-pmf-3" class="nav-link" data-scroll-target="#probability-mass-function-pmf-3"><span class="header-section-number">1.8.4</span> Probability Mass Function (PMF)</a></li>
  </ul></li>
  <li><a href="#beta-binomial" id="toc-beta-binomial" class="nav-link" data-scroll-target="#beta-binomial"><span class="header-section-number">1.9</span> Beta Binomial</a>
  <ul class="collapse">
  <li><a href="#story-1---polya-urn-model" id="toc-story-1---polya-urn-model" class="nav-link" data-scroll-target="#story-1---polya-urn-model"><span class="header-section-number">1.9.1</span> Story 1 - Polya Urn Model</a></li>
  <li><a href="#story-2-compound-distribution" id="toc-story-2-compound-distribution" class="nav-link" data-scroll-target="#story-2-compound-distribution"><span class="header-section-number">1.9.2</span> Story 2 compound distribution</a></li>
  <li><a href="#moments-6" id="toc-moments-6" class="nav-link" data-scroll-target="#moments-6"><span class="header-section-number">1.9.3</span> Moments</a></li>
  <li><a href="#probability-mass-function-pmf-4" id="toc-probability-mass-function-pmf-4" class="nav-link" data-scroll-target="#probability-mass-function-pmf-4"><span class="header-section-number">1.9.4</span> Probability mass function (PMF)</a></li>
  <li><a href="#cumulative-distribution-function-cdf-3" id="toc-cumulative-distribution-function-cdf-3" class="nav-link" data-scroll-target="#cumulative-distribution-function-cdf-3"><span class="header-section-number">1.9.5</span> Cumulative distribution function (CDF)</a></li>
  <li><a href="#relations" id="toc-relations" class="nav-link" data-scroll-target="#relations"><span class="header-section-number">1.9.6</span> Relations</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./A01.html">6. Appendices</a></li><li class="breadcrumb-item"><a href="./A02.html">Appendix: Discrete Distributions</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Appendix: Discrete Distributions</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Oren Bochman </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="discrete-distributions" class="level1 page-columns page-full" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Discrete Distributions</h1>
<section id="sec-discrete-uniform" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="sec-discrete-uniform"><span class="header-section-number">1.1</span> Discrete Uniform</h2>
<section id="stories" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="stories"><span class="header-section-number">1.1.1</span> Stories</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Discrete Uniform Finite set Parametrization
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">C</span> be a finite, nonempty set of numbers and <span class="math inline">X</span> <em>random variable</em> associated with the event of <em>choosing one of these numbers uniformly at random</em>, that is all values being equally likely <span class="math inline">X(x=c)</span></p>
<p>Then <span class="math inline">X</span> is said to have the Discrete Uniform distribution with parameter <span class="math inline">C</span>.</p>
<p>We denote this by <span class="math inline">X ∼ DUnif(C)</span>.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Discrete Uniform with Lower and Upper bound Parametrization
</div>
</div>
<div class="callout-body-container callout-body">
<p>When the set C above is <span class="math inline">C=\{c \in \mathbb{Z} \mid a \le c \le b\ \}</span>.</p>
<p>Then <span class="math inline">X</span> is said to have the Discrete Uniform distribution with lower bound parameter <span class="math inline">a</span> and upper bound parameter <span class="math inline">b</span>.</p>
<p>We denote this by <span class="math inline">X ∼ DUnif(a,b)</span>.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Urn Model
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose we have an urn with n balls labeled with the numbers a <span class="math inline">1, \dots, a_n</span> . One drawing from the urn produces a discrete uniform random variable on the set <span class="math inline">\{a_1, \dots, a_n \}</span>.</p>
</div>
</div>
</section>
<section id="moments" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="moments"><span class="header-section-number">1.1.2</span> Moments</h3>
<p><span id="eq-uniform-MGF"><span class="math display">
\begin{aligned}
    \phi_X(t)&amp;={\displaystyle {\frac {e^{at}-e^{(b+1)t}}{n(1-e^{t})}}}  &amp;&amp; \text{(MGF)}
\\  \mathbb{E}[X] &amp;= \frac{a + b}{2} &amp;&amp; \text{(Expectation)}
\\  \mathbb{V}ar[X] &amp;= \frac{(b - a + 1)^2 - 1}{12} &amp;&amp; \text{(Variance)}
\end{aligned}
\tag{1}</span></span></p>
</section>
<section id="probability-mass-function-pmf" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="probability-mass-function-pmf"><span class="header-section-number">1.1.3</span> Probability mass function (PMF)</h3>
<p><span class="math display">
f(x \mid a, b) = \frac{1}{b - a + 1}
</span></p>
</section>
<section id="cumulative-distribution-function-cdf" class="level3" data-number="1.1.4">
<h3 data-number="1.1.4" class="anchored" data-anchor-id="cumulative-distribution-function-cdf"><span class="header-section-number">1.1.4</span> Cumulative distribution function (CDF)</h3>
<p><span class="math display">
F(x \mid a, b) = \frac{\lfloor x \rfloor - a - 1}{b - a + 1} \\\text{where} \lfloor x \rfloor \text{ is the floor function (rounds down reals to nearest smaller integer)}
</span></p>
</section>
<section id="prior" class="level3" data-number="1.1.5">
<h3 data-number="1.1.5" class="anchored" data-anchor-id="prior"><span class="header-section-number">1.1.5</span> Prior</h3>
<p>Since a number of families have the uniform as a special case we can use them as priors when we want a uniform prior:</p>
</section>
</section>
<section id="sec-bernoulli-distribution" class="level2 page-columns page-full" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="sec-bernoulli-distribution"><span class="header-section-number">1.2</span> Bernoulli Distribution</h2>
<section id="stories-1" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="stories-1"><span class="header-section-number">1.2.1</span> Stories</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Bernoulli distribution arises when modeling the outcome of a binary event called a <strong>Bernoulli trial</strong>. .</p>
<p>Let <span class="math inline">X</span> be the indicator variable corresponding to the success of getting “heads” in a “coin toss”, with a coin that has probability of success <span class="math inline">p</span> for getting “heads”.</p>
<p>Then X has a <em>Bernoulli Distribution</em> with parameter <span class="math inline">p</span></p>
<p>We denote this as <span class="math inline">X \sim Bern(p)</span></p>
</div>
</div>
</section>
<section id="parameters" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="parameters"><span class="header-section-number">1.2.2</span> Parameters</h3>
<p>Because of this story, the <em>parameter</em> <span class="math inline">p</span> is often called the <strong>success</strong> probability of the Bern(p) distribution.</p>
</section>
<section id="examples" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="examples"><span class="header-section-number">1.2.3</span> Examples</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>fair coin toss</li>
<li>unfair coin toss</li>
<li>ad click</li>
<li>web site conversion</li>
<li>death or survival of a patient in a medical trial</li>
<li>indicator random variable</li>
</ul>
</div>
</div>
</section>
<section id="checklist" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="checklist"><span class="header-section-number">1.2.4</span> Checklist</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Discrete data</li>
<li>A single trial</li>
<li>Only two trial outcomes: <strong>success</strong> and <strong>failure</strong> (These do not need to literally represent successes and failures, but this shorthand is typically used.)</li>
</ul>
</div>
</div>
<p><span id="eq-bernoulli-rv"><span class="math display">
\begin{aligned}
X &amp;\sim Bernoulli(p)\\ &amp; \sim Bern(p)\\ &amp; \sim B(p)  \end{aligned}
\tag{2}</span></span></p>
</section>
<section id="moments-1" class="level3" data-number="1.2.5">
<h3 data-number="1.2.5" class="anchored" data-anchor-id="moments-1"><span class="header-section-number">1.2.5</span> Moments</h3>
<p><span id="eq-bernoulli-MGF"><span class="math display">
M_X(t)=q+pe^{t} \qquad \text{(MGF)}
\tag{3}</span></span></p>
<p><span id="eq-bernoulli-expectation"><span class="math display">
\mathbb{E}[X]= p \qquad \text{(Expectation)}
\tag{4}</span></span></p>
<p><span id="eq-bernoulli-variance"><span class="math display">
\mathbb{V}ar[x]= p(1-p) \qquad \text{(Variance)}
\tag{5}</span></span></p>
</section>
<section id="pmf" class="level3" data-number="1.2.6">
<h3 data-number="1.2.6" class="anchored" data-anchor-id="pmf"><span class="header-section-number">1.2.6</span> PMF</h3>
<p>Where parameter <span class="math inline">p</span> is the probability of getting heads.</p>
<p>The probability for the two events is:</p>
<p><span class="math display">
P(X=1) = p \qquad P(X=0)=1-p
</span></p>
<p><span id="eq-bernoulli-pmf"><span class="math display">
{\displaystyle {\begin{cases}1-p&amp;{\text{if }}k=0\\p&amp;{\text{if }}k=1\end{cases}}}  \qquad \text{(PMF)}
\tag{6}</span></span></p>
</section>
<section id="cdf" class="level3" data-number="1.2.7">
<h3 data-number="1.2.7" class="anchored" data-anchor-id="cdf"><span class="header-section-number">1.2.7</span> CDF</h3>
<p><span id="eq-bernoulli-cdf"><span class="math display">
{\displaystyle {\begin{cases}0&amp;{\text{if }}k&lt;0\\1-p&amp;{\text{if }}0\leq k&lt;1\\1&amp;{\text{if }}k\geq 1\end{cases}}} \qquad \text{(CDF)}
\tag{7}</span></span></p>
</section>
<section id="likelihood" class="level3" data-number="1.2.8">
<h3 data-number="1.2.8" class="anchored" data-anchor-id="likelihood"><span class="header-section-number">1.2.8</span> Likelihood</h3>
<p><span id="eq-bernoulli-likelihood"><span class="math display">
L(\theta) = \prod p^x(1-p)^{1-x} \mathbb{I}_{[0,1]}(x)  \qquad \text{(Likelihood)}
\tag{8}</span></span></p>
<p><span id="eq-bernoulli-log-likelihood"><span class="math display">
\mathcal{L}(\theta) =log(p) \sum x + log(1-p)\sum (1-x)  \qquad \text{(Log Likelihood)}
\tag{9}</span></span></p>
</section>
<section id="entropy-and-information" class="level3" data-number="1.2.9">
<h3 data-number="1.2.9" class="anchored" data-anchor-id="entropy-and-information"><span class="header-section-number">1.2.9</span> Entropy and Information</h3>
<p><span id="eq-bernoulli-entropy"><span class="math display">
\mathbb{H}(x)= -q \ln(q)- p \ln(p) \qquad \text{(Entropy)}
\tag{10}</span></span></p>
<p><span id="eq-bernoulli-information"><span class="math display">
\mathcal{I}[X]\frac{1}{p(1-p)} \qquad \text{(Fisher Information)}
\tag{11}</span></span></p>
<p><span id="eq-bernoulli-prior"><span class="math display">
Beta(x) \qquad \text{(Conjugate Prior)}
\tag{12}</span></span></p>
</section>
<section id="usage" class="level3" data-number="1.2.10">
<h3 data-number="1.2.10" class="anchored" data-anchor-id="usage"><span class="header-section-number">1.2.10</span> Usage</h3>
<div id="tbl-bernoulli-api" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-bernoulli-api-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Usage of Bernoulli
</figcaption>
<div aria-describedby="tbl-bernoulli-api-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Package</th>
<th style="text-align: left;">Syntax</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NumPy</td>
<td style="text-align: left;"><code>rg.choice([0, 1], p=[1-theta, theta])</code></td>
</tr>
<tr class="even">
<td>SciPy</td>
<td style="text-align: left;"><code>scipy.stats.bernoulli(theta)</code></td>
</tr>
<tr class="odd">
<td>Stan</td>
<td style="text-align: left;"><code>bernoulli(theta)</code></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="plots" class="level3 page-columns page-full" data-number="1.2.11">
<h3 data-number="1.2.11" class="anchored" data-anchor-id="plots"><span class="header-section-number">1.2.11</span> Plots</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> bernoulli</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> bernoulli.stats(p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=0.30, var=0.21, skew=0.87, kurt=-1.24</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(bernoulli.ppf(<span class="fl">0.01</span>, p),</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>              bernoulli.ppf(<span class="fl">0.99</span>, p))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>ax.plot(x, bernoulli.pmf(x, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'bernoulli pmf'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, bernoulli.pmf(x, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> bernoulli(p)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="A02_files/figure-html/unnamed-chunk-2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="A02_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Generate random numbers</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> bernoulli.rvs(p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0])</code></pre>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/bio-bernoulli.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="A Swiss stamp issueed in 1994 depicting Mathematician Jakob Bernouilli and the formula and diagram of the law of large numbers"><img src="images/bio-bernoulli.jpg" class="img-fluid figure-img" alt="A Swiss stamp issueed in 1994 depicting Mathematician Jakob Bernouilli and the formula and diagram of the law of large numbers"></a></p>
<figcaption>A Swiss stamp issueed in 1994 depicting Mathematician Jakob Bernouilli and the formula and diagram of the law of large numbers</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Biographical note on Jacob Bernoulli
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>It seems that to make a correct conjecture about any event whatever, it is necessary to calculate exactly the number of possible cases and then to determine how much more likely it is that one case will occur than another. <span class="citation" data-cites="bernoulli1713ars">(<a href="#ref-bernoulli1713ars" role="doc-biblioref">Bernoulli 1713</a>)</span></p>
</blockquote>
<p>The Bernoulli distribution as well as The Binomial distribution are due to Jacob Bernoulli (1655-1705) who was a prominent mathematician in the Bernoulli family. He discovered the fundamental mathematical constant e. With his brother Johann, he was among the first to develop Leibniz’s calculus, introducing the word integral and applying it to polar coordinates and the study of curves such as the catenary, the logarithmic spiral and the cycloid</p>
<p>His most important contribution was in the field of probability, where he derived the first version of the law of large numbers (LLN). The LLN is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value and will tend to become closer to the expected value as more trials are performed. A special form of the LLN (for a binary random variable) was first proved by Jacob Bernoulli. It took him over 20 years to develop sufficiently rigorous mathematical proof.</p>
<!-- todo: convert to a bibliography item and reference with a citation -->
<p>For a more extensive biography visit the following <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Bernoulli_Jacob/">link</a></p>
</div>
</div>
<p>The Bernoulli distribution is built on a trial of a coin toss (possibly biased).</p>
<ul>
<li>We use the Bernoulli distribution to model a random variable for the probability of such a coin toss trial.</li>
<li>We use the Binomial distribution to model a random variable for the probability of getting k heads in N independent trails.</li>
</ul>
</section>
</section>
<section id="sec-binomial-distribution" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="sec-binomial-distribution"><span class="header-section-number">1.3</span> Binomial distribution</h2>
<section id="stories-2" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="stories-2"><span class="header-section-number">1.3.1</span> Stories</h3>
<div id="story-binomial-dist" class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><span id="eq-binomial-experiment"><span class="math display">
\overbrace{\underbrace{\fbox{0}\ \ldots \fbox{0}}_{N_0}\ \underbrace{\fbox{1}\ \ldots \fbox{1}}_{N_1}}^N
\tag{13}</span></span></p>
<p>The Binomial distribution arises when we conduct multiple independent Bernoulli trials and wish to model <span class="math inline">X</span> the number of successes in <span class="math inline">Y_i\mid \theta</span> identically distributed Bernoulli trials with the same probability of success <span class="math inline">\theta</span>. If <span class="math inline">n</span> independent <em>Bernoulli trials</em> are performed, each with the same success probability p.&nbsp;The distribution of X is called the Binomial distribution with parameters n and p.&nbsp;We write <span class="math inline">X \sim \text{Bin}(n, p)</span> to mean that X has the Binomial distribution with parameters n and p, where n is a positive integer and <span class="math inline">0 &lt; p &lt; 1</span>.</p>
</div>
</div>
</section>
<section id="parameters-1" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="parameters-1"><span class="header-section-number">1.3.2</span> Parameters</h3>
<ul>
<li><span class="math inline">\theta</span> - the probability of success in the Bernoulli trials</li>
<li><span class="math inline">N</span> - the total number of trials being conducted</li>
</ul>
</section>
<section id="conditions" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="conditions"><span class="header-section-number">1.3.3</span> Conditions</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Discrete data</li>
<li>Two possible outcomes for each trial</li>
<li>Each trial is independent and</li>
<li>The probability of success/failure is the same in each trial</li>
<li>The outcome is the aggregate number of successes</li>
</ul>
</div>
</div>
</section>
<section id="examples-1" class="level3" data-number="1.3.4">
<h3 data-number="1.3.4" class="anchored" data-anchor-id="examples-1"><span class="header-section-number">1.3.4</span> Examples</h3>
<ul>
<li>to model the aggregate outcome of clinical drug trials,</li>
<li>to estimate the proportion of the population voting for each political party using exit poll data (where there are only two political parties).</li>
</ul>
<p><span id="eq-binomial-rv"><span class="math display">
X \sim Bin[n,p]
\tag{14}</span></span></p>
<p><span id="eq-binomial-pmf"><span class="math display">
f(X=x \mid \theta) = {n \choose x} \theta^x(1-\theta)^{n-x}
\tag{15}</span></span></p>
<p><span id="eq-binomial-likelihood"><span class="math display">
L(\theta)=\prod_{i=1}^{n} {n\choose x_i}  \theta ^ {x_i} (1− \theta) ^ {(n−x_i)}
\tag{16}</span></span></p>
<p><span id="eq-binomial-log-likelihood"><span class="math display">
\begin{aligned}\ell( \theta) &amp;= \log \mathcal{L}( \theta) \\&amp;= \sum_{i=1}^n \left[\log {n\choose x_i} + x_i \log  \theta + (n-x_i)\log (1- \theta) \right].\end{aligned}
\tag{17}</span></span></p>
<p><span id="eq-binomial-expectation"><span class="math display">
\mathbb{E}[X]= N \times  \theta
\tag{18}</span></span></p>
<p><span id="eq-binomial-variance"><span class="math display">
\mathbb{V}ar[X]=N \cdot \theta \cdot (1-\theta)
\tag{19}</span></span></p>
<p><span id="eq-binomial-entropy"><span class="math display">
\mathbb{H}(X) = \frac{1}{2}\log_2 \left (2\pi n \theta(1 - \theta)\right) + O(\frac{1}{n})
\tag{20}</span></span></p>
<p><span id="eq-binomial-information"><span class="math display">
\mathcal{I}(\theta)=\frac{n}{ \theta \cdot (1- \theta)}
\tag{21}</span></span></p>
</section>
<section id="usage-1" class="level3" data-number="1.3.5">
<h3 data-number="1.3.5" class="anchored" data-anchor-id="usage-1"><span class="header-section-number">1.3.5</span> Usage</h3>
<div id="tbl-binomial-api" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-binomial-api-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Usage of Binomial
</figcaption>
<div aria-describedby="tbl-binomial-api-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Package</th>
<th style="text-align: left;">Syntax</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NumPy</td>
<td style="text-align: left;"><code>rg.binomial(N, theta)</code></td>
</tr>
<tr class="even">
<td>SciPy</td>
<td style="text-align: left;"><code>scipy.stats.binom(N, theta)</code></td>
</tr>
<tr class="odd">
<td>Stan</td>
<td style="text-align: left;"><code>binomial(N, theta)</code></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="relationships" class="level3" data-number="1.3.6">
<h3 data-number="1.3.6" class="anchored" data-anchor-id="relationships"><span class="header-section-number">1.3.6</span> Relationships</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/dbinomial.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="binomial distribution relations"><img src="images/dbinomial.png" class="img-fluid figure-img" alt="binomial distribution relations"></a></p>
<figcaption>binomial distribution relations</figcaption>
</figure>
</div>
<p>The Binomial Distribution is related to</p>
<ul>
<li>The <strong>Binomial</strong> is a <em>special case</em> of the <strong>Multinomial distribution</strong> with K =2 (two categories).</li>
<li>the <strong>Poisson distribution</strong> distribution. If <span class="math inline">X \sim Binomial(n, p)</span> rv and <span class="math inline">Y \sim Poisson(np)</span> distribution then <span class="math inline">P(X = n) ≈ P(Y = n)</span> for large <span class="math inline">n</span> and small <span class="math inline">np</span>.</li>
<li>The <strong>Bernoulli distribution</strong> is a <em>special case</em> of the the <strong>Binomial distribution</strong> <br> <span class="math inline">X \sim Binomial(n=1, p) \\ \implies X \sim Bernoulli(p)</span></li>
<li>the <strong>Normal distribution</strong> If <span class="math inline">X \sim Binomial(n, p)</span> RV and <span class="math inline">Y \sim Normal(\mu=np,\sigma=np(1-p))</span> then for integers j and k, <span class="math inline">P(j ≤ X ≤ k) ≈ P(j – 1/2 ≤ Y ≤ k + 1/2)</span>. The approximation is better when <span class="math inline">p ≈ 0.5</span> and when n is large. For more information, see normal approximation to the Binomial</li>
<li>The <strong>Binomial</strong> is a <em>limit</em> of the <strong>Hypergeometric</strong>. The difference between a binomial distribution and a hypergeometric distribution is the difference between sampling with replacement and sampling without replacement. As the population size increases relative to the sample size, the difference becomes negligible. So If <span class="math inline">X \sim Binomial(n, p)</span> RV and <span class="math inline">Y \sim HyperGeometric(N,a,b)</span> then <span class="math display">\lim_{n\to \infty} X = Y </span></li>
</ul>
</section>
<section id="plots-1" class="level3" data-number="1.3.7">
<h3 data-number="1.3.7" class="anchored" data-anchor-id="plots-1"><span class="header-section-number">1.3.7</span> Plots</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> binom</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> binom.stats(n, p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=2.00, var=1.20, skew=0.18, kurt=-0.37</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(binom.ppf(<span class="fl">0.01</span>, n, p),</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>              binom.ppf(<span class="fl">0.99</span>, n, p))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>ax.plot(x, binom.pmf(x, n, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'binom pmf'</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, binom.pmf(x, n, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> binom(n, p)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="A02_files/figure-html/unnamed-chunk-3-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="A02_files/figure-html/unnamed-chunk-3-3.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">## generate random numbers</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> binom.rvs(n, p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>array([0, 1, 0, 1, 2, 3, 3, 3, 1, 2])</code></pre>
</div>
</div>
<pre><code>``` {{python}}
from __future__ import print_function
from ipywidgets import interact, interactive, fixed, interact_manual
import ipywidgets as widgets
import numpy as np
import scipy
from scipy.special import gamma, factorial, comb
import plotly.express as px
import plotly.offline as pyo
import plotly.graph_objs as go
#pyo.init_notebook_mode()
INTERACT_FLAG=False
def binomial_vector_over_y(theta, n):
    total_events = n
    y =  np.linspace(0, total_events , total_events + 1)
    p_y = [comb(int(total_events), int(yelem)) * theta** yelem * (1 - theta)**(total_events - yelem) for yelem in y]

    fig = px.line(x=y, y=p_y, color_discrete_sequence=["steelblue"], 
                  height=600, width=800, title=" Binomial distribution for theta = %lf, n = %d" %(theta, n))
    fig.data[0].line['width'] = 4
    fig.layout.xaxis.title.text = "y"
    fig.layout.yaxis.title.text = "P(y)"
    fig.show()
    
if(INTERACT_FLAG):    
    interact(binomial_vector_over_y, theta=0.5, n=15)
else:
    binomial_vector_over_y(theta=0.5, n=10)
```</code></pre>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sn-mp_ESSMc" title="”" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="sec-hypergeometric-distribution" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-hypergeometric-distribution"><span class="header-section-number">1.4</span> Hypergeometric distribution</h2>
<section id="story-1---urn-model" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="story-1---urn-model"><span class="header-section-number">1.4.1</span> story 1 - Urn Model</h3>
<p>The beta-binomial distribution with parameters <span class="math inline">\alpha</span> success rate and <span class="math inline">\beta</span> failure and <span class="math inline">n</span> the number of trials can be motivated by an Pólya urn model.</p>
<p>Imagine a trial in which a ball is drawn without replacement from urn containing <span class="math inline">\alpha</span> white balls and <span class="math inline">\beta</span> black balls. If this is repeated n times, then the probability of observing x white balls follows a hypergeometric distribution with parameters <span class="math inline">n</span>, <span class="math inline">\alpha</span> and <span class="math inline">\beta</span>.</p>
<p>Note: is we used a</p>
<p>If the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/UgqQc6epZnc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="examples-2" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="examples-2"><span class="header-section-number">1.4.2</span> Examples</h3>
<ul>
<li>k white balls from an in Urn without replacement</li>
<li>capture-recapture</li>
<li>Aces in a poker hand</li>
</ul>
</section>
<section id="story" class="level3" data-number="1.4.3">
<h3 data-number="1.4.3" class="anchored" data-anchor-id="story"><span class="header-section-number">1.4.3</span> Story</h3>
<p>Consider an urn with w white balls and b black balls. We draw n balls out of the urn at random without replacement, such that all w+b samples are equally likely. Let X be the number of white balls in n the sample. Then X is said to have the Hypergeometric distribution with parameters w, b, and n; we denote this by <span class="math inline">X ∼ HGeom(w, b, n)</span></p>
</section>
</section>
<section id="sec-poisson-distribution" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="sec-poisson-distribution"><span class="header-section-number">1.5</span> Poisson distribution</h2>
<section id="stories-3" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="stories-3"><span class="header-section-number">1.5.1</span> Stories</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Poisson Parametrization
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Poisson distribution arises when modeling the number of successes of independent and identically distributed (IID) events in a fixed interval of time or space, occurring at a constant rate <span class="math inline">\lambda</span>. Let <span class="math inline">X</span> represent the count of the number of phone calls received at a call center in a given interval, such as an hour, with the parameter <span class="math inline">\lambda</span> corresponding to the average rate at which events occur in that interval. Then <span class="math inline">X</span> is said to have the Poisson distribution with parameter <span class="math inline">\lambda</span>, and we denote this as <span class="math inline">X \sim \text{Pois}(\lambda)</span>.</p>
<p><span id="eq-poisson-rv"><span class="math display">
X \sim Pois(\lambda)
\tag{22}</span></span></p>
</div>
</div>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/yIPFA1sk5NA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="checklist-1" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="checklist-1"><span class="header-section-number">1.5.2</span> Checklist</h3>
<ul>
<li>Count of discrete events</li>
<li>Individual events occur at a given rate and independently of other events</li>
<li>Fixed amount of time or space in which the events can occur</li>
</ul>
</section>
<section id="examples-3" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="examples-3"><span class="header-section-number">1.5.3</span> Examples</h3>
<ul>
<li>The number of emails you receive in an hour. There are a lot of people who could potentially email you at that hour, but it is unlikely that any specific person will actually email you at that hour. Alternatively, imagine subdividing the hour into milliseconds. There are <span class="math inline">3.6×106</span> seconds in an hour, but in any specific millisecond, it is unlikely that you will get an email.</li>
<li>The number of chips in a chocolate chip cookie. Imagine subdividing the cookie into small cubes; the probability of getting a chocolate chip in a single cube is small, but the number of cubes is large.</li>
<li>The number of earthquakes in a year in some regions of the world. At any given time and location, the probability of an earthquake is small, but there are a large number of possible times and locations for earthquakes to occur over the course of the year.</li>
<li>Count of component failures per week</li>
<li>estimating the failure rate of artificial heart valves,</li>
<li>estimating the prevalence of violent crimes in different districts,</li>
<li>approximating the binomial which is, itself, being used to explain the prevalence of autism in the UK.</li>
</ul>
</section>
<section id="moments-2" class="level3" data-number="1.5.4">
<h3 data-number="1.5.4" class="anchored" data-anchor-id="moments-2"><span class="header-section-number">1.5.4</span> Moments</h3>
<p><span class="math display">
\mathrm{E}(X) = \lambda
</span></p>
<p><span class="math display">
\mathrm{V}ar(X) = \lambda
</span></p>
</section>
<section id="probability-mass-function-pmf-1" class="level3" data-number="1.5.5">
<h3 data-number="1.5.5" class="anchored" data-anchor-id="probability-mass-function-pmf-1"><span class="header-section-number">1.5.5</span> Probability mass function (PMF)</h3>
<p><span id="eq-poisson-PMF"><span class="math display">
f(x \mid \lambda) = \frac{\lambda^x e^{-\lambda}}{x!}
\tag{23}</span></span></p>
</section>
<section id="cumulative-distribution-function-cdf-1" class="level3" data-number="1.5.6">
<h3 data-number="1.5.6" class="anchored" data-anchor-id="cumulative-distribution-function-cdf-1"><span class="header-section-number">1.5.6</span> Cumulative distribution function (CDF)</h3>
<p><span id="eq-poisson-cdf"><span class="math display">
F(x \mid \lambda) = \frac{\Gamma(\lfloor x+1\rfloor,\lambda)}{\lfloor x \rfloor !} \qquad \text{CDF}
\tag{24}</span></span></p>
<p><span id="eq-incomplete-gamma"><span class="math display">
\text{where }\Gamma(u,v)=\int_{v}^{\infty}t^{u-1}e^{-t} \mathrm{d}t \text{ is the upper incomplete gamma function}
\tag{25}</span></span></p>
<p><span id="eq-floor-function"><span class="math display">
\text{and } \lfloor x \rfloor \text{ is the floor function (rounds down reals to nearest smaller integer)}
\tag{26}</span></span></p>
</section>
</section>
<section id="sec-geometric-distribution" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="sec-geometric-distribution"><span class="header-section-number">1.6</span> Geometric distribution</h2>
<section id="stories-4" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="stories-4"><span class="header-section-number">1.6.1</span> Stories</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Geometric Distribution Failures before success
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a sequence of independent Bernoulli trials, each with the same success probability <span class="math inline">p \in (0, 1)</span>, with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by <span class="math inline">X \sim Geom(p)</span>.</p>
<p>For example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).</p>
<p>To get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0’s (failures) ending in a single 1 (success). Each 0 has probability <span class="math inline">q = 1 − p</span> and the final 1 has probability p, so a string of k failures followed by one success has probability <span class="math inline">q^kp</span>.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Geometric distribution Failures and success
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a sequence of independent Bernoulli trials, each with the same success probability <span class="math inline">p \in (0, 1)</span>, with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by <span class="math inline">X \sim Geom(p)</span>.</p>
<p>For example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).</p>
<p>To get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0’s (failures) ending in a single 1 (success). Each 0 has probability <span class="math inline">q = 1 − p</span> and the final 1 has probability p, so a string of k failures followed by one success has probability <span class="math inline">q^kp</span>.</p>
</div>
</div>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/-vvtrsS4rkA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="conditions-1" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="conditions-1"><span class="header-section-number">1.6.2</span> Conditions</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Discrete data</li>
<li>Two possible outcomes for each trial</li>
<li>Each trial is independent and</li>
<li>The probability of success/failure is the same in each trial</li>
<li>The outcome is the count of failures before the first success</li>
</ul>
</div>
</div>
</section>
<section id="examples-4" class="level3" data-number="1.6.3">
<h3 data-number="1.6.3" class="anchored" data-anchor-id="examples-4"><span class="header-section-number">1.6.3</span> Examples</h3>
<ul>
<li>Consider polymerization of an actin filament. At each time step, an actin monomer may add to the end of the filament (“failure”), or an actin monomer may fall off the end (“success”) with (usually very low) probability θ. The length of actin filaments, measured in a number of constitutive monomers, is Geometrically distributed.</li>
</ul>
<p>The <strong>Geometric distribution</strong> arises when we want to know “What is the number of Bernoulli trials required to get the first success?”, i.e., the number of Bernoulli events until a success is observed, such as the probability of getting the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/-vvtrsS4rkA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><span id="eq-geom-rv"><span class="math display">
X \sim Geo(p)
\tag{27}</span></span></p>
</section>
<section id="moments-3" class="level3" data-number="1.6.4">
<h3 data-number="1.6.4" class="anchored" data-anchor-id="moments-3"><span class="header-section-number">1.6.4</span> Moments</h3>
<p><span id="eq-geom-mgf"><span class="math display">
\mathbb{M}_X[t] = \frac{pe^t}{1-(1-p)e^t} \qquad t&lt;-ln(1-p)
\tag{28}</span></span></p>
<p><span id="eq-geom-expectation"><span class="math display">
\mathbb{E}[X] = \frac{1}{p}
\tag{29}</span></span></p>
<p><span id="eq-geom-variance"><span class="math display">
\mathbb{V}ar[X]=\frac{1-p}{p^2}
\tag{30}</span></span></p>
</section>
<section id="pmf-1" class="level3" data-number="1.6.5">
<h3 data-number="1.6.5" class="anchored" data-anchor-id="pmf-1"><span class="header-section-number">1.6.5</span> PMF</h3>
<p><span id="eq-geom-pmf"><span class="math display">
P(X = x \mid p) = p(1-p)^{x-1} \qquad \forall x \in N;\quad 0\le p \le 1
\tag{31}</span></span></p>
</section>
<section id="cdf-1" class="level3" data-number="1.6.6">
<h3 data-number="1.6.6" class="anchored" data-anchor-id="cdf-1"><span class="header-section-number">1.6.6</span> CDF</h3>
<p><span id="eq-geom-cdf"><span class="math display">
1-(1-p)^{\lfloor x\rfloor } \qquad x&lt;1
\tag{32}</span></span></p>
</section>
<section id="memoryless-property" class="level3" data-number="1.6.7">
<h3 data-number="1.6.7" class="anchored" data-anchor-id="memoryless-property"><span class="header-section-number">1.6.7</span> Memoryless property</h3>
<p></p>
<p>The geometric distribution is based on geometric series.</p>
<p>The geometric distribution has the memoryless property:</p>
<p><span class="math display">
P (X &gt; s \mid X &gt;  t) = P (X &gt; s − t)
</span></p>
<p>One can say that the distribution “forgets” what has occurred, so that The probability of getting an additional <span class="math inline">s − t</span> failures, having already observed t failures, is the same as the probability of observing <span class="math inline">s − t</span> failures at the start of the sequence. In other words, the probability of getting a run of failures depends only on the length of the run, not on its position.</p>
<p><span class="math inline">Y=X-1</span> is the <span class="math inline">\text{negative binomial}(1,p)</span></p>
</section>
<section id="worked-out-examples" class="level3" data-number="1.6.8">
<h3 data-number="1.6.8" class="anchored" data-anchor-id="worked-out-examples"><span class="header-section-number">1.6.8</span> Worked out Examples</h3>
<div id="exm-geometric" class="theorem example">
<p><span class="theorem-title"><strong>Example 1 (Geometric Distribution)</strong></span> The Geometric distribution arises when we consider how long we will have to “wait for a success” during repeated Bernoulli trials.</p>
<p>What is the probability that we flip a fair coin four times and don’t see any heads?</p>
<p>This is the same as asking what is <span class="math inline">P(X &gt; 4)</span> where <span class="math inline">X ∼ Geo(1/2)</span>.</p>
<p><span class="math display">
  \begin{aligned}
    P(X &gt; 4) &amp;= 1 − P(X =1)−P(X = 2)−P(X = 3)−P(X = 4) \\
    &amp;= 1−(\frac{1}{2})−(\frac{1}{2})(\frac{1}{2})−(\frac{1}{2})(\frac{1}{2})^2−(\frac{1}{2})(\frac{1}{2})^3  \\
   &amp;= \frac{1}{16}
    \end{aligned}
</span></p>
<p>Of course, we could also have just computed it directly, but here we see an example of using the geometric distribution and we can also see that we got the right answer.</p>
</div>
</section>
<section id="plots-2" class="level3" data-number="1.6.9">
<h3 data-number="1.6.9" class="anchored" data-anchor-id="plots-2"><span class="header-section-number">1.6.9</span> Plots</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> geom</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> geom.stats(p,moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean=2.00, var=2.00, skew=2.12, kurt=6.50</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(geom.ppf(<span class="fl">0.01</span>, p),</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>              geom.ppf(<span class="fl">0.99</span>, p))</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>ax.plot(x, geom.pmf(x, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'geom pmf'</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, geom.pmf(x, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> geom(p)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="A02_files/figure-html/unnamed-chunk-4-5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="A02_files/figure-html/unnamed-chunk-4-5.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> geom.rvs(p,size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>array([1, 2, 2, 3, 1, 3, 5, 1, 2, 1])</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-negative-binomial-distribution" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="sec-negative-binomial-distribution"><span class="header-section-number">1.7</span> Negative Binomial Distribution</h2>
<section id="story-1" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="story-1"><span class="header-section-number">1.7.1</span> Story</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a sequence of independent Bernoulli trials with success probability p, if X is the number of failures before the r<sup>th</sup> success, then <span class="math inline">X</span> is said to have the <em>Negative Binomial</em> distribution with parameters <span class="math inline">r</span> and <span class="math inline">p</span>, denoted <span class="math inline">X \sim NBin(r, p)</span>.</p>
</div>
</div>
<p>Both the Binomial and the <em>Negative Binomial</em> distributions are based on independent Bernoulli trials; they differ in the stopping rule and in what they are counting.</p>
<p>The Binomial counts the number of successes in a fixed number of trials; the <em>Negative Binomial</em> counts the number of failures until a fixed number of successes.</p>
<p>In light of these similarities, it comes as no surprise that the derivation of the <em>Negative Binomial</em> PMF bears a resemblance to the corresponding derivation for the Binomial.</p>
</section>
<section id="parameters-2" class="level3" data-number="1.7.2">
<h3 data-number="1.7.2" class="anchored" data-anchor-id="parameters-2"><span class="header-section-number">1.7.2</span> Parameters</h3>
<ul>
<li><span class="math inline">r</span> the number of successes.</li>
<li><span class="math inline">p</span> the probability of the Bernoulli trial.</li>
</ul>
</section>
<section id="conditions-2" class="level3" data-number="1.7.3">
<h3 data-number="1.7.3" class="anchored" data-anchor-id="conditions-2"><span class="header-section-number">1.7.3</span> Conditions</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Count of discrete events</li>
<li>Non-independent events; it is sometimes said that the events can exhibit contagion, meaning that if one event occurs, it is more likely that another will also occur</li>
<li>Can model a data-generating process where the variance exceeds the mean</li>
<li>Fixed amount of time or space in which the events can occur</li>
</ul>
</div>
</div>
</section>
<section id="examples-5" class="level3" data-number="1.7.4">
<h3 data-number="1.7.4" class="anchored" data-anchor-id="examples-5"><span class="header-section-number">1.7.4</span> Examples</h3>
<ul>
<li>Stamp collection - Suppose there are n types of stamps, which you are collecting one by one, with the goal of getting a complete set. When collecting stamps, the stamp types are random. Assume that each time you collect a stamp, it is equally likely to be any of the n types. What is the expected number of toys needed until you have a complete set?</li>
<li>everything the Poisson can do and more,</li>
<li>to model the number of measles cases that occur on an island,</li>
<li>the number of banks that collapse in a financial crisis.</li>
<li>the length of a hospital stay</li>
<li>the probability you will have to visit Y houses if you must sell r cookies before returning home</li>
</ul>
</section>
<section id="moments-4" class="level3" data-number="1.7.5">
<h3 data-number="1.7.5" class="anchored" data-anchor-id="moments-4"><span class="header-section-number">1.7.5</span> Moments</h3>
<p><span class="math display">
\mathrm{E}(X) = \lambda</span> <span class="math display">var(X) = \lambda + \frac{\lambda^2}{\kappa}
</span></p>
</section>
<section id="probability-mass-function-pmf-2" class="level3" data-number="1.7.6">
<h3 data-number="1.7.6" class="anchored" data-anchor-id="probability-mass-function-pmf-2"><span class="header-section-number">1.7.6</span> Probability mass function (PMF)</h3>
<p><span class="math display">
f(x \mid \lambda,\kappa) = \frac{\Gamma(x+\kappa)}{x!\Gamma(\kappa+1)}\left(\frac{\lambda}{\lambda+\kappa}\right)^x \left(\frac{\kappa}{\lambda+\kappa}\right)^\kappa
</span></p>
</section>
<section id="cumulative-distribution-function-cdf-2" class="level3" data-number="1.7.7">
<h3 data-number="1.7.7" class="anchored" data-anchor-id="cumulative-distribution-function-cdf-2"><span class="header-section-number">1.7.7</span> Cumulative distribution function (CDF)</h3>
<p><span class="math display">
F(x \mid \lambda,\kappa) =
\begin{cases}
  I_{\frac{\kappa}{\kappa+\lambda}}(\kappa,1+\lfloor x \rfloor), &amp; x \ge q 0 \\
  0,                                                             &amp; \text{Otherwise}
\end{cases}
</span></p>
<p><span class="math display">
\text{where } I_w(u,v) \text{ is the regularised incomplete beta function: }
I_w(u,v) = \frac{B(w; u, v)}{B(u,v)}
</span></p>
<p><span class="math display">
\text{where } B(w; u,v)=\int_{0}^{w}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the incomplete beta function and }\\ B(u,v)=\int_{0}^{1}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the complete beta function}
</span></p>
</section>
</section>
<section id="sec-multinomial-distribution" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="sec-multinomial-distribution"><span class="header-section-number">1.8</span> Multinomial Distribution</h2>
<p>The Multinomial distribution is a generalization of the Binomial. Whereas the Binomial distribution counts the successes in a fixed number of trials that can only be categorized as success or failure, the Multinomial distribution keeps track of trials whose outcomes can fall into multiple categories, such as excellent, adequate, poor; or red, yellow, green, blue.</p>
<section id="story-2" class="level3" data-number="1.8.1">
<h3 data-number="1.8.1" class="anchored" data-anchor-id="story-2"><span class="header-section-number">1.8.1</span> Story</h3>
<p>Multinomial distribution. Each of N objects is independently placed into one of <span class="math inline">k</span> categories. An object is placed into category <span class="math inline">j</span> with probability <span class="math inline">p_j</span> ,P where the <span class="math inline">p_j</span> are non-negative and <span class="math inline">\sum^k_{j=1} p_j = 1</span>. Let <span class="math inline">X_1</span> be the number of objects in category 1, <span class="math inline">X_2</span> the number of objects in category 2, etc., so that <span class="math inline">X_1 + \dots + X_k = n</span>. Then <span class="math inline">X = (X_1 , \dots , X_k )</span> is said to have the Multinomial distribution with parameters <span class="math inline">n</span> and <span class="math inline">p = (p_1 , \dots , p_k )</span>. We write this as <span class="math inline">X \sim Mult_k(n, p)</span>.</p>
<p>We call X a <em>random vector</em> because it is a vector of random variables. The joint PMF of X can be derived from the story.</p>
</section>
<section id="examples-6" class="level3" data-number="1.8.2">
<h3 data-number="1.8.2" class="anchored" data-anchor-id="examples-6"><span class="header-section-number">1.8.2</span> Examples</h3>
<ul>
<li>Blood type counts across n individuals</li>
<li>Numbers of people voting for each party in a sample</li>
</ul>
</section>
<section id="moments-5" class="level3" data-number="1.8.3">
<h3 data-number="1.8.3" class="anchored" data-anchor-id="moments-5"><span class="header-section-number">1.8.3</span> Moments</h3>
<p><span class="math display">
\mathrm{E}(X_i) = n p_i \text{, }\forall i
</span></p>
<p><span class="math display">
var(X_i) = n p_i (1-p_i) \text{, }\forall i</span> <span class="math display">cov(X_i,X_j) = -n p_i p_j \text{, }\forall i\neq j
</span></p>
</section>
<section id="probability-mass-function-pmf-3" class="level3" data-number="1.8.4">
<h3 data-number="1.8.4" class="anchored" data-anchor-id="probability-mass-function-pmf-3"><span class="header-section-number">1.8.4</span> Probability Mass Function (PMF)</h3>
<p><span class="math display">
f(x_1,x_2,\dots,x_d \mid n,p_1,p_2,\dots,p_d) = \frac{n!}{x_1 ! x_2 ! \dots x_d !} p_1^{x_1} p_2^{x_2}\dots p_d^{x_d}
</span></p>
</section>
</section>
<section id="beta-binomial" class="level2 page-columns page-full" data-number="1.9">
<h2 data-number="1.9" class="anchored" data-anchor-id="beta-binomial"><span class="header-section-number">1.9</span> Beta Binomial</h2>
<section id="story-1---polya-urn-model" class="level3" data-number="1.9.1">
<h3 data-number="1.9.1" class="anchored" data-anchor-id="story-1---polya-urn-model"><span class="header-section-number">1.9.1</span> Story 1 - Polya Urn Model</h3>
<p>The beta-binomial distribution with parameters <span class="math inline">\alpha</span> success rate and <span class="math inline">\beta</span> failure and <span class="math inline">n</span> the number of trials can be motivated by an Pólya urn model.</p>
<p>Imagine an urn containing <span class="math inline">\alpha</span> red balls and <span class="math inline">\beta</span> black balls, where random draws are made. If a red ball is observed, then two red balls are returned to the urn. Likewise, if a black ball is drawn, then two black balls are returned to the urn. If this is repeated n times, then the probability of observing x red balls follows a beta-binomial distribution with parameters <span class="math inline">n</span>, <span class="math inline">\alpha</span> and <span class="math inline">\beta</span>.</p>
<p>If the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.</p>
</section>
<section id="story-2-compound-distribution" class="level3" data-number="1.9.2">
<h3 data-number="1.9.2" class="anchored" data-anchor-id="story-2-compound-distribution"><span class="header-section-number">1.9.2</span> Story 2 compound distribution</h3>
<p>The Beta distribution is a conjugate distribution of the binomial distribution. This fact leads to an analytically tractable compound distribution constructed in a hierarchical fashion where one can think of the <span class="math inline">p</span> parameter in the <span class="math inline">binomial</span> distribution as being randomly drawn from a <span class="math inline">beta</span> distribution.</p>
<p>Suppose we were interested in predicting the number of heads, x in n future trials. This is given by</p>
<p><span class="math display">
{\displaystyle {\begin{aligned}f(x\mid n,\alpha ,\beta )&amp;=\int _{0}^{1}\mathrm {Bin} (x \mid n,p)\mathrm {Beta} (p\mid \alpha ,\beta )\,dp\\[6pt]&amp;={n \choose x}{\frac {1}{\mathrm {B} (\alpha ,\beta )}}\int _{0}^{1}p^{x+\alpha -1}(1-p)^{n-x+\beta -1}\,dp\\[6pt]&amp;={n \choose x}{\frac {\mathrm {B} (x+\alpha ,n-x+\beta )}{\mathrm {B} (\alpha ,\beta )}}.\end{aligned}}}
</span></p>
<p><span class="math display">
{\displaystyle f(x\mid n,\alpha ,\beta )={\frac {\Gamma (n+1)}{\Gamma (x+1)\Gamma (n-x+1)}}{\frac {\Gamma (x+\alpha )\Gamma (n-x+\beta )}{\Gamma (n+\alpha +\beta )}}{\frac {\Gamma (\alpha +\beta )}{\Gamma (\alpha )\Gamma (\beta )}}.}
</span></p>
</section>
<section id="moments-6" class="level3" data-number="1.9.3">
<h3 data-number="1.9.3" class="anchored" data-anchor-id="moments-6"><span class="header-section-number">1.9.3</span> Moments</h3>
<p><span class="math display">
\mathrm{E}(X) = \frac{n\alpha}{\alpha+\beta}
</span> <span class="math display">
var(X) = \frac{n\alpha\beta(\alpha+\beta+n)}{(\alpha+\beta)^2(\alpha+\beta+1)}
</span></p>
</section>
<section id="probability-mass-function-pmf-4" class="level3" data-number="1.9.4">
<h3 data-number="1.9.4" class="anchored" data-anchor-id="probability-mass-function-pmf-4"><span class="header-section-number">1.9.4</span> Probability mass function (PMF)</h3>
<p><span class="math display">
f(x \mid n,\alpha,\beta) = \binom{n}{x}\frac{B(x+\alpha,n-x+\beta)}{B(\alpha,\beta)}
</span></p>
<p><span class="math display">
\text{where } B(u,v)=\int_{0}^{1}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the (complete) beta function }
</span></p>
</section>
<section id="cumulative-distribution-function-cdf-3" class="level3" data-number="1.9.5">
<h3 data-number="1.9.5" class="anchored" data-anchor-id="cumulative-distribution-function-cdf-3"><span class="header-section-number">1.9.5</span> Cumulative distribution function (CDF)</h3>
<p><span class="math display">
F(x\mid n,\alpha,\beta) = \begin{cases}
0, &amp; x&lt;0 \\
\binom{n}{x}\frac{B(x+\alpha,n-x+\beta)}{B(\alpha,\beta)} {}_{3}F_2(1,-x,n-x+\beta;n-x-1,1-x-\alpha;1), &amp; 0\leq x \leq n \\
1, &amp; x&gt;n \end{cases}
</span></p>
<p><span class="math display">
\text{where } {}_{3}F_2(a,b,x) \text{ is the generalised hypergeometric function}
</span></p>
</section>
<section id="relations" class="level3 page-columns page-full" data-number="1.9.6">
<h3 data-number="1.9.6" class="anchored" data-anchor-id="relations"><span class="header-section-number">1.9.6</span> Relations</h3>
<ul>
<li>The <strong>Pascal distribution</strong> (after Blaise Pascal) is special cases of the negative binomial distribution. Used with an integer-valued stopping-time parameter <span class="math inline">r</span></li>
<li>The <strong>Pólya distribution</strong> (for George Pólya) is special cases of the negative binomial distribution. Used with a real-valued-valued stopping-time parameter <span class="math inline">r</span></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/bio_polya.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="A photo of Hungarian Mathematician George Pólya"><img src="images/bio_polya.jpg" class="img-fluid figure-img" alt="A photo of Hungarian Mathematician George Pólya"></a></p>
<figcaption>A photo of Hungarian Mathematician George Pólya</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Biographical note on George Pólya
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>The cookbook gives a detailed description of ingredients and procedures but no proofs for its prescriptions or reasons for its recipes; the proof of the pudding is in the eating … Mathematics cannot be tested in exactly the same manner as a pudding; if all sorts of reasoning are debarred, a course of calculus may easily become an incoherent inventory of indigestible information. <span class="citation" data-cites="polya1945">(<a href="#ref-polya1945" role="doc-biblioref">Polya 1945</a>)</span></p>
</blockquote>
<p>Pólya was arguably the most influential mathematician of the 20th century. His basic research contributions span complex analysis, mathematical physics, probability theory, geometry, and combinatorics. He was a teacher par excellence who maintained a strong interest in pedagogical matters throughout his long career.</p>
<p>He was awarded a doctorate in mathematics having studied, essentially without supervision, a problem in the theory of geometric probability. Later Pólya looked at the Fourier transform of a probability measure, showing in 1923 that it was a characteristic function. He wrote on the normal distribution and coined the term “central limit theorem” in 1920 which is now standard usage.</p>
<p>In 1921 he proved his famous theorem on <em>random walks</em> on an integer lattice. He considered a d-dimensional array of lattice points where a point moves to any of its neighbors with equal probability. He asked whether given an arbitrary point A in the lattice, a point executing a random walk starting from the origin would reach A with probability 1. Pólya’s surprising answer was that it would for <span class="math inline">d=1</span> and for <span class="math inline">d=2</span>, but it would not for <span class="math inline">d\ge 3</span>. In later work he looked at two points executing independent random walks and also at random walks satisfying the condition that the moving point never passed through the same lattice point twice.</p>
<p>One of Pólya’s notable achievements was his collaboration with the economist Abraham Wald during World War II. They developed statistical techniques to solve military problems, including estimating enemy troop movements and predicting the effectiveness of bombing missions. These contributions played a vital role in aiding the Allies during the war.</p>
<p>His book “How to Solve It,” published in 1945, presented problem-solving heuristics applicable to various mathematical domains, including probability and statistics. This influential work emphasized the importance of understanding the problem, devising a plan, executing the plan, and reflecting on the results. Pólya’s problem-solving strategies continue to be widely taught and practiced.</p>
<!-- todo: convert to a bibliography item and reference with a citation -->
<p>For a more extensive biography visit the following <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Polya/">link</a></p>
</div>
</div>


<!-- -->


</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bernoulli1713ars" class="csl-entry" role="listitem">
Bernoulli, J. 1713. <em>Ars Conjectandi [the Art of Conjecturing]</em>. Impensis Thurnisiorum. <a href="https://books.google.co.il/books?id=Ba5DAAAAcAAJ">https://books.google.co.il/books?id=Ba5DAAAAcAAJ</a>.
</div>
<div id="ref-polya1945" class="csl-entry" role="listitem">
Polya, G. 1945. <em>How to Solve It</em>. Princeton University Press. <a href="https://doi.org/10.1515/9781400828678">https://doi.org/10.1515/9781400828678</a>.
</div>
</div></section></div></main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb17" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Appendix: Discrete Distributions"</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="fu"># Discrete Distributions</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="in">```{r include=FALSE}</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Necessary for using dvisvgm on macOS</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># See https://www.andrewheiss.com/blog/2021/08/27/tikz-knitr-html-svg-fun/</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="at">LIBGS =</span> <span class="st">"/usr/local/share/ghostscript/9.53.3/lib/libgs.dylib.9.53"</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>font_opts <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">dvisvgm.opts =</span> <span class="st">"--font-format=woff"</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discrete Uniform {#sec-discrete-uniform}</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stories</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Discrete Uniform Finite set Parametrization</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>Let $C$ be a finite, nonempty set of numbers and $X$ *random variable* associated with the event of *choosing one of these numbers uniformly at random*, that is all values being equally likely $X(x=c)$</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>Then $X$ is said to have the Discrete Uniform distribution with parameter $C$.</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>We denote this by $X ∼ DUnif(C)$.</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Discrete Uniform with Lower and Upper bound Parametrization</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>When the set C above is $C=<span class="sc">\{</span>c \in \mathbb{Z} \mid a \le c \le b\ <span class="sc">\}</span>$.</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>Then $X$ is said to have the Discrete Uniform distribution with lower bound parameter $a$ and upper bound parameter $b$.</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>We denote this by $X ∼ DUnif(a,b)$.</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Urn Model</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>Suppose we have an urn with n balls labeled with the numbers a $1, \dots, a_n$ . One drawing from the urn produces a discrete uniform random variable on the set $<span class="sc">\{</span>a_1, \dots, a_n <span class="sc">\}</span>$.</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moments</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>    \phi_X(t)&amp;={\displaystyle {\frac {e^{at}-e^{(b+1)t}}{n(1-e^{t})}}}  &amp;&amp; \text{(MGF)}</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span>  \mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span> &amp;= \frac{a + b}{2} &amp;&amp; \text{(Expectation)}</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span>  \mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span> &amp;= \frac{(b - a + 1)^2 - 1}{12} &amp;&amp; \text{(Variance)}</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>$$ {#eq-uniform-MGF}</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability mass function (PMF)</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>f(x \mid a, b) = \frac{1}{b - a + 1}</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cumulative distribution function (CDF)</span></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>F(x \mid a, b) = \frac{\lfloor x \rfloor - a - 1}{b - a + 1} <span class="sc">\\</span>\text{where} \lfloor x \rfloor \text{ is the floor function (rounds down reals to nearest smaller integer)}</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prior</span></span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>Since a number of families have the uniform as a special case we can use them as priors when we want a uniform prior:</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bernoulli Distribution {#sec-bernoulli-distribution}</span></span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stories</span></span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a>The Bernoulli distribution arises when modeling the outcome of a binary event called a **Bernoulli trial**. \index{Bernoulli trial}.</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a>Let $X$ be the indicator variable corresponding to the success of getting "heads" in a "coin toss", with a coin that has probability of success $p$ for getting "heads".</span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a>Then X has a *Bernoulli Distribution* with parameter $p$</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a>We denote this as $X \sim Bern(p)$</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parameters</span></span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a>Because of this story, the *parameter* $p$ is often called the **success** probability of the Bern(p) distribution.</span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>fair coin toss</span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>unfair coin toss</span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>ad click</span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>web site conversion</span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>death or survival of a patient in a medical trial</span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>indicator random variable</span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a><span class="fu">### Checklist</span></span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Discrete data</span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A single trial</span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Only two trial outcomes: **success** and **failure** (These do not need to literally represent successes and failures, but this shorthand is typically used.)</span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a>\begin{aligned} </span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a>X &amp;\sim Bernoulli(p)<span class="sc">\\</span> &amp; \sim Bern(p)<span class="sc">\\</span> &amp; \sim B(p)  \end{aligned}</span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-rv}</span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-113"><a href="#cb17-113" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moments</span></span>
<span id="cb17-114"><a href="#cb17-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-115"><a href="#cb17-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-116"><a href="#cb17-116" aria-hidden="true" tabindex="-1"></a>M_X(t)=q+pe^{t} \qquad \text{(MGF)}</span>
<span id="cb17-117"><a href="#cb17-117" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-MGF}</span>
<span id="cb17-118"><a href="#cb17-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-119"><a href="#cb17-119" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-120"><a href="#cb17-120" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span>= p \qquad \text{(Expectation)}</span>
<span id="cb17-121"><a href="#cb17-121" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-expectation}</span>
<span id="cb17-122"><a href="#cb17-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-123"><a href="#cb17-123" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-124"><a href="#cb17-124" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">x</span><span class="co">]</span>= p(1-p) \qquad \text{(Variance)}</span>
<span id="cb17-125"><a href="#cb17-125" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-variance}</span>
<span id="cb17-126"><a href="#cb17-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-127"><a href="#cb17-127" aria-hidden="true" tabindex="-1"></a><span class="fu">### PMF</span></span>
<span id="cb17-128"><a href="#cb17-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-129"><a href="#cb17-129" aria-hidden="true" tabindex="-1"></a>Where parameter $p$ is the probability of getting heads.</span>
<span id="cb17-130"><a href="#cb17-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-131"><a href="#cb17-131" aria-hidden="true" tabindex="-1"></a>The probability for the two events is:</span>
<span id="cb17-132"><a href="#cb17-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-133"><a href="#cb17-133" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-134"><a href="#cb17-134" aria-hidden="true" tabindex="-1"></a>P(X=1) = p \qquad P(X=0)=1-p </span>
<span id="cb17-135"><a href="#cb17-135" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-136"><a href="#cb17-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-137"><a href="#cb17-137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-138"><a href="#cb17-138" aria-hidden="true" tabindex="-1"></a>{\displaystyle {\begin{cases}1-p&amp;{\text{if }}k=0<span class="sc">\\</span>p&amp;{\text{if }}k=1\end{cases}}}  \qquad \text{(PMF)}</span>
<span id="cb17-139"><a href="#cb17-139" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-pmf}</span>
<span id="cb17-140"><a href="#cb17-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-141"><a href="#cb17-141" aria-hidden="true" tabindex="-1"></a><span class="fu">### CDF</span></span>
<span id="cb17-142"><a href="#cb17-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-143"><a href="#cb17-143" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-144"><a href="#cb17-144" aria-hidden="true" tabindex="-1"></a>{\displaystyle {\begin{cases}0&amp;{\text{if }}k&lt;0<span class="sc">\\</span>1-p&amp;{\text{if }}0\leq k&lt;1<span class="sc">\\</span>1&amp;{\text{if }}k\geq 1\end{cases}}} \qquad \text{(CDF)}</span>
<span id="cb17-145"><a href="#cb17-145" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-cdf}</span>
<span id="cb17-146"><a href="#cb17-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-147"><a href="#cb17-147" aria-hidden="true" tabindex="-1"></a><span class="fu">### Likelihood</span></span>
<span id="cb17-148"><a href="#cb17-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-149"><a href="#cb17-149" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-150"><a href="#cb17-150" aria-hidden="true" tabindex="-1"></a>L(\theta) = \prod p^x(1-p)^{1-x} \mathbb{I}_{<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>}(x)  \qquad \text{(Likelihood)}</span>
<span id="cb17-151"><a href="#cb17-151" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-likelihood}</span>
<span id="cb17-152"><a href="#cb17-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-153"><a href="#cb17-153" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-154"><a href="#cb17-154" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\theta) =log(p) \sum x + log(1-p)\sum (1-x)  \qquad \text{(Log Likelihood)}</span>
<span id="cb17-155"><a href="#cb17-155" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-log-likelihood}</span>
<span id="cb17-156"><a href="#cb17-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-157"><a href="#cb17-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### Entropy and Information</span></span>
<span id="cb17-158"><a href="#cb17-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-159"><a href="#cb17-159" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-160"><a href="#cb17-160" aria-hidden="true" tabindex="-1"></a>\mathbb{H}(x)= -q \ln(q)- p \ln(p) \qquad \text{(Entropy)}</span>
<span id="cb17-161"><a href="#cb17-161" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-entropy}</span>
<span id="cb17-162"><a href="#cb17-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-163"><a href="#cb17-163" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-164"><a href="#cb17-164" aria-hidden="true" tabindex="-1"></a>\mathcal{I}<span class="co">[</span><span class="ot">X</span><span class="co">]</span>\frac{1}{p(1-p)} \qquad \text{(Fisher Information)}</span>
<span id="cb17-165"><a href="#cb17-165" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-information}</span>
<span id="cb17-166"><a href="#cb17-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-167"><a href="#cb17-167" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-168"><a href="#cb17-168" aria-hidden="true" tabindex="-1"></a>Beta(x) \qquad \text{(Conjugate Prior)}</span>
<span id="cb17-169"><a href="#cb17-169" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bernoulli-prior}</span>
<span id="cb17-170"><a href="#cb17-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-171"><a href="#cb17-171" aria-hidden="true" tabindex="-1"></a><span class="fu">### Usage</span></span>
<span id="cb17-172"><a href="#cb17-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-173"><a href="#cb17-173" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Package <span class="pp">|</span> Syntax                                  <span class="pp">|</span></span>
<span id="cb17-174"><a href="#cb17-174" aria-hidden="true" tabindex="-1"></a><span class="pp">|---------|:----------------------------------------|</span></span>
<span id="cb17-175"><a href="#cb17-175" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> NumPy   <span class="pp">|</span> <span class="in">`rg.choice([0, 1], p=[1-theta, theta])`</span> <span class="pp">|</span></span>
<span id="cb17-176"><a href="#cb17-176" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> SciPy   <span class="pp">|</span> <span class="in">`scipy.stats.bernoulli(theta)`</span>          <span class="pp">|</span></span>
<span id="cb17-177"><a href="#cb17-177" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Stan    <span class="pp">|</span> <span class="in">`bernoulli(theta)`</span>                      <span class="pp">|</span></span>
<span id="cb17-178"><a href="#cb17-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-179"><a href="#cb17-179" aria-hidden="true" tabindex="-1"></a>: Usage of Bernoulli {#tbl-bernoulli-api}</span>
<span id="cb17-180"><a href="#cb17-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-181"><a href="#cb17-181" aria-hidden="true" tabindex="-1"></a><span class="fu">### Plots</span></span>
<span id="cb17-182"><a href="#cb17-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-185"><a href="#cb17-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-186"><a href="#cb17-186" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-187"><a href="#cb17-187" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> bernoulli</span>
<span id="cb17-188"><a href="#cb17-188" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-189"><a href="#cb17-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-190"><a href="#cb17-190" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-191"><a href="#cb17-191" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb17-192"><a href="#cb17-192" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> bernoulli.stats(p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb17-193"><a href="#cb17-193" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-194"><a href="#cb17-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-195"><a href="#cb17-195" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(bernoulli.ppf(<span class="fl">0.01</span>, p),</span>
<span id="cb17-196"><a href="#cb17-196" aria-hidden="true" tabindex="-1"></a>              bernoulli.ppf(<span class="fl">0.99</span>, p))</span>
<span id="cb17-197"><a href="#cb17-197" aria-hidden="true" tabindex="-1"></a>ax.plot(x, bernoulli.pmf(x, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'bernoulli pmf'</span>)</span>
<span id="cb17-198"><a href="#cb17-198" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, bernoulli.pmf(x, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb17-199"><a href="#cb17-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-200"><a href="#cb17-200" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> bernoulli(p)</span>
<span id="cb17-201"><a href="#cb17-201" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb17-202"><a href="#cb17-202" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb17-203"><a href="#cb17-203" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-204"><a href="#cb17-204" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-205"><a href="#cb17-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-206"><a href="#cb17-206" aria-hidden="true" tabindex="-1"></a><span class="co">## Generate random numbers</span></span>
<span id="cb17-207"><a href="#cb17-207" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> bernoulli.rvs(p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb17-208"><a href="#cb17-208" aria-hidden="true" tabindex="-1"></a>r</span>
<span id="cb17-209"><a href="#cb17-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-210"><a href="#cb17-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-211"><a href="#cb17-211" aria-hidden="true" tabindex="-1"></a><span class="al">![A Swiss stamp issueed in 1994 depicting Mathematician Jakob Bernouilli and the formula and diagram of the law of large numbers](images/bio-bernoulli.jpg)</span>{.column-margin alt="A Swiss stamp issueed in 1994 depicting Mathematician Jakob Bernouilli and the formula and diagram of the law of large numbers"}</span>
<span id="cb17-212"><a href="#cb17-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-213"><a href="#cb17-213" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb17-214"><a href="#cb17-214" aria-hidden="true" tabindex="-1"></a><span class="fu">### Biographical note on Jacob Bernoulli</span></span>
<span id="cb17-215"><a href="#cb17-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-216"><a href="#cb17-216" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It seems that to make a correct conjecture about any event whatever, it is necessary to calculate exactly the number of possible cases and then to determine how much more likely it is that one case will occur than another. </span><span class="co">[</span><span class="ot">@bernoulli1713ars</span><span class="co">]</span></span>
<span id="cb17-217"><a href="#cb17-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-218"><a href="#cb17-218" aria-hidden="true" tabindex="-1"></a>The Bernoulli distribution as well as The Binomial distribution are due to Jacob Bernoulli (1655-1705) who was a prominent mathematician in the Bernoulli family. He discovered the fundamental mathematical constant e. With his brother Johann, he was among the first to develop Leibniz's calculus, introducing the word integral and applying it to polar coordinates and the study of curves such as the catenary, the logarithmic spiral and the cycloid</span>
<span id="cb17-219"><a href="#cb17-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-220"><a href="#cb17-220" aria-hidden="true" tabindex="-1"></a>His most important contribution was in the field of probability, where he derived the first version of the law of large numbers (LLN). The LLN is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value and will tend to become closer to the expected value as more trials are performed. A special form of the LLN (for a binary random variable) was first proved by Jacob Bernoulli. It took him over 20 years to develop sufficiently rigorous mathematical proof.</span>
<span id="cb17-221"><a href="#cb17-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-222"><a href="#cb17-222" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- todo: convert to a bibliography item and reference with a citation --&gt;</span></span>
<span id="cb17-223"><a href="#cb17-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-224"><a href="#cb17-224" aria-hidden="true" tabindex="-1"></a>For a more extensive biography visit the following <span class="co">[</span><span class="ot">link</span><span class="co">](https://mathshistory.st-andrews.ac.uk/Biographies/Bernoulli_Jacob/)</span></span>
<span id="cb17-225"><a href="#cb17-225" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-226"><a href="#cb17-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-227"><a href="#cb17-227" aria-hidden="true" tabindex="-1"></a>The Bernoulli distribution is built on a trial of a coin toss (possibly biased).</span>
<span id="cb17-228"><a href="#cb17-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-229"><a href="#cb17-229" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We use the Bernoulli distribution to model a random variable for the probability of such a coin toss trial.</span>
<span id="cb17-230"><a href="#cb17-230" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We use the Binomial distribution to model a random variable for the probability of getting k heads in N independent trails.</span>
<span id="cb17-231"><a href="#cb17-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-232"><a href="#cb17-232" aria-hidden="true" tabindex="-1"></a><span class="fu">## Binomial distribution {#sec-binomial-distribution}</span></span>
<span id="cb17-233"><a href="#cb17-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-234"><a href="#cb17-234" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stories</span></span>
<span id="cb17-235"><a href="#cb17-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-236"><a href="#cb17-236" aria-hidden="true" tabindex="-1"></a>::: {#story-binomial-dist .callout-note}</span>
<span id="cb17-237"><a href="#cb17-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-238"><a href="#cb17-238" aria-hidden="true" tabindex="-1"></a>\overbrace{\underbrace{\fbox{0}\ \ldots \fbox{0}}_{N_0}\ \underbrace{\fbox{1}\ \ldots \fbox{1}}_{N_1}}^N </span>
<span id="cb17-239"><a href="#cb17-239" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-experiment}</span>
<span id="cb17-240"><a href="#cb17-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-241"><a href="#cb17-241" aria-hidden="true" tabindex="-1"></a>The Binomial distribution arises when we conduct multiple independent Bernoulli trials and wish to model $X$ the number of successes in $Y_i\mid \theta$ identically distributed Bernoulli trials \index{Bernoulli trial} with the same probability of success $\theta$. If $n$ independent *Bernoulli trials* are performed, each with the same success probability p. The distribution of X is called the Binomial distribution with parameters n and p. We write $X \sim \text{Bin}(n, p)$ to mean that X has the Binomial distribution with parameters n and p, where n is a positive integer and $0 &lt; p &lt; 1$.</span>
<span id="cb17-242"><a href="#cb17-242" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-243"><a href="#cb17-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-244"><a href="#cb17-244" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parameters</span></span>
<span id="cb17-245"><a href="#cb17-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-246"><a href="#cb17-246" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\theta$ - the probability of success in the Bernoulli trials</span>
<span id="cb17-247"><a href="#cb17-247" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$N$ - the total number of trials being conducted</span>
<span id="cb17-248"><a href="#cb17-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-249"><a href="#cb17-249" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditions</span></span>
<span id="cb17-250"><a href="#cb17-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-251"><a href="#cb17-251" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb17-252"><a href="#cb17-252" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Discrete data</span>
<span id="cb17-253"><a href="#cb17-253" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Two possible outcomes for each trial</span>
<span id="cb17-254"><a href="#cb17-254" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Each trial is independent and</span>
<span id="cb17-255"><a href="#cb17-255" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The probability of success/failure is the same in each trial</span>
<span id="cb17-256"><a href="#cb17-256" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The outcome is the aggregate number of successes</span>
<span id="cb17-257"><a href="#cb17-257" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-258"><a href="#cb17-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-259"><a href="#cb17-259" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb17-260"><a href="#cb17-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-261"><a href="#cb17-261" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>to model the aggregate outcome of clinical drug trials,</span>
<span id="cb17-262"><a href="#cb17-262" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>to estimate the proportion of the population voting for each political party using exit poll data (where there are only two political parties).</span>
<span id="cb17-263"><a href="#cb17-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-264"><a href="#cb17-264" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-265"><a href="#cb17-265" aria-hidden="true" tabindex="-1"></a>X \sim Bin<span class="co">[</span><span class="ot">n,p</span><span class="co">]</span></span>
<span id="cb17-266"><a href="#cb17-266" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-rv}</span>
<span id="cb17-267"><a href="#cb17-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-268"><a href="#cb17-268" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-269"><a href="#cb17-269" aria-hidden="true" tabindex="-1"></a>f(X=x \mid \theta) = {n \choose x} \theta^x(1-\theta)^{n-x}</span>
<span id="cb17-270"><a href="#cb17-270" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-pmf}</span>
<span id="cb17-271"><a href="#cb17-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-272"><a href="#cb17-272" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-273"><a href="#cb17-273" aria-hidden="true" tabindex="-1"></a>L(\theta)=\prod_{i=1}^{n} {n\choose x_i}  \theta ^ {x_i} (1− \theta) ^ {(n−x_i)}</span>
<span id="cb17-274"><a href="#cb17-274" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-likelihood}</span>
<span id="cb17-275"><a href="#cb17-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-276"><a href="#cb17-276" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-277"><a href="#cb17-277" aria-hidden="true" tabindex="-1"></a>\begin{aligned}\ell( \theta) &amp;= \log \mathcal{L}( \theta) <span class="sc">\\</span>&amp;= \sum_{i=1}^n \left<span class="co">[</span><span class="ot">\log {n\choose x_i} + x_i \log  \theta + (n-x_i)\log (1- \theta) \right</span><span class="co">]</span>.\end{aligned}</span>
<span id="cb17-278"><a href="#cb17-278" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-log-likelihood}</span>
<span id="cb17-279"><a href="#cb17-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-280"><a href="#cb17-280" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-281"><a href="#cb17-281" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span>= N \times  \theta </span>
<span id="cb17-282"><a href="#cb17-282" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-expectation}</span>
<span id="cb17-283"><a href="#cb17-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-284"><a href="#cb17-284" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-285"><a href="#cb17-285" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span>=N \cdot \theta \cdot (1-\theta)</span>
<span id="cb17-286"><a href="#cb17-286" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-variance}</span>
<span id="cb17-287"><a href="#cb17-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-288"><a href="#cb17-288" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-289"><a href="#cb17-289" aria-hidden="true" tabindex="-1"></a>\mathbb{H}(X) = \frac{1}{2}\log_2 \left (2\pi n \theta(1 - \theta)\right) + O(\frac{1}{n})</span>
<span id="cb17-290"><a href="#cb17-290" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-entropy}</span>
<span id="cb17-291"><a href="#cb17-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-292"><a href="#cb17-292" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-293"><a href="#cb17-293" aria-hidden="true" tabindex="-1"></a>\mathcal{I}(\theta)=\frac{n}{ \theta \cdot (1- \theta)}</span>
<span id="cb17-294"><a href="#cb17-294" aria-hidden="true" tabindex="-1"></a>$$ {#eq-binomial-information}</span>
<span id="cb17-295"><a href="#cb17-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-296"><a href="#cb17-296" aria-hidden="true" tabindex="-1"></a><span class="fu">### Usage</span></span>
<span id="cb17-297"><a href="#cb17-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-298"><a href="#cb17-298" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Package <span class="pp">|</span> Syntax                        <span class="pp">|</span></span>
<span id="cb17-299"><a href="#cb17-299" aria-hidden="true" tabindex="-1"></a><span class="pp">|---------|:------------------------------|</span></span>
<span id="cb17-300"><a href="#cb17-300" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> NumPy   <span class="pp">|</span> <span class="in">`rg.binomial(N, theta)`</span>       <span class="pp">|</span></span>
<span id="cb17-301"><a href="#cb17-301" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> SciPy   <span class="pp">|</span> <span class="in">`scipy.stats.binom(N, theta)`</span> <span class="pp">|</span></span>
<span id="cb17-302"><a href="#cb17-302" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Stan    <span class="pp">|</span> <span class="in">`binomial(N, theta)`</span>          <span class="pp">|</span></span>
<span id="cb17-303"><a href="#cb17-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-304"><a href="#cb17-304" aria-hidden="true" tabindex="-1"></a>: Usage of Binomial {#tbl-binomial-api}</span>
<span id="cb17-305"><a href="#cb17-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-306"><a href="#cb17-306" aria-hidden="true" tabindex="-1"></a><span class="fu">### Relationships</span></span>
<span id="cb17-307"><a href="#cb17-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-308"><a href="#cb17-308" aria-hidden="true" tabindex="-1"></a><span class="al">![binomial distribution relations](images/dbinomial.png)</span></span>
<span id="cb17-309"><a href="#cb17-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-310"><a href="#cb17-310" aria-hidden="true" tabindex="-1"></a>The Binomial Distribution is related to</span>
<span id="cb17-311"><a href="#cb17-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-312"><a href="#cb17-312" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **Binomial** is a *special case* of the **Multinomial distribution** \index{Multinomial} with K =2 (two categories).</span>
<span id="cb17-313"><a href="#cb17-313" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the **Poisson distribution** distribution. If $X \sim Binomial(n, p)$ rv and $Y \sim Poisson(np)$ distribution then $P(X = n) ≈ P(Y = n)$ for large $n$ and small $np$.</span>
<span id="cb17-314"><a href="#cb17-314" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **Bernoulli distribution** is a *special case* of the the **Binomial distribution** <span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> $X \sim Binomial(n=1, p) <span class="sc">\\</span> \implies X \sim Bernoulli(p)$</span>
<span id="cb17-315"><a href="#cb17-315" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the **Normal distribution** If $X \sim Binomial(n, p)$ RV and $Y \sim Normal(\mu=np,\sigma=np(1-p))$ then for integers j and k, $P(j ≤ X ≤ k) ≈ P(j – 1/2 ≤ Y ≤ k + 1/2)$. The approximation is better when $p ≈ 0.5$ and when n is large. For more information, see normal approximation to the Binomial</span>
<span id="cb17-316"><a href="#cb17-316" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **Binomial** is a *limit* of the **Hypergeometric**. The difference between a binomial distribution and a hypergeometric distribution is the difference between sampling with replacement and sampling without replacement. As the population size increases relative to the sample size, the difference becomes negligible. So If $X \sim Binomial(n, p)$ RV and $Y \sim HyperGeometric(N,a,b)$ then $$\lim_{n\to \infty} X = Y $$</span>
<span id="cb17-317"><a href="#cb17-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-318"><a href="#cb17-318" aria-hidden="true" tabindex="-1"></a><span class="fu">### Plots</span></span>
<span id="cb17-319"><a href="#cb17-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-322"><a href="#cb17-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-323"><a href="#cb17-323" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-324"><a href="#cb17-324" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> binom</span>
<span id="cb17-325"><a href="#cb17-325" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-326"><a href="#cb17-326" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-327"><a href="#cb17-327" aria-hidden="true" tabindex="-1"></a>n, p <span class="op">=</span> <span class="dv">5</span>, <span class="fl">0.4</span></span>
<span id="cb17-328"><a href="#cb17-328" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> binom.stats(n, p, moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb17-329"><a href="#cb17-329" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-330"><a href="#cb17-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-331"><a href="#cb17-331" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(binom.ppf(<span class="fl">0.01</span>, n, p),</span>
<span id="cb17-332"><a href="#cb17-332" aria-hidden="true" tabindex="-1"></a>              binom.ppf(<span class="fl">0.99</span>, n, p))</span>
<span id="cb17-333"><a href="#cb17-333" aria-hidden="true" tabindex="-1"></a>ax.plot(x, binom.pmf(x, n, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'binom pmf'</span>)</span>
<span id="cb17-334"><a href="#cb17-334" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, binom.pmf(x, n, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb17-335"><a href="#cb17-335" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> binom(n, p)</span>
<span id="cb17-336"><a href="#cb17-336" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb17-337"><a href="#cb17-337" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb17-338"><a href="#cb17-338" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-339"><a href="#cb17-339" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-340"><a href="#cb17-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-341"><a href="#cb17-341" aria-hidden="true" tabindex="-1"></a><span class="co">## generate random numbers</span></span>
<span id="cb17-342"><a href="#cb17-342" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> binom.rvs(n, p, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb17-343"><a href="#cb17-343" aria-hidden="true" tabindex="-1"></a>r</span>
<span id="cb17-344"><a href="#cb17-344" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-345"><a href="#cb17-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-346"><a href="#cb17-346" aria-hidden="true" tabindex="-1"></a><span class="in">````         </span></span>
<span id="cb17-347"><a href="#cb17-347" aria-hidden="true" tabindex="-1"></a><span class="in">``` {{python}}</span></span>
<span id="cb17-348"><a href="#cb17-348" aria-hidden="true" tabindex="-1"></a><span class="in">from __future__ import print_function</span></span>
<span id="cb17-349"><a href="#cb17-349" aria-hidden="true" tabindex="-1"></a><span class="in">from ipywidgets import interact, interactive, fixed, interact_manual</span></span>
<span id="cb17-350"><a href="#cb17-350" aria-hidden="true" tabindex="-1"></a><span class="in">import ipywidgets as widgets</span></span>
<span id="cb17-351"><a href="#cb17-351" aria-hidden="true" tabindex="-1"></a><span class="in">import numpy as np</span></span>
<span id="cb17-352"><a href="#cb17-352" aria-hidden="true" tabindex="-1"></a><span class="in">import scipy</span></span>
<span id="cb17-353"><a href="#cb17-353" aria-hidden="true" tabindex="-1"></a><span class="in">from scipy.special import gamma, factorial, comb</span></span>
<span id="cb17-354"><a href="#cb17-354" aria-hidden="true" tabindex="-1"></a><span class="in">import plotly.express as px</span></span>
<span id="cb17-355"><a href="#cb17-355" aria-hidden="true" tabindex="-1"></a><span class="in">import plotly.offline as pyo</span></span>
<span id="cb17-356"><a href="#cb17-356" aria-hidden="true" tabindex="-1"></a><span class="in">import plotly.graph_objs as go</span></span>
<span id="cb17-357"><a href="#cb17-357" aria-hidden="true" tabindex="-1"></a><span class="in">#pyo.init_notebook_mode()</span></span>
<span id="cb17-358"><a href="#cb17-358" aria-hidden="true" tabindex="-1"></a><span class="in">INTERACT_FLAG=False</span></span>
<span id="cb17-359"><a href="#cb17-359" aria-hidden="true" tabindex="-1"></a><span class="in">def binomial_vector_over_y(theta, n):</span></span>
<span id="cb17-360"><a href="#cb17-360" aria-hidden="true" tabindex="-1"></a><span class="in">    total_events = n</span></span>
<span id="cb17-361"><a href="#cb17-361" aria-hidden="true" tabindex="-1"></a><span class="in">    y =  np.linspace(0, total_events , total_events + 1)</span></span>
<span id="cb17-362"><a href="#cb17-362" aria-hidden="true" tabindex="-1"></a><span class="in">    p_y = [comb(int(total_events), int(yelem)) * theta** yelem * (1 - theta)**(total_events - yelem) for yelem in y]</span></span>
<span id="cb17-363"><a href="#cb17-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-364"><a href="#cb17-364" aria-hidden="true" tabindex="-1"></a><span class="in">    fig = px.line(x=y, y=p_y, color_discrete_sequence=["steelblue"], </span></span>
<span id="cb17-365"><a href="#cb17-365" aria-hidden="true" tabindex="-1"></a><span class="in">                  height=600, width=800, title=" Binomial distribution for theta = %lf, n = %d" %(theta, n))</span></span>
<span id="cb17-366"><a href="#cb17-366" aria-hidden="true" tabindex="-1"></a><span class="in">    fig.data[0].line['width'] = 4</span></span>
<span id="cb17-367"><a href="#cb17-367" aria-hidden="true" tabindex="-1"></a><span class="in">    fig.layout.xaxis.title.text = "y"</span></span>
<span id="cb17-368"><a href="#cb17-368" aria-hidden="true" tabindex="-1"></a><span class="in">    fig.layout.yaxis.title.text = "P(y)"</span></span>
<span id="cb17-369"><a href="#cb17-369" aria-hidden="true" tabindex="-1"></a><span class="in">    fig.show()</span></span>
<span id="cb17-370"><a href="#cb17-370" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb17-371"><a href="#cb17-371" aria-hidden="true" tabindex="-1"></a><span class="in">if(INTERACT_FLAG):    </span></span>
<span id="cb17-372"><a href="#cb17-372" aria-hidden="true" tabindex="-1"></a><span class="in">    interact(binomial_vector_over_y, theta=0.5, n=15)</span></span>
<span id="cb17-373"><a href="#cb17-373" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb17-374"><a href="#cb17-374" aria-hidden="true" tabindex="-1"></a><span class="in">    binomial_vector_over_y(theta=0.5, n=10)</span></span>
<span id="cb17-375"><a href="#cb17-375" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-376"><a href="#cb17-376" aria-hidden="true" tabindex="-1"></a><span class="in">````</span></span>
<span id="cb17-377"><a href="#cb17-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-378"><a href="#cb17-378" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://youtu.be/sn-mp_ESSMc title=” Binomial Distribution ?” &gt;}}</span>
<span id="cb17-379"><a href="#cb17-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-380"><a href="#cb17-380" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hypergeometric distribution {#sec-hypergeometric-distribution}</span></span>
<span id="cb17-381"><a href="#cb17-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-382"><a href="#cb17-382" aria-hidden="true" tabindex="-1"></a><span class="fu">### story 1 - Urn Model</span></span>
<span id="cb17-383"><a href="#cb17-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-384"><a href="#cb17-384" aria-hidden="true" tabindex="-1"></a>The beta-binomial distribution with parameters $\alpha$ success rate and $\beta$ failure and $n$ the number of trials can be motivated by an Pólya urn model.</span>
<span id="cb17-385"><a href="#cb17-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-386"><a href="#cb17-386" aria-hidden="true" tabindex="-1"></a>Imagine a trial in which a ball is drawn without replacement from urn containing $\alpha$ white balls and $\beta$ black balls. If this is repeated n times, then the probability of observing x white balls follows a hypergeometric distribution with parameters $n$, $\alpha$ and $\beta$.</span>
<span id="cb17-387"><a href="#cb17-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-388"><a href="#cb17-388" aria-hidden="true" tabindex="-1"></a>Note: is we used a</span>
<span id="cb17-389"><a href="#cb17-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-390"><a href="#cb17-390" aria-hidden="true" tabindex="-1"></a>If the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.</span>
<span id="cb17-391"><a href="#cb17-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-392"><a href="#cb17-392" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://youtu.be/UgqQc6epZnc &gt;}}</span>
<span id="cb17-393"><a href="#cb17-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-394"><a href="#cb17-394" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb17-395"><a href="#cb17-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-396"><a href="#cb17-396" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>k white balls from an in Urn without replacement</span>
<span id="cb17-397"><a href="#cb17-397" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>capture-recapture</span>
<span id="cb17-398"><a href="#cb17-398" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Aces in a poker hand</span>
<span id="cb17-399"><a href="#cb17-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-400"><a href="#cb17-400" aria-hidden="true" tabindex="-1"></a><span class="fu">### Story</span></span>
<span id="cb17-401"><a href="#cb17-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-402"><a href="#cb17-402" aria-hidden="true" tabindex="-1"></a>Consider an urn with w white balls and b black balls. We draw n balls out of the urn at random without replacement, such that all w+b samples are equally likely. Let X be the number of white balls in n the sample. Then X is said to have the Hypergeometric distribution with parameters w, b, and n; we denote this by $X ∼ HGeom(w, b, n)$</span>
<span id="cb17-403"><a href="#cb17-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-404"><a href="#cb17-404" aria-hidden="true" tabindex="-1"></a><span class="fu">## Poisson distribution {#sec-poisson-distribution}</span></span>
<span id="cb17-405"><a href="#cb17-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-406"><a href="#cb17-406" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stories</span></span>
<span id="cb17-407"><a href="#cb17-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-408"><a href="#cb17-408" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-409"><a href="#cb17-409" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Poisson Parametrization</span></span>
<span id="cb17-410"><a href="#cb17-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-411"><a href="#cb17-411" aria-hidden="true" tabindex="-1"></a>The Poisson distribution arises when modeling the number of successes of independent and identically distributed (IID) events in a fixed interval of time or space, occurring at a constant rate $\lambda$. Let $X$ represent the count of the number of phone calls received at a call center in a given interval, such as an hour, with the parameter $\lambda$ corresponding to the average rate at which events occur in that interval. Then $X$ is said to have the Poisson distribution with parameter $\lambda$, and we denote this as $X \sim \text{Pois}(\lambda)$.</span>
<span id="cb17-412"><a href="#cb17-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-413"><a href="#cb17-413" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-414"><a href="#cb17-414" aria-hidden="true" tabindex="-1"></a>X \sim Pois(\lambda) </span>
<span id="cb17-415"><a href="#cb17-415" aria-hidden="true" tabindex="-1"></a>$$ {#eq-poisson-rv}</span>
<span id="cb17-416"><a href="#cb17-416" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-417"><a href="#cb17-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-418"><a href="#cb17-418" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://youtu.be/yIPFA1sk5NA &gt;}}</span>
<span id="cb17-419"><a href="#cb17-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-420"><a href="#cb17-420" aria-hidden="true" tabindex="-1"></a><span class="fu">### Checklist</span></span>
<span id="cb17-421"><a href="#cb17-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-422"><a href="#cb17-422" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Count of discrete events</span>
<span id="cb17-423"><a href="#cb17-423" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Individual events occur at a given rate and independently of other events</span>
<span id="cb17-424"><a href="#cb17-424" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Fixed amount of time or space in which the events can occur</span>
<span id="cb17-425"><a href="#cb17-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-426"><a href="#cb17-426" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb17-427"><a href="#cb17-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-428"><a href="#cb17-428" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The number of emails you receive in an hour. There are a lot of people who could potentially email you at that hour, but it is unlikely that any specific person will actually email you at that hour. Alternatively, imagine subdividing the hour into milliseconds. There are $3.6×106$ seconds in an hour, but in any specific millisecond, it is unlikely that you will get an email.</span>
<span id="cb17-429"><a href="#cb17-429" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The number of chips in a chocolate chip cookie. Imagine subdividing the cookie into small cubes; the probability of getting a chocolate chip in a single cube is small, but the number of cubes is large.</span>
<span id="cb17-430"><a href="#cb17-430" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The number of earthquakes in a year in some regions of the world. At any given time and location, the probability of an earthquake is small, but there are a large number of possible times and locations for earthquakes to occur over the course of the year.</span>
<span id="cb17-431"><a href="#cb17-431" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Count of component failures per week</span>
<span id="cb17-432"><a href="#cb17-432" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>estimating the failure rate of artificial heart valves,</span>
<span id="cb17-433"><a href="#cb17-433" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>estimating the prevalence of violent crimes in different districts,</span>
<span id="cb17-434"><a href="#cb17-434" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>approximating the binomial which is, itself, being used to explain the prevalence of autism in the UK.</span>
<span id="cb17-435"><a href="#cb17-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-436"><a href="#cb17-436" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moments</span></span>
<span id="cb17-437"><a href="#cb17-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-438"><a href="#cb17-438" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-439"><a href="#cb17-439" aria-hidden="true" tabindex="-1"></a>\mathrm{E}(X) = \lambda</span>
<span id="cb17-440"><a href="#cb17-440" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-441"><a href="#cb17-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-442"><a href="#cb17-442" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-443"><a href="#cb17-443" aria-hidden="true" tabindex="-1"></a>\mathrm{V}ar(X) = \lambda</span>
<span id="cb17-444"><a href="#cb17-444" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-445"><a href="#cb17-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-446"><a href="#cb17-446" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability mass function (PMF)</span></span>
<span id="cb17-447"><a href="#cb17-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-448"><a href="#cb17-448" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-449"><a href="#cb17-449" aria-hidden="true" tabindex="-1"></a>f(x \mid \lambda) = \frac{\lambda^x e^{-\lambda}}{x!}</span>
<span id="cb17-450"><a href="#cb17-450" aria-hidden="true" tabindex="-1"></a>$$ {#eq-poisson-PMF}</span>
<span id="cb17-451"><a href="#cb17-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-452"><a href="#cb17-452" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cumulative distribution function (CDF)</span></span>
<span id="cb17-453"><a href="#cb17-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-454"><a href="#cb17-454" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-455"><a href="#cb17-455" aria-hidden="true" tabindex="-1"></a>F(x \mid \lambda) = \frac{\Gamma(\lfloor x+1\rfloor,\lambda)}{\lfloor x \rfloor !} \qquad \text{CDF}</span>
<span id="cb17-456"><a href="#cb17-456" aria-hidden="true" tabindex="-1"></a>$$ {#eq-poisson-cdf}</span>
<span id="cb17-457"><a href="#cb17-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-458"><a href="#cb17-458" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-459"><a href="#cb17-459" aria-hidden="true" tabindex="-1"></a>\text{where }\Gamma(u,v)=\int_{v}^{\infty}t^{u-1}e^{-t} \mathrm{d}t \text{ is the upper incomplete gamma function}</span>
<span id="cb17-460"><a href="#cb17-460" aria-hidden="true" tabindex="-1"></a>$$ {#eq-incomplete-gamma}</span>
<span id="cb17-461"><a href="#cb17-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-462"><a href="#cb17-462" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-463"><a href="#cb17-463" aria-hidden="true" tabindex="-1"></a>\text{and } \lfloor x \rfloor \text{ is the floor function (rounds down reals to nearest smaller integer)}</span>
<span id="cb17-464"><a href="#cb17-464" aria-hidden="true" tabindex="-1"></a>$$ {#eq-floor-function}</span>
<span id="cb17-465"><a href="#cb17-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-466"><a href="#cb17-466" aria-hidden="true" tabindex="-1"></a><span class="fu">## Geometric distribution {#sec-geometric-distribution}</span></span>
<span id="cb17-467"><a href="#cb17-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-468"><a href="#cb17-468" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stories</span></span>
<span id="cb17-469"><a href="#cb17-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-470"><a href="#cb17-470" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-471"><a href="#cb17-471" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Geometric Distribution Failures before success</span></span>
<span id="cb17-472"><a href="#cb17-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-473"><a href="#cb17-473" aria-hidden="true" tabindex="-1"></a>Consider a sequence of independent Bernoulli trials, each with the same success probability $p \in (0, 1)$, with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by $X \sim Geom(p)$.</span>
<span id="cb17-474"><a href="#cb17-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-475"><a href="#cb17-475" aria-hidden="true" tabindex="-1"></a>For example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).</span>
<span id="cb17-476"><a href="#cb17-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-477"><a href="#cb17-477" aria-hidden="true" tabindex="-1"></a>To get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0's (failures) ending in a single 1 (success). Each 0 has probability $q = 1 − p$ and the final 1 has probability p, so a string of k failures followed by one success has probability $q^kp$.</span>
<span id="cb17-478"><a href="#cb17-478" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-479"><a href="#cb17-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-480"><a href="#cb17-480" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-481"><a href="#cb17-481" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Geometric distribution Failures and success</span></span>
<span id="cb17-482"><a href="#cb17-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-483"><a href="#cb17-483" aria-hidden="true" tabindex="-1"></a>Consider a sequence of independent Bernoulli trials, each with the same success probability $p \in (0, 1)$, with trials performed until a success occurs. Let X be the number of failures before the first successful trial. Then X has the Geometric distribution with parameter p; we denote this by $X \sim Geom(p)$.</span>
<span id="cb17-484"><a href="#cb17-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-485"><a href="#cb17-485" aria-hidden="true" tabindex="-1"></a>For example, if we flip a fair coin until it lands Heads for the first time, then the number of Tails before the first occurrence of Heads is distributed as Geom(1/2).</span>
<span id="cb17-486"><a href="#cb17-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-487"><a href="#cb17-487" aria-hidden="true" tabindex="-1"></a>To get the Geometric PMF from the story, imagine the Bernoulli trials as a string of 0's (failures) ending in a single 1 (success). Each 0 has probability $q = 1 − p$ and the final 1 has probability p, so a string of k failures followed by one success has probability $q^kp$.</span>
<span id="cb17-488"><a href="#cb17-488" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-489"><a href="#cb17-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-490"><a href="#cb17-490" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://youtu.be/-vvtrsS4rkA &gt;}}</span>
<span id="cb17-491"><a href="#cb17-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-492"><a href="#cb17-492" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditions</span></span>
<span id="cb17-493"><a href="#cb17-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-494"><a href="#cb17-494" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb17-495"><a href="#cb17-495" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Discrete data</span>
<span id="cb17-496"><a href="#cb17-496" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Two possible outcomes for each trial</span>
<span id="cb17-497"><a href="#cb17-497" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Each trial is independent and</span>
<span id="cb17-498"><a href="#cb17-498" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The probability of success/failure is the same in each trial</span>
<span id="cb17-499"><a href="#cb17-499" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The outcome is the count of failures before the first success</span>
<span id="cb17-500"><a href="#cb17-500" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-501"><a href="#cb17-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-502"><a href="#cb17-502" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb17-503"><a href="#cb17-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-504"><a href="#cb17-504" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Consider polymerization of an actin filament. At each time step, an actin monomer may add to the end of the filament ("failure"), or an actin monomer may fall off the end ("success") with (usually very low) probability θ. The length of actin filaments, measured in a number of constitutive monomers, is Geometrically distributed.</span>
<span id="cb17-505"><a href="#cb17-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-506"><a href="#cb17-506" aria-hidden="true" tabindex="-1"></a>The **Geometric distribution** arises when we want to know "What is the number of Bernoulli trials required to get the first success?", i.e., the number of Bernoulli events until a success is observed, such as the probability of getting the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).</span>
<span id="cb17-507"><a href="#cb17-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-508"><a href="#cb17-508" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://youtu.be/-vvtrsS4rkA &gt;}}</span>
<span id="cb17-509"><a href="#cb17-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-510"><a href="#cb17-510" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-511"><a href="#cb17-511" aria-hidden="true" tabindex="-1"></a>X \sim Geo(p)</span>
<span id="cb17-512"><a href="#cb17-512" aria-hidden="true" tabindex="-1"></a>$$ {#eq-geom-rv}</span>
<span id="cb17-513"><a href="#cb17-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-514"><a href="#cb17-514" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moments</span></span>
<span id="cb17-515"><a href="#cb17-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-516"><a href="#cb17-516" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-517"><a href="#cb17-517" aria-hidden="true" tabindex="-1"></a>\mathbb{M}_X<span class="co">[</span><span class="ot">t</span><span class="co">]</span> = \frac{pe^t}{1-(1-p)e^t} \qquad t&lt;-ln(1-p)</span>
<span id="cb17-518"><a href="#cb17-518" aria-hidden="true" tabindex="-1"></a>$$ {#eq-geom-mgf}</span>
<span id="cb17-519"><a href="#cb17-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-520"><a href="#cb17-520" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-521"><a href="#cb17-521" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span> = \frac{1}{p}</span>
<span id="cb17-522"><a href="#cb17-522" aria-hidden="true" tabindex="-1"></a>$$ {#eq-geom-expectation}</span>
<span id="cb17-523"><a href="#cb17-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-524"><a href="#cb17-524" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-525"><a href="#cb17-525" aria-hidden="true" tabindex="-1"></a>\mathbb{V}ar<span class="co">[</span><span class="ot">X</span><span class="co">]</span>=\frac{1-p}{p^2}</span>
<span id="cb17-526"><a href="#cb17-526" aria-hidden="true" tabindex="-1"></a>$$ {#eq-geom-variance}</span>
<span id="cb17-527"><a href="#cb17-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-528"><a href="#cb17-528" aria-hidden="true" tabindex="-1"></a><span class="fu">### PMF</span></span>
<span id="cb17-529"><a href="#cb17-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-530"><a href="#cb17-530" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-531"><a href="#cb17-531" aria-hidden="true" tabindex="-1"></a>P(X = x \mid p) = p(1-p)^{x-1} \qquad \forall x \in N;\quad 0\le p \le 1</span>
<span id="cb17-532"><a href="#cb17-532" aria-hidden="true" tabindex="-1"></a>$$ {#eq-geom-pmf}</span>
<span id="cb17-533"><a href="#cb17-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-534"><a href="#cb17-534" aria-hidden="true" tabindex="-1"></a><span class="fu">### CDF</span></span>
<span id="cb17-535"><a href="#cb17-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-536"><a href="#cb17-536" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-537"><a href="#cb17-537" aria-hidden="true" tabindex="-1"></a>1-(1-p)^{\lfloor x\rfloor } \qquad x&lt;1</span>
<span id="cb17-538"><a href="#cb17-538" aria-hidden="true" tabindex="-1"></a>$$ {#eq-geom-cdf}</span>
<span id="cb17-539"><a href="#cb17-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-540"><a href="#cb17-540" aria-hidden="true" tabindex="-1"></a><span class="fu">### Memoryless property</span></span>
<span id="cb17-541"><a href="#cb17-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-542"><a href="#cb17-542" aria-hidden="true" tabindex="-1"></a>\index{memoryless property}</span>
<span id="cb17-543"><a href="#cb17-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-544"><a href="#cb17-544" aria-hidden="true" tabindex="-1"></a>The geometric distribution is based on geometric series.</span>
<span id="cb17-545"><a href="#cb17-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-546"><a href="#cb17-546" aria-hidden="true" tabindex="-1"></a>The geometric distribution has the memoryless property: </span>
<span id="cb17-547"><a href="#cb17-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-548"><a href="#cb17-548" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-549"><a href="#cb17-549" aria-hidden="true" tabindex="-1"></a>P (X &gt; s \mid X &gt;  t) = P (X &gt; s − t)</span>
<span id="cb17-550"><a href="#cb17-550" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-551"><a href="#cb17-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-552"><a href="#cb17-552" aria-hidden="true" tabindex="-1"></a>One can say that the distribution "forgets" what has occurred, so that The probability of getting an additional $s − t$ failures, having already observed t failures, is the same as the probability of observing $s − t$ failures at the start of the sequence. In other words, the probability of getting a run of failures depends only on the length of the run, not on its position.</span>
<span id="cb17-553"><a href="#cb17-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-554"><a href="#cb17-554" aria-hidden="true" tabindex="-1"></a>$Y=X-1$ is the $\text{negative binomial}(1,p)$</span>
<span id="cb17-555"><a href="#cb17-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-556"><a href="#cb17-556" aria-hidden="true" tabindex="-1"></a><span class="fu">### Worked out Examples</span></span>
<span id="cb17-557"><a href="#cb17-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-558"><a href="#cb17-558" aria-hidden="true" tabindex="-1"></a>::: {#exm-geometric}</span>
<span id="cb17-559"><a href="#cb17-559" aria-hidden="true" tabindex="-1"></a><span class="fu">### Geometric Distribution</span></span>
<span id="cb17-560"><a href="#cb17-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-561"><a href="#cb17-561" aria-hidden="true" tabindex="-1"></a>The Geometric distribution \index{Geometric distribution} arises when we consider how long we will have to "wait for a success" during repeated Bernoulli trials.</span>
<span id="cb17-562"><a href="#cb17-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-563"><a href="#cb17-563" aria-hidden="true" tabindex="-1"></a>What is the probability that we flip a fair coin four times and don't see any heads?</span>
<span id="cb17-564"><a href="#cb17-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-565"><a href="#cb17-565" aria-hidden="true" tabindex="-1"></a>This is the same as asking what is $P(X &gt; 4)$ where $X ∼ Geo(1/2)$.</span>
<span id="cb17-566"><a href="#cb17-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-567"><a href="#cb17-567" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-568"><a href="#cb17-568" aria-hidden="true" tabindex="-1"></a>  \begin{aligned}</span>
<span id="cb17-569"><a href="#cb17-569" aria-hidden="true" tabindex="-1"></a>    P(X &gt; 4) &amp;= 1 − P(X =1)−P(X = 2)−P(X = 3)−P(X = 4) <span class="sc">\\</span></span>
<span id="cb17-570"><a href="#cb17-570" aria-hidden="true" tabindex="-1"></a>    &amp;= 1−(\frac{1}{2})−(\frac{1}{2})(\frac{1}{2})−(\frac{1}{2})(\frac{1}{2})^2−(\frac{1}{2})(\frac{1}{2})^3  <span class="sc">\\</span></span>
<span id="cb17-571"><a href="#cb17-571" aria-hidden="true" tabindex="-1"></a>   &amp;= \frac{1}{16}</span>
<span id="cb17-572"><a href="#cb17-572" aria-hidden="true" tabindex="-1"></a>    \end{aligned}</span>
<span id="cb17-573"><a href="#cb17-573" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-574"><a href="#cb17-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-575"><a href="#cb17-575" aria-hidden="true" tabindex="-1"></a>Of course, we could also have just computed it directly, but here we see an example of using the geometric distribution and we can also see that we got the right answer.</span>
<span id="cb17-576"><a href="#cb17-576" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-577"><a href="#cb17-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-578"><a href="#cb17-578" aria-hidden="true" tabindex="-1"></a><span class="fu">### Plots</span></span>
<span id="cb17-579"><a href="#cb17-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-582"><a href="#cb17-582" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-583"><a href="#cb17-583" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-584"><a href="#cb17-584" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> geom</span>
<span id="cb17-585"><a href="#cb17-585" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-586"><a href="#cb17-586" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-587"><a href="#cb17-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-588"><a href="#cb17-588" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb17-589"><a href="#cb17-589" aria-hidden="true" tabindex="-1"></a>mean, var, skew, kurt <span class="op">=</span> geom.stats(p,moments<span class="op">=</span><span class="st">'mvsk'</span>)</span>
<span id="cb17-590"><a href="#cb17-590" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>mean<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>var<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>skew<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">, </span><span class="sc">{</span>kurt<span class="op">=</span><span class="sc">:1.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-591"><a href="#cb17-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-592"><a href="#cb17-592" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(geom.ppf(<span class="fl">0.01</span>, p),</span>
<span id="cb17-593"><a href="#cb17-593" aria-hidden="true" tabindex="-1"></a>              geom.ppf(<span class="fl">0.99</span>, p))</span>
<span id="cb17-594"><a href="#cb17-594" aria-hidden="true" tabindex="-1"></a>ax.plot(x, geom.pmf(x, p), <span class="st">'bo'</span>, ms<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'geom pmf'</span>)</span>
<span id="cb17-595"><a href="#cb17-595" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, geom.pmf(x, p), colors<span class="op">=</span><span class="st">'b'</span>, lw<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb17-596"><a href="#cb17-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-597"><a href="#cb17-597" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> geom(p)</span>
<span id="cb17-598"><a href="#cb17-598" aria-hidden="true" tabindex="-1"></a>ax.vlines(x, <span class="dv">0</span>, rv.pmf(x), colors<span class="op">=</span><span class="st">'k'</span>, linestyles<span class="op">=</span><span class="st">'-'</span>, lw<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb17-599"><a href="#cb17-599" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'frozen pmf'</span>)</span>
<span id="cb17-600"><a href="#cb17-600" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'best'</span>, frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-601"><a href="#cb17-601" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-602"><a href="#cb17-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-603"><a href="#cb17-603" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> geom.rvs(p,size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb17-604"><a href="#cb17-604" aria-hidden="true" tabindex="-1"></a>r</span>
<span id="cb17-605"><a href="#cb17-605" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-606"><a href="#cb17-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-607"><a href="#cb17-607" aria-hidden="true" tabindex="-1"></a><span class="fu">## Negative Binomial Distribution {#sec-negative-binomial-distribution}</span></span>
<span id="cb17-608"><a href="#cb17-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-609"><a href="#cb17-609" aria-hidden="true" tabindex="-1"></a><span class="fu">### Story</span></span>
<span id="cb17-610"><a href="#cb17-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-611"><a href="#cb17-611" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb17-612"><a href="#cb17-612" aria-hidden="true" tabindex="-1"></a>In a sequence of independent Bernoulli trials with success probability p, if X is the number of failures before the r^th^ success, then $X$ is said to have the *Negative Binomial* distribution with parameters $r$ and $p$, denoted $X \sim NBin(r, p)$.</span>
<span id="cb17-613"><a href="#cb17-613" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-614"><a href="#cb17-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-615"><a href="#cb17-615" aria-hidden="true" tabindex="-1"></a>Both the Binomial and the *Negative Binomial* distributions are based on independent Bernoulli trials; they differ in the stopping rule and in what they are counting.</span>
<span id="cb17-616"><a href="#cb17-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-617"><a href="#cb17-617" aria-hidden="true" tabindex="-1"></a>The Binomial counts the number of successes in a fixed number of trials; the *Negative Binomial* counts the number of failures until a fixed number of successes.</span>
<span id="cb17-618"><a href="#cb17-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-619"><a href="#cb17-619" aria-hidden="true" tabindex="-1"></a>In light of these similarities, it comes as no surprise that the derivation of the *Negative Binomial* PMF bears a resemblance to the corresponding derivation for the Binomial.</span>
<span id="cb17-620"><a href="#cb17-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-621"><a href="#cb17-621" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parameters</span></span>
<span id="cb17-622"><a href="#cb17-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-623"><a href="#cb17-623" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$r$ the number of successes.</span>
<span id="cb17-624"><a href="#cb17-624" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$p$ the probability of the Bernoulli trial.</span>
<span id="cb17-625"><a href="#cb17-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-626"><a href="#cb17-626" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditions</span></span>
<span id="cb17-627"><a href="#cb17-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-628"><a href="#cb17-628" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb17-629"><a href="#cb17-629" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Count of discrete events</span>
<span id="cb17-630"><a href="#cb17-630" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Non-independent events; it is sometimes said that the events can exhibit contagion, meaning that if one event occurs, it is more likely that another will also occur</span>
<span id="cb17-631"><a href="#cb17-631" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can model a data-generating process where the variance exceeds the mean</span>
<span id="cb17-632"><a href="#cb17-632" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Fixed amount of time or space in which the events can occur</span>
<span id="cb17-633"><a href="#cb17-633" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-634"><a href="#cb17-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-635"><a href="#cb17-635" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb17-636"><a href="#cb17-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-637"><a href="#cb17-637" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Stamp collection - Suppose there are n types of stamps, which you are collecting one by one, with the goal of getting a complete set. When collecting stamps, the stamp types are random. Assume that each time you collect a stamp, it is equally likely to be any of the n types. What is the expected number of toys needed until you have a complete set?</span>
<span id="cb17-638"><a href="#cb17-638" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>everything the Poisson can do and more,</span>
<span id="cb17-639"><a href="#cb17-639" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>to model the number of measles cases that occur on an island,</span>
<span id="cb17-640"><a href="#cb17-640" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the number of banks that collapse in a financial crisis.</span>
<span id="cb17-641"><a href="#cb17-641" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the length of a hospital stay</span>
<span id="cb17-642"><a href="#cb17-642" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the probability you will have to visit Y houses if you must sell r cookies before returning home</span>
<span id="cb17-643"><a href="#cb17-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-644"><a href="#cb17-644" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moments</span></span>
<span id="cb17-645"><a href="#cb17-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-646"><a href="#cb17-646" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-647"><a href="#cb17-647" aria-hidden="true" tabindex="-1"></a>\mathrm{E}(X) = \lambda$$ $$var(X) = \lambda + \frac{\lambda^2}{\kappa}</span>
<span id="cb17-648"><a href="#cb17-648" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-649"><a href="#cb17-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-650"><a href="#cb17-650" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability mass function (PMF)</span></span>
<span id="cb17-651"><a href="#cb17-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-652"><a href="#cb17-652" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-653"><a href="#cb17-653" aria-hidden="true" tabindex="-1"></a>f(x \mid \lambda,\kappa) = \frac{\Gamma(x+\kappa)}{x!\Gamma(\kappa+1)}\left(\frac{\lambda}{\lambda+\kappa}\right)^x \left(\frac{\kappa}{\lambda+\kappa}\right)^\kappa</span>
<span id="cb17-654"><a href="#cb17-654" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-655"><a href="#cb17-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-656"><a href="#cb17-656" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cumulative distribution function (CDF)</span></span>
<span id="cb17-657"><a href="#cb17-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-658"><a href="#cb17-658" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-659"><a href="#cb17-659" aria-hidden="true" tabindex="-1"></a>F(x \mid \lambda,\kappa) = </span>
<span id="cb17-660"><a href="#cb17-660" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb17-661"><a href="#cb17-661" aria-hidden="true" tabindex="-1"></a>  I_{\frac{\kappa}{\kappa+\lambda}}(\kappa,1+\lfloor x \rfloor), &amp; x \ge q 0 <span class="sc">\\</span></span>
<span id="cb17-662"><a href="#cb17-662" aria-hidden="true" tabindex="-1"></a>  0,                                                             &amp; \text{Otherwise}</span>
<span id="cb17-663"><a href="#cb17-663" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb17-664"><a href="#cb17-664" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-665"><a href="#cb17-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-666"><a href="#cb17-666" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-667"><a href="#cb17-667" aria-hidden="true" tabindex="-1"></a>\text{where } I_w(u,v) \text{ is the regularised incomplete beta function: }</span>
<span id="cb17-668"><a href="#cb17-668" aria-hidden="true" tabindex="-1"></a>I_w(u,v) = \frac{B(w; u, v)}{B(u,v)}</span>
<span id="cb17-669"><a href="#cb17-669" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-670"><a href="#cb17-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-671"><a href="#cb17-671" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-672"><a href="#cb17-672" aria-hidden="true" tabindex="-1"></a>\text{where } B(w; u,v)=\int_{0}^{w}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the incomplete beta function and }<span class="sc">\\</span> B(u,v)=\int_{0}^{1}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the complete beta function}</span>
<span id="cb17-673"><a href="#cb17-673" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-674"><a href="#cb17-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-675"><a href="#cb17-675" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multinomial Distribution {#sec-multinomial-distribution}</span></span>
<span id="cb17-676"><a href="#cb17-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-677"><a href="#cb17-677" aria-hidden="true" tabindex="-1"></a>The Multinomial distribution is a generalization of the Binomial. Whereas the Binomial distribution counts the successes in a fixed number of trials that can only be categorized as success or failure, the Multinomial distribution keeps track of trials whose outcomes can fall into multiple categories, such as excellent, adequate, poor; or red, yellow, green, blue.</span>
<span id="cb17-678"><a href="#cb17-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-679"><a href="#cb17-679" aria-hidden="true" tabindex="-1"></a><span class="fu">### Story</span></span>
<span id="cb17-680"><a href="#cb17-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-681"><a href="#cb17-681" aria-hidden="true" tabindex="-1"></a>Multinomial distribution. Each of N objects is independently placed into one of $k$ categories. An object is placed into category $j$ with probability $p_j$ ,P where the $p_j$ are non-negative and $\sum^k_{j=1} p_j = 1$. Let $X_1$ be the number of objects in category 1, $X_2$ the number of objects in category 2, etc., so that $X_1 + \dots + X_k = n$. Then $X = (X_1 , \dots , X_k )$ is said to have the Multinomial distribution with parameters $n$ and $p = (p_1 , \dots , p_k )$. We write this as $X \sim Mult_k(n, p)$.</span>
<span id="cb17-682"><a href="#cb17-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-683"><a href="#cb17-683" aria-hidden="true" tabindex="-1"></a>We call X a *random vector* because it is a vector of random variables. The joint PMF of X can be derived from the story.</span>
<span id="cb17-684"><a href="#cb17-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-685"><a href="#cb17-685" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb17-686"><a href="#cb17-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-687"><a href="#cb17-687" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Blood type counts across n individuals</span>
<span id="cb17-688"><a href="#cb17-688" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Numbers of people voting for each party in a sample</span>
<span id="cb17-689"><a href="#cb17-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-690"><a href="#cb17-690" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moments</span></span>
<span id="cb17-691"><a href="#cb17-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-692"><a href="#cb17-692" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-693"><a href="#cb17-693" aria-hidden="true" tabindex="-1"></a>\mathrm{E}(X_i) = n p_i \text{, }\forall i</span>
<span id="cb17-694"><a href="#cb17-694" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-695"><a href="#cb17-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-696"><a href="#cb17-696" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-697"><a href="#cb17-697" aria-hidden="true" tabindex="-1"></a>var(X_i) = n p_i (1-p_i) \text{, }\forall i$$ $$cov(X_i,X_j) = -n p_i p_j \text{, }\forall i\neq j</span>
<span id="cb17-698"><a href="#cb17-698" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-699"><a href="#cb17-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-700"><a href="#cb17-700" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability Mass Function (PMF)</span></span>
<span id="cb17-701"><a href="#cb17-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-702"><a href="#cb17-702" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-703"><a href="#cb17-703" aria-hidden="true" tabindex="-1"></a>f(x_1,x_2,\dots,x_d \mid n,p_1,p_2,\dots,p_d) = \frac{n!}{x_1 ! x_2 ! \dots x_d !} p_1^{x_1} p_2^{x_2}\dots p_d^{x_d}</span>
<span id="cb17-704"><a href="#cb17-704" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-705"><a href="#cb17-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-706"><a href="#cb17-706" aria-hidden="true" tabindex="-1"></a><span class="fu">## Beta Binomial</span></span>
<span id="cb17-707"><a href="#cb17-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-708"><a href="#cb17-708" aria-hidden="true" tabindex="-1"></a><span class="fu">### Story 1 - Polya Urn Model</span></span>
<span id="cb17-709"><a href="#cb17-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-710"><a href="#cb17-710" aria-hidden="true" tabindex="-1"></a>The beta-binomial distribution with parameters $\alpha$ success rate and $\beta$ failure and $n$ the number of trials can be motivated by an Pólya urn model.</span>
<span id="cb17-711"><a href="#cb17-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-712"><a href="#cb17-712" aria-hidden="true" tabindex="-1"></a>Imagine an urn containing $\alpha$ red balls and $\beta$ black balls, where random draws are made. If a red ball is observed, then two red balls are returned to the urn. Likewise, if a black ball is drawn, then two black balls are returned to the urn. If this is repeated n times, then the probability of observing x red balls follows a beta-binomial distribution with parameters $n$, $\alpha$ and $\beta$.</span>
<span id="cb17-713"><a href="#cb17-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-714"><a href="#cb17-714" aria-hidden="true" tabindex="-1"></a>If the random draws are with simple replacement (no balls over and above the observed ball are added to the urn), then the distribution follows a binomial distribution and if the random draws are made without replacement, the distribution follows a hypergeometric distribution.</span>
<span id="cb17-715"><a href="#cb17-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-716"><a href="#cb17-716" aria-hidden="true" tabindex="-1"></a><span class="fu">### Story 2 compound distribution</span></span>
<span id="cb17-717"><a href="#cb17-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-718"><a href="#cb17-718" aria-hidden="true" tabindex="-1"></a>The Beta distribution is a conjugate distribution of the binomial distribution. This fact leads to an analytically tractable compound distribution constructed in a hierarchical fashion where one can think of the $p$ parameter in the $binomial$ distribution as being randomly drawn from a $beta$ distribution.</span>
<span id="cb17-719"><a href="#cb17-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-720"><a href="#cb17-720" aria-hidden="true" tabindex="-1"></a>Suppose we were interested in predicting the number of heads, x in n future trials. This is given by</span>
<span id="cb17-721"><a href="#cb17-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-722"><a href="#cb17-722" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-723"><a href="#cb17-723" aria-hidden="true" tabindex="-1"></a>{\displaystyle {\begin{aligned}f(x\mid n,\alpha ,\beta )&amp;=\int _{0}^{1}\mathrm {Bin} (x \mid n,p)\mathrm {Beta} (p\mid \alpha ,\beta )\,dp<span class="sc">\\</span><span class="co">[</span><span class="ot">6pt</span><span class="co">]</span>&amp;={n \choose x}{\frac {1}{\mathrm {B} (\alpha ,\beta )}}\int _{0}^{1}p^{x+\alpha -1}(1-p)^{n-x+\beta -1}\,dp<span class="sc">\\</span><span class="co">[</span><span class="ot">6pt</span><span class="co">]</span>&amp;={n \choose x}{\frac {\mathrm {B} (x+\alpha ,n-x+\beta )}{\mathrm {B} (\alpha ,\beta )}}.\end{aligned}}}</span>
<span id="cb17-724"><a href="#cb17-724" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-725"><a href="#cb17-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-726"><a href="#cb17-726" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-727"><a href="#cb17-727" aria-hidden="true" tabindex="-1"></a>{\displaystyle f(x\mid n,\alpha ,\beta )={\frac {\Gamma (n+1)}{\Gamma (x+1)\Gamma (n-x+1)}}{\frac {\Gamma (x+\alpha )\Gamma (n-x+\beta )}{\Gamma (n+\alpha +\beta )}}{\frac {\Gamma (\alpha +\beta )}{\Gamma (\alpha )\Gamma (\beta )}}.}</span>
<span id="cb17-728"><a href="#cb17-728" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-729"><a href="#cb17-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-730"><a href="#cb17-730" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moments</span></span>
<span id="cb17-731"><a href="#cb17-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-732"><a href="#cb17-732" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-733"><a href="#cb17-733" aria-hidden="true" tabindex="-1"></a>\mathrm{E}(X) = \frac{n\alpha}{\alpha+\beta}</span>
<span id="cb17-734"><a href="#cb17-734" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb17-735"><a href="#cb17-735" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-736"><a href="#cb17-736" aria-hidden="true" tabindex="-1"></a>var(X) = \frac{n\alpha\beta(\alpha+\beta+n)}{(\alpha+\beta)^2(\alpha+\beta+1)}</span>
<span id="cb17-737"><a href="#cb17-737" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-738"><a href="#cb17-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-739"><a href="#cb17-739" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability mass function (PMF)</span></span>
<span id="cb17-740"><a href="#cb17-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-741"><a href="#cb17-741" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-742"><a href="#cb17-742" aria-hidden="true" tabindex="-1"></a>f(x \mid n,\alpha,\beta) = \binom{n}{x}\frac{B(x+\alpha,n-x+\beta)}{B(\alpha,\beta)}</span>
<span id="cb17-743"><a href="#cb17-743" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-744"><a href="#cb17-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-745"><a href="#cb17-745" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-746"><a href="#cb17-746" aria-hidden="true" tabindex="-1"></a>\text{where } B(u,v)=\int_{0}^{1}t^{u-1}(1-t)^{v-1}\mathrm{d}t \text{ is the (complete) beta function }</span>
<span id="cb17-747"><a href="#cb17-747" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-748"><a href="#cb17-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-749"><a href="#cb17-749" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cumulative distribution function (CDF)</span></span>
<span id="cb17-750"><a href="#cb17-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-751"><a href="#cb17-751" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-752"><a href="#cb17-752" aria-hidden="true" tabindex="-1"></a>F(x\mid n,\alpha,\beta) = \begin{cases}</span>
<span id="cb17-753"><a href="#cb17-753" aria-hidden="true" tabindex="-1"></a>0, &amp; x&lt;0 <span class="sc">\\</span> </span>
<span id="cb17-754"><a href="#cb17-754" aria-hidden="true" tabindex="-1"></a>\binom{n}{x}\frac{B(x+\alpha,n-x+\beta)}{B(\alpha,\beta)} {}_{3}F_2(1,-x,n-x+\beta;n-x-1,1-x-\alpha;1), &amp; 0\leq x \leq n <span class="sc">\\</span></span>
<span id="cb17-755"><a href="#cb17-755" aria-hidden="true" tabindex="-1"></a>1, &amp; x&gt;n \end{cases}</span>
<span id="cb17-756"><a href="#cb17-756" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-757"><a href="#cb17-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-758"><a href="#cb17-758" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-759"><a href="#cb17-759" aria-hidden="true" tabindex="-1"></a>\text{where } {}_{3}F_2(a,b,x) \text{ is the generalised hypergeometric function}</span>
<span id="cb17-760"><a href="#cb17-760" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-761"><a href="#cb17-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-762"><a href="#cb17-762" aria-hidden="true" tabindex="-1"></a><span class="fu">### Relations</span></span>
<span id="cb17-763"><a href="#cb17-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-764"><a href="#cb17-764" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **Pascal distribution** (after Blaise Pascal) is special cases of the negative binomial distribution. Used with an integer-valued stopping-time parameter $r$</span>
<span id="cb17-765"><a href="#cb17-765" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **Pólya distribution** (for George Pólya) is special cases of the negative binomial distribution. Used with a real-valued-valued stopping-time parameter $r$</span>
<span id="cb17-766"><a href="#cb17-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-767"><a href="#cb17-767" aria-hidden="true" tabindex="-1"></a><span class="al">![A photo of Hungarian Mathematician George Pólya](images/bio_polya.jpg)</span>{.column-margin alt="A photo of Hungarian Mathematician George Pólya"}</span>
<span id="cb17-768"><a href="#cb17-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-769"><a href="#cb17-769" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb17-770"><a href="#cb17-770" aria-hidden="true" tabindex="-1"></a><span class="fu">### Biographical note on George Pólya</span></span>
<span id="cb17-771"><a href="#cb17-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-772"><a href="#cb17-772" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The cookbook gives a detailed description of ingredients and procedures but no proofs for its prescriptions or reasons for its recipes; the proof of the pudding is in the eating ... Mathematics cannot be tested in exactly the same manner as a pudding; if all sorts of reasoning are debarred, a course of calculus may easily become an incoherent inventory of indigestible information. </span><span class="co">[</span><span class="ot">@polya1945</span><span class="co">]</span></span>
<span id="cb17-773"><a href="#cb17-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-774"><a href="#cb17-774" aria-hidden="true" tabindex="-1"></a>Pólya was arguably the most influential mathematician of the 20th century. His basic research contributions span complex analysis, mathematical physics, probability theory, geometry, and combinatorics. He was a teacher par excellence who maintained a strong interest in pedagogical matters throughout his long career.</span>
<span id="cb17-775"><a href="#cb17-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-776"><a href="#cb17-776" aria-hidden="true" tabindex="-1"></a>He was awarded a doctorate in mathematics having studied, essentially without supervision, a problem in the theory of geometric probability. Later Pólya looked at the Fourier transform of a probability measure, showing in 1923 that it was a characteristic function. He wrote on the normal distribution and coined the term "central limit theorem" in 1920 which is now standard usage.</span>
<span id="cb17-777"><a href="#cb17-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-778"><a href="#cb17-778" aria-hidden="true" tabindex="-1"></a>In 1921 he proved his famous theorem on *random walks* on an integer lattice. He considered a d-dimensional array of lattice points where a point moves to any of its neighbors with equal probability. He asked whether given an arbitrary point A in the lattice, a point executing a random walk starting from the origin would reach A with probability 1. Pólya's surprising answer was that it would for $d=1$ and for $d=2$, but it would not for $d\ge 3$. In later work he looked at two points executing independent random walks and also at random walks satisfying the condition that the moving point never passed through the same lattice point twice.</span>
<span id="cb17-779"><a href="#cb17-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-780"><a href="#cb17-780" aria-hidden="true" tabindex="-1"></a>One of Pólya's notable achievements was his collaboration with the economist Abraham Wald during World War II. They developed statistical techniques to solve military problems, including estimating enemy troop movements and predicting the effectiveness of bombing missions. These contributions played a vital role in aiding the Allies during the war.</span>
<span id="cb17-781"><a href="#cb17-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-782"><a href="#cb17-782" aria-hidden="true" tabindex="-1"></a>His book "How to Solve It," published in 1945, presented problem-solving heuristics applicable to various mathematical domains, including probability and statistics. This influential work emphasized the importance of understanding the problem, devising a plan, executing the plan, and reflecting on the results. Pólya's problem-solving strategies continue to be widely taught and practiced.</span>
<span id="cb17-783"><a href="#cb17-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-784"><a href="#cb17-784" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- todo: convert to a bibliography item and reference with a citation --&gt;</span></span>
<span id="cb17-785"><a href="#cb17-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-786"><a href="#cb17-786" aria-hidden="true" tabindex="-1"></a>For a more extensive biography visit the following <span class="co">[</span><span class="ot">link</span><span class="co">](https://mathshistory.st-andrews.ac.uk/Biographies/Polya/)</span></span>
<span id="cb17-787"><a href="#cb17-787" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"bottom","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>