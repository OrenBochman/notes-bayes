<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="keywords" content="Distributions, Bernoulli Distribution, Binomial Distribution">
<meta name="description" content="Outline of distributions">

<title>10&nbsp; Frequentist Inference - M2L4 – Bayesian Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C1-L04-Ex1.html" rel="next">
<link href="./C1-L03-Ex2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-923206e44a13b4518db4dede9f4ebdc9.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-279bd408c6dfe7bd56e8b154fe269440.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-987387ce273b62b48f1747d606bce1d5.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-84d0c58e965b114532ef2814536305ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(images/banner_deep.jpg);
background-size: cover;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./C1-L04.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Frequentist Inference - M2L4</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Frequentist Inference - M2L4</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
            <p class="subtitle lead">Bayesian Statistics: From Concept to Data Analysis</p>
                  <div>
        <div class="description">
          Outline of distributions
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Bayesian Statistics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>Distributions, Bernoulli Distribution, Binomial Distribution</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Statistics</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Bayesian Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L01-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Paradigms of probability - M1L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayes’ Theorem - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Conditional Probability and Bayes’ Law - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Probability and Bayes’ Theorem - M1L2HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Distributions - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Random Variables - M1L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework on Distributions - M1L3HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Frequentist Inference - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Frequentist MLE - M2L3HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bayesian Inference - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Homework on Likelihoods and MLEs - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L05-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Homework on Bayesian Inference - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Priors - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Homework Posterior Probabilities - M3L6HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">M3L7 - Binomial Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Homework on Priors - M2L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Poisson Data - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Homework on Poisson Data - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Beta Bernoulli - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">M4L9 - Exponential Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Homework on Exponential Data - M4L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Normally distributed Data - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Homework on Normal Data - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Non-Informative Priors - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Homework Alternative Priors - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Brief Review of Regression - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-L12-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Homework Regression - M4L12HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Statistical Modeling - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">M1L2 - Bayesian Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Monte Carlo estimation - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Metropolis-Hastings - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Homework on the Metropolis-Hastings algorithm - M2L4HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Gibbs sampling - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L05-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Homework Gibbs-Sampling algorithm - M2L22HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Assessing Convergence - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Homework on the Gibbs-Sampling algorithm - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L06-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Homework on M-H algorithm M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Linear regression - M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Homework on Linear Regression Model Part 1 - M2L5HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Homework on Deviance information criterion - M2L5HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">ANOVA - M3L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Homework on ANOVA - M3L8HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L08-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Homework on Multiple Factor ANOVA - M3L8HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Logistic regression - M3L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Homework on Logistic Regression - M3L9HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Poisson regression - M4L10</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L10-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Homework on Poisson regression - M4L10HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Hierarchical modeling - M4L11</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Homework on Hierarchical Models - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L11-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Homework on Non-Normal Hierarchical Models - M4L11HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Capstone Project - M4L12</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-L12-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Homework on Predictive distributions and mixture models - M4L12HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Definitions of Mixture Models - M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex1-Basic-Definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Basic Concepts of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex2-Gaussian-mixtures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Mixtures of Gaussians</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex3-Zero-Inflated-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Zero inflated distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L01-Ex4-Def-mixture-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Definition of Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Likelihood functions for Mixture Models - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Homework The Likelihood function - M1L2HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Homework Identifiability - M1L2HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Homework The likelihood function M1L2HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Homework on simulating from a Poisson Mixture Model - M1L2HW4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">HW - Simulation of Poisson mixture model - M1L2HW5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L02-Ex6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Homework Sim mixture of exponential distributions - M1L2HW6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture models - M2L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">The EM algorithm for Zero-Inflated Mixtures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L03-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">The EM algorithm for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">MCMC for Mixture Models - M4L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">The MCMC algorithm for Zero-Inflated Mixtures - M4L1HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L04-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Markov chain Monte Carlo algorithms for Mixture Models - M4L1HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Density Estimation - M4L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Clustering - M4L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Classification - M4L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the EM algorithm - M4L7HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Old Faithful eruptions density estimation with the MCMC algorithms - M4L7HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L07-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Homework on Bayesian Mixture Models for Classification of Banknotes - M4L7HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Computational Considerations - M5L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L08-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Computational considerations for Mixture Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Determining the number of components - M5L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Homework on Bayesian Information Criteria (BIC) - M5L09HW1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">Homework on Estimating the number of components in Bayesian settings - M5L09HW2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Homework on Estimating the partition structure in Bayesian models - M5L09HW3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-L09-Ex4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Homework on BIC for zero-inflated mixtures - M5L09HW4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Week 0: Introductions to time series analysis and the AR(1) process</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Stationarity, The ACF and the PCF M1L1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">The AR(1) process: definitions and properties - M1L2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">The AR(1): MLE and Bayesian inference - M1L3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">The AR(p) process - M2L4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Bayesian Inference in the AR(p) - M2L5</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Normal Dynamic Linear Models, Part 1 - M3L6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">Bayesian Inference in the NDLM: Part 1 M3L7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">Seasonal NDLMs M4L8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">96</span>&nbsp; <span class="chapter-title">Bayesian Inference in the NDLM: Part 2 - M4L9</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">97</span>&nbsp; <span class="chapter-title">Final Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-L11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">98</span>&nbsp; <span class="chapter-title">Week 0: Feynman Notebook on Bayesian Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">99</span>&nbsp; <span class="chapter-title">Appendix: Notation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">100</span>&nbsp; <span class="chapter-title">Appendix: Discrete Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">101</span>&nbsp; <span class="chapter-title">Appendix: Continuous Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">102</span>&nbsp; <span class="chapter-title">Appendix: Exponents &amp; Logarithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">103</span>&nbsp; <span class="chapter-title">Appendix: The Law of Large Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">104</span>&nbsp; <span class="chapter-title">Appendix: The Central Limit Theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">105</span>&nbsp; <span class="chapter-title">Appendix: Conjugate Priors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">106</span>&nbsp; <span class="chapter-title">Appendix: Link Function</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">107</span>&nbsp; <span class="chapter-title">Appendix: Bayes by backprop</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">108</span>&nbsp; <span class="chapter-title">Bayesian Books in R &amp; Python</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">109</span>&nbsp; <span class="chapter-title">Appendix: Yule-Walker Equations &amp; Durbin-Levinson Recursion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">110</span>&nbsp; <span class="chapter-title">Moore-Penrose Inversion &amp; Cholesky Decomposition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">111</span>&nbsp; <span class="chapter-title">Appendix: Inequalities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">112</span>&nbsp; <span class="chapter-title">Appendix: Wold’s theorem</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">113</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-confidence-intervals" id="toc-sec-confidence-intervals" class="nav-link active" data-scroll-target="#sec-confidence-intervals"><span class="header-section-number">10.1</span> Confidence Intervals</a></li>
  <li><a href="#sec-likelihood-function-and-MLE" id="toc-sec-likelihood-function-and-MLE" class="nav-link" data-scroll-target="#sec-likelihood-function-and-MLE"><span class="header-section-number">10.2</span> Likelihood function and MLE</a></li>
  <li><a href="#sec-computing-the-MLE" id="toc-sec-computing-the-MLE" class="nav-link" data-scroll-target="#sec-computing-the-MLE"><span class="header-section-number">10.3</span> Computing the MLE</a></li>
  <li><a href="#sec-computing-the-MLE-examples" id="toc-sec-computing-the-MLE-examples" class="nav-link" data-scroll-target="#sec-computing-the-MLE-examples"><span class="header-section-number">10.4</span> Computing the MLE: examples</a>
  <ul class="collapse">
  <li><a href="#sec-computing-the-MLE-for-exponential-RV" id="toc-sec-computing-the-MLE-for-exponential-RV" class="nav-link" data-scroll-target="#sec-computing-the-MLE-for-exponential-RV"><span class="header-section-number">10.4.1</span> Computing the MLE for Exponential RV</a></li>
  <li><a href="#sec-computing-the-MLE-for-uniform-RV" id="toc-sec-computing-the-MLE-for-uniform-RV" class="nav-link" data-scroll-target="#sec-computing-the-MLE-for-uniform-RV"><span class="header-section-number">10.4.2</span> Computing the MLE for Uniform RV</a></li>
  </ul></li>
  <li><a href="#sec-cumulative-distribution-function" id="toc-sec-cumulative-distribution-function" class="nav-link" data-scroll-target="#sec-cumulative-distribution-function"><span class="header-section-number">10.5</span> Cumulative Distribution Function</a></li>
  <li><a href="#sec-quantile-function" id="toc-sec-quantile-function" class="nav-link" data-scroll-target="#sec-quantile-function"><span class="header-section-number">10.6</span> Quantile Function</a></li>
  <li><a href="#sec-introduction-to-r" id="toc-sec-introduction-to-r" class="nav-link" data-scroll-target="#sec-introduction-to-r"><span class="header-section-number">11</span> Introduction to R</a>
  <ul class="collapse">
  <li><a href="#sec-plotting-the-likelihood-function-in-r" id="toc-sec-plotting-the-likelihood-function-in-r" class="nav-link" data-scroll-target="#sec-plotting-the-likelihood-function-in-r"><span class="header-section-number">11.1</span> Plotting the likelihood function in R</a></li>
  </ul></li>
  <li><a href="#sec-probability-distributions-in-r" id="toc-sec-probability-distributions-in-r" class="nav-link" data-scroll-target="#sec-probability-distributions-in-r"><span class="header-section-number">12</span> Probability Distributions in R</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<p> Before delving into Bayesian inference in the next module, in this module we will review inference in the frequentist approach. Much of the material was developed by R. A. Fischer in the last century. Some of the central ideas and tools of this approach include:</p>
<ul>
<li>Maximum Likelihood estimates MLE, which are point estimates of statistics.</li>
<li>Confidence intervals CIs which formalize uncertainty in this paradigm.</li>
<li>Likelihood functions and Log-likelihood functions which are the basis of MLE estimates.</li>
<li>Quantile Functions</li>
<li>Hypothesis testing</li>
<li>Reference Population</li>
</ul>
<p>One point of interest is how much of this work is based on the law of large numbers, central limit theorem and the empirical rule, three related key results in probability theory.</p>
<p>However the second point to stress is that the <strong>frequentist paradigm</strong> is fraught with practical as well as philosophical challenges which are handled better to some extent within the Bayesian paradigm.</p>
<p>In particular, the frequentist paradigm does not allow us to make probability statements about parameters, which is a key feature of the Bayesian approach.</p>
<section id="sec-confidence-intervals" class="level2 page-columns page-full" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="sec-confidence-intervals"><span class="header-section-number">10.1</span> Confidence Intervals</h2>

<div class="no-row-height column-margin column-container"><div id="fig-frequentist-ci" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-frequentist-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c1l04-ss-01-confidence-intervals.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;10.1: frequentist approach to confidence intervals"><img src="images/c1l04-ss-01-confidence-intervals.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-frequentist-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.1: frequentist approach to confidence intervals
</figcaption>
</figure>
</div></div><p> A brief review of the frequentist approach to inference will be useful for contrasting with the Bayesian approach. <span class="citation" data-cites="kruschke2011doing">(<a href="references.html#ref-kruschke2011doing" role="doc-biblioref">Kruschke 2011</a>)</span> Chapter 2 suggests that CI provides the basis for a Bayesian workflow and that the rest of the text fills in the missing pieces.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Frequentist paradigm
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under the <strong>frequentist paradigm</strong>, one views the data as a <strong>random sample</strong> from some larger, potentially <strong>hypothetical population</strong>. We can then make probability statements i.e.&nbsp;<strong>long-run frequency</strong> statements based on this larger population.</p>
</div>
</div>
<div id="exm-frequentist-coinflip" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.1 (Coin Flip Example - Central Limit Theorem)</strong></span> Suppose we flip a coin 100 times. And we get <strong>44 heads</strong> and <strong>56 tails</strong>. We can view these 100 flips as a random sample from a much larger infinite hypothetical population of flips from this coin. We can say that each flip is <span class="math inline">X_i</span> an RV which follows a <em>Bernoulli distribution</em> with some probability <span class="math inline">p</span>. In this case <span class="math inline">p</span> is unknown, but we can assume it is fixed since we are using a specific physical coin.</p>
<p><span id="eq-cointoss-rv"><span class="math display">
X_i \sim B(p)
\tag{10.1}</span></span></p>
<p>We ask :</p>
<ol type="1">
<li>What is our best estimate of <span class="math inline">p</span> the <strong>probability of getting a head</strong>?</li>
<li><strong>How confident are we</strong> in the estimate of <span class="math inline">p</span>?</li>
</ol>
<p>To estimate <span class="math inline">p</span> we will apply the <strong>Central limit theorem</strong> c.f. <a href="A08.html#thm-clt" class="quarto-xref">Theorem&nbsp;<span>104.1</span></a> which states that the mean of a large number of IID RV with mean <span class="math inline">\mu</span> and variance <span class="math inline">\sigma^2</span> is approximately <span class="math inline">N(\mu,\sigma^2)</span>.</p>
<p><span id="eq-cointoss-clt"><span class="math display">
\sum^{100}_{i=1} X_i\mathrel{\dot \sim } \mathcal{N}(100 \enspace p, 100 \enspace \mathbb{P}r(1-p))
\tag{10.2}</span></span></p>
<p> Given that this is a <strong>Normal distribution</strong>, we can use the <em>empirical rule</em> often called the <em>68-95-99.7 rule</em> see <span class="citation" data-cites="enwiki-empirical">(<a href="references.html#ref-enwiki-empirical" role="doc-biblioref">Wikipedia contributors 2023</a>)</span>, that says 95% of the time we will get a result is in within 1.96 standard deviations of the mean. This is referred to as a <em>Confidence Interval</em> or (CI).</p>
<p><span id="eq-cointoss-ci-theoretical"><span class="math display">
95\% \: \text{CI}= 100 \: \hat{p} \pm 1.96\sqrt{100 \: \hat{p}(1-\hat{p})}
\tag{10.3}</span></span></p>
<p>Since we observed 44 heads we can estimate <span class="math inline">\hat{p}</span> as</p>
<p><span id="eq-cointoss-phat"><span class="math display">
\hat p = \frac{44}{100} = .44
\tag{10.4}</span></span></p>
<p>This answers our first questions. Now we want to quantify our uncertainty.</p>
<p><span id="eq-cointoss-ci-empirical"><span class="math display">\begin{aligned}
95\% \: \text{CI for 100 tosses} &amp;= 100 \: (.44) \pm 1.96\sqrt{100(0.44)(1-0.44)} \\
&amp;= 44 \pm 1.96\sqrt{(44) (0.56)} \\
&amp;= 44 \pm 1.96\sqrt{23.64} \\
&amp;= (34.27,53.73) \end{aligned}
\tag{10.5}</span></span></p>
<p>We can be 95% confident that <span class="math inline">100\times \hat{p} \in [34.3,53.7]</span> We can say that we’re 95% confident that the true probability <span class="math inline">p \in (.343, .537)</span>.</p>
<p>If one were to ask <strong>do I think this coin is <em>Fair</em> ?</strong> This is a reasonable hypothesis, since <span class="math inline">0.5 \in [.343,.537]</span>.</p>
<p>But we can also step back and say what does this interval mean when we say we’re 95% confident? Under the frequentist paradigm, we have to think back to our infinite hypothetical sequence of events, were we to repeat this trial an arbitrarily large number of times and each time create a confidence interval, then on average 95% of the intervals we make will contain the true value of p.&nbsp;This makes senses as a long run frequency explanation.</p>
<p>On the other hand, we might want to know something about this particular interval. Does this interval contain the true p.&nbsp;What’s the probability that this interval contains a true p? Well, we don’t know for this particular interval. But under the frequentist paradigm, we’re assuming that there is a fixed right answer for p.&nbsp;Either p is in that interval or it’s not in that interval. And so technically, from a frequentist perspective, the probability that p is in this interval is either 0 or 1. This is not a particularly satisfying explanation. In the other hand when we get to the Bayesian approach we will be able to compute an interval and actually say there is probably a p is in this interval is 95% based on a random interpretation of an unknown parameter.</p>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this example of flipping a coin 100 times, observing 44 heads resulted in the following 95% confidence interval for p: (.343, .537). From this, we concluded that it is plausible that the coin may be fair because p=.5 is in the interval.</p>
<p>Suppose instead that we flipped the coin 100,000 times, observing 44,000 heads (the same percentage of heads as before). Then using the method just presented, the 95% confidence interval for p is (.437, .443). <strong>Is it still reasonable to conclude that this is a fair coin with 95% confidence</strong>?</p>
<p><strong>No</strong> Because <span class="math inline">0.5 \not\in (.437, .443)</span>, we must conclude that <span class="math inline">p=.5</span> is not a plausible value for the population mean . Observing 100,000 flips increases the power of the experiment, leading to a more precise estimate with a narrower CI, due to the law of large numbers.</p>
</div>
</div>
</section>
<section id="sec-likelihood-function-and-MLE" class="level2 page-columns page-full" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="sec-likelihood-function-and-MLE"><span class="header-section-number">10.2</span> Likelihood function and MLE</h2>

<div class="no-row-height column-margin column-container"><div id="fig-likelihood-fn-and-mle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-likelihood-fn-and-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c1l04-ss-02-Likelihood-fn-and-MLE.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;10.2: Likelihood fn and MLE"><img src="images/c1l04-ss-02-Likelihood-fn-and-MLE.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-likelihood-fn-and-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.2: Likelihood fn and MLE
</figcaption>
</figure>
</div></div><div id="exm-frequentist-heartattacks" class="theorem example page-columns page-full">
<p><span class="theorem-title"><strong>Example 10.2 (Heart Attack Patients - MLE)</strong></span> Consider a hospital where 400 patients are admitted over a month for heart attacks, and a month later 72 of them have died and 328 of them have survived.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class=""><strong>what’s our estimate of the mortality rate?</strong></span></div></div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Reference Population
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under the <em>frequentist paradigm</em>, we must first establish our <strong>reference population</strong>. This is the cornerstone of our thinking as we are considering how the sample parameter approximates the population statistic. What do we think our reference population is here?</p>
<ul>
<li><strong>Ref Pop 1</strong>: Heart attack patients in the region.</li>
<li><strong>Ref Pop 2</strong>: Heart attack patients that are admitted to this hospital, but over a longer period.</li>
<li><strong>Ref Pop 3</strong>: The people in the region who might have a heart attack and might get admitted to this hospital.</li>
</ul>
<p>Both <em>Ref Pop 1</em> and <em>Ref Pop 2</em> seem like viable options. Unfortunately, in our data is not a random sample drawn from either. We could pretend they are and move on, or we could also try to think harder about what our data is sampled from, perhaps <em>Ref Pop 3</em>.</p>
<p>This is an odd hypothetical situation, and so there are some <em>philosophical issues</em> with the setup of this whole problem within the <em>frequentist paradigm</em></p>
</div>
</div>
<p><span id="eq-heartattack-rv"><span class="math display">
Y_i \sim \mathrm{Bernoulli}(p)
\tag{10.6}</span></span></p>
<p>Since this is a Bernoulli trial we need to specify what we interpret as the <em>success</em> . In this case, the <em>success</em> is a mortality.</p>
<p><span id="eq-heartattack-success"><span class="math display">
\mathbb{P}r(Y_i=1) = \theta
\tag{10.7}</span></span></p>
<p>The PDF for the dataset can be written in vector form. <span class="math inline">\mathbb{P}r(\vec{Y}=\vec{y} \mid \theta)</span> is the Probability of all the Y’s take some value little y given a value of theta.</p>
<p><span id="eq-heartattack-pdf"><span class="math display">
\begin{aligned}
\mathbb{P}r(\vec{Y}=\vec{y} \mid \theta) &amp;= \mathbb{P}r(Y_1=y,\dots,Y_n=y_n \mid \theta) &amp;&amp; \text{(joint probability)}\\
&amp;= \mathbb{P}r(Y_1=y_1 \mid \theta) \cdots \mathbb{P}r(Y_n=y_n \mid \theta)            &amp;&amp; \text {(independence)}\\
&amp;= \prod^n_{i=1} \mathbb{P}r(Y_i=y_i \mid \theta)                            &amp;&amp; \text {(product notation)}\\
&amp;= \prod^n_{i=1} \theta^{y_i} (1-\theta)^{1-y_i}                   &amp;&amp; \text {(Bernoulli PMF)}
\end{aligned}
\tag{10.8}</span></span></p>
<p>We now cal the expression for <span class="math inline">\mathbb{P}r(\vec{Y}=\vec{y} \mid \theta)</span> above the likelihood function <span class="math inline">L(\theta \mid \vec{y} )</span>:</p>
<p><span id="eq-heart-attack-likelihood"><span class="math display">  
\mathcal{L}(\theta\mid\vec{y}) = \prod^n_{i=1} \theta^{y_i} (1-\theta)^{1-y_i}
\tag{10.9}</span></span></p>
<p>Recall that we want to find the mortality rate parameter <span class="math inline">\theta</span> for our Sample <span class="math inline">\vec Y</span>.</p>
<p>Since it is a probability, it has a range of values from 0 to 1. One way to estimate it is that there should be one value that maximizes (<a href="#eq-heart-attack-likelihood" class="quarto-xref">Equation&nbsp;<span>10.9</span></a>). It makes the data the most likely to occur for the particular data we observed. This is referred to as the <strong>maximum likelihood estimate</strong> (MLE). </p>
<p><span id="eq-heart-attack-mle"><span class="math display">
\mathop{\mathrm{MLE}}(\hat \theta) = \mathop{\mathrm{argmax}} \; \mathcal{L}(\theta\mid y)
\tag{10.10}</span></span></p>
<p>Although we are trying to find the <span class="math inline">\theta</span> that maximizes the likelihood, in practice, it’s usually easier to maximize the natural logarithm of the likelihood, commonly referred to as the log-likelihood.</p>
<p><span id="eq-heart-attack-loglikelihood"><span class="math display">
\begin{aligned}
\mathcal{L}(\theta) &amp;= \log(L(\theta|\vec{y}))  &amp;&amp; \\
                    &amp;= \log(\prod^n_{i=1} {\theta^{y_i} (1-\theta)^{1-y_i}})       &amp;&amp; \text{subst. likelihood} \\
                    &amp;= \sum^n_{i=1}{ \log(\theta^{y_i}) + \log(1-\theta)^{1-y_i}}  &amp;&amp; \text{log product rule} \\
                    &amp;= \sum^n_{i=1}{ y_i \log(\theta) + (1-y_i) \log(1-\theta)}     &amp;&amp; \text{log power rule}\\
                    &amp;= \log(\theta) \sum^n_{i=1}{  y_i + \log(1-\theta)} \sum^n_{i=1}{  (1-y_i) }&amp; &amp; \text{extracting logs}
\end{aligned}
\tag{10.11}</span></span></p>
<p>What is the interpretation of the MLE of <span class="math inline">\theta</span> in the context of the heart attack example?</p>
<p>If <span class="math inline">\hat \theta</span> is the MLE for <span class="math inline">\theta</span>, the 30-day mortality rate, then all possible values of θ produce a lower value of the likelihood than <span class="math inline">\hat \theta</span>.</p>
<p>To calculate the MLE one should differentiate <span class="math inline">\mathcal{L}(\theta)</span> w.r.t. <span class="math inline">\theta</span> and then set it equal to 0.</p>
</div>
</section>
<section id="sec-computing-the-MLE" class="level2 page-columns page-full" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="sec-computing-the-MLE"><span class="header-section-number">10.3</span> Computing the MLE</h2>

<div class="no-row-height column-margin column-container"><div id="fig-computing-the-mle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-computing-the-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c1l04-ss-03-computing-the-MLE.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;10.3: Computing the MLE"><img src="images/c1l04-ss-03-computing-the-MLE.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-computing-the-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.3: Computing the MLE
</figcaption>
</figure>
</div></div><p><span class="math display">
\begin{aligned}
   &amp;&amp; \mathcal{L}'(\theta)=&amp; \frac{1}{\theta}\sum_{i=1}^n y_i-\frac{1}{1-\theta}\sum_{i=1}^n 1-y_i \stackrel{\text{set}}{=}0  \text { set derivative to 0}
\\ &amp; \implies   &amp; \frac{1}{\hat \theta}\sum_{i=1}^n y_i &amp; = \frac{1}{1- \hat \theta}\sum_{i=1}^n 1 - y_i
\\ &amp; \implies   &amp; (1 -\hat \theta) \sum_{i=1}^n{y_i}    &amp;= \hat\theta \sum_{i=1}^n {1-y_i}  
\\ &amp; \implies   &amp; 1 \sum_{i=1}^n{y_i} - \cancel{ \hat \theta \sum_{i=1}^{n}{y_i}} &amp;= \hat\theta \sum_{i=1}^n {1} - \cancel{\hat\theta \sum_{i=1}^n {y_i}}  
\\ &amp; \implies   &amp; \sum_{i=1}^n{y_i}  &amp;= \hat\theta N
\\ &amp; \implies   &amp;  \hat \theta &amp;= \frac{1}{N} \sum_{i=1}^n y_i  = \hat p = \frac{72}{400}=.18
\end{aligned}
</span></p>
<p><em>Maximum Likelihood Estimates</em> (MLEs) possess the following favorable properties:</p>
<ul>
<li><strong>Unbiased</strong> - Thus given sufficient data the MLE will converge to the true value. As a consequence, <em>MLEs are asymptotically unbiased</em>. As we will see in the examples they can still be biased in finite samples.</li>
<li><strong>consistent</strong> - One important property of maximum likelihood is that it produces consistent estimates.</li>
<li><strong>invariant</strong> - The invariance principle states that the <em>MLE is invariant against reparameterization</em>.</li>
</ul>
<p>using the Central Limit theorem (see <a href="A08.html#thm-clt" class="quarto-xref">Theorem&nbsp;<span>104.1</span></a>).</p>
<p><span class="math display">
\hat \theta \pm 1.96\sqrt\frac{\hat \theta(1-\hat \theta)}{n}
</span></p>
<p><span class="math display">
\hat \theta \simeq \mathcal{N}(\theta,\frac{1}{\mathcal{I} (\hat \theta)})
</span></p>
<p>where <span class="math inline">\mathcal{I}</span> is the <em>Fischer information</em> which for the Bernoulli distribution is:</p>
<p><span class="math display">
\mathcal{I}( \hat \theta) = \frac{1}{\theta(1-\theta)}
</span></p>
<p>Note: The <em>Fischer information</em> is a measure of how much information about theta is in each data point!</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Explainable AI (XAI) &amp; Fischer information
</div>
</div>
<div class="callout-body-container callout-body">
<p>In XAI we use discuss local and global explanations.</p>
<ul>
<li><code>Global explanations</code> explain a black box model’s predictions based on each feature, via its parameters.</li>
<li><code>Local explanations</code> explain the prediction of a specific datum from its features.</li>
</ul>
<p>since <code>Fischer information</code> quantifies the information in a data point on a parameter we should be able to use it to produce local and perhaps even global explanations for Bayesian models.</p>
</div>
</div>
</section>
<section id="sec-computing-the-MLE-examples" class="level2 page-columns page-full" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="sec-computing-the-MLE-examples"><span class="header-section-number">10.4</span> Computing the MLE: examples</h2>
<p>Some more examples of maximum likelihood estimators.</p>
<section id="sec-computing-the-MLE-for-exponential-RV" class="level3 page-columns page-full" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="sec-computing-the-MLE-for-exponential-RV"><span class="header-section-number">10.4.1</span> Computing the MLE for Exponential RV</h3>

<div class="no-row-height column-margin column-container"><div id="fig-computing-the-MLE-for-exponential-rv" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-computing-the-MLE-for-exponential-rv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c1l04-ss-04-computing-the-exponential-MLE.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;10.4: computing the MLE for Exponential RV"><img src="images/c1l04-ss-04-computing-the-exponential-MLE.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-computing-the-MLE-for-exponential-rv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.4: computing the MLE for Exponential RV
</figcaption>
</figure>
</div></div><p>Let’s say <span class="math inline">X_i</span> are exponential distributed</p>
<p><span class="math display">
X_i \sim \mathrm{Exp}(\lambda)
</span></p>
<p>Let’s say the data is independent and identically distributed, therefore making the overall density function</p>
<p><span id="eq-exp-likelihood-derivation"><span class="math display">
\begin{aligned}
  f(x \mid \lambda) &amp;= \prod_{i = 1}^n{\lambda e^{-\lambda x_i}} &amp;&amp; \text {(simplifying)} \\
                    &amp;= \lambda^ne^{-\lambda \sum{x_i}}
\end{aligned}
\tag{10.12}</span></span></p>
<p>Now the likelihood function is</p>
<p><span id="eq-exp-likelihood-fn"><span class="math display">
\mathcal{L}(\lambda \mid x)=\lambda^ne^{-\lambda \sum{x_i}}
\tag{10.13}</span></span></p>
<p>the log likelihood is</p>
<p><span id="eq-exp-log-likelihood-fn"><span class="math display">
\ell(\lambda) = n\ln{\lambda} - \lambda\sum_i{x_i}
\tag{10.14}</span></span></p>
<p>Taking the derivative</p>
<p><span id="eq-exp-log-likelihood-derivative"><span class="math display">
\begin{aligned}
  \ell^\prime(\lambda) &amp;= \frac{n}{\lambda} - \sum_i{x_i} \stackrel{\text{set}}{=}0 &amp;&amp; \text {(set derivative = 0)} \\
  \implies \frac{n}{\hat{\lambda}} &amp;= \sum_i{x_i} &amp;&amp; \text{(rearranging)}
\end{aligned}
\tag{10.15}</span></span></p>
<p><span id="eq-exp-MLE"><span class="math display">
\hat{\lambda} = \frac{n}{\sum_i{x_i}} = \frac{1}{\bar{x}}
\tag{10.16}</span></span></p>
</section>
<section id="sec-computing-the-MLE-for-uniform-RV" class="level3 page-columns page-full" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="sec-computing-the-MLE-for-uniform-RV"><span class="header-section-number">10.4.2</span> Computing the MLE for Uniform RV</h3>

<div class="no-row-height column-margin column-container"><div id="fig-computing-the-MLE-for-uniform-RV" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-computing-the-MLE-for-uniform-RV-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c1l04-ss-05-computing-the-uniform-MLE.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;10.5: computing the MLE for Uniform RV"><img src="images/c1l04-ss-05-computing-the-uniform-MLE.png" class="img-fluid figure-img" style="width:53mm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-computing-the-MLE-for-uniform-RV-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.5: computing the MLE for Uniform RV
</figcaption>
</figure>
</div></div><p><span id="eq-uniform-mle-rv"><span class="math display">
X_i \sim \mathcal{U}[0, \theta]
\tag{10.17}</span></span></p>
<p><span id="eq-uniform-MLE-likelihood-derivation"><span class="math display">
f(x \mid \theta) = \prod_{i = 1}^n{\frac{1}{\theta}\mathbb{I}_{0 \le x_i \le \theta}}
\tag{10.18}</span></span></p>
<p>Combining all the indicator functions, for this to be a 1, each of these has to be true. These are going to be true if all the observations are bigger than 0, as in the minimum of the x is bigger than or equal to 0. The maximum of the x’s is also less than or equal to <span class="math inline">\theta</span>.</p>
<p><span id="eq-uniform-MLE-likelihood"><span class="math display">
\mathcal{L}(\theta|x) = \theta^{-1} \mathbb{I}_{0\le min(x_i) \le max(x_i) \le \theta}
\tag{10.19}</span></span></p>
<p><span id="eq-uniform-MLE-likelihood-derivative"><span class="math display">
\mathcal{L}^\prime(\theta) = -n\theta^{-(n + 1)}\mathbb{I}_{0 \le min(x_i) \le max(x_i)\le \theta}
\tag{10.20}</span></span></p>
<p>We ask, can we set this equal to zero and solve for <span class="math inline">\theta</span>? It turns out, this is not equal to zero for any <span class="math inline">\theta</span> positive value. We need <span class="math inline">\theta</span> to be strictly larger than zero. But for <span class="math inline">\theta</span> positive, this will always be negative. The derivative is negative, that says this is a decreasing function. Therefore this function will be maximized when we pick <span class="math inline">\theta</span> as small as possible. What’s the smallest possible value of <span class="math inline">\theta</span> we can pick? Well we need in particular for <span class="math inline">\theta</span> to be larger than all of the <span class="math inline">X_i</span>. And so, the maximum likelihood estimate is the maximum of <span class="math inline">X_i</span></p>
<p><span id="eq-uniform-mle"><span class="math display">
\hat{\theta} = max(x_i)
\tag{10.21}</span></span></p>
</section>
</section>
<section id="sec-cumulative-distribution-function" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="sec-cumulative-distribution-function"><span class="header-section-number">10.5</span> Cumulative Distribution Function</h2>
<p>The cumulative distribution function (CDF) exists for every distribution. We define it as <span class="math inline">F(x) = \mathbb{P}r(X \le x)</span> for random variable <span class="math inline">X</span>.</p>
<p>If <span class="math inline">X</span> is discrete-valued, then the CDF is computed with summation <span class="math inline">F(x) = \sum_{t = -\infty}^x {f(t)}</span>. where <span class="math inline">f(t) = \mathbb{P}r(X = t)</span> is the probability mass function (PMF) which we’ve already seen.</p>
<p>If <span class="math inline">X</span> is continuous, the CDF is computed with an integral <span class="math inline">F(x) = \int_{-\infty}^x{f(t)dt}</span></p>
<p>The CDF is convenient for calculating probabilities of intervals. Let <span class="math inline">a</span> and <span class="math inline">b</span> be any real numbers with <span class="math inline">a &lt; b</span>. Then the probability that <span class="math inline">X</span> falls between <span class="math inline">a</span> and <span class="math inline">b</span> is equal to <span class="math inline">\mathbb{P}r(a &lt; X &lt; b) = \mathbb{P}r(X \le b) - \mathbb{P}r(X \le a) = F(b) - F(a)</span></p>
<div id="fig-interval-from-cdf" class="quarto-float quarto-figure quarto-figure-center anchored" alt="using the CDF to calculate the probability of an interval">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interval-from-cdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/c1l04-ss-06-CDF.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;10.6: Illustration of using the CDF to calculate the probability of an interval for continuous random variable X. Probability values are represented with shaded regions in the graphs."><img src="images/c1l04-ss-06-CDF.png" class="img-fluid figure-img" style="width:53mm" alt="using the CDF to calculate the probability of an interval"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-interval-from-cdf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.6: Illustration of using the CDF to calculate the probability of an interval for continuous random variable X. Probability values are represented with shaded regions in the graphs.
</figcaption>
</figure>
</div>
<div id="exm-cdf-1" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.3 (CDF example 1)</strong></span> Suppose <span class="math inline">X \sim \mathrm{Binomial}(5, 0.6)</span>. Then</p>
<p><span id="eq-cdf-ex1"><span class="math display">
  \begin{aligned}
  F(1) &amp;= \mathbb{P}r(X \le 1)
\\ &amp;= \sum_{−∞}^1 f(t)
\\ &amp;= \sum_{t=−∞}^{-1} 0 + \sum_{t=0}^1 {5 \choose t} 0.6^t (1 − 0.6)^{5−t}
\\ &amp;= {5 \choose 0} 0.6^0 (1 − 0.6)5−0 +{5 \choose 1} 0.6^1 (1 − 0.6)^{5−1}
\\ &amp;= (0.4)^5 + 5(0.6)(0.4)^4
\\ &amp;≈ 0.087
\end{aligned}
\tag{10.22}</span></span></p>
</div>
<div id="exm-cdf-2" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.4 (CDF example 1)</strong></span> Example: Suppose <span class="math inline">Y ∼ Exp(1)</span>. Then</p>
<p><span id="eq-cdf-ex2"><span class="math display">
\begin{aligned}
F(2) &amp;= \mathbb{P}r(Y \le 2)
\\ &amp;= \int^{2}_{−∞} e^{−t}\mathbb{I}_{(t≥0)} dt
\\ &amp;= \int^{2}_{0} e^{−t}dt
\\ &amp;= −e^{−t}|^2_0
\\ &amp;= −(e^{−2} − e^0)
\\ &amp;= 1−e^{−2}
\\ &amp;\approx 0.865
\end{aligned}
\tag{10.23}</span></span></p>
</div>
</section>
<section id="sec-quantile-function" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="sec-quantile-function"><span class="header-section-number">10.6</span> Quantile Function</h2>
<p>The CDF takes a value for a random variable and returns a probability. Suppose instead we start with a number between <span class="math inline">0</span> and <span class="math inline">1</span>, which we call <span class="math inline">p</span>, and we wish to find a value <span class="math inline">x</span> so that <span class="math inline">\mathbb{P}r(X \le x) = p</span>. The value <span class="math inline">x</span> which satisfies this equation is called the <span class="math inline">p</span> quantile. (or <span class="math inline">100p</span> percentile) of the distribution of <span class="math inline">X</span>.</p>
<div id="exm-qf-1" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.5 (Quantile Function example 1)</strong></span> In a standardized test, the 97th percentile of scores among all test-takers is 23. Then 23 is the score you must achieve on the test in order to score higher than 97% of all test-takers. We could equivalently call <span class="math inline">q = 23</span> the .97 quantile of the distribution of test scores.</p>
</div>
<div id="exm-qf-2" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.6 (Quantile Function example 2)</strong></span> The middle 50% of probability mass for a continuous random variable is found between the .25 and .75 quantiles of its distribution. If <span class="math inline">Z \sim N(0, 1)</span>, then the <span class="math inline">.25</span> quantile is <span class="math inline">−0.674</span> and the <span class="math inline">.75</span> quantile is 0.674. Therefore, <span class="math inline">\mathbb{P}r(−0.674 &lt;Z &lt;0.674) = 0.5</span>.</p>
</div>
</section>
<section id="sec-introduction-to-r" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Introduction to R</h1>
<p>R has some nice functions that one can use for analysis</p>
<p><code>mean(z)</code> gives the mean of some row vector <span class="math inline">z</span></p>
<p><code>var(z)</code> reports the variance of some row vector</p>
<p><code>sqrt(var(z))</code> gives the standard deviation of some row vector</p>
<p><code>seq(from=0.1, to = 0.9, by = 0.1)</code> creates a vector that starts from <span class="math inline">0.1</span> and goes to <span class="math inline">0.9</span> incrementing by <span class="math inline">0.1</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">seq</span>(<span class="at">from=</span><span class="fl">0.1</span>, <span class="at">to =</span> <span class="fl">0.9</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
</div>
</div>
<p><code>names(x)</code> gives the names of all the columns in the dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(trees)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Girth"  "Height" "Volume"</code></pre>
</div>
</div>
<p><code>hist(x)</code> provides a histogram based on a vector</p>
<p>The more general <code>plot</code> function tries to guess at which type of plot to make. Feeding it two numerical vectors will make a scatter plot.</p>
<p>The R function <code>pairs</code> takes in a data frame and tries to make all possible Pairwise scatterplots for the dataset.</p>
<p>The <code>summary</code> command gives the five/six number summary (minimum, first quartile, median, mean, third quartile, maximum)</p>
<section id="sec-plotting-the-likelihood-function-in-r" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="sec-plotting-the-likelihood-function-in-r"><span class="header-section-number">11.1</span> Plotting the likelihood function in R</h2>
<p>Going back to the hospital example</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">=</span> <span class="cf">function</span>(n, y, theta) {</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta<span class="sc">^</span>y <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span>(n <span class="sc">-</span> y))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">=</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.01</span>, <span class="at">to =</span> <span class="fl">0.99</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(theta, <span class="fu">likelihood</span>(<span class="dv">400</span>, <span class="dv">72</span>, theta))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C1-L04_files/figure-html/intro-likelihood-function-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="C1-L04_files/figure-html/intro-likelihood-function-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>You can also do this with log likelihoods. This is typically more numerically stable to compute</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>loglike <span class="ot">=</span> <span class="cf">function</span>(n, y, theta) {</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(y <span class="sc">*</span> <span class="fu">log</span>(theta) <span class="sc">+</span> (n <span class="sc">-</span> y) <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> theta))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(theta, <span class="fu">loglike</span>(<span class="dv">400</span>, <span class="dv">72</span>, theta))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C1-L04_files/figure-html/intro-loglikelihood-function-plot1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="C1-L04_files/figure-html/intro-loglikelihood-function-plot1-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>Having these plotted as points makes it difficult to see, let’s plot it as lines</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(theta, <span class="fu">loglike</span>(<span class="dv">400</span>, <span class="dv">72</span>, theta), <span class="at">type =</span> <span class="st">"l"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="C1-L04_files/figure-html/intro-likelihood-function-plot2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="C1-L04_files/figure-html/intro-likelihood-function-plot2-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-probability-distributions-in-r" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Probability Distributions in R</h1>
<p>Each of the distributions introduced in Lesson 3 have convenient functions in R which allow you to evaluate the PDF/PMF, CDF, and quantile functions, as well as generate random samples from the distribution. To illustrate, see <a href="#tbl-r-api-normal" class="quarto-xref">Table&nbsp;<span>12.1</span></a>, which lists these functions for the normal distribution</p>
<div id="tbl-r-api-normal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-r-api-normal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.1: R API for the normal distribution
</figcaption>
<div aria-describedby="tbl-r-api-normal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="header">
<th>Function</th>
<th>What it does</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>dnorm(x, mean, sd)</code></td>
<td>Evaluate the PDF at <span class="math inline">x</span> (mean = <span class="math inline">\mu</span> and sd = <span class="math inline">\sqrt{\sigma^2}</span>)</td>
</tr>
<tr class="even">
<td><code>pnorm(q, mean, sd)</code></td>
<td>Evaluate the CDF at <span class="math inline">q</span></td>
</tr>
<tr class="odd">
<td><code>qnorm(p, mean, sd)</code></td>
<td>Evaluate the quantile function at <span class="math inline">p</span></td>
</tr>
<tr class="even">
<td><code>rnorm(n, mean, sd)</code></td>
<td>Generate <span class="math inline">n</span> pseudo-random samples from the normal distribution</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>These four functions exist for each distribution where <code>d...</code> function evaluates the density/mass, <code>p...</code> evaluates the CDF, <code>q...</code> evaluates the quantile, and <code>r...</code> generates a sample. In <a href="#tbl-r-api-distributions" class="quarto-xref">Table&nbsp;<span>12.2</span></a> which lists the <code>d...</code> functions for some of the most popular distributions. The <code>d</code> can be replaced with <code>p</code>, <code>q</code>, or <code>r</code> for any of the distributions, depending on what you want to calculate.</p>
<p>For details enter <code>?dnorm</code> to view R’s documentation page for the Normal distribution. As usual , replace the <code>norm</code> with any distribution to read the documentation for that distribution.</p>
<div id="tbl-r-api-distributions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-r-api-distributions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.2: R API for distribution
</figcaption>
<div aria-describedby="tbl-r-api-distributions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 31%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Function</th>
<th>Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">Binomial(n,p)</span></td>
<td><code>dbinom(x, size, prob)</code></td>
<td>size = <span class="math inline">n</span>, prob = <span class="math inline">p</span></td>
</tr>
<tr class="even">
<td><span class="math inline">Poisson(\lambda)</span></td>
<td><code>dpois(x, lambda)</code></td>
<td>lambda = <span class="math inline">\lambda</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">Exp(\lambda)</span></td>
<td><code>dexp(x, rate)</code></td>
<td>rate = <span class="math inline">\lambda</span></td>
</tr>
<tr class="even">
<td><span class="math inline">Gamma(\alpha, \beta)</span></td>
<td><code>dgamma(x, shape, rate)</code></td>
<td>shape = <span class="math inline">\alpha</span>, rate = <span class="math inline">\beta</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">Uniform(a, b)</span></td>
<td><code>dunif(x, min, max)</code></td>
<td>min = <span class="math inline">a</span>, max = <span class="math inline">b</span></td>
</tr>
<tr class="even">
<td><span class="math inline">Beta(\alpha, \beta)</span></td>
<td><code>dbeta(x, shape1, shape2)</code></td>
<td>shape1 = <span class="math inline">\alpha</span>, shape2 = <span class="math inline">\beta</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">N(\mu, \sigma^2)</span></td>
<td><code>dnorm(x, mean, sd)</code></td>
<td>mean = <span class="math inline">\mu</span>, sd = <span class="math inline">\sqrt{\sigma^2}</span></td>
</tr>
<tr class="even">
<td><span class="math inline">t_v</span></td>
<td><code>dt(x, df)</code></td>
<td>df = <span class="math inline">v</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-kruschke2011doing" class="csl-entry" role="listitem">
Kruschke, John K. 2011. <em>Doing Bayesian Data Analysis: A Tutorial with <span>R</span> and <span>BUGS</span></em>. Burlington, MA: Academic Press. <a href="http://www.amazon.com/Doing-Bayesian-Data-Analysis-Tutorial/dp/0123814855">http://www.amazon.com/Doing-Bayesian-Data-Analysis-Tutorial/dp/0123814855</a>.
</div>
<div id="ref-enwiki-empirical" class="csl-entry" role="listitem">
Wikipedia contributors. 2023. <span>“68–95–99.7 Rule — <span>Wikipedia</span>.”</span> <a href="https://en.wikipedia.org/w/index.php?title=68%E2%80%9395%E2%80%9399.7_rule" class="uri">https://en.wikipedia.org/w/index.php?title=68%E2%80%9395%E2%80%9399.7_rule</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
        for (let i=0; i<annoteTargets.length; i++) {
          const annoteTarget = annoteTargets[i];
          const targetCell = annoteTarget.getAttribute("data-target-cell");
          const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
          const contentFn = () => {
            const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            if (content) {
              const tipContent = content.cloneNode(true);
              tipContent.classList.add("code-annotation-tip-content");
              return tipContent.outerHTML;
            }
          }
          const config = {
            allowHTML: true,
            content: contentFn,
            onShow: (instance) => {
              selectCodeLines(instance.reference);
              instance.reference.classList.add('code-annotation-active');
              window.tippy.hideAll();
            },
            onHide: (instance) => {
              unselectCodeLines();
              instance.reference.classList.remove('code-annotation-active');
            },
            maxWidth: 300,
            delay: [50, 0],
            duration: [200, 0],
            offset: [5, 10],
            arrow: true,
            appendTo: function(el) {
              return el.parentElement.parentElement.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'quarto',
            placement: 'right',
            popperOptions: {
              modifiers: [
              {
                name: 'flip',
                options: {
                  flipVariations: false, // true by default
                  allowedAutoPlacements: ['right'],
                  fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                },
              },
              {
                name: 'preventOverflow',
                options: {
                  mainAxis: false,
                  altAxis: false
                }
              }
              ]        
            }      
          };
          window.tippy(annoteTarget, config); 
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C1-L03-Ex2.html" class="pagination-link" aria-label="Homework on Distributions - M1L3HW2">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Homework on Distributions - M1L3HW2</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C1-L04-Ex1.html" class="pagination-link" aria-label="Frequentist MLE - M2L3HW1">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Frequentist MLE - M2L3HW1</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb10" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Frequentist Inference - M2L4"</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Bayesian Statistics: From Concept to Data Analysis"</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="an">subject:</span><span class="co"> "Bayesian Statistics"</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Outline of distributions"</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Bayesian Statistics</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co">  </span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - Distributions</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - Bernoulli Distribution</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - Binomial Distribution</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>\index{Maximum Likelihood Estimation}</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>Before delving into Bayesian inference in the next module, in this module we will review inference in the frequentist approach.</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>Much of the material was developed by R. A. Fischer in the last century. Some of the central ideas and tools of this approach include:</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Maximum Likelihood estimates MLE, which are point estimates of statistics.</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Confidence intervals CIs which formalize uncertainty in this paradigm.</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Likelihood functions and Log-likelihood functions which are the basis of MLE estimates.</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Quantile Functions</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hypothesis testing</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reference Population</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>One point of interest is how much of this work is based on the law of large numbers, central limit theorem and the empirical rule, three related key results in probability theory.</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>However the second point to stress is that the **frequentist paradigm** is fraught with practical as well as philosophical challenges which are handled better to some extent within the Bayesian paradigm. </span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>In particular, the frequentist paradigm does not allow us to make probability statements about parameters, which is a key feature of the Bayesian approach.</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confidence Intervals {#sec-confidence-intervals}</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="al">![frequentist approach to confidence intervals](images/c1l04-ss-01-confidence-intervals.png)</span>{#fig-frequentist-ci .column-margin width="53mm"}</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>\index{Confidence Interval}</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>A brief review of the frequentist approach to inference will be useful for contrasting with the Bayesian approach. <span class="co">[</span><span class="ot">@kruschke2011doing</span><span class="co">]</span> Chapter 2 suggests that CI provides the basis for a Bayesian workflow and that the rest of the text fills in the missing pieces.</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a><span class="fu">### Frequentist paradigm</span></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>Under the **frequentist paradigm**, one views the data as a **random sample** from some larger, potentially **hypothetical population**. We can then make probability statements i.e. **long-run frequency** statements based on this larger population.</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>::: {#exm-frequentist-coinflip}</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="fu">### Coin Flip Example - Central Limit Theorem</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>\index{Confidence Interval}</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>\index{Frequentist Inference}</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>Suppose we flip a coin 100 times. And we get **44 heads** and **56 tails**. We can view these 100 flips as a random sample from a much larger infinite hypothetical population of flips from this coin. We can say that each flip is $X_i$ an RV which follows a *Bernoulli distribution* with some probability $p$. In this case $p$ is unknown, but we can assume it is fixed since we are using a specific physical coin.</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>X_i \sim B(p)</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cointoss-rv}</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>We ask :</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>What is our best estimate of $p$ the **probability of getting a head**?</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**How confident are we** in the estimate of $p$?</span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a>To estimate $p$ we will apply the **Central limit theorem** c.f. <span class="co">[</span><span class="ot">@thm-clt</span><span class="co">]</span> which states that the mean of a large number of IID RV with mean $\mu$ and variance $\sigma^2$ is approximately $N(\mu,\sigma^2)$.</span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>\sum^{100}_{i=1} X_i\mathrel{\dot \sim } \mathcal{N}(100 \enspace p, 100 \enspace \mathbb{P}r(1-p))</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cointoss-clt}</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>\index{Central Limit Theorem}</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a>Given that this is a **Normal distribution**, we can use the *empirical rule* often called the *68-95-99.7 rule* see [@enwiki-empirical], that says 95% of the time we will get a result is in within 1.96 standard deviations of the mean. This is referred to as a *Confidence Interval* or (CI).</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>95\% \: \text{CI}= 100 \: \hat{p} \pm 1.96\sqrt{100 \: \hat{p}(1-\hat{p})}</span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cointoss-ci-theoretical}</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a>Since we observed 44 heads we can estimate $\hat{p}$ as</span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>\hat p = \frac{44}{100} = .44</span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cointoss-phat}</span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a>This answers our first questions. Now we want to quantify our uncertainty.</span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a>$$\begin{aligned}</span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a>95\% \: \text{CI for 100 tosses} &amp;= 100 \: (.44) \pm 1.96\sqrt{100(0.44)(1-0.44)} <span class="sc">\\</span> </span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a>&amp;= 44 \pm 1.96\sqrt{(44) (0.56)} <span class="sc">\\</span> </span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a>&amp;= 44 \pm 1.96\sqrt{23.64} <span class="sc">\\</span> </span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a>&amp;= (34.27,53.73) \end{aligned}</span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cointoss-ci-empirical}</span>
<span id="cb10-89"><a href="#cb10-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-90"><a href="#cb10-90" aria-hidden="true" tabindex="-1"></a>We can be 95% confident that $100\times \hat{p} \in <span class="co">[</span><span class="ot">34.3,53.7</span><span class="co">]</span>$ We can say that we're 95% confident that the true probability $p \in (.343, .537)$.</span>
<span id="cb10-91"><a href="#cb10-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-92"><a href="#cb10-92" aria-hidden="true" tabindex="-1"></a>If one were to ask **do I think this coin is *Fair* ?** This is a reasonable hypothesis, since $0.5 \in <span class="co">[</span><span class="ot">.343,.537</span><span class="co">]</span>$.</span>
<span id="cb10-93"><a href="#cb10-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-94"><a href="#cb10-94" aria-hidden="true" tabindex="-1"></a>But we can also step back and say what does this interval mean when we say we're 95% confident? Under the frequentist paradigm, we have to think back to our infinite hypothetical sequence of events, were we to repeat this trial an arbitrarily large number of times and each time create a confidence interval, then on average 95% of the intervals we make will contain the true value of p. This makes senses as a long run frequency explanation.</span>
<span id="cb10-95"><a href="#cb10-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-96"><a href="#cb10-96" aria-hidden="true" tabindex="-1"></a>On the other hand, we might want to know something about this particular interval. Does this interval contain the true p. What's the probability that this interval contains a true p? Well, we don't know for this particular interval. But under the frequentist paradigm, we're assuming that there is a fixed right answer for p. Either p is in that interval or it's not in that interval. And so technically, from a frequentist perspective, the probability that p is in this interval is either 0 or 1. This is not a particularly satisfying explanation. In the other hand when we get to the Bayesian approach we will be able to compute an interval and actually say there is probably a p is in this interval is 95% based on a random interpretation of an unknown parameter.</span>
<span id="cb10-97"><a href="#cb10-97" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-98"><a href="#cb10-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-99"><a href="#cb10-99" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb10-100"><a href="#cb10-100" aria-hidden="true" tabindex="-1"></a>In this example of flipping a coin 100 times, observing 44 heads resulted in the following 95% confidence interval for p: (.343, .537). From this, we concluded that it is plausible that the coin may be fair because p=.5 is in the interval.</span>
<span id="cb10-101"><a href="#cb10-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-102"><a href="#cb10-102" aria-hidden="true" tabindex="-1"></a>Suppose instead that we flipped the coin 100,000 times, observing 44,000 heads (the same percentage of heads as before). Then using the method just presented, the 95% confidence interval for p is (.437, .443). **Is it still reasonable to conclude that this is a fair coin with 95% confidence**?</span>
<span id="cb10-103"><a href="#cb10-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-104"><a href="#cb10-104" aria-hidden="true" tabindex="-1"></a>**No** Because $0.5 \not\in (.437, .443)$, we must conclude that $p=.5$ is not a plausible value for the population mean . Observing 100,000 flips increases the power of the experiment, leading to a more precise estimate with a narrower CI, due to the law of large numbers.</span>
<span id="cb10-105"><a href="#cb10-105" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-106"><a href="#cb10-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-107"><a href="#cb10-107" aria-hidden="true" tabindex="-1"></a><span class="fu">## Likelihood function and MLE {#sec-likelihood-function-and-MLE}</span></span>
<span id="cb10-108"><a href="#cb10-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-109"><a href="#cb10-109" aria-hidden="true" tabindex="-1"></a><span class="al">![Likelihood fn and MLE](images/c1l04-ss-02-Likelihood-fn-and-MLE.png)</span>{#fig-likelihood-fn-and-mle .column-margin width="53mm"}</span>
<span id="cb10-110"><a href="#cb10-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-111"><a href="#cb10-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-112"><a href="#cb10-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-113"><a href="#cb10-113" aria-hidden="true" tabindex="-1"></a>::: {#exm-frequentist-heartattacks}</span>
<span id="cb10-114"><a href="#cb10-114" aria-hidden="true" tabindex="-1"></a><span class="fu">### Heart Attack Patients - MLE</span></span>
<span id="cb10-115"><a href="#cb10-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-116"><a href="#cb10-116" aria-hidden="true" tabindex="-1"></a>Consider a hospital where 400 patients are admitted over a month for heart attacks, and a month later 72 of them have died and 328 of them have survived.</span>
<span id="cb10-117"><a href="#cb10-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-118"><a href="#cb10-118" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">**what's our estimate of the mortality rate?**</span><span class="co">]</span>{.column-margin}</span>
<span id="cb10-119"><a href="#cb10-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-120"><a href="#cb10-120" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb10-121"><a href="#cb10-121" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Reference Population</span></span>
<span id="cb10-122"><a href="#cb10-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-123"><a href="#cb10-123" aria-hidden="true" tabindex="-1"></a>Under the *frequentist paradigm*, we must first establish our **reference population**. This is the cornerstone of our thinking as we are considering how the sample parameter approximates the population statistic. What do we think our reference population is here?</span>
<span id="cb10-124"><a href="#cb10-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-125"><a href="#cb10-125" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Ref Pop 1**: Heart attack patients in the region.</span>
<span id="cb10-126"><a href="#cb10-126" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Ref Pop 2**: Heart attack patients that are admitted to this hospital, but over a longer period.</span>
<span id="cb10-127"><a href="#cb10-127" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Ref Pop 3**: The people in the region who might have a heart attack and might get admitted to this hospital.</span>
<span id="cb10-128"><a href="#cb10-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-129"><a href="#cb10-129" aria-hidden="true" tabindex="-1"></a>Both *Ref Pop 1* and *Ref Pop 2* seem like viable options. Unfortunately, in our data is not a random sample drawn from either. We could pretend they are and move on, or we could also try to think harder about what our data is sampled from, perhaps *Ref Pop 3*.</span>
<span id="cb10-130"><a href="#cb10-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-131"><a href="#cb10-131" aria-hidden="true" tabindex="-1"></a>This is an odd hypothetical situation, and so there are some *philosophical issues* with the setup of this whole problem within the *frequentist paradigm*</span>
<span id="cb10-132"><a href="#cb10-132" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-133"><a href="#cb10-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-134"><a href="#cb10-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-135"><a href="#cb10-135" aria-hidden="true" tabindex="-1"></a>Y_i \sim \mathrm{Bernoulli}(p)</span>
<span id="cb10-136"><a href="#cb10-136" aria-hidden="true" tabindex="-1"></a>$$ {#eq-heartattack-rv}</span>
<span id="cb10-137"><a href="#cb10-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-138"><a href="#cb10-138" aria-hidden="true" tabindex="-1"></a>Since this is a Bernoulli trial we need to specify what we interpret as the *success* . In this case, the *success* is a mortality.</span>
<span id="cb10-139"><a href="#cb10-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-140"><a href="#cb10-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-141"><a href="#cb10-141" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(Y_i=1) = \theta </span>
<span id="cb10-142"><a href="#cb10-142" aria-hidden="true" tabindex="-1"></a>$$ {#eq-heartattack-success}</span>
<span id="cb10-143"><a href="#cb10-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-144"><a href="#cb10-144" aria-hidden="true" tabindex="-1"></a>The PDF for the dataset can be written in vector form. $\mathbb{P}r(\vec{Y}=\vec{y} \mid \theta)$ is the Probability of all the Y's take some value little y given a value of theta.</span>
<span id="cb10-145"><a href="#cb10-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-146"><a href="#cb10-146" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-147"><a href="#cb10-147" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb10-148"><a href="#cb10-148" aria-hidden="true" tabindex="-1"></a>\mathbb{P}r(\vec{Y}=\vec{y} \mid \theta) &amp;= \mathbb{P}r(Y_1=y,\dots,Y_n=y_n \mid \theta) &amp;&amp; \text{(joint probability)}<span class="sc">\\</span></span>
<span id="cb10-149"><a href="#cb10-149" aria-hidden="true" tabindex="-1"></a>&amp;= \mathbb{P}r(Y_1=y_1 \mid \theta) \cdots \mathbb{P}r(Y_n=y_n \mid \theta)            &amp;&amp; \text {(independence)}<span class="sc">\\</span></span>
<span id="cb10-150"><a href="#cb10-150" aria-hidden="true" tabindex="-1"></a>&amp;= \prod^n_{i=1} \mathbb{P}r(Y_i=y_i \mid \theta)                            &amp;&amp; \text {(product notation)}<span class="sc">\\</span></span>
<span id="cb10-151"><a href="#cb10-151" aria-hidden="true" tabindex="-1"></a>&amp;= \prod^n_{i=1} \theta^{y_i} (1-\theta)^{1-y_i}                   &amp;&amp; \text {(Bernoulli PMF)}</span>
<span id="cb10-152"><a href="#cb10-152" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb10-153"><a href="#cb10-153" aria-hidden="true" tabindex="-1"></a>$$ {#eq-heartattack-pdf}</span>
<span id="cb10-154"><a href="#cb10-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-155"><a href="#cb10-155" aria-hidden="true" tabindex="-1"></a>We now cal the expression for $\mathbb{P}r(\vec{Y}=\vec{y} \mid \theta)$ above the likelihood function $L(\theta \mid \vec{y} )$:</span>
<span id="cb10-156"><a href="#cb10-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-157"><a href="#cb10-157" aria-hidden="true" tabindex="-1"></a>$$  </span>
<span id="cb10-158"><a href="#cb10-158" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\theta\mid\vec{y}) = \prod^n_{i=1} \theta^{y_i} (1-\theta)^{1-y_i}</span>
<span id="cb10-159"><a href="#cb10-159" aria-hidden="true" tabindex="-1"></a>$$ {#eq-heart-attack-likelihood}</span>
<span id="cb10-160"><a href="#cb10-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-161"><a href="#cb10-161" aria-hidden="true" tabindex="-1"></a>Recall that we want to find the mortality rate parameter $\theta$ for our Sample $\vec Y$.</span>
<span id="cb10-162"><a href="#cb10-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-163"><a href="#cb10-163" aria-hidden="true" tabindex="-1"></a>Since it is a probability, it has a range of values from 0 to 1. One way to estimate it is that there should be one value that maximizes (@eq-heart-attack-likelihood). It makes the data the most likely to occur for the particular data we observed. This is referred to as the **maximum likelihood estimate** (MLE).</span>
<span id="cb10-164"><a href="#cb10-164" aria-hidden="true" tabindex="-1"></a>\index{Maximum Likelihood Estimation}</span>
<span id="cb10-165"><a href="#cb10-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-166"><a href="#cb10-166" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-167"><a href="#cb10-167" aria-hidden="true" tabindex="-1"></a>\mathop{\mathrm{MLE}}(\hat \theta) = \mathop{\mathrm{argmax}} \; \mathcal{L}(\theta\mid y)</span>
<span id="cb10-168"><a href="#cb10-168" aria-hidden="true" tabindex="-1"></a>$$ {#eq-heart-attack-mle}</span>
<span id="cb10-169"><a href="#cb10-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-170"><a href="#cb10-170" aria-hidden="true" tabindex="-1"></a>Although we are trying to find the $\theta$ that maximizes the likelihood, in practice, it's usually easier to maximize the natural logarithm of the likelihood, commonly referred to as the log-likelihood.</span>
<span id="cb10-171"><a href="#cb10-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-172"><a href="#cb10-172" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb10-173"><a href="#cb10-173" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb10-174"><a href="#cb10-174" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\theta) &amp;= \log(L(\theta|\vec{y}))  &amp;&amp; <span class="sc">\\</span></span>
<span id="cb10-175"><a href="#cb10-175" aria-hidden="true" tabindex="-1"></a>                    &amp;= \log(\prod^n_{i=1} {\theta^{y_i} (1-\theta)^{1-y_i}})       &amp;&amp; \text{subst. likelihood} <span class="sc">\\</span></span>
<span id="cb10-176"><a href="#cb10-176" aria-hidden="true" tabindex="-1"></a>                    &amp;= \sum^n_{i=1}{ \log(\theta^{y_i}) + \log(1-\theta)^{1-y_i}}  &amp;&amp; \text{log product rule} <span class="sc">\\</span></span>
<span id="cb10-177"><a href="#cb10-177" aria-hidden="true" tabindex="-1"></a>                    &amp;= \sum^n_{i=1}{ y_i \log(\theta) + (1-y_i) \log(1-\theta)}     &amp;&amp; \text{log power rule}<span class="sc">\\</span></span>
<span id="cb10-178"><a href="#cb10-178" aria-hidden="true" tabindex="-1"></a>                    &amp;= \log(\theta) \sum^n_{i=1}{  y_i + \log(1-\theta)} \sum^n_{i=1}{  (1-y_i) }&amp; &amp; \text{extracting logs}</span>
<span id="cb10-179"><a href="#cb10-179" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb10-180"><a href="#cb10-180" aria-hidden="true" tabindex="-1"></a>$$ {#eq-heart-attack-loglikelihood}</span>
<span id="cb10-181"><a href="#cb10-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-182"><a href="#cb10-182" aria-hidden="true" tabindex="-1"></a>What is the interpretation of the MLE of $\theta$ in the context of the heart attack example?</span>
<span id="cb10-183"><a href="#cb10-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-184"><a href="#cb10-184" aria-hidden="true" tabindex="-1"></a>If $\hat \theta$ is the MLE for $\theta$, the 30-day mortality rate, then all possible values of θ produce a lower value of the likelihood than $\hat \theta$.</span>
<span id="cb10-185"><a href="#cb10-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-186"><a href="#cb10-186" aria-hidden="true" tabindex="-1"></a>To calculate the MLE one should differentiate $\mathcal{L}(\theta)$ w.r.t. $\theta$ and then set it equal to 0.</span>
<span id="cb10-187"><a href="#cb10-187" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-188"><a href="#cb10-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-189"><a href="#cb10-189" aria-hidden="true" tabindex="-1"></a><span class="fu">## Computing the MLE {#sec-computing-the-MLE}</span></span>
<span id="cb10-190"><a href="#cb10-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-191"><a href="#cb10-191" aria-hidden="true" tabindex="-1"></a><span class="al">![Computing the MLE](images/c1l04-ss-03-computing-the-MLE.png)</span>{#fig-computing-the-mle .column-margin width="53mm"}</span>
<span id="cb10-192"><a href="#cb10-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-193"><a href="#cb10-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-194"><a href="#cb10-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-195"><a href="#cb10-195" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-196"><a href="#cb10-196" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb10-197"><a href="#cb10-197" aria-hidden="true" tabindex="-1"></a>   &amp;&amp; \mathcal{L}'(\theta)=&amp; \frac{1}{\theta}\sum_{i=1}^n y_i-\frac{1}{1-\theta}\sum_{i=1}^n 1-y_i \stackrel{\text{set}}{=}0  \text { set derivative to 0}</span>
<span id="cb10-198"><a href="#cb10-198" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp; \implies   &amp; \frac{1}{\hat \theta}\sum_{i=1}^n y_i &amp; = \frac{1}{1- \hat \theta}\sum_{i=1}^n 1 - y_i </span>
<span id="cb10-199"><a href="#cb10-199" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp; \implies   &amp; (1 -\hat \theta) \sum_{i=1}^n{y_i}    &amp;= \hat\theta \sum_{i=1}^n {1-y_i}  </span>
<span id="cb10-200"><a href="#cb10-200" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp; \implies   &amp; 1 \sum_{i=1}^n{y_i} - \cancel{ \hat \theta \sum_{i=1}^{n}{y_i}} &amp;= \hat\theta \sum_{i=1}^n {1} - \cancel{\hat\theta \sum_{i=1}^n {y_i}}  </span>
<span id="cb10-201"><a href="#cb10-201" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp; \implies   &amp; \sum_{i=1}^n{y_i}  &amp;= \hat\theta N </span>
<span id="cb10-202"><a href="#cb10-202" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp; \implies   &amp;  \hat \theta &amp;= \frac{1}{N} \sum_{i=1}^n y_i  = \hat p = \frac{72}{400}=.18</span>
<span id="cb10-203"><a href="#cb10-203" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb10-204"><a href="#cb10-204" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-205"><a href="#cb10-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-206"><a href="#cb10-206" aria-hidden="true" tabindex="-1"></a>*Maximum Likelihood Estimates* (MLEs) possess the following favorable properties:</span>
<span id="cb10-207"><a href="#cb10-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-208"><a href="#cb10-208" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Unbiased** - Thus given sufficient data the MLE will converge to the true value. As a consequence, *MLEs are asymptotically unbiased*. As we will see in the examples they can still be biased in finite samples.</span>
<span id="cb10-209"><a href="#cb10-209" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**consistent** - One important property of maximum likelihood is that it produces consistent estimates.</span>
<span id="cb10-210"><a href="#cb10-210" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**invariant** - The invariance principle states that the *MLE is invariant against reparameterization*.</span>
<span id="cb10-211"><a href="#cb10-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-212"><a href="#cb10-212" aria-hidden="true" tabindex="-1"></a>using the Central Limit theorem (see @thm-clt).</span>
<span id="cb10-213"><a href="#cb10-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-214"><a href="#cb10-214" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-215"><a href="#cb10-215" aria-hidden="true" tabindex="-1"></a>\hat \theta \pm 1.96\sqrt\frac{\hat \theta(1-\hat \theta)}{n}</span>
<span id="cb10-216"><a href="#cb10-216" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-217"><a href="#cb10-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-218"><a href="#cb10-218" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-219"><a href="#cb10-219" aria-hidden="true" tabindex="-1"></a>\hat \theta \simeq \mathcal{N}(\theta,\frac{1}{\mathcal{I} (\hat \theta)})</span>
<span id="cb10-220"><a href="#cb10-220" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-221"><a href="#cb10-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-222"><a href="#cb10-222" aria-hidden="true" tabindex="-1"></a>where $\mathcal{I}$ is the *Fischer information* which for the Bernoulli distribution is:</span>
<span id="cb10-223"><a href="#cb10-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-224"><a href="#cb10-224" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-225"><a href="#cb10-225" aria-hidden="true" tabindex="-1"></a>\mathcal{I}( \hat \theta) = \frac{1}{\theta(1-\theta)}</span>
<span id="cb10-226"><a href="#cb10-226" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-227"><a href="#cb10-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-228"><a href="#cb10-228" aria-hidden="true" tabindex="-1"></a>Note: The *Fischer information* is a measure of how much information about theta is in each data point!</span>
<span id="cb10-229"><a href="#cb10-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-230"><a href="#cb10-230" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb10-231"><a href="#cb10-231" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Explainable AI (XAI) &amp; Fischer information</span></span>
<span id="cb10-232"><a href="#cb10-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-233"><a href="#cb10-233" aria-hidden="true" tabindex="-1"></a>In XAI we use discuss local and global explanations.</span>
<span id="cb10-234"><a href="#cb10-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-235"><a href="#cb10-235" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`Global explanations`</span> explain a black box model's predictions based on each feature, via its parameters.</span>
<span id="cb10-236"><a href="#cb10-236" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`Local explanations`</span> explain the prediction of a specific datum from its features.</span>
<span id="cb10-237"><a href="#cb10-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-238"><a href="#cb10-238" aria-hidden="true" tabindex="-1"></a>since <span class="in">`Fischer information`</span> quantifies the information in a data point on a parameter we should be able to use it to produce local and perhaps even global explanations for Bayesian models.</span>
<span id="cb10-239"><a href="#cb10-239" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-240"><a href="#cb10-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-241"><a href="#cb10-241" aria-hidden="true" tabindex="-1"></a><span class="fu">## Computing the MLE: examples {#sec-computing-the-MLE-examples}</span></span>
<span id="cb10-242"><a href="#cb10-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-243"><a href="#cb10-243" aria-hidden="true" tabindex="-1"></a>Some more examples of maximum likelihood estimators.</span>
<span id="cb10-244"><a href="#cb10-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-245"><a href="#cb10-245" aria-hidden="true" tabindex="-1"></a><span class="fu">### Computing the MLE for Exponential RV {#sec-computing-the-MLE-for-exponential-RV}</span></span>
<span id="cb10-246"><a href="#cb10-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-247"><a href="#cb10-247" aria-hidden="true" tabindex="-1"></a><span class="al">![computing the MLE for Exponential RV](images/c1l04-ss-04-computing-the-exponential-MLE.png)</span>{#fig-computing-the-MLE-for-exponential-rv .column-margin width="53mm"}</span>
<span id="cb10-248"><a href="#cb10-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-249"><a href="#cb10-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-250"><a href="#cb10-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-251"><a href="#cb10-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-252"><a href="#cb10-252" aria-hidden="true" tabindex="-1"></a>Let's say $X_i$ are exponential distributed </span>
<span id="cb10-253"><a href="#cb10-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-254"><a href="#cb10-254" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb10-255"><a href="#cb10-255" aria-hidden="true" tabindex="-1"></a>X_i \sim \mathrm{Exp}(\lambda) </span>
<span id="cb10-256"><a href="#cb10-256" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-257"><a href="#cb10-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-258"><a href="#cb10-258" aria-hidden="true" tabindex="-1"></a>Let's say the data is independent and identically distributed, therefore making the overall density function</span>
<span id="cb10-259"><a href="#cb10-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-260"><a href="#cb10-260" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-261"><a href="#cb10-261" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb10-262"><a href="#cb10-262" aria-hidden="true" tabindex="-1"></a>  f(x \mid \lambda) &amp;= \prod_{i = 1}^n{\lambda e^{-\lambda x_i}} &amp;&amp; \text {(simplifying)} <span class="sc">\\</span></span>
<span id="cb10-263"><a href="#cb10-263" aria-hidden="true" tabindex="-1"></a>                    &amp;= \lambda^ne^{-\lambda \sum{x_i}}</span>
<span id="cb10-264"><a href="#cb10-264" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb10-265"><a href="#cb10-265" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-likelihood-derivation}</span>
<span id="cb10-266"><a href="#cb10-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-267"><a href="#cb10-267" aria-hidden="true" tabindex="-1"></a>Now the likelihood function is</span>
<span id="cb10-268"><a href="#cb10-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-269"><a href="#cb10-269" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-270"><a href="#cb10-270" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\lambda \mid x)=\lambda^ne^{-\lambda \sum{x_i}}</span>
<span id="cb10-271"><a href="#cb10-271" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-likelihood-fn}</span>
<span id="cb10-272"><a href="#cb10-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-273"><a href="#cb10-273" aria-hidden="true" tabindex="-1"></a>the log likelihood is</span>
<span id="cb10-274"><a href="#cb10-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-275"><a href="#cb10-275" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-276"><a href="#cb10-276" aria-hidden="true" tabindex="-1"></a>\ell(\lambda) = n\ln{\lambda} - \lambda\sum_i{x_i}</span>
<span id="cb10-277"><a href="#cb10-277" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-log-likelihood-fn}</span>
<span id="cb10-278"><a href="#cb10-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-279"><a href="#cb10-279" aria-hidden="true" tabindex="-1"></a>Taking the derivative</span>
<span id="cb10-280"><a href="#cb10-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-281"><a href="#cb10-281" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-282"><a href="#cb10-282" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb10-283"><a href="#cb10-283" aria-hidden="true" tabindex="-1"></a>  \ell^\prime(\lambda) &amp;= \frac{n}{\lambda} - \sum_i{x_i} \stackrel{\text{set}}{=}0 &amp;&amp; \text {(set derivative = 0)} <span class="sc">\\</span> </span>
<span id="cb10-284"><a href="#cb10-284" aria-hidden="true" tabindex="-1"></a>  \implies \frac{n}{\hat{\lambda}} &amp;= \sum_i{x_i} &amp;&amp; \text{(rearranging)}</span>
<span id="cb10-285"><a href="#cb10-285" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb10-286"><a href="#cb10-286" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-log-likelihood-derivative}</span>
<span id="cb10-287"><a href="#cb10-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-288"><a href="#cb10-288" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-289"><a href="#cb10-289" aria-hidden="true" tabindex="-1"></a>\hat{\lambda} = \frac{n}{\sum_i{x_i}} = \frac{1}{\bar{x}}</span>
<span id="cb10-290"><a href="#cb10-290" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-MLE}</span>
<span id="cb10-291"><a href="#cb10-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-292"><a href="#cb10-292" aria-hidden="true" tabindex="-1"></a><span class="fu">### Computing the MLE for Uniform RV {#sec-computing-the-MLE-for-uniform-RV}</span></span>
<span id="cb10-293"><a href="#cb10-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-294"><a href="#cb10-294" aria-hidden="true" tabindex="-1"></a><span class="al">![computing the MLE for Uniform RV](images/c1l04-ss-05-computing-the-uniform-MLE.png)</span>{#fig-computing-the-MLE-for-uniform-RV .column-margin width="53mm"}</span>
<span id="cb10-295"><a href="#cb10-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-296"><a href="#cb10-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-297"><a href="#cb10-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-298"><a href="#cb10-298" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-299"><a href="#cb10-299" aria-hidden="true" tabindex="-1"></a>X_i \sim \mathcal{U}<span class="co">[</span><span class="ot">0, \theta</span><span class="co">]</span></span>
<span id="cb10-300"><a href="#cb10-300" aria-hidden="true" tabindex="-1"></a>$$ {#eq-uniform-mle-rv}</span>
<span id="cb10-301"><a href="#cb10-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-302"><a href="#cb10-302" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-303"><a href="#cb10-303" aria-hidden="true" tabindex="-1"></a>f(x \mid \theta) = \prod_{i = 1}^n{\frac{1}{\theta}\mathbb{I}_{0 \le x_i \le \theta}}</span>
<span id="cb10-304"><a href="#cb10-304" aria-hidden="true" tabindex="-1"></a>$$ {#eq-uniform-MLE-likelihood-derivation}</span>
<span id="cb10-305"><a href="#cb10-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-306"><a href="#cb10-306" aria-hidden="true" tabindex="-1"></a>Combining all the indicator functions, for this to be a 1, each of these has to be true. </span>
<span id="cb10-307"><a href="#cb10-307" aria-hidden="true" tabindex="-1"></a>These are going to be true if all the observations are bigger than 0, as in the minimum of the x is bigger than or equal to 0. </span>
<span id="cb10-308"><a href="#cb10-308" aria-hidden="true" tabindex="-1"></a>The maximum of the x's is also less than or equal to $\theta$.</span>
<span id="cb10-309"><a href="#cb10-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-310"><a href="#cb10-310" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-311"><a href="#cb10-311" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(\theta|x) = \theta^{-1} \mathbb{I}_{0\le min(x_i) \le max(x_i) \le \theta}</span>
<span id="cb10-312"><a href="#cb10-312" aria-hidden="true" tabindex="-1"></a>$$ {#eq-uniform-MLE-likelihood}</span>
<span id="cb10-313"><a href="#cb10-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-314"><a href="#cb10-314" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-315"><a href="#cb10-315" aria-hidden="true" tabindex="-1"></a>\mathcal{L}^\prime(\theta) = -n\theta^{-(n + 1)}\mathbb{I}_{0 \le min(x_i) \le max(x_i)\le \theta}</span>
<span id="cb10-316"><a href="#cb10-316" aria-hidden="true" tabindex="-1"></a>$$ {#eq-uniform-MLE-likelihood-derivative}</span>
<span id="cb10-317"><a href="#cb10-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-318"><a href="#cb10-318" aria-hidden="true" tabindex="-1"></a>We ask, can we set this equal to zero and solve for $\theta$? It turns out, this is not equal to zero for any $\theta$ positive value. We need $\theta$ to be strictly larger than zero. But for $\theta$ positive, this will always be negative. The derivative is negative, that says this is a decreasing function. Therefore this function will be maximized when we pick $\theta$ as small as possible. What's the smallest possible value of $\theta$ we can pick? Well we need in particular for $\theta$ to be larger than all of the $X_i$. And so, the maximum likelihood estimate is the maximum of $X_i$</span>
<span id="cb10-319"><a href="#cb10-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-320"><a href="#cb10-320" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-321"><a href="#cb10-321" aria-hidden="true" tabindex="-1"></a>\hat{\theta} = max(x_i)</span>
<span id="cb10-322"><a href="#cb10-322" aria-hidden="true" tabindex="-1"></a>$$ {#eq-uniform-mle}</span>
<span id="cb10-323"><a href="#cb10-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-324"><a href="#cb10-324" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cumulative Distribution Function {#sec-cumulative-distribution-function}</span></span>
<span id="cb10-325"><a href="#cb10-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-326"><a href="#cb10-326" aria-hidden="true" tabindex="-1"></a>The cumulative distribution function (CDF) exists for every distribution. We define it as $F(x) = \mathbb{P}r(X \le x)$ for random variable $X$.</span>
<span id="cb10-327"><a href="#cb10-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-328"><a href="#cb10-328" aria-hidden="true" tabindex="-1"></a>If $X$ is discrete-valued, then the CDF is computed with summation $F(x) = \sum_{t = -\infty}^x {f(t)}$. where $f(t) = \mathbb{P}r(X = t)$ is the probability mass function (PMF) which we've already seen.</span>
<span id="cb10-329"><a href="#cb10-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-330"><a href="#cb10-330" aria-hidden="true" tabindex="-1"></a>If $X$ is continuous, the CDF is computed with an integral $F(x) = \int_{-\infty}^x{f(t)dt}$</span>
<span id="cb10-331"><a href="#cb10-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-332"><a href="#cb10-332" aria-hidden="true" tabindex="-1"></a>The CDF is convenient for calculating probabilities of intervals. Let $a$ and $b$ be any real numbers with $a &lt; b$. Then the probability that $X$ falls between $a$ and $b$ is equal to $\mathbb{P}r(a &lt; X &lt; b) = \mathbb{P}r(X \le b) - \mathbb{P}r(X \le a) = F(b) - F(a)$</span>
<span id="cb10-333"><a href="#cb10-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-334"><a href="#cb10-334" aria-hidden="true" tabindex="-1"></a><span class="al">![Illustration of using the CDF to calculate the probability of an interval for continuous random variable X. Probability values are represented with shaded regions in the graphs.](images/c1l04-ss-06-CDF.png)</span>{#fig-interval-from-cdf fig-alt="using the CDF to calculate the probability of an interval" width="53mm"}</span>
<span id="cb10-335"><a href="#cb10-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-336"><a href="#cb10-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-337"><a href="#cb10-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-338"><a href="#cb10-338" aria-hidden="true" tabindex="-1"></a>::: {#exm-cdf-1}</span>
<span id="cb10-339"><a href="#cb10-339" aria-hidden="true" tabindex="-1"></a><span class="fu">#### CDF example 1</span></span>
<span id="cb10-340"><a href="#cb10-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-341"><a href="#cb10-341" aria-hidden="true" tabindex="-1"></a>Suppose $X \sim \mathrm{Binomial}(5, 0.6)$. Then</span>
<span id="cb10-342"><a href="#cb10-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-343"><a href="#cb10-343" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-344"><a href="#cb10-344" aria-hidden="true" tabindex="-1"></a>  \begin{aligned}</span>
<span id="cb10-345"><a href="#cb10-345" aria-hidden="true" tabindex="-1"></a>  F(1) &amp;= \mathbb{P}r(X \le 1) </span>
<span id="cb10-346"><a href="#cb10-346" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= \sum_{−∞}^1 f(t) </span>
<span id="cb10-347"><a href="#cb10-347" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= \sum_{t=−∞}^{-1} 0 + \sum_{t=0}^1 {5 \choose t} 0.6^t (1 − 0.6)^{5−t} </span>
<span id="cb10-348"><a href="#cb10-348" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= {5 \choose 0} 0.6^0 (1 − 0.6)5−0 +{5 \choose 1} 0.6^1 (1 − 0.6)^{5−1} </span>
<span id="cb10-349"><a href="#cb10-349" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= (0.4)^5 + 5(0.6)(0.4)^4</span>
<span id="cb10-350"><a href="#cb10-350" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;≈ 0.087</span>
<span id="cb10-351"><a href="#cb10-351" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb10-352"><a href="#cb10-352" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cdf-ex1}</span>
<span id="cb10-353"><a href="#cb10-353" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-354"><a href="#cb10-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-355"><a href="#cb10-355" aria-hidden="true" tabindex="-1"></a>::: {#exm-cdf-2}</span>
<span id="cb10-356"><a href="#cb10-356" aria-hidden="true" tabindex="-1"></a><span class="fu">#### CDF example 1</span></span>
<span id="cb10-357"><a href="#cb10-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-358"><a href="#cb10-358" aria-hidden="true" tabindex="-1"></a>Example: Suppose $Y ∼ Exp(1)$. Then</span>
<span id="cb10-359"><a href="#cb10-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-360"><a href="#cb10-360" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-361"><a href="#cb10-361" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb10-362"><a href="#cb10-362" aria-hidden="true" tabindex="-1"></a>F(2) &amp;= \mathbb{P}r(Y \le 2) </span>
<span id="cb10-363"><a href="#cb10-363" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= \int^{2}_{−∞} e^{−t}\mathbb{I}_{(t≥0)} dt </span>
<span id="cb10-364"><a href="#cb10-364" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= \int^{2}_{0} e^{−t}dt </span>
<span id="cb10-365"><a href="#cb10-365" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= −e^{−t}|^2_0 </span>
<span id="cb10-366"><a href="#cb10-366" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= −(e^{−2} − e^0) </span>
<span id="cb10-367"><a href="#cb10-367" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;= 1−e^{−2} </span>
<span id="cb10-368"><a href="#cb10-368" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span> &amp;\approx 0.865</span>
<span id="cb10-369"><a href="#cb10-369" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb10-370"><a href="#cb10-370" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cdf-ex2}</span>
<span id="cb10-371"><a href="#cb10-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-372"><a href="#cb10-372" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-373"><a href="#cb10-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-374"><a href="#cb10-374" aria-hidden="true" tabindex="-1"></a><span class="fu">## Quantile Function {#sec-quantile-function}</span></span>
<span id="cb10-375"><a href="#cb10-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-376"><a href="#cb10-376" aria-hidden="true" tabindex="-1"></a>The CDF takes a value for a random variable and returns a probability. Suppose instead we start with a number between $0$ and $1$, which we call $p$, and we wish to find a value $x$ so that $\mathbb{P}r(X \le x) = p$. The value $x$ which satisfies this equation is called the $p$ quantile. (or $100p$ percentile) of the distribution of $X$.</span>
<span id="cb10-377"><a href="#cb10-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-378"><a href="#cb10-378" aria-hidden="true" tabindex="-1"></a>::: {#exm-qf-1}</span>
<span id="cb10-379"><a href="#cb10-379" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Quantile Function example 1</span></span>
<span id="cb10-380"><a href="#cb10-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-381"><a href="#cb10-381" aria-hidden="true" tabindex="-1"></a>In a standardized test, the 97th percentile of scores among all test-takers is 23. Then 23 is the score you must achieve on the test in order to score higher than 97% of all test-takers. We could equivalently call $q = 23$ the .97 quantile of the distribution of test scores.</span>
<span id="cb10-382"><a href="#cb10-382" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-383"><a href="#cb10-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-384"><a href="#cb10-384" aria-hidden="true" tabindex="-1"></a>::: {#exm-qf-2}</span>
<span id="cb10-385"><a href="#cb10-385" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Quantile Function example 2</span></span>
<span id="cb10-386"><a href="#cb10-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-387"><a href="#cb10-387" aria-hidden="true" tabindex="-1"></a>The middle 50% of probability mass for a continuous random variable is found between the .25 and .75 quantiles of its distribution. If $Z \sim N(0, 1)$, then the $.25$ quantile is $−0.674$ and the $.75$ quantile is 0.674. Therefore, $\mathbb{P}r(−0.674 <span class="dt">&lt;</span><span class="kw">Z</span><span class="ot"> </span><span class="er">&lt;0.674)</span><span class="ot"> </span><span class="op">=</span> <span class="st">0.5$.</span></span>
<span id="cb10-388"><a href="#cb10-388" aria-hidden="true" tabindex="-1"></a><span class="ot">:::</span></span>
<span id="cb10-389"><a href="#cb10-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-390"><a href="#cb10-390" aria-hidden="true" tabindex="-1"></a><span class="ot"># Introduction to R </span><span class="er">{</span><span class="ot">#sec-introduction-to-r</span><span class="er">}</span></span>
<span id="cb10-391"><a href="#cb10-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-392"><a href="#cb10-392" aria-hidden="true" tabindex="-1"></a><span class="ot">R has some nice functions that one can use for analysis</span></span>
<span id="cb10-393"><a href="#cb10-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-394"><a href="#cb10-394" aria-hidden="true" tabindex="-1"></a><span class="er">`</span><span class="ot">mean(z)</span><span class="er">`</span><span class="ot"> gives the mean of some row vector </span><span class="er">$</span><span class="ot">z</span><span class="er">$</span></span>
<span id="cb10-395"><a href="#cb10-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-396"><a href="#cb10-396" aria-hidden="true" tabindex="-1"></a><span class="er">`</span><span class="ot">var(z)</span><span class="er">`</span><span class="ot"> reports the variance of some row vector</span></span>
<span id="cb10-397"><a href="#cb10-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-398"><a href="#cb10-398" aria-hidden="true" tabindex="-1"></a><span class="er">`</span><span class="ot">sqrt(var(z))</span><span class="er">`</span><span class="ot"> gives the standard deviation of some row vector</span></span>
<span id="cb10-399"><a href="#cb10-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-400"><a href="#cb10-400" aria-hidden="true" tabindex="-1"></a><span class="er">`</span><span class="ot">seq(from</span><span class="op">=</span><span class="st">0.1,</span><span class="ot"> to </span><span class="op">=</span> <span class="st">0.9,</span><span class="ot"> by </span><span class="op">=</span> <span class="st">0.1)</span><span class="er">`</span><span class="ot"> creates a vector that starts from </span><span class="er">$0.1$</span><span class="ot"> and goes to </span><span class="er">$0.9$</span><span class="ot"> incrementing by </span><span class="er">$0.1$</span></span>
<span id="cb10-401"><a href="#cb10-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-404"><a href="#cb10-404" aria-hidden="true" tabindex="-1"></a><span class="in">```{R}</span></span>
<span id="cb10-405"><a href="#cb10-405" aria-hidden="true" tabindex="-1"></a><span class="ot">#</span><span class="er">|</span><span class="ot"> label: intro-sequence1</span></span>
<span id="cb10-406"><a href="#cb10-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-407"><a href="#cb10-407" aria-hidden="true" tabindex="-1"></a><span class="ot">seq(from</span><span class="op">=</span><span class="st">0.1,</span><span class="ot"> to </span><span class="op">=</span> <span class="st">0.9,</span><span class="ot"> by </span><span class="op">=</span> <span class="st">0.1)</span></span>
<span id="cb10-408"><a href="#cb10-408" aria-hidden="true" tabindex="-1"></a><span class="er">```</span></span>
<span id="cb10-409"><a href="#cb10-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-412"><a href="#cb10-412" aria-hidden="true" tabindex="-1"></a><span class="in">```{R}</span></span>
<span id="cb10-413"><a href="#cb10-413" aria-hidden="true" tabindex="-1"></a><span class="ot">#</span><span class="er">|</span><span class="ot"> label: intro-sequence2</span></span>
<span id="cb10-414"><a href="#cb10-414" aria-hidden="true" tabindex="-1"></a><span class="ot">seq(1</span><span class="er">,</span><span class="ot"> </span><span class="er">10)</span></span>
<span id="cb10-415"><a href="#cb10-415" aria-hidden="true" tabindex="-1"></a><span class="er">```</span></span>
<span id="cb10-416"><a href="#cb10-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-417"><a href="#cb10-417" aria-hidden="true" tabindex="-1"></a><span class="er">`</span><span class="ot">names(x)</span><span class="er">`</span><span class="ot"> gives the names of all the columns in the dataset.</span></span>
<span id="cb10-418"><a href="#cb10-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-421"><a href="#cb10-421" aria-hidden="true" tabindex="-1"></a><span class="in">```{R}</span></span>
<span id="cb10-422"><a href="#cb10-422" aria-hidden="true" tabindex="-1"></a><span class="ot">#</span><span class="er">|</span><span class="ot"> label: intro-names</span></span>
<span id="cb10-423"><a href="#cb10-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-424"><a href="#cb10-424" aria-hidden="true" tabindex="-1"></a><span class="ot">names(trees)</span></span>
<span id="cb10-425"><a href="#cb10-425" aria-hidden="true" tabindex="-1"></a><span class="er">```</span></span>
<span id="cb10-426"><a href="#cb10-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-427"><a href="#cb10-427" aria-hidden="true" tabindex="-1"></a><span class="er">`</span><span class="ot">hist(x)</span><span class="er">`</span><span class="ot"> provides a histogram based on a vector</span></span>
<span id="cb10-428"><a href="#cb10-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-429"><a href="#cb10-429" aria-hidden="true" tabindex="-1"></a><span class="ot">The more general </span><span class="er">`</span><span class="ot">plot</span><span class="er">`</span><span class="ot"> function tries to guess at which type of plot to make. Feeding it two numerical vectors will make a scatter plot.</span></span>
<span id="cb10-430"><a href="#cb10-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-431"><a href="#cb10-431" aria-hidden="true" tabindex="-1"></a><span class="ot">The R function </span><span class="er">`</span><span class="ot">pairs</span><span class="er">`</span><span class="ot"> takes in a data frame and tries to make all possible Pairwise scatterplots for the dataset.</span></span>
<span id="cb10-432"><a href="#cb10-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-433"><a href="#cb10-433" aria-hidden="true" tabindex="-1"></a><span class="ot">The </span><span class="er">`</span><span class="ot">summary</span><span class="er">`</span><span class="ot"> command gives the five</span><span class="er">/</span><span class="ot">six number summary (minimum</span><span class="er">,</span><span class="ot"> first quartile</span><span class="er">,</span><span class="ot"> median</span><span class="er">,</span><span class="ot"> mean</span><span class="er">,</span><span class="ot"> third quartile</span><span class="er">,</span><span class="ot"> maximum)</span></span>
<span id="cb10-434"><a href="#cb10-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-435"><a href="#cb10-435" aria-hidden="true" tabindex="-1"></a><span class="ot">## Plotting the likelihood function in R </span><span class="er">{</span><span class="ot">#sec-plotting-the-likelihood-function-in-r</span><span class="er">}</span></span>
<span id="cb10-436"><a href="#cb10-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-437"><a href="#cb10-437" aria-hidden="true" tabindex="-1"></a><span class="ot">Going back to the hospital example</span></span>
<span id="cb10-438"><a href="#cb10-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-441"><a href="#cb10-441" aria-hidden="true" tabindex="-1"></a><span class="in">```{R}</span></span>
<span id="cb10-442"><a href="#cb10-442" aria-hidden="true" tabindex="-1"></a><span class="ot">#</span><span class="er">|</span><span class="ot"> label: intro-likelihood-function</span></span>
<span id="cb10-443"><a href="#cb10-443" aria-hidden="true" tabindex="-1"></a><span class="ot">likelihood </span><span class="op">=</span> <span class="st">function(n,</span><span class="ot"> y</span><span class="er">,</span><span class="ot"> theta) </span><span class="er">{</span></span>
<span id="cb10-444"><a href="#cb10-444" aria-hidden="true" tabindex="-1"></a><span class="ot">  return(theta</span><span class="er">^</span><span class="ot">y * (1 </span><span class="er">-</span><span class="ot"> theta)</span><span class="er">^</span><span class="ot">(n </span><span class="er">-</span><span class="ot"> y))</span></span>
<span id="cb10-445"><a href="#cb10-445" aria-hidden="true" tabindex="-1"></a><span class="er">}</span></span>
<span id="cb10-446"><a href="#cb10-446" aria-hidden="true" tabindex="-1"></a><span class="ot">theta </span><span class="op">=</span> <span class="st">seq(from</span><span class="ot"> </span><span class="op">=</span> <span class="st">0.01,</span><span class="ot"> to </span><span class="op">=</span> <span class="st">0.99,</span><span class="ot"> by </span><span class="op">=</span> <span class="st">0.01)</span></span>
<span id="cb10-447"><a href="#cb10-447" aria-hidden="true" tabindex="-1"></a><span class="ot">plot(theta</span><span class="er">,</span><span class="ot"> likelihood(400</span><span class="er">,</span><span class="ot"> </span><span class="er">72,</span><span class="ot"> theta))</span></span>
<span id="cb10-448"><a href="#cb10-448" aria-hidden="true" tabindex="-1"></a><span class="er">```</span></span>
<span id="cb10-449"><a href="#cb10-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-450"><a href="#cb10-450" aria-hidden="true" tabindex="-1"></a><span class="ot">You can also do this with log likelihoods. This is typically more numerically stable to compute</span></span>
<span id="cb10-451"><a href="#cb10-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-454"><a href="#cb10-454" aria-hidden="true" tabindex="-1"></a><span class="in">```{R}</span></span>
<span id="cb10-455"><a href="#cb10-455" aria-hidden="true" tabindex="-1"></a><span class="ot">#</span><span class="er">|</span><span class="ot"> label: intro-loglikelihood-function-plot1</span></span>
<span id="cb10-456"><a href="#cb10-456" aria-hidden="true" tabindex="-1"></a><span class="ot">loglike </span><span class="op">=</span> <span class="st">function(n,</span><span class="ot"> y</span><span class="er">,</span><span class="ot"> theta) </span><span class="er">{</span></span>
<span id="cb10-457"><a href="#cb10-457" aria-hidden="true" tabindex="-1"></a><span class="ot">  return(y * log(theta) </span><span class="er">+</span><span class="ot"> (n </span><span class="er">-</span><span class="ot"> y) * log(1 </span><span class="er">-</span><span class="ot"> theta))</span></span>
<span id="cb10-458"><a href="#cb10-458" aria-hidden="true" tabindex="-1"></a><span class="er">}</span></span>
<span id="cb10-459"><a href="#cb10-459" aria-hidden="true" tabindex="-1"></a><span class="ot">plot(theta</span><span class="er">,</span><span class="ot"> loglike(400</span><span class="er">,</span><span class="ot"> </span><span class="er">72,</span><span class="ot"> theta))</span></span>
<span id="cb10-460"><a href="#cb10-460" aria-hidden="true" tabindex="-1"></a><span class="er">```</span></span>
<span id="cb10-461"><a href="#cb10-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-462"><a href="#cb10-462" aria-hidden="true" tabindex="-1"></a><span class="ot">Having these plotted as points makes it difficult to see</span><span class="er">,</span><span class="ot"> let</span><span class="er">'</span><span class="ot">s plot it as lines</span></span>
<span id="cb10-463"><a href="#cb10-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-466"><a href="#cb10-466" aria-hidden="true" tabindex="-1"></a><span class="in">```{R}</span></span>
<span id="cb10-467"><a href="#cb10-467" aria-hidden="true" tabindex="-1"></a><span class="ot">#</span><span class="er">|</span><span class="ot"> label: intro-likelihood-function-plot2</span></span>
<span id="cb10-468"><a href="#cb10-468" aria-hidden="true" tabindex="-1"></a><span class="ot">plot(theta</span><span class="er">,</span><span class="ot"> loglike(400</span><span class="er">,</span><span class="ot"> </span><span class="er">72,</span><span class="ot"> theta)</span><span class="er">,</span><span class="ot"> type </span><span class="op">=</span> <span class="st">"l"</span><span class="er">)</span></span>
<span id="cb10-469"><a href="#cb10-469" aria-hidden="true" tabindex="-1"></a><span class="er">```</span></span>
<span id="cb10-470"><a href="#cb10-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-471"><a href="#cb10-471" aria-hidden="true" tabindex="-1"></a><span class="ot"># Probability Distributions in R </span><span class="er">{</span><span class="ot">#sec-probability-distributions-in-r</span><span class="er">}</span></span>
<span id="cb10-472"><a href="#cb10-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-473"><a href="#cb10-473" aria-hidden="true" tabindex="-1"></a><span class="ot">Each of the distributions introduced in Lesson </span><span class="er">3</span><span class="ot"> have convenient functions in R which allow you to evaluate the PDF</span><span class="er">/</span><span class="ot">PMF</span><span class="er">,</span><span class="ot"> CDF</span><span class="er">,</span><span class="ot"> and quantile functions</span><span class="er">,</span><span class="ot"> as well as generate random samples from the distribution. To illustrate</span><span class="er">,</span><span class="ot"> see </span><span class="er">@</span><span class="ot">tbl-r-api-normal</span><span class="er">,</span><span class="ot"> which lists these functions for the normal distribution</span></span>
<span id="cb10-474"><a href="#cb10-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-475"><a href="#cb10-475" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> Function             </span><span class="er">|</span><span class="ot"> What it does                                                      </span><span class="er">|</span></span>
<span id="cb10-476"><a href="#cb10-476" aria-hidden="true" tabindex="-1"></a><span class="er">|----------------------|-------------------------------------------------------------------|</span></span>
<span id="cb10-477"><a href="#cb10-477" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dnorm(x</span><span class="er">,</span><span class="ot"> mean</span><span class="er">,</span><span class="ot"> sd)</span><span class="er">`</span><span class="ot"> </span><span class="er">|</span><span class="ot"> Evaluate the PDF at </span><span class="er">$</span><span class="ot">x</span><span class="er">$</span><span class="ot"> (mean </span><span class="op">=</span> <span class="st">$\mu$</span><span class="ot"> and sd </span><span class="op">=</span> <span class="st">$\sqrt{\sigma^2}$)</span><span class="ot"> </span><span class="er">|</span></span>
<span id="cb10-478"><a href="#cb10-478" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">pnorm(q</span><span class="er">,</span><span class="ot"> mean</span><span class="er">,</span><span class="ot"> sd)</span><span class="er">`</span><span class="ot"> </span><span class="er">|</span><span class="ot"> Evaluate the CDF at </span><span class="er">$</span><span class="ot">q</span><span class="er">$</span><span class="ot">                                           </span><span class="er">|</span></span>
<span id="cb10-479"><a href="#cb10-479" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">qnorm(p</span><span class="er">,</span><span class="ot"> mean</span><span class="er">,</span><span class="ot"> sd)</span><span class="er">`</span><span class="ot"> </span><span class="er">|</span><span class="ot"> Evaluate the quantile function at </span><span class="er">$</span><span class="ot">p</span><span class="er">$</span><span class="ot">                             </span><span class="er">|</span></span>
<span id="cb10-480"><a href="#cb10-480" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">rnorm(n</span><span class="er">,</span><span class="ot"> mean</span><span class="er">,</span><span class="ot"> sd)</span><span class="er">`</span><span class="ot"> </span><span class="er">|</span><span class="ot"> Generate </span><span class="er">$</span><span class="ot">n</span><span class="er">$</span><span class="ot"> pseudo-random samples from the normal distribution   </span><span class="er">|</span></span>
<span id="cb10-481"><a href="#cb10-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-482"><a href="#cb10-482" aria-hidden="true" tabindex="-1"></a><span class="ot">: R API for the normal distribution </span><span class="er">{</span><span class="ot">#tbl-r-api-normal</span><span class="er">}</span></span>
<span id="cb10-483"><a href="#cb10-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-484"><a href="#cb10-484" aria-hidden="true" tabindex="-1"></a><span class="ot">These four functions exist for each distribution where </span><span class="er">`</span><span class="ot">d...</span><span class="er">`</span><span class="ot"> function evaluates the density</span><span class="er">/</span><span class="ot">mass</span><span class="er">,</span><span class="ot"> </span><span class="er">`</span><span class="ot">p...</span><span class="er">`</span><span class="ot"> evaluates the CDF</span><span class="er">,</span><span class="ot"> </span><span class="er">`</span><span class="ot">q...</span><span class="er">`</span><span class="ot"> evaluates the quantile</span><span class="er">,</span><span class="ot"> and </span><span class="er">`</span><span class="ot">r...</span><span class="er">`</span><span class="ot"> generates a sample. In </span><span class="er">@</span><span class="ot">tbl-r-api-distributions which lists the </span><span class="er">`</span><span class="ot">d...</span><span class="er">`</span><span class="ot"> functions for some of the most popular distributions. The </span><span class="er">`</span><span class="ot">d</span><span class="er">`</span><span class="ot"> can be replaced with </span><span class="er">`</span><span class="ot">p</span><span class="er">`,</span><span class="ot"> </span><span class="er">`</span><span class="ot">q</span><span class="er">`,</span><span class="ot"> or </span><span class="er">`</span><span class="ot">r</span><span class="er">`</span><span class="ot"> for any of the distributions</span><span class="er">,</span><span class="ot"> depending on what you want to calculate.</span></span>
<span id="cb10-485"><a href="#cb10-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-486"><a href="#cb10-486" aria-hidden="true" tabindex="-1"></a><span class="ot">For details enter </span><span class="er">`?</span><span class="ot">dnorm</span><span class="er">`</span><span class="ot"> to view R</span><span class="er">'</span><span class="ot">s documentation page for the Normal distribution. As usual </span><span class="er">,</span><span class="ot"> replace the </span><span class="er">`</span><span class="ot">norm</span><span class="er">`</span><span class="ot"> with any distribution to read the documentation for that distribution.</span></span>
<span id="cb10-487"><a href="#cb10-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-488"><a href="#cb10-488" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> Distribution           </span><span class="er">|</span><span class="ot"> Function                   </span><span class="er">|</span><span class="ot"> Parameters                           </span><span class="er">|</span></span>
<span id="cb10-489"><a href="#cb10-489" aria-hidden="true" tabindex="-1"></a><span class="er">|------------------------|----------------------------|--------------------------------------|</span></span>
<span id="cb10-490"><a href="#cb10-490" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">Binomial(n</span><span class="er">,</span><span class="ot">p)</span><span class="er">$</span><span class="ot">        </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dbinom(x</span><span class="er">,</span><span class="ot"> size</span><span class="er">,</span><span class="ot"> prob)</span><span class="er">`</span><span class="ot">    </span><span class="er">|</span><span class="ot"> size </span><span class="op">=</span> <span class="st">$n$,</span><span class="ot"> prob </span><span class="op">=</span> <span class="st">$p$</span><span class="ot">               </span><span class="er">|</span></span>
<span id="cb10-491"><a href="#cb10-491" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">Poisson(</span><span class="er">\</span><span class="ot">lambda)</span><span class="er">$</span><span class="ot">     </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dpois(x</span><span class="er">,</span><span class="ot"> lambda)</span><span class="er">`</span><span class="ot">         </span><span class="er">|</span><span class="ot"> lambda </span><span class="op">=</span> <span class="st">$\lambda$</span><span class="ot">                   </span><span class="er">|</span></span>
<span id="cb10-492"><a href="#cb10-492" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">Exp(</span><span class="er">\</span><span class="ot">lambda)</span><span class="er">$</span><span class="ot">         </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dexp(x</span><span class="er">,</span><span class="ot"> rate)</span><span class="er">`</span><span class="ot">            </span><span class="er">|</span><span class="ot"> rate </span><span class="op">=</span> <span class="st">$\lambda$</span><span class="ot">                     </span><span class="er">|</span></span>
<span id="cb10-493"><a href="#cb10-493" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">Gamma(</span><span class="er">\</span><span class="ot">alpha</span><span class="er">,</span><span class="ot"> </span><span class="er">\</span><span class="ot">beta)</span><span class="er">$</span><span class="ot"> </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dgamma(x</span><span class="er">,</span><span class="ot"> shape</span><span class="er">,</span><span class="ot"> rate)</span><span class="er">`</span><span class="ot">   </span><span class="er">|</span><span class="ot"> shape </span><span class="op">=</span> <span class="st">$\alpha$,</span><span class="ot"> rate </span><span class="op">=</span> <span class="st">$\beta$</span><span class="ot">     </span><span class="er">|</span></span>
<span id="cb10-494"><a href="#cb10-494" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">Uniform(a</span><span class="er">,</span><span class="ot"> b)</span><span class="er">$</span><span class="ot">        </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dunif(x</span><span class="er">,</span><span class="ot"> min</span><span class="er">,</span><span class="ot"> max)</span><span class="er">`</span><span class="ot">       </span><span class="er">|</span><span class="ot"> min </span><span class="op">=</span> <span class="st">$a$,</span><span class="ot"> max </span><span class="op">=</span> <span class="st">$b$</span><span class="ot">                 </span><span class="er">|</span></span>
<span id="cb10-495"><a href="#cb10-495" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">Beta(</span><span class="er">\</span><span class="ot">alpha</span><span class="er">,</span><span class="ot"> </span><span class="er">\</span><span class="ot">beta)</span><span class="er">$</span><span class="ot">  </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dbeta(x</span><span class="er">,</span><span class="ot"> shape1</span><span class="er">,</span><span class="ot"> shape2)</span><span class="er">`</span><span class="ot"> </span><span class="er">|</span><span class="ot"> shape1 </span><span class="op">=</span> <span class="st">$\alpha$,</span><span class="ot"> shape2 </span><span class="op">=</span> <span class="st">$\beta$</span><span class="ot">  </span><span class="er">|</span></span>
<span id="cb10-496"><a href="#cb10-496" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">N(</span><span class="er">\</span><span class="ot">mu</span><span class="er">,</span><span class="ot"> </span><span class="er">\</span><span class="ot">sigma</span><span class="er">^2)$</span><span class="ot">     </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dnorm(x</span><span class="er">,</span><span class="ot"> mean</span><span class="er">,</span><span class="ot"> sd)</span><span class="er">`</span><span class="ot">       </span><span class="er">|</span><span class="ot"> mean </span><span class="op">=</span> <span class="st">$\mu$,</span><span class="ot"> sd </span><span class="op">=</span> <span class="st">$\sqrt{\sigma^2}$</span><span class="ot"> </span><span class="er">|</span></span>
<span id="cb10-497"><a href="#cb10-497" aria-hidden="true" tabindex="-1"></a><span class="er">|</span><span class="ot"> </span><span class="er">$</span><span class="ot">t_v</span><span class="er">$</span><span class="ot">                  </span><span class="er">|</span><span class="ot"> </span><span class="er">`</span><span class="ot">dt(x</span><span class="er">,</span><span class="ot"> df)</span><span class="er">`</span><span class="ot">                </span><span class="er">|</span><span class="ot"> df </span><span class="op">=</span> <span class="st">$v$</span><span class="ot">                             </span><span class="er">|</span></span>
<span id="cb10-498"><a href="#cb10-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-499"><a href="#cb10-499" aria-hidden="true" tabindex="-1"></a><span class="ot">: R API for distribution </span><span class="er">{</span><span class="ot">#tbl-r-api-distributions</span><span class="er">}</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"bottom","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>