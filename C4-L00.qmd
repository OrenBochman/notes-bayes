---
date: 2024-10-22
title: "Week 0: Introductions to time series analysis and the AR(1) process"
subtitle: Time Series Analysis
description: "The AR(1) process, Stationarity, ACF, PACF, Differencing, and Smoothing"
categories: 
  - Coursera 
  - notes
  - Bayesian Statistics
  - Autoregressive Models
  - Time Series
keywords: 
  - time series
  - notation
  - bibliography   
  - R code
image: course-banner.png
fig-caption: Notes about ... Bayesian Statistics
title-block-banner: images/banner_deep.jpg
#bibliography: references.bib
format: 
    html: 
        code-fold: true
        css: styles.css
---

I decided to migrate some material that is auxiliary to the course:

1. An overview of the course.
1. A review of some mathematical and statistical results used in the course.
1. A bibliography of books I found useful in the course.
1. A Feynman notebook for the course - is now in a separate notebook.


## Course Card

-  **Course:** [Bayesian Statistics: Time Series](https://www.coursera.org/learn/bayesian-statistics-time-series)
-  **Offered by:** University of California, Santa Cruz
-  **Instructor:** Raquel Prado
-  **Certificate:** Yes
-  **Level:** Graduate
-  **Commitment:** 4 weeks of study, 3-4 hours/week


## Overview of the course

This course seems very similar to classic basic time series course without the Bayesian part. (AR, MA, ARMA, ARIMA, SARIMA, DLM etc.)

One of the questions I had when I started this course was what is the difference between a Bayesian approach to time series analysis and a classical approach. The following is a summary of what I found:

::: {.callout-important}

### Are we Being Bayesian ?

The Bayesian approach presents primarily in:

1. Sections on Bayesian inference  where we do inference on the parameters of the models.
2. Bayesian prediction unlike an MLE prediction is a distribution of predictions not just a point estimate, and therefore is useful for quantifying uncertainty.
3. We also cover some material on model selection - this again is where the Bayesian approach to optimization presents more powerful tools than the classical approach.
4. When we want to quantify the uncertainty in our model we have four sources of uncertainty:
   1. Uncertainty due to using the correct model (structure).
      - I consider this is an epistemic uncertainty - 
      - One could reduce it by collecting more data, then applying the Bayesian model selection to choose the best model.
   1. Uncertainty due to the estimation of the model parameters. This is an epistemic uncertainty - we can reduce it by collecting more data reducing the plausible intervals for these parameters under the bayesian approach.
   1. Uncertainty due to random shocks $\epsilon_t$. for the period being predicted. This is an aleatory uncertainty.
   1.  Uncertainty in the forecasted values $X_{t+h}$
   Items 2-3 can be quantified using a plausible interval in the Bayesian approach and as we predict further into the future the interval will grow. 
5. Model selection is a big part of the Bayesian approach. We can use the DIC, WAIC, and LOO to compare models.

:::

- The book by Professor Prado is very comprehensive and covers plenty of additional models and references lots of recent research. These including VAR, VARMA models, Kalman filters, SMC/Particle filters, etc. These are useful for the *continuous control* flavours of RL. But you will need to learn it on your own. 
- In the capstone project that is the next course in the specialization the teacher adds another layer of sophistication by introducing mixtures of TS models.
- However unlike some courses I took we dive deep enough and get sufficient examples to understand how to put all the bits together into more sophisticated time series models. 




### Mathematical Review 


- There is a issues with mathematics most of the results and techniques are so rarely useful that students will soon forget most but a few very useful results. Having a good memory is a great asset in mathematics but is rarely enough. I like to review some mathematical results from my undergraduate days every five years or so. This helps me keep many of the results fresh in my mind and also makes reading new mathematics easier. Fundamentals in mathematics can fo a very long way.
This is material from topology, determinants and solving linear equations, numerical methods for decomposing matrices, and so on. Definitions of certain groups. 

- One reason this and other Bayesian courses and books can be challenging and even overwhelming is that they can use lots of mathematics. This can range from high school material like complex numbers and quadratics formulas to intermediate results like finding root of characteristic polynomials, eigenvalues, Topelitz matrices, jordan forms, and advanced topics like the Durbin-Levinson recursion and certain results from functional analysis  theory. 

Note that I have not even touched on probability and statistics in that list. 



Rather than complain I see this as an opportunity to review/learn some mathematics and statistics that can be useful to a data scientist. During my last sting in Data science I often was able to write formulas but more often then not felt that I lacked sufficient mathematical tools to manipulate them to get the kind of results I wanted. Rather then learning lots of mathematics I wanted to find the most practical and useful results for wrangling maths. When I was a physics undergraduate these might be trigonometric identities, completing the square, being familiar with many integrals and [Taylor](https://en.wikipedia.org/wiki/Taylor_series) or Maclaurin series approximations and a few useful inequalities occasionally we use l'Hopital's rule. Familiarity with some ODEs was also greatly beneficial as these come up in many physical models. Later on hermitian and unitary matrices, fourier expansions, spectral theory, and some results from functional analysis were useful.

For statistics we have the variants of the law of large numbers and the central limit theorem, convergence theorems, manipulations of the normal distribution, linear properties of expectation can get you along way. But you have to remember lots of definitions and there are lots of results and theorems that seem to be stepping stones to other results rather than any practical use.

On the other hand conjugacy of certain distributions as demonstrated by Herbert Lee and other instructors in this specialization are often very challenging. Charts of Convergence of distributions to other distributions under certain conditions are neat but. There is [Hoeffding's inequality](https://en.wikipedia.org/wiki/Hoeffding%27s_inequality) and the [Markov's inequality](https://en.wikipedia.org/wiki/Markov%27s_inequality) which can be useful but like most results in mathematics I never had a where they might be used. Then there are certain results - convergence of Markov chains, doubly stochastic matrices. De Finetti's theorem in statistics.


I have found that the more I learn the more I can understand and appreciate the material.

  - The autoregressive process gives rise to Toeplitz matrices which can be solved using the Durbin-Levinson recursion mentioned many times in the course.
  - Durbin-Levinson recursion - is an advanced topic not covered in Numerical Analysis courses or Algebra courses I took.
  - To use it with time series we also need to understand the Yule-Walker equations.
  - ar(p) require some linear algebra concepts like eigenvalues and Eigenvectors, and characteristic polynomials. 
  - The AR(p) the Wold decomposition theorem to get to the infinite order moving average representation and this is not a result I recall learning in my functional analysis course. 
  We also use some complex numbers and Fourier analysis and spectral density functions.


Summarize some of the extra curricular material I found useful in the course.


- [x] Complex numbers
- [ ] Eigenvalues, Eigenvectors and characteristic polynomials
- [x] Durbin-Levinson recursion
- [x] Yule-Walker equations
- [ ] Wiener process (Random walk)
- [ ] Brownian motion (Continuous Random walk with drift)
- [ ] Markov Chains ()
- [ ] Martingales ()
- [ ] Stopping theorem
- [x] Kalman filter
- [ ] Wold's theorem
- [ ] De Finetti's theorem
- [ ] Cholesky decomposition


### Complex Numbers (Review)

When we wish to find the roots of real valued polynomials we will often encounter complex numbers. In this course such polynomials arise naturally in the characteristic polynomials of AR(p) processes. 

We will need the polar form of complex numbers to represent some variants of AR(p) process.


The numbers in the Complex field $z \in \mathbb{C}$ numbers are numbers that can be expressed in the form $z = a + bi$, where $a,b\in\mathbb{R}$ and $i$ is the imaginary unit. The imaginary unit $i$ is defined as the square root of -1. Complex numbers can be added, subtracted, multiplied, and divided just like real numbers. 

The complex conjugate [complex conjugate]{.column-margin} of a complex number $z = a + bi$ is denoted by $\bar{z} = a - bi$. The magnitude of a complex number $z = a + bi$ is denoted by $|z| = \sqrt{a^2 + b^2}$. This is sometimes called the modulus of the complex number in this course. The argument of a complex number $z = a + bi$ is denoted by $\text{arg}(z) = \tan^{-1}(b/a)$. The polar form of a complex number is given by $z = r e^{i \theta}$, where $r = |z|$ and $\theta = \text{arg}(z)$.

The polar form of a complex number is given by:

$$
\begin{aligned}
z &= \mid z\mid e^{i \theta} \\
  &= r (\cos(\theta) + i \sin(\theta))
\end{aligned}
$$ {#eq-polar-form}

where:

- $|z|$ is the magnitude of the complex number, i.e. the distance from the origin to the point in the complex plane. 
- $\theta$ is the angle of the complex number. 


I think we will also need the unit roots. 

### Eigenvalues, Eigenvectors the characteristic polynomials and Unit roots

The Eigenvalues of a matrix are the roots of the characteristic polynomial of the matrix. The characteristic polynomial of a matrix A is defined as:

$$
\begin{aligned}
\text{det}(A - \lambda I) = 0
\end{aligned}
$$

where $\lambda$ is the Eigenvalue and $I$ is the identity matrix. The eigenvectors of a matrix are the vectors that satisfy the equation:

$$
\begin{aligned}
A v = \lambda v
\end{aligned}
$$

where $v$ is the eigenvector and $\lambda$ is the eigenvalue. The eigenvalues and eigenvectors of a matrix are used in many applications in mathematics and physics, including the diagonalization of matrices, the solution of differential equations, and the analysis of dynamical systems.

#### Unit Roots

A unit root is a root of the characteristic polynomial of an autoregressive model that is equal to 1. The presence of a unit root in an autoregressive model indicates that the model is not stationary. The unit root test is a statistical test that is used to determine whether a time series is stationary or non-stationary. The unit root test is based on the null hypothesis that the time series has a unit root, and the alternative hypothesis that the time series is stationary. The unit root test is used to determine whether a time series is stationary or non-stationary, and is an important tool in time series analysis.

### Spectral analysis (1898)

The power spectrum of a signal is the squared absolute value of its Fourier transform. 
If it is estimated from the discrete Fourier transform it is also called periodogram. 
Usually estimated using the a fast Fourier transform (FFT) algorithm.

### Yule-Walker Equations (1932)


### Durbin-Levinson recursion (Off-Course Reading)

Like me, you might be curious about the Durbin-Levinson recursion mentioned above. This is not covered in the course, and turned out to be an enigma wrapped in a mystery.

I present my finding in the note below - much of it is due to [@enwiki-LevinsonRecursion] and [@enwiki-YuleWalkerEquations]

In [@yule1927periodicities] and [@walker1931periodicity], Yule and Walker proposed a method for estimating the parameters of an autoregressive model. The method is based on the Yule-Walker equations which are a set of linear equations that can be used to estimate the parameters of an autoregressive model.

Due to the autoregressive nature of the model, the equations are take a special form called a Toeplitz matrix. However at the time they probably had to use the numerically unstable Gauss-Jordan elimination to solve these equations which is $O(n^3)$ in time complexity.

A decade or two later in [@Levinson1947Wiener] and [@Durbin1960Fitting] the authors came up for with a weakly stable yet more efficient algorithm for solving these autocorrelated system of equations which requires only $O(n^2)$ in time complexity. Later their work was further refined in [@Trench1964ToeplitzMI] and [@Zohar1969ToeplitzMI] to just $3\times n^2$ multiplication. A cursory search reveals that Toeplitz matrix inversion is still an area of active research with papers covering parallel algorithms and stability studies. Not surprising as man of the more interesting deep learning models, including LLMs are autoregressive.

So the [Durbin-Levinson recursion](https://en.wikipedia.org/wiki/Levinson_recursion) is just an elegant bit of linear algebra for solving the [Yule-Walker equations](https://w.wiki/9gVB#Estimation_of_AR_parameters) more efficiently.

Here is what I dug up:

### Durbin-Levinson and the Yule-Walker equations (Off-Course Reading)

The Durbin-Levinson recursion is a method in linear algebra for computing the solution to an equation involving a *Toeplitz matrix* AKA a *diagonal-constant matrix* where descending diagonals are constant. The recursion runs in $O(n^2)$ time rather then $O(n^3)$ time required by Gauss-Jordan elimination.

The recursion can be used to compute the coefficients of the autoregressive model of a stationary time series. It is based on the [Yule-Walker equations](https://w.wiki/9gVB#Estimation_of_AR_parameters) and is used to compute the PACF of a time series.

The Yule-Walker equations can be stated as follows for an AR(p) process:

$$
\gamma_m = \sum_{k=1}^p \phi_k \gamma_{m-k} + \sigma_\epsilon^2\delta_{m,0} \qquad \text{(Yule-Walker equations)}
$$ {#eq-yule-walker}

where:

-   $\gamma_m$ is the autocovariance function of the time series,
-   $\phi_k$ are the AR coefficients,
-   $\sigma_\epsilon^2$ is the variance of the white noise process, and
-   $\delta_{m,0}$ is the Kronecker delta function.

when $m=0$ the equation simplifies to:

$$
\gamma_0 = \sum_{k=1}^p \phi_k \gamma_{-k} + \sigma_\epsilon^2 \qquad \text{(Yule-Walker equations for m=0)}
$$ {#eq-yule-walker-m-0}

for $m > 0$ the equation simplifies to:

$$ 
  \begin{bmatrix}
    \gamma_1 \\
    \gamma_2 \\
    \gamma_3 \\
    \vdots   \\
    \gamma_p 
  \end{bmatrix} =  
  \begin{bmatrix}
    \gamma_0     & \gamma_{-1}  & \gamma_{-2}  & \cdots \\
    \gamma_1     & \gamma_0     & \gamma_{-1}  & \cdots \\
    \gamma_2     & \gamma_1     & \gamma_0     & \cdots \\
    \vdots       & \vdots       & \vdots       & \ddots \\
    \gamma_{p-1} & \gamma_{p-2} & \gamma_{p-3} & \cdots 
 \end{bmatrix}  
 \begin{bmatrix}
    \phi_{1} \\
    \phi_{2} \\
    \phi_{3} \\
    \vdots   \\
    \phi_{p} 
 \end{bmatrix}
$$

\index{Toeplitz matrix}
\index{Durbin-Levinson recursion}
and since this matrix is **Toeplitz**, we can use **Durbin-Levinson** recursion to efficiently solve the system for $\phi_k \forall k$.

Once $\{\phi_m \qquad m=1,2, \dots ,p \}$ are known, we can consider m=0 and solved for $\sigma_\epsilon^2$ by substituting the $\phi_k$ into @eq-yule-walker-m-0 Yule-Walker equations.

Of course the **Durbin-Levinson** recursion is not the last word on solving this system of equations. There are today numerous improvements which are both faster and more numerically stable.

The Yule-Walker equations are a set of p linear equations in the p unknowns $\phi_1, \phi_2, \ldots, \phi_p$ that can be used to estimate the parameters of an autoregressive model of order p. The *Yule-Walker* equations are derived by setting the sample autocorrelation function equal to the theoretical autocorrelation function of an *AR(p)* model and then solving for the unknown parameters. The **Yule-Walker** equations are given by:

$$
\begin{aligned}
\gamma(0) & = \phi_1 \gamma(1) + \phi_2 \gamma(2) + \ldots + \phi_p \gamma(p) \\
\gamma(1) & = \phi_1 \gamma(0) + \phi_2 \gamma(1) + \ldots + \phi_p \gamma(p-1) \\
\gamma(2) & = \phi_1 \gamma(1) + \phi_2 \gamma(0) + \ldots + \phi_p \gamma(p-2) \\
\vdots \\
\gamma(p) & = \phi_1 \gamma(p-1) + \phi_2 \gamma(p-2) + \ldots + \phi_p \gamma(0) \\
\end{aligned}
$$

where $\gamma(k)$ is the sample autocorrelation function at lag k. The Yule-Walker equations can be solved using matrix algebra to obtain the estimates of the AR parameters $\phi_1, \phi_2, \ldots, \phi_p$.


### Wold's theorem - (extra curricular) circa 1939


\index{Yule, George Udny}
\index{Slutsky, Eugen}
In the 1920 [George Udny Yule](https://en.wikipedia.org/wiki/Udny_Yule) and [Eugen Slutsky](https://en.wikipedia.org/wiki/Eugen_Slutsky) were researching time series and they came up with two different ways to represent a time series.

- Yule’s researches led to the notion of the autoregressive scheme.
$$
\begin{aligned}
Y_{t} & = \sum _{j=1}^{p} \phi _{j} Y_{t-j} + u_{t}
\end{aligned}
$$ {#eq-yule-autoregressive-scheme}



- Slutsky’s researches led to the notion of a moving average scheme.
$$
\begin{aligned}
Y_{t} & =\sum _{j=0}^{q} \theta _{j} u_{t-j}
\end{aligned}
$$ {#eq-slutsky-moving-average-scheme}

we can use the two schemes together and get the ARMA(p,q) model:

$$
\begin{aligned}
Y_{t} & = \sum _{j=1}^{p} \phi _{j} Y_{t-j} + u_{t} + \sum _{j=0}^{q} \theta _{j} u_{t-j}
\end{aligned}
$$ {#eq-arma-scheme}

where:


The following is extracted from: the wikipedia at https://en.wikipedia.org/wiki/Wold%27s_theorem

Wold's decomposition AKA called the Wold representation theorem states that:

> Every covariance-stationary time series $Y_{t}$ can be written as the sum of two time series, one deterministic and one stochastic.

Formally:

$$
\begin{aligned}
Y_{t} & =\sum _{j=0}^{\infty }  \underbrace{b_{j}\epsilon _{t-j}}_{\text{stochastic}} + \underbrace{\eta _{t}}_{\text{deterministic}} \\
&= \sum _{j=0}^{\infty } b_{j}\epsilon _{t-j} + \phi_{j} y_{t-j} 
\end{aligned}
$$

where:

- ${Y_{t}}$ is the time series being considered,
- ${\epsilon _{t}}$ is an white noise sequence called **innovation process** that acts as an input to the linear filter ${\{b_{j}\}}$.
- ${b}$ is the possibly infinite vector of moving average weights (coefficients or parameters)
- ${\eta _{t}}$ is a "deterministic" time series, in the sense that it is completely determined as a linear combination of its past values It may include "deterministic terms" like sine/cosine waves of ${t}$, but it is a stochastic process and it is also covariance-stationary, it cannot be an arbitrary deterministic process that violates stationarity.

The moving average coefficients have these properties:

1. Stable, that is, square summable $\sum _{j=1}^{\infty } \mid b_{j}|^{2} < \infty$
2. Causal (i.e. there are no terms with j < 0)
3. Minimum delay
4. Constant ($b_j$ independent of t)
5. It is conventional to define $b_0=1$

Any stationary process has this seemingly special representation. Not only is the existence of such a simple linear and exact representation remarkable, but even more so is the special nature of the moving average model. 

This result is used without stating its name in the course when we are show the AR(p) representation in terms of moving averages.

## Kalman Filter (1960)

$$
\begin{aligned}
x_{t} & = F_{t} x_{t-1} + G_{t} u_{t} + w_{t} && \text{(transition equation)} \\
y_{t} & = H_{t} x_{t} + v_{t} && \text{(observation equation)}
\end{aligned}
$$ {#eq-kalman-filter}

where:

- $x_{t}$ is the state vector at time t,
- $F_{t}$ is the state transition matrix,
- $G_{t}$ is the control input matrix,
- $u_{t}$ is the control vector,
- $w_{t}$ is the process noise vector,
- $y_{t}$ is the observation vector at time t,
- $H_{t}$ is the observation matrix,
- $v_{t}$ is the observation noise vector.

The Kalman filter is a recursive algorithm that estimates the state of a linear dynamic system from a series of noisy observations. The Kalman filter is based on a linear dynamical system model that is defined by two equations: the state transition equation and the observation equation. The state transition equation describes how the state of the system evolves over time, while the observation equation describes how the observations are generated from the state of the system. The Kalman filter uses these two equations to estimate the state of the system at each time step, based on the observations received up to that time step.
This could be implemented  in real time in the 1960s and was used in the Apollo missions.

The Extended Kalman Filter (EKF) is an extension of the Kalman filter that can be used to estimate the state of a nonlinear dynamic system. The EKF linearizes the nonlinear system model at each time step and then applies the Kalman filter to the linearized system. The EKF is an approximation to the true nonlinear system, and its accuracy depends on how well the linearized system approximates the true system.

### Box Jenkins Method (1970)

see [Box Jenkins Method](https://en.wikipedia.org/wiki/Box%E2%80%93Jenkins_method)

A five step process for identifying, selecting and assessing ARMA (and similar) models.


- There are three courses on Stochastic Processes on MIT OCW that I found useful:
  - [Introduction to Stochastic Processes](https://ocw.mit.edu/courses/18-445-introduction-to-stochastic-processes-spring-2015/)
  - [Discrete Stochastic Processes](https://ocw.mit.edu/courses/6-262-discrete-stochastic-processes-spring-2011/)
   - has lecture videos and notes
   - poisson processes
  - [Advanced Stochastic Processes](https://ocw.mit.edu/courses/15-070j-advanced-stochastic-processes-fall-2013/)
   - martingales
   - ito calculus

