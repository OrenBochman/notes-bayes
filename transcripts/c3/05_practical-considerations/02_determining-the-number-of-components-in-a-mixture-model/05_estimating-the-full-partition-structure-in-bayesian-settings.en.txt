We have discussed full
Bayesian inference for the number of
components of the mixture, and that is an interesting
quantity that we may want to investigate for different reasons
and specific problems. But it's not the only
interesting summary that we can obtain from the
posterior distribution, we may want to look at the full partition structure as something that we
want to summarize. That summary is
not an easy one to obtain in part because
of the label switching. So I want to discuss some tools that can
be used to assess Bolsa point estimator
for the structure, the partition structure,
and also ways to represent the uncertainty that is associated with
that partition, something that is very natural
in a Bayesian context. So today, we're going to
discuss full Bayesian inference for the partition structure. The key as I said, is going to be to select
the right summary of the posterior distribution
that addresses the issue of label switching that we observe in
mixture models. One summary that is very popular and will be
very helpful for us, it's going to be what I'm going to call the
co-clustering matrix. I'm going to call that
clustering matrix D. The ij entry of that matrix just reflects the
probability that C sub i is equal to C sub
j given the data. So it's the posterior
probability that the two observations belong
to the same component. This one is invariant to
label switching because it doesn't matter what labels they actually used
for the components, the only thing that
matters is whether two observations
have the same label. So that is a very important
property of this quantity, that it is invariant
to label switching. So one thing that we want to do with this co-clustering
matrix is we typically want to create a heatmap plot, and we will see examples
in just a minute. The advantage of
the heatmap plot is that it gives you a
sense of uncertainty. When you have a block of observations that
all of them have really high probabilities of being allocated to
the same cluster, that is essentially
telling you that you have a very well-defined
cluster with very little uncertainty about which observations belong to it. On the other hand, when this values
tend to be smaller, then that is clearly reflected
in the heatmap plot, and essentially is telling
you that even though you may report a particular
observation as belonging to one
particular clustering, you are not really
very sure about that point estimator
that you're reporting. So heatmap plots in terms
of lots of this matrix D, are very useful in terms of interpreting or assessing
how much uncertainty you have with particular decisions that you're making in terms
of the point estimate. But the other thing
that you may want to do is with this matrix, is to try to use it to obtain point estimators themselves of the partition structure
that are fully Bayesian, fully Bayesian point estimators of the partition. In this second point, I want to discuss in a
little bit more detail. In particular, what we're
going to do is just to proceed with any other
Bayesian procedure, we are going to start
with a utility function. In particular, in this case, rather than the utility function, we're going to work
with a loss function, which at the end of
the day is the same. It's just that instead
of maximizing utility, we're going to minimize loss, but we're going to start
with this loss function, that is a function of the true partition
that I don't know, but I cover posterior
distribution on, and an estimator
for that partition. In front days, we're going to construct the expected value of Lcc hat given the data. We're going to use
the suspected utility that I'm going to call L star of c hat and we are
going to try to find the c hat that maximizes
this utility function. So it turns out that for the one utility function that I'm going to
pick in a minute, when we are through with
all this calculations to obtain this expected utility, this expected utility
is going to be a function of this
matrix v alone. Therefore, it will be a key ingredient in finding
our point estimator. There are a number
of utility functions that we could use for the purpose of providing point
estimators for partitions, but I've seen a very simple
one that we sometimes find less function because of the person that
first published it. It just basically
looks at two types of errors that you can do when
you're doing clustering. One error is to assign
observations in the same cluster that in reality belong to
different clusters, and of course the opposite. So let's construct
our loss function, c hat as the sum of two terms. So what we're going to
do is we're going to look at every possible
pair of observations. So from 1 to n minus 1
in front ji plus 1-n. So this allows us to look at
every pair of observations. As I said, one type of
error is to say that observations that are in the
same cluster in reality, we really allocate them in our point estimator to
clusters that are different. Let me penalize that
by a constant Gamma 1, and this guy has to be positive. Let us consider the
other type of error. That is the observations in real life are not in
the same cluster, but I decide in my point
estimator to put them together, and this is another cost Gamma 2 that also has to be
greater than zero. So you could think about this
two terms in some sense as your Type I error
and your Type II error in the context
of hypothesis testing. That is sometimes a useful way to think about this two terms, but it's basically separating things that should be together or joining together things
that should be separate. Of course, depending on what
Gamma 1 and Gamma 2 are, you're going to weigh these
two errors differently, and you will get different
point estimators. I will come back to this
discussion about the values of Gamma 1 and Gamma 2 in a moment. But for now, let's just work with this
particular structure. So what we want to do, is we want to compute this
function that I called L star, that is just a function of c hat, and that is the expected value of Lcc hat. Well, I want to take
the expected value of this very big quantity here, if I do that expected value. Because the expected value
is a linear function, I can just take it inside, and so the sums. So I'm going to have the sum
from one to n minus one, sum from j equals i plus one to n of Gamma one. This is not random, this is the quantity that
we're trying to maximize, so it can come out. This is the indicator of c_i hat, different from c_j hat. Then I just need to compute the expectation
of this indicator. But this indicator at
the end of the day, its expectation is just the
probability of the event. So it's just the
probability that c_i is equal to c_j given the data, and if you look at
this carefully, this is just what I defined
originally as my D_ij. So that's one of the places where D_ij is going to come into play. Then I have a second term
that has Gamma two in it. Again, this indicator is just a constant for the purpose of taking
the expectation. So this is the
indicator of c_i hat, is equal to c_j hat. Then I have the expected value
of this quantity that is just the probability that c_i is different from
c_j given the data. Now as before, just like
this guy is just D_ij, it's easy to see that
this is one minus D_ij. So the probability that
they are different is one minus the probability
that they are the same. So this big function depends on the day that just through this summary D_ij that
I discussed before. Now we're going to do some
additional rearrangement in this formula to get an expression that is a
little bit more simplified. Now using the fact that the indicator that c
hat i is equal to c hat j. This is just one minus
the indicator of c_i hat is different to c_j hat, because they are
complimentary events. Then using that fact, we can just rewrite, with a little bit of algebra, our loss function L of
c hat as two terms. The first term is a double
sum from one to n minus one, from j equals i plus one, to n of Gamma one D_ ij, plus the second term that
I'm going to write as Gamma one plus Gamma two multiplied
by again the double sum, equals one to n minus one, j equals i plus one, to n of Gamma two divided by Gamma one
plus Gamma two minus d_ij, that multiplies the
indicator that c sub i hat, is equal to c sub j hat. Okay. So this just comes from substituting this in
the previous expression that we had down there, and expanding on the products
and lumping terms together. Now this is a very interesting expression
for a couple of reasons. First of all note that this is independent of c hat tilde. So it doesn't matter
who c hat tilde is, this quantity is the
same one all the time. So we can for the purpose of
maximizing this quantity, we can potentially ignore it. The other thing that
is interesting is that this is again a
multiplication factor. So I can drop this term
because it's a constant, and then also multiplying
by a constant, doesn't affect where the
function has the maximum. So maximizing this
function is equivalent to maximizing this function that I'm going to call L
star star, double star. That it just focuses on
this last piece here. So it's the sum
from i equals one, to n minus one, sum from i plus one, to n of Gamma two divided by Gamma one plus
Gamma two minus D_ ij, indicator of c_i hat, equals to c_j hat. It's interesting now that we
have reduced the problem to one of maximizing or minimizing, this case because
it's a loss function of minimizing this quantity. The interpretation is
very straight forward. So you can think about
this Gamma two divided by Gamma one plus Gamma two
as some sort of threshold, and I'm actually going
to call this D bar. So basically whether adding a term is favorable
or not depends on how the probability that those two
observations are clustered together changes with
respect to the bar. So since we're trying
to minimize the loss, we're trying to make this
quantity as small as possible. So we essentially going to include pairs of observations in the same cluster if they give
you a negative value here. In other words, if the
probability of being clustered together is higher than a certain threshold
that is given by D bar. So essentially, the ratio
of Gamma one to Gamma two, the ratio of the two
penalties that you pay for making mistakes, essentially control how likely it is that you put
observations together. In particular, if we go back
to the original expression, you can see that if you make this ratio really close to zero, then basically you're better off putting everybody in the, or putting all observations
in the same cluster. So you essentially get, if you were to make
Gamma two equal to zero, what you're going to
end up with is putting all of the observations
in the same cluster. On the other hand, if you take Gamma one to be zero so that
this ratio is one, then what you will
try to do is to put every observation within
a cluster of its own, and by taking values that are not so extreme for
Gamma one and Gamma two, you can get basically
combinations of clusters that
have all the sizes. One typical choice
is just to say that you want to pay the same penalty for both types of mistakes. In other words, Gamma one
and Gamma two is the same. In which case your
threshold is just 1.5 and you are
essentially saying that you're only going to
put observations together in the same cluster if this posterior probability
that you have up here, is greater than 1.5. So the structure of the loss function
that we end up with, is one that has very high
degree of interpretability. So let's see how to use this
particular loss function with a real data example, where we can also understand
a little bit what is the sensitivity of the results to changes in these parameters.