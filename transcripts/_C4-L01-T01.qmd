<!-- transcript of https://www.coursera.org/learn/bayesian-statistics-time-series-analysis/lecture/whV84/stationarity -->


I will now describe the concept of stationarity. 
This is an important concept because many of the standard models for time series analysis such as the autoregressive and moving average processes work under the assumption of stationarity. 
So first we will talk a little bit about just notation for the class. 
Usually when I write down {yt} like this, I'm referring to the time series process. 
So in this case I'm thinking of each of the yt is a random variable and we are recording this process sequentially over time when we take the observations. 
So here we are working as we mentioned before with equally space time series processes. 
And we are working with yt that are univariate did not multivariate in this course. I will also use the notation y1 up to capital T this is without brackets. 
This refers to the data. 
So here I am thinking that I have observed data from y1 all the way up to capital T. 
So we can also write the sequence like this. So the y1 to the capital T is just a short notation for that. So we will now talk about two concepts for stationarity one is strong stationary. This is a distributional concept and it works in the following way. 
So here we are going to assume again that we have a time series process yt. 
And the process is going to be strongly stationary if for n and it's an integer here
greater than 0 and any sequence. Of times here t1 up to the tn. So you can have as many as only one or several up to n here and any integer h>0. 
So the process {yt} is strongly stationary. If the distribution of this collection of random variables that I'm going to write in the form of a vector. 
If the distribution of this collection is the same as the distribution of this collection of random variables. So we are going to just shift by h here. 
So this has to hold again for any n and any h. The distribution of the vector of random variables is the same as the distribution of this vector of random variables. 
Then we say the process is strongly stationary. 
So there is this idea that the properties that characterize the process are kind of maintained over time. 
Then there is another notion that is a notion of weak stationarity usually in practice it is hard to determine if a process is strongly stationary. 
So sometimes we work with the other concept which is weak stationarity or second order stationarity. 
Okay, and in this case we say again that we're working with the time, series process {yt}.
So we are thinking now that the first and second moments of this process exist and are finite.
And then instead of making a distributional assumption, we say now that the first and second moments. 
Of the two sequences. 
Exist and are identical. So in this case we can also write
down that the expected value of yt. 
Is mu, meaning that the expected value of the process does not depend on the time is just constant over time. 
And then the variance of yt is constant over time. 
And the covariance here between any 2 yt and ys will depend not on what points they are not on t and s. 
But on the difference between the distance between t and s. 
So we can write this out as just the distance between t and s. 
So this is when the process is weakly or second order stationary. Strong stationarity implies weak
stationary the reverse is not true. 
If we work with Gaussian processes, then the two concepts are equivalent. 
So here again Strong stationarity implies weak or second order, provided that the moments are finite. 
And in the case of Gaussian processes which is usually the case that we are going to describe in this class. 
We are going to be having the equivalence between the strong stationarity and the weak stationarity.