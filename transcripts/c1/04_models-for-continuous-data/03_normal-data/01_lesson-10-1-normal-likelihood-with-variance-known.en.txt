The last distribution I'll talk about
is the normal distribution also known as the Gaussian distribution. The normal distribution arises
in a wide variety of contexts. Including heights of people,
manufacturing industrial processes and as a result of the central limit theorem. For now,
let's suppose the standard deviation or variance is known and we're only
interested in learning about the mean. This is the situation that often arises in monitoring of industrial
production processes. So we'll say the x sub i's are iid normal with unknown mean mu and
known variants sigma naught squared. How would we choose a prior for mu? We'd like to use a conjugate prior,
it would be convenient. It turns out the normal is conjugate for
itself for its mean parameter. So we'll specify a prior for
mu, which is normally distributed with some mean m naught and
some variance s nought squared. I'm putting on noughts to specify
particular values in this case. That these are not parameters. The posterior then mu given the data x. That will be proportional
to the likelihood. Times the prior. I'm not going to go through
all the calculations here. I'll leave that to the supplementary
material because it's fairly extensive and involves completing the square. At this point I will just
jump to the final result which is the post here from mu given
x follows a normal distribution. And its mean is nx bar over sigma naught
squared plus m naught over s naught squared all over n over sigma naught
squared plus one over s naught squared. And it has variance one over n over sigma
non squared plus one over s not squared. This is a somewhat
complicated expression but let's take a little closer
look at the posterior mean. This posterior mean,
we can rewrite as n over sigma-nought squared over n over
sigma-nought squared plus one over s-nought squared
times x bar plus one over s-nought squared
over n over sigma nought squared plus one over s
nought squared times m. A little bit of simplification
will give us n over n plus sigma nought squared over s nought squared over n plus. Sigma nought squared over
s nought squared, times m. Thus we see, that the posterior mean, is a weighted average,
of the prior mean and the data mean. And indeed that the effective sample size,
for this prior, is the ratio of the variance for
the data, to the variance in the prior. This makes sense because, the larger the variance of the prior
the less information that's in it. The smaller the variation of the prior,
the more information that's in it. We can also consider the case that
both m and sigma squared are unknown