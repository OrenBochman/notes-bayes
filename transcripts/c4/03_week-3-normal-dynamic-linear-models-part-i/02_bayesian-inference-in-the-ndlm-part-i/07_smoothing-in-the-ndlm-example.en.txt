So now we will show how to compute
the smoothing equations in this case, and it's moving distributions for
the same example with the Lake Huron data. So the first thing is
I'm going to just put all the functions into
a single set of R code. So I'm going to first source the code
called all DLM functions dot R. So that's the file that we source first,
and this file contains the functions
we have discussed before. So the set up DLM matrices
that set up initial states. The function to compute
the forward filtering equations, as well as the function to compute
the forecasting functions. So the forecasting distributions and then function to obtain the 95%
credible intervals as well. So the new thing that this function
contains is also a function call, backwards smoothing. So the code has a function that in the
input you're going to require the data and the matrices that establish
the structure of the model. And then you also have to pass what
we call here is posterior states. Is the object that
the filtering function returns. So you just have to first run the
filtering equations using the function for computing those filtering equations, and then pass that as an object to
the backward smoothing function. So if you go inside the function,
you will see that again, you're going to just obtain
the functions the matrices and keep everything in terms
of the posterior moments. So now in the notation here is mnt
is just to denote the mean of the smoothing distribution for
theta t given DT. Assuming that you have observed
capital T observations. So the variance is Cnt,
the mean for the distribution, the mean distribution
of the series is also going to be kept here in
terms of fnt and Qnt. So you just get again,
if you look into the equations, we are using the equations we discussed
before to get the moments for the distribution of the state
vector given the DT. And also the moments for
the smoothed distribution of the mean response in are kept in fnt and
Qnt. And then the function returns at
list with all these moments for all these distributions. So going back to the example,
once we source all the functions again, I'm just repeating
something we did before. Which is just reading the data, plotting
the data and setting up the matrices for the structure of the model as well
as the prior distribution for theta0 given D0. So, as we discussed before, F is one,
this is the first order polynomial model. G is one, V is going to be assumed
equal to one and W is equal to one. And then we have m0 and C0 here
are the moments of the prior distribution. We use the functions that just
put all those matrices and initial states together as a object. And as I said, we first have to run
the forward filtering function. We keep the results here in
results filtered as we did before. We can compute credible intervals for
the distribution of theta_t given Dt. And now we proceed with the smoothing. So we use the function
backwards smoothing. We pass the data, we pass the matrices here that we
define with the structure of the model. So that contains F, G, V and W. And then here we also have to
pass the filtering results. So the results filtered is
that object that contains at, Rt, mt, Ct, ft and
Qt with the filtering equations. So we run that we get, we can compute
as well credible intervals for the distribution,
the smoothing distributions for the theta_t given DT. And now we can plot everything, so
here again, I'm plotting the data. The dots correspond to
the actual observations. And then we are just going to plot here,
this is the filtering distribution. So the solid red line is the mean
of the filtering distribution for Thetat given DT. And the dotted lines correspond to the 95%
credible intervals associated to that. And then I'm now going to plot
the smoothing distributions in a different color. So, the solid blue line that
I'm showing you here corresponds to the mean of the smoothing
distributions. After we have observed
all those 94 data points. And I can compute also
the credible intervals, 95% credible intervals for
those distributions. Those are the blue dotted lines. So you can see that the blue line
is smoother than the red line, which is always the case for
the smoothing distributions. You're using more information. And also the intervals,
the credible intervals, are narrower than the ones for
the filtering distributions. So this is just how you can
compute the smooth distributions. If you change the structure of your model,
of course, in terms of either the F the G, the V or the W you're going
to obtain different results. And also the prior distribution has
an impact in your posterior estimates and your smoothing estimates
in this particular case.