In this code, we discuss Bayesian inference
for the case of the AR(1) process assuming a conditional likelihood
and a reference prior. I'm going to go ahead and
just generate some data. Here I'm sampling 200
observations from an AR(1) with AR
coefficient 0.9, and standard deviation
one or variance one for the
observational variance. Here, just recall how we compute the maximum likelihood
estimator for the AR(1) using the conditional likelihood
and making the correspondence to the regression setting. Here I'm setting up my y
response vector, my X matrix, and then I just run
the equations to obtain the two estimates. The maximum likelihood
estimate for the AR coefficient in this case, and then I also get
an estimate for the observation and
variance that is unbiased. Now, if we want to proceed with Bayesian inference using
the conditional likelihood and the reference prior, we obtain closed form
inference in this case. We can use direct
sampling by first sampling the variance parameter and then conditional
on the variance, we can sample the
AR coefficients. Here I'm just going to set
up the sample to be 3000. I'm going to obtain 3000 samples from the
posterior distribution. The first step is to sample
from the posterior of v, which is an inverse
Gamma distribution with the corresponding
parameters. Recall here we have a degrees
of freedom parameter, and then we have
the other parameter for the inverse gamma. I'm sampling these 3000 samples and now conditional
on each of those, I'm going to sample from
a normal distribution. This piece of code
is just doing that. Just sampling from the normal
for each of the variances, for each of the samples
of the variances here. I can plot now a histogram of the posterior samples for phi. This is my histogram for the
posterior sample for phi. If you remember, the process was
originally sampled from an AR with coefficient 0.9, so this is my posterior. Here I can also show a histogram of the
posterior for the variance. Again recall, in this case, we were sampling from an AR process with
observation and variance one. This is our posterior
inference based on the reference prior and the
conditional likelihood.