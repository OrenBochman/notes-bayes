---
title: "Homework on Bayesian Inference - M2L5HW2"
subtitle: "Bayesian Statistics: From Concept to Data Analysis"
categories:
  - Bayesian Statistics
keywords:
  - Bayesian Inference
  - Homework
---

::::: {.content-visible unless-profile="HC"}

::: {.callout-caution}
Section omitted to comply with the Honor Code
:::

:::::

::::: {.content-hidden unless-profile="HC"} 


::: {#exr-bayesian-infernce-1}
[Bayes' theorem]{.column-margin}

When do we use the continuous version of Bayes' theorem?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:

-   [x] $\theta$ is continuous
-   [ ] $Y$ is continuous
-   [ ] $f(y\mid\theta)$ is continuous
-   [ ] All of the above
-   [ ] None of the above

If $\theta$ is continuous, we use a probability density for the prior.
:::

::: {#exr-bayesian-infernce-2}
Consider the coin-flipping example from the lesson. Recall that the likelihood for this experiment was Bernoulli with unknown probability of heads, i.e., $f(y \mid \theta) = \theta^y(1-\theta)^{1-y} I_{\{ 0 \le \theta \le 1 \}}$ and we started with a uniform prior on the interval $[0,1]$

After the first flip resulted in heads $(Y_1=1)$, the posterior for $\theta$ became $f(\theta \mid Y_1=1) = 2\theta I_{\{ 0 \le \theta \le 1 \}}$

Now use this posterior as your prior for $\theta$ before the next (second) flip. Which of the following represents the posterior PDF for $\theta$ after the second flip also results in heads $(Y_2=1)$?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:

-   [ ] $f(\theta \mid Y_2=1) = \frac{ (1-\theta) \cdot 2\theta } { \int_0^1 (1-\theta) \cdot 2\theta d\theta} I_{\{ 0 \le \theta \le 1 \}}$

-   [x] $f(\theta \mid Y_2=1) = \frac{ \theta \cdot 2\theta} { \int_0^1 \theta \cdot 2\theta d\theta} I_{\{ 0 \le \theta \le 1 \}}$

-   [ ] $f(\theta \mid Y_2=1) = \frac{ \theta (1-\theta) \cdot 2\theta} { \int_0^1 \theta (1-\theta) \cdot 2\theta d\theta} I_{\{ 0 \le \theta \le 1 \}}$

This simplifies to the posterior PDF $f(\theta \mid Y_2=1) = 3 \theta^2 I_{\{ 0 \le \theta \le 1 \}}$.

Incidentally, if we assume that the two coin flips are independent, we would have arrived at the same posterior if we had again started with a uniform prior and performed a single update using $Y_1=1$ and $Y_2=1$.
:::

::: {#exr-bayesian-infernce-3}
Consider again the coin-flipping example from the lesson. Recall that we used a $\text{Uniform}(0,1)$ prior for $\theta$.

Which of the following is a correct interpretation of $\mathbb{P}r(0.3 < \theta < 0.9) = 0.6$?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:

-   [x] $(0.3, 0.9)$ is a 60% credible interval for $\theta$ before observing any data.

-   [ ] $(0.3, 0.9)$ is a 60% credible interval for $\theta$ after observing Y=1.

-   [ ] $(0.3, 0.9)$ is a 60% confidence interval for $\theta$.

-   [ ] The posterior probability that $\theta\in(0.3,0.9)$ is 0.6.

The probability statement came from our prior, so the prior probability that $\theta$ is in this interval is 0.6.
:::

::: {#exr-bayesian-infernce-4}
Consider again the coin-flipping example from the lesson. Recall that the posterior PDF for $\theta$, after observing $Y=1$, was $f(\theta \mid Y=1) = 2\theta I_{\{0 \le \theta \le 1 \}}$. Which of the following is a correct interpretation of $\mathbb{P}r(0.3 < \theta < 0.9 \mid Y=1) = \int_{0.3}^{0.9} 2\theta d\theta = 0.72$?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:

-   [ ] $(0.3, 0.9)$ is a 72% credible interval for $\theta$ before observing any data.

-   [x] $(0.3, 0.9)$ is a 72% credible interval for $\theta$ after observing $Y=1$.

-   [ ] $(0.3, 0.9)$ is a 72% confidence interval for $\theta$.

-   [ ] The prior probability that $\theta \in (0.3,0.9)$ is 0.72.

The probability statement came from the posterior, so the posterior probability that $\theta$ is in this interval is 0.72.
:::

::: {#exr-bayesian-infernce-5}
Which two quantiles are required to capture the middle 90% of a distribution (thus producing a 90% equal-tailed interval)?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:

-   [ ] .025 and .975

-   [ ] .10 and .90

-   [x] .05 and .95

-   [ ] 0 and .9

90% of the probability mass is contained between the .05 and .95 quantiles (or equivalently, the 5th and 95th percentiles). 5% of the probability lies on either side of this interval.
:::

<div>

Suppose you collect measurements to perform inference about a population mean $\theta$. Your posterior distribution after observing data is $\theta \mid \mathbf{y} \sim \text{N}(0,1)$.

Report the upper end of a 95% equal-tailed interval for $\theta$.

</div>

::: {.solution .callout-tip collapse="true"}
#### Solution:

```{r}
#| label: C1-L05-Ex2-1
qnorm(p=0.975, mean=0, sd=1)
```

where probability=0.975, mean=0, standard_dev=1
:::

::: {#exr-bayesian-infernce-7}
What does "HPD interval" stand for?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:

-   [ ] Highest precision density interval
-   [ ] Highest point distance interval
-   [ ] Highest partial density interval
-   [x] Highest posterior density interval
:::

::: {#exr-bayesian-infernce-8}
Each of the following graphs depicts a 50% credible interval from a posterior distribution. Which of the intervals represents the HPD interval?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:

-   [ ] 50% interval: $\theta\in(0.500,1.000)$
-   [ ] 50% interval: $\theta\in(0.400,0.756)$
-   [ ] 50% interval: $\theta\in(0.196,0.567)$
-   [x] 50% interval: $\theta\in(0.326,0.674)$

This is the 50% credible interval with the highest posterior density values. It is the shortest possible interval containing 50% of the probability under this posterior distribution.
:::

:::::