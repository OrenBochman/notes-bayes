---
title: "Homework Alternative Priors - M4L11HW1"
subtitle: "Bayesian Statistics: From Concept to Data Analysis"
categories:
  - Bayesian Statistics
keywords:
  - Exponential Distribution
  - Homework
---

::::: {.content-visible unless-profile="HC"}

::: {.callout-caution}
Section omitted to comply with the Honor Code
:::

:::::

::::: {.content-hidden unless-profile="HC"} 


::: {#exr-alt-priors-1}
Suppose we flip a coin five times to estimate $\theta$, the probability of obtaining heads. We use a Bernoulli likelihood for the data and a non-informative (and improper) $\mathrm{Beta}(0,0)$ prior for $\theta$. We observe the following sequence: $(H, H, H, T, H)$.

Because we observed at least one H and at least one T, the posterior is proper. What is the posterior distribution for $\theta$
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:


Beta(4,1)

We observed four "successes" and one "failure," and these counts are the parameters of the posterior beta distribution.
:::

::: {#exr-alt-priors-2}
Continuing the previous question, what is the posterior mean for $\theta$ ? Round your answer to one decimal place.
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:


$\bar{y} = 0.8 $
:::

::: {#exr-alt-priors-3}
Consider again the thermometer calibration problem from Lesson 10.

Assume a normal likelihood with unknown mean $\theta$  and known variance $\sigma^2=0.25$. Now use the non-informative (and improper) flat prior for $\theta$ across all real numbers. This is equivalent to a conjugate normal prior with variance equal to $\infty$.

You collect the following $n=5$ measurements: (94.6, 95.4, 96.2, 94.9, 95.9). What is the posterior distribution for $\theta$?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:


Recall from the lesson that with a flat prior on $\theta$ , the posterior distribution is

$$
\mathcal{N}(\bar{y},\frac{\sigma^2}{n})=\mathcal{N}(95.4,0.05)
$$
:::

::: {#exr-alt-priors-4}
Which of the following graphs shows the Jeffreys prior for a Bernoulli/binomial success probability p?

Hint: The Jeffreys prior in this case is $\mathrm{Beta}(1/2, 1/2)$.
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:


Beta(1/2, 1/2).
:::

::: {#exr-alt-priors-5}
Scientist A studies the probability of a certain outcome of an experiment and calls it $\theta$ . To be non-informative, he assumes a $Uniform(0,1)$ prior for $\theta$ .

Scientist B studies the same outcome of the same experiment using the same data, but wishes to model the odds $\phi= \frac{\theta}{1−\theta}$. Scientist B places a uniform distribution on $\phi$. If she reports her inferences in terms of the probability $\theta$, will they be equivalent to the inferences made by Scientist A?
:::

::: {.solution .callout-tip collapse="true"}
#### Solution:


No, they did not use the Jeffreys prior.

The uniform prior on $\theta$ implies the following prior PDF for

$$
f(\phi)= \frac{1}{(1+\phi)^2} I_{\{\phi≥0\}}
$$

​which is not the uniform prior used by Scientist B.

They would obtain equivalent inferences if they both use the Jeffrey's prior.
:::

:::::